# 금주의 AI 에이전트

Author: Pascal Biese
URL: https://www.llmwatch.com/p/ai-agents-of-the-week-f8b

============================================================

**핵심 요약**

**행동으로서의 동적 메모리(Dynamic Memory as Action):** 연구원들은 자율 에이전트(autonomous agent)가 미리 설정된 휴리스틱(heuristics)에 의존하는 대신, 컨텍스트(context)를 능동적으로 삭제하거나 편집함으로써 자체 작업 메모리(working memory)를 관리할 수 있도록 하는 '행동으로서의 메모리(Memory-as-Action)' 프레임워크를 도입했습니다. 메모리 관리를 에이전트의 정책(policy)(강화 학습(reinforcement learning)을 통해 학습됨)의 일부로 구성함으로써, 에이전트는 관련 없는 세부 사항을 전략적으로 잊고 장기적인 목표에 집중할 수 있습니다. 이는 컨텍스트 과부하를 방지하여 장기적인 작업(long-horizon tasks)에서 향상된 작업 성능과 효율성을 가져왔습니다.

**다중 에이전트 RL(Multi-Agent RL)의 혁신:** AT-GRPO라는 새로운 방법은 여러 협력하는 LLM 에이전트(LLM agents)에 온-정책 강화 학습(on-policy reinforcement learning)을 적용했습니다. 이 방법은 역할(role)과 턴(turn)별로 에이전트를 훈련시키는 그룹화 전략을 도입하여, 다중 에이전트 프롬프트(multi-agent prompts)에서 표준 RL(standard RL)의 불안정성을 극복했습니다. 그 결과 성능이 크게 향상되었습니다. 장기 계획 작업(long-horizon planning tasks)에서 다중 에이전트 정확도는 약 14%에서 약 98%로 급증했으며(단일 에이전트 RL 기준선(single-agent RL baseline) 대비), 코딩(+약 5%) 및 수학(+약 13%) 추론 작업에서도 주목할 만한 성과를 보였습니다. 이는 에이전트를 함께 공동 훈련(co-training)하는 것이 계획 및 추론 능력을 극적으로 향상시킬 수 있음을 보여줍니다.

**공유 캐시(Shared Cache)를 통한 효율성:** 에이전트 팀의 중복 계산을 해결하기 위해 KVCOMM 프레임워크(KVCOMM framework)는 에이전트가 '사고 과정(thought process)' 캐시(caches)를 공유할 수 있도록 합니다. 이 프레임워크는 에이전트들의 컨텍스트 오프셋(context offsets)을 정렬함으로써 트랜스포머(transformer)의 키-값 캐시(key-value caches)를 에이전트 간에 영리하게 재사용합니다. KVCOMM은 다양한 다중 에이전트 작업(도구 사용, 수학, 코딩)에서 출력 품질 손실 없이 약 70%의 계산 재사용을 달성했으며, 5개 에이전트 설정에서 최대 7.8배의 속도 향상을 제공했습니다. 이는 에이전트 스웜(agent swarms)이 더 효율적으로 통신하여 낭비되는 사이클(cycles)을 피하는 미래를 시사합니다.

**더 어려운 에이전트 작업 생성:** “ProgSearch” 데이터 생성 파이프라인(data-generation pipeline)은 길고 도구를 사용하는 임무를 위한 에이전트 훈련의 과제를 해결했습니다. 이 파이프라인은 현재 능력보다 약간 더 어려운 각 새로운 작업을 보장하기 위해 루프(loop) 내에서 기준 웹 에이전트(baseline web agent)를 사용하여 점진적으로 난이도가 증가하는 질문-답변 작업을 합성합니다. 그 결과 생성된 데이터셋(dataset)은 규모는 작지만 이전 세트보다 2배 더 다양한 도구 사용 행동을 포함했으며, 반복적인 전략을 피하는 에이전트를 생성했습니다. 이 데이터로 미세 조정(fine-tuned)된 모델은 기존 데이터로 훈련된 모델보다 더 나은 성능을 보였습니다(벤치마크(benchmarks)에서 최대 +8-23%). 이는 더 큰 모델뿐만 아니라 더 스마트한 훈련 데이터가 자율 에이전트의 역량에 핵심임을 강조합니다.

**광범위한 동향:** 통합적인 주제는 구조화된 에이전트의 반성(reflectiveness)과 적응성(adaptability)입니다. 에이전트가 지식 구조를 잊고 발전시킬 수 있게 하는 메모리 시스템부터 협력적인 문제 해결을 촉진하는 다중 에이전트 알고리즘(multi-agent algorithms)에 이르기까지, 이번 주 연구는 AI 에이전트를 더 큰 자율성과 장기적인 역량으로 이끌고 있습니다. 또한 커뮤니티는 AI 에이전트 사회가 신뢰할 수 있고 안전하다는 것이 무엇을 의미하는지 공식화하기 시작했습니다. 새로운 모델링 프레임워크(modeling framework)는 다중 에이전트 작업 오케스트레이션(multi-agent task orchestration)을 위한 수십 가지 검증 가능한 속성(활성(liveness), 안전(safety), 공정성(fairness) 등)을 정의하여, 이러한 강력한 에이전트가 더욱 독립적이 되더라도 올바르고 안전하게 유지되도록 보장하는 것을 목표로 합니다. 아래의 심층 분석에서는 이러한 각 개발 사항 – 즉 핵심 혁신, 자율 AI(autonomous AI)에 중요한 이유, 해결하는 문제, 그리고 에이전트 AI(agentic AI)의 미래에 무엇을 시사하는지 자세히 살펴보겠습니다.