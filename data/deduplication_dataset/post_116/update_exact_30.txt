인공지능(AI)은 지난 수십 년간 인류의 삶을 혁신적으로 변화시켜 왔으며, 특히 최근 몇 년간은 그 발전 속도가 예측 불가능할 정도로 가속화되고 있습니다. 이미지 생성부터 자연어 처리, 복잡한 문제 해결에 이르기까지 AI는 놀라운 능력을 선보이며 우리의 일상과 산업 전반에 깊숙이 스며들었습니다. 하지만 이러한 눈부신 성과 뒤에는 AI의 근본적인 작동 원리와 그 기반이 되는 가정들에 대한 심도 깊은 질문들이 숨어 있습니다. 과연 현재 AI가 나아가고 있는 방향은 올바른 것일까요? 우리는 지능의 본질을 제대로 이해하고 있을까요?

이 글은 AI의 가장 기본적인 구성 요소인 '인공 뉴런'에 대한 우리의 이해가 현대 AI의 발전과 어떤 관계를 가지는지 비판적으로 탐구하고자 합니다. AI의 역사를 거슬러 올라가, 그 시작점인 맥컬록과 피츠의 초기 모델부터 현재의 대규모 언어 모델(LLM)에 이르기까지, AI의 여정을 재조명하고 그 과정에서 우리가 간과했을지도 모르는 근본적인 문제들을 짚어봅니다.

***

I. 1943년 과학자 워렌 S. 맥컬록(Warren S. McCulloch)과 월터 피츠(Walter Pitts)가 최초의 뉴런 수학적 모델을 발명했을 때, 그들은 80년 후 인류가 자신들의 아이디어에 수천억 달러를 쏟아부을 것이라고는 상상조차 하지 못했을 것입니다. 하지만 우리는 지금 여기에 있고 그들은 없으므로, 현재의 인공지능 열풍이 얼마나 명백히 터무니없게 되었는지 그들은 우리에게 말해줄 수 없습니다. AI 모델이 생성되는 현대적인 파이프라인을 살펴보면—어떤 무명의 개발자가 작성한 첫 번째 코드 줄부터 샘 알트만(Sam Altman)이 무대에 올라 "이 새로운 모델로 저는 AGI(인공 일반 지능)를 느꼈습니다"라고 주장하는 순간까지—"음, 이건 다른 방식으로 했어야 했어"라고 진지하게 주장할 수 있는 여러 지점들이 있습니다. (아마도 다음 세대 AI 모델이 알려지지 않은 벤치마크(benchmark) 테스트에서 성능을 0.5% 포인트 높이기 위해 1000조 개의 데이터 토큰(tokens)—즉, 1,000,000,000,000,000개—를 필요로 한다는 것은 자랑할 만한 일이 아닐 것입니다.) 그러나 이 분야의 시작으로 거슬러 올라가야만 충분한 관심이나 고려를 받지 못했던 최초의 논란이 되는 결정을 찾을 수 있다는 것은 진정으로 놀라운 일입니다. 심지어 더 강력한 컴퓨터와 더 많은 돈, 더 많은 데이터 토큰이 이 목적에 투입된 후에도 말이죠. AI 연구소들이 왜 대규모 언어 모델(LLMs)을 인간 두뇌 크기(대략 1000조 개의 시냅스(synapses) 범위)로 확장하려고 하는지, 또는 왜 딥러닝(DL)과 강화 학습(RL)을 결합하는 것이 충분하다고 생각하는지(이것이 현재의 사전 학습(pre-training) + 사후 학습(post-training) 전략입니다), 심지어 인공 신경망(ANNs)이 진정으로 그들이 필요로 하는 유일한 패러다임(paradigm)인지 의아해할 수도 있겠지만, 그래도 이 분야의 원죄를 지적하지는 못할 것입니다: 맥컬록과 피츠의 뉴런 모델의 단순성을 생물학적 대응물의 충실한 표현으로 받아들인 것 말입니다. 이는 기능적으로나 구조적으로나 훨씬 더 복잡하다는 것이 입증되었습니다. AI를 연구하는 사람들은 뇌에서 영감을 받은 은유에 대한 모든 애정에도 불구하고, 그 한 가지를 결코 다시 검토하지 않았습니다. 이제 와서 되돌리기는 너무 늦었을지 모르지만, 인류의 운명을 손에 쥐고 있는 사람들의 순진함과 어리석음을 지적하기에 너무 늦은 때는 없습니다. 이것이 극적으로 들릴 수도 있지만, 그것은 당신이 저의 다른 기사 "그들은 기계 신의 제단에 경제를 희생하고 있다"를 읽지 않았기 때문입니다. 우리는 맥컬록과 피츠의 연구에서부터 어떻게 여기까지 왔는지 이해해야 하며, 첫 번째 단계는 몇 가지 흔한 오해를 명확히 하는 것입니다. 많은 분들이 ChatGPT나 생성형 AI(generative AI)를 AI 전체를 아우르는 기본 레이블(label)로 생각하게 되었습니다. 저는 당신을 비난하지 않습니다. 업계는 이 제유법(synecdoche, 부분이 전체를 나타냄)을 밀어붙이기 위해 많은 노력을 기울였습니다. 가장 인기 있는 하위-하위-하위 분야가 그렇게 많은 투자와 관심을 모을 수 있다면, 이 잘못된 특성 부여가 역사책과 대중의 의견에 수정되지 않은 채 스며들도록 내버려 두지 않을 이유가 무엇이겠습니까? 이것은 마케팅 거래입니다. 그러나 우리가 AI 분야의 분류 체계(taxonomy)를 구상한다면—위키피디아(Wikipedia)조차 잘 해내지 못한 벅찬 과제입니다—이러한 오류를 거부하고 대신 다음과 같은 벤 다이어그램(Venn diagram)을 그려야 합니다(전문가들은 어떠한 부정확성도 용서할 것입니다): ChatGPT까지의 AI 분류 체계(간략화된). 만약 제가 인식론적으로 엄격했다면, 먼저 분류 기준을 정의하고 모든 예외를 설명해야 했을 것입니다. 하지만 저에게는 그럴 시간이 없고 당신에게는 그럴 집중력이 없습니다. 좋습니다, 생각보다 쉬웠네요: AI 분야는 기본적으로 중첩된 원들의 묶음이며, 엄밀한 의미의 벤 다이어그램조차 아닙니다. 왜냐하면 그 어떤 것도 서로 교차하지 않기 때문입니다. 그래서 우리는 인공지능(artificial intelligence)이 기계 학습(machine learning)을 포함하고, 기계 학습이 인공 신경망(artificial neural networks)을 포함하고, 인공 신경망이 딥러닝(deep learning)을 포함하고, 딥러닝이 생성형 AI를 포함하고, 생성형 AI가 대규모 언어 모델(large language models)을 포함하고, 대규모 언어 모델이 ChatGPT를 포함한다는 것을 알 수 있습니다. 또는 수학적 표기법으로 (인용 준비 완료): AI ⊃ ML ⊃ ANNs ⊃ DL ⊃ GenAI ⊃ LLMs ⊃ ChatGPT. (이것을 친구들에게 보여주면, 그들은 당신이 1) 지적 천재이거나 2) 참을 수 없는 괴짜라고 생각할 것입니다.) 대부분의 사람들이 모르는 또 다른 것이 있는데, 이는 토끼굴이 얼마나 깊은지 파악하는 데 근본적입니다: ChatGPT가 대표 역할을 하는 더 작은 세 가지 하위 분야—생성형 AI, LLM, 그리고 트랜스포머(transformer) 기반 챗봇(chatbot)—는 지난 10년 동안 구상되었지만 (각각의 시작일을 정한다면, GenAI는 2014년 "생성적 적대 신경망(Generative Adversarial Networks)" 논문에, LLM은 2017년 "어텐션 이즈 올 유 니드(Attention is all you need)" 논문에, 그리고 현대 챗봇은 물론 2022년 ChatGPT 출시에 해당한다고 말할 수 있습니다), 다른 네 분야는 훨씬 더 오래되었습니다. AI는 1956년 여름에 연구 분야로 확립되었습니다. ML과 DL은 각각 1959년과 1986년에 도입되었습니다. 그리고 인공 신경망(artificial neural networks)—당시 미성숙했던 신경과학 분야에서 차용한 용어—은 워렌 맥컬록과 월터 피츠의 선구적인 연구와 함께 1943년에 가장 먼저 등장했습니다. 그들의 연구는 현재 인공지능에 대한 최초의 연구로 간주되며, 우리의 이야기는 여기서 시작됩니다: 트라우마를 치유하려면, 그 기원을 찾아야 합니다. (AI 선구자 위르겐 슈미트후버(Jürgen Schmidhuber)는 이 모든 날짜에 이의를 제기할 것이지만, 저는 역사가가 아니므로, 동료 심사를 거친 계보(genealogy)는 불필요합니다; 우리는 전환점의 약식 타임라인(timeline)만 필요합니다.) 이 모든 지루한 배경 설명 후에, 저는 수사적 질문을 던지며 계속할 수 있을 것입니다: 생물학적 뉴런(biological neuron)이 단일 인공 뉴런(artificial neuron)보다 전체 인공 신경망(artificial neural network)으로 더 잘 표현된다고 제가 말한다면 어떨까요? 아니면, 덜 괴짜스럽게 말하자면: 추론할 수 있는 지능형 에이전트(agent)를 만드는 데 관심을 두는 분야가 왜 바위처럼 고집스럽게 행동하는 것을 고집할까요? 아니면, 더 명확하게 말하자면 (마지막 질문입니다, 맹세합니다): AI에서 처음으로 만들어진 가정이 현실의 위험한 단순화라는 것이 거듭해서 입증되었음에도 불구하고, 왜 아무도 그 가정을 다시 검토하지 않았을까요?

***

**초기 AI 모델의 부침과 딥러닝의 부활: 단순함 속의 복잡성 추구**

맥컬록과 피츠의 뉴런 모델은 AI 연구의 중요한 시작점이었지만, 그 이후 AI의 역사는 결코 순탄하지 않았습니다. 이 단순한 모델을 기반으로 한 초기 연구는 곧 한계에 부딪혔고, 이는 AI 분야에 깊은 성찰의 시간을 가져다주었습니다.

1950년대 후반, 프랑크 로젠블라트(Frank Rosenblatt)는 맥컬록-피츠 모델을 기반으로 한 퍼셉트론(Perceptron)을 개발했습니다. 퍼셉트론은 입력층과 출력층으로 구성된 단일 계층 신경망(single-layer neural network)으로, 간단한 패턴 분류 문제에서 인상적인 성능을 보여주며 AI 연구에 큰 기대를 불러일으켰습니다. 하지만 1969년 마빈 민스키(Marvin Minsky)와 시모어 A. 파퍼트(Seymour A. Papert)는 그들의 저서 『퍼셉트론(Perceptrons)』에서 단일 계층 퍼셉트론이 XOR(배타적 논리합)과 같은 비선형 분류 문제를 해결할 수 없음을 수학적으로 증명했습니다. 이 비판은 AI 연구에 찬물을 끼얹었고, ‘AI 겨울(AI Winter)’이라는 침체기로 이어지는 주요 원인 중 하나가 되었습니다. 당시 컴퓨터 과학계는 퍼셉트론의 한계가 인공 신경망 전반의 한계라고 오해하는 경향이 있었습니다.

그러나 AI 연구는 완전히 멈추지 않았습니다. 1980년대에 제프리 힌튼(Geoffrey Hinton), 데이비드 루멜하트(David Rumelhart), 로널드 윌리엄스(Ronald Williams) 등은 다층 퍼셉트론(multi-layer perceptron)을 훈련할 수 있는 역전파(Backpropagation) 알고리즘을 재발견하고 발전시켰습니다. 이는 은닉층(hidden layers)을 통해 복잡한 비선형 관계를 학습할 수 있게 하여, 이론적으로는 어떤 함수도 근사할 수 있는 범용 근사자(universal approximator)로서 인공 신경망의 잠재력을 다시금 부각시켰습니다. 역전파 알고리즘의 발전은 두 번째 AI 겨울을 끝내고 딥러닝(Deep Learning)의 시대를 여는 결정적인 계기가 되었습니다.

하지만 여기서 주목해야 할 중요한 점은, 역전파와 다층 신경망의 도입에도 불구하고 각 개별 뉴런의 기본 모델은 여전히 맥컬록-피츠 모델의 단순한 입출력 논리에서 크게 벗어나지 않았다는 것입니다. 비선형 활성화 함수(nonlinear activation functions)의 도입과 가중치(weights)의 최적화는 모델의 표현력을 비약적으로 향상시켰지만, 생물학적 뉴런의 복잡한 내부 메커니즘을 반영하는 방향으로 발전한 것은 아니었습니다. 오히려 이는 단순한 구성 요소들이 대규모로 연결되고 계층화될 때, 상상 이상의 복잡한 기능이 '창발(emergent properties)'될 수 있다는 믿음을 강화했습니다.

이러한 접근 방식은 엄청난 성공을 거두었지만, 동시에 '블랙박스(black box)' 문제라는 새로운 도전을 야기했습니다. 수많은 계층과 수십억 개의 매개변수(parameters)를 가진 딥러닝 모델은 왜 특정 결정을 내리는지, 어떤 방식으로 정보를 처리하는지 인간이 직관적으로 이해하기 어렵게 만들었습니다. 이는 생물학적 뇌가 어떻게 작동하는지 이해하려는 신경과학의 설명 가능한(explainable) 접근 방식과는 대조적입니다. AI는 기능적 성능(functional performance)에 초점을 맞추면서, 그 내부 작동 원리의 투명성(transparency)을 희생하는 길을 걸어왔습니다.

이러한 맥락에서, AI 연구자들이 지능을 구현하기 위해 생물학적 뉴런의 복잡성을 얼마나 반영해야 하는지에 대한 논쟁은 계속해서 이어지고 있습니다. 현재의 딥러닝 모델은 놀라운 능력을 보여주지만, 이는 방대한 데이터와 막대한 컴퓨팅 파워를 통해 '규모의 힘(power of scale)'을 빌린 결과입니다. 과연 이러한 양적 성장이 지능의 모든 본질적인 문제를 해결할 수 있을까요? 아니면, 여전히 맥컬록과 피츠의 '원죄'가 우리 발목을 잡고 있는 것일까요? 이러한 질문들은 다음 섹션에서 다룰 생물학적 뉴런에 대한 최근의 놀라운 발견들과 함께 더욱 심화될 것입니다.

***

III. (여기서 어떤 기술적이거나 전문 용어적인 세부 사항을 따를 필요는 없다는 점을 명심하십시오. 중요한 부분은 신경과학이 뉴런, 신경망, 뇌, 지능에 대해 아는 것과 AI가 그것들에 대해 아는 것 사이의 극명한 대조를 느끼는 것입니다.) 생물학적 뉴런의 신호 수용체(signal receptor)인 수상돌기(dendrites)를 잠시 살펴보겠습니다. 1980년대 초, 크리스토프 코흐(Christof Koch)와 다른 연구자들은 수상돌기 형태(dendritic morphology)와 시냅스 패턴(synaptic patterns)이 뉴런이 입력을 내부적으로 처리하는 방식에 영향을 미칠 수 있음을 발견했습니다. 오랫동안 과학자들은 수상돌기가 균일하게 행동하고 다른 뉴런에서 오는 입력을 수동적으로 추가한다고 생각했지만, 코흐의 발견은 형태와 기능이 교과서에서 제시하는 것보다 훨씬 더 복잡하다는 것을 밝혀냈습니다. 1996년, 컬럼비아 대학교(Columbia University)와 벨 연구소(Bell Labs)의 과학자들은 개별 수상돌기의 역할을 조사하여 수상돌기 자체가 처리 단위(processing units)로 작동한다는 것을 발견했습니다: 수상돌기는 스파이크(spikes)를 생성하기 위한 자체 임계값(threshold, 수상돌기 스파이크(dendritic spikes)라고 불림)을 가지고 있으며, 이는 전체 뉴런의 임계값과는 다릅니다. 즉, 뉴런은 MCP 모델이 제시하는 것처럼 단순한 "논리 게이트(logic gates)"가 아닙니다. 수상돌기는 그 자체로 논리 게이트 역할을 할 수 있는 것으로 보입니다. 따라서 생물학적 뉴런은 독립적인 처리 시스템으로 구성된 처리 시스템입니다: 프로세서(processor) 내의 프로세서. 인공 신경망에서 이를 표현하려면, 뉴런 간의 연결은 신경 출력에서의 역할에 영향을 미치는 독특한 형태를 가져야 할 것입니다(실제로 그렇지 않습니다). 그런 다음, 그러한 연결은 내부적으로 처리 시스템으로 작동할 것입니다(실제로 그렇지 않습니다): 뉴런에 도달하는 각 입력 연결은 뉴런의 전체 출력을 변경하는 스파이크를 생성하거나(또는 생성하지 않거나) 할 것입니다(실제로 그렇지 않습니다). 이러한 복잡성 불일치는 생물학적 뉴런이 계층형 네트워크(layered network)로 더 잘 이해되어야 함을 의미하며, 여기서 계층(수상돌기)은 비선형 중간 입출력 매핑(nonlinear intermediate input-output mappings)으로 기능합니다. 결과로 나오는 중간 출력은 "연결 트리(connection tree)"의 형태에 따라 합산되어 최종 출력을 생성합니다. 불과 5년 전인 2020년, 알베르트 기돈(Albert Gidon)과 베를린 훔볼트 대학교(Humboldt University of Berlin) 동료들은 이러한 놀라운 발견을 바탕으로 사이언스(Science)지에 획기적인 논문을 발표했습니다. 그들은 현재 모델로는 설명되지 않은 피라미드형 인간 뉴런(pyramidal human neurons)의 새로운 입출력 특징을 발견했습니다. 이 뉴런의 수상돌기는 임계 수준(threshold level)의 자극에 대해 강도가 가장 높고, 들어오는 전류가 증가할 때 가장 낮은 유형의 스파이크를 생성합니다. 이 발견은 일부 수상돌기가 XOR 논리 게이트(XOR logical gates) 역할을 할 수 있음을 증명했습니다. 즉, 입력 중 하나만 참일 경우에만 출력이 참입니다. 1969년, AI 선구자인 마빈 민스키(Marvin Minsky)와 시모어 A. 파퍼트(Seymour A. Papert)는 단일 계층 퍼셉트론(single-layer perceptron, 초기 유형의 인공 신경망)이 이러한 유형의 계산을 수행할 수 없음을 증명했습니다. 기돈의 연구는 단일 생물학적 수상돌기가 이를 수행할 수 있음을 증명합니다. 생물학적 뉴런 내부의 요소가 전체 신경망이 할 수 없는 복잡한 계산을 수행할 수 있습니다. 물론, 더 복잡한 것들은 할 수 있었겠지만(여기서는 수십 개의 매개변수(parameters)에 대해 이야기하고 있으며, GPT-4o는 수천억 개를 가졌습니다), 이것은 여전히 인간 두뇌의 기본 요소와 AI 시스템 간의 두 자릿수 규모의 계산 격차를 나타냅니다. 수상돌기가 기본적인 인공 신경망의 작업을 수행할 수 있다면, 생물학적 뉴런은 인공 뉴런에 비해 얼마나 더 복잡한가요? 아니면, 더 나은 질문은, 얼마나 더 강력한가요? 2021년, 기돈의 연구 1년 후, 데이비드 베니아게프(David Beniaguev)와 동료들은 뉴런(Neuron)지에 수십 년 동안 제기되어 온 것을 증명하는 논문을 발표했습니다: 인공 뉴런은 생물학적 뉴런을 전혀 정확하게 표현할 수 없습니다. 이를 증명하기 위해 그들은 피라미드형 인간 뉴런의 입출력 행동을 시뮬레이션하기 위해 현대 기계 학습(machine learning) 기술을 사용했습니다. 그들은 두 가지를 테스트하고 싶었습니다: 실제 입출력 쌍으로 훈련되었을 때 인공 신경망이 뉴런 출력을 정확하게 예측할 수 있는지 여부, 그리고 생물학적 뉴런의 전체 복잡성을 충분한 정확도로 포착하기 위해 인공 신경망이 얼마나 커야 하는지. 그들은 최소한 5계층 128단위 시공간 컨볼루션 네트워크(temporal convolutional network, TCN)가 피라미드형 뉴런의 입출력 패턴을 밀리초(millisecond) 해상도(단일 스파이크 정밀도)로 시뮬레이션하는 데 필요하다는 것을 발견했습니다. 그들은 깊이와 너비를 수정하여 8계층 256단위 TCN이 최고의 성능을 달성한다는 것을 발견했습니다. 대략적인 비교를 하자면: 이는 단일 생물학적 뉴런이 적절하게 시뮬레이션되기 위해 640개에서 2048개의 인공 뉴런을 필요로 한다는 의미입니다. 이는 세 자릿수 규모입니다. 제가 가능한 한 엄격하게 말하고 싶기 때문에, 이것이 생물학적 뉴런이 이만큼 더 많은 계산 능력이나 복잡성을 가지고 있다는 것을 반드시 의미하지는 않지만, 두 가지 유형의 뉴런이 구조, 기능, 행동 면에서 이전에 생각했던 것보다 훨씬 더 다르다는 명확한 신호라는 점을 주목하십시오. 이러한 이유와 제가 여기서 언급하지 않을 다른 이유들 때문에, 인공 신경망, 그리고 딥러닝과 LLM에 기반한 현대 AI의 전체 구조가 전혀 작동한다는 것이 기적입니다. 그들은 이것을 "딥러닝의 비합리적인 효과(unreasonable effectiveness of deep learning)"라고 부릅니다. 비합리적으로 효과적인 것의 문제는 그것이 똑같이 비합리적이거나, 오히려 예상치 못한 순간에 고장날 수 있다는 것입니다. 베니아게프 팀은 생물학적 뉴런을 시뮬레이션하기가 왜 그렇게 어려운지 정확한 메커니즘을 밝혀낼 수 있었습니다: 수상돌기 형태(dendritic morphology)와 NMDA라고 불리는 특정 유형의 시냅스 수용체(synapse receptor)의 존재였습니다. 이것들은 신경과학에서 오랫동안 잘 알려져 있었지만, 교실을 거의 벗어나지 않는 소수의 연구를 제외하고는 현대 AI와 ANN에서는 완전히 무시되어 온 생물학적 뉴런의 구조적, 기능적 측면입니다. 제가 공유할 마지막 예시는 파나요타 포이라지(Panayiota Poirazi) 팀이 2025년 1월 네이처 커뮤니케이션즈(Nature Communications)에 발표한 논문입니다. 이 팀은 수상돌기 형태와 연결성을 가진 인공 신경망을 구축하여 표준 신경망보다 우수한 효율성, 회복력, 정밀도를 보임을 보여주었습니다. 이것은 학자들을 특징짓는 선의적이고 순진한 방식으로 영리하고 용감합니다: 그들은 AI와 신경과학 사이의 간극을 메우려 노력하지만, 그들이 호소하려는 사람들에 의해 다리가 해체되었다는 것을 깨닫지 못합니다. 이 논문은 흥미로움에도 불구하고, 놀랍게도 23회 인용되었지만, 자금은 전혀 받지 못했습니다. 이러한 통찰력에서 몇 가지 질문이 발생합니다: 왜 AI 커뮤니티는 시뮬레이션하려는 현실에 더 잘 적응하기 위해 그 기반을 재구성하려 하지 않았는가? AI는 그 기반이 전복되고 처음부터 재건될 때까지 AGI(인공 일반 지능)를 달성하려는 탐구에서 실패할 운명인가? 그렇게 근본적인 수준에서 AI를 변경하는 것의 결과는 무엇인가? 아니면, 반대로, 아무것도 변경하지 않는 것의 결과는 무엇인가?

***

**생물학적 영감과 AI의 미래: 단순한 스케일링을 넘어**

수상돌기의 놀라운 복잡성과 단일 생물학적 뉴런이 수행하는 정교한 계산 능력에 대한 최신 연구는 AI 커뮤니티에 중요한 질문을 던집니다. 현재의 인공 신경망이 단순화된 뉴런 모델로도 놀라운 성과를 내고 있지만, 이것이 과연 지능의 궁극적인 형태를 탐구하는 데 충분한 기반이 될 수 있을까요? 아니면, 우리는 생물학적 지능의 깊이를 이해하기 위해 더 근본적인 변화를 모색해야 할까요?

흥미롭게도, 최근의 일부 AI 아키텍처는 명시적인 생물학적 모방을 목표로 하지는 않지만, 결과적으로 생물학적 뇌의 작동 원리와 유사한 특성을 보여주기도 합니다. 예를 들어, 트랜스포머(Transformer) 모델의 핵심인 **어텐션 메커니즘(attention mechanism)**은 입력 데이터의 특정 부분에 '집중'하여 관련성을 판단하는 방식으로 작동합니다. 이는 인간 뇌가 복잡한 정보 속에서 중요한 자극에 선택적으로 주의를 기울이는 방식과 유사합니다. 또한, 이미지 처리 분야에서 혁혁한 공을 세운 **컨볼루션 신경망(Convolutional Neural Networks, CNN)**은 시각 피질(visual cortex)이 시각 정보를 계층적으로 처리하며 단순한 선분이나 모서리에서부터 점점 더 복잡한 특징(예: 얼굴, 객체)을 추출하는 방식과 유사한 구조를 가지고 있습니다. 이러한 유사성은 수학적 최적화 과정에서 우연히 발견된 효율적인 정보 처리 방식일 수도 있고, 혹은 지능의 본질적인 원리가 물리적 기판을 넘어 보편적으로 적용될 수 있음을 시사하는 것일 수도 있습니다.

더 나아가, 뇌의 에너지 효율성을 모방하려는 시도 중 하나로 **희소 활성화(sparse activation)** 연구가 있습니다. 생물학적 뇌는 모든 뉴런이 동시에 활성화되는 것이 아니라, 특정 작업에 필요한 뉴런들만이 선택적으로 활성화되는 희소 코딩(sparse coding) 방식을 사용합니다. 이는 에너지 효율성을 높이고 정보 처리의 밀도를 조절하는 데 중요한 역할을 합니다. 일부 인공 신경망에서도 희소 활성화를 도입하여 모델의 효율성을 높이고 과적합(overfitting)을 줄이는 연구가 진행되고 있습니다. 또한, 순환 신경망(Recurrent Neural Networks, RNN)의 일종인 LSTM(Long Short-Term Memory)이나 트랜스포머 모델의 게이팅 메커니즘(gating mechanisms)은 정보의 흐름을 조절하고 불필요한 정보를 걸러내는 역할을 합니다. 이는 시냅스 가소성(synaptic plasticity)이나 신경 조절(neuromodulation)과 같이 뇌에서 정보 처리의 유연성을 담당하는 생물학적 메커니즘과 부분적으로 유사하다고 볼 수 있습니다.

이러한 발견들은 **지능의 기판 독립성(substrate independence)**이라는 철학적 논쟁을 다시금 수면 위로 끌어올립니다. 지능이 특정 생물학적 구조(탄소 기반의 뇌)에만 국한되지 않고, 충분히 복잡한 정보 처리 시스템이라면 어떤 물리적 기판(실리콘 기반의 컴퓨터)에서도 구현될 수 있다는 주장입니다. 만약 그렇다면, 인공 신경망이 생물학적 뉴런을 완벽하게 모방할 필요는 없으며, 현재의 단순화된 모델과 대규모 스케일링을 통한 접근 방식도 유효한 경로가 될 수 있습니다. 하지만 문제는 현재 AI 시스템의 막대한 컴퓨팅 자원 및 에너지 소비량입니다. LLM 훈련에 드는 천문학적인 에너지 비용은 생물학적 뇌의 경이로운 에너지 효율성(일반적인 뇌는 20와트(watt) 정도의 전력만으로 작동합니다)과 극명한 대조를 이룹니다. 이러한 비효율성은 장기적인 관점에서 지속 가능한 AI 발전에 심각한 도전 과제를 제시합니다.

또한, 현재 AI 모델은 방대한 양의 훈련 데이터에 의존하는데, 이는 인간 유아가 적은 데이터와 경험만으로도 세상을 학습하고 추론하는 방식과는 다릅니다. 진정한 일반 지능(AGI)을 달성하기 위해서는 단순히 데이터 패턴을 암기하고 모방하는 것을 넘어, 새로운 환경에 적응하고, 창의적으로 문제를 해결하며, 효율적으로 학습하는 능력이 필수적입니다. 이러한 능력은 생물학적 뇌의 복잡한 구조와 역동적인 상호작용에서 비롯될 가능성이 높습니다.

이러한 한계를 극복하기 위해, 하드웨어 수준에서 뇌의 구조와 기능을 모방하려는 **뉴로모픽 컴퓨팅(Neuromorphic Computing)** 연구가 활발히 진행되고 있습니다. IBM의 트루노스(TrueNorth)나 인텔의 로이히(Loihi)와 같은 뉴로모픽 칩은 이벤트 기반(event-driven) 처리 방식과 메모리와 연산 유닛을 통합하는 아키텍처를 통해 기존 컴퓨터의 폰 노이만 병목 현상(von Neumann bottleneck)을 우회하고, 뇌처럼 에너지 효율적인 병렬 처리를 목표로 합니다. 이는 단순히 소프트웨어 알고리즘의 개선을 넘어, AI의 근본적인 '물리적 기반'을 혁신하려는 시도입니다.

궁극적으로, AI의 미래는 단순한 스케일링이나 특정 패러다임에 대한 맹목적인 추종을 넘어, 다양한 분야의 통찰력을 통합하는 학제 간 연구(interdisciplinary research)에 달려 있을 것입니다. 신경과학은 지능의 본질에 대한 심오한 통찰력을 제공하며, 컴퓨터 과학은 이를 구현할 수 있는 새로운 아키텍처와 알고리즘을 개발할 것입니다. 이 두 분야의 협력을 통해 우리는 생물학적 영감을 바탕으로 하면서도 공학적으로 효율적이고 지속 가능한, 진정한 지능형 시스템을 구축할 수 있을 것입니다.

**결론: 지능의 본질을 찾아서**

우리는 맥컬록과 피츠의 단순한 뉴런 모델에서 시작된 AI의 여정이 현재의 놀라운 딥러닝 시대를 열었음을 인정해야 합니다. 하지만 이 여정은 동시에 지능의 본질에 대한 근본적인 질문들을 끊임없이 던지고 있습니다. 현재 AI의 성공은 주로 '규모의 힘'에 의존하고 있으며, 이는 막대한 컴퓨팅 자원과 데이터, 그리고 그에 따른 천문학적인 에너지 소비를 요구합니다. 이는 원문에서 언급된 '자본의 동기'와 '잘못된 아키텍처'라는 비판적 시각과 맞닿아 있습니다.

AI가 진정한 인공 일반 지능(AGI)으로 나아가기 위해서는 단기적인 성능 향상과 더불어, 장기적인 관점에서 지능의 본질에 대한 깊이 있는 이해와 지속 가능한 발전 경로를 모색해야 합니다. 생물학적 뉴런의 복잡성에 대한 신경과학의 최신 연구는 우리에게 지능이 단순히 선형적인 계산의 합이 아님을, 오히려 복잡한 상호작용과 동적인 구조에서 비롯되는 '창발적 현상'일 수 있음을 시사합니다.

리처드 서튼(Richard Sutton)의 '쓴 교훈(Bitter Lesson)'은 컴퓨팅 자원을 늘리는 것이 단기적으로 가장 효과적인 전략일 수 있음을 강조합니다. 그러나 이 교훈은 '어떤 구성 요소에서 시작해야 하는가'라는 더 근본적인 질문을 간과할 수 있습니다. 단순화된 모델에 계속해서 계층을 추가하는 것이 언젠가는 한계에 부딪힐 것이라는 경고는 여전히 유효합니다.

결론적으로, AI의 미래는 기술적 진보뿐만 아니라 철학적 성찰을 요구합니다. 우리는 인공지능이 인간 지능의 단순한 복사본이 될 필요는 없지만, 생물학적 지능이 제시하는 효율성과 적응력의 원리를 무시해서는 안 됩니다. '맥컬록과 피츠 뉴런이 신이 되는 것이 합리적인 목표라고 생각하지 않습니다'라는 말처럼, AI의 기반을 재고하고, 신경과학과 인지과학의 통찰력을 적극적으로 수용하여, 더욱 견고하고 지속 가능한 지능의 길을 모색하는 것이 지금 우리에게 주어진 가장 중요한 과제일 것입니다. 이는 단지 기술적 선택의 문제가 아니라, 인류의 미래를 결정할 중요한 방향 설정의 문제이기도 합니다.

사실은 사람에 대한 AI 블로그
구독