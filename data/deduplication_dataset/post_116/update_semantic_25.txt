다음은 원문을 바탕으로 재구성된 업데이트 문서입니다.

**I.**
1943년 신경 과학자 워렌 S. 맥컬록(Warren S. McCulloch)과 월터 피츠(Walter Pitts)가 신경 세포의 최초 수학적 모형(mathematical model)을 고안했을 때, 80년이 지난 지금 인류가 그 개념에 천문학적인 자금을 쏟아붓고 있으리라고는 상상조차 못했을 것입니다. 당시 그들이 현재의 인공지능(AI) 광풍이 얼마나 비현실적인지 목격할 수 없다는 점이 아쉽습니다. 오늘날 인공지능 모형(AI model)이 개발되는 일련의 과정을 보면—익명의 개발자가 작성한 첫 줄의 코드(code)부터 샘 알트만(Sam Altman)이 무대에서 "이 새로운 모형으로 저는 AGI(인공 일반 지능, artificial general intelligence)를 느꼈습니다"라고 선언하는 순간까지—"이것은 다른 접근 방식이 필요했다"고 진지하게 주장할 수 있는 다양한 지점들이 존재합니다. (차세대 인공지능 모형이 특정 벤치마크(benchmark)에서 단 0.5% 포인트의 성능 향상을 위해 1000조 개에 달하는 데이터 조각(token)을 요구한다는 사실은 결코 자랑스러운 성과가 아닐 것입니다.) 놀라운 점은, 이 분야의 근본적인 오류가 수십 년 전, 즉 더 강력한 컴퓨터와 막대한 자원, 그리고 방대한 데이터가 투입되기 훨씬 이전에 충분한 재검토나 숙고 없이 결정되었다는 것입니다. 왜 인공지능 연구 기관들이 대규모 언어 모형(LLM)을 인간 두뇌와 유사한 규모(대략 1000조 개의 시냅스(synapse) 수준)로 확장하려 하는지, 혹은 딥러닝(DL)과 강화 학습(RL)의 결합(현재의 사전 학습(pre-training)과 사후 학습(post-training) 전략)만으로 충분하다고 여기는지, 나아가 인공 신경망(ANN)이 지능 구현을 위한 유일한 패러다임(paradigm)인지 의문을 가질 수 있습니다. 하지만 이 모든 의문에도 불구하고, 이 분야의 진정한 원죄는 맥컬록-피츠 신경세포 모형의 간소함이 생물학적 신경세포의 정확한 모사라고 간주된 데서 비롯된다는 사실을 간과하고 있습니다. 생물학적 신경세포는 기능적 및 구조적으로 훨씬 더 복잡하다는 것이 이미 수많은 연구를 통해 입증되었습니다. 뇌에서 영감을 받은 비유(metaphor)에 대한 깊은 애정을 표명하는 인공지능 연구자들조차 이 근본적인 전제를 다시 검토한 적이 없습니다. 지금 와서 이를 되돌리기는 너무 늦었을지 모르지만, 인류의 미래를 좌우하는 위치에 있는 이들의 순진함과 오판을 지적하는 데는 결코 늦지 않았습니다. 이 주장이 다소 과장되게 들릴 수 있다면, 그것은 아마도 제가 이전에 작성한 "그들은 기계 신의 제단에 경제를 희생하고 있다"라는 글을 읽지 않았기 때문일 것입니다. 우리는 맥컬록과 피츠의 업적에서부터 현재의 상황에 이르게 된 과정을 이해해야 하며, 그 첫걸음은 몇 가지 흔한 오해를 해소하는 것입니다. 많은 사람들이 챗GPT(ChatGPT)나 생성형 인공지능(generative AI)을 인공지능 전체를 대표하는 용어로 여기는 경향이 있습니다. 이는 여러분의 잘못이 아닙니다. 업계는 이러한 부분과 전체를 동일시하는 제유법(synecdoche)을 적극적으로 활용해왔습니다. 가장 인기 있는 세부 분야가 막대한 투자와 관심을 끌어모을 수 있다면, 이러한 잘못된 인식이 역사책과 대중의 인식 속에 수정되지 않은 채 자리 잡도록 내버려 두는 것이 마케팅(marketing) 측면에서 유리하기 때문입니다.

그러나 만약 우리가 인공지능 분야의 체계적인 분류(taxonomy)를 시도한다면—위키피디아(Wikipedia)조차 제대로 해내지 못한 어려운 과제입니다—이러한 오류를 배제하고 다음과 같은 벤 다이어그램(Venn diagram) 형태로 이해해야 할 것입니다 (전문가들은 다소의 부정확성을 너그러이 이해해 주시리라 믿습니다): 챗GPT까지 이어지는 인공지능의 간략화된 분류 체계. 만약 제가 인식론적으로 엄밀하게 접근한다면, 먼저 분류 기준을 명확히 하고 모든 예외 사항을 설명해야 할 것입니다. 하지만 저에게는 그러한 여유가 없고 여러분에게는 그럴 만한 집중력이 없을 것입니다. 좋습니다. 생각보다 간단하게 정리되네요. 인공지능 분야는 본질적으로 중첩된 원들의 집합으로, 엄밀한 의미의 벤 다이어그램조차 아닙니다. 왜냐하면 각 범주가 서로 교차하지 않고 포함 관계를 이루기 때문입니다. 즉, 인공지능(AI) 영역은 기계 학습(ML)을 포괄하고, 기계 학습은 인공 신경망(ANN)을 포함하며, 인공 신경망은 딥러닝(DL)을, 딥러닝은 생성형 AI(GenAI)를, 생성형 AI는 대규모 언어 모델(LLM)을, 그리고 대규모 언어 모델은 챗GPT(ChatGPT)를 품는 계층적 구조를 이룹니다. 이를 수학적 표기법(mathematical notation)으로 표현하면 다음과 같습니다: AI ⊃ ML ⊃ ANNs ⊃ DL ⊃ GenAI ⊃ LLMs ⊃ ChatGPT. (이것을 친구들에게 보여주면, 그들은 당신이 1) 지적 천재이거나 2) 참을 수 없는 괴짜라고 생각할 것입니다.)

대부분의 사람들이 간과하고 있지만, 이 분야의 깊이를 이해하는 데 근본적인 또 다른 사실이 있습니다. 챗GPT를 대표로 하는 생성형 AI, LLM, 그리고 트랜스포머(transformer) 기반 챗봇(chatbot)과 같은 세 가지 하위 분야는 지난 10년 사이에 구상되었지만 (각각의 시작점을 꼽자면, 생성형 AI는 2014년의 "생성적 적대 신경망(Generative Adversarial Networks)" 논문, LLM은 2017년의 "어텐션 이즈 올 유 니드(Attention is all you need)" 논문, 그리고 현대 챗봇은 물론 2022년 챗GPT의 출시로 볼 수 있습니다), 다른 네 분야는 훨씬 더 오랜 역사를 지닌다는 점입니다. 인공지능은 1956년 여름에 정식 연구 분야로 확립되었습니다. 기계 학습과 딥러닝은 각각 1959년과 1986년에 도입되었습니다. 그리고 인공 신경망—당시 미성숙했던 신경과학 분야에서 차용한 용어—은 워렌 맥컬록과 월터 피츠의 선구적인 연구와 함께 1943년에 가장 먼저 등장했습니다. 그들의 연구는 현재 인공지능에 대한 최초의 시도로 평가되며, 우리의 이야기는 여기서부터 시작됩니다. 상처를 치유하려면 그 기원을 찾아야 하듯이, 인공지능의 현주소를 이해하려면 그 뿌리를 탐색해야 합니다. (인공지능 선구자 위르겐 슈미트후버(Jürgen Schmidhuber)는 이 모든 연대에 이의를 제기할 수도 있지만, 제가 역사가가 아니므로, 동료 심사를 거친 계보(genealogy)는 불필요합니다. 우리는 단지 중요한 전환점들을 요약한 타임라인(timeline)만 필요합니다.)

이러한 배경 설명을 마치고 나면, 저는 수사적인 질문을 던지고 싶어집니다. 만약 제가 생물학적 뉴런(biological neuron)이 단일 인공 뉴런(artificial neuron)보다는 전체 인공 신경망으로 더 잘 표현된다고 말한다면 어떨까요? 혹은 좀 더 비전문적인 표현으로, 추론 능력을 갖춘 지능형 에이전트(agent)를 만드는 데 몰두하는 분야가 왜 그토록 완고하게 기존의 방식을 고수하는 것일까요? 다시 말해 (이것이 마지막 질문입니다, 맹세합니다), 인공지능 분야에서 처음 세워진 가정이 현실을 위험하게 단순화한 것이라는 사실이 거듭 입증되었음에도 불구하고, 왜 아무도 그 가정을 재검토하지 않았을까요? 이 질문은 단순히 기술적인 문제를 넘어, 과학 철학적 관점에서 우리가 지능을 어떻게 정의하고 구현하려 하는지에 대한 근본적인 성찰을 요구합니다. 과거의 결정이 현재의 방향을 결정짓는 강력한 힘을 가질 때, 그 결정이 합리적이었는지, 그리고 그로 인해 발생할 수 있는 장기적인 파급 효과는 무엇인지 되짚어보는 것은 매우 중요합니다.

**II.**
최초의 신경망이 탄생한 것은 초기 컴퓨터 과학의 태동기였던 1943년이었습니다. 컴퓨터 과학의 선구자 중 한 명인 앨런 튜링(Alan Turing)은 불과 7년 전에 계산 가능성(computability)과 튜링 기계(Turing machine)에 대한 기념비적인 논문을 발표했으며, 그의 유명한 모방 게임(Imitation Game), 즉 "튜링 테스트(Turing Test)"(게리 마커스(Gary Marcus)의 주장과는 달리 이미 명백히 통과된 것으로 평가됩니다)에 대한 논문은 또 다시 7년 후에야 세상에 공개될 예정이었습니다. 1943년 당시, 신경 과학자들은 이미 수십 년 동안(최소한 19세기 후반 산티아고 라몬 이 카할(Santiago Ramón y Cajal)과 카밀로 골지(Camillo Golgi)의 연구 이래로) 생물학적 신경 세포를 모형화해왔습니다. 그러나 맥컬록과 피츠의 연구는 신경 세포를 명제 논리(propositional logic)의 관점에서, 즉 원칙적으로 컴퓨터로 구현될 수 있는 시스템으로 처음 기술했다는 점에서 중요한 의미를 가집니다. 인공지능의 역사에 정통한 사람이라면 이 그림을 바로 알아볼 것입니다: MCP 뉴런. 매우 간단하죠. 이것이 바로 맥컬록-피츠 신경세포 모형(MCP)입니다. 이 맥컬록-피츠 신경세포 모델(MCP)은 80년 전 고안된 유물과 같지만, 여전히 대부분의 현대 AI 입문 교육 과정에서 필수적으로 다루어진다. 그 이유는 MCP가 오랜 세월 동안 정교화가 필요 없었던 완벽한 모형이라서가 아니라, 딥러닝이 1943년 이후 기본 구성 요소(elemental level)에서 거의 변화하지 않았기 때문입니다. 과학계의 격언인 "모든 모형은 불완전하지만 일부는 유용하다"는 말이 인공지능 분야에서는 '결함 있는 모형도 효과를 낼 수 있다'는 의미로 지나치게 확장되어 무책임한 경지에 이르렀다. 그 폐해는 곧 드러날 것입니다.

MCP 신경세포는 생물학적 신경 세포의 단순화된 신경생리학적 버전(neurophysiological version)을 표현하기 위해 고안되었습니다. 일련의 입력(inputs)이 신경 세포로 들어오면, 신경 세포는 이를 처리한 다음 출력(output)을 생성하거나 생성하지 않습니다. 여기에는 임계 활성화 함수(threshold activation function)가 적용되었습니다. 즉, 입력의 합이 음수이면 출력은 0이고, 그렇지 않으면 1입니다. 현재의 신경망(챗GPT의 기반인 트랜스포머(transformer) 아키텍처(architecture)와 같은)은 의미 있는 학습과 더 정밀한 입출력 매핑(mapping)을 위해 가중치 입력(weighted inputs)과 더 복잡한 비선형 활성화 함수(nonlinear activation functions)를 사용합니다 (이것들이 무엇을 의미하는지 자세히 이해할 필요는 없습니다). 그러나 이들 또한 MCP 모형의 약간 개선된 버전에 불과합니다. 기본적인 원리는 동일합니다. 즉, 일부 입력이 출력으로 변환되는 것입니다. 신경 세포가 잘 학습하는지 여부는 이러한 모형들이 실제 생물학적 신경 세포와 닮지 않았다는 사실과는 무관합니다. 현재의 인공 신경망(ANN) 신경 세포 모형.

이러한 맥락에서 "AI는 단지 선형 대수학(linear algebra)일 뿐이다"라는 말을 들을 수 있는데, 이는 완전히 틀린 말은 아닙니다. 이 기본적인 수준에서는 사실입니다. 문제는 이러한 주장을 과도하게 확장하는 것입니다. 규모가 커지면서 새로운 복잡성(complexity)이 나타나기 때문입니다 ("더 많은 것은 다르다" 등). 이것이 제가 그러한 종류의 비판을 싫어하는 이유입니다. 사실인 측면에서는 사소하지만, 흥미로울 수 있는 측면에서는 잘못된 주장입니다. 마치 톨스토이(Tolstoy)의 "안나 카레니나(Anna Karenina)"가 다른 모든 책과 다를 바 없는 책이라고 말하는 것과 같습니다. 사실이지만 무의미하죠. 분석이 신경 세포 수준에 머무는 한, 아키텍처를 무시하는 것은 정당할 수 있지만, 규모는 아무도 메울 수 없는 인식론적 공백(epistemic voids)을 만듭니다. 이 때문에 "우리는 AI가 어떻게 작동하는지 모른다"는 말을 듣게 될 수도 있습니다. 이는 완전히 틀린 말은 아닙니다. 현대 인공지능은 설계되거나 코딩되거나 구축되는 것이 아니라, 정원의 꽃이나 숲의 나무처럼 양육되고 성장하기 때문입니다.

하지만 다시 MCP로 돌아가 봅시다. 가장 큰 단순화—그리고 모형의 충실도를 가장 해치는 부분—는 각 신경 세포가 공간의 한 점으로 축소된다는 것입니다. 이는 일부 단순한 신경 세포의 행동을 시뮬레이션하기에 충분하지만, 다른 복잡한 신경 세포의 생물물리학적 본질은 너무나 미묘하고 복합적입니다. 생체 뉴런은 수상돌기(dendrites), 세포체(soma), 축삭(axons)을 통해 전기 신호가 시공간적으로 전달되며, 각 수상돌기의 기능, 시냅스(synapse) 연결 패턴, 다양한 수용체(receptors) 유형이 신경 활동에 복합적으로 영향을 미친다. 모든 수상돌기가 동일하게 작동하는 것도 아니며, 모든 입력이 출력 생성에 참여하는 것도 아닙니다 (수상돌기를 따라 전압이 감소합니다). 수상돌기 나무 형태(dendritic tree morphology), 시냅스 패턴, 다양한 유형의 수용체가 모두 신경 세포의 행동에 영향을 미칩니다. 그리고 훨씬 더 많은 기본적인 메커니즘(mechanisms)과 과정이 궁극적으로 우리의 지능을 발생시키는 기반을 형성합니다. 이러한 특성 중 어느 것도 MCP나 현재 사용되는 신경 세포 모형에 설명되어 있지 않습니다. (신경형태학(neuromorphic) 연구 및 업데이트된 기본 신경 세포 모형—"표현형 누출 기억 뉴런(Expressive Leaky Memory neurons)", "다중 구획 스파이크 뉴런(Multi-compartment spiking neurons)", 또는 "수상돌기 스파이크 뉴런(Dendritic spiking neurons)"—과 같이 인공지능을 근본적으로 현대화하려는 시도가 있었지만, 그러한 노력은 존재함에도 불구하고 학계의 일부 알려지지 않은 구석을 제외하고는 자금이나 관심을 모으지 못합니다.)

(이 이상하게 들리는 신경 세포 이름들도 모두 모형이라는 것을 알아야 합니다. 다시 한번, 우리는 "모든 모형은 틀렸지만, 일부는 유용하다"는 경구(aphorism)를 떠올려야 합니다. 과학의 목표는 우리가 파악하기 어려울 가능성이 높은 세상의 진정한 본질을 밝히는 것이 아니라, 모형과 헤아릴 수 없는 현실 사이의 불일치를 줄이면서도 유용하게 유지하는 것입니다. 바로 이 지점에서 과학과 공학이 충돌합니다. 너무 가까이 다가가면 약간 틀렸지만, 감당할 수 없거나 실행 불가능한 모형을 갖게 될 것입니다. 너무 멀리 떨어져 있으면 지나치게 틀린 모형을 갖게 될 것입니다. 궁금하시다면, 신경 과학에서 신경 세포 행동을 수학적으로 표현하는 고전적인 황금 표준 모형은 1952년의 호지킨-헉슬리 모형(Hodgkin–Huxley model)인데, 이는 이온 채널 역학(ion channel dynamics)(Na⁺, K⁺, 누설 전류—이게 무슨 뜻이든 간에, 그렇죠?)을 설명하는 네 개의 연립 미분 방정식으로 신경 세포를 설명하며, 나중에 나온 거의 모든 생물물리학적 모형의 기반이 됩니다. 재미있게도 이 모형들은 시뮬레이션(simulation) 등을 위해 컴퓨터를 필요로 합니다.)

주목할 만한 점은, 1943년에 MCP 신경 세포가 구상될 당시 신경 과학은 이미 신경 세포가 공간의 한 점으로 환원될 수 없게 만드는 특징을 가지고 있다는 것을 알고 있었다는 것입니다. 맥컬록과 피츠는 논리 기반 모형을 만들기 위해 그러한 성가신 복잡성을 단순화했습니다 (훌륭한 출발점이었죠!). 그러나 그 과정에서 그들은 자신의 전제를 다시 들여다보고 인지 과학(cognitive sciences)의 관련 발견과 비교하려고 하지 않은 전체 분야의 기반을 마련했습니다. 과학이 "한 번에 한 번의 장례식을 통해 발전한다"—플랑크(Planck) 원리의 대중적인 의역을 사용하자면, 죽은 아이디어(실제로는 한때 그 아이디어를 가졌던 죽은 사람들)가 정상적이며 진보의 필수 조건이라는 의미입니다—고 하더라도, 왜 인공지능에서는 그런 일이 일어나지 않았는지 묻는다면, 당신은 올바른 질문을 하는 것입니다. 저는 나중 섹션의 내용을 미리 말하지 않고, 유사성으로 답하겠습니다. 학계에서 취약한 기반을 무너뜨리는 데는 이상주의적인 용기나 무모한 용기가 필요합니다. 산업에서 취약한 기반을 무너뜨리는 데는 강철 같은 의지나 황제의 권력이 필요합니다. 인공지능의 연금술적 본질(이는 괜찮습니다)과는 대조적으로, 신경 과학은 확립된 과학입니다. 상업적으로 무관하기 때문에 신경 과학자들은 이윤을 쫓을 수 없으므로 과학적 방법을 따를 수밖에 없습니다. 그러나 가장 중요한 대조는 신경 과학이 지난 80년 동안 급격히 발전했다는 것입니다. 50년대에는 더 성숙했고, 오늘날에는 훨씬 더 성숙합니다. 생물학적 신경 세포에 대한 우리의 이해는 인공지능 연구자들이 인공 신경 세포를 더 이상 "신경 세포"라고 부를 수 없는 지경에 이르렀습니다. 그리고 실제로 그들은 그렇게 하지 않습니다. 인공지능 분야에서 일하는 모든 사람들은 챗GPT가 인간 두뇌에서 멀리 떨어진 영감을 받았다는 것을 당연하게 여기지만, 챗GPT 이전 시대처럼 더 이상 "신경 세포"나 "단위(unit)"라는 단어를 언급하는 것을 듣지 못합니다. 이 분야에서 유용한 단순화였던 것이 산업계에서는 의도적인 누락으로 변했습니다. LLM이 작동하고 챗GPT가 인기가 있으며, 둘 다 투자 수익을 제공하는 한, 그들에게는 중요하지 않습니다.

저는 직관이 시사하는 바와는 달리, 그것이 실제로 중요하며, 우리가 처한 상황—아시다시피, 대만에 설계된 GPU(그래픽 처리 장치)와 북부 버지니아에 건설된 데이터센터(datacenter) 형태의 인공지능 인프라(infrastructure) 구축에 투입된 1조 달러, 그리고 최첨단 기술을 아주 조금이라도 발전시키는 데 필요한 1000조 개의 데이터 조각—이 매몰 비용(sunk cost)이 여전히 합리적이었을 때 되돌아가지 않은 직접적인 결과라고 주장할 것입니다. 하지만 그 전에, 이 주제에 대한 최근의 가장 관련성 높은 신경 과학 연구를 살펴봄으로써 제 주장을 강화해 봅시다. 저는 인공지능이 인지 과학, 그리고 우리가 아는 유일한 지능의 사례인 인간 두뇌로부터 얼마나 멀리 벗어났는지 설득력 있게 보여줄 수 있기를 바랍니다. 이러한 간극은 단순히 기술적인 비효율성을 넘어, 지능의 본질에 대한 우리의 이해를 왜곡하고, 장기적으로 인공지능 발전의 방향성을 위협할 수 있습니다.

**사실은 사람에 대한 AI 블로그**
**구독**

**III.**
(여기서 어떤 기술적이거나 전문 용어적인 세부 사항을 따를 필요는 없다는 점을 기억하십시오. 중요한 부분은 신경 과학이 신경 세포, 신경망, 뇌, 그리고 지능에 대해 아는 것과 인공지능이 그것들에 대해 아는 것 사이의 극명한 대조를 파악하는 것입니다.) 생물학적 신경 세포의 신호 수용체(signal receptor)인 수상돌기(dendrites)를 잠시 살펴보겠습니다. 1980년대 초, 크리스토프 코흐(Christof Koch)와 동료 연구자들은 수상돌기의 형태(dendritic morphology)와 시냅스 패턴(synaptic patterns)이 신경 세포가 입력을 내부적으로 처리하는 방식에 영향을 미칠 수 있음을 발견했습니다. 오랫동안 과학자들은 수상돌기가 균일하게 작동하며 다른 신경 세포에서 오는 입력을 단순히 수동적으로 합산한다고 생각했습니다. 그러나 코흐의 발견은 그 형태와 기능이 교과서에서 제시하는 것보다 훨씬 복잡하다는 것을 밝혀냈습니다. 1996년, 컬럼비아 대학교(Columbia University)와 벨 연구소(Bell Labs)의 과학자들은 개별 수상돌기의 역할을 조사하여 수상돌기 자체가 처리 단위(processing units)로 작동한다는 것을 발견했습니다. 수상돌기는 스파이크(spikes)를 생성하기 위한 자체 임계값(threshold)(수상돌기 스파이크(dendritic spikes)라고 불림)을 가지고 있으며, 이는 전체 신경 세포의 임계값과는 다릅니다. 즉, 신경 세포는 MCP 모형이 제시하는 것처럼 단순한 "논리 게이트(logic gates)"가 아닙니다. 수상돌기는 그 자체로 논리 게이트 역할을 할 수 있는 것으로 보입니다.

따라서 생물학적 신경 세포는 독립적인 처리 시스템으로 구성된 처리 시스템입니다. 즉, 프로세서(processor) 안에 또 다른 프로세서가 있는 구조입니다. 인공 신경망에서 이를 표현하려면, 신경 세포 간의 연결은 신경 출력에서의 역할에 영향을 미치는 독특한 형태를 가져야 할 것입니다 (실제로 그렇지 않습니다). 그런 다음, 그러한 연결은 내부적으로 처리 시스템으로 작동할 것입니다 (실제로 그렇지 않습니다). 신경 세포에 도달하는 각 입력 연결은 신경 세포의 전체 출력을 변경하는 스파이크를 생성하거나 (또는 생성하지 않거나) 할 것입니다 (실제로 그렇지 않습니다). 이러한 복잡성 불일치는 생물학적 신경 세포가 계층형 네트워크(layered network)로 더 잘 이해되어야 함을 의미합니다. 여기서 계층(수상돌기)은 비선형 중간 입출력 매핑(nonlinear intermediate input-output mappings)으로 기능합니다. 결과로 나오는 중간 출력은 "연결 트리(connection tree)"의 형태에 따라 합산되어 최종 출력을 생성합니다. 불과 5년 전인 2020년, 알베르트 기돈(Albert Gidon)과 베를린 훔볼트 대학교(Humboldt University of Berlin) 동료들은 이러한 놀라운 발견을 바탕으로 사이언스(Science)지에 획기적인 논문을 발표했습니다. 그들은 현재 모형으로는 설명되지 않은 피라미드형 인간 신경 세포(pyramidal human neurons)의 새로운 입출력 특징을 발견했습니다. 이 신경 세포의 수상돌기는 임계 수준(threshold level)의 자극에 대해 강도가 가장 높고, 들어오는 전류가 증가할 때 가장 낮은 유형의 스파이크를 생성합니다. 이 발견은 일부 수상돌기가 XOR 논리 게이트(XOR logical gates) 역할을 할 수 있음을 증명했습니다. 즉, 입력 중 하나만 참일 경우에만 출력이 참입니다. 1969년, 인공지능 선구자인 마빈 민스키(Marvin Minsky)와 시모어 A. 파퍼트(Seymour A. Papert)는 단일 계층 퍼셉트론(single-layer perceptron, 초기 유형의 인공 신경망)이 이러한 유형의 계산을 수행할 수 없음을 증명했습니다. 기돈의 연구는 단일 생물학적 수상돌기가 이를 수행할 수 있음을 증명합니다. 생물학적 신경 세포 내부의 요소가 전체 신경망이 할 수 없는 복잡한 계산을 수행할 수 있습니다. 물론, 더 복잡한 인공 신경망은 가능했겠지만 (여기서는 수십 개의 매개변수(parameters)에 대해 이야기하고 있으며, GPT-4o는 수천억 개를 가졌습니다), 이것은 여전히 인간 두뇌의 기본 요소와 인공지능 시스템 간의 두 자릿수 규모의 계산 격차를 나타냅니다. 수상돌기가 기본적인 인공 신경망의 작업을 수행할 수 있다면, 생물학적 신경 세포는 인공 신경 세포에 비해 얼마나 더 복잡한가요? 아니면, 더 나은 질문은, 얼마나 더 강력한가요?

2021년, 기돈의 연구 1년 후, 데이비드 베니아게프(David Beniaguev)와 동료들은 뉴런(Neuron)지에 수십 년 동안 제기되어 온 것을 증명하는 논문을 발표했습니다. 인공 신경 세포는 생물학적 신경 세포를 전혀 정확하게 표현할 수 없습니다. 이를 증명하기 위해 그들은 피라미드형 인간 신경 세포의 입출력 행동을 시뮬레이션(simulate)하기 위해 현대 기계 학습(machine learning) 기술을 사용했습니다. 그들은 두 가지를 테스트하고 싶었습니다. 실제 입출력 쌍으로 훈련되었을 때 인공 신경망이 신경 세포 출력을 정확하게 예측할 수 있는지 여부, 그리고 생물학적 신경 세포의 전체 복잡성을 충분한 정확도로 포착하기 위해 인공 신경망이 얼마나 커야 하는지. 그들은 최소한 5계층 128단위 시공간 컨볼루션 네트워크(temporal convolutional network, TCN)가 피라미드형 신경 세포의 입출력 패턴을 밀리초(millisecond) 해상도(단일 스파이크 정밀도)로 시뮬레이션하는 데 필요하다는 것을 발견했습니다. 그들은 깊이와 너비를 수정하여 8계층 256단위 TCN이 최고의 성능을 달성한다는 것을 발견했습니다. 대략적인 비교를 하자면, 이는 단일 생물학적 신경 세포가 적절하게 시뮬레이션되기 위해 640개에서 2048개의 인공 신경 세포를 필요로 한다는 의미입니다. 이는 세 자릿수 규모입니다. 제가 가능한 한 엄격하게 말하고 싶기 때문에, 이것이 생물학적 신경 세포가 이만큼 더 많은 계산 능력이나 복잡성을 가지고 있다는 것을 반드시 의미하지는 않지만, 두 가지 유형의 신경 세포가 구조, 기능, 행동 면에서 이전에 생각했던 것보다 훨씬 더 다르다는 명확한 신호라는 점을 주목하십시오. 이러한 이유와 제가 여기서 언급하지 않을 다른 이유들 때문에, 인공 신경망, 그리고 딥러닝과 LLM에 기반한 현대 인공지능의 전체 구조가 전혀 작동한다는 것이 기적입니다. 그들은 이것을 "딥러닝의 비합리적인 효과(unreasonable effectiveness of deep learning)"라고 부릅니다. 비합리적으로 효과적인 것의 문제는 그것이 똑같이 비합리적이거나, 오히려 예상치 못한 순간에 고장날 수 있다는 것입니다. 베니아게프 팀은 생물학적 신경 세포를 시뮬레이션하기가 왜 그렇게 어려운지 정확한 메커니즘을 밝혀낼 수 있었습니다. 수상돌기 형태(dendritic morphology)와 NMDA라고 불리는 특정 유형의 시냅스 수용체(synapse receptor)의 존재였습니다. 이것들은 신경 과학에서 오랫동안 잘 알려져 있었지만, 교실을 거의 벗어나지 않는 소수의 연구를 제외하고는 현대 인공지능과 인공 신경망에서는 완전히 무시되어 온 생물학적 신경 세포의 구조적, 기능적 측면입니다.

제가 공유할 마지막 예시는 파나요타 포이라지(Panayiota Poirazi) 팀이 2025년 1월 네이처 커뮤니케이션즈(Nature Communications)에 발표한 논문입니다. 이 팀은 수상돌기 형태와 연결성을 가진 인공 신경망을 구축하여 표준 신경망보다 우수한 효율성, 회복력, 정밀도를 보임을 보여주었습니다. 이것은 학자들을 특징짓는 선의적이고 순진한 방식으로 영리하고 용감합니다. 그들은 인공지능과 신경 과학 사이의 간극을 메우려 노력하지만, 그들이 호소하려는 사람들에 의해 다리가 해체되었다는 것을 깨닫지 못합니다. 이 논문은 흥미로움에도 불구하고, 놀랍게도 23회 인용되었지만, 자금은 전혀 받지 못했습니다. 이러한 통찰력에서 몇 가지 질문이 발생합니다. 왜 인공지능 커뮤니티는 시뮬레이션하려는 현실에 더 잘 적응하기 위해 그 기반을 재구성하려 하지 않는가? 인공지능은 그 기반이 전복되고 처음부터 재건될 때까지 AGI를 달성하려는 탐구에서 실패할 운명인가? 그렇게 근본적인 수준에서 인공지능을 변경하는 것의 결과는 무엇인가? 아니면, 반대로, 아무것도 변경하지 않는 것의 결과는 무엇인가? 이 질문들은 단순한 학문적 논쟁을 넘어, 인공지능 기술이 사회 전반에 미치는 영향과 그 잠재적 위험성을 심각하게 고려해야 함을 시사합니다. 특히, 효율성만을 추구하는 현재의 인공지능 개발 패러다임이 간과하고 있는 생물학적 지능의 핵심 원리들이 무엇인지, 그리고 이를 통합하지 않을 경우 장기적으로 어떤 한계에 봉착할 것인지에 대한 깊은 논의가 필요합니다.

**IV.**
인공지능 분야의 일반적인 입장을 살펴보겠습니다. 챗GPT와 같은 인공지능 시스템은 생성형 인공지능과 LLM의 현재 작업에 선행하는 기본 가정에 대한 의도적인 재구조화 없이도 궁극적으로 AGI 또는 인간 수준의 성능에 도달할 때까지 반복적으로 확장되고 개선될 수 있습니다. 이것이 바로 구글 딥마인드(Google DeepMind), 오픈AI(OpenAI), 앤트로픽(Anthropic), 메타(Meta)와 같은 선도 기업들이 추구하는 방향입니다. (제가 "의도적"이라고 말하는 이유는, 멍청하고 목적론적이지 않은 진화 시스템이 그러하듯이, 앞으로 나아가면서 표면적으로는 항상 수정할 수 있기 때문입니다.) 아마도 인공 신경 구조와 생물학적 신경 구조 사이의 명백한 차이는 최악의 경우 충분한 자원(예: 컴퓨팅(compute) 자원 및 데이터—아시다시피, 그 수많은 1000조 개의 GPU와 토큰)으로 조화될 수 있으며, 최선의 경우 무관할 것입니다. 신경 과학은 지능, 뇌, 그리고 마음에 관심을 둡니다. 신경 과학자들은 우리가 아는 유일한 지능의 사례인 우리 자신을 내면적으로 들여다보는 데 자연스럽게 관심을 둡니다. 대조적으로, 인공지능 연구자들은 인공적인 수단을 사용하여 지능을 복제하는 데 관심을 둡니다. 그들은 세상을 인지하고 그에 따라 행동하는 지능형 에이전트를 설계하고 구축하는 데 관심을 둡니다 (저는 이것을 이 분야의 궁극적인 목표로 간주합니다. 비록 바이브(Vibes)와 소라(Sora)와 같이 신경 과학과는 아무 관련이 없는 중간 목표들, 그리고 언젠가 우리의 생물학적 신경 세포를 복제하기를 바라며 우리의 생물학적 신경 세포를 먹어치우는 인공지능 슬롭(AI slop)과 같은 것들이 있다는 것을 알지만 말입니다). 이 불일치를 냉정하게 본다면, 두 분야 모두 합리적인 일을 하고 있다는 것을 깨달을 것입니다. 신경 과학은 지능의 전제에 관심을 두는 반면, 인공지능은 그 결과물에 관심을 둡니다.

만약 우리가 다른 기판(substrate)(예: 실리콘(silicon) 대 탄소(carbon)), 아키텍처(architecture)(예: LLM 대 피질(cortices)), 또는 우리의 상황에 더 잘 맞는 일련의 절충안(trade-offs)을 찾을 수 있다면, 우리는 인간 두뇌를 본떠 지능형 에이전트를 모형화할 필요는 없습니다. 저는 더 나아가서, 그것은 불가능하다고 말하고 싶습니다. 왜냐하면 컴퓨터와 인공지능 시스템은 이미 거의 즉각적인 계산, 임의로 높은 정밀도, 사진 같은 기억력(eidetic memory) 등 인간이 복제할 수 없는 일련의 능력을 보여주기 때문입니다. 요컨대, 인간은 가능한 지능의 공간에서 하나의 사례일 뿐이지만, 원칙적으로 어떤 물리 법칙도 다른 지능의 존재를 막지 않으며, 모든 것을 고려할 때, 우리의 것을 선호할 이유가 없습니다. 규모 극대주의자(scale maximalists)와 LLM 극대주의자(LLM maximalists)(우리가 필요한 모든 요소를 이미 가지고 있다고 생각하는 사람들을 지칭하는 용어)에 대해 경계심을 갖게 되었지만, 프랑수아 숄레(Francois Chollet), 안드레이 카르파티(Andrej Karpathy), 리처드 서튼(Richard Sutton)과 같이 이 분야에서 잘 알려진 몇몇 인물들처럼 어떤 식으로든 인공지능을 싫어한다고 비난받을 수 없는 사람들조차 일반적으로 이 점에 동의합니다. 즉, 다른 방식으로 기능적 역량(functional competence)을 달성할 수 있다면 완전한 생물학적 충실도(biological fidelity)는 필요 없습니다.

다음은 숄레가 LLM(2024)과 AGI 추구(2025)에 대한 그의 입장을 담은 두 개의 트윗(tweet)입니다.
"LLM(및 일반적인 딥러닝)은 유용하며, 시간이 지남에 따라 더욱 유용해질 것이다. 또한 그것들은 지능형 에이전트로 변모하지 않을 것이다. 왜냐하면 그들은 단순히 지능의 메커니즘을 구현하지 않기 때문이다. 우리 작업의 요점은 인공 인간을 만드는 것이 아니다. 우주는 우리 자신의 반영보다 훨씬 더 흥미로운 질문들로 가득하다. 요점은 우리가 스스로 할 수 있는 것보다 우주를 더 잘 탐험하고 이해하는 데 도움이 될 새로운 종류의 마음을 만드는 것이다. LLM은 지능을 위한 핵심 메커니즘이 부족하지만, 그렇다고 해서 지능적이기 위해 "인공 인간"과 닮아야 한다는 의미는 아니다!"

드와르케시(Dwarkesh) 팟캐스트(podcast)에서 서튼의 인터뷰에 대한 카르파티의 코멘트입니다.
"...오늘날의 최첨단 LLM 연구는 동물을 만드는 것이 아니다. 유령을 소환하는 것이다. 유령은 가능한 지능의 공간에서 근본적으로 다른 종류의 지점이라고 생각할 수 있다. 그것들은 인류에 의해 혼란스러워졌다. 인류에 의해 철저히 공학적으로 만들어졌다. 그것들은 불완전한 복제품이며, 인류의 문서를 통계적으로 정제한 것에 약간의 양념을 더한 것이다. 그것들은 플라톤적으로 "쓴 교훈(bitter lesson)"을 완전히 받아들인 것은 아니지만, 적어도 이전에 나온 많은 것들과 비교할 때 "실질적으로" 쓴 교훈을 받아들인 것일 수 있다. 시간이 지남에 따라 우리는 유령을 점점 더 동물에 가깝게 미세 조정(finetune)할 수 있을 것 같다. 그것은 근본적인 비호환성이라기보다는 지능 공간에서의 초기화(initialization) 문제이다. 하지만 그것들이 심지어 더 멀리 발산하여 영구적으로 다르고, 동물 같지 않지만, 여전히 엄청나게 유용하고 세상을 제대로 변화시키는 존재가 될 가능성도 상당히 높다."

그리고 팟캐스트에서 서튼은 아이들이 모방을 하는 것이 아니라 세상에 사는 능동적인 주체(proactive agents)로서 대부분의 것을 경험하는 반면, LLM은 주로 인간이 만든 훈련 데이터(training data)를 모방한다고 말했습니다.
"아이들을 보면, 그저 이것저것 시도하고 손을 흔들고 눈을 움직이는 것을 봅니다. 그들이 눈을 움직이는 방식이나 심지어 내는 소리에 대한 모방은 없습니다. 같은 소리를 내고 싶을 수도 있지만, 아기가 실제로 하는 행동에는 목표가 없습니다. 그것에 대한 예시도 없습니다. ...대규모 언어 모델은 훈련 데이터로부터 학습합니다. 경험으로부터 학습하는 것이 아닙니다. 정상적인 삶 동안 결코 이용할 수 없을 것에서 학습합니다. 정상적인 삶에서 이 행동을 해야 한다고 말하는 훈련 데이터는 결코 없습니다."

그들은 약간 다른 방식으로 같은 것을 이야기하고 있습니다. 인공지능 분야(LLM)에서 우리가 가진 것은 충분하지 않으며, 생체 영감(bioinspiration)은 고려할 가치가 있지만, 우리는 "인공 인간"과는 거의 닮지 않고 "동물 같지 않은" 것에 더 가까운 것으로 귀결될 수 있습니다. 인지 과학이 제공할 수 있는 어떤 통찰력도 선험적으로(a priori) 거부하는 것은 말이 안 되지만(이것이 카르파티와 서튼의 주요 주장입니다), 단지 우리가 이미 알고 있다는 이유만으로 우리가 이미 알고 있는 것에 집착할 필요는 없습니다(이것이 숄레의 요점입니다). 이전 섹션에서 제가 끝맺었던 질문에 답하자면: 아마도 80년 전의 원래 신경 세포 모형을 다시 검토할 필요는 없을 수도 있습니다. 아마도 우리는 지난 10년 동안 해왔던 것처럼 계속 나아가고, 아무런 재앙도 일어나지 않을 수도 있습니다. 우리는 이 실수를 저질러서는 안 됩니다. 인공지능의 목표는 모든 수준에서 인간 지능을 복제하는 것이 아니며, 결코 아니었습니다. 얕은 추상화(abstraction)로 목표를 달성할 수 있다면, 수상돌기 스파이크, 전압 기울기(voltage gradients), 이상한 형태(morphology)로 복잡하게 만들 필요가 있는가? 복잡성이 지능의 전제 조건인가? 말이 안 됩니다. 진화는 어떤 목적론적 충동도 가지고 있지 않기 때문에 정확히 복잡하게 만들며, 대신 생존 압력과 다른 외부 힘의 조절 하에 진행됩니다. 제가 언급한 연구들은 인간 신경 세포가 우리가 생각했던 것보다 얼마나 더 복잡한지에 관심을 두지만, 인공지능 연구자라면 문제를 바라보는 올바른 렌즈가 아닙니다. 신경 세포 수준의 충실도가 인지(cognition)에 필수적인가? 저는 반대 가설을 검증함으로써 답하겠습니다. 극적으로 다른 복잡성, 형태, 크기, 기판, 현상학을 가진 두 가지 지능의 구현은 원칙적으로 유사한 지능을 초래할 수 있습니다. 지도가 실제 지형과 완벽히 일치하지 않아도 유용한 길잡이가 될 수 있듯이, 지능 구현에도 반드시 생체 모방이 필요한 것은 아니다. 이것들은 제 초기 주장에 대한 완전히 합리적인 반론입니다. 결국, 맥컬록과 피츠의 "충분히 좋은" 80년 된 단순한 신경 모형은 체스, 코딩, 수학, 그리고 다양한 분야에서 점점 더 많은 문제에서 인간을 이길 만큼 똑똑한 시스템의 기초가 됩니다. 인공지능 모형의 성능을 평가하는 데 도움이 되는 벤치마크는 우리가 충분히 어려운 작업을 생각해낼 수 없기 때문에 포화 상태에 이르고 있습니다. 그러나 인공지능의 표준 평가에는 중요한 한계가 있습니다 (여기에는 METR의 장기 작업 분석과 오픈AI의 GDPval처럼 현실 세계의 혼돈스러운 본질을 포착하려는 시도도 포함됩니다). 인공지능 테스트는 우리가 불확실한 것들이 실제로 측정되지 않도록 설계됩니다. 정확히 말하자면, 유일하게 관련 있는 벤치마크는 실제 세계에서의 역량(competence)이며, 지금까지 모든 벤치마크는 현실의 복잡성을 포착하는 데 실패하고, 모든 인공지능 모형은 인간 유아가 실패하지 않을 방식으로 "야생에서" 테스트될 때 실패합니다 (ARC-AGI와 같이 즉석에서 해결하는 기술을 요구하는 벤치마크나 생산성 및 경제 분석에 고려되지만 실험실 평가에서는 테스트되지 않는 대규모 프로젝트에서 이를 볼 수 있습니다). 예측 역량(prediction-competence)과 환경 역량(environment-competence) 사이에는 거대한 격차가 있습니다 (숄레는 결정화된 지능(crystallized intelligence)과 유동 지능(fluid intelligence)에 대해 논의합니다. 이는 광범위한 기술을 소유하는 것과 새로운 기술을 효율적으로 습득하는 데 능숙한 것 사이의 구별을 강조하는 심리학적 개념입니다).

그래서 아마도, 기능적 성능이 목표이지만, 생물학적 충실도가 우리가 인정하고 싶어 하는 것보다 훨씬 더 깊은 수준의 요구 사항임이 밝혀집니다. 결국, 그것은 우리가 가진 세계 역량의 유일한 참고 자료입니다. "좋아, 어쩌면 이 비행기는 날개 없이 날 수 있을지도 몰라"와 같은 가설을 세우는 것은 괜찮습니다. 비행기라는 작은 동물을 아는 어떤 구경꾼이 보기에는 말도 안 되는 소리일지라도 말입니다. 그 가설은 "좋아, 어쩌면 이 인공지능은 그 모든 이상하게 생긴 뇌회(gyri)와 뇌구(sulci) 없이도 지능적일 수 있을지도 몰라"라고 말하는 것과 같습니다. 하지만 수년간의 시도와 우리를 태우고 다닐 수 있는 거대한 새 종을 직접 사육하는 비용을 왜소하게 만들 정도의 자금 투입에도 불구하고, 여전히 그 빌어먹을 것을 날게 할 수 없다면, 아마도 전제를 재고할 때일 것입니다. 아마도 비행기에 날개를 추가하는 것은 불합리한 고려 사항이 아닐 것입니다. 하지만 저는 방금 당신에게 속임수를 썼습니다. 왜냐하면 저는 거짓임을 아는 유사성을 그리기 위해 비유를 사용했기 때문입니다. 다른 가설을 제안할 수도 있습니다. "좋아, 어쩌면 이 비행기는 날개를 퍼덕이지 않고도 날 수 있을지도 몰라." 오, 와우, 거의 같은 것이지만 너무나 다릅니다—왜냐하면 사실이기 때문입니다! 비행기는 날개를 퍼덕일 필요가 없습니다! 무엇이 작동하고 무엇이 작동하지 않는지에 대한 제한된 지식이 문제의 근본 원인입니다. 생물학에서 얼마나 많은 것을 취해야 하는가? 우리는 모릅니다. 왜냐하면, 알고 보니, 우리의 은유적인 인공지능 비행기는 어느 정도 날고 어느 정도 날지 않습니다. 그리고 우리는 두 가지 모두 사실인 이유를 전혀 모릅니다. 왜냐하면 그것이 따르는 패턴 자체가 우리에게 완전히 낯설기 때문입니다.

그래서 이 시점에서 가능한 지능의 공간은 자연이 허용하는 것보다 더 넓다는 것이 꽤 명확합니다 (생물학적 의미에서 그렇습니다. 물리적 의미에서는 인공지능 시스템조차 빛의 속도와 열역학 제2법칙을 위반할 수 없습니다). 하지만 우리는 새겨진 길에서 너무 멀리 벗어나고 싶지 않을 수도 있습니다. 후회하는 것보다 안전한 것이 낫습니다. 특히 사과가 수조 달러의 손실을 동반할 것이라면 말입니다. 우리는 어떤 요소가 항상 필요하고, 어떤 요소가 우리 지능형 설계자들이 감수할 필요가 없는 진화의 특정 절충안인지 모릅니다 (예: 비행기는 엔진이 필요한 추진력을 생성하기 때문에 날개를 퍼덕이지 않지만, 여전히 공기역학이 부과하는 물리적 제약에 종속되므로 날개는 유지됩니다). 이것이 창조 게임에서 보수적으로 접근하는 것이 최선의 방법인 이유입니다. 진화의 설계 공간은 우리가 우발적인 기벽으로 여기는 지능의 원리를 인코딩하는 구조적 사전 정보(structural priors)를 포함할 수 있습니다. 알 수 없는 미지의 것들과 놀지 마십시오. 우리는 우리가 생각하는 만큼 타협적인 해결책에서 자유롭지 않으며, 우리 것—어느 정도는 생물학적인 것과 유사하고 어느 정도는 다른—이 설계 공간에서 해결 공간으로의 임의적인 매핑(mapping)에 어떻게 영향을 미치는지 모릅니다. 지도가 영토와 일치할 필요는 없지만, 유용한 나침반을 만들 수 있습니다. 그러나 표현이 더 충실할수록 길을 잃기 어렵습니다. 다시 말해, 우리는 자연을 복사할 필요는 없지만, 그 경계(우리가 합리적이라고 생각하는 것과 아직 이해하지 못하는 것)를 존중하는 것이 좋습니다.

리처드 서튼(Richard Sutton)은 2019년 "쓴 교훈(Bitter Lesson)" 에세이로 가장 잘 알려져 있는데, 간단히 말해, 장기적으로는 우리의 제한된 지식을 활용하여 더 나은 인공지능 시스템을 찾으려고 스스로 노력하는 대신 컴퓨터가 그 부담을 지도록 하는 것이 더 낫다는 내용입니다. 그리고 그것은 괜찮습니다. 아마도 사실일 것입니다. 그것을 쓴 교훈이라고 부른 것이 실수입니다. 기껏해야 씁쓸합니다. 진정한 쓴 교훈이 무엇인지 아십니까? 진화는 목적론적이지 않은 시행착오와 무작위 돌연변이를 통해 더 복잡한 기본 구성 요소를 더 크고, 더 똑똑하고, 더 강력하며, 더 다재다능한 시스템으로 효율적으로 확장하는 데 성공했습니다. 그것은 생물학적 신경 세포에서 인간 지능에 이르는 겉보기에 복잡한 경로를 능숙하게 개척했습니다. 서튼의 교훈은 확장될 요소의 복잡성에는 신경 쓰지 않고, 단지 효율적으로 확장 가능해야 한다는 사실에만 주목하기 때문에 강력합니다. 컴퓨팅 자원을 추가하는 것이 약한 휴리스틱(heuristics)을 조정하고 불완전한 지식을 활용하는 것보다 더 잘 작동하지만, 올바른 구성 요소에서 시작하는 것보다 더 좋은 것은 없습니다—그리고 저는 아무것도 없다고 강조합니다. 어떤 면에서, 이 교훈은 "국가처럼 보기(Seeing Like a State)"의 주요 교훈을 상기시킵니다. 세상을 너무 단순화하면 읽기 쉽게 만들겠지만, 동시에 세상을 살아있게 하는 바로 그 요소들을 파괴할 것입니다. 찾을 수 있는 가장 단순한 신경 세포 모형을 통해 만들고 있는 인공 뇌를 완벽하게 제어하고 모니터링하려고 시도함으로써, 당신은 거의 공리적인 진실처럼, 그것이 당신이 원하는 방식으로 똑똑하지 않을 것임을 보장했습니다. 분야와 산업 모두 오랫동안 무시해온 이 쓴 교훈에도 불구하고, 당신은 LLM에 계속 계층을 추가할 것입니다. 그래서 저는 이렇게 내기합니다. 당신은 분야의 기반을 다시 검토하지 않아 발생한 불필요한 장애물을 극복하기보다 훨씬 더 빨리 추가할 계층(컴퓨팅 능력, 훈련 데이터 등)이 바닥날 것입니다. 그것을 나는 쓰다고 부를 것입니다.

**V.**
이 긴 글을 통해 제가 여러 번 언급했지만, 독립적인 섹션을 할애할 가치가 있는 것이 있습니다. 바로 우리가 삶의 모든 측면에서 겪지만, 생물학은 결코 직면하지 않았고 앞으로도 직면하지 않을 종류의 절충안, 즉 자본의 동기입니다. 자본의 논리는 단기적인 성과에 집중하며, 이는 뉴런의 복잡성을 간과한 채 단순화된 모델을 채택하게 만들었다. 결과적으로 초기 비용 절감은 현재 인간 수준의 지능 구현에 막대한 대가를 치르게 하는 원인이 되었다. 어떤 면에서, 진화의 뇌 크기와 뇌 무게 사이의 절충안은 인공지능 연구소의 모형 크기와 모형 비용 사이의 절충안과 크게 다르지 않습니다. 한 가지를 제외하고는, 진화는 목표가 없으므로 단기적인 승리(유전적 맥락에서 무엇을 의미하든)에 관심이 없지만, 투자자들은 그들이 쫓는 상에 레이저처럼 집중합니다. 그래서 초기에 일을 너무 복잡하게 만들지 않는 것이 합리적이지만, 이것은 우리를 곤란한 상황에 빠뜨렸습니다. 우리는 신경 세포의 극도로 단순화된 모형을 사용하여 많은 돈을 절약했지만, 실제 환경에서 인간 지능을 모방하는 것이 더 어렵다는 것이 입증된 지금 우리는 그 대가를 추가로 지불하고 있을지도 모릅니다. 수익성이 없는 인공지능 기업들이 점점 더 많은 LLM을 훈련하기 위해 데이터센터에 쏟아붓는 수천억 달러는 그들의 투지, 야망, 비전의 증거가 아니라 그들의 성급함의 증거입니다. (그들이 이 모든 것에 신경 쓰지 않고, 실제로는 절대 감시와 같은 더 평범한 목적을 추구하고 있을 가능성은 여기서는 다루지 않겠습니다. 그 주제는 독립적인 기사를 필요로 합니다.) 만약 그들이 처음에 더 나은 기반을 찾는 데 더 많은 자원과 시간을 할애했다면, 신생아가 훨씬 더 똑똑한 존재로 성장하는 데 필요한 데이터의 극히 일부만으로도 충분할 때, 인간 데이터의 전체 코퍼스(corpus)로 LLM을 훈련하는 데 그렇게 많은 에너지와 돈을 낭비하지 않았을 것입니다. 하지만 물론, 인공지능 선구자들이 그렇게 했다면, 어떤 합리적인 투자자도 그들에게 단 한 푼도 주지 않았을 것입니다. 챗GPT가 존재한다면, 그것은 우리가 비용을 지불하기 때문입니다. 챗GPT가 존재한다면, 그것은 더 높은 목표를 세울 만큼 무모한 사람이 없었기 때문입니다. 챗GPT가 존재한다면, 그것은 그 존재를 지배하는 사회경제적 역학이 더 나은 것을 허용하지 않기 때문입니다. 그래서 우리는 진정으로 지능적인 존재로 변모시키려는 바로 그 시스템처럼, 지역 최저점(local minima)에 갇혀 있음을 발견합니다. (우리의 경제 최적화 도구(optimizer)가 인공지능 시스템을 구동하는 경사 하강법(gradient descent)을 반영한다는 것이 아이러니하지 않습니까—아니면 어쩌면 그것이 패턴일 수도 있습니다…)

자본 배분 에이전트(capital allocation agents)는 항상 이런 일을 합니다 (이 시점에서 당신이 여전히 붙잡고 있을지도 모르는 인류에 대한 마지막 한 조각의 믿음을 포기하고 싶다면, 스콧 알렉산더(Scott Alexander)의 "몰록에 대한 명상(Meditations on Moloch)"을 읽고 마침내 전체 토끼굴을 한 번에 볼 수 있습니다). 산업 혁명(Industrial Revolution)을 생각해 보십시오. 우리가 자동화가 세상을 오염시킬 가치가 있다고 결정했을 때 말입니다. (저는 이것을 기후 변화 논쟁으로 바꾸지 않겠습니다.) 그때는 우리의 발전을 기반으로 할 실제 세계 모형이 없었습니다. 더러운 석탄을 태우는 것이 우리의 작은 푸른 행성의 폐에 해로울 것이며, 대신 일찍이 원자력, 태양광, 풍력에 투자했어야 했다는 것을 어떻게 알 수 있었겠습니까? 게다가, 혁신에는 다른 한계가 있다는 것을 잊어서는 안 됩니다. 그것은 인접한 가능한 것(adjacent possible thing)으로만 경계를 밀어붙일 수 있을 뿐, 더 멀리는 아닙니다. 하지만 인공지능 분야는 필요한 최고의 영감(즉, 우리 인간)에 접근할 수 있기 때문에 특별합니다 (이것을 논란의 여지가 있는 주장으로 간주하더라도 이해합니다). 그런데도 자본 배분 에이전트들은 여전히 같은 실수를 저지르고 있습니다. 그들은 최적화(optimization)와 재정적 압력이 우리를 더 안전하고 합리적인 길에서 벗어나게 합니다. 불행히도, 과학은 자금을 지원받을 수 있고, 측정 가능하며, 출판 가능한 것을 따릅니다. 그리고 그것은 헤쳐나가기 어려운 절충안입니다. 왜냐하면 자본 배분자의 단기적인 관점에서 볼 때, 더 나은 접근 방식으로 보이는 것이 그 시야를 넘어선 이유로 인해 가장 비싼 것으로 판명될 수 있기 때문입니다. 원치 않는 절충안을 강요받을 때까지 미루는 것—자본주의 역학의 본질—이 우리를 거기서 여기까지 이끌었습니다. "거기서 여기까지"라는 말은 무슨 뜻일까요? 만약 당신이 주의 깊게 읽었다면, 저는 맥컬록과 피츠의 1943년 선구적인 연구와 인공지능 기업들이 너무 많은 기회와 영향력을 모아 원하는 대로 할 수 있게 되어(그들이 그래야 하는 방식이 아님) 다가오는 2025년 금융 재앙 사이의 연관성을 그리는 데 7,000단어 이상을 쏟아부었습니다. 그리고 그들은 인공지능 인프라 구축에 수천억 달러를 지출하고 싶어 하는데, 이는 80년 전에는 계산 단위의 단순화된 모형처럼 보였던 것—따라서 자본의 눈에는 환영할 만한 소식이었던—이, 인간 두뇌보다 작고 멍청한 LLM 중 하나를 훈련하고 서비스하기 위해 인간이 생산한 모든 데이터와 중간 규모 국가의 전기 요금이 필요하다는 것을 업계가 깨달았을 때 값비싼 실수로 판명되었기 때문에 그렇게 비쌀 수밖에 없습니다. 이 LLM은 다른 조건이 동일하다면 가정용 전구 하나의 에너지를 소비할 것입니다. 컴퓨터 과학자 그레이디 부치(Grady Booch)는 샘 알트만(Sam Altman)의 7조 달러 투자 발언에 대해 "영국 전체의 전력 소비량에 맞먹는 에너지를 투입하여 칩을 만들려면, 당신은 근본적으로 잘못된 설계도를 가지고 있는 것"이라고 일침을 가했다.

실용적이고 경험적인 성공의 보상은 이론적 불순물의 인식론적 비용보다 큽니다—그렇지 않을 때까지는 말입니다. 시장의 보이지 않는 손(invisible hand)이 온순한 초지능(superintelligence)의 현존하는 예시라고 말할 때, 당신은 이 예시를 반론으로 사용할 수 있습니다. 그리고 만약 당신이 여전히 우리가 실제 신과 같은 초지능을 구축해야 한다고 확신한다면, 그것이 무엇이든 간에, 저는 우리가 서 있는 기반을 평소보다 조금 더 재고해야 할 수도 있다는 것을 당신에게 설득했기를 바랍니다. 저는 맥컬록과 피츠 신경 세포가 신이 되는 것이 합리적인 목표라고 생각하지 않습니다. 이 에세이에서 보이는 것과는 달리, 저는 인공지능 분야가 내린 선택에 대해 분개하지 않습니다. 그들이 생물학의 절충안에 주의를 기울이지 않은 것은 괜찮습니다. 왜냐하면 인간 세계는 그 자체의 절충안을 가지고 있기 때문입니다. 하지만 자연의 경고—자연은 우리보다 훨씬 현명합니다—를 무시하고 결국 우리 자신의 무덤을 파게 된다면 암울하게 아이러니하지 않겠습니까? 맥컬록과 피츠의 신경 모형이 너무 단순했고, 인공지능이 성과를 내지 못해 우리가 지금 금융 재앙에 직면하고 있다는 두 현실 사이에 합리적으로 정확한 궤적을 그릴 수 있는지는 명확하지 않습니다. 하지만 수년이 흘렀음에도 불구하고, 이런 이야기를 쓰고 우리가 제대로 다루지 못한 그 첫 번째 은유의 그림자가 여전히 우리를 쫓고 있다고 어느 정도 확고하게 주장하는 것이 여전히 사소하다는 것은 놀랍습니다. 카르파티가 LLM은 우리가 다른 차원에서 소환한 유령이라고 말할 때 그는 옳습니다. 가장 멀리 떨어진 실수가 가장 오랫동안 당신을 괴롭히는 법이니까요.

**사실은 사람에 대한 AI 블로그**
**구독**