**참고**: 이 글을 게시한 후, Anthropic으로부터 Sonnet 3.7이 10^26 FLOP 모델로 간주되지 않으며 훈련에 수천만 달러가 들었지만, 미래 모델은 훨씬 더 커질 것이라는 연락을 받았습니다. 저는 이 정보를 바탕으로 게시물을 업데이트했습니다. 유일한 중요한 변경 사항은 Claude 3가 이제 Gen3 모델이 아닌 고급(advanced) 모델로 언급된다는 것입니다.

저는 최근 며칠간 차세대 인공지능 모델인 Claude 3.7과 Grok 3의 초기 버전을 면밀히 검토해왔습니다. Grok 3는 GPT-4 대비 10배 이상 많은 연산 능력으로 학습된 첫 번째 인공지능 모델로 알려져 있으며, Claude는 혁신적인 코딩(coding) 및 추론(reasoning) 기능을 탑재하고 있습니다. 이처럼 두 모델은 그 자체로 주목할 만할 뿐만 아니라, 인공지능 기술의 미래 방향을 가늠케 하는 중요한 단서를 제공합니다. 본격적인 논의에 앞서 간략히 요약하자면, 이 차세대 인공지능들은 이전보다 훨씬 더 지능적이며, 특히 난해한 과제나 수리적 문제, 프로그래밍 코드 처리 능력에서 비약적인 발전이 눈에 뜁니다. 이러한 모델들을 접할 때마다 저는 과거 ChatGPT-4를 처음 경험했을 때와 유사한 감정을 자주 느낍니다. 즉, 그 능력에 깊은 감명을 받으면서도 동시에 미묘한 불안감을 떨칠 수 없습니다. 이 새로운 지능형 시스템들은 단순히 도구의 진화를 넘어, 인간의 사고와 창작의 영역에까지 깊숙이 개입할 잠재력을 보여주기 때문입니다.

클로드의 향상된 프로그래밍(programming) 역량을 예로 들자면, 이제 저는 별도의 코딩 지식 없이도 일상적인 대화나 문서를 통해 작동하는 소프트웨어(software)를 쉽게 얻을 수 있게 되었습니다. 예를 들어, 클로드에게 신규 AI 학습 도구에 대한 기획안을 제시하고 "제안된 시스템 구조(system architecture)를 삼차원 형태로 시각화하고 대화형(interactive)으로 구현해달라"고 요청하자, 우리의 핵심 논문 설계에 대한 상호작용 가능한 시각 자료가 완벽하게 만들어졌습니다. 이는 오류 없이 즉시 사용 가능한 결과물이었으며, 독자 여러분도 직접 시도해보고 AI에게 편집이나 수정 요청을 할 수 있습니다. 생성된 그래픽(graphics)은 깔끔했지만, 진정으로 인상 깊었던 점은 클로드가 요청받지 않았음에도 불구하고 개념 설명을 위해 이를 단계별 시연(demo) 형태로 만들기로 스스로 결정했다는 사실입니다. 이러한 선제적인 필요 예측과 새로운 접근 방식의 제안은 인공지능 분야에서 전례 없는 현상입니다. 또 다른 흥미로운 사례로, 저는 클로드에게 "대화형 타임머신(time machine) 유물을 만들어줘, 시간을 거슬러 여행하고 흥미로운 일들이 일어나게 해줘. 돌아갈 수 있는 특이한 시간대를 골라줘..."라고 말한 뒤, "그래픽(graphics)을 더 추가해줘"라고 요청했습니다. 단 두 번의 이러한 지시만으로 투박하지만 매력적인 픽셀 그래픽(pixel graphics)을 갖춘 완전히 작동하는 대화형 경험이 탄생했습니다. 이는 사실 놀라울 정도로 인상적인데, 인공지능은 자신이 무엇을 만들고 있는지 직접 볼 수 없는 상태에서 순수한 코드(code)를 사용하여 이를 '그려내야' 하기 때문입니다. 이는 마치 눈을 가린 예술가가 그림을 그리면서도 정확한 구도를 만들어내는 것과 같습니다. 물론, 이러한 시스템(system)들이 아직 완벽과는 거리가 멀고 여전히 오류를 범하지만, 그 발전 속도는 가히 폭발적입니다.

현재의 상황과 미래의 발전 방향을 이해하기 위한 중요한 지표로서, 우리는 인공지능의 핵심 동력인 두 가지 스케일링 원칙에 주목해야 합니다.

### 인공지능 발전의 두 가지 핵심 원칙 (Scaling Laws)

겉보기에는 단순해 보일지라도, 이 두 가지 도표는 인공지능 분야에서 가장 중요한 지표일 수 있습니다. OpenAI가 공개한 이 그래프들은 인공지능이 복잡한 질문에 답하는 능력을 어떻게 향상시킬 수 있는지, 특히 악명이 높은 미국 수학 경시대회(AIME)에서 더 높은 점수를 얻는 방식을 통해 두 가지 '스케일링 법칙(Scaling Laws)'을 명확히 보여줍니다. 좌측 그래프는 학습 스케일링 법칙(training Scaling Law)을 나타냅니다. 이는 모델의 크기가 커질수록 성능이 향상됨을 의미합니다. 이러한 대규모 모델을 훈련시키기 위해서는 투입되는 연산 능력(computing power), 학습 데이터(data), 에너지(energy)의 양을 비례적으로 늘려야 하며, 이는 막대한 규모로 이루어져야 합니다. 일반적으로 성능의 선형적 개선을 위해서는 연산 능력을 10배 증대시켜야 합니다. 연산 능력은 컴퓨터가 수행하는 기본적인 산술 연산(덧셈, 곱셈 등)의 횟수를 나타내는 FLOPs(부동 소수점 연산) 단위로 평가되며, 이는 인공지능 모델 학습 과정에서 필요한 총 연산량을 객관적으로 측정하는 기준이 됩니다.

우리는 이제 GPT-4와 그 수많은 경쟁 모델들보다 10배 이상 많은 연산 능력으로 학습된 차세대 인공지능의 첫 번째 모델들을 목격하고 있습니다. 이들은 10^26 플롭스(FLOPs)를 초과하는 연산력을 활용합니다. 이는 현재 스마트폰을 63만 4천 년간 가동하거나, 인류를 달에 보냈던 아폴로 유도 컴퓨터를 79조 년 동안 구동할 수 있는 막대한 규모에 해당합니다. 하지만 10^26이라는 수치는 명명하기에 다소 어색합니다. 이는 100 셉틸리언(septillion) 플롭스에 해당하며, 표준 단위 명칭에 약간의 유연성을 부여한다면 헥토요타플롭(HectoyottaFLOP)이라고 부를 수 있습니다. 따라서 제가 이들을 GPT-4(2세대)보다 한 자릿수 더 많은 연산 능력으로 훈련된 최초의 인공지능 집합인 3세대(Gen3) 모델이라 칭하는 이유를 쉽게 이해할 수 있을 것입니다.

일론 머스크(Elon Musk)의 인공지능 기업 xAI는 Grok 3를 통해 3세대 영역에 가장 먼저 공개적으로 진입했으며, 이는 그들의 전략적 방향을 고려할 때 전혀 놀라운 일이 아닙니다. xAI는 '더 큰 것(훨씬 더 큰 것)이 더 낫다'는 철학에 막대한 투자를 하고 있습니다. xAI는 세계에서 가장 큰 컴퓨터 클러스터(computer cluster)를 기록적인 시간 내에 구축했으며, 이는 Grok 3가 새로운 세대 인공지능에 스케일링 법칙(Scaling Law)이 여전히 유효한지 여부를 입증한 최초의 모델이었음을 의미합니다. Grok 3가 어떤 기반 모델(base model)에서도 볼 수 없었던 가장 높은 벤치마크(benchmark) 점수를 기록했으므로, 이 스케일링 법칙은 분명히 유효한 것으로 보입니다. 오늘 출시된 Claude 3.7은 아직 3세대 모델은 아니지만, 이전 인공지능 모델들에 비해 성능에서 상당한 진전을 보여줍니다. 벤치마크에서는 Grok 3와 유사한 수준을 보이지만, 저는 개인적으로 제가 사용하는 사례(use case)에서 더 영리하다고 느꼈습니다. 물론, 이는 사용자마다 다르게 경험될 수 있습니다. 아직 출시되지 않은 OpenAI의 o3 또한 뛰어난 성능을 가진 3세대 모델이 될 것으로 예상됩니다. 이는 단지 시작에 불과하며, Anthropic을 포함한 더 많은 기업들이 이 규모의 자체 모델을 출시할 준비를 하고 있습니다. 이러한 대규모 모델의 출시는 단순히 연산 능력의 확장을 넘어, 이전에 볼 수 없었던 새로운 능력, 즉 '이머전트 능력(emergent abilities)'의 발현으로 이어지기도 합니다. 이는 특정 규모 이상에서 예측 불가능하게 나타나는 고도의 추론 능력이나 문제 해결 능력을 의미하며, 인공지능 연구의 새로운 지평을 열고 있습니다.

오른쪽에 있는 두 번째 그래프(graph)에 대해서는 아직 언급하지 않았다는 것을 눈치채셨을 것입니다. 첫 번째 스케일링 법칙이 학습에 막대한 연산 능력을 투입하는 것(기본적으로 처음부터 더 똑똑한 AI를 구축하는 것)에 관한 것이라면, 두 번째 법칙은 인공지능 모델에 더 많은 사고 시간을 부여함으로써 단순히 성능을 개선할 수 있다는 사실을 밝혀냈습니다. OpenAI는 모델이 문제 해결에 더 많은 연산 능력을 사용하게 하면(그들이 테스트 시간(test-time) 또는 추론 시간 컴퓨팅(inference-time compute)이라고 부르는 것), 더 나은 결과를 얻는다는 것을 발견했습니다. 이는 똑똑한 사람에게 퍼즐(puzzle)을 풀 시간을 몇 분 더 주는 것과 비슷합니다. 이 두 번째 스케일링 법칙은 제가 지난 게시물에서 다루었던 '추론기(Reasoners)'의 등장을 촉발했습니다. 3세대 모델들은 필요할 때 모두 추론기 역할을 수행할 것이므로, 이들은 학습 과정에서의 대규모 투자와 더불어 실제 문제 해결 시 확장이 가능한 능력을 동시에 갖추게 됩니다. 이처럼 두 가지 스케일링 법칙이 결합되면서 인공지능은 그야말로 '생각하는 기계'로 진화하고 있으며, 이는 단순히 빠른 계산을 넘어 복잡한 논리적 사고와 의사결정까지 가능하게 하는 토대가 됩니다.

### 추론(reasoning)을 활용하는 모델들의 진화와 접근성

이 두 가지 경향은 인공지능의 역량을 초고속으로 향상시키고 있으며, 동시에 새로운 능력들을 추가하고 있습니다. 크고 지능적인 인공지능 모델이 있다면, 이를 활용하여 부모 모델만큼은 아니더라도 여전히 상당히 뛰어난 더 작고, 더 빠르고, 더 저렴한 모델들을 생성할 수 있습니다. 여기에 작은 모델에도 추론기(Reasoner) 기능을 접목하면, 이들은 훨씬 더 영리해집니다. 이는 비용이 지속적으로 하락하는 가운데서도 인공지능의 성능이 끊임없이 향상되고 있음을 의미합니다. 다음 그래프는 인공지능의 능력을 y축에, 그리고 로그(logarithmically)적으로 감소하는 비용을 x축에 매핑(mapping)하여 이러한 발전 속도가 얼마나 빠른지 보여줍니다. GPT-4 출시 초기에는 백만 개의 토큰(대략 단어 하나에 해당)당 약 50달러의 비용이 들었으나, 현재는 초기 GPT-4보다 훨씬 더 뛰어난 성능을 보이는 Gemini 1.5 Flash를 활용하는 데 백만 토큰당 약 12센트 정도가 소요됩니다. 이러한 비용 효율성의 혁신은 고성능 인공지능 기술의 대중화를 가속화하며, 소규모 개발자나 스타트업도 첨단 AI 역량을 활용할 수 있는 기회를 제공합니다. 이는 인공지능 기술이 특정 거대 기업의 전유물이 아닌, 더 넓은 생태계에서 혁신을 촉진하는 플랫폼으로 자리매김하고 있음을 시사합니다.

대학원 수준의 구글 프루프 Q&A 테스트(Graduate-Level Google-Proof Q&A test, GPQA)는 고도의 지식을 평가하기 위해 고안된 매우 어려운 객관식 문제(multiple-choice problems) 시리즈입니다. 인터넷(internet)에 접근할 수 있는 박사(PhD)들은 자신의 전문 분야(specialty) 밖에서는 이 테스트에서 34%를 맞추고, 전문 분야 내에서는 81%를 맞춥니다. 백만 토큰(token)당 비용은 모델(model) 사용 비용입니다 (Gemini Flash Thinking Costs는 추정치입니다). 데이터(data)는 제 연구를 기반으로 하지만, Epoch와 Artificial Analysis는 좋은 자료였으며, Latent Space는 여러 모델에 걸친 비용에 대한 자체적인 더 포괄적인 그래프를 제공합니다. 모델의 지능은 증가하고 있으며, 시간이 지남에 따라 비용은 감소하고 있음을 알 수 있습니다. 이러한 추세는 우리 모두에게 상당한 파급 효과를 미칩니다.

### 지능형 규모의 활용을 진지하게 고려하기

인공지능 활용에 대한 많은 초점, 특히 기업 환경에서 인공지능 활용에 대한 주된 시각은 제가 '자동화 중심 사고방식(automation mindset)'이라 명명하는 틀에 갇혀 있었습니다. 이는 인공지능을 주로 전자우편 처리나 회의록 작성 등 기존 업무 흐름을 신속하게 만드는 도구로만 바라보는 관점을 의미합니다. 이러한 시각은 초기 인공지능 모델에는 어느 정도 타당했지만, 이는 마치 스마트폰(smartphone)을 오직 전화 통화 기능만으로 평가하는 것과 다름없습니다. 3세대 인공지능은 무엇이 가능한지에 대한 근본적인 재고의 기회를 제공합니다. 모델이 개선되고 추론(reasoning) 및 인터넷(internet) 접근과 같은 더 많은 기술을 적용함에 따라, 환각(hallucinate) 현상이 줄어들고(여전히 실수는 하지만) 더 높은 수준의 "사고"가 가능해집니다. 예를 들어, 이 경우 우리는 Claude에게 AI로 교육 게임(game)을 만드는 새로운 방법을 설명하는 24페이지 분량의 학술 논문과 다른 게임의 관련 없는 설명서 몇 개를 제공했습니다. 우리는 AI에게 그 예시들을 사용하여 우리 학술 논문을 기반으로 한 게임에 대한 고객 친화적인 가이드(guide)를 작성해 달라고 요청했습니다. 결과는 매우 높은 품질이었습니다. 이를 위해 AI는 논문의 아이디어(idea)와 다른 설명서의 패턴(pattern) 및 접근 방식을 모두 추상화(abstract)하여 완전히 새로운 것을 구축해야 했습니다. 이는 박사(PhD) 수준의 일주일치 작업을 단 몇 초 만에 해낸 것입니다. 그리고 오른쪽에서는 또 다른 박사 수준의 작업, 즉 복잡한 학술 논문을 읽고 수학적 논리(math and logic)를 확인하며 실제 적용에 대한 함의(implications for practice)를 파악하는 발췌문도 볼 수 있습니다. 이러한 사례들은 인공지능이 단순한 정보 처리기를 넘어, 복잡한 지식 통합 및 창출이 가능한 지적 협력자(intellectual collaborator)로 진화했음을 명확히 보여줍니다.

관리자와 지도자들은 이러한 새로운 인공지능 모델들을 고려하여, 인공지능이 무엇을 할 수 있는지, 그리고 얼마나 잘 할 수 있는지에 대한 기존의 인식을 새롭게 정립해야 할 것입니다. 인공지능이 낮은 수준의 작업만을 수행할 수 있다고 가정하기보다는, 인공지능이 진정한 지적 동반자(intellectual partner)로서 어떤 역할을 할 수 있는지 심도 있게 고민해야 합니다. 이 모델들은 이제 놀라운 정교함으로 복잡한 분석 작업, 창의적인 작업, 심지어 연구 수준의 문제까지 처리할 수 있습니다. 제가 공유한 예시들, 즉 학술 개념의 상호작용 3D 시각화(interactive 3D visualizations) 생성부터 박사 수준 분석 수행에 이르기까지는 우리가 단순한 자동화(automation)를 넘어 인공지능 기반 지식 작업(knowledge work)의 영역으로 나아가고 있음을 명확히 보여줍니다. 이러한 시스템들은 여전히 완벽과는 거리가 멀고, 광범위한 작업에서 인간 전문가(human experts)를 일관되게 능가하지는 못하지만, 그 잠재력과 현재의 성과는 매우 인상적입니다. 특히, 인공지능이 인간의 창의성을 보강하고 새로운 아이디어를 탐색하는 데 기여하는 '창의적 보조자(creative assistant)' 역할에 대한 기대가 커지고 있습니다.

이러한 변화는 조직이 인공지능 통합(integration)에 접근하는 방식에 심오한 영향을 미칩니다. 첫째, 조직의 관심사는 단순 작업 자동화(task automation)에서 역량 강화(capability augmentation)로 전환되어야 합니다. 지도자들은 '어떤 업무를 자동화할 수 있는가?'라는 질문 대신, '어떤 새로운 역량을 창출할 수 있는가?'를 물어야 합니다. 그리고 그들은 이러한 변화를 탐색하고 개발하는 데 도움이 되도록 자체 조직 내에서 역량(capacity)을 구축해야 할 것입니다. 둘째, 능력과 비용 효율성(cost efficiency) 모두에서 빠른 개선은 인공지능 구현(implementation)을 위한 어떤 정적인 전략(strategy)도 빠르게 구식이 될 것임을 의미합니다. 조직은 이러한 모델들이 계속 발전함에 따라 진화할 수 있는 동적인 접근 방식(dynamic approaches)을 개발해야 합니다. 두 가지 스케일링 법칙이 모두 작동하는 세상에서 오늘날 특정 모델에 올인(all-in)하는 것은 현명한 계획이 아닙니다. 마지막으로, 그리고 아마도 가장 중요하게는, 우리는 인공지능의 기여를 측정하고 평가하는 방법을 재고해야 합니다. 절약된 시간이나 절감된 비용이라는 전통적인 측정 기준(metrics)은 이러한 시스템들의 더 혁신적인 영향, 즉 새로운 통찰력(insights)을 생성하고, 복잡한 정보(information)를 종합하며, 새로운 형태의 문제 해결(problem-solving)을 가능하게 하는 능력을 간과할 수 있습니다. 너무 빨리 구체적인 핵심 성과 지표(KPIs)로 이동하고 탐색을 등한시하면 기업들은 무엇이 가능한지 보지 못하게 될 것입니다. 더 나쁜 것은, 이는 기업들이 인공지능을 인간 노동의 대체물로 생각하도록 조장하며, 인공지능이 인간의 작업을 어떻게 향상시킬 수 있는지 탐색하는 대신 그렇게 만듭니다. 우리는 인공지능을 단순한 도구가 아닌, 인간의 지적 한계를 확장하고 새로운 가치를 창출하는 '확장된 지능(augmented intelligence)'으로 바라보는 패러다임 전환이 필요합니다.

### 직접적인 탐색을 통한 이해

이러한 심각한 경고는 잠시 제쳐두고, 한 가지 제안을 드리고 싶습니다. 이 새로운 모델들은 영리할 뿐만 아니라, 사용자에게 더 친근하고 매력적인 상호작용을 제공합니다. 그들은 종종 사용자에게 질문을 던지거나 생각을 새로운 방향으로 이끌 가능성이 높으며, 양방향 대화(two-way conversation)에 능숙한 경향이 있습니다. 따라서 그들의 능력을 가장 잘 이해하는 방법은 직접 탐색하고 실험해보는 것입니다. Claude 3.7은 유료 고객(paying customers)에게 제공되며, 이 게시물에서 보셨듯이 자신이 작성한 코드(code)를 실행할 수 있는 깔끔한 기능이 있습니다. 이 모델은 여러분이 업로드(upload)한 데이터(data)로 훈련하지 않습니다. Grok 3는 무료이며, 훌륭한 심층 연구(Deep Research) 옵션(option)을 포함하여 더 넓은 범위의 기능(feature)을 가지고 있지만, 아마추어(amateurs)가 코딩(coding)에 사용하기에는 더 어렵습니다. 제가 시도한 작업에서는 Claude 3.7만큼 좋지는 않지만, xAI의 스케일링(scaling)에 대한 의지는 빠르게 개선될 것임을 의미합니다. 또한 Grok은 여러분의 데이터(data)로 훈련하지만, 유료 고객(paying customers)의 경우 이 기능을 끌 수 있다는 점을 알아두세요.

어떤 모델을 선택하든, 여러분은 적극적으로 실험해봐야 합니다. 모델에게 요청하기만 하면 무언가를 코딩(coding)해달라고 하거나(저는 Claude에게 허먼 멜빌(Herman Melville)의 소설 "필경사 바틀비(Bartleby the Scrivner)"를 기반으로 한 독특한 메커니즘(mechanics)을 가진 비디오 게임(video game)을 요청했고, 단 하나의 프롬프트(prompt)로 그렇게 했습니다), 문서(document)를 제공하고 인포그래픽 요약(infographic summary)을 요청하거나, 업로드(upload)한 이미지(image)에 대해 코멘트(comment)를 요청해보세요. 이것이 너무 장난스럽다면, 제 책의 조언을 따르고 위에서 언급한 개인 정보 보호(privacy) 주의 사항을 고려하여 업무 작업에만 사용하세요. 새로운 아이디어(idea)를 브레인스토밍(brainstorming)하는 데 사용하거나, 뉴스 기사(news article)나 분석가 보고서(analyst report)가 여러분의 비즈니스(business)에 어떤 영향을 미칠지 물어보거나, 새로운 제품(product)이나 스타트업(startup) 개념을 위한 재무 대시보드(financial dashboard)를 만들어달라고 요청하세요. 여러분은 놀라움을 주는 사례들을 발견할 것이고, 어떤 경우에는 새로운 모델들이 아직 도움이 될 만큼 충분히 좋지 않다는 것을 알게 될 것입니다. 중요한 것은 이들과 상호작용하는 과정에서 '프롬프트 엔지니어링(prompt engineering)'이라는 새로운 기술을 익히는 것입니다. 즉, 인공지능에게 원하는 결과를 얻기 위해 어떻게 질문하고 지시해야 하는지를 배우는 과정 자체가 새로운 역량이 됩니다.

이러한 모델들의 한계는 여전히 매우 현실적이지만, 3세대 인공지능이 첫 번째 및 두 번째 스케일링 법칙(Scaling Law) 모두로 인해 2세대 모델보다 우수하다는 사실은 우리에게 본질적인 통찰을 제공합니다. 이러한 법칙들은 우주의 근본적인 상수(constants)가 아니라, 인공지능 개발에 막대한 자원(resources)을 투입할 때 어떤 일이 일어나는지에 대한 관찰 결과입니다. 연산 능력(computing power)은 계속 증가하고, 능력은 계속 향상되며, 이 주기는 각 세대마다 가속화됩니다. 이러한 법칙들이 계속 유효한 한, 인공지능은 계속해서 발전할 것입니다. 이제 우리는 다음 세대 인공지능이 계속해서 빠른 개선을 제공할 것이며, 이는 인공지능 능력이 미래에도 계속 증가할 가능성이 높다는 것을 시사합니다. 인공지능의 발전은 단순한 기술적 진보를 넘어, 인류 사회와 경제 구조, 그리고 우리의 삶의 방식 전반에 걸쳐 근본적인 변화를 가져올 거대한 흐름임을 인식하고, 이에 대한 심도 있는 이해와 현명한 대응이 필요한 시점입니다.

구독 공유