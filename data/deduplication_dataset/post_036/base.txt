# **새로운 세대의 AI: 클로드 3.7과 그록 3**

Author: Ethan Mollick
URL: https://www.oneusefulthing.org/p/a-new-generation-of-ais-claude-37

============================================================

**참고**: 이 글을 게시한 후, Anthropic으로부터 Sonnet 3.7이 10^26 FLOP 모델로 간주되지 않으며 훈련에 수천만 달러가 들었지만, 미래 모델은 훨씬 더 커질 것이라는 연락을 받았습니다. 저는 이 정보를 바탕으로 게시물을 업데이트했습니다. 유일한 중요한 변경 사항은 Claude 3가 이제 Gen3 모델이 아닌 고급(advanced) 모델로 언급된다는 것입니다.

저는 지난 며칠 동안 새로운 세대의 AI 모델인 Claude 3.7과 Grok 3의 첫 번째 버전을 실험해 왔습니다. Grok 3는 GPT-4보다 한 자릿수 더 많은 컴퓨팅 파워(computing power)로 훈련된 것으로 알려진 최초의 모델이며, Claude는 새로운 코딩(coding) 및 추론(reasoning) 기능을 포함하고 있습니다. 따라서 이 모델들은 그 자체로 흥미로울 뿐만 아니라 AI가 어디로 향하고 있는지에 대한 중요한 정보를 제공합니다. 본격적으로 들어가기 전에 간단히 살펴보자면, 이 새로운 세대의 AI는 더 똑똑하며, 특히 복잡한 작업, 수학, 코드(code)를 처리하는 방식에서 능력의 도약이 놀랍습니다. 이 모델들은 제가 ChatGPT-4를 처음 사용했을 때와 같은 느낌을 자주 줍니다. 즉, 그 능력에 깊은 인상을 받으면서도 동시에 약간 불안감을 느낍니다.

Claude의 기본 코딩(coding) 능력을 예로 들면, 이제 저는 자연스러운 대화나 문서를 통해 작동하는 프로그램(program)을 얻을 수 있으며, 프로그래밍(programming) 기술이 필요 없습니다. 예를 들어, Claude에게 새로운 AI 교육 도구에 대한 제안서를 주고 "제안된 시스템 아키텍처(system architecture)를 3D로 표시하고 상호작용(interactive) 가능하게 만들어라"고 요청하는 대화를 나눈 결과, 저희 논문의 핵심 설계에 대한 상호작용 시각화(interactive visualization)가 오류 없이 생성되었습니다. 여기에서 직접 시도해 볼 수 있으며, AI에게 요청하여 편집하거나 변경할 수 있습니다. 그래픽(graphics)은 깔끔했지만, 인상적인 부분은 아니었습니다. 오히려 Claude가 요청받지 않은 일임에도 불구하고 개념을 설명하기 위해 이를 단계별 데모(demo)로 만들기로 결정했다는 점이었습니다. 이러한 필요를 예측하고 새로운 접근 방식을 고려하는 것은 AI에서 새로운 현상입니다. 또는 좀 더 재미있는 예시로, 저는 Claude에게 "상호작용하는 타임머신(time machine) 유물을 만들어줘, 시간을 거슬러 여행하고 흥미로운 일들이 일어나게 해줘. 돌아갈 수 있는 특이한 시간대를 골라줘..."라고 말하고 "그래픽(graphics)을 더 추가해줘"라고 요청했습니다. 이 두 가지 프롬프트(prompt)만으로 투박하지만 매력적인 픽셀 그래픽(pixel graphics)을 갖춘 완벽하게 작동하는 상호작용 경험이 탄생했습니다 (이는 사실 놀랍도록 인상적입니다. AI는 자신이 무엇을 만들고 있는지 볼 수 없는 상태에서 순수한 코드(code)를 사용하여 이를 '그려야' 합니다. 마치 눈을 가린 예술가가 그림을 그리면서도 정확한 그림을 만들어내는 것과 같습니다). 명확히 말하면, 이러한 시스템(system)들은 완벽과는 거리가 멀고 실수를 저지르지만, 빠르게 훨씬 더 좋아지고 있습니다.

현재 상황과 미래 방향을 이해하기 위한

### 두 가지 스케일링 법칙(Scaling Laws)

겉보기에는 그렇지 않을지라도, 이것들은 AI에서 가장 중요한 두 가지 그래프(graph)일 수 있습니다. OpenAI가 발표한 이 그래프들은 AI가 어려운 질문에 답하는 능력을 어떻게 향상시킬 수 있는지, 이 경우 유명하게 어려운 미국 초청 수학 시험(AIME)에서 더 높은 점수를 얻는 방법을 알려주는 두 가지 "스케일링 법칙(Scaling Laws)"을 보여줍니다. 왼쪽 그래프는 훈련 스케일링 법칙(training Scaling Law)입니다. 이는 더 큰 모델(model)이 더 유능하다는 것을 보여줍니다. 이러한 더 큰 모델들을 훈련시키려면 사용되는 컴퓨팅 파워(computing power), 데이터(data), 에너지(energy)의 양을 늘려야 하며, 이를 대규모로 수행해야 합니다. 일반적으로 성능의 선형적인 증가를 얻기 위해서는 컴퓨팅 파워(computing power)를 10배 늘려야 합니다. 컴퓨팅 파워(computing power)는 컴퓨터(computer)가 수행하는 덧셈이나 곱셈과 같은 기본적인 수학 연산의 수인 FLOPs(Floating Point Operations)로 측정되며, 이는 AI 훈련(training) 중에 수행되는 계산 작업량을 정량화하는 방법을 제공합니다.

우리는 이제 GPT-4와 그 많은 경쟁자들보다 10배 이상의 컴퓨팅 파워(computing power)로 훈련된 새로운 세대 AI의 첫 번째 모델들을 보고 있습니다. 이 모델들은 훈련에 10^26 FLOPs 이상의 컴퓨팅 파워(computing power)를 사용합니다. 이는 현대 스마트폰(smartphone)을 634,000년 동안 구동하거나, 인류를 달에 보낸 아폴로 유도 컴퓨터(Apollo Guidance Computer)를 79조 년 동안 구동하는 것과 맞먹는 엄청난 양의 컴퓨팅 파워(computing power)입니다. 하지만 10^26을 명명하는 것은 어색합니다. 이는 100 셉틸리언(septillion) FLOPs이거나, 표준 단위 이름에 약간의 자유를 부여하면 헥토요타플롭(HectoyottaFLOP)입니다. 따라서 제가 이들을 GPT-4(Gen2)보다 한 자릿수 더 많은 컴퓨팅 파워(computing power)로 훈련된 최초의 AI 집합인 Gen3 모델(model)이라고 부르는 이유를 알 수 있을 것입니다.

일론 머스크(Elon Musk)의 AI 회사인 xAI는 Grok 3로 Gen3 영역에 처음으로 공개적으로 진출했으며, 이는 그들의 전략을 고려할 때 놀라운 일이 아닙니다. xAI는 더 큰 것(훨씬 더 큰 것)이 더 좋다는 생각에 크게 베팅하고 있습니다. xAI는 세계에서 가장 큰 컴퓨터 클러스터(computer cluster)를 기록적인 시간 내에 구축했으며, 이는 Grok 3가 새로운 세대 AI에 스케일링 법칙(Scaling Law)이 유효한지 여부를 보여준 최초의 AI 모델(model)이었음을 의미합니다. Grok 3가 어떤 기본 모델(base model)에서도 볼 수 없었던 가장 높은 벤치마크(benchmark) 점수를 기록했으므로, 스케일링 법칙은 유효한 것으로 보입니다. 오늘 Claude 3.7이 출시되었는데, 아직 Gen3 모델(model)은 아니지만 이전 AI들에 비해 성능에서 상당한 개선을 보여줍니다. 벤치마크(benchmark)에서는 Grok 3와 유사하지만, 저는 개인적으로 제 사용 사례(use case)에 더 영리하다고 생각합니다. 하지만 여러분은 다르게 생각할 수도 있습니다. 아직 출시되지 않은 OpenAI의 o3 또한 뛰어난 성능을 가진 Gen3 모델(model)인 것으로 보입니다. 이는 단지 시작에 불과할 가능성이 높습니다. Anthropic을 포함한 더 많은 회사들이 이 규모의 자체 모델(model)을 출시할 준비를 하고 있습니다.

오른쪽에 있는 두 번째 그래프(graph)에 대해서는 아직 언급하지 않았다는 것을 눈치채셨을 것입니다. 첫 번째 스케일링 법칙(Scaling Law)이 훈련에 막대한 컴퓨팅 파워(computing power)를 투입하는 것(기본적으로 처음부터 더 똑똑한 AI를 구축하는 것)에 관한 것이라면, 두 번째 법칙은 놀라운 사실을 밝혀냈습니다. 즉, AI에게 생각할 시간을 더 많이 주면 단순히 성능을 향상시킬 수 있다는 것입니다. OpenAI는 모델(model)이 문제 해결에 더 많은 컴퓨팅 파워(computing power)를 사용하게 하면(그들이 테스트 시간(test-time) 또는 추론 시간 컴퓨팅(inference-time compute)이라고 부르는 것), 더 나은 결과를 얻는다는 것을 발견했습니다. 이는 똑똑한 사람에게 퍼즐(puzzle)을 풀 시간을 몇 분 더 주는 것과 비슷합니다. 이 두 번째 스케일링 법칙(Scaling Law)은 제가 지난 게시물에서 썼던 추론기(Reasoners)의 탄생으로 이어졌습니다. 새로운 세대의 Gen3 모델(model)들은 필요할 때 모두 추론기(Reasoners)로 작동할 것이므로, 두 가지 장점을 가집니다. 즉, 훈련(training)에서의 더 큰 규모와 실제로 문제를 해결할 때 확장(scale)할 수 있는 능력입니다.

### 추론(reasoning)을 사용하는 세 가지 다른 모델(model)의 예시

이 두 가지 추세는 함께 AI 능력을 초고속으로 향상시키고 있으며, 다른 능력들도 추가하고 있습니다. 크고 똑똑한 AI 모델(model)이 있다면, 그것을 사용하여 부모 모델(parent model)만큼은 아니더라도 여전히 상당히 똑똑한 더 작고, 더 빠르고, 더 저렴한 모델들을 만들 수 있습니다. 그리고 작은 모델(model)에도 추론기(Reasoner) 기능을 추가하면, 그들은 훨씬 더 똑똑해집니다. 이는 비용이 하락하는 와중에도 AI 능력이 향상되고 있다는 것을 의미합니다. 이 그래프(graph)는 AI의 능력을 y축에, 로그(logarithmically)적으로 감소하는 비용을 x축에 매핑(mapping)하여 이 추세가 얼마나 빠르게 발전했는지 보여줍니다. GPT-4가 처음 나왔을 때는 백만 토큰(token, 대략 한 단어)당 약 50달러였지만, 이제는 원래 GPT-4보다 훨씬 더 유능한 모델(model)인 Gemini 1.5 Flash를 사용하는 데 백만 토큰당 약 12센트가 듭니다.

대학원 수준의 구글 프루프 Q&A 테스트(Graduate-Level Google-Proof Q&A test, GPQA)는 고급 지식을 테스트하기 위해 고안된 매우 어려운 객관식 문제(multiple-choice problems) 시리즈입니다. 인터넷(internet)에 접근할 수 있는 박사(PhD)들은 자신의 전문 분야(specialty) 밖에서는 이 테스트(test)에서 34%를 맞추고, 전문 분야 내에서는 81%를 맞춥니다. 백만 토큰(token)당 비용은 모델(model) 사용 비용입니다 (Gemini Flash Thinking Costs는 추정치입니다). 데이터(data)는 제 연구를 기반으로 하지만, Epoch와 Artificial Analysis는 좋은 자료였으며, Latent Space는 여러 모델(model)에 걸친 비용에 대한 자체적인 더 포괄적인 그래프(graph)를 제공합니다. 모델(model)의 지능은 증가하고 있으며, 시간이 지남에 따라 비용은 감소하고 있음을 알 수 있습니다. 이는 우리 모두에게 상당히 큰 영향을 미칩니다.

### 규모를 진지하게 받아들이기

AI 사용에 대한 많은 초점, 특히 기업 세계에서는 제가 "자동화 사고방식(automation mindset)"이라고 부르는 것에 갇혀 있었습니다. 즉, AI를 주로 이메일 관리(email management) 및 회의록 작성(meeting transcription)과 같은 기존 워크플로우(workflow)를 가속화하는 도구로 보는 것입니다. 이러한 관점은 초기 AI 모델(model)에는 타당했지만, 스마트폰(smartphone)을 오직 전화 통화 능력만으로 평가하는 것과 같습니다. Gen3 세대는 무엇이 가능한지에 대한 근본적인 재고의 기회를 제공합니다. 모델(model)이 개선되고 추론(reasoning) 및 인터넷(internet) 접근과 같은 더 많은 기술을 적용함에 따라, 환각(hallucinate) 현상이 줄어들고(여전히 실수는 하지만) 더 높은 수준의 "사고"가 가능해집니다. 예를 들어, 이 경우 우리는 Claude에게 AI로 교육 게임(game)을 만드는 새로운 방법을 설명하는 24페이지 분량의 학술 논문과 다른 게임(game)의 관련 없는 설명서 몇 개를 제공했습니다. 우리는 AI에게 그 예시들을 사용하여 우리 학술 논문을 기반으로 한 게임(game)에 대한 고객 친화적인 가이드(guide)를 작성해 달라고 요청했습니다. 결과는 매우 높은 품질이었습니다. 이를 위해 AI는 논문의 아이디어(idea)와 다른 설명서의 패턴(pattern) 및 접근 방식을 모두 추상화(abstract)하여 완전히 새로운 것을 구축해야 했습니다. 이는 박사(PhD) 수준의 일주일치 작업을 단 몇 초 만에 해낸 것입니다. 그리고 오른쪽에서는 또 다른 박사(PhD) 수준의 작업, 즉 복잡한 학술 논문을 읽고 수학적 논리(math and logic)를 확인하며 실제 적용에 대한 함의(implications for practice)를 파악하는 발췌문도 볼 수 있습니다.

관리자와 리더(leader)들은 이러한 새로운 AI 모델(model)들을 고려하여 AI가 무엇을 할 수 있는지, 그리고 얼마나 잘 할 수 있는지에 대한 믿음을 업데이트(update)해야 할 것입니다. AI가 낮은 수준의 작업만 할 수 있다고 가정하기보다는, AI가 진정한 지적 파트너(intellectual partner)로서 역할을 할 수 있는 방법을 고려해야 할 것입니다. 이 모델(model)들은 이제 놀라운 정교함으로 복잡한 분석 작업, 창의적인 작업, 심지어 연구 수준의 문제까지 다룰 수 있습니다. 제가 공유한 예시들, 즉 학술 개념의 상호작용 3D 시각화(interactive 3D visualizations) 생성부터 박사(PhD) 수준 분석 수행에 이르기까지는 우리가 단순한 자동화(automation)를 넘어 AI 기반 지식 작업(knowledge work)의 영역으로 나아가고 있음을 보여줍니다. 이러한 시스템(system)들은 여전히 완벽과는 거리가 멀고, 광범위한 작업에서 인간 전문가(human experts)를 일관되게 능가하지는 못하지만, 매우 인상적입니다.

이러한 변화는 조직이 AI 통합(integration)에 접근하는 방식에 심오한 영향을 미칩니다. 첫째, 초점은 작업 자동화(task automation)에서 능력 증강(capability augmentation)으로 이동해야 합니다. "어떤 작업을 자동화할 수 있는가?"라고 묻는 대신, 리더(leader)들은 "어떤 새로운 능력을 발휘할 수 있는가?"라고 물어야 합니다. 그리고 그들은 이러한 변화를 탐색하고 개발하는 데 도움이 되도록 자체 조직 내에서 역량(capacity)을 구축해야 할 것입니다. 둘째, 능력과 비용 효율성(cost efficiency) 모두에서 빠른 개선은 AI 구현(implementation)을 위한 어떤 정적인 전략(strategy)도 빠르게 구식이 될 것임을 의미합니다. 조직은 이러한 모델(model)들이 계속 발전함에 따라 진화할 수 있는 동적인 접근 방식(dynamic approaches)을 개발해야 합니다. 두 가지 스케일링 법칙(Scaling Laws)이 모두 작동하는 세상에서 오늘날 특정 모델(model)에 올인(all-in)하는 것은 좋은 계획이 아닙니다. 마지막으로, 그리고 아마도 가장 중요하게는, 우리는 AI 기여를 측정하고 평가하는 방법을 재고해야 합니다. 절약된 시간이나 절감된 비용이라는 전통적인 측정 기준(metrics)은 이러한 시스템(system)들의 더 혁신적인 영향, 즉 새로운 통찰력(insights)을 생성하고, 복잡한 정보(information)를 종합하며, 새로운 형태의 문제 해결(problem-solving)을 가능하게 하는 능력을 놓칠 수 있습니다. 너무 빨리 구체적인 핵심 성과 지표(KPIs)로 이동하고 탐색을 등한시하면 기업들은 무엇이 가능한지 보지 못하게 될 것입니다. 더 나쁜 것은, 이는 기업들이 AI를 인간 노동의 대체물로 생각하도록 장려하며, AI가 인간의 작업을 어떻게 향상시킬 수 있는지 탐색하는 대신 그렇게 만듭니다.

### 직접 탐색하기

이러한 심각한 경고는 제쳐두고, 한 가지 제안을 드리고 싶습니다. 이 새로운 모델(model)들은 영리하지만, 또한 친근하고 사용하기에 더 매력적입니다. 그들은 여러분에게 질문을 하거나 여러분의 생각을 새로운 방향으로 이끌 가능성이 높으며, 양방향 대화(two-way conversation)에 능숙한 경향이 있습니다. 따라서 그들의 능력을 이해하는 가장 좋은 방법은 직접 탐색하는 것입니다. Claude 3.7은 유료 고객(paying customers)에게 제공되며, 이 게시물에서 보셨듯이 자신이 작성한 코드(code)를 실행할 수 있는 깔끔한 기능이 있습니다. 이 모델은 여러분이 업로드(upload)한 데이터(data)로 훈련하지 않습니다. Grok 3는 무료이며, 훌륭한 심층 연구(Deep Research) 옵션(option)을 포함하여 더 넓은 범위의 기능(feature)을 가지고 있지만, 아마추어(amateurs)가 코딩(coding)에 사용하기에는 더 어렵습니다. 제가 시도한 작업에서는 Claude 3.7만큼 좋지는 않지만, Xai의 스케일링(scaling)에 대한 의지는 빠르게 개선될 것임을 의미합니다. 또한 Grok은 여러분의 데이터(data)로 훈련하지만, 유료 고객(paying customers)의 경우 이 기능을 끌 수 있다는 점을 알아두세요.

어떤 모델(model)을 선택하든, 여러분은 실험해봐야 합니다. 모델(model)에게 요청하기만 하면 무언가를 코딩(coding)해달라고 하거나(저는 Claude에게 허먼 멜빌(Herman Melville)의 소설 "필경사 바틀비(Bartleby the Scrivner)"를 기반으로 한 독특한 메커니즘(mechanics)을 가진 비디오 게임(video game)을 요청했고, 단 하나의 프롬프트(prompt)로 그렇게 했습니다), 문서(document)를 제공하고 인포그래픽 요약(infographic summary)을 요청하거나, 업로드(upload)한 이미지(image)에 대해 코멘트(comment)를 요청해보세요. 이것이 너무 장난스럽다면, 제 책의 조언을 따르고 위에서 언급한 개인 정보 보호(privacy) 주의 사항을 고려하여 업무 작업에만 사용하세요. 새로운 아이디어(idea)를 브레인스토밍(brainstorming)하는 데 사용하거나, 뉴스 기사(news article)나 분석가 보고서(analyst report)가 여러분의 비즈니스(business)에 어떤 영향을 미칠지 물어보거나, 새로운 제품(product)이나 스타트업(startup) 개념을 위한 재무 대시보드(financial dashboard)를 만들어달라고 요청하세요. 여러분은 놀라움을 주는 사례들을 발견할 것이고, 어떤 경우에는 새로운 모델(model)들이 아직 도움이 될 만큼 충분히 좋지 않다는 것을 알게 될 것입니다.

이러한 모델(model)들의 한계는 여전히 매우 현실적이지만, Gen3 AI가 첫 번째 및 두 번째 스케일링 법칙(Scaling Law) 모두로 인해 Gen2보다 우수하다는 사실은 우리에게 본질적인 것을 보여줍니다. 이러한 법칙들은 우주의 근본적인 상수(constants)가 아니라, AI 개발에 막대한 자원(resources)을 투입할 때 어떤 일이 일어나는지에 대한 관찰 결과입니다. 컴퓨팅 파워(computing power)는 계속 증가하고, 능력은 계속 향상되며, 이 주기는 각 세대마다 가속화됩니다. 이러한 법칙들이 계속 유효한 한, AI는 계속해서 발전할 것입니다. 이제 우리는 다음 세대 AI가 계속해서 빠른 개선을 제공할 것이며, 이는 AI 능력이 미래에도 계속 증가할 가능성이 높다는 것을 시사합니다.

구독 공유