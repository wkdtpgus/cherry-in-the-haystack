**참고**: 이 글을 게시한 후, Anthropic으로부터 Sonnet 3.7이 10^26 FLOP 수준의 모델로 분류되지 않으며 훈련에 수천만 달러 규모의 훈련 비용이 소요되었지만, 향후 모델들은 훨씬 더 거대해질 것이라는 연락을 받았습니다. 저는 이 정보를 바탕으로 게시물을 갱신했습니다. 유일한 중요한 변경 사항은 Claude 3가 이제 Gen3 모델이 아닌 향상된(advanced) 모델로 지칭된다는 점입니다. 이러한 변화의 속도는 AI 기술 발전의 역동성을 명확히 보여줍니다.

저는 최근 며칠 동안 차세대 인공지능 모델인 Claude 3.7과 Grok 3의 초기 버전을 탐구해 보았습니다. Grok 3는 GPT-4 대비 훨씬 더 높은 연산 능력(computing power)으로 학습된 것으로 알려진 최초의 모델이며, Claude는 혁신적인 코딩(coding) 및 추론(reasoning) 역량을 포함하고 있습니다. 이러한 모델들은 그 자체로도 매력적일 뿐만 아니라, 인공지능 기술이 나아갈 방향에 대한 중요한 통찰력을 제공합니다. 간략히 살펴보자면, 이 새로운 시대의 AI는 이전보다 훨씬 더 지능적이며, 특히 복잡한 작업, 수학적 문제, 그리고 코드(code) 처리 방식에서 역량의 비약적인 발전이 눈에 띕니다. 이들 모델은 제가 ChatGPT-4를 처음 접했을 때와 유사한 감정을 자주 불러일으킵니다. 즉, 그 능력에 깊은 감명을 받으면서도 동시에 미묘한 불안감을 경험합니다. 이러한 감정은 인공지능이 단순한 도구를 넘어선 지적 동반자로 진화하고 있음을 반영하는 것일지도 모릅니다.

Claude의 코딩(coding) 역량을 예로 들어보면, 이제 저는 자연스러운 대화나 문서를 통해서도 실행 가능한 프로그램(program)을 얻을 수 있으며, 별도의 프로그래밍(programming) 지식 없이도 가능합니다. 예를 들어, Claude에게 새로운 AI 교육 도구에 대한 제안서를 건네고 "제안된 시스템 아키텍처(system architecture)를 3D로 시각화하고 상호작용(interactive) 가능하게 만들어라"고 요청하는 대화를 나눈 결과, 저희 논문의 핵심 설계에 대한 상호작용 시각화(interactive visualization)가 문제없이 만들어졌습니다. 이 결과물은 직접 체험해 볼 수 있으며, AI에게 요청하여 수정하거나 변경할 수도 있습니다. 생성된 그래픽(graphics)은 깔끔했지만, 그 자체로 가장 인상적인 부분은 아니었습니다. 오히려 Claude가 명시적인 지시 없이도 개념을 설명하기 위해 이를 단계별 데모(demo)로 만들기로 결정했다는 점이 놀라웠습니다. 사용자의 잠재적 요구를 예측하고 창의적인 해결책을 제시하는 것은 인공지능 분야에서 새롭게 나타나는 현상입니다. 또는 좀 더 흥미로운 예시로, 저는 Claude에게 "상호작용하는 타임머신(time machine) 유물을 만들어줘, 시간을 거슬러 여행하고 흥미로운 일들이 일어나게 해줘. 돌아갈 수 있는 특이한 시간대를 골라줘..."라고 말하고 "그래픽(graphics)을 더 추가해줘"라고 요청했습니다. 이 단 두 가지 프롬프트(prompt)만으로 다소 투박하나 매력적인 픽셀 기반 이미지(pixel graphics)를 갖춘 완벽하게 작동하는 상호작용 경험이 탄생했습니다. (이는 사실 놀랍도록 인상적입니다. AI는 자신이 무엇을 만들고 있는지 볼 수 없는 상태에서 순수한 코드(code)를 사용하여 이를 '그려야' 합니다. 마치 눈을 가린 채로도 정확한 그림을 그려내는 숙련된 예술가와 같습니다.) 물론 이러한 시스템(system)들은 완벽과는 거리가 멀고 실수를 저지르기도 하지만, 그 발전 속도는 놀랍도록 빠릅니다. 이제는 이러한 '선제적 사고' 능력이 다양한 모델에서 나타나며, 단순히 명령을 수행하는 것을 넘어 사용자의 의도를 파악하고 최적의 결과를 위한 추가적인 단계를 제안하는 방향으로 진화하고 있습니다.

현재 상황과 미래 방향을 이해하기 위한

### 두 가지 스케일링 법칙(Scaling Laws)

겉으로 보기에는 평범해 보일지라도, 이것들은 AI 분야에서 가장 핵심적인 두 가지 도표일 가능성이 높습니다. OpenAI가 공개한 이 그래프들은 인공지능이 복잡한 문제 해결 역량을 어떻게 증진시킬 수 있는지, 이 경우 유명하게 어려운 미국 초청 수학 시험(AIME)에서 더 높은 점수를 얻는 방법을 알려주는 두 가지 "스케일링 법칙(Scaling Laws)"을 보여줍니다. 왼쪽 그래프는 훈련 스케일링 법칙(training Scaling Law)입니다. 이는 모델의 규모가 커질수록 더욱 뛰어난 성능을 발휘함을 입증합니다. 이러한 대규모 모델들을 훈련시키려면 필요한 연산 자원(computing power), 학습 데이터(data), 소모 에너지(energy)의 규모를 확대해야 하며, 이를 방대한 규모로 수행해야 합니다. 일반적으로 성능의 비례적 향상을 달성하려면 연산 능력(computing power)을 10배 늘려야 합니다. 연산 능력(computing power)은 컴퓨터(computer)가 수행하는 덧셈, 곱셈 등 기초적인 수학적 연산의 총량인 FLOPs(Floating Point Operations)로 측정되며, 이는 AI 훈련(training) 과정에서 수행되는 계산 작업량을 정량화하는 유용한 방법을 제공합니다. 이러한 대규모 모델 훈련은 종종 예측 불가능한 '초월적 능력(emergent properties)'을 발현시키는데, 이는 특정 규모 이상에서 모델이 이전에 보이지 않던 새로운 역량을 갑자기 습득하는 현상을 의미합니다.

우리는 이제 GPT-4와 다수의 경쟁 모델들을 능가하는, 10배를 초과하는 연산 능력(computing power)으로 학습된 새로운 세대 AI의 첫 모델들을 목격하고 있습니다. 이 모델들은 훈련에 10^26 FLOPs 이상의 연산 능력(computing power)을 사용합니다. 이는 현대 스마트폰(smartphone)을 634,000년 동안 구동하거나, 인류를 달에 보낸 아폴로 유도 컴퓨터(Apollo Guidance Computer)를 79조 년 동안 구동하는 것과 필적하는 막대한 규모의 연산 자원(computing power)에 해당합니다. 하지만 10^26이라는 숫자에 명칭을 부여하기에는 다소 부자연스럽습니다. 이는 100 셉틸리언(septillion) FLOPs이거나, 표준 단위 명칭에 다소 유연성을 적용하자면 헥토요타플롭(HectoyottaFLOP)입니다. 따라서 제가 이들을 GPT-4(Gen2)보다 한 자릿수 더 많은 연산 능력(computing power)으로 훈련된 최초의 AI 집합인 Gen3 모델(model)이라고 부르는 이유를 알 수 있을 것입니다. 이러한 규모의 AI 훈련은 엄청난 양의 에너지를 소모하며, 이는 지속 가능성(sustainability)과 환경적 영향에 대한 중요한 논의를 촉발하고 있습니다. 각 기업은 더욱 강력한 AI 모델을 구축하기 위한 경쟁에 뛰어들고 있으며, 이는 기술적 우위를 확보하려는 전략적 움직임으로 해석될 수 있습니다.

일론 머스크(Elon Musk)의 AI 회사인 xAI는 Grok 3를 통해 Gen3 영역에 처음으로 공개적으로 진출했으며, 이는 그들의 전략을 고려할 때 예상 밖의 일은 아닙니다. xAI는 더 큰 것(훨씬 더 큰 것)이 더 좋다는 신념에 과감하게 투자하고 있습니다. xAI는 세계에서 가장 큰 컴퓨터 클러스터(computer cluster)를 최단 시간 내에 건설했으며, 이는 Grok 3가 새로운 세대 AI에 스케일링 법칙(Scaling Law)의 유효성을 입증한 첫 AI 모델(model) 중 하나임을 시사합니다. Grok 3가 기존의 어떤 기반 모델(base model)도 달성하지 못했던 최고 수준의 벤치마크(benchmark) 성과를 달성했기에, 스케일링 법칙은 여전히 유효한 것으로 보입니다. 오늘 Claude 3.7이 출시되었는데, 아직 Gen3 모델(model)은 아니지만 이전 AI들에 비해 성능 면에서 현저한 진전을 드러냅니다. 벤치마크(benchmark)에서는 Grok 3와 유사하지만, 저는 개인적인 활용 사례(use case)에서 더 우수한 지능을 보인다고 판단합니다. 하지만 여러분은 다르게 생각할 수도 있습니다. 아직 출시되지 않은 OpenAI의 o3 또한 뛰어난 성능을 가진 Gen3 모델(model)인 것으로 보입니다. 이러한 현상은 단지 시작에 불과할 가능성이 높습니다. Anthropic을 포함한 더 많은 회사들이 이 규모의 자체 모델(model)을 출시할 준비를 하고 있으며, Google의 Gemini 시리즈나 Meta의 Llama와 같은 다른 주요 모델들도 이 경쟁에 합류하며 AI 생태계를 더욱 풍성하게 만들고 있습니다.

오른쪽에 있는 두 번째 그래프(graph)에 대해서는 아직 다루지 않았다는 점을 알아차리셨을 겁니다. 첫 번째 스케일링 법칙(Scaling Law)이 훈련에 막대한 연산 능력(computing power)을 투입하는 것(기본적으로 처음부터 더 똑똑한 AI를 구축하는 것)에 관한 것이라면, 두 번째 법칙은 놀라운 진실을 드러냈습니다. 즉, AI에게 생각할 시간을 더 많이 주면 단순히 성능을 개선할 수 있다는 결론입니다. OpenAI는 모델(model)이 문제 해결에 더 많은 연산 능력(computing power)을 사용하게 하면(그들이 테스트 시간(test-time) 또는 추론 시간 연산(inference-time compute)이라고 부르는 것), 더욱 우수한 성과를 도출한다는 점을 확인했습니다. 이는 지능적인 사람에게 퍼즐(puzzle)을 푸는 데 추가 시간을 할애하는 것과 유사합니다. 이 두 번째 스케일링 법칙(Scaling Law)은 제가 지난 게시물에서 다루었던 추론 엔진(Reasoners)의 출현을 촉발했습니다. '사고의 사슬(Chain-of-Thought)'이나 '사고의 나무(Tree-of-Thought)'와 같은 기법을 통해 AI는 문제를 단계별로 분석하고 여러 가능성을 탐색하며, 이는 최종 결과의 정확성과 깊이를 크게 향상시킵니다. 새로운 세대의 Gen3 모델(model)들은 필요할 때 모두 추론 엔진(Reasoners)으로 작동할 것이므로, 두 가지 장점을 가집니다. 즉, 훈련(training)에서의 더 큰 규모와 실제로 문제를 해결할 때 확장(scale)할 수 있는 능력입니다. 이러한 추론 능력은 더 작은 모델들에도 적용될 수 있어, 고급 AI 기능의 접근성과 비용 효율성을 높이는 데 기여합니다.

### 추론(reasoning)을 사용하는 세 가지 다른 모델(model)의 예시

이 두 가지 추세는 함께 AI 능력을 극도로 빠르게 발전시키고 있으며, 새로운 역량들을 더하고 있습니다. 크고 지능적인 AI 모델(model)이 있다면, 그것을 사용하여 원천 모델(parent model) 수준은 아니더라도 여전히 상당한 지능을 가진 더 작고, 더 빠르고, 더 저렴한 모델들을 만들 수 있습니다. 이를 '모델 증류(model distillation)'라고 부르는데, 이는 대규모 모델의 지식을 소규모 모델로 이전하는 과정입니다. 그리고 소규모 모델(model)에도 추론 엔진(Reasoner) 기능을 추가하면, 그들은 훨씬 더 똑똑해집니다. 이는 비용은 감소하는 동시에 AI의 역량은 증대되고 있음을 뜻합니다. 이 그래프(graph)는 AI의 능력을 y축에, 로그(logarithmically) 스케일로 하락하는 비용을 x축에 대응시켜 이 추세가 얼마나 빠르게 발전했는지 보여줍니다. GPT-4가 처음 나왔을 때는 백만 토큰(token, 대략 한 단어)당 약 50달러였지만, 이제는 월등히 뛰어난 역량을 지닌 Gemini 1.5 Flash를 활용하는 데 백만 토큰당 약 12센트가 듭니다. 이러한 비용 효율성의 증가는 AI 기술의 민주화를 가속화하며, 더 많은 사용자 및 기업이 고급 AI 기능을 활용할 수 있게 합니다.

대학원 수준의 구글 프루프 Q&A 테스트(Graduate-Level Google-Proof Q&A test, GPQA)는 최고 수준의 지식을 평가하도록 설계된 매우 난해한 객관식 문항(multiple-choice problems)들로 구성됩니다. 인터넷(internet)에 접근할 수 있는 박사(PhD)들은 본인의 전공 분야(specialty) 외에서는 해당 시험(test)에서 34%의 정답률을 보이며, 전문 분야 내에서는 81%를 맞춥니다. 백만 토큰(token)당 비용은 모델(model) 사용 비용입니다 (Gemini Flash Thinking Costs는 추정치입니다). 데이터(data)는 제 연구를 기반으로 하지만, Epoch와 Artificial Analysis는 좋은 자료였으며, Latent Space는 여러 모델(model)에 걸친 비용에 대한 더욱 광범위한 도표를 제시합니다. 모델(model)의 지능은 증가하고 있으며, 시간이 지남에 따라 비용은 감소하고 있음을 알 수 있습니다. 이는 우리 모두에게 매우 중대한 파급 효과를 가져옵니다. AI가 이러한 전문 지식 영역에서 인간 전문가의 수준에 근접하거나 심지어 능가하기 시작하면서, 과학 연구, 법률, 의료 진단 등 고도로 전문화된 분야에서의 AI 활용 가능성은 무궁무진해지고 있습니다.

### 규모를 진지하게 받아들이기

AI 사용에 대한 많은 초점, 특히 기업 세계에서는 제가 "자동화 중심의 사고방식(automation mindset)"이라고 부르는 것에 머물러 있었습니다. 즉, AI를 주로 이메일 관리(email management) 및 회의록 작성(meeting transcription)과 같은 기존 업무 흐름(workflow)을 효율화하는 수단으로 간주하는 경향이 있었습니다. 이러한 관점은 초기 AI 모델(model)에는 적절했으나, 스마트폰(smartphone)을 오직 전화 통화 능력만으로 평가하는 것과 같습니다. Gen3 세대는 무엇이 가능한지에 대한 본질적인 재평가의 기회를 제공합니다. 모델(model)이 개선되고 추론(reasoning) 및 인터넷(internet) 접근과 같은 더 많은 기술을 적용함에 따라, 환각(hallucination) 현상이 감소하며(여전히 실수는 하지만) 더욱 고차원적인 "사고"가 구현 가능해집니다. 예를 들어, 이 경우 우리는 Claude에게 AI로 교육 게임(game)을 만드는 새로운 방법을 설명하는 24페이지 분량의 학술 논문과 다른 게임(game)의 관련 없는 설명서 몇 개를 제공했습니다. 우리는 AI에게 그 예시들을 사용하여 우리 학술 논문을 기반으로 한 게임(game)에 대한 사용자 친화적인 안내서(guide)를 생성해 달라고 요청했습니다. 결과는 매우 높은 품질이었습니다. 이를 위해 AI는 논문의 아이디어(idea)와 다른 설명서의 패턴(pattern) 및 접근 방식을 모두 추상화(abstract)하여 완전히 새로운 것을 구축해야 했습니다. 이는 박사(PhD) 학위 소지자의 일주일간 작업량을 단 수 초 만에 수행해냈습니다. 그리고 오른쪽에서는 또 다른 박사(PhD) 수준의 작업, 즉 복잡한 학술 논문을 읽고 수학적 논리(math and logic)를 확인하며 실제 적용에 대한 함의(implications for practice)를 파악하는 발췌문도 볼 수 있습니다. 이러한 AI는 단순한 자동화 도구를 넘어 '공동 창작자(co-creator)' 또는 '증강 지능(augmented intelligence)'으로서의 역할을 수행하며, 법률 문서 초안 작성, 복잡한 데이터 분석, 시장 동향 예측 등 다양한 지식 집약적 영역에서 인간 전문가의 능력을 보완하고 확장할 수 있습니다.

관리자와 리더(leader)들은 이러한 새로운 AI 모델(model)들을 고려하여 AI가 무엇을 할 수 있는지, 그리고 얼마나 잘 할 수 있는지에 대한 인식을 갱신해야 할 필요가 있습니다. AI가 단순한 하위 작업만을 처리할 수 있다고 추정하기보다, AI가 진정한 지적 협력자(intellectual partner)로서 기능할 수 있는 방안을 모색해야 합니다. 이 모델(model)들은 이제 놀라운 정밀성으로 복잡한 분석 업무, 창의적 활동, 심지어 연구 단계의 난제까지 처리할 수 있습니다. 제가 공유한 예시들, 즉 학술 개념의 상호작용 3D 시각화(interactive 3D visualizations) 생성부터 박사(PhD) 수준 분석 수행에 이르기까지는 우리가 단순 자동화(automation)를 넘어 인공지능 기반 지식 노동(knowledge work)의 영역으로 진입하고 있음을 입증합니다. 이러한 시스템(system)들은 여전히 완벽과는 거리가 멀고, 광범위한 작업에서 인간 전문가(human experts)를 일관되게 능가하지는 못하지만, 매우 인상적입니다. 리더들은 이러한 변화에 대한 비전을 제시하고, 조직 내에서 AI 리터러시(AI literacy)를 강화하기 위한 전략적 투자를 아끼지 않아야 할 것입니다. 또한, AI의 강력한 능력에는 윤리적 고려사항이 수반되므로, 책임감 있는 AI 개발 및 활용에 대한 명확한 지침을 마련하는 것이 중요합니다.

이러한 변화는 조직이 AI 통합(integration)에 접근하는 방식에 깊은 영향을 미칠 것입니다. 첫째, 중점은 단순 작업 자동화(task automation)에서 역량 강화(capability augmentation)로 전환되어야 합니다. "어떤 작업을 자동화할 수 있는가?"라고 묻는 대신, 리더(leader)들은 "어떤 새로운 능력을 발휘할 수 있는가?"라고 물어야 합니다. 그리고 그들은 이러한 변화를 탐색하고 개발하는 데 도움이 되도록 내부 조직 역량(capacity)을 확충해야 합니다. 이는 AI를 활용한 새로운 비즈니스 기회를 발굴하고, 직원들이 AI와 협력하여 더 높은 가치를 창출할 수 있도록 지원하는 것을 포함합니다. 둘째, 능력과 비용 효율성(cost efficiency) 모두에서 빠른 개선은 AI 구현(implementation)을 위한 어떤 정적인 전략(strategy)도 신속하게 시대에 뒤떨어질 것임을 뜻합니다. 조직은 이러한 모델(model)들이 계속 발전함에 따라 진화할 수 있는 유연한 접근 방식(dynamic approaches)을 수립해야 합니다. 두 가지 스케일링 법칙(Scaling Laws)이 모두 작동하는 세상에서 오늘날 특정 모델(model)에 올인(all-in)하는 것은 좋은 계획이 아닙니다. 지속적인 학습과 적응력을 갖춘 크로스-펑셔널 팀(cross-functional teams)을 구성하여 AI 기술의 변화를 주시하고, 최적의 솔루션을 끊임없이 탐색해야 합니다. 마지막으로, 그리고 아마도 가장 중요하게는, 우리는 AI의 기여도를 측정하고 평가하는 방식에 대해 재고해야 합니다. 절약된 시간이나 절감된 비용이라는 기존의 측정 지표(metrics)는 이러한 시스템(system)들의 더 혁신적인 영향, 즉 새로운 식견(insights)을 창출하고, 복잡한 데이터를 통합하며, 혁신적인 문제 해결(problem-solving) 양식을 가능하게 하는 역량을 간과할 수 있습니다. 너무 빨리 구체적인 핵심 성과 지표(KPIs)로 이동하고 탐색을 등한시하면 기업들은 무엇이 가능한지 보지 못하게 될 것입니다. 더 나쁜 것은, 이는 기업들이 AI를 인간 노동의 대체물로 생각하도록 장려하며, AI가 인간의 작업을 어떻게 향상시킬 수 있는지 탐색하는 대신 그렇게 만듭니다. '인간 중심(human-in-the-loop)' 접근 방식을 통해 AI가 인간의 창의성과 전문성을 증폭시키는 협업 도구로 활용될 때 진정한 잠재력이 발휘될 것입니다.

### 직접 탐색하기

이러한 중대한 경고는 잠시 뒤로하고, 한 가지 제안을 드리고 싶습니다. 이 새로운 모델(model)들은 영리하지만, 또한 사용자 친화적이며 매력도가 높습니다. 그들은 여러분에게 질문을 하거나 여러분의 생각을 새로운 방향으로 이끌 가능성이 높으며, 쌍방향 소통(two-way conversation)에 능숙한 경향을 보입니다. 따라서 그들의 역량을 파악하는 최선의 길은 직접 체험해보는 것입니다. Claude 3.7은 유료 고객(paying customers)에게 제공되며, 이 게시물에서 보셨듯이 직접 생성한 코드(code)를 실행할 수 있는 세련된 기능을 갖추고 있습니다. 이 모델은 여러분이 업로드(upload)한 데이터(data)로 훈련하지 않습니다. Grok 3는 무료이며, 훌륭한 심층 연구(Deep Research) 옵션(option)을 포함하여 더 광범위한 기능(feature)을 제공하지만, 초보자(amateurs)가 코딩(coding) 용도로 활용하기에는 다소 난이도가 있습니다. 제가 시도한 작업에서는 Claude 3.7만큼 좋지는 않지만, Xai의 스케일링(scaling)에 대한 의지는 빠르게 개선될 것임을 의미합니다. 또한 Grok은 여러분의 데이터(data)로 훈련하지만, 유료 고객(paying customers)의 경우 이 기능을 끌 수 있다는 점을 알아두세요. 모델마다 강점이 다르므로, 여러 모델을 비교하며 자신에게 맞는 것을 찾는 것이 중요합니다.

어떤 모델(model)을 선택하든, 여러분은 직접 테스트해봐야 합니다. 모델(model)에게 요청하기만 하면 무언가를 코딩(coding)해달라고 하거나(저는 Claude에게 허먼 멜빌(Herman Melville)의 소설 "필경사 바틀비(Bartleby the Scrivner)"를 기반으로 한 독창적인 게임 플레이 방식(mechanics)을 갖춘 비디오 게임(video game) 제작을 의뢰했고, 단 하나의 프롬프트(prompt)로 그렇게 했습니다), 문서(document)를 제공하고 정보 그래픽 요약(infographic summary)을 의뢰하거나, 제공한 이미지(image)에 대한 의견(comment)을 요청해 보세요. 이것이 너무 장난스럽다면, 제 책의 조언을 따르고 위에서 언급한 개인 정보 보호(privacy) 주의 사항을 고려하여 업무 작업에만 사용하세요. 새로운 아이디어(idea)를 브레인스토밍(brainstorming)하는 데 사용하거나, 뉴스 기사(news article)나 분석가 보고서(analyst report)가 여러분의 비즈니스(business)에 어떤 영향을 미칠지 물어보거나, 새로운 제품(product)이나 스타트업(startup) 개념을 위한 재무 대시보드(financial dashboard)를 만들어달라고 요청하세요. 여러분은 놀라움을 주는 사례들을 발견할 것이고, 어떤 경우에는 최신 모델(model)들이 아직은 기대만큼 유용하지 않다는 점을 발견할 수도 있습니다. 중요한 것은 반복적인 프롬프트(prompt) 입력과 결과물 개선 과정을 통해 AI와의 상호작용을 최적화하는 것입니다.

이러한 모델(model)들의 제한점은 여전히 명확하게 존재하지만, Gen3 AI가 첫 번째 및 두 번째 스케일링 법칙(Scaling Law) 모두로 인해 Gen2보다 우수하다는 사실은 우리에게 핵심적인 사실을 드러냅니다. 이러한 법칙들은 자연계의 불변하는 상수(constants)가 아니라, 방대한 자원(resources)을 AI 개발에 투자했을 때 나타나는 현상에 대한 관찰적 결론입니다. 연산 능력(computing power)은 계속 증가하고, 능력은 계속 향상되며, 이 주기는 각 세대별로 더욱 빨라집니다. 이러한 법칙들이 계속 유효한 한, AI는 계속해서 발전할 것입니다. 이제 우리는 다음 세대 AI가 계속해서 빠른 개선을 제공할 것이며, 이는 인공지능 역량이 미래에도 지속적으로 증대될 가능성이 농후함을 시사합니다. 이러한 급격한 발전 속도 속에서, 기술적 진보와 함께 책임감 있는 AI 개발과 사회적 영향에 대한 깊은 성찰이 반드시 동반되어야 할 것입니다.

구독 공유