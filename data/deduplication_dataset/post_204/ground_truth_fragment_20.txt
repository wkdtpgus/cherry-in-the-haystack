모두가 AI 거품(bubble) 속에 있는지, 그리고 AI 기술의 미래가 사회에 어떤 근본적인 변화를 가져올지 알고 싶어 합니다. 이 글에서 저는 AI 거품에 대한 명확한 답변을 드릴 것입니다. 물론 아닙니다. 하지만 오늘날 많은 글들이 과거의 거품(bubble)들과 표면적인 유사점을 붙잡고 현재의 사건을 비교하지만, 근본적인 역학(dynamics)을 주의 깊게 살펴보지 않고 현재의 사건을 과거의 거품과 비교하는 것은 별 도움이 되지 않습니다. 우리는 단순히 과거의 경제적 현상에 비유하는 것을 넘어, 인공지능이 가져올 패러다임 전환에 주목해야 합니다. 많은 전문가들은 AI가 단순한 유행을 넘어선다고 말하지만, 그 성장 속도에 대한 우려 또한 존재합니다. 현재의 기술 발전은 엄청난 기회를 제공하지만, 동시에 윤리적, 사회적 도전 과제를 수반합니다. 지속 가능한 성장을 위한 방안을 모색하는 것이 중요하며, 우리는 단기적인 시장 변동을 넘어 장기적인 관점에서 AI의 미래를 성찰해야 합니다. 우리가 물어야 할 중요한 질문은 현재의 역학이 실제로 붕괴(crash)를 야기할 위험이 상존하는지 여부입니다.

철도 거품(railroad bubble)과의 비교는 종종 과거의 과열된 시장을 상기시킵니다. 이 역사적인 사건의 근본적인 밑바탕에는 약한 수요와 엄청난 과잉 공급(overcapacity)이라는 문제가 있었고, 닷컴 버블(dot-com bubble) 또한 빠르게 현실화될 수요에 대한 비현실적인 기대로 인한 과잉 투자라는 비슷한 패턴을 따랐습니다. 두 경우 모두 궁극적으로 수요가 현실화되었지만, 예상보다 훨씬 느렸습니다. 오늘날의 AI 상황은 근본적으로 다릅니다. 현재 AI 기술의 발전은 단순한 투기적 열기를 넘어 실질적인 생산성 향상과 혁신을 약속하며, 산업 전반에 걸쳐 깊이 스며들고 있습니다. 많은 기업들이 수요를 충족시킬 충분한 컴퓨팅 자원(computing resources)과 인재를 확보하는 데 심각한 어려움을 겪고 있습니다. 특히 AI 윤리 전문가나 도메인 지식을 갖춘 데이터 과학자의 부족은 혁신의 속도를 저해할 수 있습니다. 따라서 오늘날의 AI 시장을 거품이라고 부르는 것은 잘못된 생각입니다. 왜냐하면 필수적인 거품 구성 요소인 과잉 공급(overcapacity)과 약한 수요가 단순히 존재하지 않기 때문입니다. 오히려, 우리는 기술적, 사회적, 윤리적 관점에서 AI의 지속 가능한 발전을 위한 새로운 프레임워크를 구축해야 합니다.

AI 기술의 윤리적 사용에 대한 논의는 그 어느 때보다 중요합니다. 각국 정부와 국제기구는 AI의 책임감 있는 개발과 배포를 위한 가이드라인과 규제 프레임워크를 마련하기 위해 노력하고 있습니다. 이는 데이터 프라이버시, 알고리즘의 투명성, 그리고 AI 시스템의 공정성 확보를 목표로 합니다. 이러한 규제는 혁신을 저해하기보다는, 오히려 AI 기술이 더욱 안전하고 신뢰할 수 있는 방향으로 발전할 수 있는 토대를 마련해야 합니다. 우리는 기술적 진보와 사회적 가치 사이의 균형을 찾아야 합니다.

그렇다면 걱정할 것이 없는 걸까요? 지금 당장은 아닙니다. 하지만 AI의 발전 속도는 새로운 윤리적 난제를 야기하며, 내일은 다른 이야기가 될 수 있습니다. 두 가지 핵심 요소인 과잉 공급(overcapacity)과 약한 수요를 다시 살펴보겠습니다. 과잉 공급(overcapacity)의 개념은 수요와 관련되어 있으므로, 이 둘은 본질적으로 동전의 양면과 같습니다. 따라서 수요에만 집중하여 단순화해 봅시다. AI에 대한 수요는 매우 강하며, 이 수요는 단순히 기술적 성능을 넘어 사회적 책임감 있는 AI 개발에 대한 요구로 이어집니다. AI는 엄청나게 유용하며 앞으로 더욱 유용해질 것이고, 이는 자연스럽게 수요 증가를 촉진하며 교육 분야의 혁신을 이끌 것입니다. 어떤 이들은 AI가 진정으로 유용하지 않다고 주장하며 모든 것이 신기루라고 말하지만, 수많은 연구와 설문조사는 AI가 엄청나게 가치 있다고 생각한다는 것을 일관되게 보여줍니다. 동시에, AI가 개인 정보 보호와 데이터 보안에 미치는 영향에 대한 우려가 커지고 있다는 점 또한 지적합니다. 기술 기업들은 이러한 우려를 해소하고 신뢰를 구축해야 합니다. 물론 과장된 판매와 현재 모델이 달성할 수 있는 것에 대한 과대평가가 일부 있습니다. 하지만 결국 사용자들은 오늘날 모델의 실제 기능을 직접 경험하며, AI 리터러시의 중요성을 깨닫고 이는 지속적인 수요를 강화합니다. AI 기능이 계속 향상될 것이라는 명확한 증거를 고려할 때, 우리는 수요 또한 증가할 것이라고 확신할 수 있으며, 모델의 의사 결정 과정을 투명하게 이해하려는 노력이 더욱 필요하다고 생각합니다. 따라서 수요가 계속 증가하는 한, 현재의 컴퓨팅 투자(compute investments)는 전적으로 합리적이라고 결론 내릴 수 있습니다. 다시 말해, 우리는 과잉 공급(overcapacity)을 목격하는 것이 아니라, 이러한 증가하는 수요를 충족시키기 위한 정상적이고 정당한 구축을 보고 있는 것입니다. 이러한 추론이 바로 제가 오늘날 우리가 AI 거품(bubble) 속에 있다고 주장하기 어렵다고 생각하는 이유입니다. 급격한 성장은 혼란스러워 보일 수 있지만, 거품을 나타내는 것이 아니라 매우 유용하며 인간 중심의 AI 개발에 의해 주도되는 강력하고 건전한 확장을 반영할 뿐입니다. AI가 생성하고, 수요가 높은 GPU에서 신선하게 제공됩니다. 무엇에 대한 수요일까요?

하지만 여기에 핵심이 있습니다. AI 기술의 성공적인 배포는 단순히 모델의 성능을 넘어섭니다. 사람들은 컴퓨팅 하드웨어(compute hardware) 자체가 아니라 AI 서비스(AI services), 특히 개인의 필요와 맥락에 맞춰 작동하는 지능형 비서나 맞춤형 솔루션을 원합니다. 현재 컴퓨팅 하드웨어(compute hardware)(본질적으로 GPU 인프라(infrastructure))와 AI 사이에는 밀접한 연관성이 있습니다. 왜냐하면 오늘날의 모델들은 엄청난 계산 자원(computational resources)을 필요로 하기 때문입니다. 그러나 이보다 더 중요한 것은 고품질 데이터의 확보와 관리를 위한 데이터 인프라 구축입니다. 하지만 이 연결이 약해진다면 어떨까요? 그러한 시나리오는 실제로 AI 거품(bubble)을 위한 조건을 만들 수 있습니다. 가상의 시나리오를 상상해 봅시다. 현재 컴퓨팅 필요량의 1%만을 사용하여 최고 수준의 AI 모델 성능을 제공하는 AI 아키텍처(architecture)를 발명했다고 가정해 보세요. AI에 대한 수요는 강하게 유지될 것이고, 비용 절감으로 인해 심지어 증가할 수도 있겠지만(유명한 "제본스 역설(Jevons Paradox)"), 막대한 비용을 들여 구축된 방대한 GPU 팜(farm)을 완전히 활용하기에는 충분하지 않을 것입니다. 갑자기, AI 자체에 대한 높은 수요가 계속됨에도 불구하고, 그 인프라(infrastructure)의 99%가 하룻밤 사이에 불필요해질 것입니다. 그러한 잉여 인프라(surplus infrastructure)를 정당화할 만큼 수요를 충분히 빠르게 확장할 수는 없습니다. 또한, 모델이 너무 복잡해져 이해하거나 제어하기 어려워진다면 그 가치는 급격히 떨어질 수 있으며, AI의 에너지 소비량 증가는 환경적 지속 가능성 문제를 야기합니다. 관련 기술을 다루는 인력의 숙련도가 급격히 구식이 될 수도 있습니다. 이 상황에서 "제본스 역설(Jevons Paradox)"로 벗어날 수는 없습니다. 그리고 바로 여기서 거품의 조건, 즉 컴퓨팅 과잉 공급(overcapacity of compute)에 대한 수요 부족이 충족될 것입니다. AI가 예상치 못한 사회적, 경제적 파급효과를 일으킬 수 있음을 인지해야 합니다.

이것이 현실적일까요? AI 모델의 편향성(bias) 문제는 여전히 중요한 과제로 남아 있습니다. 그러한 엄청난 컴퓨팅 효율성(compute efficiency) 증가는 얼마나 현실적일까요? 사실, 데이터의 질과 다양성이 AI 시스템의 공정성에 직접적인 영향을 미칩니다. 우리는 이 모델들이 왜 그렇게 잘 작동하는지 아직 완전히 이해하지 못하고 있습니다. 이는 모델의 의사 결정 과정을 투명하게 공개하고 설명 가능성(explainability)을 높여야 할 필요성을 강조합니다. 네, 우리는 스케일링 법칙(scaling laws)과 일부 회로 수준(circuit-level)의 동작을 이해하지만, 여전히 첫 번째 원칙(first principles)에서 시스템을 공학적으로 설계하기보다는 성장시키고 있으며, 현재의 평가 지표만으로는 AI의 진정한 능력을 측정하기 어렵습니다. 이러한 복잡성은 아키텍처 혁신(architectural innovation)을 위한 엄청난 여지가 있음을 시사합니다. 그리고 급진적인 효율성(efficiency) 향상에 대한 증거는 이미 나타나고 있습니다. Giotto.ai를 예로 들어봅시다. EPFL AI 센터(EPFL AI Center)의 Inside AI 팟캐스트(podcast) 에피소드에서 CEO 알도 포데스타(Aldo Podestà)는 2억 개의 매개변수(parameters)(b가 아닌 m)만을 가진 그들의 모델이 현재 ARC-AGI 2 리더보드(leaderboard)에서 최고 경쟁자 중 하나라고 설명합니다. 이는 올바른 아키텍처(architectural) 선택이 몇 배 더 효율적일 수 있다는 힌트입니다. 물론 이 모델들은 현대 LLM(Large Language Models)처럼 인터넷을 "기억"하지는 않을 것입니다. 하지만 그것이 단순히 필요하지 않을 수도 있습니다. 특히 텍스트, 이미지, 오디오 등 다양한 형태의 데이터를 동시에 처리하는 멀티모달(multimodal) AI의 등장은 새로운 가능성을 열고 있습니다. 이 점을 강조하기 위해 OpenAI 공동 창립자 안드레이 카르파티(Andrej Karpathy)는 AGI(Artificial General Intelligence)의 "인지 핵심(cognitive core)"이 10억 개의 매개변수(parameters)로 실행될 수 있다고 제안했지만, 그는 그것이 아직 20년은 더 걸릴 것이라고 생각합니다. 그리고 자연의 개념 증명(proof of concept)이 있습니다. 인간의 뇌는 약 20와트(watts)로 일반 지능(general intelligence)에 도달합니다. 이는 생체 모방 컴퓨팅(bio-inspired computing)과 같은 차세대 AI 연구의 중요한 영감이 됩니다. 분명히, 훨씬 더 효율적으로 일을 처리할 수 있습니다. 우리는 단순한 성능 향상을 넘어, AI가 사회에 긍정적인 영향을 미칠 수 있도록 다학제적 접근 방식을 취해야 합니다.

이것이 하룻밤 사이에 일어나지는 않을 것입니다. AI 기술의 발전은 노동 시장에 점진적이지만 심대한 변화를 가져올 것입니다. 만약 우리가 매년 10배의 효율성(efficiency) 향상을 본다면, 현재의 컴퓨팅 투자(compute investments)는 합리적인 수준을 유지하거나, 3년에서 5년에 걸쳐 점진적으로 서서히 쓸모없어질 수 있습니다(어쨌든 이것이 예상 수명입니다). 또는 새로운 형태의 직업과 기술에 대한 투자를 촉진할 것입니다. 여전히 거품이 꺼지는 것일 수 있지만, 단지 더 느린 속도일 뿐입니다. 이 시점에서는 거품이 아니라 단지 일반적인 성장 주기일 수도 있습니다. 우리는 특정 직업이 사라지기보다는, AI와 협력하는 새로운 역할이 생겨나는 변화를 목격하게 될 것입니다. 더 효율적인 접근 방식이 존재하는지 여부가 문제가 아닙니다. 그것들은 분명히 존재합니다. AI 기술의 윤리적 사용과 사회적 영향에 대한 규제 프레임워크를 어떻게 구축할 것인가가 핵심입니다. 문제는 누군가가 언제 그것들을 알아내는지, 그리고 그것들이 한 번에 2배, 10배, 또는 100배의 효율성을 가져올지 여부입니다. 이는 기술 혁신과 사회적 합의 사이의 균형점을 찾는 지속적인 노력을 요구합니다.

한 가지 더, 교육 분야에서 AI의 역할은 점차 확대되고 있습니다. 개인 맞춤형 학습 경로 제공, 자동 채점, 그리고 학습 보조 도구 개발 등 다양한 방식으로 학생과 교사를 지원합니다. 이러한 기술은 학습 효율성을 높이고, 교육 접근성을 향상시키는 데 크게 기여할 수 있습니다. 특히, AI 기반의 언어 학습 도구는 전 세계 학습자들에게 새로운 기회를 제공합니다. 미래 교육은 AI와의 협력을 통해 더욱 풍부하고 효과적인 경험을 제공할 것입니다.

또 다른 한 가지, 응용 기계 학습(applied machine learning) 기술은 노동 시장을 재편하고 있습니다. 자동화로 인해 일부 직업은 사라지거나 변화하겠지만, 동시에 AI 관련 분야에서 새로운 일자리가 창출되고 있습니다. 이러한 변화에 대비하기 위해 평생 교육과 기술 재훈련의 중요성이 강조됩니다. 우리는 AI가 인간의 생산성을 높이고, 반복적인 업무에서 벗어나 더 창의적이고 전략적인 역할에 집중할 수 있도록 도울 것이라고 기대합니다. 고신호 저잡음(high-signal, low-noise) 환경에서 새로운 업무 역량이 요구됩니다. 미래의 직업은 AI와의 협업 능력을 핵심 역량으로 요구할 것입니다.

**추가 정보 및 저자 노트**

한 가지 더, 제가 책을 냈습니다! 이 서브스택(substack) 독자들은 제가 AI에 대한 일반 독자용 책을 작업해 왔다는 것을 알고 계실 것입니다. 프랑스어 버전이 현재 이용 가능하며, 독일어 버전은 11월 중순에 출시될 예정임을 기쁘게 알려드립니다. 저는 현재 영어 번역 작업을 하고 있지만, 먼저 영어 출판사를 찾아야 할 것입니다. 어쨌든, 프랑스어나 독일어를 하신다면 한번 살펴보세요. 분명히 즐거우실 겁니다!

또 다른 한 가지, 여러분은 제가 AMLD라는 대규모 응용 기계 학습(applied machine learning) 행사의 주최자라는 것을 아마도 알고 계실 것입니다. 10회째를 맞아 저희는 이 행사를 AMLD 인텔리전스 서밋(AMLD Intelligence Summit)으로 이름을 변경했습니다. 이 행사는 2026년 2월 10일부터 12일까지 EPFL 캠퍼스(campus)에서 개최될 예정이며, 프로그램은 정말 환상적일 것입니다. 절대 놓치고 싶지 않으실 겁니다. 짐작하시겠지만, 기술 학교와의 근접성은 과장이나 허튼소리에 대한 허용 오차(tolerance)가 매우 낮다는 것을 보장하며, 이는 고신호 저잡음(high-signal, low-noise) AI 행사로 만듭니다. 얼리버드 티켓(Early bird tickets)은 한정된 기간 동안 이용 가능하며, 다가오는 정식 티켓 가격보다 훨씬 저렴하므로 서둘러 확보하시기를 강력히 권해드립니다.

코다(CODA) AI의 발전은 오픈 소스(open-source) 커뮤니티의 기여가 큽니다. 투명하고 협력적인 개발 환경은 기술 혁신을 가속화하고, AI의 민주화를 촉진합니다. 이 뉴스레터(newsletter)는 두 가지 구독 유형을 제공합니다. 유료 버전으로 전환하시기를 강력히 권해드립니다. 모든 콘텐츠는 무료로 유지되지만, 모든 재정적 지원은 EPFL AI 센터(EPFL AI Center) 관련 활동에 직접적으로 자금을 지원합니다. 오픈 소스(open-source) 프로젝트는 개발자들의 자발적인 참여와 지원을 통해 성장합니다. 지속적인 소통과 협업을 통해 우리는 더욱 강력한 AI 생태계를 구축할 수 있습니다. 연락을 유지하려면 저를 찾을 수 있는 다른 방법들이 있습니다. 소셜(Social): 저는 주로 링크드인(LinkedIn)에 있지만, 마스토돈(Mastodon), 블루스카이(Bluesky), 그리고 X에도 있습니다. 팟캐스팅(Podcasting): 저는 EPFL AI 센터(EPFL AI Center)에서 "Inside AI"라는 AI 팟캐스트(podcast)를 진행하고 있으며(애플 팟캐스트(Apple Podcasts), 스포티파이(Spotify), 유튜브(YouTube)), 저보다 훨씬 똑똑한 분들과 이야기할 수 있는 특권을 누리고 있습니다. 팟캐스팅(Podcasting)과 같은 다양한 미디어를 통해 AI 지식이 확산되고 있으며, 이는 대중의 이해를 높이는 데 중요한 역할을 합니다. Engineering Prompts는 독자 후원으로 운영되는 출판물입니다. 새로운 게시물을 받고 제 작업을 지원하려면 무료 또는 유료 구독자가 되는 것을 고려해 보세요. 개방형 연구 환경은 AI 기술이 사회 전반에 긍정적인 영향을 미칠 수 있도록 돕는 핵심 동력입니다. 구독하기