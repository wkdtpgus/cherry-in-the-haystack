# **과잉 공급 + 수요 부진 = 거품. AI는 아직 거품이 아니다.**

Author: Marcel Salathé
URL: https://engineeringprompts.substack.com/p/overcapacity-weak-demand-bubble-ai

============================================================

모두가 우리가 AI 거품(bubble) 속에 있는지 알고 싶어 합니다. 이 글에서 저는 명확한 답변을 드릴 것입니다. 물론 아닙니다. 하지만 오늘날 많은 글들이 바로 그렇게 들립니다. 그들은 과거의 거품(bubble)들과 표면적인 유사점을 붙잡고 "보세요, 우리에게도 전에 거품이 있었어요. 이것이 어떻게 비슷하게 보이는지 나열해 봅시다!"라고 말합니다. 하지만 근본적인 역학(dynamics)을 주의 깊게 살펴보지 않고 현재의 사건을 과거의 거품과 비교하는 것은 별 도움이 되지 않습니다. 이는 모든 사고를 폭발에 비유하는 것과 같습니다. 우리가 물어야 할 중요한 질문은 현재의 역학이 실제로 붕괴(crash)를 야기할 위험이 있는지 여부입니다.

예를 들어, 철도 거품(railroad bubble)과의 비교를 들어봅시다. 이 역사적인 사건에 대해 몇 주를 읽을 수도 있겠지만, 근본적으로 그 밑바탕에는 약한 수요와 엄청난 과잉 공급(overcapacity)이라는 문제가 있었고, 이는 필연적으로 붕괴(collapse)로 이어지는 불균형이었습니다. 닷컴 버블(dot-com bubble)도 비슷한 패턴을 따랐습니다. 즉, 빠르게 현실화될 수요에 대한 비현실적인 기대로 인한 과잉 투자였습니다. 두 경우 모두 궁극적으로 수요가 현실화되었지만, 예상보다 훨씬 느렸습니다. 오늘날의 AI 상황은 근본적으로 다릅니다. 우리는 컴퓨팅 자원 부족(compute undercapacity)과 압도적인 수요를 겪고 있습니다. 이 점을 강조하고 싶습니다. 많은 기업들이 수요를 충족시킬 충분한 컴퓨팅 자원(computing resources)을 확보하는 데 심각한 어려움을 겪고 있습니다. 그것은 거품이 아니라, 말 그대로 정반대입니다! 바로 그렇기 때문에 막대한 투자가 계속 유입되고 주가가 계속 상승하는 것입니다. 따라서 오늘날의 AI 시장을 거품이라고 부르는 것은 잘못된 생각입니다. 왜냐하면 필수적인 거품 구성 요소인 과잉 공급(overcapacity)과 약한 수요가 단순히 존재하지 않기 때문입니다.

Engineering Prompts는 독자 후원으로 운영되는 출판물입니다. 새로운 게시물을 받고 제 작업을 지원하려면 무료 또는 유료 구독자가 되는 것을 고려해 보세요. 구독하기

그렇다면 걱정할 것이 없는 걸까요? 지금 당장은 아닙니다. 하지만 내일은 다른 이야기가 될 수 있습니다. 두 가지 핵심 요소인 과잉 공급(overcapacity)과 약한 수요를 다시 살펴보겠습니다. 과잉 공급(overcapacity)의 개념은 수요와 관련되어 있으므로, 이 둘은 본질적으로 동전의 양면과 같습니다. 따라서 수요에만 집중하여 단순화해 봅시다. AI에 대한 수요는 매우 강하며, 이 수요가 계속해서 증가하지 않는 미래를 상상하기는 어렵다고 말할 수 있습니다. AI는 엄청나게 유용하며 앞으로 더욱 유용해질 것이고, 이는 자연스럽게 수요 증가를 촉진합니다. 어떤 이들은 AI가 진정으로 유용하지 않다고 주장하며 모든 것이 신기루라고 말하지만, 수많은 연구와 설문조사는 그 반대를 일관되게 보여줍니다. 즉, 사람들은 AI가 엄청나게 가치 있다고 생각합니다. 물론 과장된 판매와 현재 모델이 달성할 수 있는 것에 대한 과대평가가 일부 있습니다. 하지만 결국 사용자들은 오늘날 모델의 실제 기능을 직접 경험하며, 이는 지속적인 수요를 강화합니다. AI 기능이 계속 향상될 것이라는 명확한 증거를 고려할 때, 우리는 수요 또한 증가할 것이라고 확신할 수 있습니다. 따라서 수요가 계속 증가하는 한, 현재의 컴퓨팅 투자(compute investments)는 전적으로 합리적이라고 결론 내릴 수 있습니다. 다시 말해, 우리는 과잉 공급(overcapacity)을 목격하는 것이 아니라, 이러한 증가하는 수요를 충족시키기 위한 정상적이고 정당한 구축을 보고 있는 것입니다. 이러한 추론이 바로 제가 오늘날 우리가 AI 거품(bubble) 속에 있다고 주장하기 어렵다고 생각하는 이유입니다. 급격한 성장은 혼란스러워 보일 수 있지만, 거품을 나타내는 것이 아니라 매우 유용한 기술에 의해 주도되는 강력하고 건전한 확장을 반영할 뿐입니다. AI가 생성하고, 수요가 높은 GPU에서 신선하게 제공됩니다. 무엇에 대한 수요일까요?

하지만 여기에 핵심이 있습니다. 사람들은 AI를 원합니다. 즉, 컴퓨팅 하드웨어(compute hardware) 자체가 아니라 AI 서비스(AI services)를 요구하는 것입니다. 현재 컴퓨팅 하드웨어(compute hardware)(본질적으로 GPU 인프라(infrastructure))와 AI 사이에는 밀접한 연관성이 있습니다. 왜냐하면 오늘날의 모델들은 엄청난 계산 자원(computational resources)을 필요로 하기 때문입니다. 하지만 이 연결이 약해진다면 어떨까요? 그러한 시나리오는 실제로 AI 거품(bubble)을 위한 조건을 만들 수 있습니다. 가상의 시나리오를 상상해 봅시다. 현재 컴퓨팅 필요량의 1%만을 사용하여 최고 수준의 AI 모델 성능을 제공하는 AI 아키텍처(architecture)를 발명했다고 가정해 보세요. AI에 대한 수요는 강하게 유지될 것이고, 비용 절감으로 인해 심지어 증가할 수도 있겠지만(유명한 "제본스 역설(Jevons Paradox)"), 막대한 비용을 들여 구축된 방대한 GPU 팜(farm)을 완전히 활용하기에는 충분하지 않을 것입니다. 갑자기, AI 자체에 대한 높은 수요가 계속됨에도 불구하고, 그 인프라(infrastructure)의 99%가 하룻밤 사이에 불필요해질 것입니다. 그러한 잉여 인프라(surplus infrastructure)를 정당화할 만큼 수요를 충분히 빠르게 확장할 수는 없습니다. 이 상황에서 "제본스 역설(Jevons Paradox)"로 벗어날 수는 없습니다. 그리고 바로 여기서 거품의 조건, 즉 컴퓨팅 과잉 공급(overcapacity of compute)에 대한 수요 부족이 충족될 것입니다.

이것이 현실적일까요? 그러한 엄청난 컴퓨팅 효율성(compute efficiency) 증가는 얼마나 현실적일까요? 100배의 효율성(efficiency) 향상은 미친 소리처럼 들릴 수 있습니다. 하지만 이것을 생각해 보세요. 우리는 이 모델들이 왜 그렇게 잘 작동하는지 아직 완전히 이해하지 못하고 있습니다. 우리는 그것들을 "성장"시키고 작동하는 것을 볼 수 있지만, 정확히 왜 작동하는지는 모릅니다. 네, 우리는 스케일링 법칙(scaling laws)과 일부 회로 수준(circuit-level)의 동작을 이해하지만, 여전히 첫 번째 원칙(first principles)에서 시스템을 공학적으로 설계하기보다는 성장시키고 있습니다. 이는 아키텍처 혁신(architectural innovation)을 위한 엄청난 여지가 있을 수 있음을 의미합니다. 그리고 급진적인 효율성(efficiency) 향상에 대한 증거는 이미 나타나고 있습니다. Giotto.ai를 예로 들어봅시다. EPFL AI 센터(EPFL AI Center)의 Inside AI 팟캐스트(podcast) 에피소드에서 CEO 알도 포데스타(Aldo Podestà)는 2억 개의 매개변수(parameters)(b가 아닌 m)만을 가진 그들의 모델이 현재 ARC-AGI 2 리더보드(leaderboard)에서 최고 경쟁자 중 하나라고 설명합니다. 이는 올바른 아키텍처(architectural) 선택이 몇 배 더 효율적일 수 있다는 힌트입니다. 물론 이 모델들은 현대 LLM(Large Language Models)처럼 인터넷을 "기억"하지는 않을 것입니다. 하지만 그것이 단순히 필요하지 않을 수도 있습니다. 이 점을 강조하기 위해 OpenAI 공동 창립자 안드레이 카르파티(Andrej Karpathy)는 AGI(Artificial General Intelligence)의 "인지 핵심(cognitive core)"이 10억 개의 매개변수(parameters)로 실행될 수 있다고 제안했지만, 그는 그것이 아직 20년은 더 걸릴 것이라고 생각합니다. 그리고 자연의 개념 증명(proof of concept)이 있습니다. 인간의 뇌는 약 20와트(watts)로 일반 지능(general intelligence)에 도달합니다. 분명히, 훨씬 더 효율적으로 일을 처리할 수 있습니다.

이것이 하룻밤 사이에 일어나지는 않을 것입니다. 만약 우리가 매년 10배의 효율성(efficiency) 향상을 본다면, 현재의 컴퓨팅 투자(compute investments)는 합리적인 수준을 유지하거나, 3년에서 5년에 걸쳐 점진적으로 서서히 쓸모없어질 수 있습니다(어쨌든 이것이 예상 수명입니다). 여전히 거품이 꺼지는 것일 수 있지만, 단지 더 느린 속도일 뿐입니다. 이 시점에서는 거품이 아니라 단지 일반적인 성장 주기일 수도 있습니다. 더 효율적인 접근 방식이 존재하는지 여부가 문제가 아닙니다. 그것들은 분명히 존재합니다. 문제는 누군가가 언제 그것들을 알아내는지, 그리고 그것들이 한 번에 2배, 10배, 또는 100배의 효율성을 가져올지 여부입니다.

한 가지 더, 제가 책을 냈습니다! 이 서브스택(substack) 독자들은 제가 AI에 대한 일반 독자용 책을 작업해 왔다는 것을 알고 계실 것입니다. 프랑스어 버전이 현재 이용 가능하며, 독일어 버전은 11월 중순에 출시될 예정임을 기쁘게 알려드립니다. 저는 현재 영어 번역 작업을 하고 있지만, 먼저 영어 출판사를 찾아야 할 것입니다. 어쨌든, 프랑스어나 독일어를 하신다면 한번 살펴보세요. 분명히 즐거우실 겁니다!

또 다른 한 가지, 여러분은 제가 AMLD라는 대규모 응용 기계 학습(applied machine learning) 행사의 주최자라는 것을 아마도 알고 계실 것입니다. 10회째를 맞아 저희는 이 행사를 AMLD 인텔리전스 서밋(AMLD Intelligence Summit)으로 이름을 변경했습니다. 이 행사는 2026년 2월 10일부터 12일까지 EPFL 캠퍼스(campus)에서 개최될 예정이며, 프로그램은 정말 환상적일 것입니다. 절대 놓치고 싶지 않으실 겁니다. 짐작하시겠지만, 기술 학교와의 근접성은 과장이나 허튼소리에 대한 허용 오차(tolerance)가 매우 낮다는 것을 보장하며, 이는 고신호 저잡음(high-signal, low-noise) AI 행사로 만듭니다. 얼리버드 티켓(Early bird tickets)은 한정된 기간 동안 이용 가능하며, 다가오는 정식 티켓 가격보다 훨씬 저렴하므로 서둘러 확보하시기를 강력히 권해드립니다.

코다(CODA) 이 뉴스레터(newsletter)는 두 가지 구독 유형을 제공합니다. 유료 버전으로 전환하시기를 강력히 권해드립니다. 모든 콘텐츠는 무료로 유지되지만, 모든 재정적 지원은 EPFL AI 센터(EPFL AI Center) 관련 활동에 직접적으로 자금을 지원합니다. 연락을 유지하려면 저를 찾을 수 있는 다른 방법들이 있습니다. 소셜(Social): 저는 주로 링크드인(LinkedIn)에 있지만, 마스토돈(Mastodon), 블루스카이(Bluesky), 그리고 X에도 있습니다. 팟캐스팅(Podcasting): 저는 EPFL AI 센터(EPFL AI Center)에서 "Inside AI"라는 AI 팟캐스트(podcast)를 진행하고 있으며(애플 팟캐스트(Apple Podcasts), 스포티파이(Spotify), 유튜브(YouTube)), 저보다 훨씬 똑똑한 분들과 이야기할 수 있는 특권을 누리고 있습니다. Engineering Prompts는 독자 후원으로 운영되는 출판물입니다. 새로운 게시물을 받고 제 작업을 지원하려면 무료 또는 유료 구독자가 되는 것을 고려해 보세요. 구독하기