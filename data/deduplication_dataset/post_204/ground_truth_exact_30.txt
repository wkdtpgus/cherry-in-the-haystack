## AI 거품 논쟁: 현재의 역학과 미래의 시나리오

최근 몇 년간 인공지능(AI) 분야는 전례 없는 성장과 투자를 경험하며 많은 이들의 이목을 집중시키고 있습니다. 이로 인해 'AI 거품'이라는 용어가 자주 언급되며, 과연 현재의 열기가 지속 가능한지에 대한 논쟁이 뜨겁습니다. 본 글에서는 이러한 거품론에 대한 명확한 분석과 함께, AI 시장의 현재 역학 그리고 미래에 발생할 수 있는 잠재적 변화 시나리오를 심층적으로 다루고자 합니다. 단순히 과거의 사례에 비추어 현상을 판단하기보다는, AI 기술의 본질적인 특성과 시장의 구조적 요인을 고려하여 보다 현실적인 전망을 제시할 것입니다.

모두가 우리가 AI 거품(bubble) 속에 있는지 알고 싶어 합니다. 이 글에서 저는 명확한 답변을 드릴 것입니다. 물론 아닙니다. 하지만 오늘날 많은 글들이 바로 그렇게 들립니다. 그들은 과거의 거품(bubble)들과 표면적인 유사점을 붙잡고 "보세요, 우리에게도 전에 거품이 있었어요. 이것이 어떻게 비슷하게 보이는지 나열해 봅시다!"라고 말합니다. 하지만 근본적인 역학(dynamics)을 주의 깊게 살펴보지 않고 현재의 사건을 과거의 거품과 비교하는 것은 별 도움이 되지 않습니다. 이는 모든 사고를 폭발에 비유하는 것과 같습니다. 우리가 물어야 할 중요한 질문은 현재의 역학이 실제로 붕괴(crash)를 야기할 위험이 있는지 여부입니다.

예를 들어, 철도 거품(railroad bubble)과의 비교를 들어봅시다. 이 역사적인 사건에 대해 몇 주를 읽을 수도 있겠지만, 근본적으로 그 밑바탕에는 약한 수요와 엄청난 과잉 공급(overcapacity)이라는 문제가 있었고, 이는 필연적으로 붕괴(collapse)로 이어지는 불균형이었습니다. 닷컴 버블(dot-com bubble)도 비슷한 패턴을 따랐습니다. 즉, 빠르게 현실화될 수요에 대한 비현실적인 기대로 인한 과잉 투자였습니다. 두 경우 모두 궁극적으로 수요가 현실화되었지만, 예상보다 훨씬 느렸습니다. 오늘날의 AI 상황은 근본적으로 다릅니다. 우리는 컴퓨팅 자원 부족(compute undercapacity)과 압도적인 수요를 겪고 있습니다. 이 점을 강조하고 싶습니다. 많은 기업들이 수요를 충족시킬 충분한 컴퓨팅 자원(computing resources)을 확보하는 데 심각한 어려움을 겪고 있습니다. 그것은 거품이 아니라, 말 그대로 정반대입니다! 바로 그렇기 때문에 막대한 투자가 계속 유입되고 주가가 계속 상승하는 것입니다. 따라서 오늘날의 AI 시장을 거품이라고 부르는 것은 잘못된 생각입니다. 왜냐하면 필수적인 거품 구성 요소인 과잉 공급(overcapacity)과 약한 수요가 단순히 존재하지 않기 때문입니다.

### 현재의 컴퓨팅 자원 부족 심화와 수요의 다각화

현재 AI 시장의 핵심은 '컴퓨팅 자원 부족'에 있습니다. 특히 최첨단 AI 모델 훈련 및 추론에 필수적인 고성능 GPU(그래픽 처리 장치)는 품귀 현상을 겪고 있으며, NVIDIA와 같은 주요 공급업체는 폭발적인 수요를 감당하기 위해 생산 능력을 최대한으로 끌어올리고 있습니다. 고대역폭 메모리(HBM)와 같은 핵심 부품 역시 공급망 병목 현상을 겪으며 가격 상승을 부추기고 있습니다. 마이크로소프트, 구글, 아마존 등 주요 클라우드 서비스 제공업체(하이퍼스케일러)들은 수십억 달러를 투자하여 AI 인프라를 확장하고 있지만, 여전히 수요를 따라잡기에는 역부족입니다. 이러한 투자 경쟁은 단순한 기업의 이윤 추구를 넘어 국가적 차원의 기술 패권 경쟁으로까지 확대되고 있습니다.

AI에 대한 수요는 매우 광범위하고 다각적입니다. 엔터프라이즈 AI는 기업의 생산성 향상, 고객 서비스 자동화, 데이터 분석 등 다양한 영역에서 혁신을 주도하고 있습니다. 소비자 AI는 챗봇, 이미지 생성, 개인 비서 앱 등으로 일상생활에 깊숙이 파고들고 있으며, 그 활용 범위는 계속해서 확장되고 있습니다. 또한, GPT-4나 Llama 3와 같은 대규모 파운데이션 모델(foundation model)을 훈련하고 미세 조정(fine-tuning)하는 데 막대한 컴퓨팅 자원이 필요하며, 이들 모델을 기반으로 한 다양한 애플리케이션의 추론(inference) 부하 또한 기하급수적으로 증가하고 있습니다. 이러한 복합적인 수요는 현재의 컴퓨팅 자원 부족을 더욱 심화시키고 있으며, 이는 거품의 전형적인 특징인 '약한 수요'와는 거리가 니다.

그렇다면 걱정할 것이 없는 걸까요? 지금 당장은 아닙니다. 하지만 내일은 다른 이야기가 될 수 있습니다. 두 가지 핵심 요소인 과잉 공급(overcapacity)과 약한 수요를 다시 살펴보겠습니다. 과잉 공급(overcapacity)의 개념은 수요와 관련되어 있으므로, 이 둘은 본질적으로 동전의 양면과 같습니다. 따라서 수요에만 집중하여 단순화해 봅시다. AI에 대한 수요는 매우 강하며, 이 수요가 계속해서 증가하지 않는 미래를 상상하기는 어렵다고 말할 수 있습니다. AI는 엄청나게 유용하며 앞으로 더욱 유용해질 것이고, 이는 자연스럽게 수요 증가를 촉진합니다. 어떤 이들은 AI가 진정으로 유용하지 않다고 주장하며 모든 것이 신기루라고 말하지만, 수많은 연구와 설문조사는 그 반대를 일관되게 보여줍니다. 즉, 사람들은 AI가 엄청나게 가치 있다고 생각합니다. 물론 과장된 판매와 현재 모델이 달성할 수 있는 것에 대한 과대평가가 일부 있습니다. 하지만 결국 사용자들은 오늘날 모델의 실제 기능을 직접 경험하며, 이는 지속적인 수요를 강화합니다. AI 기능이 계속 향상될 것이라는 명확한 증거를 고려할 때, 우리는 수요 또한 증가할 것이라고 확신할 수 있습니다. 따라서 수요가 계속 증가하는 한, 현재의 컴퓨팅 투자(compute investments)는 전적으로 합리적이라고 결론 내릴 수 있습니다. 다시 말해, 우리는 과잉 공급(overcapacity)을 목격하는 것이 아니라, 이러한 증가하는 수요를 충족시키기 위한 정상적이고 정당한 구축을 보고 있는 것입니다. 이러한 추론이 바로 제가 오늘날 우리가 AI 거품(bubble) 속에 있다고 주장하기 어렵다고 생각하는 이유입니다. 급격한 성장은 혼란스러워 보일 수 있지만, 거품을 나타내는 것이 아니라 매우 유용한 기술에 의해 주도되는 강력하고 건전한 확장을 반영할 뿐입니다. AI가 생성하고, 수요가 높은 GPU에서 신선하게 제공됩니다. 무엇에 대한 수요일까요?

### 기술 혁신이 가져올 미래의 불확실성

하지만 현재의 강력한 수요와 컴퓨팅 부족 현상이 영원히 지속될 것이라고 단정할 수는 없습니다. 기술의 발전 속도는 예측 불가능하며, 미래의 혁신이 현재의 시장 역학을 뒤흔들 수 있는 잠재력을 가지고 있습니다. 특히, AI 모델의 효율성 향상은 현재의 인프라 수요를 급격히 변화시킬 수 있는 가장 중요한 변수 중 하나입니다.

하지만 여기에 핵심이 있습니다. 사람들은 AI를 원합니다. 즉, 컴퓨팅 하드웨어(compute hardware) 자체가 아니라 AI 서비스(AI services)를 요구하는 것입니다. 현재 컴퓨팅 하드웨어(compute hardware)(본질적으로 GPU 인프라(infrastructure))와 AI 사이에는 밀접한 연관성이 있습니다. 왜냐하면 오늘날의 모델들은 엄청난 계산 자원(computational resources)을 필요로 하기 때문입니다. 하지만 이 연결이 약해진다면 어떨까요? 그러한 시나리오는 실제로 AI 거품(bubble)을 위한 조건을 만들 수 있습니다. 가상의 시나리오를 상상해 봅시다. 현재 컴퓨팅 필요량의 1%만을 사용하여 최고 수준의 AI 모델 성능을 제공하는 AI 아키텍처(architecture)를 발명했다고 가정해 보세요. AI에 대한 수요는 강하게 유지될 것이고, 비용 절감으로 인해 심지어 증가할 수도 있겠지만(유명한 "제본스 역설(Jevons Paradox)"), 막대한 비용을 들여 구축된 방대한 GPU 팜(farm)을 완전히 활용하기에는 충분하지 않을 것입니다. 갑자기, AI 자체에 대한 높은 수요가 계속됨에도 불구하고, 그 인프라(infrastructure)의 99%가 하룻밤 사이에 불필요해질 것입니다. 그러한 잉여 인프라(surplus infrastructure)를 정당화할 만큼 수요를 충분히 빠르게 확장할 수는 없습니다. 이 상황에서 "제본스 역설(Jevons Paradox)"로 벗어날 수는 없습니다. 그리고 바로 여기서 거품의 조건, 즉 컴퓨팅 과잉 공급(overcapacity of compute)에 대한 수요 부족이 충족될 것입니다.

이것이 현실적일까요? 그러한 엄청난 컴퓨팅 효율성(compute efficiency) 증가는 얼마나 현실적일까요? 100배의 효율성(efficiency) 향상은 미친 소리처럼 들릴 수 있습니다. 하지만 이것을 생각해 보세요. 우리는 이 모델들이 왜 그렇게 잘 작동하는지 아직 완전히 이해하지 못하고 있습니다. 우리는 그것들을 "성장"시키고 작동하는 것을 볼 수 있지만, 정확히 왜 작동하는지는 모릅니다. 네, 우리는 스케일링 법칙(scaling laws)과 일부 회로 수준(circuit-level)의 동작을 이해하지만, 여전히 첫 번째 원칙(first principles)에서 시스템을 공학적으로 설계하기보다는 성장시키고 있습니다. 이는 아키텍처 혁신(architectural innovation)을 위한 엄청난 여지가 있을 수 있음을 의미합니다. 그리고 급진적인 효율성(efficiency) 향상에 대한 증거는 이미 나타나고 있습니다. Giotto.ai를 예로 들어봅시다. EPFL AI 센터(EPFL AI Center)의 Inside AI 팟캐스트(podcast) 에피소드에서 CEO 알도 포데스타(Aldo Podestà)는 2억 개의 매개변수(parameters)(b가 아닌 m)만을 가진 그들의 모델이 현재 ARC-AGI 2 리더보드(leaderboard)에서 최고 경쟁자 중 하나라고 설명합니다. 이는 올바른 아키텍처(architectural) 선택이 몇 배 더 효율적일 수 있다는 힌트입니다. 물론 이 모델들은 현대 LLM(Large Language Models)처럼 인터넷을 "기억"하지는 않을 것입니다. 하지만 그것이 단순히 필요하지 않을 수도 있습니다. 이 점을 강조하기 위해 OpenAI 공동 창립자 안드레이 카르파티(Andrej Karpathy)는 AGI(Artificial General Intelligence)의 "인지 핵심(cognitive core)"이 10억 개의 매개변수(parameters)로 실행될 수 있다고 제안했지만, 그는 그것이 아직 20년은 더 걸릴 것이라고 생각합니다. 그리고 자연의 개념 증명(proof of concept)이 있습니다. 인간의 뇌는 약 20와트(watts)로 일반 지능(general intelligence)에 도달합니다. 분명히, 훨씬 더 효율적으로 일을 처리할 수 있습니다.

### 효율성 향상 전략과 새로운 컴퓨팅 패러다임

AI 모델의 효율성을 향상시키는 방법은 비단 아키텍처 혁신에만 국한되지 않습니다. 소프트웨어 단에서는 양자화(quantization), 희소성(sparsity), 지식 증류(knowledge distillation)와 같은 기술들이 모델의 크기를 줄이고 추론 속도를 높이며, 필요한 컴퓨팅 자원을 대폭 감소시키고 있습니다. 예를 들어, 8비트 또는 4비트 양자화를 통해 모델의 메모리 사용량과 계산량을 줄이면서도 성능 저하를 최소화하는 연구가 활발합니다. 또한, 모델의 모든 가중치를 사용하지 않고 중요한 부분만 활성화하는 희소성 기법은 계산 효율을 크게 높일 수 있습니다.

하드웨어 측면에서는 GPU 외에 새로운 컴퓨팅 패러다임이 부상하고 있습니다. 뉴로모픽 칩(neuromorphic chips)은 뇌의 구조와 기능을 모방하여 에너지 효율적인 AI 연산을 목표로 하며, 아날로그 AI 칩(analog AI chips)은 디지털 방식이 아닌 아날로그 신호를 활용하여 전력 소모를 줄이고 속도를 높일 가능성을 제시합니다. 아직 상용화 단계는 아니지만, 이러한 혁신적인 하드웨어는 장기적으로 현재의 GPU 중심 인프라에 큰 변화를 가져올 수 있습니다.

오픈소스 AI 모델의 부상도 중요한 변수입니다. Meta의 Llama 시리즈와 같은 오픈소스 모델은 커뮤니티의 기여를 통해 빠르게 발전하고 있으며, 이러한 모델들은 특정 기업의 독점적인 컴퓨팅 자원에 대한 의존도를 낮출 수 있습니다. 개발자들이 자체적으로 모델을 훈련하고 최적화할 수 있는 기회를 제공함으로써, 컴퓨팅 수요의 분산과 효율적인 활용을 촉진할 수 있습니다.

또한, AI 모델의 데이터 효율성 측면에서도 발전이 기대됩니다. 현재의 대규모 모델들은 방대한 데이터를 학습하지만, 미래에는 더 적은 데이터로도 높은 성능을 달성하거나, 합성 데이터(synthetic data)를 활용하여 실제 데이터 수집 및 처리 비용을 줄이는 방향으로 발전할 수 있습니다. 장기적으로는 '모델 붕괴(model collapse)'와 같은 현상, 즉 생성된 데이터가 다시 학습에 사용되면서 모델의 품질이 저하되는 문제가 발생할 수 있다는 우려도 제기되고 있습니다. 이는 궁극적으로 새로운 컴퓨팅 자원에 대한 수요를 간접적으로 둔화시킬 수도 있는 요인입니다.

이러한 다양한 기술적 진보는 현재의 컴퓨팅 자원 부족 현상을 완화하고, AI 서비스를 제공하는 데 필요한 총비용을 줄일 잠재력을 가지고 있습니다. 이는 AI의 대중화를 더욱 가속화할 수 있지만, 동시에 현재의 막대한 인프라 투자가 과잉 공급으로 이어질 수 있는 위험을 내포하고 있습니다.

이것이 하룻밤 사이에 일어나지는 않을 것입니다. 만약 우리가 매년 10배의 효율성(efficiency) 향상을 본다면, 현재의 컴퓨팅 투자(compute investments)는 합리적인 수준을 유지하거나, 3년에서 5년에 걸쳐 점진적으로 서서히 쓸모없어질 수 있습니다(어쨌든 이것이 예상 수명입니다). 여전히 거품이 꺼지는 것일 수 있지만, 단지 더 느린 속도일 뿐입니다. 이 시점에서는 거품이 아니라 단지 일반적인 성장 주기일 수도 있습니다. 더 효율적인 접근 방식이 존재하는지 여부가 문제가 아닙니다. 그것들은 분명히 존재합니다. 문제는 누군가가 언제 그것들을 알아내는지, 그리고 그것들이 한 번에 2배, 10배, 또는 100배의 효율성을 가져올지 여부입니다.

### AI 시장의 미래: 지속적인 진화와 적응

결론적으로, 현재 AI 시장은 과거의 거품들과는 근본적으로 다른 역학을 가지고 있습니다. 압도적인 수요와 컴퓨팅 자원 부족은 투자를 정당화하는 강력한 근거가 됩니다. 그러나 기술 혁신의 속도는 예측 불가능하며, 컴퓨팅 효율성의 급진적인 향상이나 새로운 컴퓨팅 패러다임의 등장은 미래에 시장의 균형을 뒤흔들 수 있습니다.

AI 시장은 단순한 거품이 아닌, 끊임없이 진화하고 적응하는 복잡한 생태계입니다. 현재의 강력한 성장은 혁신적인 기술과 명확한 효용성에 기반을 두고 있지만, 미래의 불확실성에 대비하는 유연한 전략이 필요합니다. 지속적인 연구 개발과 효율성 추구는 AI 기술의 장기적인 발전뿐만 아니라, 시장의 안정적인 성장을 위한 필수적인 요소가 될 것입니다. 현재는 AI 기술의 황금기이지만, 미래의 변화에 대한 면밀한 관찰과 분석이 동반되어야 할 것입니다.

한 가지 더, 제가 책을 냈습니다! 이 서브스택(substack) 독자들은 제가 AI에 대한 일반 독자용 책을 작업해 왔다는 것을 알고 계실 것입니다. 프랑스어 버전이 현재 이용 가능하며, 독일어 버전은 11월 중순에 출시될 예정임을 기쁘게 알려드립니다. 저는 현재 영어 번역 작업을 하고 있지만, 먼저 영어 출판사를 찾아야 할 것입니다. 어쨌든, 프랑스어나 독일어를 하신다면 한번 살펴보세요. 분명히 즐거우실 겁니다!

또 다른 한 가지, 여러분은 제가 AMLD라는 대규모 응용 기계 학습(applied machine learning) 행사의 주최자라는 것을 아마도 알고 계실 것입니다. 10회째를 맞아 저희는 이 행사를 AMLD 인텔리전스 서밋(AMLD Intelligence Summit)으로 이름을 변경했습니다. 이 행사는 2026년 2월 10일부터 12일까지 EPFL 캠퍼스(campus)에서 개최될 예정이며, 프로그램은 정말 환상적일 것입니다. 절대 놓치고 싶지 않으실 겁니다. 짐작하시겠지만, 기술 학교와의 근접성은 과장이나 허튼소리에 대한 허용 오차(tolerance)가 매우 낮다는 것을 보장하며, 이는 고신호 저잡음(high-signal, low-noise) AI 행사로 만듭니다. 얼리버드 티켓(Early bird tickets)은 한정된 기간 동안 이용 가능하며, 다가오는 정식 티켓 가격보다 훨씬 저렴하므로 서둘러 확보하기를 강력히 권해드립니다.

코다(CODA) 이 뉴스레터(newsletter)는 두 가지 구독 유형을 제공합니다. 유료 버전으로 전환하시기를 강력히 권해드립니다. 모든 콘텐츠는 무료로 유지되지만, 모든 재정적 지원은 EPFL AI 센터(EPFL AI Center) 관련 활동에 직접적으로 자금을 지원합니다. 연락을 유지하려면 저를 찾을 수 있는 다른 방법들이 있습니다. 소셜(Social): 저는 주로 링크드인(LinkedIn)에 있지만, 마스토돈(Mastodon), 블루스카이(Bluesky), 그리고 X에도 있습니다. 팟캐스팅(Podcasting): 저는 EPFL AI 센터(EPFL AI Center)에서 "Inside AI"라는 AI 팟캐스트(podcast)를 진행하고 있으며(애플 팟캐스트(Apple Podcasts), 스포티파이(Spotify), 유튜브(YouTube)), 저보다 훨씬 똑똑한 분들과 이야기할 수 있는 특권을 누리고 있습니다. Engineering Prompts는 독자 후원으로 운영되는 출판물입니다. 새로운 게시물을 받고 제 작업을 지원하려면 무료 또는 유료 구독자가 되는 것을 고려해 보세요. 구독하기