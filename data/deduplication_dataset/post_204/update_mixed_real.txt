모두가 우리가 AI 거품(bubble) 속에 있는지 알고 싶어 합니다. 이 글에서 저는 명확한 답변을 드릴 것입니다. 물론 아닙니다. 하지만 오늘날 많은 글들이 바로 그렇게 들립니다. 비슷한 주장을 하는 글들이 많지만, 과거의 거품 사례와 겉모습만 비교하는 것은 본질을 놓치는 일입니다. 근본적인 역학(dynamics)을 간과한 채 현재의 사건을 과거의 거품과 비교하는 것은 별 도움이 되지 않습니다. 이는 마치 모든 급격한 변화를 똑같은 방식으로 해석하려는 시도와 같습니다. 우리가 물어야 할 중요한 질문은 현재의 역학이 실제로 붕괴(crash)를 야기할 위험이 있는지 여부입니다.

예를 들어, 철도 거품(railroad bubble)과의 비교를 들어봅시다. 이 역사적인 사건에 대해 몇 주를 읽을 수도 있겠지만, 근본적으로 그 밑바탕에는 약한 수요와 엄청난 과잉 공급(overcapacity)이라는 문제가 있었고, 이는 필연적으로 붕괴(collapse)로 이어지는 불균형이었습니다. 닷컴 버블 역시 유사한 양상을 보였습니다. 단기간 내에 폭발적인 수요가 발생할 것이라는 비현실적인 기대감이 과도한 투자를 유발했던 것이죠. 수요가 결국 현실화되었지만, 예상보다는 훨씬 더뎠다는 공통점이 있습니다. 오늘날의 AI 상황은 근본적으로 다릅니다. 우리는 컴퓨팅 자원 부족(compute undercapacity)과 압도적인 수요를 겪고 있습니다. 이 점을 강조하고 싶습니다. 특히, 많은 기업이 급증하는 AI 서비스 수요를 감당할 컴퓨팅 자원(computing resources)을 확보하는 데 큰 난관에 부딪히고 있다는 점을 주목해야 합니다. 그것은 거품이 아니라, 말 그대로 정반대입니다! 이러한 자원 부족 현상은 오히려 AI 인프라에 대한 투자를 가속화하고 관련 기업들의 가치를 높이는 요인으로 작용합니다. 따라서 오늘날의 AI 시장을 거품이라고 부르는 것은 잘못된 생각입니다. 왜냐하면 필수적인 거품 구성 요소인 과잉 공급(overcapacity)과 약한 수요가 단순히 존재하지 않기 때문입니다.

Engineering Prompts는 독자 후원으로 운영되는 출판물입니다. 새로운 게시물을 받고 제 작업을 지원하려면 무료 또는 유료 구독자가 되는 것을 고려해 보세요. 구독하기

그렇다면 걱정할 것이 없는 걸까요? 지금 당장은 아닙니다. 하지만 내일은 다른 이야기가 될 수 있습니다. 핵심 요소인 과잉 공급(overcapacity)과 약한 수요는 서로 밀접하게 연결되어 있습니다. 결국 수요가 공급을 결정하기에, 현재의 수요 동향에 집중하여 상황을 분석해 봅시다. AI에 대한 수요는 매우 강하며, 이 수요가 계속해서 증가하지 않는 미래를 상상하기는 어렵다고 말할 수 있습니다. AI는 엄청나게 유용하며 앞으로 더욱 유용해질 것이고, 이는 자연스럽게 수요 증가를 촉진합니다. 일부 회의론자들은 AI의 실질적 유용성에 의문을 제기하지만, 다수의 연구와 사용자 피드백은 AI의 가치를 명확히 입증하고 있습니다. 물론, 초기 단계의 과장된 마케팅이나 성능에 대한 과도한 기대가 없지 않았습니다. 그러나 사용자들은 이제 AI 모델의 실질적인 기능을 일상과 업무에 통합하며 그 가치를 체감하고 있으며, 이러한 경험이 지속적인 수요를 견인하고 있습니다. AI 기능이 계속 향상될 것이라는 명확한 증거를 고려할 때, 우리는 수요 또한 증가할 것이라고 확신할 수 있습니다. 결론적으로, AI에 대한 수요가 꾸준히 증가하는 한, 현재의 컴퓨팅 인프라 투자(compute infrastructure investments)는 충분히 정당성을 가집니다. 이는 과잉 공급이 아닌, 급증하는 수요에 발맞춘 자연스러운 인프라 확장에 가깝다고 볼 수 있습니다. 이러한 추론이 바로 제가 오늘날 우리가 AI 거품(bubble) 속에 있다고 주장하기 어렵다고 생각하는 이유입니다. 급격한 성장은 혼란스러워 보일 수 있지만, 이는 거품이 아닌, 매우 유용한 기술에 의해 주도되는 강력하고 건전한 확장을 반영합니다. AI가 생성하는 가치는 수요가 높은 GPU를 통해 제공되고 있습니다. 그렇다면 이 수요는 어디서 오는 것일까요?

하지만 여기에 핵심이 있습니다. 사람들은 AI를 원합니다. 즉, 컴퓨팅 하드웨어(compute hardware) 자체가 아니라 AI 서비스(AI services)를 요구하는 것입니다. 현재 AI의 발전은 막대한 GPU 인프라와 같은 컴퓨팅 하드웨어에 크게 의존하고 있으며, 이는 대규모 모델들이 요구하는 엄청난 계산 자원 때문입니다. 하지만 이 연결이 약해진다면 어떨까요? 그러한 시나리오는 실제로 AI 거품(bubble)을 위한 조건을 만들 수 있습니다. 예를 들어, 현재의 컴퓨팅 자원 요구량의 1%만으로도 최상급 AI 모델 성능을 구현하는 혁신적인 AI 아키텍처(architecture)가 등장했다고 가정해 봅시다. AI에 대한 수요는 강하게 유지될 것이고, 비용 절감으로 인해 심지어 증가할 수도 있겠지만(유명한 "제본스 역설(Jevons Paradox)"), 막대한 비용을 들여 구축된 방대한 GPU 팜(farm)을 완전히 활용하기에는 충분하지 않을 것입니다. 이 경우, AI 서비스에 대한 수요는 여전히 높겠지만, 막대한 비용을 들여 구축된 기존 GPU 팜의 99%는 순식간에 유휴 자원이 될 것입니다. 이러한 잉여 인프라(surplus infrastructure)를 정당화할 만큼 수요를 빠르게 늘리기는 불가능하며, '제본스 역설'도 여기서는 통하지 않을 것입니다. 그리고 바로 여기서 거품의 조건, 즉 컴퓨팅 과잉 공급(overcapacity of compute)에 대한 수요 부족이 충족될 것입니다.

이것이 현실적일까요? 그러한 엄청난 컴퓨팅 효율성(compute efficiency) 증가는 얼마나 현실적일까요? 100배의 효율성(efficiency) 향상은 미친 소리처럼 들릴 수 있습니다. 하지만 이것을 생각해 보세요. 현재의 AI 모델들이 왜 그토록 뛰어난 성능을 발휘하는지에 대한 근본적인 이해는 아직 부족합니다. 우리는 모델을 학습시키고 그 결과를 관찰하지만, 정확한 작동 원리는 여전히 미지의 영역입니다. 네, 우리는 스케일링 법칙(scaling laws)과 일부 회로 수준(circuit-level)의 동작을 이해하지만, 여전히 첫 번째 원칙(first principles)에서 시스템을 공학적으로 설계하기보다는 성장시키고 있습니다. 이는 곧 아키텍처 혁신(architectural innovation)을 통해 효율성을 극대화할 수 있는 잠재력이 매우 크다는 것을 시사합니다. 그리고 급진적인 효율성(efficiency) 향상에 대한 증거는 이미 나타나고 있습니다. Giotto.ai를 예로 들어봅시다. EPFL AI 센터(EPFL AI Center)의 Inside AI 팟캐스트(podcast) 에피소드에서 CEO 알도 포데스타(Aldo Podestà)는 2억 개의 매개변수(parameters)(b가 아닌 m)만을 가진 그들의 모델이 현재 ARC-AGI 2 리더보드(leaderboard)에서 최고 경쟁자 중 하나라고 설명합니다. 이는 올바른 아키텍처 설계가 기존 방식보다 훨씬 더 효율적인 결과를 가져올 수 있음을 암시합니다. 물론 이 모델들은 현대 LLM(Large Language Models)처럼 인터넷을 "기억"하지는 않을 것입니다. 하지만 그것이 단순히 필요하지 않을 수도 있습니다. 또한, OpenAI 공동 창립자인 안드레이 카르파티(Andrej Karpathy)는 AGI(Artificial General Intelligence)의 '인지 핵심(cognitive core)'이 10억 개의 매개변수로도 구현될 수 있다고 언급하며, 효율성 개선의 가능성을 제기했습니다. 물론, 그는 이러한 발전이 아직 먼 미래의 일이라고 전망했지만, 이는 기술 발전의 방향성을 보여주는 중요한 통찰입니다. 그리고 자연의 개념 증명(proof of concept)이 있습니다. 인간의 뇌는 약 20와트(watts)로 일반 지능(general intelligence)에 도달합니다. 분명히, 훨씬 더 효율적으로 일을 처리할 수 있습니다.

이것이 하룻밤 사이에 일어나지는 않을 것입니다. 만약 우리가 매년 10배의 효율성(efficiency) 향상을 본다면, 현재의 컴퓨팅 투자(compute investments)는 합리적인 수준을 유지하거나, 3년에서 5년에 걸쳐 점진적으로 서서히 쓸모없어질 수 있습니다(어쨌든 이것이 예상 수명입니다). 이는 느린 속도로 진행되는 거품 붕괴로 비춰질 수도 있지만, 오히려 기술 발전과 시장의 자연스러운 성장 주기로 해석하는 것이 더 적절할 것입니다. 더 효율적인 접근 방식이 존재하는지 여부가 문제가 아닙니다. 그것들은 분명히 존재합니다. 문제는 누군가가 언제 그것들을 알아내는지, 그리고 그것들이 한 번에 2배, 10배, 또는 100배의 효율성을 가져올지 여부입니다.

한 가지 더, 최근 몇 년간 AI 분야의 급속한 발전은 저에게 새로운 영감을 주었습니다. 저는 이 서브스택(substack) 독자들을 위해 AI의 미래와 그 잠재적 위험에 대한 심층적인 분석을 담은 새로운 시리즈를 준비하고 있습니다. 첫 번째 글은 다음 달에 공개될 예정이며, 현재의 AI 생태계가 직면한 윤리적, 사회적 과제에 초점을 맞출 것입니다. 많은 기대 부탁드립니다.

또 다른 한 가지, 여러분은 제가 AMLD라는 대규모 응용 기계 학습(applied machine learning) 행사의 주최자라는 것을 아마도 알고 계실 것입니다. 저희는 올해로 11회째를 맞아 행사의 규모와 내용을 더욱 확장하여 'AMLD 인텔리전스 서밋(AMLD Intelligence Summit) 2026'으로 개최할 예정입니다. 이 행사는 2026년 2월 10일부터 12일까지 EPFL 캠퍼스(campus)에서 진행되며, 최신 AI 연구와 산업 적용 사례를 아우르는 혁신적인 프로그램으로 구성될 것입니다. 짐작하시겠지만, 기술 학교와의 근접성은 과장이나 허튼소리에 대한 허용 오차(tolerance)가 매우 낮다는 것을 보장하며, 이는 고신호 저잡음(high-signal, low-noise) AI 행사로 만듭니다. 현재 얼리버드 티켓(Early bird tickets) 판매가 시작되었으니, AI 분야의 최전선을 경험하고 싶으시다면 서둘러 확보하시기를 강력히 권해드립니다.

코다(CODA) 이 뉴스레터(newsletter)는 두 가지 구독 유형을 제공합니다. 유료 버전으로 전환하시기를 강력히 권해드립니다. 모든 콘텐츠는 무료로 유지되지만, 모든 재정적 지원은 EPFL AI 센터(EPFL AI Center) 관련 활동에 직접적으로 자금을 지원합니다. 저와 소통할 수 있는 다양한 채널이 있습니다. 소셜 미디어(Social Media): 저는 주로 링크드인(LinkedIn)에서 활동하지만, 마스토돈(Mastodon), 블루스카이(Bluesky), 그리고 X(구 트위터)에서도 저를 찾으실 수 있습니다. 팟캐스팅(Podcasting): 저는 EPFL AI 센터(EPFL AI Center)에서 "Inside AI"라는 AI 팟캐스트(podcast)를 진행하고 있으며(애플 팟캐스트(Apple Podcasts), 스포티파이(Spotify), 유튜브(YouTube)), 저보다 훨씬 똑똑한 분들과 이야기할 수 있는 특권을 누리고 있습니다. Engineering Prompts는 독자 후원으로 운영되는 출판물입니다. 새로운 게시물을 받고 제 작업을 지원하려면 무료 또는 유료 구독자가 되는 것을 고려해 보세요. 구독하기