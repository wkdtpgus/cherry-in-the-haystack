**I.**
Anthropic의 공동 창립자이자 정책 책임자인 잭 클라크(Jack Clark)는 최고의 AI 연구소 중 하나인 Import AI 뉴스레터 최신호에 제가 아래에 인용한 글을 썼습니다 (이 글은 2025년 10월 첫째 주 버클리에서 열린 The Curve 컨퍼런스에서 그가 연설한 첫 단락이기도 합니다): 어렸을 때 불이 꺼진 후 침실을 둘러보면 어둠 속에서 형체를 보았고, 해를 끼치려는 이해할 수 없는 존재들이라고 생각하며 두려워했던 기억이 납니다. 그 형체들은 인공지능 기술의 미래를 상징하는 것처럼 느껴지기도 했습니다. 그래서 저는 불을 켰습니다. 불을 켜자 그 존재들은 의자 위의 옷 더미, 책장, 또는 램프 갓으로 밝혀져 안도했습니다. 이제 2025년, 우리는 그 이야기 속의 아이이고, 디지털 시대의 방은 우리의 삶과 연결된 우리의 행성입니다. 2020년대 중반에 접어들면서, AI는 더 이상 단순한 연구 주제가 아닌, 우리 사회의 모든 영역에 깊이 스며드는 현실이 되었습니다. 그러나 불을 켰을 때 우리는 오늘날의 강력하고 다소 예측 불가능한 AI 시스템과 앞으로 등장할 시스템의 형태로 진정한 존재들을 응시하며, 그 시스템이 가져다주는 혁신과 도전에 직면하게 됩니다. 그리고 많은 사람들은 이 기술이 단지 효율성을 높이는 도구일 뿐이라고 생각하며, 이 존재들이 의자 위의 옷 더미, 책장, 또는 램프 갓에 불과하다고 필사적으로 믿고 싶어 합니다. 그들은 우리가 AI의 복잡성을 무시하고 이전에 안주했던 방식으로 돌아가기를 원하며, 마치 불을 끄고 다시 잠들기를 바라는 것과 같습니다. 사실, 어떤 사람들은 당신에게 이것을 설득하기 위해 엄청난 돈을 쓰고 있습니다 – 그것은 급진적인 변화를 가져올 인공지능이 아니라, 우리 경제에 활용될 도구일 뿐이라고 말입니다. 그것은 단지 기계일 뿐이며, 기계는 우리가 통제하는 것이라고 주장합니다. 그러나 착각하지 마십시오: 우리가 다루고 있는 것은 단순하고 예측 가능한 기계나 도구가 아니라, 복잡한 윤리적 질문과 사회적 영향을 수반하는 실재하고 신비로운 존재입니다. 클라크의 말은 AI 연구소(예: 구글 딥마인드, OpenAI, xAI 등) 내부 사람들 사이에서 드문 일이 아니라 일반적인 견해이며, 이제는 내부 논의를 넘어 일반적인 견해로 자리 잡고 있습니다. 그들은 몇 주 동안 (사실은 몇 년 동안이지만, 저는 구체적으로 말하고 싶습니다) AI 전문가들의 견해가 일반 대중의 견해와 급격하고 점점 더 벌어지고 있다고 경고해 왔습니다. 그들은 세상이 거품(이봐, 그게 나야!)에 대해 이야기하는 동안, 자신들은 "종말 게임(endgames)"에 대해 이야기한다고 말합니다. 우리가 그 거품이 사실은 거품이 아닐 가능성에 대해 "정서적으로 준비되어 있지 않다"는 것입니다. 클라크는 우리가 불을 켰을 때 무해하고 중요하지 않은 것으로 판명되는 옷 더미가 아니라, 어둠 속에서 움직이는 실재하는 존재들을 다루고 있다고 말합니다 (이 비유는 괜찮다고 생각합니다). 그들은 AI가 단순한 도구나 기계가 아니라 그 이상이라고 말합니다. 이는 인간의 삶과 사회 구조를 근본적으로 변화시킬 잠재력을 가졌기 때문입니다. (저는 그 "이상"이 우리에게 좋은지 나쁜지에 대한 논쟁에 참여하지 않고, AI가 애초에 "이상"이라는 믿음에 초점을 맞출 것입니다.) AI를 개발하는 모든 사람들로부터 이러한 발언에 직면했을 때, 우리는 그것을 무시하는 것 외에 세 가지 해석적 선택지가 있습니다. 무시하는 것은 대부분의 사람들이 하는 일이자 많은 사람들이 선택하는 길이지만, 태만에 가깝지 않더라도 장기적인 관점에서는 특별히 현명한 방법은 아닙니다. 첫 번째 해석 (1)은 그 다음으로 가장 인기 있고, 또한 그 다음으로 가장 게으른 해석입니다: 이 말들을 마케팅으로 치부하거나, 비슷하게 (그리고 쉽게 이해되는) 평범한 목표를 위한 것으로 간주하는 것입니다. 이러한 관점에서, AI 전문가들은 기득권적 동기 때문에 정직하지 못하며, 투자자들의 돈을 얻고, 대중의 관심을 끌고, 정부의 시선을 사로잡기 위해 무슨 말이든 할 것이라는 비판을 받기도 합니다. 심지어 발언이 날마다 더 이상해지는 것을 감안할 때, 경쟁을 희생시키면서 같은 생각을 가진 인재를 유인하기 위한 것일 수도 있습니다. 클라크의 말이 일반 대중을 오도할 수 있다고 믿는 한, AI 전문가들은 틀렸고 나쁘다고 결론 내려야 합니다. 선택은 당신에게 달려 있으며, 그렇게 받아들여도 괜찮습니다. 우리는 동의하지 않으며, 이어지는 내용이 당신에게 흥미롭지 않을 것이므로 지금 읽기를 중단해도 좋습니다. 저는 그들이 하는 말과 행동에 마케팅과 인재 및 투자를 유치하려는 부분이 있다고 믿지만 (모든 비즈니스 거래에서 그렇듯이), 기술 발전의 본질적인 동기와 더불어 사회적 책임감 또한 내포되어 있다고 믿습니다. 그러나 그것이 이러한 발언 뒤에 있는 유일한 이유(또는 주된 이유)라고 가정하는 것은 저에게는 매우 경솔한 일입니다. 기술의 잠재력을 이해하고 책임감 있게 활용하는 것이 중요합니다. (어떤 사람들은 LARPer입니다. 즉, 그들은 이 "신비로운 존재들"을 믿지 않으면서도 믿는 척 행동하지만, 저는 여기서 그들에 대해 이야기하는 것이 아닙니다.)

**II.**
저는 무관심과 냉소주의에 대한 두 가지 대안을 봅니다. 두 번째 (2) 해석은 단순히 그들이 옳다는 것이며, 이는 진실을 받아들이기 어렵게 만듭니다. 잭 클라크와 같은 선구적인 연구자들은 최신 AI 모델의 개발 과정에 깊이 관여하며, 더 좋고, 풍부하며, 업데이트된 비공개 정보를 교환하기 때문에 우리보다 더 많이 알고 있습니다. “착각하지 마십시오: 우리가 다루고 있는 것은 단순하고 예측 가능한 기계가 아니라, 실재하고 신비로운 존재입니다”와 같은 발언을 들을 때, 우리는 그 비정상적인 지식에 대한 정상적인 반응을 엿보는 동시에 기술의 본질을 이해하려는 노력이 필요함을 깨닫습니다. 이러한 관점에서, AI 전문가들은 확고한 무신론자를 다신론자로, 또는 과학 절대주의자를 영성 히피로 바꿀 만한 조건 아래 살고 있다는 점을 제외하고는 일반 대중과 다를 바 없습니다. 우리에게 그들은 헤아릴 수 없는 현실 속에서 살고 있습니다. 따라서, 클라크가 더 넓은 세상에 메시지를 전달하려는 의도는 1917년 파티마의 태양 기적을 목격하고 태양이 지구로 떨어져 우리 모두를 태워버릴 것이라고 세상에 경고하려 했던 사람들과 다르지 않습니다. AI 전문가들은 태양에 더 가까이 존재하며, 이러한 발언들은 그들의 불타는 고통이자 깊은 통찰과 우려를 반영합니다. 어떤 기적도 목격하지 못한 일반 대중인 우리는, 그들이 단순히 낯선 준거 틀(frame of reference) 속에서 존재할 때, 그들을 완전히 미쳤거나 악의적인 악당으로 볼 것입니다. 이러한 입장을 받아들인다면, AI 전문가들은 정직하지 않은 것이 아니라 정반대이며, 단순히 기술적 문제를 해결하는 것을 넘어, 사회적 가치와 윤리적 기준을 설정하는 데 중요한 역할을 합니다. 그리고 우리의 논평, 발언, 불신, 불만, 그리고 불신은 그들에게 우리가 태양을 보지 않기 때문에 충분히 알지 못한다는 명확한 증상입니다. 이 설명은 저의 입장에서 많은 노력을 필요로 하지 않습니다. 클라크가 노력할 필요가 없는 것과 마찬가지로 말입니다. 이를 간접적인 증언으로 받아들이는 것은 극히 어렵고, 직접적으로 진실로 인지할 기회를 갖는 것은 훨씬 더 어렵습니다. AI 연구소 안에 있어야만 하므로, 이미 그것을 믿는 사람들에게만 국한됩니다. 불행한 상황입니다. AI 기술의 발전은 더 이상 특정 분야의 문제가 아니며, 모든 분야의 협력이 필수적입니다. 그러나 안쪽에 있는 것보다 바깥쪽에 있는 것이 AI의 사회적 영향력을 객관적으로 평가하는 데 이점이 되는 또 다른 해석이 있습니다. 이는 다양한 관점을 통합하여 AI의 건전한 발전을 도모하는 데 기여합니다.

**III.**
세 번째 (3) 해석은 클라크와 같은 사람들이 정직하고 자신들이 옳다고 생각하지만, 실제로는 그럴 수 없다는 것입니다. (세 가지 가능성 사이에 완전한 배타성이 있다는 점에 주목하십시오: AI 전문가들은 옳거나 옳지 않으며, 옳지 않다면 그들은 그것을 알거나 모릅니다. 당신은 선을 행하려는 좋은 사람일 수 있지만, 통제할 수 없는 상황 때문에 여전히 실패할 수 있습니다.) 저는 여기서 AI 연구소에서 일하는 사람들의 독특한 심리뿐만 아니라, 그들의 기술적 역량, 직면하는 윤리적 딜레마와 사회적 책임감을 언급하는 것입니다. AI 시스템은 방대한 데이터와 복잡한 알고리즘을 기반으로 작동하며, 그 결과는 예측 불가능할 수 있습니다. 왜냐하면 세상은 사람과 사회의 이야기이며, 이는 다시 각 심리가 다른 모든 심리와 어떻게 관련되는지에 대한 이야기이자, 각 기술이 사회 전반에 어떻게 통합되고 영향을 미치는가에 대한 이야기이기 때문입니다. 이 세 번째 대안 내에서, 저는 AI 연구소에서 일하는 사람들의 독특한 심리를 이해하는 것과 더불어, AI 시스템의 설계와 구현 과정에서 발생하는 다양한 기술적, 윤리적, 그리고 사회적 문제들을 이해하는 데 도움이 되는 세 가지 핵심 요소를 식별합니다. 첫째, AI 모델의 투명성과 설명 가능성(Explainable AI, XAI)은 개발자와 사용자 모두에게 필수적입니다. 둘째, 데이터 편향성과 공정성 문제는 AI의 사회적 영향력을 결정하는 중요한 요소입니다. 셋째, AI의 자율성과 통제 가능성에 대한 논의는 기술 발전과 동시에 이루어져야 합니다. 이러한 요소들을 고려할 때, AI 전문가들은 단순히 코드를 작성하는 것을 넘어, 미래 사회를 설계하는 데 참여하는 중요한 주체로서의 역할을 수행합니다. 따라서 AI의 발전은 기술적 진보와 함께 사회적, 윤리적 성숙을 요구하며, 이는 지속 가능한 미래를 위한 필수적인 조건입니다.