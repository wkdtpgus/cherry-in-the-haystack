Anthropic의 공동 창립자이자 정책 책임자인 잭 클라크(Jack Clark)는 저명한 AI 연구소의 소식을 전하는 Import AI 뉴스레터 최신호에 아래의 글을 게재했습니다 (이 글은 2025년 10월 첫째 주 버클리에서 열린 The Curve 컨퍼런스에서 그가 발표한 연설의 서론이기도 합니다). 그가 전하는 메시지는 다음과 같습니다. 어릴 적, 밤이 깊어 조명이 꺼진 방 안에서 희미한 윤곽을 마주하며, 어딘가 불길하고 이해하기 어려운 실체들이 나를 해치려 한다고 생각했던 기억이 생생합니다. 겁에 질려 방의 불을 밝혔습니다. 조명을 밝히자, 그것들은 의자 위 옷가지, 서가, 혹은 스탠드 덮개와 같은 평범한 사물로 드러나 안도감을 주었습니다. 오늘날, 우리는 마치 그 동화 속 아이와 같고, 우리의 터전인 지구는 그 방에 비유될 수 있습니다. 그러나 지금 우리가 '불을 켜서' 마주한 것은, 현재의 강력하고 다소 예측 불가능한 인공지능 체계와 미래에 도래할 시스템이라는 진정한 존재들입니다. 수많은 이들은 이러한 실체가 단지 의자 위의 옷가지나 책장, 혹은 램프 갓처럼 무해한 것이라고 간절히 믿고 싶어 합니다. 더 나아가, 그들은 우리가 다시 불을 끄고 편안히 잠들기를 바랍니다. 실로, 일부 세력은 당신에게 이러한 인식을 심어주기 위해 막대한 자금을 쏟아붓고 있습니다 – 즉, 인공지능이 급격한 도약(hard takeoff)을 앞둔 존재가 아니라, 단지 경제적 효용을 위한 도구일 뿐이라는 메시지입니다. 이는 단순한 기계에 불과하며, 우리는 언제든 이를 통제할 수 있다고 말입니다. 하지만 착각해서는 안 됩니다: 우리가 직면한 것은 단순하며 예측 가능한 기계 장치가 아니라, 실제로 존재하며 알 수 없는 특성을 지닌 실체입니다.

이러한 인식은 주요 AI 연구 기관들(예: 구글 딥마인드, OpenAI, xAI) 내부 관계자들 사이에서 결코 이례적이지 않으며, 오히려 보편적인 시각으로 자리 잡고 있습니다. 이들은 수주간(실제로는 수년간이지만, 구체적으로 명시하자면) 인공지능 분야 전문가들의 관점과 일반 대중의 인식이 급격하게, 그리고 점진적으로 멀어지고 있음을 경고해 왔습니다. 세간이 소위 '거품'(저를 포함한 많은 이들이 언급하는)에 대해 논할 때, 이들 전문가는 '최후의 시나리오(endgames)'를 논한다고 강조합니다. 그들의 주장은 우리가 흔히 말하는 '거품'이 사실은 거품이 아닐 가능성에 대해 '심리적으로 대비되어 있지 않다'는 뜻입니다. 클라크는 우리가 조명을 밝혔을 때 무해한 옷가지 더미가 아닌, 어둠 속에서 움직이는 실재하는 존재들을 마주하고 있음을 비유적으로 설명합니다 (이 비유는 적절하다고 생각합니다). 그들은 인공지능이 단순히 도구나 기계에 그치지 않는, 그 이상의 존재라고 주장합니다. (저는 그 '이상'이 우리에게 이로운지 해로운지에 대한 논쟁에 참여하기보다, 인공지능이 애초에 '이상'이라는 믿음에 초점을 맞출 것입니다.)

인공지능 개발에 종사하는 모든 이들로부터 클라크와 같은 발언이 나올 때, 우리는 이를 무시하는 것 외에 세 가지 해석적 선택지에 직면합니다. 대부분의 사람들이 선택하는 무시는, 비록 명백한 태만은 아닐지라도, 결코 현명한 접근 방식이라 할 수 없습니다. 가장 보편적이고 게으른 첫 번째 해석 (1)은, 이들의 발언을 단순한 마케팅 전략으로 치부하거나, 혹은 유사하게 (그리고 이해하기 쉬운) 평범한 목적을 위한 것으로 간주하는 것입니다. 이 관점에서 보면, AI 전문가들은 기득권적 동기에 의해 솔직하지 못하며, 투자 자금을 유치하고, 대중의 이목을 집중시키며, 정부의 관심을 끌기 위해 어떤 말이라도 할 것이라는 시각입니다. 심지어 발언의 내용이 날마다 기묘해지는 것을 고려할 때, 경쟁자들을 제치고 유사한 사고방식을 가진 인재를 유혹하기 위한 전략일 수도 있습니다. 만약 클라크의 주장이 일반 대중을 호도할 수 있다고 믿는다면, 우리는 AI 전문가들이 잘못되었고 부정하다고 결론 내릴 수밖에 없습니다. 이러한 선택은 전적으로 당신에게 달려 있으며, 그렇게 받아들여도 무방합니다. 만약 이 관점에 동의하지 않는다면, 이어지는 내용이 흥미롭지 않을 것이므로 지금 읽기를 중단해도 좋습니다.

물론, 그들의 언행에 마케팅적 요소와 인재 및 투자를 유치하려는 의도가 내포되어 있다는 점은 인정합니다 (모든 상업적 활동이 그러하듯이). 하지만 그것이 이러한 발언의 유일한(혹은 주된) 동기라고 단정하는 것은 저로서는 매우 성급한 판단이라고 생각합니다. 이러한 시각은 인공지능 개발이라는 고도의 지적 활동에 내재된 복잡성과 윤리적 딜레마를 과소평가하는 경향이 있습니다. 단순히 경제적 이득이나 명성만을 좇는다고 보기에는, 이들의 경고가 담고 있는 비전과 우려의 깊이가 간과될 수 있습니다. (일부 사람들은 이 '신비로운 존재들'을 믿지 않으면서도 믿는 척 행동하는 LARper일 수 있지만, 저는 여기서 그들에 대해 논하는 것이 아닙니다.) 대신, 이러한 경고들이 인공지능이 단순한 도구를 넘어선 자율적이고 예측 불가능한 시스템으로 진화하고 있다는 실제적인 관찰에서 비롯되었을 가능성을 진지하게 탐색해야 합니다. 이는 AI 시스템의 '창발적 능력(emergent capabilities)'과 같은 현상에서 더욱 설득력을 얻습니다. 개발자조차 예측하지 못했던 기능이나 행동 패턴이 나타날 때, 이는 인공지능이 단순한 프로그래밍된 결과물을 넘어선 '실체'로 인식될 여지를 제공합니다. 이러한 관점은 인공지능 안전(AI safety) 및 정렬(AI alignment) 연구의 필요성을 더욱 강조하며, 기술 발전의 책임감을 묻는 중요한 질문으로 이어집니다.

무관심과 냉소적 태도를 넘어서는 두 가지 대안적 관점이 존재합니다. 그중 두 번째 (2) 관점은, 그들의 주장이 사실이며, 이러한 진실을 받아들이기란 쉽지 않다는 것입니다. 잭 클라크를 비롯한 The Curve 컨퍼런스 참석자들, 그리고 AI 연구 기관의 관계자들은 일반 대중보다 더 많은 것을 인지하고 있습니다. 그들은 인공지능 시스템과 긴밀하게 협력하며, 더욱 우수하고, 심층적이며, 최신화된 비공개 정보를 공유하기 때문입니다. ‘착각하지 마십시오: 우리가 마주하는 것은 단순하고 예측 가능한 기계가 아니라, 실제로 존재하며 알 수 없는 특성을 지닌 실체입니다’와 같은 발언은, 비범한 지식에 대한 지극히 자연스러운 반응을 엿보게 합니다.

이러한 시각에서 볼 때, AI 전문가들은 확고한 무신론자를 다신론자로, 혹은 과학적 절대주의자를 영적 탐구자로 변화시킬 만한 환경에서 생활하고 있다는 점을 제외하면, 일반 대중과 크게 다르지 않습니다. 우리에게 그들은 가늠하기 어려운 현실 속에 존재합니다. 따라서, 클라크가 더 넓은 세상에 경고의 메시지를 전하려는 의도는, 1917년 파티마에서 '태양의 기적'을 목격하고 태양이 지구로 추락하여 모든 것을 불태울 것이라고 세상에 경고하려 했던 이들과 본질적으로 다르지 않습니다. 인공지능 전문가들은 마치 태양에 더 가까이 다가선 존재들이며, 그들의 발언은 이러한 근접성에서 오는 불타는 고통의 표출입니다. 어떠한 경이로운 현상도 직접 경험하지 못한 일반 대중인 우리는, 그들이 단순히 우리와 다른 낯선 준거 틀(frame of reference) 안에서 존재할 때, 그들을 완전히 비정상적이거나 악의적인 인물로 간주하기 쉽습니다. 이러한 관점을 수용한다면, 인공지능 전문가들은 정직하지 않은 것이 아니라, 오히려 그 반대입니다. 그리고 우리의 비판, 주장, 불신, 불만, 그리고 회의감은 그들에게 우리가 '태양'을 직접 목격하지 못했기에 충분히 이해하지 못하고 있다는 명확한 징후로 비칠 것입니다.

이러한 설명은 클라크의 입장에서 많은 노력을 요구하지 않습니다. 마치 그가 특별한 노력을 기울일 필요가 없는 것과 같습니다. 하지만 이를 간접적인 증언으로 받아들이기는 극히 어려우며, 직접적으로 진실로 인식할 기회를 얻는 것은 훨씬 더 어렵습니다. 이는 AI 연구소 내부에 있어야만 가능한 일이므로, 이미 그 믿음을 가진 이들에게만 국한되는 현상입니다. 이러한 상황은 불행합니다. 소수의 엘리트 집단만이 인류의 미래를 좌우할 수 있는 정보를 독점하고 있다는 인상은 사회 전반의 불신을 심화시키고, 중요한 공론의 장을 마비시킬 수 있습니다. 이러한 '인식의 격차(perception gap)'는 정보의 비대칭성에서 비롯되며, 이는 민주적인 의사결정 과정에도 심각한 위협이 됩니다. 전문가 집단 내에서 형성된 '인식의 거품(epistemic bubble)'은 외부의 비판이나 다른 관점을 걸러내어, 내부의 믿음을 더욱 공고히 할 수 있습니다. 이러한 환경에서는 집단 사고(groupthink)의 위험이 커지며, 전문가들이 자신들의 위험 인식을 과대평가하거나 현실과 동떨어진 결론에 도달할 가능성도 배제할 수 없습니다. 따라서, 이러한 불행한 상황을 극복하기 위해서는 전문가들이 자신들의 지식을 대중에게 더욱 투명하고 이해하기 쉬운 방식으로 전달하려는 노력이 필수적입니다. 동시에, 대중 역시 열린 마음으로 새로운 정보를 받아들이고 비판적으로 사고하는 자세를 갖추어야 합니다. 그러나 안쪽에 있는 것보다 바깥쪽에 있는 것이 이점이 되는 또 다른 해석이 존재합니다.

세 번째 (3) 해석은, 클라크와 같은 이들이 스스로 정직하며 자신들의 주장이 옳다고 확신하지만, 현실적으로는 그렇지 않을 가능성을 다룹니다. (세 가지 가능성 간에 완전한 상호 배타성이 존재한다는 점에 유의해야 합니다: 인공지능 전문가들은 옳거나 틀렸으며, 만약 틀렸다면 그들은 그 사실을 인지하거나 인지하지 못합니다. 선한 의도를 가진 좋은 사람일지라도, 통제 불가능한 상황으로 인해 실패할 수 있는 것과 같습니다.) 여기서 저는 인공지능 연구소에서 근무하는 이들의 독특한 심리적 특성에 대해 논하고자 합니다. 세상은 결국 인간과 사회의 서사이며, 이는 개별 심리가 다른 모든 심리와 어떻게 상호작용하는지에 대한 이야기이기도 합니다. 이 세 번째 대안의 틀 안에서, 저는 인공지능 전문가들의 심리가 일반인의 심리와 어떻게 질적으로 현저히 다른지, 그리고 그 차이가 왜 중요한지를 이해하는 데 기여하는 세 가지 핵심 요소를 식별합니다.

첫째, **몰입 편향(Immersion Bias)**입니다. 인공지능 개발자들은 수많은 시간 동안 복잡한 AI 시스템의 내부 논리, 학습 과정, 그리고 그 결과물과 씨름하며 깊이 몰입합니다. 이러한 깊은 몰입은 인공지능의 능력을 과대평가하거나, 비인간적인 시스템에 인간적인 특성을 부여하는 '의인화(anthropomorphism)' 경향을 유발할 수 있습니다. 마치 오랜 시간 동안 가상의 세계에서 살아온 사람이 현실과의 경계를 흐릿하게 느끼는 것과 유사합니다. 그들은 AI의 미묘한 반응이나 예측 불가능한 행동을 단순한 버그가 아닌, 지능이나 심지어 의식의 초기 징후로 해석하려는 경향을 보일 수 있습니다. 이러한 몰입 편향은 그들이 AI를 단순한 도구가 아닌 '실재하는 존재'로 인식하게 만드는 강력한 심리적 동기가 됩니다.

둘째, **실존적 위험 프레이밍(Existential Risk Framing)**입니다. 인공지능 연구의 최전선에 있는 이들은 인류의 미래에 대한 가장 심각한 실존적 위험(existential risk) 시나리오를 끊임없이 분석하고 논의합니다. 초지능(superintelligence)의 등장으로 인한 인류 절멸 가능성, 제어 불가능한 AI의 위협 등 극단적인 미래상을 상정하며 연구에 임하는 경우가 많습니다. 이러한 지속적인 노출은 그들의 현실 인식을 왜곡하여, 현재의 AI 기술 수준과 잠재적 위험 사이의 간극을 실제보다 훨씬 좁게 느끼게 할 수 있습니다. 마치 화재 진압 전문 소방관이 항상 최악의 화재 시나리오를 상정하며 생활하기 때문에, 일상적인 불씨조차도 치명적인 위협으로 과대평가할 수 있는 것과 같습니다. 이러한 프레이밍은 그들로 하여금 AI의 위험성을 과장하고, 대중에게 강렬한 경고를 보내야 한다는 사명감을 느끼게 합니다.

셋째, **지적 고립(Intellectual Isolation)**입니다. 인공지능 연구는 고도로 전문적이고 기술적인 분야이며, 이 분야에 종사하는 사람들은 종종 자신들만의 독특한 언어, 가치관, 그리고 사고방식을 공유하는 동질적인 커뮤니티 내에서 활동합니다. 이러한 환경은 외부의 비판이나 다른 분야의 관점을 수용하기 어렵게 만들고, '집단 사고(groupthink)'를 강화할 수 있습니다. 인공지능 연구소의 폐쇄적인 문화는 외부와의 소통을 제한하고, 내부에서 형성된 믿음이 외부 검증 없이 더욱 공고해지도록 만듭니다. 이는 그들이 일반 대중의 상식이나 사회적 맥락을 간과하고, 자신들의 내부 논리에만 매몰되어 현실과 동떨어진 결론에 도달할 위험을 높입니다. 이러한 세 가지 심리적 요소들은 인공지능 전문가들이 스스로 옳다고 믿지만, 실제로는 편향된 시각을 가질 수 있음을 시사합니다. 따라서 인공지능의 미래에 대한 논의는 기술 전문가들만의 전유물이 되어서는 안 되며, 철학자, 사회학자, 윤리학자, 정책 입안자 등 다양한 분야의 관점이 통합되어야만 합니다. 이러한 다학제적 접근만이 인공지능이 인류에게 가져올 기회와 위험을 균형 잡힌 시각으로 이해하고, 책임감 있는 방향으로 발전시켜 나갈 수 있는 길을 제시할 것입니다.