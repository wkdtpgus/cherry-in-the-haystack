Anthropic의 공동 창립자이자 정책 책임자인 잭 클라크(Jack Clark)는 AI 연구 분야에서 선두 주자 중 하나인 Import AI 뉴스레터를 통해 다음과 같은 글을 공유했습니다 (이 내용은 2025년 10월 첫째 주 버클리에서 열린 The Curve 컨퍼런스에서 그가 발표한 첫 단락이기도 합니다).

**I.**
어렸을 때 불이 꺼진 후 침실을 둘러보면 어둠 속에서 형체를 보았고, 해를 끼치려는 이해할 수 없는 존재들이라고 생각하며 두려워했던 기억이 납니다. 그래서 저는 불을 켰습니다. 불을 켜자 그 존재들은 의자 위의 옷 더미, 책장, 또는 램프 갓으로 밝혀져 안도했습니다. 이제 2025년, 우리는 그 이야기 속의 아이이고 방은 우리의 행성입니다. 그러나 불을 켰을 때 우리는 오늘날의 강력하고 다소 예측 불가능한 AI 시스템과 앞으로 등장할 시스템의 형태로 진정한 존재들을 응시하고 있는 자신을 발견합니다. 그리고 많은 사람들은 이 존재들이 의자 위의 옷 더미, 책장, 또는 램프 갓에 불과하다고 필사적으로 믿고 싶어 합니다. 그리고 그들은 우리가 불을 끄고 다시 잠들기를 원합니다. 사실, 어떤 사람들은 당신에게 이것을 설득하기 위해 엄청난 돈을 쓰고 있습니다 – 그것은 급격한 발전(hard takeoff)을 앞둔 인공지능이 아니라, 우리 경제에 활용될 도구일 뿐이라고 말입니다. 그것은 단지 기계일 뿐이며, 기계는 우리가 통제하는 것입니다. 그러나 착각하지 마십시오: 우리가 다루고 있는 것은 단순하고 예측 가능한 기계가 아니라, 실재하고 신비로운 존재입니다.

클라크의 이러한 언급은 구글 딥마인드, OpenAI, xAI 등 주요 AI 연구소 내부 관계자들 사이에서 일반적인 시각입니다. 실제로 그들은 수년 동안 AI 전문가들의 견해가 일반 대중의 인식과 현저하게, 그리고 점점 더 벌어지고 있다고 꾸준히 경고해 왔습니다. 대중이 AI의 잠재적 위험성에 대해 "거품"이라는 표현을 쓰는 동안, 연구자들은 "종말 게임(endgames)"과 같은 심각한 시나리오를 논의하고 있습니다. AI의 급격한 발전 가능성에 대해 대중이 "정서적으로 준비되어 있지 않다"는 것이 그들의 핵심 주장입니다.

클라크는 우리가 불을 켰을 때 마주하는 것이 무해한 옷 더미가 아니라, 어둠 속에서 움직이던 실재하는 존재들이라고 비유합니다. 그는 AI가 단순한 도구나 기계를 넘어선 "이상"의 존재임을 강조합니다. (여기서 저는 그 "이상"이 인류에게 긍정적인지 부정적인지에 대한 논쟁에 참여하기보다는, AI가 근본적으로 "이상"이라는 믿음에 초점을 맞출 것입니다.)

AI 개발에 참여하는 이들로부터 클라크와 같은 발언을 접했을 때, 우리는 이를 무시하는 것 외에 세 가지 방식의 해석을 시도할 수 있습니다. 무시하는 것은 많은 이들이 선택하는 방식이지만, 이는 현명한 접근법이라고 보기는 어렵습니다. 첫 번째 해석 (1)은 가장 흔하고, 또한 가장 손쉬운 방식입니다. 바로 이러한 발언들을 단순한 마케팅 전략으로 치부하거나, 쉽게 이해할 수 있는 평범한 동기에서 비롯된 것으로 간주하는 것입니다. 이러한 관점에서 보면, AI 전문가들은 기득권적 동기로 인해 솔직하지 못하며, 투자 유치, 대중의 관심 확보, 정부의 규제 시선 회피, 또는 심지어 갈수록 과감해지는 발언들을 통해 경쟁사보다 우수한 인재를 유인하기 위해 무슨 말이든 할 수 있다고 봅니다. 만약 클라크의 주장이 일반 대중을 호도할 수 있다고 믿는다면, AI 전문가들이 틀렸고 나쁘다고 결론 내리는 것이 합리적입니다. 이러한 선택은 전적으로 당신의 몫이며, 그렇게 받아들여도 무방합니다. 만약 이러한 관점을 취하신다면, 이어지는 내용은 흥미롭지 않을 것이므로 지금 읽기를 중단하셔도 좋습니다. 저는 그들의 말과 행동에 마케팅적 요소와 인재 및 투자를 유치하려는 부분이 있다고 믿습니다 (모든 비즈니스 활동이 그러하듯이). 그러나 그것만이 이러한 발언의 유일한(또는 주된) 이유라고 단정하는 것은 매우 경솔한 태도라고 생각합니다. (물론 일부는 'LARPer'입니다. 즉, 이 "신비로운 존재들"을 실제로 믿지 않으면서도 믿는 척 행동하는 사람들이지만, 여기서 제가 이야기하려는 대상은 아닙니다.)

**II.**
저는 무관심과 냉소주의를 넘어서는 두 가지 대안적 해석을 제시합니다. 두 번째 (2) 해석은 클라크와 같은 AI 전문가들의 주장이 단순히 옳다는 것입니다. 이는 받아들이기 쉽지 않은 진실일 수 있습니다. 잭 클라크, 그리고 The Curve 컨퍼런스에 참석했던 이들, 그리고 AI 연구소의 직원들처럼 인공지능과 밀접하게 일하는 사람들은 우리보다 더 많은 것을 알고 있습니다. 그들은 최신의, 더 풍부하며, 비공개적인 정보를 지속적으로 교환하기 때문입니다. "착각하지 마십시오: 우리가 다루고 있는 것은 단순하고 예측 가능한 기계가 아니라, 실재하고 신비로운 존재입니다"와 같은 발언을 들을 때, 당신은 그들의 비범한 지식에 대한 지극히 정상적인 반응을 엿보는 것입니다.

이러한 시각에서 보면, AI 전문가들은 확고한 무신론자를 다신론자로, 또는 과학 절대주의자를 영성적 신념을 가진 사람으로 변화시킬 만한 환경에서 살고 있다는 점을 제외하고는 일반 대중과 크게 다르지 않습니다. 우리에게 그들은 상상하기 어려운 현실 속에 존재합니다. 따라서, 클라크가 더 넓은 세상에 메시지를 전달하려는 의도는 1917년 파티마에서 태양의 기적을 목격하고 태양이 지구로 떨어져 우리 모두를 태워버릴 것이라고 세상에 경고하려 했던 사람들의 마음과 다르지 않습니다. AI 전문가들은 마치 태양에 더 가까이 존재하며, 그들의 이러한 발언들은 그들이 겪는 불타는 고통의 표현인 셈입니다. 어떤 기적도 직접 목격하지 못한 일반 대중인 우리는, 그들이 단순히 낯선 준거 틀(frame of reference) 속에서 존재할 때, 그들을 완전히 미쳤거나 악의적인 악당으로 오해하기 쉽습니다.

이러한 입장을 받아들인다면, AI 전문가들은 정직하지 않은 것이 아니라 오히려 그 반대입니다. 그리고 우리의 논평, 발언, 불신, 불만, 그리고 불신은 그들에게 우리가 태양을 보지 않기 때문에 충분히 알지 못한다는 명확한 증상입니다. 이 설명은 저의 입장에서 많은 노력을 필요로 하지 않습니다. 클라크가 노력할 필요가 없는 것과 마찬가지로 말입니다. 이를 간접적인 증언으로 받아들이는 것은 극히 어렵고, 직접적으로 진실로 인지할 기회를 갖는 것은 훨씬 더 어렵습니다. AI 연구소 안에 있어야만 하므로, 이미 그것을 믿는 사람들에게만 국한됩니다. 불행한 상황입니다. 그러나 안쪽에 있는 것보다 바깥쪽에 있는 것이 이점이 되는 또 다른 해석이 있습니다.

**III.**
세 번째 (3) 해석은 클라크와 같은 사람들이 정직하고 자신들이 옳다고 생각하지만, 실제로는 그럴 수 없다는 것입니다. (세 가지 가능성 사이에 완전한 배타성이 있다는 점을 주목하십시오: AI 전문가들은 옳거나 옳지 않으며, 옳지 않다면 그들은 그것을 알거나 모릅니다. 당신은 선을 행하려는 좋은 사람일 수 있지만, 통제할 수 없는 상황 때문에 여전히 실패할 수 있습니다.) 저는 여기서 AI 연구소에서 일하는 사람들의 독특한 심리를 언급하는 것입니다. 왜냐하면 세상은 사람과 사회의 이야기이며, 이는 다시 각 심리가 다른 모든 심리와 어떻게 관련되는지에 대한 이야기이기 때문입니다. 이 세 번째 대안 내에서, 저는 AI 전문가들의 심리가 일반인의 심리와 어떻게 크게 다른지 (이는 질적 분석입니다) 그리고 왜 그것이 중요한지를 이해하는 데 도움이 되는 세 가지 부분을 식별합니다.

첫째, AI 연구의 특성상 그들은 현실과 잠재적 미래 사이의 경계에 서 있습니다. 매일같이 인간 지능의 한계를 넘어서는 모델과 씨름하며, 이들의 능력과 예측 불가능성을 직접 경험합니다. 이러한 몰입적인 환경은 그들에게 AI가 단순한 도구가 아니라는 본능적인 인식을 심어줄 수 있습니다. 둘째, AI 연구 커뮤니티 내의 강한 유대감과 정보 공유는 특정 관점, 특히 AI의 위험성에 대한 시각을 강화하는 경향이 있습니다. 외부의 시선과 단절된 채 내부에서 공유되는 정보와 경험은 집단사고(groupthink)로 이어질 수 있으며, 이는 그들의 견해를 더욱 확고하게 만들지만, 동시에 외부 현실과의 괴리를 초래할 수도 있습니다. 셋째, 그들의 작업은 본질적으로 추상적이고 미래 지향적입니다. 일반 대중이 당장 눈앞의 AI 활용 사례에 집중할 때, 이들은 수십 년 후의 잠재적 시나리오, 즉 AI가 사회 전반에 미칠 장기적인 영향에 깊이 천착합니다. 이러한 시간적 관점의 차이는 그들이 AI를 바라보는 방식에 근본적인 영향을 미치며, 그들의 경고가 단순한 기우가 아닐 수 있다는 가능성을 열어둡니다. 이처럼 AI 개발자들의 독특한 심리적 배경을 이해하는 것은 그들의 발언을 단순히 무시하거나 맹목적으로 추종하는 것을 넘어, 보다 균형 잡힌 관점에서 AI의 미래를 논의하는 데 필수적입니다.