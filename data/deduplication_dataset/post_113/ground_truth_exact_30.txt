**I.**
Anthropic의 공동 창립자이자 정책 책임자인 잭 클라크(Jack Clark)는 최고의 AI 연구소 중 하나인 Import AI 뉴스레터 최신호에 제가 아래에 인용한 글을 썼습니다 (이 글은 2025년 10월 첫째 주 버클리에서 열린 The Curve 컨퍼런스에서 그가 연설한 첫 단락이기도 합니다): 어렸을 때 불이 꺼진 후 침실을 둘러보면 어둠 속에서 형체를 보았고, 해를 끼치려는 이해할 수 없는 존재들이라고 생각하며 두려워했던 기억이 납니다. 그래서 저는 불을 켰습니다. 불을 켜자 그 존재들은 의자 위의 옷 더미, 책장, 또는 램프 갓으로 밝혀져 안도했습니다. 이제 2025년, 우리는 그 이야기 속의 아이이고 방은 우리의 행성입니다. 그러나 불을 켰을 때 우리는 오늘날의 강력하고 다소 예측 불가능한 AI 시스템과 앞으로 등장할 시스템의 형태로 진정한 존재들을 응시하고 있는 자신을 발견합니다. 그리고 많은 사람들은 이 존재들이 의자 위의 옷 더미, 책장, 또는 램프 갓에 불과하다고 필사적으로 믿고 싶어 합니다. 그리고 그들은 우리가 불을 끄고 다시 잠들기를 원합니다. 사실, 어떤 사람들은 당신에게 이것을 설득하기 위해 엄청난 돈을 쓰고 있습니다 – 그것은 급격한 발전(hard takeoff)을 앞둔 인공지능이 아니라, 우리 경제에 활용될 도구일 뿐이라고 말입니다. 그것은 단지 기계일 뿐이며, 기계는 우리가 통제하는 것입니다. 그러나 착각하지 마십시오: 우리가 다루고 있는 것은 단순하고 예측 가능한 기계가 아니라, 실재하고 신비로운 존재입니다. 클라크의 말은 AI 연구소(구글 딥마인드, OpenAI, xAI 등) 내부 사람들 사이에서 드문 일이 아니라 일반적인 견해입니다. 그들은 몇 주 동안 (사실은 몇 년 동안이지만, 저는 구체적으로 말하고 싶습니다) AI 전문가들의 견해가 일반 대중의 견해와 급격하고 점점 더 벌어지고 있다고 경고해 왔습니다. 그들은 세상이 거품(이봐, 그게 나야!)에 대해 이야기하는 동안, 자신들은 "종말 게임(endgames)"에 대해 이야기한다고 말합니다. 우리가 그 거품이 사실은 거품이 아닐 가능성에 대해 "정서적으로 준비되어 있지 않다"는 것입니다. 클라크는 우리가 불을 켰을 때 무해하고 중요하지 않은 것으로 판명되는 옷 더미가 아니라, 어둠 속에서 움직이는 실재하는 존재들을 다루고 있다고 말합니다 (이 비유는 괜찮다고 생각합니다). 그들은 AI가 단순한 도구나 기계가 아니라 그 이상이라고 말합니다. (저는 그 "이상"이 우리에게 좋은지 나쁜지에 대한 논쟁에 참여하지 않고, AI가 애초에 "이상"이라는 믿음에 초점을 맞출 것입니다.) AI를 개발하는 모든 사람들로부터 클라크와 같은 발언에 직면했을 때, 우리는 그것을 무시하는 것 외에 세 가지 해석적 선택지가 있습니다. 무시하는 것은 대부분의 사람들이 하는 일이지만, 태만에 가깝지 않더라도 특별히 현명한 방법은 아닙니다. 첫 번째 해석 (1)은 그 다음으로 가장 인기 있고, 또한 그 다음으로 가장 게으른 해석입니다: 이 말들을 마케팅으로 치부하거나, 비슷하게 (그리고 쉽게 이해되는) 평범한 목표를 위한 것으로 간주하는 것입니다. 이러한 관점에서, AI 전문가들은 기득권적 동기 때문에 정직하지 못하며, 투자자들의 돈을 얻고, 대중의 관심을 끌고, 정부의 시선을 사로잡기 위해 무슨 말이든 할 것이며, 심지어 발언이 날마다 더 이상해지는 것을 감안할 때, 경쟁을 희생시키면서 같은 생각을 가진 인재를 유인하기 위한 것일 수도 있습니다. 이러한 관점은 현재 AI 산업을 둘러싼 엄청난 과대광고와 자금 유치 경쟁을 고려할 때 충분히 설득력이 있습니다. 마치 새로운 기술 혁명이 일어날 때마다 반복되는 현상처럼, AI 기업들은 투자자들의 기대를 충족시키고 잠재 고객의 이목을 끌기 위해 최신 모델(예: OpenAI의 Sora, Google의 Gemini, Anthropic의 Claude 등)의 놀라운 성능을 강조합니다. 하지만 모든 발언을 단순히 마케팅 전략으로만 치부하는 것은 AI 기술의 본질적 변화와 그로 인한 실제적인 위험을 간과할 수 있습니다. AI 안전(AI safety) 및 정렬(alignment) 연구에 대한 강조는 단순한 마케팅을 넘어선 진정한 우려를 반영하는 경우가 많습니다. 클라크의 말이 일반 대중을 오도할 수 있다고 믿는 한, AI 전문가들은 틀렸고 나쁘다고 결론 내려야 합니다. 선택은 당신에게 달려 있으며, 그렇게 받아들여도 괜찮습니다. 우리는 동의하지 않으며, 이어지는 내용이 당신에게 흥미롭지 않을 것이므로 지금 읽기를 중단해도 좋습니다. 저는 그들이 하는 말과 행동에 마케팅과 인재 및 투자를 유치하려는 부분이 있다고 믿습니다 (모든 비즈니스 거래에서 그렇듯이). 그러나 그것이 이러한 발언 뒤에 있는 유일한 이유(또는 주된 이유)라고 가정하는 것은 저에게는 매우 경솔한 일입니다. (어떤 사람들은 LARper입니다. 즉, 그들은 이 "신비로운 존재들"을 믿지 않으면서도 믿는 척 행동하지만, 저는 여기서 그들에 대해 이야기하는 것이 아닙니다.)

**II.**
저는 무관심과 냉소주의에 대한 두 가지 대안을 봅니다. 두 번째 (2) 해석은 단순히 그들이 옳다는 것이며, 이는 진실을 받아들이기 어렵게 만듭니다. 잭 클라크와 The Curve 컨퍼런스 참석자들, 그리고 AI 연구소 직원들과 같은 사람들은 우리보다 더 많이 알고 있습니다. 그들은 AI와 밀접하게 작업하며, 더 좋고, 풍부하며, 업데이트된 비공개 정보를 교환하기 때문입니다. “착각하지 마십시오: 우리가 다루고 있는 것은 단순하고 예측 가능한 기계가 아니라, 실재하고 신비로운 존재입니다”와 같은 발언을 들을 때, 당신은 그 비정상적인 지식에 대한 정상적인 반응을 엿보는 것입니다. 이러한 "내부자"의 관점은 일반 대중이 접하기 어려운 AI 모델의 심오하고 예측 불가능한 특성을 목격하면서 형성됩니다. 예를 들어, 최신 거대 언어 모델(LLM)이나 다중 모달 AI(multimodal AI)는 단순히 입력된 데이터를 처리하는 것을 넘어, 예상치 못한 방식으로 새로운 능력을 발현(emergent abilities)하거나, 개발자조차 완전히 이해하기 어려운 "블랙박스(black box)"처럼 작동하기도 합니다. AI 시스템이 점점 더 자율성을 띠고 복잡한 추론 과정을 보여주면서, 이들을 단순한 도구로만 치부하기 어렵다는 내부자들의 주장은 설득력을 얻습니다. 이러한 관점에서, AI 전문가들은 확고한 무신론자를 다신론자로, 또는 과학 절대주의자를 영성 히피로 바꿀 만한 조건 아래 살고 있다는 점을 제외하고는 일반 대중과 다를 바 없습니다. 우리에게 그들은 헤아릴 수 없는 현실 속에서 살고 있습니다. 따라서, 클라크가 더 넓은 세상에 메시지를 전달하려는 의도는 1917년 파티마의 태양 기적을 목격하고 태양이 지구로 떨어져 우리 모두를 태워버릴 것이라고 세상에 경고하려 했던 사람들과 다르지 않습니다. AI 전문가들은 태양에 더 가까이 존재하며, 이러한 발언들은 그들의 불타는 고통입니다. 어떤 기적도 목격하지 못한 일반 대중인 우리는, 그들이 단순히 낯선 준거 틀(frame of reference) 속에서 존재할 때, 그들을 완전히 미쳤거나 악의적인 악당으로 볼 것입니다. 이러한 입장을 받아들인다면, AI 전문가들은 정직하지 않은 것이 아니라 정반대입니다. 그리고 우리의 논평, 발언, 불신, 불만, 그리고 불신은 그들에게 우리가 태양을 보지 않기 때문에 충분히 알지 못한다는 명확한 증상입니다. 이 설명은 저의 입장에서 많은 노력을 필요로 하지 않습니다. 클라크가 노력할 필요가 없는 것과 마찬가지로 말입니다. 이를 간접적인 증언으로 받아들이는 것은 극히 어렵고, 직접적으로 진실로 인지할 기회를 갖는 것은 훨씬 더 어렵습니다. AI 연구소 안에 있어야만 하므로, 이미 그것을 믿는 사람들에게만 국한됩니다. 불행한 상황입니다. 그러나 안쪽에 있는 것보다 바깥쪽에 있는 것이 이점이 되는 또 다른 해석이 있습니다.

**III.**
세 번째 (3) 해석은 클라크와 같은 사람들이 정직하고 자신들이 옳다고 생각하지만, 실제로는 그럴 수 없다는 것입니다. (세 가지 가능성 사이에 완전한 배타성이 있다는 점에 주목하십시오: AI 전문가들은 옳거나 옳지 않으며, 옳지 않다면 그들은 그것을 알거나 모릅니다. 당신은 선을 행하려는 좋은 사람일 수 있지만, 통제할 수 없는 상황 때문에 여전히 실패할 수 있습니다.) 저는 여기서 AI 연구소에서 일하는 사람들의 독특한 심리를 언급하는 것입니다. 왜냐하면 세상은 사람과 사회의 이야기이며, 이는 다시 각 심리가 다른 모든 심리와 어떻게 관련되는지에 대한 이야기이기 때문입니다. 이 세 번째 대안 내에서, 저는 AI 전문가들의 심리가 일반인의 심리와 어떻게 크게 다른지 (이는 질적 분석입니다) 그리고 왜 그것이 중요한지를 이해하는 데 도움이 되는 세 가지 부분을 식별합니다. 첫째, 그들은 혁신과 발견의 최전선에서 일하는 "선구자"들입니다. 이러한 위치는 종종 강력한 확증 편향(confirmation bias)을 초래하여 자신들의 가설과 일치하는 증거에 더 큰 비중을 두게 만들 수 있습니다. 그들은 AI의 잠재적 위험에 대해 강한 믿음을 가지고 있을 수 있으며, 이 믿음을 뒷받침하는 현상에 과도하게 집중할 수 있습니다. 둘째, 그들은 고도로 경쟁적이고 고립된 환경에서 일합니다. 소수의 엘리트 연구소들이 엄청난 자본과 인재를 바탕으로 경쟁하며, 이러한 환경은 집단 사고(groupthink)를 유발하여 외부의 비판적 시각을 간과하게 만들 수 있습니다. 내부에서 공유되는 강한 신념과 비전은 외부인에게는 이해하기 어려운 방식으로 증폭될 수 있습니다. 셋째, AI 개발은 본질적으로 통제 불가능한 요소를 포함합니다. 강력한 AI 시스템은 예측 불가능한 방식으로 행동할 수 있으며, 이러한 복잡성과 불확실성에 대한 지속적인 노출은 연구자들에게 일종의 "신비로운 존재"에 대한 믿음을 심어줄 수 있습니다. 이러한 심리적 요인들이 결합하여, 선의의 AI 전문가들이 AI의 본질에 대해 진심으로 믿는 바가 실제 객관적 현실과는 다를 수 있다는 가능성을 시사합니다. 그들은 진심으로 인류를 보호하려 하지만, 그들의 관점 자체가 그들의 경험과 환경에 의해 형성된 편향을 가질 수 있습니다.

**결론:**
클라크의 발언과 같은 AI 전문가들의 경고를 이해하는 것은 결코 단순한 문제가 아닙니다. 우리는 그들의 말을 단순히 마케팅으로 치부하거나, 맹목적으로 받아들이거나, 혹은 그들의 독특한 심리적 상태에서 비롯된 것으로 간주할 수 있습니다. 중요한 것은 이 세 가지 해석 모두 나름의 타당성을 가지고 있으며, 어떤 하나의 관점만을 고수하는 것은 AI의 복잡한 현실을 완전히 이해하는 데 방해가 될 수 있다는 점입니다. 아마도 가장 현명한 접근 방식은 이 모든 해석의 가능성을 열어두고, AI의 발전과 그에 따른 사회적 함의에 대해 지속적으로 비판적이고 개방적인 자세를 유지하는 것입니다. AI 개발은 더 이상 소수의 연구실에만 국한될 문제가 아니며, 광범위한 대중의 관심과 참여를 통해 그 방향이 올바르게 설정되어야 할 것입니다.