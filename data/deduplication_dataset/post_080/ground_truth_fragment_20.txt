오늘 호에서는:

엔비디아(NVIDIA)가 유니버설 딥 리서치(Universal Deep Research)를 소개합니다
엔비디아(NVIDIA)가 새로운 AI 가속기를 소개합니다
오픈AI(OpenAI)가 GPT-4b 마이크로(micro)를 소개합니다
오픈AI(OpenAI)가 멀티모달 모델을 공개합니다
미스트랄(Mistral)이 르 챗(Le Chat)을 출시합니다
미스트랄(Mistral)이 LLM API를 출시합니다
맞춤형 MCP 커넥터(Custom MCP Connectors)
맞춤형 AI 솔루션(Custom AI Solutions)의 중요성
다중 에이전트(multi-agent) 실패 추적 연구
분산 에이전트(distributed agent) 협업 연구
LLM 사회 지능(Social Intelligence) 탐색
LLM 사회적 영향(Social Impact) 연구
음성 에이전트(voice agent) 프롬프팅(prompting) 팁
데이터 기반 의사 결정(data-driven decision-making) 팁
자가 진화 에이전트(Self-Evolving Agents) 설문조사
자가 학습 시스템(Self-Learning Systems) 설문조사
구글(Google)이 임베딩젬마(EmbeddingGemma)를 소개합니다
구글(Google)이 새로운 온디바이스(on-device) AI를 소개합니다
관점적 에이전트형 AI(aspective agentic AI)에 대한 새로운 연구
확장 가능한 AI(scalable AI) 시스템에 대한 새로운 연구
DAIR이 AI 에이전트 101(AI Agents 101) 단기 강좌를 출시합니다
DAIR이 AI 윤리 101(AI Ethics 101) 단기 강좌를 출시합니다
n8n과 함께하는 강좌
클라우드 플랫폼(cloud platform)과 함께하는 강좌
주요 AI 도구, 제품, 연구 업데이트 및 기술 동향, 산업 보고서.

**주요 소식**
**엔비디아(NVIDIA)가 유니버설 딥 리서치(Universal Deep Research)를 소개합니다**
사용자가 자체 모델과 전략을 가져올 수 있도록 하는 일반적이고 모델에 구애받지 않는(model-agnostic) 딥 리서치 에이전트(deep-research agent)를 제안합니다. 고정된 파이프라인(pipeline) 대신, 유니버설 딥 리서치(Universal Deep Research, UDR)는 자연어 연구 전략을 실행 가능한 코드(executable code)로 컴파일(compile)하고, 샌드박스(sandbox)에서 실행하며, 최종 보고서를 반환하기 전에 구조화된 진행 알림(structured progress notifications)을 내보냅니다.

**동기.** 현재의 딥 리서치 도구는 전략과 모델 선택을 하드코딩(hard-code)하여 소스 우선순위 지정, 도메인별 워크플로우(domain-specific workflows), 그리고 모델 교체 가능성(model swap-ability)을 제한합니다. UDR은 연구 전략을 기반 모델과 분리함으로써 이 세 가지 격차를 모두 해결합니다.

**메커니즘.** 사용자는 전략과 프롬프트(prompt)를 제공합니다. UDR은 엄격한 도구 및 제어 흐름(control-flow) 제약 조건 하에 전략을 단일 호출 가능 함수(callable function)로 변환한 다음, 이를 격리된 환경에서 실행합니다. 오케스트레이션(orchestration)은 순수한 코드(pure code)로 이루어지며, LLM은 요약, 순위 지정 또는 추출과 같은 로컬 작업에만 호출됩니다. 상태(state)는 증가하는 컨텍스트(context)가 아닌 명명된 변수(named variables)에 존재합니다.

**단계 및 도구.** 1단계는 건너뛰는 단계와 드리프트(drift)를 줄이기 위해 전략을 단계별로 컴파일(compile)합니다. 2단계는 실시간 UI 업데이트를 위해 동기식 도구 호출(synchronous tool calls)과 yield 기반 알림(yield-based notifications)으로 실행됩니다. 이 논문은 광범위한 적용 가능성을 보여주기 위해 최소한의, 확장적인, 그리고 집중적인 예시 전략들을 제공합니다.

**효율성 및 신뢰성.** 제어 로직(control logic)은 CPU에서 실행되는 반면, LLM 호출은 범위가 지정되고 드물게 발생하여 비용과 지연 시간(latency)을 개선합니다. 엔드투엔드(end-to-end) 전략 컴파일은 LLM이 자체적으로 오케스트레이션(orchestrate)하도록 프롬프팅(prompting)하거나 단계별 코드를 이어 붙이는 것보다 더 신뢰할 수 있음이 입증되었습니다.

**보안, UI 및 한계.** 전략은 프롬프트 인젝션(prompt-injection) 또는 코드 익스플로잇(code exploits)을 방지하기 위해 샌드박스(sandbox)에서 실행됩니다. 데모 UI는 전략 편집, 알림 모니터링 및 보고서 보기를 지원합니다. 한계점으로는 코드 생성 충실도(code-generation fidelity)에 대한 의존성, 실행 중 상호작용(interactivity) 불가, 그리고 사용자가 작성한 전략이 건전하다고 가정하는 점 등이 있습니다. 저자들은 편집 가능한 전략 라이브러리(library)를 제공하고 자유로운 추론(free reasoning)에 대한 사용자 제어를 강화하는 방안을 모색할 것을 권장합니다.

**엔비디아(NVIDIA)가 차세대 컴퓨팅 아키텍처를 공개합니다**
사용자가 자체 모델과 데이터셋을 활용할 수 있도록 하는 일반적이고 유연한(flexible) AI 개발 플랫폼을 제안합니다. 고정된 파이프라인(pipeline)의 한계를 넘어, 새로운 데이터 처리 방식을 통해 복잡한 분석을 효율적으로 수행하며, 최종 결과 보고서를 반환하기 전에 실시간 진행 알림(real-time progress notifications)을 내보냅니다.

**동기.** 현재의 데이터 분석 도구는 복잡한 데이터 통합과 모델 배포를 하드코딩(hard-code)하여 유연성과 확장성을 제한합니다. 이 새로운 아키텍처는 데이터 분석 전략을 기반 모델과 분리함으로써 이러한 복잡성을 해결합니다.

**메커니즘.** 사용자는 분석 목표와 필요한 데이터를 제공합니다. 이 플랫폼은 엄격한 보안 및 제어 흐름(control-flow) 제약 조건 하에 분석 전략을 모듈화된 워크플로우(workflow)로 변환한 다음, 이를 안전하고 효율적인 환경에서 실행합니다. 오케스트레이션(orchestration)은 최적화된 모듈로 이루어지며, AI 모델은 데이터 전처리, 패턴 인식 또는 예측과 같은 핵심 작업에만 호출됩니다. 상태(state)는 분산된 저장소(distributed storage)에 명명된 변수(named variables)로 존재합니다.

**단계 및 도구.** 데이터 처리의 첫 단계는 데이터 정제 및 이상치(outlier)를 줄이기 위해 전략을 단계별로 최적화합니다. 이후 단계는 실시간 UI 업데이트를 위해 비동기 처리와 알림 시스템으로 실행됩니다. 이 시스템은 광범위한 적용 가능성을 보여주기 위해 다양한 산업 분야의 예시 워크플로우(workflow)들을 제공합니다.

**효율성 및 신뢰성.** 분석 로직(analysis logic)은 GPU에서 가속화되는 반면, 데이터 입출력은 최적화되어 비용과 처리 시간(processing time)을 크게 개선합니다. 엔드투엔드(end-to-end) 시스템 통합은 개별 컴포넌트(component)를 수동으로 연결하거나 단계별 코드를 이어 붙이는 것보다 훨씬 더 신뢰할 수 있음이 입증되었습니다.

**보안, UI 및 한계.** 데이터 처리 파이프라인은 보안 취약점 또는 데이터 유출(data leakage)을 방지하기 위해 격리된 환경에서 실행됩니다. 직관적인 UI는 워크플로우 편집, 진행 상황 모니터링 및 최종 결과 보기를 지원합니다. 한계점으로는 복잡한 데이터 모델링의 난이도, 실시간 데이터 스트리밍(real-time data streaming)의 제약, 그리고 초기 설정의 복잡성 등이 있습니다. 개발팀은 확장 가능한 데이터 라이브러리(library)를 제공하고 사용자 맞춤형 기능을 강화하는 방안을 모색할 것을 권장합니다.

**논문**

**추가 자료**