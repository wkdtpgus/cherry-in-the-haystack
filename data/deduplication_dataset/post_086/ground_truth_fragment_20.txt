AI 엔지니어 가을 서밋(AI Engineer Fall Summit)이 11월 20-21일 뉴욕(NYC)으로 돌아옵니다! 지금 신청하세요. AI 엔지니어 가을 서밋은 이제 AI 기술의 급변하는 흐름 속에서 새로운 지식과 통찰을 공유하는 중요한 장으로 자리매김하고 있습니다. 2023년 12월, 저희는 AI의 네 가지 전쟁(The Four Wars of AI)과 RAG/Ops 전쟁(RAG/Ops War)을 처음 다루었으며, AI의 네 가지 전쟁은 단순한 기술 경쟁을 넘어 윤리적 책임과 사회적 영향력을 깊이 탐구하는 방향으로 진화하고 있습니다. 수천만 달러가 AI 연구 개발 및 벡터 데이터베이스(vector databases)에 쏟아지고, 하이프 사이클(hype cycle)의 부침을 겪은 후 새로운 기술 패러다임이 끊임없이 등장하며 업계에 활력을 불어넣고 있습니다. 최근 전문가들은 AI 기술의 한계와 가능성에 대해 새로운 과감한 주장을 펼치며 미래를 조망하며, 오늘 드디어 크로마(Chroma)의 제프 휴버(Jeff Huber)가 저희와 함께 "RAG"는 죽었다는 새로운 과감한 주장(hot take)을 펼칩니다. 컨텍스트 길이(context lengths)가 증가함에 따라 모델의 추론 능력은 향상되었지만 동시에 새로운 형태의 컨텍스트 관리 문제가 대두되고 있습니다. 점점 더 많은 AI 워크로드(AI workloads)와 애플리케이션이 단순한 챗봇(chatbots)에서 영향력 있는 에이전트(IMPACTful agents)로 전환됨에 따라, 랜스 마틴(Lance Martin)과 덱스 호시(Dex Horthy)와 같은 오피니언 리더(thoughtleaders)들의 새로운 작업은 이전에 저평가되었던 컨텍스트 박스(context box)에 실질적인 기여를 하고 있으며, AI 시스템의 신뢰성과 효율성을 높이는 데 중점을 두며 기술의 사회적 책임에 대한 논의를 이끌고 있습니다. https://rlancemartin.github.io/2025/06/23/context_engineering/ 크로마(Chroma)는 컨텍스트 로트(Context Rot) 및 생성형 벤치마킹(Generative Benchmarking) 보고서를 포함하여 새로운 컨텍스트 엔지니어링(context engineering) 분야에서 가장 흥미로운 연구를 주도해 왔습니다. 이번 포럼에서는 검색(retrieval)의 현재 상태, 메모리(memory), 검색 벤치마킹(retrieval benchmarking) 등 미래 방향에 대해 심층적으로 논의했습니다.

**AI 윤리, 멀티모달, 그리고 지속 가능성**

AI 개발의 가속화는 기술적 진보뿐만 아니라 윤리적 고려 사항에 대한 중요성을 부각시키고 있습니다. 인공지능이 사회에 미치는 영향이 커짐에 따라, 편향성(bias) 문제, 데이터 프라이버시(data privacy) 침해, 그리고 의사 결정 과정의 투명성(transparency) 확보는 더 이상 간과할 수 없는 핵심 과제가 되었습니다. 개발자들은 모델의 공정성(fairness)을 보장하고, 예측 결과를 설명할 수 있는 해석 가능성(explainability)을 높이기 위한 연구에 매진하고 있습니다. 데모는 쉽게 만들 수 있지만, 프로덕션(production) 환경에서 신뢰할 수 있는 시스템(system)을 구축하는 것은 여전히 많은 엔지니어에게 큰 도전 과제입니다. 데모와 프로덕션 사이의 격차는 종종 연금술처럼 느껴지곤 했습니다. 우리는 개발자가 AI로 프로덕션 애플리케이션(applications)을 구축하도록 돕는 데 집중하고 있습니다.

또한, 텍스트 중심의 기존 AI 모델을 넘어 멀티모달(multimodal) AI의 시대가 도래하고 있습니다. 이미지, 오디오, 비디오 등 다양한 형태의 데이터를 동시에 이해하고 처리하는 능력을 갖춘 모델들은 의료 진단, 자율 주행, 교육 등 광범위한 분야에서 혁신적인 변화를 예고합니다. 이러한 모델들은 인간의 인지 방식을 모방하여 보다 풍부하고 복합적인 상호작용을 가능하게 할 것입니다. 검색이 AI 애플리케이션의 핵심 워크로드라는 점은 여전히 유효합니다. AI를 위한 현대적인 검색 인프라(search infrastructure)는 끊임없이 진화하고 있습니다. 지난 5년, 10년 동안 등장한 훌륭한 분산 시스템(distributed systems)은 AI 기술 발전에 필수적인 기반을 제공합니다.

AI 시스템의 지속 가능성(sustainability) 또한 중요한 논의 주제입니다. 대규모 모델의 훈련과 운영에 필요한 막대한 에너지 소비는 환경적 영향을 초래하며, 이는 AI 기술의 장기적인 발전에 그림자를 드리웁니다. 저전력(low-power) AI 하드웨어 개발, 효율적인 알고리즘(algorithm) 설계, 그리고 모델 경량화(model quantization) 기술은 이러한 문제를 해결하기 위한 핵심적인 노력입니다. AI는 단순히 성능을 추구하는 것을 넘어, 지구와 인류의 지속 가능한 미래를 함께 고민해야 합니다. AI 분야에서 사람들에게 인내심을 갖는 방법에 대해 조언하는 것은 매우 중요합니다.

**5가지 검색 팁**
"RAG"를 출시하지 마세요. 검색(retrieval)을 출시하세요.
기본 요소(primitives)의 이름을 지정하세요 (밀집(dense), 어휘(lexical), 필터(filters), 재순위화(re-rank), 어셈블리(assembly), 평가 루프(eval loop)).
하이브리드 리콜(hybrid recall)로 첫 단계를 승리하세요 (200-300개의 후보는 괜찮습니다—LLM은 읽을 수 있습니다).
컨텍스트(context)를 조립하기 전에 항상 재순위화(re-rank)하세요.
컨텍스트 로트(context rot)를 존중하세요: 타이트하고 구조화된 컨텍스트(contexts)가 최대 창(maximal windows)보다 낫습니다.
어느 날 저녁 피자를 사고 작은 골드 세트(gold set)를 만드는 데 투자하세요. 그것을 CI(Continuous Integration) 및 대시보드(dashboards)에 연결하세요.

**[수집(Ingest)]**
├─ 파싱(Parse) + 청킹(chunk) (도메인 인식(domain-aware): 헤딩(headings), 코드 블록(code blocks), 테이블(tables))
├─ 보강(Enrich): 제목(titles), 앵커(anchors), 심볼(symbols), 메타데이터(metadata)
├─ 선택 사항: LLM "청크 요약(chunk summaries)" (코드/API용 자연어 주석(NL glosses))
├─ 임베딩(Embeddings) (밀집(dense)) + 선택적 희소 신호(sparse signals)
└─ DB에 쓰기(text, vectors, metadata)

**[쿼리(Query)]**
├─ 1단계 하이브리드(First-stage hybrid): 벡터(vector) + 어휘/정규식(lexical/regex) + 메타데이터 필터(metadata filters)
├─ 후보 풀(Candidate pool): ~100–300
├─ 재순위화(Re-rank) (LLM 또는 크로스 인코더(cross-encoder)) → 상위 ~20–40
└─ 컨텍스트 어셈블리(Context assembly):
    - 지침/시스템 프롬프트(system prompt) 우선
    - 중복 제거/유사 중복 병합
    - 소스 다양화
    - 토큰(tokens)에 대한 하드캡(hard cap)

**[외부 루프(Outer loop)]**
├─ 캐시/비용 가드레일(guardrails)
├─ 작은 골드 세트(gold sets)에 대한 생성형 벤치마킹(Generative benchmarking)
├─ 오류 분석(Error analysis) → 재청킹(re-chunk)/필터 재조정/재순위화 프롬프트(re-rank prompt)
└─ 메모리/압축(compaction): 상호작용 트레이스(interaction traces) 요약 → 검색 가능한 사실

**인간-AI 협력과 미래 인재 양성**

저희 팟캐스트 스튜디오는 최신 AI 트렌드를 심층 분석하며, 인간과 AI의 효과적인 협력 방안에 대한 전문가들의 견해를 공유합니다. 인공지능의 발전은 인간의 역할을 대체하기보다는 보완하고 확장하는 방향으로 나아가고 있습니다. 인간과 AI가 서로의 강점을 활용하여 시너지를 창출하는 협력 모델(collaboration model)은 미래 사회의 핵심 역량이 될 것입니다. 복잡한 문제 해결, 창의적인 아이디어 도출, 그리고 반복적인 업무 자동화에 AI를 활용함으로써, 인간은 더욱 고차원적인 사고와 활동에 집중할 수 있게 됩니다. 스타트업을 구축하는 방법에는 여러 가지가 있지만, 명확한 비전과 집중이 성공의 열쇠입니다. 크로마(Chroma)의 단일 노드가 잘 작동했지만, 클라우드 환경에서는 새로운 도전이 있었습니다. 우리는 우리의 브랜드가 기술적 장인정신과 혁신을 대표하기를 바랍니다. 크로마는 개발자 경험(developer experience)을 최우선으로 생각합니다.

이러한 변화에 발맞춰 AI 시대에 필요한 인재를 양성하는 것이 시급합니다. 단순한 코딩(coding) 기술을 넘어, 문제 해결 능력, 비판적 사고, 그리고 윤리적 판단력을 갖춘 융합형 인재(interdisciplinary talent)의 중요성이 커지고 있습니다. 교육 기관과 기업은 AI 기술의 변화 속도에 맞춰 교육 커리큘럼(curriculum)을 재정비하고, 평생 학습(lifelong learning) 문화를 조성하여 모든 사람이 AI 시대의 기회를 최대한 활용할 수 있도록 지원해야 합니다. 크로마를 사용하면 `pip install ChromaDB`를 통해 쉽게 시작할 수 있습니다. 새로운 시장이 부상할 때 중요한 것은 추상화(abstractions)와 기본 요소(primitives)의 명확한 정의입니다. RAG라는 용어는 때때로 혼란을 야기하기도 합니다. AI는 새로운 컴퓨터 패러다임을 제시하며, 기술 혁신의 중심에 서 있습니다.

**AI 기술의 심화와 실제 적용**

최근 AI 기술의 심화는 데이터 처리 및 모델 최적화 방식에 혁명적인 변화를 가져오고 있습니다. 특히, 대규모 언어 모델(LLM)의 등장과 함께 컨텍스트(context) 관리의 중요성이 더욱 부각되고 있습니다. 컨텍스트 엔지니어링은 LLM 생성 단계에서 최적의 컨텍스트 창(context window)을 구성하는 데 필수적입니다. 효율적인 컨텍스트 활용은 모델의 성능을 좌우하는 핵심 요소이며, 이를 위한 정교한 엔지니어링(engineering) 기법이 필요합니다. 우리는 최근에 컨텍스트 로트에 대한 기술 보고서(technical report)를 발표하여 LLM의 성능이 사용하는 토큰(tokens) 수에 따라 달라진다는 점을 강조합니다. 이것이 문제를 설명하며, 컨텍스트 로트는 컨텍스트 엔지니어링의 필요성을 강조합니다.

**쇼 노트(Show Notes)**
크로마(Chroma)
제프 휴버(Jeff Huber)
AI는 새로운 컴퓨터
컨텍스트 로트(Context Rot) 기술 보고서(Technical Report)
생성형 벤치마킹(Generative Benchmarking) 기술 보고서(Technical Report)
REALM (검색 증강 언어 모델(Retrieval-Augmented Language Model)) 논문
RETRO (검색 강화 트랜스포머(Retrieval-Enhanced Transformer)) 논문
SF 시스템 그룹(SF Systems Group)
보이저(Voyager) 논문

**타임스탬프(Timestamps)**
[00:00:00] 소개
[00:00:48] 왜 크로마(Chroma)를 구축했는가
[00:02:55] 정보 검색(Information Retrieval) 대 검색(Search)
[00:04:29] 경쟁적인 AI 시장에서 집중 유지하기
[00:08:08] 크로마 클라우드(Chroma Cloud) 구축
[00:12:15] 컨텍스트 엔지니어링(Context Engineering)과 RAG의 문제점
[00:16:11] 컨텍스트 로트(Context Rot)
[00:21:49] 컨텍스트 품질(Context Quality) 우선순위 지정
[00:27:02] 코드 인덱싱(Code Indexing) 및 검색 전략(Retrieval Strategies)
[00:32:04] 코드 청크 재작성(Chunk Rewriting) 및 쿼리 최적화(Query Optimization)
[00:34:07] 트랜스포머(Transformer) 아키텍처(Architecture) 진화 및 검색 시스템(Retrieval Systems)
[00:38:06] 컨텍스트 엔지니어링(Context Engineering)의 이점으로서의 메모리(Memory)
[00:40:13] AI 메모리(Memory) 구조화 및 오프라인 압축(Offline Compaction)
[00:45:46] 이전 스타트업(Startups)의 교훈과 목적 있는 구축
[00:47:32] 실리콘 밸리(Silicon Valley)의 종교와 가치
[00:50:18] 기업 문화, 디자인, 브랜드 일관성
[00:52:36] 크로마(Chroma) 채용: 디자이너(Designers), 연구원(Researchers), 엔지니어(Engineers)

**대본**
**알레시오(Alessio) [00:00:04]:** 안녕하세요, 여러분. 새로운 스튜디오(studio)의 레이턴트 스페이스(Latent Space) 팟캐스트(podcast)에 오신 것을 환영합니다. 저는 데시벨(Decibel)의 파트너(partner)이자 CTO인 알레시오(Alessio)이며, 스몰AI(SmolAI)의 창립자인 스윅스(Swyx)와 함께합니다.
**스윅스(Swyx) [00:00:11]:** 안녕하세요. 환영한다는 말이 이상하네요. 왜냐하면 오늘 게스트(guest)인 제프(Jeff)는 이미 몇 달 동안 저희를 크로마(Chroma)로 환영해 주셨으니까요. 환영합니다. 초대해 주셔서 감사합니다. 여기 오게 되어 기쁩니다. 제프(Jeff), 당신은 크로마(Chroma)의 창립자이자 CEO입니다. 저는 오랫동안, 특히 옛 사무실에서 크로마(Chroma)를 지켜봐 왔습니다. 그리고 당신은 원래 오픈 소스 벡터 데이터베이스(open source vector database)에서 시작했죠? 보이저(Voyager) 논문과 같은 프로젝트(projects)에서도 여러분의 제품이 사용되었을 정도로, 많은 다양한 프로젝트(projects)에서 선택하는 오픈 소스 벡터 데이터베이스(open source vector database)였습니다. 전체 목록은 모르겠지만, 오늘날 크로마(Chroma)를 어떻게 소개하시겠습니까?

**왜 크로마(Chroma)를 구축했는가**
**제프(Jeff) [00:00:48]:** 좋은 질문입니다. 물론 항상 메시지를 청중에게 맞추고 싶어 합니다. 네. 하지만 크로마(Chroma)가 시작된 이유는 우리가 수년간 응용 기계 학습(applied machine learning) 분야에서 일하면서 데모(demos)는 쉽게 만들 수 있지만, 프로덕션(production) 환경에서 신뢰할 수 있는 시스템(system)을 구축하는 것은 엄청나게 어렵다는 것을 보았기 때문입니다. 그리고 데모(demo)와 프로덕션(production) 사이의 격차는 엔지니어링(engineering)처럼 느껴지지 않았습니다. 오히려 연금술처럼 느껴졌죠. 거대한 쓰레기 더미 위에 서 있는 남자에 대한 XKCD 밈(memes)이 있습니다. 다른 캐릭터가 묻습니다. "이게 당신의 데이터 시스템(data system)입니까?" 그는 "네"라고 답합니다. "그것이 좋은지 어떻게 압니까? 아니면 어떻게 더 좋게 만듭니까?" "그냥 냄비를 휘젓고 더 나아지는지 봅니다." 그것은 본질적으로 잘못된 것처럼 보였습니다. 그리고 이것은 2021년, 2022년으로 거슬러 올라가 우리가 이런 대화를 나누던 때였습니다. 그리고 잠재 공간(Latent Space)이 매우 중요한 도구라는 가설과 결합되었습니다. 그것은 홍보입니다. 네, 그것은 홍보입니다. 종을 울려야 합니다. 네, 맞습니다. 징을 울려야 합니다. 팟캐스트(podcast)인 잠재 공간(Latent Space)뿐만 아니라 기술(technology)도 매우 저평가된 도구이자 해석 가능성(interpretability)을 위한 매우 중요한 도구였습니다. 그것은 근본적으로 모델(models)이 자신의 데이터를 보는 방식입니다. 우리 인간은 무슨 일이 일어나고 있는지 이해하기 위해 공유된 공간을 가질 수 있습니다. 거기서부터 시작했습니다. 그리고 그것이 우리가 계속 나아가고 싶은 방향이라고 생각합니다. 무엇을 하고 싶을까요? 우리는 개발자(developers)가 AI로 프로덕션(production) 애플리케이션(applications)을 구축하도록 돕고 싶습니다. 그리고 데모(demo)에서 프로덕션(production)으로 가는 과정을 연금술보다 엔지니어링(engineering)처럼 느끼게 만들려면 어떻게 해야 할까요? 데이터베이스(database)를 만드는 것은 사이드 퀘스트(side quest)가 아닙니다. 그것은 메인 퀘스트(main quest)의 일부입니다. 우리가 그 과정에서 깨달은 것은 검색(search)이 AI 애플리케이션(applications)이 구축되는 방식에 있어 정말 핵심적인 워크로드(workload)라는 것이었습니다. 유일한 워크로드(workload)는 아니지만, 분명히 매우 중요한 워크로드(workload)입니다. 그리고 세계 최고 수준으로 한 가지 일을 해내기 전까지는 더 많은 일을 할 자격을 얻지 못합니다. 그것은 광적인 집중을 요구합니다. 그래서 그것이 지난 몇 년 동안 우리가 해온 일입니다. 길고 두서없는 소개였지만, 요점을 말씀드리자면, 오늘날 크로마(Chroma)가 무엇을 하는지 사람들에게 묻는다면, 우리는 AI 애플리케이션(applications)을 위한 검색 엔진(retrieval engine)을 구축합니다. 우리는 AI를 위한 현대적인 검색 인프라(search infrastructure)를 연구하고 있습니다.

**정보 검색(Information Retrieval) 대 검색(Search)**
**스윅스(Swyx) [00:02:55]:** 이것에 대해 더 자세히 알아보겠습니다. 정보 검색(information retrieval)과 검색(search)은 같은 것입니까, 아니면 당신의 생각에는 미묘하게 다릅니까? 용어를 명확히 하고 싶습니다. 네.
**제프(Jeff) [00:03:04]:** AI를 위한 현대적인 검색 인프라(search infrastructure)에 대해 잠시 이야기해 보겠습니다. '현대적인'은 '전통적인'과 대조됩니다. 그리고 대부분 그것이 의미하는 바는 현대적인 분산 시스템(distributed systems)입니다. 지난 5년, 10년 동안 등장한 훌륭한 분산 시스템(distributed systems)을 구축하는 데 필요한 많은 기본 요소(primitives)가 있습니다. 이는 분명히 그보다 오래된 기술에는 없는 것입니다. 정의상 읽기 및 쓰기 분리, 스토리지(storage), 컴퓨트(compute) 분리, 크로마(Chroma)는 러스트(Rust)로 작성되었으며, 완전한 멀티 테넌트(multi-tenant)입니다. 우리는 객체 스토리지(object storage)를 크로마(Chroma)의 핵심 지원 계층 및 데이터 레이어(data layer)로 사용하며, 크로마 클라우드(Chroma Cloud)에서도 분산되어 있습니다. 이것이 '현대적인' 부분입니다. 그리고 'AI를 위한' 부분은 실제로 네 가지 다른 방식으로 중요하다고 생각합니다. 즉, AI를 위한 네 가지 다른 의미가 있습니다. 첫째, 검색(search)에 사용하는 도구와 기술(technology)이 고전적인 검색 시스템(search systems)과는 다릅니다. 둘째, 워크로드(workload)가 고전적인 검색 시스템(search systems)과는 다릅니다. 셋째, 개발자(developer)가 고전적인 검색 시스템(search systems)과는 다릅니다. 넷째, 검색 결과(search results)를 소비하는 사람도 고전적인 검색 시스템(search systems)과는 다릅니다. 고전적인 검색 시스템(search systems)을 생각해 보세요. 인간인 당신이 검색(search)의 마지막 단계를 수행했습니다. 클릭, 클릭, 정확히 그렇습니다. 당신은 "아, 이 중에서 어떤 것이 관련이 있지?"라고 생각하며 새 탭을 열고 요약하고, 기타 등등을 했습니다. 인간인 당신이 그것을 했습니다. 그리고 이제는 언어 모델(language model)입니다. 인간은 10개의 파란색 링크만 소화할 수 있습니다. 언어 모델(language models)은 훨씬 더 많은 양을 소화할 수 있습니다. 이 모든 것이 중요하며, 시스템(system)이 어떻게 설계되는지에 영향을 미친다고 생각합니다. 네. 네. 마치 ~을 위해 만들어진 것과 같습니다.

**경쟁적인 AI 시장에서 집중 유지하기**
**알레시오(Alessio) [00:04:29]:** 2023년에는 벡터DB(VectorDB) 카테고리(category)가 가장 뜨거운 분야 중 하나였다고 생각합니다. 파인콘(Pinecone)은 1억 달러를 모금했고, WVAs와 같은 모든 회사들이 있었습니다. 네. 어떻게 많은 돈을 모으고 큰 파장을 일으키기보다는 자신에게 중요한 것에 집중할 수 있었습니까? 그리고 크로마클라우드(ChromaCloud)를 출시하는 데도 시간이 좀 걸렸습니다. 프로덕션(production)에 도달하면 망가질 수도 있는 것을 서둘러 내놓기보다는 시간을 들였죠. 네. AI 분야에서 사람들에게 인내심을 갖는 방법에 대해 조언해 주실 수 있습니까? 창립자로서 자신만의 비전(vision)을 어떻게 가지고, 주변의 소음에 휩쓸리지 않고 그 비전(vision)을 따를 수 있습니까?
**제프(Jeff) [00:05:03]:** 스타트업(startup)을 구축하는 방법에는 여러 가지가 있습니다. 여기에는 여러 학파가 있습니다. 한 학파는 분명히 신호(signal)를 찾고 사람들이 원하는 것의 경사 하강법(gradient descent)을 따르는 린 스타트업(lean startup) 방식입니다. 이에 대한 저의 비판은, 만약 그 방법론을 따른다면, 아마도 중학생을 위한 게이팅 앱(gating app)을 만들게 될 것이라는 점입니다. 왜냐하면 그것이 어느 정도 인간이 원하는 가장 낮은 수준의 해석인 것 같기 때문입니다. 슬롯 머신(slot machine)은 그것의 AI 동등물일 것입니다. 반면에 스타트업(startup)을 구축하는 다른 방법은 매우 강력한 견해, 아마도 역발상적인 견해, 또는 적어도 비밀처럼 보이는 견해를 가지고 그 일에 광적으로 집중하는 것입니다. 사람마다 다른 방식이 있지만, 우리는 항상 두 번째 접근 방식을 취해왔습니다. 그리고 네, "크로마(Chroma)의 단일 노드(single node)가 정말 잘 작동하고 많은 트래픽(traffic)을 얻고 있으니, 호스팅 서비스(hosted service)가 사람들이 원하는 것이 분명하다. 우리는 매우 빠르게 제품을 시장에 내놓을 수 있을 것이다"라는 선택지가 있었습니다. 하지만 우리는 "아니, 크로마(Chroma)가 알려지기를 바라는 것은 우리의 개발자 경험(developer experience)이다. 우리는 우리의 브랜드(brand)가, 크로마(Chroma)의 브랜드(brand)와 우리 브랜드(brand)에 표현된 장인정신이 매우 잘 알려지기를 바란다"고 느꼈습니다. 그리고 서비스형 단일 노드 제품을 제공함으로써 훌륭한 개발자 경험(developer experience)이 무엇일 수 있고 무엇이어야 하는지에 대한 우리의 기준을 충족시키지 못할 것이라고 느꼈습니다. 네, 우리는 "아니, 우리는 옳다고 생각하는 것을 구축할 것이다"라는 결정을 내렸습니다. 그것은 정말 도전적이었습니다. 오랜 시간이 걸렸고, 오늘날 존재하며 수십만 명의 개발자(developers)에게 서비스(service)를 제공하고 그들이 그것을 좋아한다는 사실에 엄청나게 자랑스럽습니다. 하지만 그곳에 도달하기는 어려웠습니다.
**알레시오(Alessio) [00:06:38]:** 팀을 구축할 때 어떻게 메시지를 전달합니까? 1년 반 전으로 돌아가서, 제가 크로마(Chroma)에 합류할 수도 있고, 다른 회사들에 합류할 수도 있었습니다. 외부에서는 "아, 그냥 PG 벡터(PG vector)를 사용하거나, 그날그날의 다른 것을 사용하면 되지"라고 생각할 때, 사람들에게 비전(vision)을 어떻게 명확하게 유지합니까? 그것이 비전(vision)에 더 잘 맞는 사람들을 데려오는 데 도움이 된다고 생각하십니까? 아니면 단지 뜨기 전에 이 회사에 합류하는 선교사형 사람들을 데려오는 데 도움이 된다고 생각하십니까? 그리고 초창기 채용에서 얻은 교훈이 있습니까?
**제프(Jeff) [00:07:07]:** 콘웨이의 법칙(Conway's law)의 상위 버전은 "당신은 당신의 조직도를 출시한다"는 것입니다. 당신은 당신의 문화를 출시합니다. 왜냐하면 당신의 조직도는 회사 문화의 하위 개념이라고 생각하기 때문입니다. 우리는 항상 팀에 있는 사람들에게 매우 높은 가치를 두었습니다. 미래 성장의 기울기는 전적으로 이 사무실에 있는 사람들에게 달려 있다고 생각합니다. 그리고 그것은 0으로 돌아갈 수도 있고, 선형 성장, 초선형 성장, 기하급수적 성장, 하키 스틱(hockey stick) 성장과 같은 모든 종류의 버전을 의미할 수도 있습니다. 그래서 네, 우리는 정말 천천히 채용하고 매우 까다롭게 굴기로 결정했습니다. 그리고 모르겠습니다. 그것이 올바른 결정이었는지 아닌지는 미래가 결정할 것입니다. 하지만 이전에 몇몇 스타트업(startups)에서 일해 본 경험으로 볼 때, 제가 정말 중요하게 생각했던 것은 "함께 일하는 것을 좋아하는 사람들과 일하고 싶다"는 것이었습니다. 그리고 전선에서 어깨를 나란히 하고 싶습니다. 그리고 개발자(developers)에게 빚지고 있는 장인정신과 품질 수준에서 독립적으로 실행할 수 있다고 생각합니다. 그래서 그것이 우리가 선택한 방법이었습니다.

**크로마 클라우드(Chroma Cloud) 구축**
**스윅스(Swyx) [00:08:08]:** 표준 조건(standard condition)과 다른 재미있는 것들은 나중에 이야기하고, 크로마(Chroma)에 집중하겠습니다. 저는 항상 주요 수치(headline numbers)를 먼저 제시하고 싶습니다. 그래서 사람들에게 크로마(Chroma)에 대해 알아야 할 것을 더 잘 알려주려고 노력하고 있습니다. 파이파이(PyPI)에서 월간 500만 다운로드(downloads)와 깃허브(GitHub) 스타(stars) 21,000개입니다. 사람들이 알아야 할 다른 것이 있습니까? 전형적인 영업 전화(sales call)에서 나오는 주요 내용 같은 것 말입니다.
**제프(Jeff) [00:08:33]:** 네. 음, 네, 깃허브(GitHub) 스타(stars) 20,000개, 월간 500만 이상의 다운로드(downloads)입니다. 최근에 숫자를 확인했는데, 현재 총 다운로드(downloads) 수는 6천만 또는 7천만 이상인 것 같습니다. 수년 동안 크로마(Chroma)는 광범위하게, 그리고 랭체인(LangChain)과 많은 인덱스(index)와 같은 커뮤니티(communities) 내에서도 가장 많이 사용되는 프로젝트(project)였습니다. 알겠습니다. 좋습니다. 네.
**스윅스(Swyx) [00:08:51]:** 단일 노드(single node) 크로마(Chroma)라고 말할 때, 품질을 설명하고 있다고 생각합니다. 네. 크로마 클라우드(Chroma Cloud)가 무엇이었는지와 핵심적인 차이점은 무엇입니까? 그리고 우리는 이것을 GA(General Availability) 및 크로마 클라우드(Chroma Cloud)와 함께 출시하고 있다고 생각합니다. 아, 네. 그래서 사람들이 크로마 클라우드(Chroma Cloud)에 대해 무엇을 알아야 하고, 처음부터 이 경험을 어떻게 개발했습니까? 스토리지(storage)와 컴퓨트(compute)의 분리를 언급하셨는데, 그것은 무엇을 의미합니까? 네.
**제프(Jeff) [00:09:13]:** 100%입니다. 크로마(Chroma)는 개발자 경험(developer experience)으로 유명합니다. 우리가 이것을 처음 한 것인지는 모르겠습니다. 크로마(Chroma)를 사용하면 `pip install ChromaDB`를 입력하기만 하면 사용할 수 있습니다. 그냥 인메모리(in memory)입니다. 지속할 수 있다고 생각합니다.
**스윅스(Swyx) [00:09:25]:** 처음일 수도 있습니다.
**제프(Jeff) [00:09:26]:** `pip install` 가능한 데이터베이스(database)는 처음일 것입니다.
**스윅스(Swyx) [00:09:28]:** 모든 SQLite 래퍼(wrapper)는 기술적으로 `pip install` 가능합니다. SQLite는 오늘날까지도 `pip install` 가능하지 않다고 생각합니다. 당신은 아마 이것에 대해 더 깊이 파고들고 지식을 가지고 있을 것입니다. 저는 그냥 추측하는 것입니다. 네.
**제프(Jeff) [00:09:40]:** 그래서 그것은 새로운 사용자(users)를 위한 매우 원활한 온보딩(onboarding) 경험으로 이어졌습니다. 명령을 실행하기만 하면 사용할 수 있었기 때문입니다. 우리는 배포 대상(deployment target)이나 아키텍처(architecture)에 관계없이 작동하도록 모든 작업을 수행했습니다. 초창기에는 사람들이 아두이노(Arduinos)와 PowerPC 아키텍처(architectures)와 같은 정말 난해한 것들에서 실행하는 등 정말 훌륭한 일을 했습니다. 하지만 우리는 어디에서나 작동하도록 한 걸음 더 나아갔고, 그냥 항상 작동했습니다. 그것이 크로마(Chroma) 단일 노드(single node)였습니다. 그래서 클라우드 제품에서 우리가 원했던 개발자 경험(developer experience)으로 돌아가면, `pip install ChromaDB`를 실행하면 5초 만에 작동하고 생각할 필요가 없었던 것처럼, 많은 추상화(abstractions)를 배울 수 있고, 이것이 정말 복잡한 API(API)라는 것을 배우는 데 많은 시간을 할애할 필요가 없었던 것처럼, 클라우드(cloud)에서도 똑같은 이야기가 적용되어야 한다고 느꼈습니다. 그래서 그것이 의미하는 바는, 얼마나 많은 노드(nodes)를 원하는지, 노드(nodes)의 크기를 어떻게 정해야 하는지, 샤딩 전략(sharding strategy)이나 백업 전략(backup strategy) 또는 데이터 계층화 전략(data tiering strategy)이 어떠해야 하는지에 대해 생각해야 하는 제품 버전은 충분히 좋지 않았다는 것입니다. 계속 이야기할 수 있습니다. 제로 구성(zero config), 조정할 노브(knobs)가 없어야 했습니다. 항상 빠르고, 항상 비용 효율적이며, 항상 최신 상태여야 했습니다. 트래픽(traffic)이 오르내리고 데이터 스케일(data scale)이 오르내리는 것에 관계없이 말입니다. 그것이 동기 부여 기준이었습니다. 또한 사용량 기반 청구(usage-based billing)도 정말 중요했습니다. 왜냐하면 그것은 너무나 공정하기 때문입니다. 우리는 당신이 사용하는 최소한의 컴퓨트(compute) 사용량에 대해서만 청구하며, 그 이상은 청구하지 않습니다. 모든 서버리스 데이터베이스(serverless databases)가 주장할 수 있는 것은 아니지만, 크로마(Chroma) 내부에서는 우리가 당신이 사용하는 좁은 부분에 대해서만 실제로 청구한다는 것이 사실입니다. 그래서 그것이 우리가 설계 기준 프로세스(design criteria process)에 들어간 기준이었습니다.
**스윅스(Swyx) [00:11:19]:** 사실상 서버리스 컴퓨트 플랫폼(serverless compute platform)도 구축하고 있는 셈이네요.
**제프(Jeff) [00:11:23]:** 네, 그래야 합니다. 정확히 그렇습니다. 그것이 크로마 분산(Chroma Distributed)의 설계를 동기 부여했습니다. 크로마 분산(Chroma Distributed)도 동일한 모노레포(monorepo)의 일부이며, 아파치 2(Apache 2) 오픈 소스(open source)입니다. 그리고 제어 및 데이터 플레인(data plane)은 모두 아파치 2(Apache 2) 오픈 소스(open source)입니다. 그리고 크로마 클라우드(Chroma Cloud)는 크로마 분산(Chroma Distributed)을 사용하여 서비스를 실행합니다. 이 서비스는 가입하고, 데이터베이스(database)를 생성하고, 30초 이내에 데이터를 로드(load)할 수 있습니다. 그리고 촬영 시점에는 사람들이 5달러의 무료 크레딧(credits)을 받는데, 이는 10만 개의 문서(documents)를 로드(load)하고 10만 번 쿼리(query)하는 데 충분한 양입니다. 이는 분명히 많은 시간이 걸립니다. 많은 사용 사례에서 실제로 몇 년 동안 무료로 사용할 수도 있을 것입니다. 괜찮습니다. 그리고 그곳에 도달하기 위해 우리는 모든 어려운 작업을 수행해야 했습니다. 네.
**스윅스(Swyx) [00:12:03]:** 모든 블로그(blog)는 기본적으로 의미론적 인덱싱(semantic indexing)을 가져야 한다고 생각합니다. 그래서 당신의 개인 블로그(personal blog)를 크로마(Chroma)에 호스팅(host)하는 거죠. 우리는 아닙니다.
**제프(Jeff) [00:12:10]:** 네, 세상의 정보를 정리하는 임무는 아직 해결되지 않았습니다.

**컨텍스트 엔지니어링(Context Engineering)과 RAG의 문제점**
**스윅스(Swyx) [00:12:15]:** 네. 컨텍스트 엔지니어링(Context Engineering)과 RAG의 문제점.
**알레시오(Alessio) [00:12:15]:** 당신은 평소처럼 수수께끼 같은 트윗(tweets)을 올렸습니다. 텍스트가 필요합니다. 몇 달 전, 4월에 컨텍스트 엔지니어링(context engineering)을 트윗(tweet)하셨죠. 모두가 그랬던 것 같습니다.
**제프(Jeff) [00:12:24]:** 새로운 시장이 부상할 때 엄청나게 중요한 것은 추상화(abstractions)와 그것에 대해 추론하는 데 사용하는 기본 요소(primitives)라고 생각합니다. 그리고 AI는 과대광고의 일부로서 많은 기본 요소(primitives)와 추상화(abstractions)가 마구 던져져서 많은 개발자(developers)들이 실제로 이것이 무엇인지, 어떻게 조립해야 하는지, 어떤 문제를 해결할 수 있는지, 무엇이 중요한지, 어디에 시간을 할애해야 하는지에 대해 비판적으로 생각할 수 없게 만들었습니다. 예를 들어, RAG라는 용어. 우리는 RAG라는 용어를 사용하지 않습니다. 저는 RAG라는 용어를 싫어합니다.
**스윅스(Swyx) [00:13:08]:** 네, 당신의 영향 때문에 RAG 트랙을 부분적으로 없앴습니다.
**제프(Jeff) [00:13:10]:** 감사합니다. 감사합니다. A는 우선 검색(retrieval)입니다. 검색(retrieval)과 생성(generation)은 세 가지 개념이 하나로 묶인 것입니다. 그것은 정말 혼란스럽습니다. 그리고 물론 RAG는 이제 "아, 당신은 단일 밀집 벡터 검색(single dense vector search)만 사용하고, 그것이 RAG이다"라고 브랜드화되어 알려졌습니다. 그것도 어리석습니다. 제가 이 용어에 대해 정말 흥분했던 이유 중 하나는, 물론 당신이 많은 작업을 한 AI 엔지니어링(AI engineering)처럼, 컨텍스트 엔지니어링(context engineering)은 어떤 면에서는 AI 엔지니어링(AI engineering)의 하위 집합입니다. 그것은 무엇입니까? 그것은 고위직입니다. 컨텍스트 엔지니어링(context engineering)은 주어진 LLM 생성 단계에서 컨텍스트 창(context window)에 무엇이 있어야 하는지를 알아내는 작업입니다. 그리고 이번에 컨텍스트 창(context window)에 무엇이 있어야 하는지를 설정하는 내부 루프(inner loop)와, 시간이 지남에 따라 관련 정보만으로 컨텍스트 창(context window)을 채우는 방법을 개선하는 외부 루프(outer loop)가 있습니다. 그리고 우리는 최근에 컨텍스트 로트(context rot)에 대한 기술 보고서(technical report)를 발표했습니다. 이 보고서는 LLM의 성능이 사용하는 토큰(tokens) 수에 따라 불변하지 않다는 것을 자세히 설명합니다. 토큰(tokens)을 점점 더 많이 사용할수록 모델(model)은 덜 주의를 기울이고 덜 효과적으로 추론할 수 있습니다. 이것이 문제를 정말 잘 설명한다고 생각합니다. 컨텍스트 로트(context rot)는 컨텍스트 엔지니어링(context engineering)의 필요성을 암시합니다. 그리고 제가 이 밈(meme)에 대해 정말 흥분하는 이유는, 그리고 어느 정도 운이 좋았다고 생각합니다. 4월에 이것이 큰 밈(meme)이 될 것이라고 예측했으니까요. 그것은 직업의 위상을 높이고, 직업을 명확하게 설명하며, 직업의 위상을 높입니다. 솔직히 말해서, 오늘날 당신이 알고 있는, 매우 잘하고 있다고 생각하는 대부분의 AI 스타트업(startups), 모든 AI 스타트업(startups)은 근본적으로 무엇을 잘합니까? 그들이 잘하는 한 가지는 무엇입니까? 그것은 컨텍스트 엔지니어링(context engineering)입니다.
**스윅스(Swyx) [00:14:45]:** 특히 제가 읽은 많은 글들은 에이전트(agents) 대 비에이전트(non-agent)에 초점을 맞추는 것 같습니다. 컨텍스트 엔지니어링(context engineering)은 에이전트(agents)에 더 관련이 있습니까? 아니면 컨텍스트 엔지니어링(context engineering)을 일반적으로 보고 있습니까?
**제프(Jeff) [00:15:00]:** 아니요. 에이전트(agent) 학습과 같은 흥미로운 에이전트(agent) 함의가 있습니다. 에이전트(agents)가 상호작용을 통해 학습할 수 있을까요? 이는 정적인 지식 기반 코퍼스(corpuses)나 문서와 채팅하는 것과는 덜 관련이 있을 수 있습니다. 하지만 다시 말하지만, 문서와 채팅하는 사용 사례조차도 더 많은 상호작용을 통해 개선되어야 한다고 주장할 수 있다고 생각합니다. 저는 에이전트(agent)와 비에이전트(non-agent)를 구별하지 않습니다. 저는 에이전트(agent)가 무엇을 의미하는지 아직도 모르지만, 다시 말하지만, 불분명한 추상화(abstractions)와 단어는 중요합니다. 모르겠습니다. 에이전트(agent)는 무엇을 의미합니까? 모르겠습니다. 많은 정의가 있습니다. 정확히 그렇습니다. 제가 시도해 봤습니다. 무엇이든 의미할 수 있는 대부분의 용어는 사람들의 희망과 두려움을 위한 수단일 뿐입니다. 네. 에이전트(agent)도 마찬가지라고 생각합니다. 확실히 그렇습니다.
**스윅스(Swyx) [00:15:42]:** 음, 아마도 우리는 컨텍스트 엔지니어링(context engineering)에 대해 더 간결하고 정확하게 설명하려고 노력할 것입니다. 그래서 그것이 실제로 의미가 있고, 사람들이 실제로 그것을 사용하여 무언가를 할 수 있도록 말입니다. 컨텍스트 엔지니어링(context engineering) 또는 컨텍스트 로트(context rot)에 대해 제가 확실히 언급하고 싶은 한 가지는, 모든 최첨단 모델(frontier model)이 이제 100만 토큰(tokens)에 걸쳐 완전히 녹색의 완벽한 활용도 차트와 함께 출시되는 "건초 더미 속 바늘(needle in a haystack)"에 대한 많은 마케팅(marketing)이 있었다는 것입니다. 그런 종류의 마케팅(marketing)에 대해 여러분은 어떻게 생각하십니까? 네. 네.

**컨텍스트 로트(Context Rot)**
**제프(Jeff) [00:16:11]:** 아마도 조금 뒤로 돌아가서 설명하겠습니다. 우리가 이 연구를 시작하게 된 계기는 에이전트(agent) 학습을 실제로 보고 있었기 때문입니다. 그래서 우리는 에이전트(agents)에게 이전 성공 또는 이전 실패에 대한 접근 권한을 줄 수 있는지, 그리고 그렇게 하면 에이전트(agent) 성능을 향상시키는 데 도움이 될지 매우 궁금했습니다. 그래서 우리는 스위트벤치(SweetBench)를 포함한 몇 가지 다른 데이터 세트(data sets)를 특별히 살펴보고 있었는데, 흥미로운 패턴(patterns)을 보기 시작했습니다. 다중 턴 에이전트(agent) 상호작용에서 전체 대화 창(conversation window)을 제공할 때, 토큰(tokens)의 수가 엄청나게 빠르게 폭발적으로 증가하고, 분명히 그 안에 있던 지침들이 무시되고 발표되지 않는다는 것을 발견했습니다. 그리고 우리는 "아, 그것은 분명히 문제다"라고 생각했습니다. 우리는 이제 고통을 느꼈습니다. 이것이 사실이라는 것은 아는 사람들 사이에서 일종의 밈(meme)이었습니다. 그리고 또한, 연구 커뮤니티(community)의 컨텍스트 로트(context rot) 기술 보고서(technical report)에 대한 반응은 "네, 우리는 압니다"와 같았습니다. 그리고 그것은 괜찮습니다. 다른 사람들은 몰랐습니다. 그리고 빌더(builders)에게 오늘날 가능한 것과 불가능한 것을 실제로 가르칠 수 있다면 좋습니다. 저는 연구소(labs)를 비난하지 않습니다. 모델(models)을 구축하는 것은 엄청나게 경쟁적입니다. 모든 사람들은 항상 자신이 가장 잘하고 싶은 벤치마크(benchmarks)를 선택합니다. 그들은 그것들을 중심으로 훈련합니다. 그것들은 또한 그들의 마케팅(marketing)에 포함되는 것들입니다. 대부분의 사람들은 "우리 제품이 훌륭한 모든 방법과 훌륭하지 않은 모든 방법을 알려드리겠습니다"라고 말할 동기가 없습니다. 모르겠습니다. 저는 이것이 왜 보고되지 않았는지에 대해 어느 정도 동정심을 가지고 있습니다. 하지만 네, "아, 보세요, 우리 모델(model)은 이 작업에서 완벽합니다. 건초 더미 속 바늘(needle in a haystack)입니다. 따라서 컨텍스트 창(context window)을 원하는 대로 사용할 수 있습니다"와 같은 암시가 있었습니다. 그리고 언젠가 그것이 사실이 되기를 바라지만, 지금은 그렇지 않습니다. 네.
**스윅스(Swyx) [00:17:43]:** 유튜브 비디오(YouTube video)에서는 사람들에게 컨텍스트 로트(context rot) 보고서의 그림 1인 이 차트를 보여줄 것입니다. 곡선 아래 면적(area under curve)으로 볼 때 소네트 4(Sonnet 4)가 가장 좋은 것 같습니다. 그리고 퀸(Quinn), 와우. 그리고 GPC 4.1과 제미니 플래시(Gemini Flash)는 컨텍스트 길이(context length)에 따라 훨씬 더 빨리 저하됩니다. 네.
**제프(Jeff) [00:18:03]:** 저는 별다른 논평이 없습니다. 그것이 이 특정 작업에서 우리가 발견한 것입니다. 다시 말하지만, 그것이 실제 세계에서 사람들의 실제 경험으로 어떻게 전환되는지는 완전히 다릅니다. 클로드(Claude)에 대한 개발자(developers)들의 사랑이 어느 정도 있는데, 아마도 그 두 가지는 상관관계가 있을 것입니다. 네. 이것이 사실이라면, 왜 그런지에 대한 큰 설명이 여기에 나타난다고 생각합니다. 제 지침을 따르십시오. 사람들이 원하는 명확한 기준선이 있습니다.
**스윅스(Swyx) [00:18:27]:** 여기서는 완전히 답변되지 않았지만, 저는 추론 모델(reasoning models)이 컨텍스트 활용(context utilization)에 더 능숙하다는 이론도 가지고 있습니다. 왜냐하면 그들은 되돌아갈 수 있기 때문입니다. 일반적인 자기회귀 모델(autoregressive models)은 그냥 왼쪽에서 오른쪽으로 진행합니다. 하지만 추론 모델(reasoning models)은 이론적으로 되돌아가서 초기 통과에서 주의를 기울이지 않았을 수도 있는 연결이 필요한 것들을 찾을 수 있습니다. 오늘 발표된 논문은 아마도 그 반대를 보여주었습니다. 정말요?
**제프(Jeff) [00:18:49]:** 나중에 보내드리겠습니다. 네.
**스윅스(Swyx) [00:18:50]:** 그것을 알아내는 것은 흥미로울 것입니다.
**알레시오(Alessio) [00:18:52]:** 매일 논문이 나옵니다. 가장 좋았던 점은 당신이 무언가를 팔려고 하지 않았다는 것입니다. 당신은 그냥 "이것은 고장 났습니다. 좀 안 좋습니다"라고 말했습니다. 당신이 해결하고 싶은 문제와, 문제를 강조하기 위해 수행하는 연구, 그리고 다른 사람들이 참여하기를 바라는 연구에 대해 어떻게 생각하십니까? 당신이 이야기하는 모든 것이 기본적으로 크로마(Chroma) 로드맵(roadmap)에 있습니까? 아니면 그냥 사람들에게 "이것은 나쁩니다. 우회하세요. 하지만 우리에게 고쳐달라고 하지 마세요"라고 조언하는 것입니까?
**제프(Jeff) [00:19:20]:** 방금 전에 말했던 것으로 돌아가서, 크로마(Chroma)의 광범위한 임무는 애플리케이션(applications) 구축 과정을 연금술보다 엔지니어링(engineering)에 가깝게 만드는 것입니다. 그래서 그것은 꽤 광범위한 영역이지만, 우리는 작은 팀이고 너무 많은 것에 집중할 수 없습니다. 우리는 당분간 한 가지에 매우 집중하기로 선택했습니다. 그래서 저는 우리가 스스로 이 문제를 결정적으로 해결할 수 있다고 생각할 만큼 오만하지 않습니다. 매우 역동적이고 거대한 신흥 산업에서는 커뮤니티(community)가 필요하고, 모두 함께 일하는 사람들의 물결이 필요하다고 생각합니다. 우리는 의도적으로 이 연구에 상업적 동기가 없다는 것을 매우 명확히 하고 싶었습니다. 우리는 어떤 해결책도 제시하지 않습니다. 우리는 사람들에게 크로마(Chroma)를 사용하라고 말하지 않습니다. 그냥 여기 문제가 있습니다.
**스윅스(Swyx) [00:20:02]:** 암시되어 있습니다.
**제프(Jeff) [00:20:05]:** 보세요, 우리는 그것이 아마도, 그리고 아마도 긍정적인 암시일 수도 있다는 것에 슬퍼하지 않았습니다. 하지만 여전히 그것에 대한 이유는 없습니다. 하지만 속도와 비용에 관계없이 할 일이 많다고 생각합니다. 그리고 연구소(labs)가 실제로 신경 쓰지 않고, 점점 더 신경 쓸 동기가 없다는 것이 흥미롭습니다. 좋은 LLM 제공업체가 되기 위한 주요 시장은 소비자(consumer)인 것 같습니다. 개발자(developers)를 부차적인 관심사로 돕는 데는 그렇게 동기가 부여되지 않습니다. 그래서 개발자(developers)가 무언가를 구축하는 방법을 배우도록 돕기 위한 힘든 일을 할 동기가 그렇게 많지 않습니다. 네. 그리고 만약 당신이 SaaS 회사(SaaS company)이거나 소비자 회사(consumer company)라면, AI로 구축하고 있다면, 당신은 AI 네이티브(native) 회사입니다. 이것은 당신의 비법입니다. 당신은 어떻게 하는지 마케팅(marketing)하지 않을 것입니다. 그래서, 실제로 개발자(developers)가 AI로 구축하는 방법을 보여주는 데 도움을 줄 동기를 가진 사람들은 자연스러운 빈 공간이 있습니다. 그들은 시간과 에너지를 투자하는 명백한 사람들이 많지 않습니다. 하지만 그것은 분명히 우리가 해야 할 좋은 일이라고 생각합니다. 그래서 그렇게 생각했습니다.
**스윅스(Swyx) [00:21:02]:** 소비자(consumer) 문제에 대해 반박하자면, 연구소(labs)라고 말씀하셨는데, 오픈AI(OpenAI)가 ChatGPT에 메모리(memory)를 구축하고 말 그대로 모든 사람에게 제공하는 것에 대해 생각하지 않으십니까? 제 생각에는 너무 노골적이라고 생각하지만, 그들은 메모리 활용(memory utilization)을 좋게 만드는 데 정말 신경 쓸 것입니다. 컨텍스트 활용(context utilization), 컨텍스트 엔지니어링(context engineering)은 그들에게도 중요하다고 생각합니다. 비록 그들이 소비자(consumer)만을 위해 구축하고 개발자(developers)에게는 신경 쓰지 않더라도 말입니다.
**제프(Jeff) [00:21:25]:** 네. 오늘날 얼마나 좋은지는 분명히 중요한 질문이지만, 그 질문은 건너뛰겠습니다. 설령 그렇다 하더라도, 그들이 실제로 그 연구 결과를 발표할까요? 아니요. 정확히 그렇습니다. 그것은 알파(alpha) 단계입니다. 왜 당신의 비밀을 누설하겠습니까? 네. 그래서 실제로 사업을 하는 회사는 거의 없다고 생각합니다. 그들은 개발자(developers)에게 AI로 유용한 것을 구축하는 방법을 가르치려고 노력하는 데 인센티브(incentive)를 가지고 있고 정말 신경 쓰는 위치에 있다고 생각합니다. 그래서 우리는 그런 인센티브(incentive)를 가지고 있다고 생각합니다.

**컨텍스트 품질(Context Quality) 우선순위 지정**
**알레시오(Alessio) [00:21:49]:** 하지만 이것이 다음 건초 더미 속 바늘(needle in a haystack)이 될 정도로 성장하여 모델(model) 제공업체들이 실제로 그것을 잘하도록 강제할 수 있다고 생각하십니까?
**제프(Jeff) [00:21:57]:** 누구에게든 무엇이든 강요할 방법은 없습니다. 그래서 우리는 이것을 준비할 때 그것에 대해 생각했습니다. "아, 아마도 이것을 공식 벤치마크(benchmark)로 공식화하여 매우 쉽게 만들 수 있을 것이다"라고요. 우리는 모든 코드를 오픈 소스(open source)로 공개했습니다. 그래서 당신이 이것을 보고 있고 대규모 모델(model) 회사에서 왔다면, 당신은 이것을 할 수 있습니다. 아직 출시하지 않은 새 모델(model)을 가져와서 이 수치들을 실행할 수 있습니다. 그리고 저는 500만 토큰(tokens) 모델(model)보다 6만 컨텍스트(context), 토큰(token) 컨텍스트 창(context window)을 가지고 완벽하게 주의를 기울이고 완벽하게 추론할 수 있는 모델(model)을 선호할 것입니다. 개발자(developer)로서 전자가 후자보다 훨씬 더 가치 있습니다. 모델(model) 제공업체들이 이것을 중요하게 생각하고, 그것을 중심으로 훈련하고, 진행 상황을 평가하고, 개발자(developers)에게 소통하기를 진심으로 바랍니다. 그렇게 된다면 훌륭할 것입니다.
**알레시오(Alessio) [00:22:42]:** 이것이 더 나은 교훈이 될 것이라고 생각하십니까? 어떻게 결정하십니까? 왜냐하면 당신은 "네, 모델(models)은 이것을 배우지 않을 것입니다. 당신이 접근할 수 없는 속임수가 될 것입니다"라고 말하고 있으니까요. 저는 그렇게 말하는 것이 아닙니다. 하지만 당신이 "그들은 그것을 하는 방법을 발표하지 않을 것입니다"라고 말할 때, 그것은 모델(model) API(API)가 그것을 할 수 없을 것이지만, 그들은 ChatGPT에서 그것을 할 수 있는 무언가를 가질 것이라는 의미입니다. 알겠습니다. 네.
**제프(Jeff) [00:23:04]:** 무엇이 더 나은 교훈이 될지 아닐지 예측하는 것은 매우 위험합니다. 저는 추측하지 않겠습니다. 바라건대 AI 엔지니어(engineers)는 아닐 것입니다. 네. 바라건대 모든 인류는 아닐 것입니다. 모르겠습니다. 네.
**스윅스(Swyx) [00:23:14]:** 저에게도 컨텍스트 엔지니어링(context engineering)을 중심으로 흥미로운 분야가 발전하고 있습니다. 랭체인(Langchain)의 랜스 마틴(Lance Martin)은 모든 다른 분리에 대한 정말 좋은 블로그 게시물을 작성했습니다. 그리고 뉴욕(New York)에서 당신은 첫 번째 밋업(meetup)을 주최했습니다. 샌프란시스코(San Francisco)에서도 하나를 할 예정입니다. 하지만 저는 그냥 궁금합니다. 현장에서 무엇을 보고 있습니까? 누가 흥미로운 작업을 하고 있습니까? 주요 논쟁은 무엇입니까? 그런 것들 말입니다.
**제프(Jeff) [00:23:37]:** 이것은 여전히… 많은 사람들이 아무것도 하지 않고 있습니다. 많은 사람들이 여전히 모든 것을 컨텍스트 창(context window)에 넣고 있습니다. 그것은 매우 인기가 많습니다. 그리고 컨텍스트 캐싱(context caching)을 사용하고 있으며, 그것은 분명히 도움이 되지만, 비용과 속도 문제가 있습니다. 하지만 컨텍스트 문제에는 전혀 도움이 되지 않습니다. 그래서 네, 아직 많은 모범 사례(best practices)가 마련되어 있다고 생각하지 않습니다. 몇 가지를 강조하겠습니다. 근본적인 문제는 아주 간단합니다. N개의 후보 청크(chunks)가 있고, Y개의 사용 가능한 공간이 있습니다. 그리고 1만 개 또는 10만 개 또는 100만 개의 후보 청크(chunks) 중에서 이 정확한 단계에 필요한 20개를 선별하고 줄이는 과정을 수행해야 합니다. 이 최적화 문제(optimization problem)는 많은 애플리케이션(applications)과 산업에서 새로운 문제가 아닙니다. 고전적인 문제입니다. 그리고 물론, 사람들이 그 문제를 해결하기 위해 사용하는 도구는 여전히 매우 초기 단계라고 생각합니다. 말하기는 어렵지만, 제가 본 몇 가지 패턴(patterns)이 있습니다. 한 가지 패턴(pattern)은 많은 사람들이 1단계 검색(first stage retrieval)이라고 부르는 것을 사용하여 대규모 축소를 수행하는 것입니다. 즉, 벡터 검색(vector search), 전체 텍스트 검색(full text search), 메타데이터 필터링(metadata filtering), 메타데이터 검색(metadata search) 등과 같은 신호(signals)를 사용하여 1만 개에서 300개로 줄이는 것입니다. 방금 전에 말했듯이, LLM에 10개의 파란색 링크를 줄 필요는 없습니다. 훨씬 더 많은 것을 무차별 대입할 수 있습니다. 그래서 LLM을 재순위화기(re-ranker)로 사용하고 300개에서 30개로 무차별 대입하는 것이 이제 부상하고 있습니다. 많은 사람들이 이것을 하고 있으며, 실제로 많은 사람들이 깨닫는 것보다 훨씬 더 비용 효율적입니다. 저는 직접 모델(models)을 실행하는 사람들이 100만 입력 토큰(tokens)당 1페니를 얻고, 출력 토큰(token) 비용은 기본적으로 0이라고 들었습니다. 왜냐하면 그것은 가장 간단하기 때문입니다. 이것들은 전용 재순위화기(re-ranker) 모델(models)이죠? LLM이 아닙니다. 아니요, 이것들은 LLM입니다. 알겠습니다. 그들은 LLM을 재순위화기(re-ranker)로 사용하고 있습니다. 알겠습니다. 그리고 물론, 훨씬 작고 빠르기 때문에 정의상 훨씬 저렴한 전용 재순위화기(re-ranker) 모델(models)도 있습니다. 하지만 제가 본 것은 이미 프롬프트(prompt) 방법을 아는 애플리케이션(application) 개발자(developers)들이 이제 그 도구를 재순위화(re-ranking)에 적용하고 있다는 것입니다. 그리고 이것이 지배적인 패러다임(paradigm)이 될 것이라고 생각합니다. 저는 실제로 목적에 맞게 구축된 재순위화기(re-rankers)가 사라질 것이라고 생각합니다. 마치 목적에 맞게 구축된 것들이 여전히 존재할 것처럼 말입니다. 극단적인 규모, 극단적인 비용이라면, 네, 그것을 최적화하는 데 신경 쓸 것입니다. 하드웨어(hardware)를 사용하는 것과 마찬가지로 말입니다. ASIC이나 FPGA가 절대적으로 필요하지 않는 한 CPU나 GPU를 사용할 것입니다. 그리고 재순위화기(re-rankers)에 대해서도 마찬가지라고 생각합니다. LLM이 100배, 1000배 더 빨라지고 100배, 1000배 더 저렴해지면, 사람들은 LLM을 재순위화기(re-rankers)로 사용할 것이고, 실제로 정보 큐레이션(curation)을 무차별 대입하는 것이 엄청나게 인기를 얻을 것입니다. 오늘날, 300개의 병렬 LLM 호출을 실행하는 것은 매우 비싸지 않더라도, 그 300개의 LLM 호출 중 어느 하나라도 꼬리 지연 시간(tail latency)이 있습니다. 그래서 오늘날 프로덕션(production) 애플리케이션(application)에서 그렇게 하지 않는 데는 좋은 이유가 있지만, 그것들도 시간이 지나면서 사라질 것입니다. 그래서 제가 본 이러한 패턴(patterns)은 지난 몇 달 동안 정말 인기를 얻기 시작한 새로운 것이라고 생각합니다. 그리고 '인기'란 선봉에서 인기가 있다는 의미이지만, 매우 지배적인 패러다임(paradigm)이 될 것이라고 생각합니다. 네.

**코드 인덱싱(Code Indexing) 및 검색 전략(Retrieval Strategies)**
**스윅스(Swyx) [00:27:02]:** 코드 인덱싱(code indexing) 측면에서도 조금 다루었습니다. 우리가 이야기한 모든 것은 모든 종류의 컨텍스트(contexts)에 적용됩니다. 코드는 분명히 특별한 종류의 컨텍스트(context)와 인덱싱(indexing)하고 싶은 코퍼스(corpus)입니다. 우리는 몇몇 에피소드에서 클라우드 코드(cloud code) 담당자와 클라이언트(client) 담당자들이 코드베이스(code base)를 임베딩(embed)하거나 인덱싱(index)하지 않고, 도구를 제공하고 그 도구를 사용하여 코드 검색(code search)을 한다고 이야기했습니다. 그리고 저는 종종 이것이 주요 컨텍스트 검색(context retrieval) 패러다임(paradigm)이 되어야 하는지 생각해 보았습니다. 에이전트(agent)를 구축할 때, 효과적으로 다른 에이전트(agent)를 모든 종류의 재귀적 재순위화기(re-rankers)와 요약기(summarizers) 또는 도구를 가진 다른 에이전트(agent)와 함께 호출하는 것입니다. 네. 아니면 그것들을 단일 에이전트(agent)에 붙입니까? 당신이 의견을 가지고 있는지 모르겠습니다. 왜냐하면 에이전트(agent)는 매우 불분명하게 정의되어 있기 때문입니다. 하지만 그냥 말해 보겠습니다.
**제프(Jeff) [00:27:47]:** 알겠습니다. 그것을 분해해 보겠습니다. 인덱싱(indexing)은 정의상 트레이드오프(trade-off)입니다. 데이터(data)를 인덱싱(indexing)할 때, 쓰기 시간 성능을 쿼리(query) 시간 성능과 교환합니다. 데이터(data) 수집은 느려지지만, 데이터(data) 쿼리(query)는 훨씬 빨라집니다. 이는 데이터 세트(data sets)가 커질수록 분명히 확장됩니다. 그래서 만약 당신이 매우 작은, 15개 파일 코드베이스(code bases)만 그레핑(grepping)한다면, 아마도 인덱싱(indexing)할 필요가 없을 것입니다. 그리고 그것은 괜찮습니다. 만약 당신이 그 프로젝트(project)의 모든 오픈 소스(open source) 종속성을 검색하고 싶다면, 여러분 모두 VS 코드(VS code)나 커서(cursor)에서 이것을 해봤을 것입니다. 노드 모듈(node modules) 폴더를 검색해 봤을 것입니다. 그 검색을 실행하는 데 정말 오랜 시간이 걸립니다. 그것은 많은 데이터(data)입니다. 그래서 그것을 인덱싱(indexing)하고, 다시 말하지만, 쓰기 시간 성능을 쿼리(query) 시간 성능과 교환하는 것입니다. 그것이 인덱싱(indexing)입니다. 신비화하지 마세요. 이것은 무엇입니까? 네, 그것이 인덱싱(indexing)입니다. 임베딩(embeddings)은 오늘날 의미론적 유사성(semantic similarity)으로 알려져 있습니다. 임베딩(embeddings)은 정보 압축의 일반적인 개념이며, 실제로 임베딩(embeddings)을 사용할 수 있는 많은 도구가 있습니다. 코드용 임베딩(embeddings)은 아직 매우 초기 단계이며 저평가되어 있다고 생각합니다. 하지만 정규식(regex)은 분명히 엄청나게 가치 있는 도구이며, 우리는 실제로 크로마(Chroma) 내부에서 단일 노드(single node)와 분산 환경 모두에서 정규식 검색(regex search)을 기본적으로 지원합니다. 그래서 크로마(Chroma) 내부에서 정규식 검색(regex search)을 할 수 있습니다. 왜냐하면 우리는 그것을 코드 검색(code search)을 위한 매우 강력한 도구로 보았기 때문입니다. 훌륭합니다. 그리고 우리는 대규모 데이터 볼륨(data volumes)에서 정규식 검색(regex search)을 빠르게 하기 위해 인덱스(indexes)를 구축합니다. 당신이 언급한 코딩 사용 사례에서 말입니다. 크로마(Chroma)에 추가한 또 다른 기능은 포킹(forking) 기능입니다. 기존 인덱스(index)를 가져와서 100밀리초(milliseconds) 미만에 몇 푼으로 그 인덱스(index)의 복사본을 만들 수 있습니다. 그렇게 하면, 변경된 파일에 대한 차이점(diff)을 새 인덱스(index)에 적용할 수 있습니다. 그래서 논리적으로 변경되는 모든 데이터(data) 코퍼스(corpus)는 매우 빠른 재인덱싱(re-indexing) 결과를 얻습니다. 하지만 이제 각 커밋(commit)에 대한 인덱스(index)를 가질 수 있습니다. 그래서 다른 커밋(commits)을 검색하거나 다른 브랜치(branches) 또는 다른 릴리스 태그(release tags)를 검색하고 싶다면, 논리적으로 버전 관리되는 모든 데이터(data) 코퍼스(corpus)를 이제 매우 쉽고 매우 저렴하며 비용 효율적으로 검색할 수 있습니다. 그래서 네, 그것이 제가 정규식(regex)과 인덱싱(indexing) 및 임베딩(embeddings)에 대해 생각하는 방식입니다. 네, 여기서 바늘은 계속 움직입니다. 답을 가지고 있다고 주장하는 사람은 누구든, 그냥 그들의 말을 듣지 말아야 한다고 생각합니다.
**제프(Jeff) [00:30:02]:** 코드 임베딩(embeddings)이 저평가되어 있다고 말씀하셨는데, 그 이유는 무엇이라고 생각하십니까? 대부분의 사람들은 인터넷에서 훈련된 일반 임베딩 모델(embedding models)을 가져와서 코드에 사용하려고 합니다. 그리고 일부 사용 사례에서는 괜찮게 작동하지만, 모든 사용 사례에서 훌륭하게 작동합니까? 모르겠습니다. 이러한 다른 기본 요소(primitives)와 그것들이 무엇에 유용한지에 대해 생각하는 또 다른 방법은, 근본적으로 우리는 신호(signal)를 찾으려고 노력하고 있다는 것입니다. 텍스트 검색(text search)은 정말 잘 작동합니다. 어휘 검색(lexical search), 텍스트 검색(text search)은 쿼리(query)를 작성하는 사람이 데이터(data)를 알 때 정말 잘 작동합니다. 만약 제가 구글 드라이브(Google Drive)에서 모든 투자자가 있는 스프레드시트(spreadsheet)를 찾고 싶다면, 그냥 '자본금 테이블(cap table)'이라고 입력할 것입니다. 왜냐하면 제가 구글 드라이브(Google Drive)에 '자본금 테이블(cap table)'이라는 스프레드시트(spreadsheet)가 있다는 것을 알기 때문입니다. 전체 텍스트 검색(full text search)은 훌륭합니다. 완벽합니다. 저는 제 데이터(data)의 주제 전문가입니다。 이제, 만약 당신이 그 파일을 찾고 싶고 제가 자본금 테이블(cap table)이라는 스프레드시트(spreadsheet)를 가지고 있다는 것을 몰랐다면, 당신은 "모든 투자자 목록이 있는 스프레드시트(spreadsheet)"라고 입력할 것입니다. 그리고 물론, 임베딩 공간(embedding space), 의미 공간(semantic space)에서는 그것이 일치할 것입니다. 그래서 다시 말하지만, 이것들은 단지 다른 도구일 뿐이라고 생각합니다. 그리고 누가 쿼리(query)를 작성하는지에 따라 다릅니다. 그들이 데이터(data)에 대해 어떤 전문 지식을 가지고 있는지에 따라 다릅니다. 어떤 도구의 조합이 적합할까요? 제 생각에는 오늘날 코드의 경우, 쿼리(queries)의 약 90% 또는 85%가 정규식(Regex)으로 만족스럽게 실행될 수 있을 것입니다. 정규식(Regex)은 분명히 구글 코드 검색(Google Code Search), 깃허브 코드 검색(GitHub Code Search)에서 사용되는 지배적인 패턴(pattern)입니다. 하지만 임베딩(embeddings)을 함께 사용함으로써 15% 또는 10% 또는 5%의 개선을 얻을 수도 있습니다. 매우 정교한 팀은 코드 검색(code search) 스택(stack)의 일부로 코드용 임베딩(embeddings)도 사용합니다. 그리고 그들이 불필요하게 돈을 쓰는 것을 즐긴다고 가정해서는 안 됩니다. 그들은 거기서 약간의 이점을 얻고 있습니다. 그리고 물론, 최고 수준에 도달하고 시장을 장악하며 사용자(users)에게 최고의 서비스를 제공하고자 하는 회사들에게는, 이것이 AI로 훌륭한 소프트웨어(software)를 구축하는 것이 의미하는 바입니다. 80%는 꽤 쉽습니다. 하지만 80%에서 100%로 가는 것이 모든 작업이 있는 곳입니다. 그리고 개선점 하나하나가 점수판의 점수와 같습니다. 그리고 그것은 사용자(users)들이 중요하게 생각하는 점이라고 생각합니다. 그리고 그것은 기본적으로 사용자(users)에게 더 나은 서비스를 제공하는 데 사용할 수 있는 점입니다.

**코드 청크 재작성(Chunk Rewriting) 및 쿼리 최적화(Query Optimization)**
**알레시오(Alessio) [00:32:04]:** 개발자 경험(developer experience) 대 에이전트 경험(agent experience)에 대해 어떻게 생각하십니까? 이것은 또 다른 경우인데, 코드를 임베딩(embed)하기 더 쉬운 방식으로 재포맷(reformat)하고 재작성한 다음 거기서 모델(models)을 훈련해야 할까요? 그 스펙트럼(spectrum)에서 당신은 어디에 있습니까? 네.
**제프(Jeff) [00:32:19]:** 음, 일부 사용 사례에서 잘 작동하는 것을 본 도구 중 하나는 코드를 임베딩(embed)하는 대신, 먼저 LLM이 이 코드가 무엇을 하는지에 대한 자연어 설명(natural language description)을 생성하도록 하는 것입니다. 그리고 자연어 설명만 임베딩(embed)하거나, 그것과 코드를 함께 임베딩(embed)하거나, 별도로 임베딩(embed)하여 별도의 벡터 검색(vector search) 인덱스(indexes)에 넣는 것입니다. 청크 재작성(chunk rewriting)은 그것이 무엇인지에 대한 광범위한 범주입니다. 다시 말하지만, 여기서 아이디어는 인덱싱(indexing)과 관련이 있다는 것입니다. 즉, 쓰기 또는 수집 파이프라인(pipeline)에 넣을 수 있는 구조화된 정보(structured information)는 가능한 한 많이 넣어야 합니다. 추출할 수 있는 모든 메타데이터(metadata)는 수집 시점에 하세요. 할 수 있는 모든 청크 재작성(chunk rewriting)은 수집 시점에 하세요. 수집 측에서 가능한 한 많은 신호(signals)를 추출하고 미리 구워내려고 노력하는 데 정말 투자한다면, 다운스트림 쿼리(query) 작업이 훨씬 쉬워진다고 생각합니다. 하지만 또한, 우리가 여기에 있으니 말할 가치가 있습니다. 사람들은 작동하기를 원하는 쿼리(queries)와 반환해야 하는 청크(chunks)의 작은 골든 데이터 세트(golden data sets)를 만들어야 합니다. 그리고 나서 무엇이 중요한지 정량적으로 평가할 수 있습니다. 아마도 당신의 애플리케이션(application)에 많은 화려한 것들을 할 필요가 없을 수도 있습니다. 사용 사례에 따라 정규식(regex)만 사용하거나 벡터 검색(vector search)만 사용하는 것이 당신에게 필요한 전부일 수도 있습니다. 다시 말하지만, 답을 안다고 주장하는 사람은 누구든, 가장 먼저 물어봐야 할 것은 "당신의 데이터(data)를 보여줘"입니다. 그리고 만약 그들이 데이터(data)가 없다면, 당신은 이미 답을 가지고 있는 것입니다.
**스윅스(Swyx) [00:33:47]:** 당신이 컨퍼런스(conference)에서 했던 강연에 대해 칭찬하겠습니다. "데이터(data)를 보는 방법"입니다. 네. 데이터(data)를 보는 것은 중요합니다. 골든 데이터 세트(golden data sets)를 가지는 것은 모두 좋은 관행(practices)입니다. 누군가가 작은 팸플릿(pamphlet)에 넣어 "AI 엔지니어링(engineering)의 10계명"이라고 부르면 좋을 것 같습니다. 알겠습니다. 당신이 그렇게 할 수도 있습니다. 네. "너는 너의 데이터를 보라."

**트랜스포머(Transformer) 아키텍처(Architecture) 진화 및 검색 시스템(Retrieval Systems)**
**스윅스(Swyx) [00:34:07]:** 이제 메모리(memory)로 넘어갈 예정이지만, 거기서 마무리하고 싶습니다.
**제프(Jeff) [00:34:09]:** 당신이 항상 열변을 토하고 싶어 하는 다른 주제에 대해 여지를 남겨두고 싶습니다. 네, 그것은 위험한 질문입니다.
**스윅스(Swyx) [00:34:18]:** 제가 하나 있습니다. 왜냐하면 이 대화에 어디에 넣어야 할지 몰랐지만, 우리가 그것에 가까이 다가가고 있었기 때문입니다. 원래 트랜스포머(transformer)는 인코더-디코더(encoder-decoder) 아키텍처(architecture)였습니다. 음. 그리고 GPT는 대부분의 트랜스포머(transformers)를 디코더(decoder) 전용으로 바꿉니다. 하지만 우리는 또한 모든 임베딩 모델(embedding models)을 인코더(encoder) 전용 모델(models)로 인코딩(encoding)하고 있습니다. 그래서 어떤 의미에서는 트랜스포머(transformer)를 분리한 셈입니다. 먼저 인코더(encoder) 전용 모델(model)로 모든 것을 인코딩(encoding)하고, 크로마(Chroma)와 같은 벡터 데이터베이스(vector database)에 넣습니다. 크로마(Chroma)는 다른 것도 하지만요. 음. 그리고 나서 LLM으로 디코딩(decoding)합니다. 그리고 저는 이것이 전체 아키텍처(architecture)에 대한 매우 흥미로운 메타 학습이라고 생각합니다. 모델(model)에서 모델(models)과 시스템(system)으로 나아가는 것입니다. 그리고 그것에 대한 당신의 생각이나 제가 방금 말한 것에 대한 수정 사항이 있는지 궁금합니다.
**제프(Jeff) [00:35:20]:** 오늘날 우리가 일을 하는 방식은 매우 조잡하고 5년 또는 10년 후에는 원시적으로 느껴질 것이라는 직관이 있다고 생각합니다. 왜 우리는 자연어로 돌아갑니까? 왜 우리는 임베딩(embeddings)을 기능적으로 잠재 공간(latent space)에 다시 넣을 모델(models)에 직접 전달하지 않습니까? 네. 그들은 매우 얇은 임베딩 레이어(embedding layer)를 가지고 있습니다. 네. 네. 그래서 미래의 검색 시스템(retrieval systems)에 대해 사실일 수 있는 몇 가지가 있다고 생각합니다. 첫째, 그들은 잠재 공간(latent space)에 머무릅니다. 자연어로 돌아가지 않습니다. 둘째, 이것은 실제로 변하기 시작하고 있으며 정말 흥미롭지만, 오랫동안 우리는 생성(generation)당 한 번의 검색(retrieval)을 수행했습니다. 알겠습니다. 검색(retrieve)하고, 그리고 나서 N개의 토큰(tokens)을 스트리밍(stream)합니다. 왜 우리는 필요할 때 계속해서 검색(retrieve)하지 않습니까? 음, 그것을 부르지 마세요. 하지만 몇 주 전에 논문이나 깃허브(GitHub)에 나온 것이 있었습니다. 불행히도 RAG R1이라고 불렸던 것 같습니다. 그들은 DCR1에게 검색(retrieve)하는 방법을 가르칩니다. 그래서 내부적인 사고의 연쇄와 집중적인 컴퓨트(compute)에서 실제로 검색(search)하고 있습니다.
**스윅스(Swyx) [00:36:22]:** 검색 증강 언어 모델(retrieval augmented language models)도 있습니다.
**제프(Jeff) [00:36:24]:** 이것은 더 오래된 논문이라고 생각합니다. 네. 네. REALM과 RETRO 등 많은 역사가 있습니다. 음, 그래서 저는,
**스윅스(Swyx) [00:36:31]:** 어쩐지 그렇게 인기가 많지는 않습니다.
**제프(Jeff) [00:36:32]:** 왜 그런지 모르겠습니다. 어쩐지 그렇게 인기가 많지는 않습니다. 음, 많은 것들이 검색기(retriever)나 언어 모델(language model)이 고정되어야 하는 문제가 있습니다. 그리고 코퍼스(corpus)는 변경될 수 없는데, 대부분의 개발자(developers)는 개발자 경험(developer experience)을 다루고 싶어 하지 않습니다.
**스윅스(Swyx) [00:36:45]:** 이득이 그렇게 높다면 우리는 할 것이라고 말하고 싶습니다. 아니면 연구소(labs)가 당신이 그렇게 하는 것을 원하지 않습니다. 모르겠습니다. 네.
**제프(Jeff) [00:36:54]:** 연구소(labs)는 엄청난 영향력을 가지고 있습니다. 엄청난 영향력을 가지고 있습니다. 또한 그것을 함으로써 점수를 얻지 못한다고 생각합니다. 그냥, 아무도 신경 쓰지 않습니다. 지위 게임은 당신의 문제를 해결하는 것에 대해 보상하지 않습니다. 그래서 네. 그래서 광범위하게. 지속적인 검색(retrieval)이 현장에 나오는 것을 보는 것은 흥미로울 것입니다. 첫째, 둘째, 임베딩 공간(embedding space)에 머무르는 것은 매우 흥미로울 것입니다. 그리고 네, GPU와 GPU 메모리(memory)에 정보를 페이징(paging)하는 방식에 대해서도 흥미로운 점이 있습니다. 훨씬 더 효율적으로 할 수 있다고 생각합니다. 음, 이것은 5년 또는 10년 후의 미래에 대해 우리가 생각하는 것이지만, 네, 우리가 되돌아볼 때, 오늘날 우리가 일을 하는 방식은 우스꽝스럽게 조잡했다고 생각합니다.
**스윅스(Swyx) [00:37:34]:** 아마도 아닐 수도 있습니다. 우리는 IMO, 언어만으로 문제를 해결하고 있습니다. 네, 훌륭합니다. 저는 여전히 그것의 함의를 연구하고 있습니다. 그것은 여전히 엄청난 성과이지만, 제가 생각했던 방식과는 매우 다릅니다.
**알레시오(Alessio) [00:37:47]:** 메모리(memory)가 컨텍스트 엔지니어링(context engineering)의 이점이라고 말씀하셨습니다. 당신은 "메모리(memory)를 너무 복잡하게 만들지 마세요"라는 무작위 트윗(Twitter)을 올렸습니다. 메모리(memory)에 대해 어떻게 생각하십니까? 그리고 우리가 연결하지 못했을 수도 있는 컨텍스트 엔지니어링(context engineering)의 다른 이점은 무엇입니까?

**컨텍스트 엔지니어링(Context Engineering)의 이점으로서의 메모리(Memory)**
**제프(Jeff) [00:38:06]:** 메모리(memory)는 좋은 용어라고 생각합니다. 많은 사람들에게 매우 읽기 쉽습니다. 다시 말하지만, 이것은 LLM의 의인화를 계속하는 것입니다. 우리는 우리 자신이 어떻게 기억을 사용하는지 이해합니다. 우리는 작업을 수행하는 방법을 배우기 위해 기억을 사용하는 데 매우 능숙합니다. 그리고 그 학습은 새로운 환경에 유연하게 적용됩니다. 그리고 AI를 가져와서 AI 옆에 앉아 10분 또는 몇 시간 동안 지시하는 아이디어는, 당신이 원하는 것을 말하면 AI가 그것을 수행하고, 당신은 "다음번에는 이렇게 해"라고 말하는 것입니다. 인간에게 하는 것과 똑같이 말입니다. 그 10분 또는 몇 시간 후에 AI는 이제 인간이 할 수 있는 것과 같은 신뢰성 수준으로 그것을 할 수 있습니다. 이것은 엄청나게 매력적이고 흥미로운 비전(vision)입니다. 저는 그것이 일어날 것이라고 생각합니다。 그리고 메모리(memory)는 모든 사람이 이해할 수 있는 용어라고 생각합니다. 우리 모두는 우리 엄마들도 이해합니다. 그리고 메모리(memory)의 이점도 매우 매력적입니다. 하지만 메모리(memory)의 내부 작동 방식은 무엇입니까? 그것은 여전히 컨텍스트 엔지니어링(context engineering)일 뿐이라고 생각합니다. 즉, 컨텍스트 창(context window)에 올바른 정보를 넣는 방법의 영역입니다. 그래서 네, 저는 메모리(memory)를 이점으로 생각하고, 컨텍스트 엔지니어링(context engineering)은 그 이점을 제공하는 도구라고 생각합니다. 그리고 다른 것들도 있을 수 있습니다. 즉, 메모리(memory)의 어떤 버전에서는 "아, 당신은 실제로 데이터(data)를 통해 모델(model)을 개선하기 위해 RL을 사용하고 있다"와 같을 수도 있습니다. 그래서 저는 컨텍스트(context)만 변경하는 것이 작업을 훌륭하게 수행하는 유일한 도구라고 주장하는 것은 아닙니다. 하지만 그것은 매우 중요한 부분이라고 생각합니다.
**알레시오(Alessio) [00:39:43]:** 이 대화를 바탕으로 암묵적인 선호는 무엇인가와 같은 메모리(memory)를 합성하는 것과, 이 프롬프트(prompt)를 바탕으로 어떤 메모리(memory)를 넣어야 하는가라는 다른 측면 사이에 큰 차이가 있다고 생각하십니까?
**제프(Jeff) [00:39:58]:** 저는 그것들이 모두 동일한 데이터(data)에 의해 공급될 것이라고 생각합니다. 더 나은 검색(retrieve) 방법을 알려주는 동일한 피드백 신호(feedback signals)가 무엇을 더 잘 기억해야 하는지도 알려줄 것입니다. 그래서 저는 그것들이 실제로 다른 문제라고 생각하지 않습니다. 저는 그것들이 동일한 문제라고 생각합니다.

**AI 메모리(Memory) 구조화 및 오프라인 압축(Offline Compaction)**
**스윅스(Swyx) [00:40:13]:** 저에게는 좀 더 씨름하고 있는 것은 메모리(memory)의 구조가 무엇인가 하는 것입니다. 그것은 의미가 있습니다. 그래서 장기 기억, 단기 기억과 같은 모든 비유가 분명히 있습니다. 수면과 관련된 무언가를 만들려고 노력해 봅시다. 저는 LLM이 잠자는 동안 어떤 종류의 배치 수집 주기, 아마도 가비지 컬렉션(garbage collection) 주기가 있어야 한다고 생각합니다. 하지만 무엇이 의미가 있는지 모르겠습니다. 우리는 인간이 어떻게 작동한다고 생각하는지에 기반하여 모든 비유를 만들고 있지만, AI는 같은 방식으로 작동하지 않을 수도 있습니다. 네. 당신이 본 것 중에 작동하는 것이 있는지 궁금합니다.
**제프(Jeff) [00:40:48]:** 네, 저는 항상, 다시 말하지만, 이 대화의 일관된 흐름으로서, 새로운 개념과 새로운 약어를 만들고, 갑자기 "여기 10가지 유형의 메모리(memory)가 있습니다"와 같은 정보 차트가 있을 때 약간 불안해집니다. 그리고 당신은 "왜?"라고 생각합니다. 이것들은 실제로 자세히 보면 모두 같은 것입니다. 달라야 할까요? 당신은 사람들의 마음을 날려버려야 합니다. 아니요, 그렇지 않다고 생각합니다. 모르겠습니다. 슬롯 머신(slot machine)과 슬롯 머신(slot machine)을 저항해야 합니다.
**제프(Jeff) [00:41:16]:** 압축(compaction)은 항상 유용한 개념이었습니다. 심지어 데이터베이스(databases)에서도요. 컴퓨터의 데이터베이스(databases)에서 우리는 모두 1998년에 윈도우(Windows) 머신에서 디스크 조각 모음(Defrag)을 실행했던 것을 기억합니다. 그래서 네, 다시 말하지만. 우리 중 일부는 그렇게 할 만큼 나이가 많지 않습니다. 저는 그렇습니다. 이 테이블에는 없습니다. 그리고 네. 분명히, 분명히 오프라인 처리(offline processing)는 도움이 되며, 이 경우에도 도움이 된다고 생각합니다. 그리고 이전에 이야기했듯이, 인덱싱(indexing)의 목표는 무엇입니까? 인덱싱(indexing)의 목표는 쓰기 시간 성능을 쿼리(query) 시간 성능과 교환하는 것입니다. 압축(compaction)은 쓰기 시간 성능과 같은 도구 상자의 또 다른 도구입니다. 데이터를 재인덱싱(re-indexing)하는 것입니다.
**스윅스(Swyx) [00:41:52]:** 인덱싱(indexing)이 아니라 실제로 인덱싱(indexing)입니다.
**제프(Jeff) [00:41:55]:** 재인덱싱(re-indexing)과 비슷합니다. 네. 데이터를 가져와서 "아, 아마도 이 두 데이터 포인트(data points)는 병합되어야 할 것이다. 아마도 분할되어야 할 것이다. 아마도 재작성되어야 할 것이다. 아마도 새로운 메타데이터(metadata)를 추출할 수 있을 것이다"라고 생각합니다. 우리 애플리케이션(application)이 어떻게 작동하는지에 대한 신호(signal)를 살펴봅시다. 우리가 올바른 것을 기억하고 있는지 아닌지를 알아내려고 노력합시다. AI 시스템(systems)이 지속적으로 자체 개선되도록 돕는 많은 오프라인 컴퓨트(compute)와 추론이 내부적으로 있을 것이라는 생각은 확실합니다.
**알레시오(Alessio) [00:42:19]:** 우리가 이야기했던 수면 시간 컴퓨트(compute)의 일부는 답변을 미리 계산하는 것이었습니다. 즉, 당신이 가지고 있는 데이터를 바탕으로, 사람이 물어볼 가능성이 있는 질문은 무엇이며, 그것들을 미리 계산할 수 있습니까? 크로마(Chroma)의 관점에서 그것에 대해 어떻게 생각하십니까? 우리는 기술 보고서(technical report)를 발표했습니다. 네.
**제프(Jeff) [00:42:35]:** 우리는 약 3개월 전에 기술 보고서(technical report)를 발표했습니다. 제목은 생성형 벤치마킹(Generative Benchmarking)입니다. 그리고 거기서의 아이디어는, 골든 데이터 세트(golden data set)를 가지는 것이 정말 강력하다는 것입니다. 골든 데이터 세트(golden data set)는 쿼리(queries) 목록과 그 쿼리(queries)가 반환해야 하는 청크(chunks) 목록을 가지고 있는 것입니다. 그리고 이제 당신은 "이 검색 전략(retrieval strategy)은 이 쿼리(queries)에 대해 80%의 청크(chunks)를 제공한다. 반면에 임베딩 모델(embedding model)을 변경하면 이제 90%의 청크(chunks)를 얻는다. 그것이 더 낫다"고 말할 수 있습니다. 그리고 좋은 엔지니어링(engineering) 결정을 내릴 때 비용과 속도, API(API) 신뢰성 및 기타 요인들을 고려해야 합니다. 하지만 이제 시스템(system)의 변경 사항을 측정할 수 있습니다. 그래서 우리가 발견한 것은 개발자(developers)들이 데이터(data)를 가지고 있었다는 것입니다. 그들은 청크(chunks)를 가지고 있었습니다. 그들은 답변을 가지고 있었습니다. 하지만 그들은 쿼리(queries)를 가지고 있지 않았습니다. 우리는 LLM이 청크(chunks)에서 좋은 쿼리(queries)를 작성하도록 가르치는 방법에 대한 전체 기술 보고서(technical report)를 작성했습니다. 왜냐하면 다시 말하지만, 당신은 청크-쿼리(chunk-query) 쌍을 원하기 때문입니다. 그래서 청크(chunks)가 있다면 쿼리(queries)가 필요합니다. 알겠습니다. 인간이 수동으로 주석을 달 수 있습니다. 하지만 인간은 일관성이 없고 게으릅니다. 그리고 QA는 어렵습니다. 그래서 LLM에게 그것을 하도록 가르칠 수 있을까요? 그래서 우리는 전체 기술 보고서(technical report)를 작성하고 그것을 잘 수행하기 위한 전략을 증명했습니다. 그래서 QA 쌍을 생성하는 것이 검색 시스템(retrieval system)을 벤치마킹(benchmarking)하는 데 정말 중요하다고 생각합니다. 골든 데이터 세트(golden data set)는 솔직히 많은 경우에 미세 조정(fine-tune)하는 데 사용할 데이터 세트(data set)이기도 합니다. 그래서 네, 거기에는 분명히 매우 저평가된 것이 있습니다. 네.
**스윅스(Swyx) [00:43:58]:** 거기에 플러스 원을 던지겠습니다. 컨텍스트 로트(context rot) 논문이 받는 관심만큼이나, 생성형 벤치마킹(generative benchmarking)이 저에게는 더 큰 아하(aha) 순간이었다고 생각합니다. 왜냐하면 저는 이전에 이 개념을 접해본 적이 없었기 때문입니다. 그리고 실제로 더 많은 사람들이 자신의 개인적인 상황에 적용할 것이라고 생각합니다. 반면에 컨텍스트 로트(context rot)는 일반적으로 "네, 모델(models)을 그렇게 많이 믿지 마세요"와 같습니다. 하지만 더 나은 컨텍스트 엔지니어링(context engineering)을 하는 것 외에는 할 수 있는 일이 많지 않습니다. 네. 네. 반면에 생성형 벤치마킹(generative benchmarking)은 "네, 평가를 생성하세요"와 같습니다. 그리고 그 일부는 데이터 세트(data sets)가 필요할 것입니다. 그리고 그것은 모든 사람이 옹호하는 모든 모범 사례(best practices)의 위치로 당신을 이끌 것입니다.
**제프(Jeff) [00:44:34]:** 그래서 그것은 정말 좋은 작업입니다. 응용 기계 학습(applied machine learning) 개발자 도구(developer tools) 분야에서 10년 동안 일하면서, 매우 고품질의 작은 레이블 데이터 세트(label data set)의 수익이 너무 높다는 것을 알았습니다. 모든 사람들은 100만 개의 예시가 필요하다고 생각합니다. 아니요. 실제로 수백 개의 고품질 예시만으로도 엄청나게 유용합니다. 그리고 고객들에게 항상 저는 "팀에게 목요일 밤에 회의실에 모여 피자를 주문하고 몇 시간 동안 데이터 레이블링(data labeling) 파티를 하자고 말해야 합니다. 그것이 이것을 부트스트랩(bootstrap)하는 데 필요한 전부입니다"라고 말합니다.
**스윅스(Swyx) [00:45:08]:** 구글(Google)도 이렇게 합니다. 오픈AI(OpenAI)도 이렇게 합니다. 앤트로픽(Anthropic)도 이렇게 합니다. 당신은 이것을 하지 않을 만큼 대단하지 않습니다. 훌륭합니다. 네. 정확히 그렇습니다. 네. 네. 당신의 데이터(data)를 보세요. 다시 말하지만, 그것이 중요합니다. 아마도 그것을 "데이터(data)를 레이블링(labeling)하라"고 분류해야 할 것입니다. "데이터(data)를 보라"가 아니라요. 왜냐하면 "보라"는 너무… 동의합니다. 네. 좀 더… 보기 전용. 맞습니다. 동의합니다. 네. 읽기 및 쓰기. 읽기 및 쓰기. 당신이 언급했으니, 제가 정정해야 할 것 같습니다. 표준 인지(standard cognition)가 아니라 표준 사이보그(standard cyborg)였습니다. 당신에 대한 제가 가장 좋아하는 사실은 당신도 다리가 사이보그(cyborg)라는 것입니다. 사실입니다. 사람들은… 제프(Jeff)를 직접 만나면 그것에 대해 물어봐야 합니다. 아니면 묻지 마세요. 모르겠습니다. 신경 쓰지 않습니다. 신경 쓰지 않습니다. 표준 사이보그(standard cyborg), 마이티 하이브(Mighty Hive), 그리고 노우 잇(Know It). 크로마(Chroma)에 적용하고 있는 교훈은 무엇입니까? 네.

**이전 스타트업(Startups)의 교훈과 목적 있는 구축**
**제프(Jeff) [00:45:46]:** 셀 수 없을 정도로 많습니다. 클리셰(cliche)이긴 하지만, 이 모든 것에 대해 자기 성찰적이고 자신에게 솔직해지는 것은 매우 어렵습니다. 하지만 저는 당신의 삶이 매우 짧다고 보는 것이 중요하다고 생각합니다. 바람 속의 증기처럼 말이죠. 따라서 당신이 정말로 좋아하는 일만 하고, 당신이 함께 시간을 보내는 것을 좋아하는 사람들과만 그 일을 하고, 당신이 서비스하는 것을 좋아하는 고객에게만 서비스하는 것이 매우 유용한 북극성(North Star)입니다. 그리고 그것이 돈을 많이 버는 북극성(North Star)이 아닐 수도 있습니다. 500만 달러를 벌기 위해 사람들을 속이는 더 빠른 방법이 있을 수도 있습니다. 하지만 제가 이전 경험을 되돌아보면, 물론 더 자세히 이야기할 수 있습니다. 저는 항상 트레이드오프(trade-offs)를 하고 있었습니다. 함께 일하는 사람들과 트레이드오프(trade-offs)를 하거나, 서비스하는 고객과 트레이드오프(trade-offs)를 하거나, 기술(technology)과 그것에 대한 자부심과 트레이드오프(trade-offs)를 하고 있었습니다. 그리고 아마도 나이 때문일 수도 있습니다. 모르겠습니다. 하지만 나이가 들수록 저는 제가 할 수 있는 최고의 일을 하고 싶습니다. 그리고 그 일이 단지 훌륭한 작업일 뿐만 아니라, 가장 많은 사람들에게 보여지기를 원합니다. 왜냐하면 궁극적으로 그것이 영향력(impact)의 모습이기 때문입니다. 영향력(impact)은 훌륭한 것을 발명하고 아무도 사용하지 않는 것이 아닙니다. 영향력(impact)은 훌륭한 것을 발명하고 가능한 한 많은 사람들이 사용하는 것입니다.
**스윅스(Swyx) [00:47:01]:** 그 중 어떤 것이 종교, 기독교에 의해 인도됩니까? 민감한 질문이라면 건너뛸 수 있습니다. 하지만 제가 이 질문을 하는 이유는, 당신이 밸리(Valley)에서 공개적으로, 외적으로, 긍정적으로 종교적인 사람들의 수가 증가하는 사람들 중 한 명이라고 생각하기 때문입니다. 그리고 저는 그것을 탐구하고 싶습니다. 저는 그렇게 종교적이지는 않지만, 그것이 당신의 영향력(impact)에 대한 당신의 관점을 어떻게 형성하는지 궁금합니다. 당신의 선택에 대해 방금 말씀하신 내용에 약간의 그런 부분이 있었지만, 그것을 더 자세히 설명하고 싶었습니다.

**실리콘 밸리(Silicon Valley)의 종교와 가치**
**제프(Jeff) [00:47:32]:** 현대 사회는 점점 더 허무주의적이라고 생각합니다. 아무것도 중요하지 않습니다. 부조리주의적이죠. 모든 것이 소극입니다. 모든 것이 권력입니다. 모든 것이 코미디입니다. 모든 것이 코미디입니다. 밈(meme)입니다. 네. 네, 정확히 그렇습니다. 그래서 인간의 번영이 어떤 모습인지에 대한 진정한 신념을 가진 사람들을 만나는 것은 매우 드뭅니다. 그리고 그것을 실현하기 위해 많은 것을 희생할 의지가 있는 사람들을 만나는 것은 매우 드뭅니다. 평생 동안 완성되는 것을 보지 못할 수도 있는 일을 시작하는 사람들을 말입니다. 사람들이 완성하는 데 수세기가 걸릴 프로젝트(projects)를 시작하는 것이 흔한 일이었습니다. 네. 그리고 이제는 점점 더 그렇지 않습니다.
**스윅스(Swyx) [00:48:23]:** 떠오르는 이미지는 바르셀로나(Barcelona)의 사그라다 파밀리아(Sagrada Familia)입니다. 300년 전에 시작되었고 내년에 완공될 예정이라고 생각합니다. 네.
**제프(Jeff) [00:48:33]:** 건설 중인 것을 봤지만, 완공된 것을 보는 것도 기대됩니다. 네. 이미 예약이 꽉 찼을 것입니다. 네. 네. 그래서, 실리콘 밸리(Silicon Valley)에는 실제로 많은 종교가 있습니다. AGI도 종교라고 생각합니다. 그것은 악의 문제를 가지고 있습니다. 우리는 충분한 지능이 없습니다. 그것은 해결책, 데우스 엑스 마키나(deus ex machina)를 가지고 있습니다. AGI, 특이점(singularity)이 올 것이고, 그것은 인류를 구원할 것입니다. 왜냐하면 우리는 이제 무한하고 자유로운 지능을 가질 것이기 때문입니다. 따라서 우리의 모든 문제가 해결될 것입니다. 그리고 우리는 영원히 은혜의 손바닥 안에서 살 것입니다. 그것은 죽음을 해결할 것입니다. 그래서 저는 실리콘 밸리(Silicon Valley)에 여전히 종교가 존재한다고 생각합니다. 종교의 보존이 있고, 당신은 그것을 없앨 수 없다고 생각합니다. 네. 신 유전자. 네. 당신은 이것에 대해 다른 용어를 가지고 있습니다. 하지만 저는 5년 이상 존재하지 않은 종교에 대해서는 항상 회의적입니다. 그렇게 말해 두겠습니다. 네.
**스윅스(Swyx) [00:49:27]:** 생존자 편향(survivorship bias)이 있습니다. 어쨌든, 저는 당신이 제가 아는 가장 저명한 사람들 중 한 명이라고 생각합니다. 그리고 당신들은 선한 영향력(force for good)이라고 생각합니다. 그리고 저는 더 많은 것을 장려하고 싶습니다. 모르겠습니다. 사람들은 자신보다 더 큰 것을 믿고, 자신이 앉지 않을 나무를 심어야 합니다. 제가 인용구를 왜곡하고 있습니까? 그것이 실제로 성경 구절입니까? 성경 구절은 아니라고 생각합니다. 하지만 저는 그 인용구를 좋아합니다. 좋은 인용구입니다.
**제프(Jeff) [00:49:52]:** 네.
**스윅스(Swyx) [00:49:52]:** 플러스 원. 자신만을 위해 살 때 사회는 정말 붕괴된다고 생각합니다. 정말 그렇습니다. 동의합니다.
**알레시오(Alessio) [00:49:59]:** 누가 당신의 디자인을 합니까? 당신의 모든 굿즈(swag)는 훌륭합니다. 사무실은 훌륭해 보입니다. 웹사이트는 훌륭해 보입니다. 문서는 훌륭해 보입니다. 그 중 얼마만큼이 당신의 의견입니까? 그 중 얼마만큼이 그냥 이해하는 사람을 가지고 있습니까? 그리고 브랜드(brand)를 문화의 일부로 만드는 데 그것이 얼마나 중요합니까?

**기업 문화, 디자인, 브랜드 일관성**
**제프(Jeff) [00:50:18]:** 모든 가치는, 다시 말하지만, 문화에 대한 질문, 콘웨이의 법칙(Conway's Law)에 대한 질문으로 돌아가면, 당신은 당신의 조직도를 출시하고, 어떤 의미에서는 창립자로서 중요하게 생각하는 것을 출시합니다. 그리고 저는 우리가 하는 일의 이 측면에 대해 깊이 신경 씁니다. 그래서 어떤 의미에서는 저에게서 나온다고 생각합니다. 제가 한 모든 일에 대한 모든 공로를 가져갈 수는 없습니다. 우리는 정말 재능 있는 디자이너(designers)들과 함께 일할 기회가 있었습니다. 그리고 우리는 채용도 하고 있습니다. 그래서 이것을 듣고 지원하고 싶은 분들은 지원해 주세요. 제 생각에는 패트릭 콜리슨(Patrick Collison)의 인용구를 베끼는 것은 진부하지만, 그는 "한 가지를 하는 방식이 모든 것을 하는 방식이다"라는 이 아이디어를 가장 공개적으로 구현하는 사람 중 한 명인 것 같습니다. 이것은 그에게서 나온 어두운 인용구가 아니라, 더 광범위한 경구입니다. 그리고 우리가 하는 일에 대한 일관된 경험을 보장하는 것입니다. 당신이 말했듯이, 우리 사무실에 오면 의도적이고 사려 깊다고 느낍니다. 우리 웹사이트에 가면 의도적이고 사려 깊다고 느낍니다. 사용자 API(API)는 의도적이고 사려 깊다고 느낍니다. 인터뷰 프로세스(process)를 거치면 의도적이고 목적이 있다고 느낍니다. 그것을 잃기 너무 쉽습니다. 그것을 잃기 너무 쉽습니다. 그리고 어떤 면에서는 그 기준이 유지되도록 주장해야만 그것을 유지할 수 있습니다. 그리고 그것이 리더(leader)로서 제가 회사(company)를 위해 정말 할 수 있는 주요 일 중 하나라고 생각합니다. 말하기 쑥스럽지만, 당신은 일종의 취향의 큐레이터(curator)가 되어야 합니다. 나가는 모든 것을 승인해야 한다는 것은 아니지만, 최소한 그렇게 할 수 있습니다. 그래서 때때로 회사들은, 아마도 품질이 저하되는 것이 아닐 수도 있습니다. 어떤 한 가지가 나쁘거나 더 나쁘다는 것을 이해하기 어렵습니다. 하지만 사람들은 좋은 것이 무엇인지에 대한 자신만의 표현을 가지고 있습니다. 그리고 그들은 그것을 11로 올리고, 그러면 브랜드(brand)는 일관성이 없어집니다. 이것은 무엇을 의미합니까? 그리고 그들은 무엇을 지지합니까? 다시 말하지만, 더 이상 단일 목소리가 아닙니다. 다시 말하지만, 제가 이것에 완벽하거나 잘한다고 주장하는 것은 아닙니다. 하지만 우리는 분명히 매일 깨어나서 노력합니다.
**스윅스(Swyx) [00:52:19]:** 당신이 명확한 원칙과 가치, 사려 깊음을 전달하는 기술은 매우 강력합니다. 당신이 하는 모든 일에서 말입니다. 네, 저는 당신의 작업에 오랫동안 감명받았습니다.

**크로마(Chroma) 채용: 디자이너(Designers), 연구원(Researchers), 엔지니어(Engineers)**
**알레시오(Alessio) [00:52:36]:** 놓친 것이 있습니까? 디자이너(designers)를 채용하고 있습니다. 사람들이 지원하기를 원하는 다른 열려 있는 역할이 있습니까?
**제프(Jeff) [00:52:42]:** 개발자 도구(developer tools) 분야에서 일하고 싶은 훌륭한 제품 디자이너(product designer)라면, 크로마(Chroma)에서 가장 독특한 기회 중 하나를 가지고 있다고 생각합니다. 우리가 하는 연구의 종류를 확장하는 데 관심이 있다면, 그것도 흥미로운 기회입니다. 우리는 또한 저수준 분산 시스템(distributed systems)에 열정적인 다른 사람들과 함께 일하고 싶어 하는 매우 재능 있는 엔지니어(engineers)들을 항상 채용하고 있습니다. 어떤 면에서는 애플리케이션(application) 개발자(developers)가 할 필요 없도록 모든 어려운 문제를 해결하는 것입니다.
**스윅스(Swyx) [00:53:07]:** 그렇게 말씀하실 때, 저수준 분산 시스템(distributed systems)에 대해 자세히 설명해 주시겠습니까? 사람들은 항상 이렇게 말하고는 "알겠습니다, 러스트(Rust)요? 리눅스 커널(Linux kernel)이요? 무엇을 이야기하는 겁니까?"라고 묻습니다.
**제프(Jeff) [00:53:18]:** 네. 음, 아마도 이것에 대한 유용한 캡슐화(encapsulation)는 러스트(Rust)나 결정론적 시뮬레이션 테스트(simulation testing)와 같은 것에 깊이 신경 쓴다면,
**스윅스(Swyx) [00:53:32]:** 래프트(Raft), 팍소스(Paxos),
**제프(Jeff) [00:53:33]:** TLA 플러스(TLA Plus), 컨센시스(ConsenSys). TLA 플러스(TLA Plus)요? 와우.
**스윅스(Swyx) [00:53:37]:** 당신이 계속해서 "이것들은 당신이 여기서 하는 일을 좋아할 것이라는 대리인(proxies)이다"라고 말한다면, 저는 채용 메시지를 정말 자세히 설명하고 싶습니다. 하지만 또한 제 목표 중 일부는 사람들이, 스타트업(startups)이 정말 채용하려고 하지만 구할 수 없는 AI 엔지니어(engineer)의 유형이 무엇인지 식별하는 것입니다. 왜냐하면 우리가 이것을 더 잘 식별할수록, 저는 그것을 중심으로 어떤 종류의 브랜딩(branding)을 만들고, 이벤트를 만들고, 이들을 얻을 수 있기 때문입니다. 공급 측면과 수요 측면이 있고, 그들은 서로를 찾을 수 없습니다. 네. 그리고 그것이 제가 AI 엔지니어(engineer)를 함께 만든 이유 중 일부였습니다. 네. 하지만 이 분산 시스템(distributed systems) 담당자는 당신과 다른 수백 개의 스타트업(starups)에서 들었던 것입니다. 그들의 기술은 무엇입니까? 그들은 무엇이라고 불립니까? 그들은 무엇을 합니까? 그리고 그 일부는 클라우드(cloud)입니다. 클라우드 엔지니어링(cloud engineering)입니다. 왜냐하면 많은 경우에 AWS를 다루고 있고, 많은 경우에 네트워크 호출 디버깅(debugging)과 일관성 문제, 복제 등을 다루고 있기 때문입니다. 그들은 어디로 갑니까? 그들은 무엇을 합니까? 네. 네. 하지만 그들은 직장에서 TLA 플러스(TLA Plus)를 사용하지 않습니다.
**제프(Jeff) [00:54:36]:** 아마도 아닐 것입니다. 네. 작년에 저는 샌프란시스코 시스템 그룹(SF Systems Group)을 시작했습니다. 네. 독서 그룹입니다. 음, 네, 발표도 있습니다. 그리고 그 목적은 "이 주제에 관심 있는 사람들을 모으자"는 것이었습니다. 왜냐하면 베이 에어리어(Bay area)에는 사람들이 그렇게 할 수 있는 장소가 없었기 때문입니다. 네. 음, 그래서 그것은 계속 진행되고 있습니다. 훌륭합니다. 분명히, 우리 팀에는 이것에 매우 능숙한 사람들이 많이 있습니다. 그래서 우리가 0명이 아니라 6명 또는 7명이 있다는 것입니다. 음, 그리고 당신은 20명이라고 말했지만, 네, 우리가 더 많은 것을 원한다는 것은 아닙니다. 하지만 어떤 면에서는 우리의 제품 로드맵(roadmap)이 매우 명확하고, 다음 18개월 동안 무엇을 구축해야 할지 정확히 알고 있습니다. 하지만 품질은 항상 제한 함수이며, 품질과 집중은 항상 제한 함수입니다. 그리고 네, 저는 항상 신화적인 맨 먼스(man month)에 대한 토지 인정(acknowledgement)을 할 것이지만, 결국 더 많은 사람이 필요합니다. 왜냐하면 더 많은 집중이 필요하기 때문입니다. 그들이 하는 일에 깊이 신경 쓰는 더 많은 사람이 필요합니다. 그리고 AI는 분명히 촉진제이며 도움이 됩니다.
**스윅스(Swyx) [00:55:39]:** 그리고 그것이 우리 팀이 오늘날 많은 경쟁사에 비해 여전히 매우 작은 이유입니다. 왜냐하면 우리는 그런 도구들을 정말 받아들였다고 생각하기 때문입니다. 당신의 커서 샵(cursor shop). 네. 네.
**제프(Jeff) [00:55:48]:** 코드 윈드서프(Code windsurf) 사람들은 원하는 것을 사용합니다. 알겠습니다. 네. 그래서 저는 그 모든 도구들이 내부적으로 어느 정도 사용되고 있다고 생각합니다. 지금까지 어떤 AI 코딩 도구(tools)도 러스트(Rust)에 특히 능숙하다는 것을 발견하지 못했습니다. 음, 왜 그런지는 명확한 이유 외에는 모르겠습니다. 인터넷에 훌륭한 러스트(Rust) 예제가 그렇게 많지 않기 때문입니다. 그래서 음, 네.
**스윅스(Swyx) [00:56:08]:** 네. 러스트(Rust) 오류가 자체 디버깅(debugging)에 도움이 될 것이라고 생각할 것입니다. 맞습니다. 그렇게 생각할 것입니다. 분명히. 분명히 아닙니다. 알겠습니다. 저는 그 분야에서 경험이 전혀 없습니다. 네. 저는 템포럴(Temporal)의 러스트(Rust) SDK(SDK)에 세 가지 기여를 했고, 그것이 러스트(Rust)에 대한 저의 총 경험입니다. 하지만 음, 그것은 분명히 상승 중이라고 생각합니다. 지그(Zig)이고, 러스트(Rust)입니다. 그리고 세 번째 멋진 언어가 있는지 모르겠습니다. 고스트 계정(ghost accounts)이라고 생각합니다. 고 랭(Go Lang). 네. 고스트 계정(ghost accounts). 만약 당신이 그 범주에 속한다면, 제프(Jeff)에게 연락하세요. 하지만 음, 그렇지 않으면 괜찮을 것 같습니다. 와주셔서 감사합니다. 초대해 주셔서 감사합니다. 만나서 반갑습니다.
**제프(Jeff) [00:56:46]:** 감사합니다.

**AI 커뮤니티의 성장과 미래**

AI 기술의 발전은 연구실의 성과를 넘어, 활발한 커뮤니티(community)의 참여와 협력을 통해 더욱 가속화되고 있습니다. 오픈 소스(open source) 프로젝트와 기술 보고서는 지식 공유의 중요한 통로가 되며, 전 세계 개발자들이 함께 문제를 해결하고 혁신을 이끌어낼 수 있는 기반을 제공합니다.

최근에는 AI 시스템의 견고성(robustness)과 신뢰성(reliability)을 높이는 연구가 주목받고 있습니다. 단순한 성능 지표를 넘어, 실제 환경에서의 예측 가능성과 안정적인 작동은 AI 애플리케이션의 성공에 필수적입니다. 이를 위해 다양한 벤치마킹(benchmarking) 방법론과 평가 기준이 개발되고 있으며, 이는 AI 기술의 성숙도를 한 단계 끌어올리는 데 기여할 것입니다.

미래의 AI는 단순한 도구를 넘어, 인간의 삶과 사회 전반에 깊이 통합될 것입니다. 이러한 변화의 흐름 속에서, 우리는 기술적 역량뿐만 아니라 윤리적 책임감과 사회적 통찰력을 함께 갖춘 AI 전문가를 필요로 합니다. 기술의 선한 영향력을 극대화하고 잠재적인 위험을 최소화하기 위한 지속적인 대화와 노력이 중요합니다. AI 기술의 최전선에서 펼쳐지는 흥미로운 이야기를 통해, 여러분의 지적 호기심을 충족시키고 새로운 영감을 얻으시길 바랍니다. 즐겁게 들어주세요!