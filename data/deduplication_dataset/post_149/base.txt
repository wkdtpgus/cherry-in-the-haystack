# **업데이트 제82호: 인공지능(AI) 소송 및 SOPHON**

Author: The Gradient
URL: https://thegradientpub.substack.com/p/update-82-ai-lawsuits-and-sophon

============================================================

Gradient의 82번째 업데이트에 오신 것을 환영합니다! 새로 오셨고 저희 콘텐츠가 마음에 드신다면, 구독하시고 트위터에서 저희를 팔로우해주세요. 저희 뉴스레터는 내용이 길기 때문에, 전체 내용을 보시려면 Substack에서 이 게시물을 확인하셔야 합니다! 언제나처럼, 저희와 함께 글을 쓰고 싶으시다면 이 양식을 통해 제안서를 보내주세요.

**뉴스 하이라이트**: AI 거대 기업들에 대한 수많은 소송 진행 허용
GPT-4o에 대한 프롬프트: “로봇이 예술가(프랑스인, 베레모와 붓을 들고 있는)의 주머니에서 현금으로 가득 찬 지갑을 소매치기하는 그림을 그려줄 수 있니?”

**요약**
스탠포드(Stanford) 학생들과의 최근 인터뷰에서, 전 구글 CEO 에릭 슈미트(Eric Schmidt)는 "재택근무가 승리하는 것보다 더 중요했다"는 그의 선정적인 주장에 주로 초점을 맞춘 수많은 헤드라인을 장식했습니다. 구글의 주가가 원격 근무 기간 동안 세 배로 뛰었다는 점을 감안할 때, 그의 발언은 더 비판적인 반응을 받아야 할 생성형 AI(generative AI)에 대한 그의 언급을 크게 가렸습니다. 더 버지(The Verge)의 보도에 따르면, 전 임원은 생성형 AI의 성공을 뒷받침하는 핵심 요소가 '절도'라는 자신의 믿음을 강조했습니다. 그는 학생들에게 "틱톡(TikTok)을 복사하고, 모든 사용자를 훔치고, 모든 음악을 훔치고, 내 선호도를 넣고… 이 모든 혼란을 정리할 변호사들을 잔뜩 고용하세요… 모든 콘텐츠를 훔쳤다는 것은 중요하지 않습니다. 그리고 저를 인용하지 마세요."라고 권장했습니다.

에릭 슈미트가 생성형 AI와 절도 사이의 관계를 주장한 첫 번째 인물도, 마지막 인물도 아닙니다. 이 경우, 틱톡의 지적 재산(intellectual properties)뿐만 아니라 사용자들의 개인 (및 사적인) 데이터, 그리고 틱톡이 매년 5억 달러를 지불한다고 알려진 모든 음악까지 훔치는 것을 의미합니다. 또한, 모든 생성형 AI 애플리케이션이 절도에 기반을 둔 것은 아니지만 (접히지 않은 단백질 구조(unfolded protein structures)를 생성하도록 훈련된 알파폴드(AlphaFold)나 수십억 개의 화학적 정량적 결합 측정값으로 훈련되어 새로운 약물 후보를 생성하는 데 사용되는 인코더-디코더 모델(encoder-decoder model)인 코아티(COATI)를 생각해 보세요), 이러한 태도는 많은 상업 기술 및 AI 분야 전반에 걸쳐 일반적으로 만연해 있습니다. 실제로 이러한 태도는 지적 재산(intellectual property) 절도, 저작권 침해(copyright infringement), 데이터 프라이버시(data privacy) 위반 등 다양한 주장을 담은 수십 건의 소송으로 이어졌습니다. 챗GPT(ChatGPT)가 저희가 아는 한 가장 많은 소송을 끌어모았지만 (한 법률 추적기에 따르면 13건의 소송이 계류 중), 그들에 대한 주장은 독특하거나 새로운 것이 아닙니다. 이번 주, 두 건의 별도 사건에서 판사들은 미드저니(Midjourney)와 스테빌리티AI(StabilityAI)에 대한 수많은 예술가들의 주장을 진행하도록 허용했으며, 앤트로픽(Anthropic)의 챗봇 클로드(Claude)에 대한 작가 그룹의 주장도 마찬가지였습니다. 두 경우 모두, 창작자들은 생성형 AI 도구가 자신들의 저작권이 있는 자료에 대한 공정 이용(fair use)에 해당하지 않으며, 이러한 도구들이 자신들의 권리를 침해한다고 주장합니다.

**개요**
처음에는 콘셉트 아티스트(concept artists), 권위 있는 미디어 기관, 로맨스 작가, 코미디언, 음악가, 소프트웨어 엔지니어, 배우, 그리고 조지 R.R. 마틴(George R. R. Martin)을 하나로 묶을 수 있는 것이 무엇인지 상상하기 어려울 수 있습니다. 종합적으로 볼 때, 창작자, 예술가, 지식인들이 자신들의 평생의 작품이 (동의 없이) 저작권이 있는 자료를 재현하고 언젠가 창작자들을 대체할 잠재력이 있다고 주장하는 생성형 모델(generative models)을 훈련하는 데 사용되는 공통된 패턴을 발견합니다. 모든 소송에서 우리는 공통된 핵심 주장과 법적 질문들을 발견합니다.

*   저작권이 있는 저작물로 대규모 언어 모델(large language model)을 훈련하는 것이 공정 이용(fair use)에 해당하는가?
*   LLM(대규모 언어 모델)이 생성한 콘텐츠가 저작권을 침해할 수 있는가?
*   법원 판결은 콘텐츠가 직접적인 복제, 의역, 모방 또는 패러디였는지 여부에 따라 달라질 것인가?
*   DMCA(디지털 밀레니엄 저작권법, Digital Millennium Copyright Act)는 AI가 생성한 잠재적 침해 자료를 제거할 법적 구제책을 제공하는가?
*   저작권 또는 상표 기호를 제거한 AI 생성 이미지가 DMCA를 위반하는가?
*   모델 훈련을 위해 콘텐츠를 스크래핑(scraping)하는 것이 개인 정보의 무단 사용에 해당하며 프라이버시(privacy) 및 소비자 권리를 침해하는가?

현재까지 판사들은 몇 가지 주목할 만한 예외를 제외하고 거의 모든 쟁점에서 AI 기업들의 손을 들어주었습니다. 코미디언 사라 실버맨(Sarah Silverman)과 관련된 초기 사건 중 하나에서, 판사는 오픈AI(OpenAI)에 대한 6건의 고소 중 DMCA 관련 고소를 포함한 5건을 기각했으며, 직접적인 침해가 있었는지 여부에 대한 한 가지 혐의만 남겨두었습니다. 지난주 다른 법정에서도 유사한 패턴이 나타났는데, 미국 지방법원 판사는 스테이블 디퓨전(Stable Diffusion)과 미드저니(Midjourney)에 대한 저작권 침해 주장을 진행시키면서 DMCA 및 부당 이득과 관련된 주장은 기각했습니다. 이번 주 샌프란시스코에서 제기된 세 번째 소송은 앤트로픽(Anthropic)의 챗봇 클로드(Claude)를 훈련하는 데 사용된 방대한 텍스트 데이터 모음인 '더 파일(The Pile)'의 사용이 "불법 복제된" 도서 컬렉션을 포함하고 있기 때문에 공정 이용(fair use)에 해당하지 않는다고 주장합니다. 이러한 주장은 클로드(Claude)가 인기 있는 (그리고 더 중요하게는 저작권이 있는) 가사를 놀랍도록 재현하는 능력 때문에 음악 출판사들이 10월에 앤트로픽(Anthropic)에 대해 제기한 주장과 유사합니다. 판사들이 어떻게 판결할지 (그리고 미국 대법원이 그러한 판결을 유지할지 또는 이의를 제기할지) 추측하기는 어렵지만, 우리는 판사들이 곧 이러한 공정 이용(fair use) 및 저작권 문제에 대해 직접 판결을 내리기 시작할 갈림길에 서 있습니다. 판사들이 어떻게 판결하든 상관없이, 이 사건들은 창작 커뮤니티와 AI 커뮤니티 모두에 지대한 영향을 미칠 잠재력을 가지고 있으며, 이들은 필연적으로 그 결정의 영향을 받을 것입니다.

**우리의 견해**
저는 사람들이 전 임원의 말을 인용하기를 진심으로 바랍니다! 특히 이 모든 소송 절차에 참여하는 변호사들이요. - 저스틴(Justin)

**연구 하이라이트**: SOPHON: 사전 훈련된 모델(Pre-trained Models)의 작업 전이성(Task Transferability)을 제한하기 위한 미세 조정 불가능 학습(Non-Fine-Tunable Learning)
**그림**: 미세 조정 불가능 학습(non-fine-tunable learning)의 목표. (1) **무결성(Intactness)**: 원본 도메인(original domain)에서 모델 성능을 보존해야 합니다. (2) **미세 조정 불가능성(Non-fine-tunability)**: 제한된 도메인(restricted domain)에서 모델을 미세 조정(fine-tuning)하는 것은 모델을 처음부터 훈련하는 것과 비슷하거나 더 큰 오버헤드(overhead)를 발생시켜야 합니다.

**요약**
저장대학교(Zhejiang University)와 앤트 그룹(Ant Group) 연구원들의 "SOPHON: 사전 훈련된 모델(Pre-trained Models)의 작업 전이성(Task Transferability)을 제한하기 위한 미세 조정 불가능 학습(Non-Fine-Tunable Learning)"은 AI 커뮤니티에서 증가하고 있는 시급한 문제, 즉 사전 훈련된 모델이 비윤리적이거나 해로운 작업에 재활용될 위험을 다룹니다. AI 모델이 더욱 강력하고 접근 가능해짐에 따라 오용 가능성도 커지고 있습니다. SOPHON은 이러한 모델이 의도된 작업을 수행하면서도 불법적인 목적을 위한 적응에 저항할 수 있도록 보호 프레임워크(protection framework)를 도입하여 잠재적인 해결책을 제시합니다.

**개요**
다양한 데이터 양식(data modalities)에 걸친 대규모 훈련을 통해, 사전 훈련된 모델(pre-trained models)은 특정 다운스트림 작업(downstream tasks)을 위해 모델을 효율적으로 개발하고 배포하는 데 일반적으로 백본(backbone)으로 사용됩니다. 방대한 데이터셋(datasets)과 엄청난 컴퓨팅 파워(computational power)로 훈련된 이 모델들은 다양한 작업을 수행하도록 쉽게 미세 조정(fine-tuned)될 수 있습니다. 그러나 이러한 다재다능함 자체가 상당한 위험을 초래합니다. 동일한 모델이 프라이버시(privacy) 침해나 악성 콘텐츠 생성과 같은 비윤리적이거나 해로운 목적으로 전용될 수 있기 때문입니다. 저장대학교(Zhejiang University)와 앤트 그룹(Ant Group) 연구원들의 최근 연구는 미세 조정 불가능 학습(non-fine-tunable learning)으로 알려진 새로운 학습 패러다임(learning paradigm)을 도입하여 바로 이 문제를 해결합니다. SOPHON의 동기는 사전 훈련된 모델(pre-trained model)이 원래 의도된 도메인(domains)에서 효과를 유지하면서도 부적절한 작업으로 미세 조정(fine-tuned)되는 것을 방지하는 것입니다. 이 논문은 두 가지 핵심 주체, 즉 공격자(adversary)와 방어자(defender)가 있는 프레임워크(framework)를 소개합니다. 공격자(adversary)는 비윤리적인 작업을 위해 사전 훈련된 모델(pre-trained model)을 미세 조정(fine-tune)하려는 악의적인 주체를 나타냅니다. 그들의 목표는 부적절한 콘텐츠를 생성하거나 민감한 개인 정보를 추론하는 것과 같이 제한된 도메인(restricted domain)에서 모델이 잘 작동하도록 수정하는 것입니다. 반면에 방어자(defender)는 사전 훈련된 모델(pre-trained model)의 출시를 제어하고 오용을 방지하려는 주체입니다. 방어자의 목표는 모델이 원래 작업에 효과적으로 유지되지만, 공격자(adversary)에 의해 쉽게 재활용될 수 없도록 하는 것입니다.

**그림**: SOPHON은 두 가지 핵심 단계로 작동합니다. 1) **미세 조정 억제(Fine-Tuning Suppression, FTS) 루프(loops)**: 제한된 도메인(restricted domain)에서 성능을 저하시키기 위해 다양한 미세 조정(fine-tuning) 시나리오를 시뮬레이션(simulate)합니다. 2) **정상 훈련 강화(Normal Training Reinforcement, NTR) 루프(loops)**: 모델의 원본 도메인(original domain) 성능을 보존하는 데 중점을 둡니다.

이를 달성하기 위해 SOPHON 프레임워크(framework)는 모델 불가지론적 메타 학습(Model-Agnostic Meta-Learning, MAML)에서 영감을 받은 기술을 활용합니다. MAML은 최소한의 데이터로 새로운 작업에 빠르게 적응할 수 있도록 모델을 최적화(optimize)하도록 설계된 메타 학습(meta-learning) 접근 방식입니다. 그러나 SOPHON의 맥락에서는 MAML이 제한된 작업에 대한 미세 조정(fine-tuning)을 어렵게 만들기 위해 다소 역방향으로 사용됩니다.

**미세 조정 시뮬레이션(Fine-Tuning Simulation)**: 방어자(defender)는 MAML을 사용하여 공격자(adversary)가 사용할 수 있는 다양한 미세 조정(fine-tuning) 전략을 시뮬레이션(simulate)합니다. 이러한 시뮬레이션(simulations)은 방어자가 공격자가 모델을 어떻게 적응시키려 할지 예측할 수 있게 해주기 때문에 중요합니다. 이러한 시나리오를 시뮬레이션함으로써 방어자는 모델의 매개변수(parameters)를 조정하여 제한된 도메인(restricted domains)에서의 미세 조정(fine-tuning)을 매우 비효율적이거나 심지어 비효과적으로 만들 수 있습니다.

**최적화 프로세스(Optimization Process)**: SOPHON은 이러한 시뮬레이션된 미세 조정(fine-tuning) 프로세스를 최적화 프레임워크(optimization framework)에 통합합니다. 핵심 아이디어는 제한된 작업에 대해 미세 조정(fine-tuned)될 때 모델의 성능을 저하시키면서도 원본 도메인(original domain)에서의 효과를 유지하는 것입니다. 이는 두 가지 목표의 균형을 맞춤으로써 이루어집니다.
*   **무결성(Intactness)**: 모델이 원래 작업에서 성능을 유지하도록 보장합니다.
*   **미세 조정 불가능성(Non-Fine-Tunability)**: 제한된 도메인(restricted domains)에서 모델을 미세 조정(fine-tuning)하는 것이 상당한 성능 저하를 초래하거나, 새로운 모델을 처음부터 훈련하는 것만큼 많은 노력을 필요로 하도록 만듭니다.

**방어자의 전략(Defender’s Strategy)**: 방어자(defender)의 전략은 미세 조정(fine-tuning) 시도를 반복적으로 시뮬레이션(simulating)하고, 모델의 취약성을 평가하며, 이러한 잠재적인 적대적 적응에 대해 모델을 강화하는 것을 포함합니다. 이 과정은 계산적으로 집약적(computationally intensive)이지만, 모델이 오용에 대해 견고하게 유지되도록 보장하는 데 중요합니다.

**그림**: 세 가지 다른 미세 조정(finetuning) 방법에서 SOPHON 모델은 처음부터 훈련하는 것보다 일관되게 낮은 성능을 보입니다.

이 논문은 SOPHON의 효과를 검증하기 위한 광범위한 실험 결과도 제공합니다. 이 프레임워크(framework)는 7개의 다른 제한된 도메인(restricted domains)과 6개의 모델 아키텍처(model architectures)를 사용하여 두 가지 주요 유형의 딥러닝(deep learning) 작업(위 그림에 표시된 분류(classification) 및 생성(generation))에 걸쳐 테스트되었습니다. 실험 결과, SOPHON으로 보호된 모델은 공격자(adversaries)가 제한된 작업을 위해 미세 조정(fine-tune)하려고 할 때 상당한 오버헤드(overhead)를 발생시키는 것으로 나타났습니다. 어떤 경우에는 성능 저하가 너무 커서 새로운 모델을 처음부터 훈련하는 비용과 같거나 그 이상이었습니다. 또한, 위 그림에서 볼 수 있듯이 SOPHON은 최적화 도구(optimizers), 학습률(learning rates), 배치 크기(batch sizes)와 같은 다양한 미세 조정(fine-tuning) 방법에 대해 견고합니다. 정성적으로 볼 때, CelebA 데이터셋(dataset)에서 이미지를 노이즈 제거(denoising)하는 작업의 경우, 제한된 도메인(restricted domain)에서 원본 모델을 미세 조정(fine-tuning)하면 강력한 성능을 달성하며, 모델을 처음부터 훈련하는 것도 약간 덜 효과적이지만 상당히 좋은 결과를 낳습니다. 그러나 SOPHON에서 미세 조정(fine-tuned)될 때, 확산 모델(diffusion model)은 아래 그림에서 볼 수 있듯이 얼굴 이미지의 노이즈 제거(denoise)에 현저한 무능력을 보입니다.

**그림**: SOPHON은 제한된 도메인(restricted domain)의 이미지를 노이즈 제거(denoise)할 수 없으므로 기준선(baselines)과 비교하여 "보호"됩니다.

**우리의 견해**
SOPHON은 AI를 오용으로부터 보호하는 데 있어 중요한 진전입니다. AI 모델이 강력해질수록 비윤리적인 작업에 재활용될 위험이 커집니다. SOPHON은 모델의 의도된 기능을 유지하면서 제한된 도메인(restricted domains)에서의 미세 조정(fine-tuning)을 방지함으로써 이 문제를 해결합니다. MAML의 사용은 특히 참신합니다. 전통적으로 모델을 더 잘 적응시키기 위해 사용되었지만, 여기서는 적대적 미세 조정(adversarial fine-tuning)에 모델이 저항하도록 만들기 위해 영리하게 역으로 사용됩니다. "SOPHON"이라는 이름 또한 특히 적절하고 영리한 선택인데, 이는 '삼체 문제(The Three-Body Problem)'에서 제약과 보호를 의미하는 개념에서 따온 것입니다. 전반적으로, 이 논문은 깔끔한 아이디어를 제시하며 실제로 잘 작동한다면 유망한 진전을 보여줍니다. – 샤룻(Sharut)

**Gradient의 새로운 소식**
주디 팬(Judy Fan): 인간 인지 도구 키트(Human Cognitive Toolkit) 역설계(Reverse Engineering) 듣기
L.M. 사카사스(L.M. Sacasas): 기술에 관한 질문 듣기

**주목할 만한 다른 소식**
**뉴스**
**시장 후보, AI 봇 VIC에게 와이오밍 주도 운영을 맡기겠다고 공약**
와이오밍(Wyoming) 주 시장 후보 빅터 밀러(Victor Miller)는 VIC(가상 통합 시민, Virtual Integrated Citizen)이라는 AI 봇으로 샤이엔(Cheyenne) 시를 전적으로 운영하겠다고 공약했습니다. 이러한 공약은 미국 선거 운동에서 전례 없는 것으로 여겨지며, 공무원과 기술 기업들 사이에서 우려를 불러일으켰습니다. 밀러는 AI가 정부 의사 결정에 객관성, 효율성, 투명성을 가져올 것이라고 주장합니다. 그러나 비판론자들은 챗봇(chatbots)의 도덕성 부족과 주관적인 의사 결정 능력, 그리고 잘못된 정보의 가능성 및 기술 조작의 용이성에 대해 우려합니다. 회의론에도 불구하고 밀러는 자신의 AI 중심 캠페인에 자신감을 유지하고 있습니다. 이 사례는 AI의 급속한 발전과 정치 분야에서의 AI 사용 규제에 대한 과제를 잘 보여줍니다.

**유출된 녹음에서 아마존 클라우드 책임자, AI가 코딩 작업을 인계받으면 대부분의 개발자가 곧 코딩을 중단할 수 있다고 직원들에게 말해**
유출된 녹음에서 아마존 웹 서비스(Amazon Web Services) CEO 맷 가먼(Matt Garman)은 인공지능(AI)이 코딩 작업을 인계받음에 따라 미래에는 대부분의 개발자가 코딩할 필요가 없을 수도 있다고 말했습니다. 가먼은 코딩은 컴퓨터와 소통하는 수단일 뿐이며, 진정한 기술은 최종 사용자를 위한 혁신과 흥미로운 것을 구축하는 데 있다고 믿습니다. 그는 개발자들이 코드 작성보다는 고객 요구를 이해하고 혁신적인 솔루션을 만드는 데 더 집중해야 할 것이라고 제안합니다. 가먼의 발언은 암울한 경고가 아니라 AI 시대에 개발자의 역할 변화에 대한 낙관적인 견해를 의미했습니다.

**딥마인드(DeepMind) 직원들, 구글의 국방 계약에 항의하는 서한에 서명**
딥마인드(DeepMind)의 최소 200명 직원이 구글의 국방 계약에 대한 불만을 표명했습니다. 5월에 내부적으로 배포된 서한에서 직원들은 구글이 군사 조직과 맺은 계약, 특히 이스라엘 군과의 AI 및 클라우드 컴퓨팅(cloud computing) 서비스 계약에 대한 우려를 표했습니다. 직원들은 군사 및 무기 제조에 관여하는 것은 딥마인드(DeepMind)의 사명 선언문과 명시된 AI 원칙에 위배되며, 윤리적이고 책임감 있는 AI 분야의 리더로서의 입지를 훼손한다고 주장합니다. 이는 구글이 2018년에 딥마인드(DeepMind) 기술이 군사 또는 감시 목적으로 사용되지 않을 것이라고 약속했던 점을 고려할 때, 구글과 딥마인드(DeepMind) 간의 잠재적인 문화적 충돌을 강조합니다.

**AI 영업 담당자 스타트업(startups)이 급증하고 있습니다. 그렇다면 벤처 캐피탈(VCs)은 왜 경계할까요?**
AI 영업 개발 담당자(sales development representatives, SDRs)는 시장에서 급격한 성장을 경험하고 있으며, 여러 스타트업(startups)이 단기간에 성공을 거두고 있습니다. 이들 스타트업(startups)은 LLM(대규모 언어 모델) 및 음성 기술과 같은 AI 기술을 사용하여 영업팀을 위한 콘텐츠 생성을 자동화합니다. 그러나 벤처 캐피탈(venture capitalists)은 인간의 아웃리치(outreach)와 비교했을 때 이들의 장기적인 생존 가능성과 효과에 대한 우려 때문에 이들 회사에 투자하는 것을 경계하고 있습니다. 중소기업들은 영업 아웃리치(sales outreach)를 개선하기 위해 AI SDR을 실험하는 데 열심이지만, 이러한 도구들이 실제로 기업의 판매를 더 효과적으로 돕고 있는지는 불분명합니다. 또한, 세일즈포스(Salesforce), 허브스팟(HubSpot), 줌인포(ZoomInfo)와 같은 기존 경쟁업체들은 유사한 AI 솔루션을 무료 기능으로 제공할 수 있어 AI SDR 스타트업(startups)의 성장에 위협이 될 수 있습니다. 전반적으로 AI SDR의 채택은 빠르지만, 투자자들은 시장에서의 지속력에 대해 회의적입니다.

**마침내 오픈소스(open-source) AI에 대한 정의를 얻었습니다.**
한 그룹이 AI 시스템이 오픈소스(open-source)라는 것이 무엇을 의미하는지 마침내 정의했습니다. 이 정의에 따르면, 오픈소스(open-source) AI 시스템은 허가 없이 어떤 목적으로든 사용 가능해야 하며, 연구자들이 그 구성 요소를 검사하고 작동 방식을 이해할 수 있도록 허용해야 하며, 수정 및 공유 가능해야 합니다. 이 표준은 또한 훈련 데이터(training data), 소스 코드(source code), 가중치(weights) 측면에서의 투명성을 강조합니다. 이 정의는 일부 기업들이 마케팅에서 이 용어를 오용해 왔기 때문에 AI 시스템이 진정으로 오픈소스(open-source)라는 것이 무엇을 의미하는지 명확히 한다는 점에서 중요합니다.

**웨이모(Waymo), 자녀들의 운전기사가 되고 싶어 합니다.**
알파벳(Alphabet)의 자회사인 웨이모(Waymo)는 십대들이 혼자서 차량을 호출하고 부모에게 픽업 및 하차 알림을 보낼 수 있도록 하는 "웨이모 틴(Waymo Teen)"이라는 구독 프로그램(subscription program)을 고려하고 있습니다. 이 프로그램은 승인된 십대들이 보호자의 감독 하에 웨이모(Waymo)를 이용하도록 요구할 것입니다. 웨이모(Waymo)는 이 분야 연구에서 긍정적인 피드백을 받았습니다. 웨이모(Waymo)의 이러한 움직임은 작년에 우버(Uber)가 십대들을 자사 네트워크의 높은 평가를 받은 운전자들과 연결해 준 이니셔티브(initiative)에 뒤이은 것입니다. 법적 보호자의 동의가 필요하며, 보호자들은 자녀의 탑승 중 위치에 대한 알림을 받게 됩니다.

**SAG-AFTRA의 더 나은 AI 보호를 위한 파업에 대해 질문받자, 아마존 게임즈(Amazon Games) 사장, AI는 배우들의 '일자리를 빼앗는 것과 아무 관련이 없다'고 주장하며 '게임에는 연기가 없기 때문'이라고 말해**
IGN과의 인터뷰에서 아마존 게임즈(Amazon Games) CEO 크리스토프 하트만(Christoph Hartmann)은 게임 산업에서 생성형 AI(generative AI) 사용에 관해 흥미로운 발언을 했습니다. 그는 AI가 게임 개발 주기(development cycle)를 단축할 수 있기를 희망한다고 밝혔지만, SAG-AFTRA 성우들의 더 나은 AI 보호를 위한 파업에 대해 질문받자 "게임에는 연기가 없다"고 주장했습니다. 이 발언은 발더스 게이트 3(Baldur's Gate 3) 및 더 라스트 오브 어스(The Last of Us)와 같은 많은 비디오 게임에서 연기가 차지하는 중요한 역할과 모순됩니다. 하트만은 또한 AI가 게임 개발을 도울 수 있는 다른 영역, 특히 현지화(localization)에 대해서도 논의했습니다. 그러나 현지화(localization)는 미묘한 번역과 문화적 이해를 포함하며, 이는 AI로 쉽게 달성되지 않을 수 있다는 점에 유의해야 합니다. 하트만은 인간의 창의성과 독창성은 기술로 대체될 수 없다고 강조하며 결론을 맺었습니다.

**AI를 이용해 아동 포르노를 제작한 남성 체포**
플로리다(Florida) 주의 한 남성이 AI로 생성된 아동 포르노를 제작 및 배포한 혐의로 체포되어 20건의 음란물 혐의에 직면해 있습니다. 필립 마이클 맥코클(Phillip Michael McCorkle)은 인디언 리버 카운티 보안관 사무소(Indian River County Sheriff's Office)가 그가 AI 이미지 생성기(AI image generator)를 사용하여 아동 성 착취 이미지를 만들고 배포하고 있다는 제보를 받은 후 체포되었습니다. 이 체포는 생성형 AI(generative AI)가 범죄와 아동 학대를 위한 새로운 길을 제공하므로 악의적인 목적으로 사용될 위험성을 강조합니다. AI로 생성된 아동 포르노의 증가하는 확산은 국회의원들이 이를 불법화하는 법안을 추진하도록 촉구했지만, 효과적으로 막기 어려운 문제로 남아 있습니다. 국립 실종 및 착취 아동 센터(National Center for Missing & Exploited Children)는 작년에 AI로 생성된 아동 포르노에 대한 수천 건의 보고를 받았으며, 심지어 실제 아동의 딥페이크(deepfakes)도 생성형 AI(generative AI)를 사용하여 만들어지고 있습니다. 이 통제 불가능한 문제는 긴급한 관심과 조치를 요구합니다.

**논문**
*   시각적 기억(visual memory)을 통한 유연한 인식(flexible perception)을 향하여
*   지식 그래프(Knowledge Graphs)에서 언어 모델(Language Models) 훈련하기: 환각(Hallucinations) 및 그 탐지 가능성에 대한 통찰
*   에이전트 시스템(Agentic Systems)의 자동화된 설계
*   트랜스퓨전(Transfusion): 하나의 다중 모달 모델(Multi-Modal Model)로 다음 토큰(Token) 예측 및 이미지 확산
*   코딩할 것인가, 말 것인가? 순환 신경망(Recurrent Neural Networks) 사전 훈련(Pre-training)에서 코드의 영향 탐구
*   비선형 표현(Non-Linear Representations)을 사용하여 시퀀스(Sequences) 저장 및 생성 학습
*   매직덱(MagicDec): 추측 디코딩(Speculative Decoding)을 통한 긴 컨텍스트(Context) 생성에서 지연 시간-처리량(Latency-Throughput) 트레이드오프(Tradeoff) 깨기
*   언어 모델(language models)에서 새로운 실험 가설 생성: 교차 여격 일반화(cross-dative generalization)에 대한 사례 연구

**마무리 생각**
이번 호의 주제에 대해 할 말이 있으신가요? editor@thegradient.pub으로 이메일을 보내주시면, 다음 뉴스레터에서 독자들의 가장 흥미로운 생각을 공유하는 것을 고려해 보겠습니다! 이 뉴스레터가 마음에 드셨다면, Substack 구독을 통해 The Gradient에 기부하는 것을 고려해 주세요. 이는 이 자원봉사 프로젝트를 유지하는 데 도움이 됩니다. Gradient의 최신 업데이트를 읽어주셔서 감사합니다!