# NeurIPS 2026 논문들을 탐색하세요

**NeurIPS 2026 논문들이 드디어 공개되었습니다.** 그 방대한 양은 여전히 압도적입니다. 이 시각화 도구(모바일보다는 컴퓨터에서 보는 것이 가장 좋습니다)는 클러스터(cluster), 심층 요약, 그리고 최신 LLM(대규모 언어 모델)이 생성한 설명을 활용하여 방대한 연구 분야를 대화형으로 탐색할 수 있도록 돕습니다. 이를 통해 해당 분야를 더욱 쉽고 직관적으로 이해할 수 있습니다. NeurIPS 2026의 최신 연구 동향을 깊이 있게 탐색하려면 클릭하세요 (최적의 경험을 위해 컴퓨터 사용을 권장합니다). 이 시각화는 Cohere의 최신 생성 모델(generation model)과 임베딩 모델(embedding model) 및 아래에서 자세히 설명할 워크플로우(workflow)를 활용하여 대규모 텍스트 아카이브(text archive)를 효과적으로 탐색하는 데 중점을 둡니다. 모든 데이터는 최종적으로 datamapplot을 사용하여 일부 맞춤 설정(customization)과 함께 시각적으로 플로팅(plotting)됩니다.

Language Models & Co.를 읽어주셔서 감사합니다! 새로운 게시물을 무료로 받아보고 제 작업을 지원하려면 구독하세요. 구독하기

---

### 정보의 홍수 속에서 최전선 연구를 탐색하는 것은 필수적입니다.

NeurIPS는 수년간 최고의 연구 결과가 발표되는 주요 기계 학습(machine learning) 컨퍼런스(conference) 중 하나로 자리매김했습니다. 여러 차례 참석하면서 느낀 점은, 이러한 경험이 여러 면에서 도전적일 수 있다는 것입니다.

*   ML(기계 학습)과 같이 급변하는 분야에서는 5월 제출 마감일과 12월 컨퍼런스 개최 시점 사이에 연구 분야가 빠르게 발전하는 경우가 많습니다. 따라서 논문을 조기에 탐색하는 것이 매우 중요합니다.
*   학회 논문의 규모와 양은 압도적입니다. 정보 과부하(information overload)를 효과적으로 줄일 수 있는 더 나은 도구가 절실하며, AI(인공지능)와 시각화(visualization)를 전략적으로 활용하는 것이 큰 도움이 될 수 있습니다.
*   자신의 전문 분야(domain)를 벗어난 다른 분야의 작업은 종종 해독하기 어려울 수 있습니다. LLM(대규모 언어 모델)은 이러한 복잡한 내용을 일반적인 용어로 쉽게 설명해 줄 수 있는 강력한 도구입니다.

지난 몇 년 동안 저는 이러한 학회 논문들을 탐색하는 데 유용한 간단하고 대화형인 시각화 도구들을 꾸준히 만들어왔습니다. 그리고 채택된 논문 목록이 방금 발표되었으므로, 여러분이 직접 최신 연구를 탐색할 수 있도록 여기 그 시각화 도구를 소개합니다.

---

### 시각화 도구 가이드 둘러보기

왼쪽에 있는 주제 계층(topic hierarchy)을 탐색하거나, 오른쪽에 펼쳐진 전체 지도를 직접 탐색해 볼 수 있습니다.

지도를 확대하면 더 작고 세분화된 클러스터(cluster)의 이름이 선명하게 나타납니다. 또한 최상위 범주(top-level category)를 확장하여 그 안에 포함된 주요 클러스터들을 한눈에 볼 수 있습니다. 주제 트리(topic tree)에서 특정 클러스터 이름을 클릭하면, 플롯(plot)이 해당 클러스터에 초점을 맞춰 재정렬됩니다. 클러스터 이름은 LLM(대규모 언어 모델)이 제안하며, 제가 직접 검토하고 수정하여 정확성을 높입니다.

더 깊이 확대하면, 연구 논문의 세분화된 영역 이름들이 더욱 상세하게 드러납니다.

논문 위에 마우스를 올리면 논문의 제목과 초록(abstract)을 포함한 핵심 정보가 표시됩니다. 하지만 저는 항상 모델이 이 텍스트에 대해서도 추가적인 작업을 수행하기를 원했기 때문에, LLM이 추출한 요약(summary), 문제 진술(problem statement), 방법론(methodology)과 더불어 다섯 살 아이도 이해할 수 있는 설명(explanation for a five-year-old, ELI5)을 함께 볼 수 있도록 구성했습니다. 특히 제가 당면한 초점(focus) 외의 분야를 탐색하기 시작하면서 이 부분은 제가 가장 선호하는 섹션(section)이 되었습니다.

논문 위에 마우스를 올리면 제목, 저자, 초록 등 더 많은 상세 정보가 나타납니다. 툴팁(tooltip)은 초록뿐만 아니라 이를 세분화하는 데 도움이 되는 다른 섹션도 제공합니다. 제목과 초록 외에도 LLM이 생성한 요약, ELI5(다섯 살 아이를 위한 설명), 논문의 문제 진술, 방법론, 실제 적용 사례 등을 상세히 읽어보세요. 이 기능은 복잡한 개념을 빠르고 효과적으로 이해하는 데 큰 도움이 됩니다.

---

### 컨퍼런스 관찰 및 주요 동향

**주요 테마: LLM(대규모 언어 모델), 다중 모드(Multimodality), 강화 학습(Reinforcement Learning), 그리고 에이전트(Agent) 연구**

이 네 가지가 저에게는 가장 큰 그룹으로 두드러집니다. 이들은 단순히 주요 클러스터일 뿐만 아니라, 다른 클러스터의 핵심 구성 요소가 되는 경향이 있습니다 (저는 다중 레이블 분류(multi-label classification) 단계를 실행하므로 논문이 단일 클러스터에만 국한되지 않습니다). 제 계산에 따르면, 약 30%의 논문이 다중 모드를 주요 초점(primary focus)으로 포함하고, 15%는 강화 학습을 핵심 초점으로 다룹니다 (이들은 중복될 수 있습니다). 또한 14%에서는 평가(Evaluation) 논문과 추론(Reasoning) 논문을 발견할 수 있었습니다.

**LLM 추론 연구의 지속적인 급증.** 추론 능력은 NeurIPS 2025 복도에서 O1 모델의 초기 출시 이후 주요 논의 주제였으며, 이러한 관심은 예상대로 NeurIPS 2026의 채택된 연구에서도 더욱 강화되어 반영됩니다. 추론을 핵심 초점(core focus)으로 하는 약 800개 이상의 논문이 확인되었습니다. 추론은 2026년의 주요 돌파 테마(breakout theme) 중 하나로 명확히 자리매김했습니다.

**확산 모델(Diffusion model)은 LLM(대규모 언어 모델), 강화 학습과 함께 컨퍼런스의 주요 테마 중 하나로 확고히 자리 잡았습니다.** 시각화 공간의 상단 부분은 주로 컴퓨터 비전(computer vision)과 다중 모드로 구성되어 있으며, 서쪽 지역에서는 확산 모델의 다양한 측면을 심층적으로 탐구합니다. 컴퓨터 비전은 텍스트 다음으로 두 번째 주요 모드(modality)인 것으로 보이며, 생성(generation) 및 표현(representation) 발전 모두에서 중요한 하위 범주(sub category)를 형성합니다. 주제 트리(topic tree)는 확산 모델에 대한 여러 주요 클러스터로 이를 명확히 반영합니다.

**모든 것을 확산시키다.**

과학 분야에서 ELI5(다섯 살 아이를 위한 설명) 기능의 가치는 아무리 강조해도 지나치지 않습니다. 저는 며칠 동안 이 기능들을 활용하여 논문을 읽는 데 시간을 보낼 것 같습니다. 제 과정은 먼저 요약을 읽고, 이해가 잘 되지 않으면 ELI5를 읽은 다음 다시 요약을 읽는 것인데, 이 방법이 종종 복잡한 개념을 파악하는 데 큰 도움이 됩니다. 여기 AI가 당신의 뇌를 감싸 안아주고, 그렇지 않으면 모호하게 여겨질 수 있는 정보를 흡수하도록 돕는다고 느껴지는 몇 가지 예시가 있습니다. 저는 이 사용 사례(use case)와 인간의 마음을 확장할 수 있는 그 잠재력을 정말 좋아합니다. ELI5는 독자에게 더 모호한 영역을 명확하게 이해하는 데 도움을 줍니다.

추가 너드 스나이프(nerd snipe): 슈뢰딩거 브리지 문제(Schrodinger bridge problem)란 정확히 무엇일까요?

또 다른 예시: 저는 요약을 읽고, 이해가 안 되면 ELI5로 전환한 다음 다시 요약으로 돌아갑니다. 그러면 짜잔! 조금 더 명확하게 이해하게 됩니다. 이처럼 AI는 복잡한 연구를 소화 가능한 형태로 변환하여 지식 습득의 장벽을 낮추는 데 기여합니다.

---

### AI는 인간의 마음을 확장해야 합니다.

이러한 접근 방식에서는 이 방대한 텍스트 모음을 더 쉽게 읽을 수 있도록 AI를 의도적으로 여러 하위 문제(sub-problem)에 집중시킵니다. 이는 정보 접근성을 혁신하는 핵심 전략입니다.

---

### 개별 텍스트 분석의 심화

이러한 단계 중 일부는 개별 항목 수준(individual item level)에 적용되며, 일부는 그룹(클러스터)에 적용되어 전체 컬렉션(collection)을 효과적으로 탐색하는 데 도움을 줍니다.

*   텍스트 추출(Text extraction)
*   분류(Classification)
*   질문 답변(Question answering)
*   요약(Summarization)

최신 텍스트-투-텍스트 모델(text-to-text model)의 가장 큰 장점은 이 모든 작업을 단일 단계(single step)로 통합하여 수행할 수 있다는 것입니다. 우리는 단순히 최적화된 프롬프트 템플릿(prompt template)을 준비하고, 각 텍스트를 그 프롬프트에 주입하여, 총 6,200개 이상의 프롬프트(컨퍼런스에서 채택된 논문당 하나)를 효율적으로 생성합니다. 수천 개의 텍스트를 대량 분석(bulk analysis)할 때는 분석할 텍스트를 삽입할 수 있는 프롬프트 템플릿을 사용한 다음, 각 프롬프트를 LLM에 제시하는 방식이 매우 효과적입니다.

수천 개의 프롬프트를 실행하는 것은 LLM 사용이 모두 플레이그라운드(playground)를 통해서만 이루어진다면 활용할 수 없는 초능력 중 하나입니다. 관련된 잠재적 비용과 복잡성을 고려할 때, 아직 많은 에이전트(agent)에게 완전히 위임하는 것은 현명하지 않을 수 있습니다. 따라서 이러한 작업은 종종 개별 스크립트(script)나 정교하게 설계된 워크플로우(workflow)로 실행되며, 두 경우 모두 인간에 의해 의도적으로 트리거(trigger)됩니다.

---

### 많은 작은 그룹으로의 클러스터링(Clustering)

3년 전, 저는 "텍스트 클러스터링을 이용한 10,000개 해커 뉴스 게시물에서 통찰력 찾기(Combing For Insight in 10,000 Hacker News Posts With Text Clustering)"라는 글을 썼는데, 이는 제가 여기서 사용한 프로세스(process)와 매우 유사한 과정을 상세히 설명했습니다. 그 과정을 이 그림에서 시각적으로 확인할 수 있습니다.

*   임베딩(embedding)은 텍스트의 의미론적 정보를 효과적으로 포착합니다.
*   UMAP은 유사한 텍스트가 서로 가깝게 플로팅되도록 유지하면서 이러한 고차원 표현(representation)을 시각적으로 플로팅할 수 있게 합니다.

논문의 초록은 먼저 임베딩된 다음, UMAP을 사용하여 2차원(two dimensions)으로 차원이 축소되고, K-평균(K-Means) 알고리즘을 통해 여러 작은 클러스터로 클러스터링됩니다. 이 클러스터들은 나중에 모델에 제시되어 의미 있는 클러스터 이름을 할당받습니다. 이때 UMAP 단계는 임베딩의 크기를 극적으로 줄이며 일부 정보 손실이 발생할 수 있습니다. 그러나 이 시나리오(scenario)에서는 플롯의 시각적 일관성(coherence)이 높은 우선순위(high priority)이기 때문에 (예: 클러스터들이 실제로 의미 있게 함께 그룹화됨) 이러한 접근 방식이 적합합니다. 다른 시나리오에서는 임베딩을 직접 클러스터링하거나, 정보 손실을 최소화하기 위해 중간 임베딩 크기(interim embedding size)로 줄일 수 있습니다. 이러한 고급 흐름에 대한 자세한 내용은 저희 책 "Hands-On Large Language Models" 5장에서 심도 있게 다루고 있습니다.

---

### 작은 클러스터들을 몇 개의 더 큰 상위 클러스터로 재구성하기

이제 이 벡터(vector)들을 플로팅하여 클러스터링의 효과를 더욱 명확하게 볼 수 있도록 전환해 봅시다. 두 단계의 클러스터링은 계층(hierarchy)의 다른 수준에서 이름을 할당할 수 있도록 하는 강력한 이점을 제공합니다. 이는 마치 Google 지도에서 한 수준에서는 도시 이름을, 다른 수준에서는 국가 이름을 보는 것과 같다고 생각할 수 있습니다. 두 번째 그리드(grid)에 있는 작은 원들은 각 클러스터의 중심점(cluster centroid)을 나타냅니다. 이 중심점들은 K-평균 클러스터링 알고리즘(K-Means clustering algorithm)의 일부로 생성됩니다. 그런 다음 이 중심점들을 다시 클러스터링하여 예를 들어 10개의 최상위 범주(top-level category)에 해당하는 더 높은 수준의 클러스터링을 생성할 수 있습니다. 이 과정만으로도 플롯에 많은 정보가 추가되지만, 각 클러스터에 의미 있는 이름을 할당하면 훨씬 더 풍부한 정보를 사용자에게 전달할 수 있습니다.

---

### 클러스터 이름의 효율적인 할당

이제 임베딩 모델과 생성 모델(generation model)이 시너지를 발휘하는 방식을 볼 수 있습니다. 임베딩 기반 클러스터와 각 초록의 요약을 바탕으로, 개별 클러스터를 생성 모델(generative model)에 제시하여 가장 적절한 이름을 할당받을 수 있습니다. 이 과정에서 전체 초록을 사용하거나 이전 단계에서 생성된 요약을 활용할 수 있습니다. LLM은 다양한 방식으로 파이프라인(pipeline)을 풍부하게 만들 수 있습니다. 여기서는 정보 추출(extraction)과 클러스터 이름 지정(cluster naming)을 두 가지 별개의 작업으로 간주합니다. 단순히 클러스터에서 예시 논문을 샘플링(sampling)하여 이름을 지정하는 것 외에도, 더욱 정교한 여러 이름 지정 기술들이 존재합니다. 이 단계에서 남은 작업은 이렇게 생성된 데이터를 놀라운 datamapplot에 연결하고, 일부 매개변수(parameter)를 맞춤 설정하여 최종 시각화 그림을 완성하는 것입니다.

---

### 컨텍스트 핸드오프(Context Handoff)를 통한 상위 클러스터 이름 지정

이 워크플로우(workflow)가 강조하는 한 가지 중요한 패턴(pattern)은 파이프라인(pipeline) 단계 전반에 걸쳐 컨텍스트(context)에 집중해야 한다는 점입니다. 프롬프트 엔지니어링(prompt engineering)과 컨텍스트 엔지니어링(context engineering)은 LLM(대규모 언어 모델) 작업의 핵심 영역이며, 이는 LLM 처리 파이프라인에도 그대로 적용됩니다. 이전 단계에서 생성된 클러스터 이름은 중복될 수 있습니다. 예를 들어, 모델에 해당 클러스터의 논문만 제공된다면, 인접한 두 클러스터가 모두 "LLM 추론(LLM Reasoning)"이라고 불릴 수 있습니다.

이를 해결하는 몇 가지 효과적인 방법이 있습니다. 하나는 다른 클러스터의 논문들을 함께 묶어서 모든 클러스터에 한 번에 이름을 부여하는 것입니다. 모델이 여러 클러스터의 더 넓은 텍스트 컬렉션을 보면 전역 계층(global hierarchy)에 대한 가시성(visibility)이 더 높아지지만, 이는 컨텍스트 길이(context-length) 문제를 야기할 수 있습니다. 이 접근 방식은 데이터가 모델의 컨텍스트 창(context window)에 들어갈 수 있다면 효과적으로 작동할 수 있습니다. 또 다른 접근 방식은 두 단계로 수행하는 것입니다. 1) 클러스터만 보고 이름을 지정하고, 2) 첫 번째 이름 지정 통과(pass) 후 모델이 클러스터를 더 넓은 컨텍스트에서 다시 볼 수 있도록 허용하는 것입니다. 즉, 먼저 클러스터에 독립적으로 이름을 지정한 다음, 모델이 포괄적이면서도 요약된 컨텍스트에서 클러스터를 볼 때 나중에 이름을 다시 지정하여 두 가지 장점을 모두 얻는 것입니다.

이 파이프라인(pipeline)에서는 고수준 클러스터 이름(high-level cluster name)을 할당하는 단계(이를 "범주 이름(category name)"이라고도 부를 것입니다)와 깔끔하게 맞아떨어지기 때문에 이 접근 방식을 선호했습니다. 이런 식으로, 첫 번째 유형의 컨텍스트는 모델이 개별 클러스터에 집중하고 다른 클러스터에 의해 방해받지 않도록 자유롭게 사용됩니다. 하지만 이것은 `cluster_name` 외에도, 너무 많은 정보로 이름 변경 단계를 과도하게 채우지 않고도 이 컨텍스트 핸드오프(context hand-off)를 가능하게 할 충분한 세부 정보를 포함하는 `cluster_description`을 생성하기 때문에 작동합니다.

프롬프트(prompt)의 형태는 다음과 같을 수 있습니다.

```
"다음 클러스터에 대한 짧고 간결한 이름을 제안하고, 해당 클러스터의 핵심 내용을 설명하는 한 문장 요약을 제공하세요.
클러스터 논문 요약: [논문 요약 리스트]
클러스터 설명: [cluster_description]
이름:
설명:"
```

두 번째 LLM 단계는 고수준 클러스터의 이름을 지정하고, 더 넓은 컨텍스트에서 볼 때 중복을 발견하거나 더 나은 이름을 할당할 수 있다면 선택적으로 하위 수준 클러스터의 이름을 변경합니다. 이러한 호출(call)을 몇 번만 수행하기 때문에, 이를 더욱 고급 모델에 할당할 수 있습니다. 예를 들어, 여기에서 Command-B 추론(Reasoning) 모델을 사용하여 이름에 대해 추론하도록 할 수 있습니다. 이러한 추적(trace)을 보는 것은 항상 흥미롭습니다. 다음은 범주 이름 할당을 위한 추론 추적 예시입니다.

**모델 추론 과정:**
고수준 범주 이름의 경우, 이 테마를 캡슐화해야 합니다. "LLM 추론" 및 "평가"와 같은 용어가 떠오릅니다. 이 범주가 더 큰 ML 연구 컬렉션의 일부이므로 구체적이어야 합니다. "LLM 추론 및 평가"는 개발 및 평가 측면을 모두 다루므로 적절해 보입니다.

---

### 최신 모델에 대하여

Command B, Command B 추론(Reasoning), 그리고 Embed 5는 2026년 초에 출시된 Cohere의 최신 모델 라인업입니다. Command B 모델이 어떻게 구축되었는지에 대한 60페이지 분량의 심층적인 통찰력을 담고 있는 Command B 기술 보고서(Technical Report)를 읽음으로써 이 모델에 대해 더 자세히 알아볼 수 있습니다. 이 모델들은 이전 세대보다 향상된 성능과 효율성을 제공합니다.

---

### 향후 작업 및 한계점

이 작업은 단순히 가능한 파이프라인(pipeline) 중 하나이며, 지속적으로 개선될 수 있는 여지가 많습니다. 제 궁극적인 목표는 더 많은 사람들이 방대한 양의 정보를 초인적인 방식으로 처리할 수 있도록 돕는 방법과 사용자 인터페이스(user interface)를 혁신하는 것입니다. 제가 추가 개발이 필요하다고 생각하는 몇 가지 핵심 영역은 다음과 같습니다.

*   많은 작은 클러스터를 검토하는 더 나은 자동화 방법. 현재는 수동으로 스캔하고(주로 엑셀에서) 큰 클러스터 이름을 더 자세히 살펴보는 방식을 사용하지만, 클러스터 수가 수백 개로 늘어나면 더 정교한 도구의 도움이 필요할 것입니다.
*   노이즈(noise)를 더욱 효과적으로 처리하는 클러스터링 워크플로우. HDBSCAN이 이 부분에 유용하다는 것을 알고 있습니다. 저는 종종 첫 번째 K-평균(K-Means) 단계를 선호하지만, 의미론적 유사성(semantic similarity)에도 불구하고 실제로는 일관된 그룹화(coherent grouping)의 일부가 아닐 수 있기 때문에 논문 수가 적은 클러스터는 노이즈로 간주하고 있습니다.
*   다양한 토폴로지(topology) 또는 다른 할당(assignment) 간 전환을 허용하는 직관적인 UI(사용자 인터페이스). Datamapplot은 이 중 일부 기능을 이미 제공하며, 저는 그 부분을 더 깊이 파고들어 사용자 경험을 향상시킬 계획입니다.

**감사 인사**

Adrien Morisot, Ahmet Ustun, Case Ploeg, Eugene Cho, Irem Ergun, Keith Hall, Komal Kumar Teru, Madeline Smith, Nick Frosst, Patrick Lewis, Rafid Al-Humaimidi, Sarra Habchi, Sophia Althammer, Suhas Pai, Thomas Euyang, Trent Fowler, Varun Kumethi에게 이 탐색에 대한 피드백, 생각, 그리고 복도에서의 건설적인 대화에 진심으로 감사드립니다.

과거에 이러한 방법을 탐색해 본 적이 있습니까? 댓글로 공유하고 링크를 남겨주세요!

Language Models & Co.를 읽어주셔서 감사합니다! 새로운 게시물을 무료로 받아보고 제 작업을 지원하려면 구독하세요. 구독하기