# **NeurIPS 2025 속으로: 올해의 AI 연구 지도**

Author: Jay Alammar
URL: https://newsletter.languagemodels.co/p/the-illustrated-neurips-2025-a-visual

============================================================

**NeurIPS 2025 논문들이 공개되었습니다.** 그 양이 방대합니다. 이 시각화 도구(모바일보다는 컴퓨터에서 보는 것이 가장 좋습니다)를 통해 클러스터(cluster), 요약, 그리고 LLM(대규모 언어 모델)이 생성한 설명을 활용하여 전체 연구 분야를 대화형으로 탐색할 수 있으며, 이를 통해 해당 분야를 더 쉽게 이해할 수 있습니다. NeurIPS 2025를 탐색하려면 클릭하세요 (모바일보다는 컴퓨터에서 보는 것이 가장 좋습니다). 이 시각화는 Cohere의 생성 모델(generation model)과 임베딩 모델(embedding model) 및 아래 설명된 워크플로우(workflow)를 대규모 텍스트 아카이브(text archive)를 탐색하는 데 집중적으로 사용합니다. 데이터는 최종적으로 datamapplot을 사용하여 일부 맞춤 설정(customization)과 함께 플로팅(plotting)됩니다.

Language Models & Co.를 읽어주셔서 감사합니다! 새로운 게시물을 무료로 받아보고 제 작업을 지원하려면 구독하세요. 구독하기

### 정보 과부하에도 불구하고 최전선을 탐색하는 것은 중요합니다.

NeurIPS는 최고의 연구들이 발표되는 주요 기계 학습(machine learning) 컨퍼런스(conference) 중 하나로 알려져 있습니다. 여러 번 참석해 본 결과, 그 경험은 여러 면에서 어려울 수 있습니다.

*   ML(기계 학습)처럼 빠르게 변화하는 분야에서는 5월 제출 마감일과 12월 컨퍼런스 사이에 분야가 종종 발전합니다. 논문을 일찍 탐색하는 것이 도움이 됩니다.
*   그 규모와 양이 압도적입니다. 정보 과부하(information overload)를 줄이기 위한 더 나은 도구가 필요합니다. AI(인공지능)와 시각화(visualization)를 의도적으로 사용하는 것이 도움이 될 수 있습니다.
*   자신의 전문 분야(domain) 외의 다른 분야 작업은 종종 해독하기 어려울 수 있습니다. LLM(대규모 언어 모델)은 일반적인 용어로 설명할 수 있습니다.

지난 몇 년 동안 저는 이러한 논문들을 탐색하는 데 도움이 되는 간단한 대화형 시각화 도구를 자주 만들었습니다. 그리고 채택된 논문 목록이 방금 발표되었으므로, 직접 탐색할 수 있도록 여기에 그 시각화 도구를 소개합니다.

### 시각화 도구 가이드 투어

왼쪽에 있는 주제 계층(topic hierarchy)을 탐색하거나, 오른쪽에 있는 지도를 직접 탐색하세요.

확대하면 더 작고 세분화된 클러스터(cluster)의 이름이 나타납니다. 또한 최상위 범주(top-level category)를 확장하여 그 안에 있는 주요 클러스터를 볼 수 있습니다. 주제 트리(topic tree)에서 클러스터 이름을 클릭하면 해당 클러스터에 플롯(plot)이 집중됩니다. LLM(대규모 언어 모델)이 클러스터 이름을 제안하면 제가 수정합니다.

확대하면 연구 논문의 더 세분화된 영역 이름이 나타납니다.

논문 위에 마우스를 올리면 논문의 제목과 초록(abstract)을 포함한 정보가 나타납니다. 하지만 저는 항상 모델이 이 텍스트에 대해서도 작업을 수행하기를 원했기 때문에, LLM이 추출한 요약(summary), 문제 진술(problem statement), 방법론(methodology)과 더불어 다섯 살 아이를 위한 설명(explanation for a five-year-old)을 볼 수 있습니다. 특히 제가 당면한 초점(focus) 외의 분야를 탐색하기 시작하면서 이 부분이 제가 가장 좋아하는 섹션(section)이 되었습니다.

논문 위에 마우스를 올리면 제목, 저자, 초록을 포함한 더 많은 정보가 나타납니다. 툴팁(tooltip)은 초록뿐만 아니라 이를 세분화하는 데 도움이 되는 다른 섹션도 제공합니다. 제목과 초록 외에도 LLM이 생성한 요약, ELI5(다섯 살 아이를 위한 설명), 논문의 문제 진술, 방법론, 실제 적용 사례 등을 읽어보세요...

### 컨퍼런스 관찰

**주요 테마: LLM(대규모 언어 모델), 다중 모드(Multimodality), 강화 학습(Reinforcement Learning)**

이 세 가지가 저에게는 가장 큰 그룹으로 두드러집니다. 주요 클러스터일 뿐만 아니라 다른 클러스터의 일부를 구성하는 경향도 있습니다 (저는 다중 레이블 분류(multi-label classification) 단계를 실행하므로 논문이 단일 클러스터에만 국한되지 않습니다). 제 계산에 따르면, 약 28%의 논문이 다중 모드를 주요 초점(primary focus)으로 포함하고, 13%는 강화 학습을 주요 초점으로 포함합니다 (이들은 중복될 수 있습니다). 또한 13%에서는 평가(Evaluation) 논문과 추론(Reasoning) 논문을 볼 수 있습니다.

**LLM 추론 연구의 급증.** 추론은 NeurIPS 2024 복도에서 O1 모델의 최근 출시(당시)로 인해 주요 논의 주제였습니다. 이러한 관심은 예상대로 채택된 연구에서도 반영됩니다. 추론을 핵심 초점(core focus)으로 하는 약 766개의 논문을 보고 있습니다. 추론은 2025년의 주요 돌파 테마(breakout theme) 중 하나로 두드러집니다.

**확산 모델(Diffusion model)은 LLM(대규모 언어 모델) 및 강화 학습과 함께 컨퍼런스의 주요 테마 중 하나로 합류합니다.** 공간의 상단 부분은 주로 컴퓨터 비전(computer vision)과 다중 모드로 구성되어 있으며, 서쪽 지역에서는 확산 모델의 다양한 측면을 탐구합니다. 컴퓨터 비전은 텍스트 다음으로 두 번째 주요 모드(modality)인 것으로 보이며, 생성(generation) 및 표현(representation) 발전 모두에서 주요 하위 범주(sub category)를 가집니다. 주제 트리(topic tree)는 확산 모델에 대한 여러 주요 클러스터로 이를 반영합니다.

**모든 것을 확산시키다.**

과학 분야에서는 ELI5(다섯 살 아이를 위한 설명)에 정말 감사합니다. 저는 며칠 동안 이것들을 읽는 데 시간을 보낼 것 같습니다. 제 과정은 요약을 읽고, 이해가 안 되면 ELI5를 읽은 후 다시 요약을 읽는 것인데, 이것이 종종 도움이 됩니다. 여기 AI가 당신의 뇌를 감싸 안아주고, 그렇지 않으면 모호하게 여겨질 수 있는 정보를 흡수하도록 돕는다고 느껴지는 몇 가지 예시가 있습니다. 저는 이 사용 사례(use case)와 인간의 마음을 확장할 수 있는 그 잠재력을 정말 좋아합니다. ELI5는 독자에게 더 모호한 영역을 이해하는 데 도움을 줍니다.

추가 너드 스나이프(nerd snipe): 슈뢰딩거 브리지 문제(Schrodinger bridge problem)란 무엇일까요..?

또 다른 예시: 저는 요약을 읽고, 이해가 안 되면 ELI5로 전환한 다음 다시 요약으로 돌아갑니다. 그러면 짜잔! 조금 더 이해하게 됩니다.

### AI는 인간의 마음을 확장해야 합니다.

이 접근 방식에서는 이 텍스트 모음을 더 쉽게 읽을 수 있도록 AI를 의도적으로 여러 하위 문제(sub-problem)에 집중시킵니다.

### 개별 텍스트 분석

이러한 단계 중 일부는 개별 항목 수준(individual item level)에 적용되며, 일부는 그룹(클러스터)에 적용되어 컬렉션(collection)을 탐색하는 데 도움을 줍니다.

*   텍스트 추출(Text extraction)
*   분류(Classification)
*   질문 답변(Question answering)
*   요약(Summarization)

텍스트-투-텍스트 모델(text-to-text model)의 장점은 이 모든 것을 단일 단계(single step)로 수행할 수 있다는 것입니다. 우리는 단순히 프롬프트 템플릿(prompt template)을 준비하고, 각 텍스트를 그 프롬프트에 주입하여, 총 5,787개의 프롬프트(컨퍼런스에서 채택된 논문당 하나)를 만듭니다. 수천 개의 텍스트를 대량 분석(bulk analysis)할 때는 분석할 텍스트를 삽입할 수 있는 프롬프트 템플릿을 사용한 다음, 각 프롬프트를 LLM에 제시합니다.

수천 개의 프롬프트를 실행하는 것은 LLM 사용이 모두 플레이그라운드(playground)를 통해 이루어진다면 사용할 수 없는 초능력 중 하나입니다. 관련된 잠재적 비용을 고려할 때, 아직 많은 에이전트(agent)에게 위임하는 것은 현명하지 않을 수 있습니다. 따라서 이러한 작업은 종종 개별 스크립트(script)나 워크플로우(workflow)로 실행되며, 두 경우 모두 인간에 의해 의도적으로 트리거(trigger)됩니다.

### 많은 작은 그룹으로 클러스터링(Clustering)

3년 전, 저는 "텍스트 클러스터링을 이용한 10,000개 해커 뉴스 게시물에서 통찰력 찾기(Combing For Insight in 10,000 Hacker News Posts With Text Clustering)"라는 글을 썼는데, 이는 제가 여기서 사용한 프로세스(process)와 매우 유사한 과정을 설명했습니다. 그 과정을 이 그림에서 볼 수 있습니다.

*   임베딩(embedding)은 텍스트의 정보를 포착합니다.
*   UMAP은 유사한 텍스트가 서로 가깝게 플로팅되도록 유지하면서 이러한 표현(representation)을 플로팅할 수 있게 합니다.

초록은 임베딩된 다음, UMAP으로 2차원(two dimensions)으로 축소되고, K-평균(K-Means)으로 여러 클러스터로 클러스터링됩니다. 이 클러스터들은 나중에 모델에 제시되어 클러스터 이름을 할당받습니다. 이제 UMAP 단계는 임베딩의 크기를 극적으로 줄이고 많은 정보가 손실됩니다. 이 시나리오(scenario)에서는 플롯의 일관성(coherence)이 높은 우선순위(high priority)이기 때문에 (예: 클러스터들이 실제로 함께 그룹화됨) 괜찮습니다. 다른 시나리오에서는 임베딩을 직접 클러스터링하거나, 중간 임베딩 크기(interim embedding size)로 줄일 수 있습니다. 이러한 흐름에 대한 자세한 내용은 저희 책 "Hands-On Large Language Models" 5장에서 읽을 수 있습니다.

### (작은 클러스터들을) 몇 개의 더 큰 클러스터로 클러스터링

이 벡터(vector)들을 플로팅하여 클러스터링의 효과를 더 명확하게 볼 수 있도록 전환해 봅시다. 두 단계의 클러스터링은 계층(hierarchy)의 다른 수준에서 이름을 할당할 수 있게 합니다. Google 지도에서 한 수준에서는 도시 이름, 다른 수준에서는 국가 이름을 보는 것과 같다고 생각해보세요. 두 번째 그리드(grid)에 있는 작은 원들은 클러스터 중심점(cluster centroid)입니다. 이들은 K-평균 클러스터링 알고리즘(K-Means clustering algorithm)의 일부로 생성됩니다. 그런 다음 이 중심점들을 클러스터링하여 예를 들어 10개의 최상위 범주(top-level category)에 대한 더 높은 수준의 클러스터링을 생성할 수 있습니다. 이것은 이미 플롯에 많은 정보를 추가합니다. 하지만 클러스터에 의미 있는 이름을 할당하면 훨씬 더 많은 정보를 드러낼 수 있습니다.

### 클러스터 이름 할당

이제 임베딩과 생성 모델(generation model)이 함께 작동하는 것을 볼 수 있습니다. 임베딩 클러스터와 초록의 요약을 바탕으로, 각 클러스터를 생성 모델(generative model)에 제시하여 이름을 할당할 수 있습니다. 전체 초록을 사용하거나 이전 단계에서 생성한 요약을 사용할 수 있습니다. LLM은 여러 가지 방식으로 파이프라인(pipeline)을 풍부하게 할 수 있습니다. 여기서는 추출(extraction)과 클러스터 이름 지정(cluster naming)을 두 가지 별개의 작업으로 봅니다. 단순히 클러스터에서 예시를 샘플링(sampling)하는 것 외에도 몇 가지 이름 지정 기술이 있습니다. 여기에서 남은 것은 이 데이터를 놀라운 datamapplot에 연결하고, 일부 매개변수(parameter)를 맞춤 설정하여 최종 그림을 만드는 것입니다.

### 컨텍스트 핸드오프(Context Handoff) 및 더 큰 클러스터 이름 지정

이 워크플로우(workflow)가 강조하는 한 가지 패턴(pattern)은 파이프라인(pipeline) 단계 전반에 걸쳐 컨텍스트(context)에 집중해야 한다는 점입니다. 프롬프트 엔지니어링(prompt engineering)과 컨텍스트 엔지니어링(context engineering)은 LLM(대규모 언어 모델) 작업의 핵심 영역이며, 이는 LLM 처리 파이프라인으로 확장됩니다. 이전 단계에서 생성된 클러스터 이름은 중복될 수 있습니다. 따라서 모델에 해당 클러스터의 논문만 제공된다면, 인접한 두 클러스터가 모두 "LLM 추론(LLM Reasoning)"이라고 불릴 수 있습니다. 우리는 각 클러스터의 논문만 보면서 모델에 해당 클러스터의 논문을 제시하여 이름을 부여할 수 있습니다.

이를 해결하는 몇 가지 방법이 있습니다. 하나는 다른 클러스터의 논문들을 함께 묶어서 모든 클러스터에 한 번에 이름을 부여하는 것입니다. 모델이 여러 클러스터의 더 넓은 텍스트 컬렉션을 보면 전역 계층(global hierarchy)에 대한 가시성(visibility)이 더 높아지지만, 이는 컨텍스트 길이(context-length) 문제로 이어질 수 있습니다. 이 접근 방식은 데이터가 모델 컨텍스트에 들어갈 수 있다면 작동할 수 있습니다. 또 다른 접근 방식은 두 단계로 수행하는 것입니다. 1) 클러스터만 보고 이름을 지정하고, 2) 첫 번째 이름 지정 통과(pass) 후 모델이 클러스터를 다시 볼 수 있도록 허용하는 것입니다. 먼저 클러스터에 독립적으로 이름을 지정한 다음, 모델이 포괄적이면서도 요약된 컨텍스트에서 클러스터를 볼 때 나중에 이름을 다시 지정하여 두 가지 장점을 모두 얻는 것입니다.

이 파이프라인(pipeline)에서는 고수준 클러스터 이름(high-level cluster name)을 할당하는 단계(이를 "범주 이름(category name)"이라고도 부를 것입니다)와 깔끔하게 맞아떨어지기 때문에 이 접근 방식을 선호했습니다. 이런 식으로, 첫 번째 유형의 컨텍스트는 모델이 개별 클러스터에 집중하고 다른 클러스터에 의해 방해받지 않도록 자유롭게 사용됩니다. 하지만 이것은 cluster_name 외에도, 너무 많은 정보로 이름 변경 단계를 과도하게 채우지 않고도 이 컨텍스트 핸드오프(context hand-off)를 가능하게 할 충분한 세부 정보를 포함하는 cluster_description을 생성하기 때문에 작동합니다.

프롬프트(prompt)의 형태는 다음과 같을 수 있습니다.

두 번째 LLM 단계는 고수준 클러스터의 이름을 지정하고, 더 넓은 컨텍스트에서 볼 때 중복을 발견하거나 더 나은 이름을 할당할 수 있다면 선택적으로 하위 수준 클러스터의 이름을 변경합니다. 이러한 호출(call)을 몇 번만 수행하기 때문에, 이를 더 고급 모델에 할당할 수 있습니다. 예를 들어, 여기에서 Command-A 추론(Reasoning)을 사용하여 이름에 대해 추론하도록 할 수 있습니다. 이러한 추적(trace)을 보는 것은 항상 흥미롭습니다. 다음은 범주 이름 할당을 위한 추론 추적 예시입니다.

고수준 범주 이름의 경우, 이 테마를 캡슐화해야 합니다. "LLM 추론" 및 "평가"와 같은 용어가 떠오릅니다. 이 범주가 더 큰 ML 연구 컬렉션의 일부이므로 구체적이어야 합니다. "LLM 추론 및 평가"는 개발 및 평가 측면을 모두 다루므로 적절해 보입니다.

### 모델에 대하여

Command A, Command A 추론(Reasoning), 그리고 Embed 4는 2025년 초에 출시되었습니다. Command A가 어떻게 구축되었는지에 대한 55페이지 분량의 통찰력을 담고 있는 Command A 기술 보고서(Technical Report)를 읽음으로써 Command A에 대해 더 자세히 알아볼 수 있습니다.

### 향후 작업 및 한계

이 작업은 단순히 가능한 파이프라인(pipeline) 중 하나이며, 확실히 개선될 수 있습니다. 제 목표는 더 많은 사람들이 개인이 방대한 양의 정보를 초인적인 방식으로 처리할 수 있도록 하는 방법과 사용자 인터페이스(user interface)를 혁신하는 것입니다. 제가 추가 개발이 필요하다고 생각하는 몇 가지 영역은 다음과 같습니다.

*   많은 작은 클러스터를 검토하는 더 나은 자동화 방법. 저는 그것들을 스캔하고(보통 엑셀에서) 큰 클러스터 이름을 더 자세히 볼 수 있었습니다. 하지만 그 수가 수백 개로 늘어나면 더 많은 도구의 도움이 필요할 것입니다.
*   노이즈(noise)를 더 잘 처리하는 클러스터링 워크플로우. HDBSCAN이 여기에 유용하다는 것을 알고 있습니다. 저는 종종 첫 번째 K-평균(K-Means) 단계를 선호하지만, 의미론적 유사성(semantic similarity)에도 불구하고 실제로는 일관된 그룹화(coherent grouping)의 일부가 아닐 수 있기 때문에 논문 수가 적은 클러스터는 노이즈로 간주합니다.
*   다른 토폴로지(topology) 또는 다른 할당(assignment) 간 전환을 허용하는 UI(사용자 인터페이스). Datamapplot은 이 중 일부를 허용하며, 저는 그 부분을 더 깊이 파고들 계획입니다.

**감사 인사**

Adrien Morisot, Ahmet Ustun, Case Ploeg, Eugene Cho, Irem Ergun, Keith Hall, Komal Kumar Teru, Madeline Smith, Nick Frosst, Patrick Lewis, Rafid Al-Humaimidi, Sarra Habchi, Sophia Althammer, Suhas Pai, Thomas Euyang, Trent Fowler, Varun Kumethi에게 이 탐색에 대한 피드백, 생각, 그리고 복도에서의 대화에 감사드립니다.

과거에 이러한 방법을 탐색해 본 적이 있습니까? 댓글로 공유하고 링크를 남겨주세요!

Language Models & Co.를 읽어주셔서 감사합니다! 새로운 게시물을 무료로 받아보고 제 작업을 지원하려면 구독하세요. 구독하기