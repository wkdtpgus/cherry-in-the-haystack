**NeurIPS 2025: 방대한 지식의 바다를 항해하는 새로운 접근법**

NeurIPS 2025 학술 논문들이 대중에게 공개되었습니다. 이처럼 엄청난 양의 연구 결과들을 효과적으로 이해하고 탐색하기 위해서는 혁신적인 도구가 필수적입니다. 본 시각화 도구(최적의 경험을 위해 모바일보다는 데스크톱 환경을 권장합니다)는 클러스터링, 핵심 요약, 그리고 대규모 언어 모델(LLM)이 생성한 설명을 활용하여 전체 연구 영역을 대화형 방식으로 탐색할 수 있도록 지원하며, 이를 통해 해당 분야에 대한 이해를 한층 더 쉽게 만들어 줍니다. 지금 바로 NeurIPS 2025 콘텐츠를 탐색해보세요. 이 시각화 시스템은 Cohere의 최신 생성 모델 및 임베딩 모델과 함께, 방대한 텍스트 자료를 심층적으로 분석하는 데 특화된 워크플로우를 집중적으로 활용합니다. 모든 데이터는 datamapplot 라이브러리를 기반으로 일부 맞춤형 설정을 거쳐 최종적으로 시각화됩니다.

Language Models & Co.를 읽어주셔서 감사합니다! 새로운 게시물을 무료로 받아보고 제 작업을 지원하려면 구독하세요. 구독하기

### 정보의 폭증 속에서 연구의 최전선을 꿰뚫어 보는 통찰력

NeurIPS는 최첨단 연구 성과가 발표되는 세계적인 기계 학습(ML) 학회 중 하나로 명성이 높습니다. 수차례 참여 경험에 비추어 볼 때, 이 행사는 여러 면에서 도전적일 수 있습니다.

*   기계 학습과 같이 급변하는 분야에서는 5월 제출 마감일과 12월 컨퍼런스 개최 시점 사이에 연구 환경이 빠르게 진화하는 경향이 있습니다. 따라서 논문을 조기에 파악하는 것이 연구자들에게 큰 이점으로 작용합니다.
*   학회의 엄청난 규모와 논문의 양은 때때로 압도적인 정보 과부하를 야기합니다. 이러한 부담을 경감시키기 위한 더욱 정교한 도구가 절실합니다. 인공지능(AI)과 시각화 기술을 의도적으로 접목하는 것이 효과적인 해결책이 될 수 있습니다.
*   자신의 전문 분야(도메인)를 벗어난 다른 영역의 연구는 그 내용을 파악하기 어렵습니다. 대규모 언어 모델(LLM)은 복잡한 개념을 일반적인 언어로 명료하게 설명하는 데 기여할 수 있습니다.

지난 몇 년간 저는 이러한 방대한 논문들을 효과적으로 탐색할 수 있도록 돕는 간단하면서도 상호작용적인 시각화 도구를 꾸준히 개발해왔습니다. 최근 채택된 논문 목록이 발표됨에 따라, 여러분이 직접 연구 트렌드를 탐색할 수 있도록 이 도구를 공개합니다.

### 시각화 도구 활용 가이드

화면 좌측에 위치한 주제 계층 구조를 살펴보거나, 우측의 지도에서 직접 탐색을 시작할 수 있습니다.

지도를 확대하면 더욱 작고 세분화된 클러스터들의 명칭이 드러납니다. 또한, 최상위 범주를 확장하여 그 안에 포함된 주요 클러스터들을 확인할 수 있습니다. 주제 트리에서 특정 클러스터 이름을 클릭하면 플롯이 해당 클러스터에 집중되어 표시됩니다. 클러스터 이름은 주로 LLM이 제안하며, 필요에 따라 제가 수정 과정을 거칩니다.

확대할수록 연구 논문의 더 상세한 영역 이름이 나타나게 됩니다.

개별 논문 위에 마우스 커서를 올리면 해당 논문의 제목과 초록을 포함한 기본 정보가 표시됩니다. 하지만 저는 모델이 이 텍스트에 대해서도 추가적인 분석을 수행하기를 원했기 때문에, LLM이 추출한 요약, 문제 진술, 방법론과 더불어 '다섯 살 아이를 위한 설명(ELI5)'을 제공하도록 했습니다. 특히 제가 당면한 연구 초점 외의 분야를 탐색하기 시작하면서 이 부분이 가장 유용하고 흥미로운 기능이 되었습니다.

논문 위에 마우스를 올리면 제목, 저자, 초록을 포함한 상세 정보가 표시됩니다. 툴팁은 초록뿐만 아니라 이를 세분화하는 데 도움이 되는 다른 섹션도 제공합니다. 제목과 초록 외에도 LLM이 생성한 요약, ELI5(다섯 살 아이를 위한 설명), 논문의 문제 진술, 방법론, 실제 적용 사례 등을 읽어보세요. 이 기능은 연구자가 복잡한 아이디어를 빠르게 흡수하고, 새로운 관점을 얻는 데 결정적인 역할을 합니다. 이는 단순한 정보 제공을 넘어, 사용자가 지식의 연결고리를 스스로 발견하도록 돕는 인지적 확장 도구로서 기능합니다.

### NeurIPS 2025 핵심 관찰 및 신흥 트렌드

**주요 테마: 대규모 언어 모델(LLM), 다중 모드(Multimodality), 강화 학습(Reinforcement Learning)**

이 세 가지 영역은 이번 학회에서 가장 큰 연구 그룹으로 두드러집니다. 이들은 단순히 주요 클러스터를 형성할 뿐만 아니라, 다른 클러스터의 구성 요소로도 자주 등장합니다 (저는 다중 레이블 분류 단계를 실행하므로, 논문이 단일 클러스터에만 국한되지 않습니다). 제 분석에 따르면, 약 28%의 논문이 다중 모드를 주요 초점으로 다루고 있으며, 13%는 강화 학습을 핵심 주제로 포함합니다 (이들은 중복될 수 있습니다). 또한, 13%에서는 평가(Evaluation) 및 추론(Reasoning) 관련 논문들이 주목할 만한 비중을 차지합니다.

**LLM 추론 연구의 폭발적 증가.** 추론은 NeurIPS 2024에서 O1 모델의 최근 출시(당시)로 인해 주요 논의 주제였습니다. 이러한 관심은 예상대로 2025년 채택된 연구에서도 강력하게 반영됩니다. 현재 약 766개의 논문이 추론을 핵심 초점으로 다루고 있는 것으로 파악됩니다. 추론은 2025년의 주요 돌파 테마 중 하나로 확고히 자리매김하고 있습니다. 이는 LLM이 단순한 텍스트 생성기를 넘어, 복잡한 문제 해결과 논리적 사고 능력을 갖춘 에이전트로 진화하고 있음을 시사합니다.

**확산 모델(Diffusion model)의 부상: 생성 AI의 새로운 지평.** 확산 모델은 대규모 언어 모델(LLM) 및 강화 학습과 함께 컨퍼런스의 핵심 테마 중 하나로 새롭게 부상했습니다. 시각화 공간의 상단 부분은 주로 컴퓨터 비전과 다중 모드 연구로 구성되어 있으며, 이 중 서쪽 영역은 확산 모델의 다양한 측면을 심층적으로 탐구합니다. 컴퓨터 비전은 텍스트 다음으로 두 번째로 중요한 모달리티로 보이며, 생성 및 표현 학습 발전 모두에서 주요 하위 범주를 가집니다. 주제 트리에서도 확산 모델에 대한 여러 핵심 클러스터가 이를 명확히 보여줍니다. 최근 확산 모델은 이미지, 비디오, 오디오 생성뿐만 아니라 과학적 데이터 합성 및 로봇 제어에까지 그 적용 범위를 확장하며 생성 인공지능 분야의 혁신을 주도하고 있습니다. 이는 LLM과의 결합을 통해 더욱 강력한 다중 모드 생성 능력을 발휘할 잠재력을 가지고 있습니다.

**모든 것을 확산시키다.**

과학 분야에서 ELI5(다섯 살 아이를 위한 설명)는 정말 감사한 기능입니다. 저는 며칠 동안 이 설명을 읽는 데 시간을 보낼 것 같습니다. 제 과정은 요약을 읽고, 이해가 안 되면 ELI5를 읽은 후 다시 요약을 읽는 것인데, 이것이 종종 도움이 됩니다. 여기 AI가 당신의 뇌를 감싸 안아주고, 그렇지 않으면 모호하게 여겨질 수 있는 정보를 흡수하도록 돕는다고 느껴지는 몇 가지 예시가 있습니다. 저는 이 사용 사례와 인간의 마음을 확장할 수 있는 그 잠재력을 정말 좋아합니다. ELI5는 독자에게 더 모호한 영역을 이해하는 데 도움을 줍니다.

추가 너드 스나이프: 슈뢰딩거 브리지 문제란 무엇일까요?

또 다른 예시: 저는 요약을 읽고, 이해가 안 되면 ELI5로 전환한 다음 다시 요약으로 돌아갑니다. 그러면 짜잔! 조금 더 이해하게 됩니다. 이처럼 ELI5는 복잡한 기술 개념을 비전문가도 접근하기 쉬운 형태로 변환하여, 지식 격차를 해소하고 학습 곡선을 완화하는 데 탁월한 역할을 수행합니다. 이는 단순히 정보를 요약하는 것을 넘어, 개념적 장벽을 허무는 강력한 교육 도구로서의 가치를 지닙니다.

### AI는 인류의 지적 능력을 확장하는 도구여야 합니다.

이러한 접근 방식에서는 AI를 의도적으로 여러 하위 문제에 집중시켜, 방대한 양의 텍스트 자료를 사용자가 더 쉽게 이해하고 소화할 수 있도록 돕습니다. 이는 단순한 자동화가 아닌, 인간의 인지 과정을 보완하고 증강하는 방향으로 설계된 것입니다.

### 개별 텍스트 분석: LLM 기반의 정교한 정보 추출

이러한 단계 중 일부는 개별 항목 수준에 적용되며, 일부는 그룹(클러스터)에 적용되어 전체 컬렉션을 효과적으로 탐색하는 데 도움을 줍니다.

*   텍스트 추출(Text extraction)
*   분류(Classification)
*   질문 답변(Question answering)
*   요약(Summarization)

텍스트-투-텍스트 모델(text-to-text model)의 장점은 이 모든 작업을 단일 단계로 수행할 수 있다는 점입니다. 우리는 단순히 프롬프트 템플릿을 준비하고, 각 텍스트를 해당 프롬프트에 주입하여, 총 5,787개의 프롬프트(컨퍼런스에서 채택된 논문당 하나)를 생성합니다. 수천 개의 텍스트를 대량 분석할 때는 분석할 텍스트를 삽입할 수 있는 프롬프트 템플릿을 사용한 다음, 각 프롬프트를 대규모 언어 모델(LLM)에 제시합니다.

수천 개의 프롬프트를 실행하는 것은 LLM 활용이 단순히 플레이그라운드에서 이루어진다면 불가능한 초능력 중 하나입니다. 관련된 잠재적 비용을 고려할 때, 아직 많은 에이전트에게 작업을 완전히 위임하는 것은 현명하지 않을 수 있습니다. 따라서 이러한 작업은 종종 개별 스크립트나 워크플로우로 실행되며, 두 경우 모두 인간에 의해 의도적으로 트리거됩니다. 이러한 방식은 비용 효율성을 유지하면서도 대량의 데이터를 체계적으로 처리할 수 있는 유연성을 제공합니다.

### 많은 작은 그룹으로의 클러스터링: 구조화된 지식 발견

3년 전, 저는 "텍스트 클러스터링을 이용한 10,000개 해커 뉴스 게시물에서 통찰력 찾기"라는 글을 썼는데, 이는 제가 여기서 사용한 과정과 매우 유사한 절차를 설명했습니다. 그 과정을 다음 그림에서 확인할 수 있습니다.

*   임베딩(embedding)은 텍스트의 의미론적 정보를 벡터 공간에 효과적으로 포착합니다.
*   UMAP은 이러한 고차원 표현을 2차원으로 축소하여, 유사한 텍스트들이 서로 가깝게 배치되도록 유지하면서 시각적으로 플로팅할 수 있게 합니다.

초록은 임베딩된 다음, UMAP을 통해 2차원으로 차원 축소되고, K-평균(K-Means) 알고리즘을 사용하여 여러 클러스터로 그룹화됩니다. 이렇게 형성된 클러스터들은 나중에 모델에 제시되어 각 클러스터의 명칭을 할당받습니다. UMAP 단계에서 임베딩의 차원이 극적으로 줄어들면서 일부 정보 손실이 발생할 수 있습니다. 그러나 이 시나리오에서는 플롯의 시각적 일관성(예: 클러스터들이 실제로 의미 있게 함께 그룹화되는지)이 높은 우선순위를 가지므로 이러한 손실은 용인될 수 있습니다. 다른 상황에서는 임베딩을 직접 클러스터링하거나, 중간 정도의 임베딩 크기로 축소하는 방안도 고려될 수 있습니다. 이러한 고급 임베딩 및 클러스터링 흐름에 대한 더 자세한 내용은 저희 책 "Hands-On Large Language Models" 5장에서 심도 있게 다루고 있습니다.

### 계층적 클러스터링: 작은 클러스터들을 더 큰 그룹으로 묶기

이러한 벡터들을 플로팅하여 클러스터링의 효과를 더욱 명확하게 시각화해 봅시다. 두 단계의 클러스터링은 계층 구조의 다른 수준에서 이름을 할당할 수 있도록 합니다. 이는 마치 Google 지도에서 한 수준에서는 도시 이름을 보고, 다른 수준에서는 국가 이름을 보는 것과 같다고 생각할 수 있습니다. 두 번째 그리드에 있는 작은 원들은 각 클러스터의 중심점(centroid)입니다. 이들은 K-평균 클러스터링 알고리즘의 일부로 생성됩니다. 그런 다음 이 중심점들을 다시 클러스터링하여, 예를 들어 10개의 최상위 범주에 대한 더 높은 수준의 클러스터링을 생성할 수 있습니다. 이 과정만으로도 플롯에 많은 정보가 추가되지만, 각 클러스터에 의미 있는 이름을 할당하면 훨씬 더 풍부한 통찰력을 얻을 수 있습니다.

### 클러스터 이름 할당: LLM의 지능적 명명 능력

이제 임베딩 모델과 생성 모델이 시너지를 발휘하는 지점을 살펴볼 수 있습니다. 임베딩된 클러스터와 초록의 요약을 기반으로, 각 클러스터를 생성 모델에 제시하여 적절한 이름을 할당할 수 있습니다. 이때 전체 초록을 사용하거나 이전 단계에서 생성한 요약을 활용할 수 있습니다. 대규모 언어 모델(LLM)은 다양한 방식으로 파이프라인을 풍부하게 할 수 있습니다. 여기서는 텍스트 추출과 클러스터 이름 지정을 두 가지 별개의 작업으로 간주합니다. 단순히 클러스터에서 예시를 샘플링하는 것을 넘어, 몇 가지 고급 이름 지정 기술을 적용하여 정확하고 의미 있는 이름을 도출합니다. 이 단계에서 남은 것은 이 데이터를 놀라운 datamapplot 시각화 도구에 연결하고, 일부 매개변수를 맞춤 설정하여 최종적인 그림을 완성하는 것입니다.

### 컨텍스트 핸드오프 및 상위 클러스터 이름 지정: LLM 파이프라인의 정교함

이 워크플로우가 강조하는 한 가지 중요한 패턴은 파이프라인 단계 전반에 걸쳐 컨텍스트(Context) 관리에 집중해야 한다는 점입니다. 프롬프트 엔지니어링과 컨텍스트 엔지니어링은 LLM 작업의 핵심 영역이며, 이는 LLM 처리 파이프라인으로 자연스럽게 확장됩니다. 이전 단계에서 생성된 클러스터 이름은 종종 중복될 수 있습니다. 예를 들어, 모델에 해당 클러스터의 논문만 제공된다면, 인접한 두 클러스터가 모두 "LLM 추론(LLM Reasoning)"이라고 명명될 가능성이 있습니다. 우리는 각 클러스터의 논문만 보면서 모델에 해당 클러스터의 논문을 제시하여 이름을 부여할 수 있습니다.

이를 해결하는 몇 가지 방법이 있습니다. 하나는 다른 클러스터의 논문들을 함께 묶어서 모든 클러스터에 한 번에 이름을 부여하는 것입니다. 모델이 여러 클러스터의 더 넓은 텍스트 컬렉션을 보면 전역 계층 구조에 대한 가시성이 더 높아지지만, 이는 컨텍스트 길이 문제로 이어질 수 있습니다. 이 접근 방식은 데이터가 모델 컨텍스트에 들어갈 수 있다면 효과적일 수 있습니다. 또 다른 접근 방식은 두 단계로 수행하는 것입니다. 첫째, 클러스터만 보고 이름을 지정하고, 둘째, 첫 번째 이름 지정 통과 후 모델이 클러스터를 다시 볼 수 있도록 허용하는 것입니다. 먼저 클러스터에 독립적으로 이름을 지정한 다음, 모델이 포괄적이면서도 요약된 컨텍스트에서 클러스터를 볼 때 나중에 이름을 다시 지정하여 두 가지 장점을 모두 얻는 것입니다.

이 파이프라인에서는 고수준 클러스터 이름(이를 "범주 이름"이라고도 부를 것입니다)을 할당하는 단계와 깔끔하게 맞아떨어지기 때문에 이 후자의 접근 방식을 선호했습니다. 이런 식으로, 첫 번째 유형의 컨텍스트는 모델이 개별 클러스터에 집중하고 다른 클러스터에 의해 방해받지 않도록 자유롭게 사용됩니다. 하지만 이것은 `cluster_name` 외에도, 너무 많은 정보로 이름 변경 단계를 과도하게 채우지 않고도 이 컨텍스트 핸드오프를 가능하게 할 충분한 세부 정보를 포함하는 `cluster_description`을 생성하기 때문에 더욱 효과적입니다.

프롬프트의 형태는 다음과 같을 수 있습니다.

```
"다음 클러스터의 논문 목록을 분석하여 가장 적절하고 간결한 이름을 제안하고, 이 이름이 이 클러스터의 핵심 주제를 가장 잘 반영하는 이유를 설명하시오: [클러스터 논문 요약 목록]"
```

두 번째 LLM 단계는 고수준 클러스터의 이름을 지정하고, 더 넓은 컨텍스트에서 볼 때 중복을 발견하거나 더 나은 이름을 할당할 수 있다면 선택적으로 하위 수준 클러스터의 이름을 변경합니다. 이러한 호출을 몇 번만 수행하기 때문에, 이를 더 고급 모델에 할당할 수 있습니다. 예를 들어, 여기에서 Command-A 추론(Reasoning)을 사용하여 이름에 대해 추론하도록 할 수 있습니다. 이러한 추적을 보는 것은 항상 흥미롭습니다. 다음은 범주 이름 할당을 위한 추론 추적 예시입니다.

고수준 범주 이름의 경우, 이 테마를 캡슐화해야 합니다. "LLM 추론" 및 "평가"와 같은 용어가 떠오릅니다. 이 범주가 더 큰 ML 연구 컬렉션의 일부이므로 구체적이어야 합니다. "LLM 추론 및 평가"는 개발 및 평가 측면을 모두 다루므로 적절해 보입니다.

### 사용된 모델에 대한 정보

본 시스템은 Cohere의 최신 언어 모델인 Command A, Command A 추론(Reasoning), 그리고 Embed 4를 활용합니다. 이 모델들은 2025년 초에 출시되었으며, 특히 Command A는 그 구축 과정에 대한 심도 깊은 통찰력을 담은 55페이지 분량의 기술 보고서(Technical Report)를 통해 더 자세히 이해할 수 있습니다. 이들 모델은 텍스트 이해, 생성, 그리고 추론 능력에서 최첨단 성능을 보여주며, 본 시각화 도구의 핵심 동력원 역할을 합니다.

### 향후 개발 방향 및 한계점

이 작업은 방대한 정보를 처리하기 위한 수많은 가능한 파이프라인 중 하나일 뿐이며, 분명히 개선될 여지가 많습니다. 제 궁극적인 목표는 개인이 초인적인 방식으로 방대한 양의 정보를 처리하고, 사용자 인터페이스(UI)를 혁신하여 지식 발견 경험을 극대화하는 방법을 모색하는 것입니다. 제가 추가 개발이 필요하다고 생각하는 몇 가지 핵심 영역은 다음과 같습니다.

*   **소규모 클러스터 검토 자동화 강화**: 현재는 많은 작은 클러스터들을 수동으로 스캔(주로 엑셀에서)하여 큰 클러스터 이름을 더 자세히 검토하고 있습니다. 그러나 클러스터 수가 수백 개로 늘어나면 이러한 수작업은 비효율적이 되므로, 더욱 정교한 자동화 도구의 지원이 절실합니다. 예를 들어, LLM이 각 소규모 클러스터의 대표 논문을 선별하고 요약하여 사용자에게 제시하는 기능을 추가할 수 있습니다.
*   **노이즈 처리 및 클러스터링 워크플로우 개선**: 클러스터링 과정에서 발생하는 노이즈(예: 의미론적 유사성에도 불구하고 일관된 그룹화에 속하지 않는 소수의 논문)를 더 효과적으로 처리하는 워크플로우가 필요합니다. HDBSCAN과 같은 밀도 기반 클러스터링 알고리즘이 이 문제 해결에 유용할 수 있습니다. 저는 종종 첫 번째 K-평균 단계를 선호하지만, 논문 수가 적은 클러스터는 노이즈로 간주하고 이를 걸러내는 메커니즘을 강화할 계획입니다.
*   **다양한 토폴로지 및 할당 간 전환을 허용하는 UI**: 사용자가 클러스터링의 다른 토폴로지(예: 계층적 클러스터링의 다른 깊이)나 다른 할당(예: 특정 논문을 여러 클러스터에 속하게 하는 다중 레이블 할당) 간에 유연하게 전환할 수 있는 사용자 인터페이스를 개발해야 합니다. Datamapplot은 이러한 기능 중 일부를 지원하며, 저는 이 부분을 더 깊이 탐구하고 통합할 계획입니다. 또한, 사용자가 직접 클러스터링 파라미터를 조정하거나, 클러스터링 결과를 실시간으로 재구성할 수 있는 기능을 추가하여 개인화된 탐색 경험을 제공할 수 있습니다.

**감사 인사**

Adrien Morisot, Ahmet Ustun, Case Ploeg, Eugene Cho, Irem Ergun, Keith Hall, Komal Kumar Teru, Madeline Smith, Nick Frosst, Patrick Lewis, Rafid Al-Humaimidi, Sarra Habchi, Sophia Althammer, Suhas Pai, Thomas Euyang, Trent Fowler, Varun Kumethi에게 이 탐색에 대한 귀중한 피드백, 깊이 있는 생각, 그리고 복도에서의 건설적인 대화에 진심으로 감사드립니다. 여러분의 통찰력은 이 프로젝트를 발전시키는 데 큰 도움이 되었습니다.

과거에 이러한 방법을 탐색해 본 적이 있습니까? 댓글로 경험을 공유하고 관련 링크를 남겨주세요!

Language Models & Co.를 읽어주셔서 감사합니다! 새로운 게시물을 무료로 받아보고 제 작업을 지원하려면 구독하세요. 구독하기