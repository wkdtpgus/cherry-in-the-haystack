데이터 과학자를 위한 효율적인 파이썬(Efficient Python for Data Scientists) 강좌의 아홉 번째 강의에서, 우리는 pandas를 사용하여 값을 효율적으로 선택하고 교체하는 두 가지 필수적인 DataFrame 연산에 대해 깊이 있게 다룰 것입니다.
1년 동안 50% 할인

특정 또는 무작위 행(row)과 열(column)을 효율적으로 선택하는 실용적인 기술과, replace() 함수를 사용하여 하나 또는 여러 값을 리스트(list)와 딕셔너리(dictionary)로 수정하는 방법을 배울 것입니다. 이러한 기술은 모든 데이터 과학 워크플로우(workflow)의 데이터 조작 단계에서 필수적이며, 더 깔끔하고 빠르며 효율적인 코드를 작성하는 데 도움이 됩니다. 급변하는 데이터 환경과 갈수록 커지는 데이터셋의 규모 속에서, 효율적인 코딩은 단순한 선택이 아닌 필수 역량이 되었습니다. 실시간 데이터 처리, 대규모 모델 학습 등 다양한 시나리오에서 코드의 성능은 프로젝트의 성공 여부를 결정짓는 중요한 요소로 작용합니다.

**목차:**
*   왜 효율적인 코딩이 필요한가?
*   .iloc[ ] 및 .loc[ ]를 사용하여 행과 열을 효율적으로 선택하기
*   DataFrame에서 값을 효과적으로 교체하기
*   값 선택 및 교체를 위한 모범 사례 요약

### 내 모든 책을 40% 할인된 가격으로 한 번의 클릭으로 구매하세요

**유세프 호스니(Youssef Hosni) · 6월 17일**

제 책과 로드맵(roadmap)을 묶은 번들(bundle)을 만들었으니, 단 한 번의 클릭으로 모든 것을 원래 가격보다 40% 저렴하게 구매할 수 있습니다. 이 번들에는 다음을 포함한 8개의 전자책(eBook)이 포함되어 있습니다:

[전체 이야기 읽기](https://medium.com/@youssefhosni/get-all-my-books-one-button-away-with-40-off-221295324150)

### 1. 왜 효율적인 코딩이 필요한가?

효율적인 코드(Efficient code)는 더 빠르게 실행되고 더 적은 계산 메모리(computational memory)를 사용하는 코드입니다. 이 글에서는 time() 함수를 사용하여 계산 시간(computational time)을 측정할 것입니다. 이 함수는 현재 시간을 측정하므로, 코드 실행 전과 후에 변수에 할당한 다음, 그 차이를 계산하여 코드의 계산 시간을 알 수 있습니다.

간단한 예시는 아래 코드에 나와 있습니다:

```python
import time

# record time before execution
start_time = time.time()

# execute operation
result = 5 + 2

# record time after execution
end_time = time.time()

print("Result calculated in {} sec".format(end_time - start_time))
```

효율적인 코드 방법을 적용하는 것이 어떻게 코드 실행 시간(runtime)을 개선하고 계산 시간 복잡도(computational time complexity)를 줄이는지 몇 가지 예시를 살펴보겠습니다:

0부터 100만까지 각 숫자의 제곱을 계산할 것입니다. 먼저, 리스트 컴프리헨션(list comprehension)을 사용하여 이 연산을 실행한 다음, for 루프(loop)를 사용하여 동일한 절차를 반복할 것입니다.

**첫째, 리스트 컴프리헨션 사용:**

```python
#using List comprehension
list_comp_start_time = time.time()
result = [i*i for i in range(0,1000000)]
list_comp_end_time = time.time()
print("Time using the list_comprehension: {} sec".format(list_comp_end_time - list_comp_start_time))
```

이제 for 루프를 사용하여 동일한 연산을 실행할 것입니다:

```python
# Using For loop
for_loop_start_time= time.time()
result=[]
for i in range(0,1000000):
    result.append(i*i)
for_loop_end_time= time.time()
print("Time using the for loop: {} sec".format(for_loop_end_time - for_loop_start_time))
```

둘 사이에 큰 차이가 있음을 알 수 있습니다. 둘 사이의 차이를 백분율로 계산할 수 있습니다:

```python
list_comp_time = list_comp_end_time - list_comp_start_time
for_loop_time = for_loop_end_time - for_loop_start_time

print("Difference in time: {} %".format((for_loop_time - list_comp_time)/ list_comp_time*100))
```

효율적인 코드를 작성하는 것은 단순히 코드를 빠르게 만드는 것을 넘어, 자원 절약 및 대규모 데이터 처리 능력 향상과 직결됩니다. 특히 데이터 과학 분야에서는 빅데이터를 다루는 경우가 많으므로, 시간 복잡도(Time Complexity)와 공간 복잡도(Space Complexity)를 고려하는 것이 중요합니다. 시간 복잡도는 알고리즘이 문제를 해결하는 데 걸리는 시간의 양을, 공간 복잡도는 알고리즘이 문제를 해결하는 데 필요한 메모리 공간의 양을 의미합니다.

파이썬에서 효율적인 코딩의 중요성을 보여주는 또 다른 예시로, 대규모 숫자 배열에 대한 연산에서 순수 파이썬 리스트와 NumPy 배열 간의 성능 차이를 살펴보겠습니다. NumPy는 과학 계산을 위한 핵심 라이브러리로, C로 구현된 내부 루틴을 사용하여 파이썬 리스트보다 훨씬 빠르게 대규모 배열 연산을 수행할 수 있습니다.

0부터 1000만까지 각 숫자의 제곱을 계산하는 작업을 예로 들어보겠습니다.

```python
import time
import numpy as np

N = 10000000 # 1천만 개의 숫자

print(f"{N}개의 숫자에 대한 제곱 연산 비교:")

# 1. 순수 파이썬 리스트 컴프리헨션 사용
list_comp_start_time = time.time()
result_list = [i*i for i in range(N)]
list_comp_end_time = time.time()
list_comp_time = list_comp_end_time - list_comp_start_time
print(f"  - 리스트 컴프리헨션 사용 시간: {list_comp_time:.4f} 초")

# 2. NumPy 배열 연산 사용
numpy_start_time = time.time()
arr = np.arange(N) # 0부터 N-1까지의 정수 배열 생성
result_numpy = arr * arr # 배열 요소별 제곱 연산
numpy_end_time = time.time()
numpy_time = numpy_end_time - numpy_start_time
print(f"  - NumPy 배열 연산 사용 시간: {numpy_time:.4f} 초")

# 성능 개선율 계산
if numpy_time > 0:
    performance_gain = (list_comp_time - numpy_time) / numpy_time * 100
    print(f"  - NumPy 사용 시 성능 개선율: {performance_gain:.2f} %")
else:
    print("  - NumPy 연산 시간이 너무 짧아 비교가 어렵습니다.")
```

이 예시에서 볼 수 있듯이, NumPy는 대규모 숫자 연산에서 파이썬의 기본 리스트보다 압도적인 성능을 보여줍니다. 이는 NumPy가 벡터화된 연산(vectorized operations)을 지원하고, 내부적으로 최적화된 C 코드를 사용하기 때문입니다. 데이터 과학 프로젝트에서 수백만, 수천만 개의 데이터를 다루는 것은 흔한 일이므로, 이러한 라이브러리의 효율성을 활용하는 것이 매우 중요합니다.

효율적인 코드를 작성하는 효과를 보여주는 또 다른 예시입니다. 1부터 100만까지의 모든 연속된 숫자의 합을 계산하려고 합니다. 두 가지 방법이 있습니다: 첫 번째는 무차별 대입(brute force) 방식을 사용하는 것으로, 1부터 100만까지 하나씩 더하는 것입니다.

```python
def sum_brute_force(N):
    res = 0
    for i in range(1,N+1):
        res+=i
    return res

# Using brute force
bf_start_time = time.time()
bf_result = sum_brute_force(1000000)
bf_end_time = time.time()
print("Time using brute force: {} sec".format(bf_end_time - bf_start_time))
```

더 효율적인 또 다른 방법은 공식을 사용하여 계산하는 것입니다. 1부터 N까지의 모든 정수(integer number)의 합을 계산하려면, N에 N+1을 곱한 다음 2로 나누면 원하는 결과를 얻을 수 있습니다. 이 문제는 실제로 19세기 독일의 일부 학생들에게 주어졌으며, 칼 프리드리히 가우스(Carl-Friedrich Gauss)라는 영리한 학생이 이 공식을 고안하여 문제를 몇 초 만에 해결했습니다.

```python
def sum_formula(N):
    return N*(N+1)/2

# Using the formula
formula_start_time = time.time()
formula_result = sum_formula(1000000)
formula_end_time = time.time()
print("Time using the formula: {} sec".format(formula_end_time - formula_start_time))
```

두 가지 방법을 모두 실행한 후, 우리는 160,000%가 넘는 엄청난 개선을 달성했으며, 이는 간단한 작업에도 효율적이고 최적화된 코드(optimized code)가 필요한 이유를 명확히 보여줍니다.

### 2. .iloc[ ] 및 .loc[ ]를 사용하여 행과 열을 효율적으로 선택하기

이 하위 섹션에서는 pandas의 .iloc[] 및 .loc[] 함수를 사용하여 데이터프레임(DataFrame)에서 행을 효율적으로 찾고 선택하는 방법을 소개할 것입니다. iloc[]는 인덱스 번호 로케이터(index number locator)로, loc[]는 인덱스 이름 로케이터(index name locator)로 사용할 것입니다.

이 두 함수는 데이터프레임에서 데이터를 선택하는 데 필수적이지만, 사용 방식과 성능 특성에서 차이가 있습니다. `.loc[]`는 라벨 기반 인덱싱(label-based indexing)을, `.iloc[]`는 정수 위치 기반 인덱싱(integer-position-based indexing)을 사용합니다. 특정 조건에 맞는 데이터를 필터링하거나, 특정 행/열에 접근해야 할 때 이들을 효율적으로 사용하는 방법을 알아보겠습니다.

가상의 고객 데이터프레임을 생성하여 다양한 선택 방법을 시연해 보겠습니다.

```python
import pandas as pd
import numpy as np

# 가상 고객 데이터프레임 생성
np.random.seed(42) # 재현성을 위한 시드 설정
data = {
    'Customer_ID': range(101, 111),
    'Name': ['김철수', '이영희', '박민준', '최지우', '정현우', '한소희', '강동원', '송혜교', '윤아', '이준기'],
    'Age': np.random.randint(20, 60, 10),
    'City': ['서울', '부산', '대구', '서울', '인천', '부산', '대전', '서울', '광주', '울산'],
    'Gender': np.random.choice(['남', '여'], 10),
    'Purchase_Amount': np.random.randint(10000, 100000, 10)
}
customers_df = pd.DataFrame(data)
customers_df.set_index('Customer_ID', inplace=True) # Customer_ID를 인덱스로 설정

print("원본 고객 데이터프레임:")
print(customers_df)
print("\n")

# .loc[]를 사용한 선택 예시:
# 1. 특정 인덱스 라벨을 사용하여 행 선택 (예: Customer_ID 103)
print("loc[]: Customer_ID 103의 정보:")
print(customers_df.loc[103])
print("\n")

# 2. 인덱스 라벨 범위로 행 선택 (예: Customer_ID 101부터 105까지)
print("loc[]: Customer_ID 101부터 105까지의 고객 정보:")
print(customers_df.loc[101:105])
print("\n")

# 3. 조건부 선택 (예: 서울에 거주하는 30세 이상 고객)
print("loc[]: 서울에 거주하는 30세 이상 고객:")
print(customers_df.loc[(customers_df['City'] == '서울') & (customers_df['Age'] >= 30)])
print("\n")

# 4. 특정 행과 열 라벨 선택 (예: Customer_ID 102의 Name과 Purchase_Amount)
print("loc[]: Customer_ID 102의 이름과 구매 금액:")
print(customers_df.loc[102, ['Name', 'Purchase_Amount']])
print("\n")

# .iloc[]를 사용한 선택 예시:
# 1. 정수 위치를 사용하여 행 선택 (예: 첫 번째 행)
print("iloc[]: 첫 번째 고객의 정보:")
print(customers_df.iloc[0])
print("\n")

# 2. 정수 위치 범위로 행 선택 (예: 첫 3개 행)
print("iloc[]: 첫 3개 고객의 정보:")
print(customers_df.iloc[:3])
print("\n")

# 3. 특정 행과 열의 정수 위치 선택 (예: 첫 2개 행의 첫 3개 열)
print("iloc[]: 첫 2개 행의 Name, Age, City 열:")
print(customers_df.iloc[:2, :3])
print("\n")

# .at[] 및 .iat[]를 사용한 단일 값 접근:
# .at[]는 라벨 기반, .iat[]는 정수 위치 기반으로 단일 셀에 가장 빠르게 접근할 수 있습니다.
# 이는 특히 대규모 데이터프레임에서 단일 값을 조회하거나 수정할 때 성능 이점을 제공합니다.

# .at[] 예시 (Customer_ID 104의 City)
print(".at[]: Customer_ID 104의 거주 도시:")
print(customers_df.at[104, 'City'])
customers_df.at[104, 'City'] = '수원' # 단일 값 수정
print(".at[]를 사용하여 Customer_ID 104의 도시를 '수원'으로 변경 후:")
print(customers_df.loc[104, 'City'])
print("\n")

# .iat[] 예시 (인덱스 5번째 행, 3번째 열 (Gender))
print(".iat[]: 인덱스 위치 5 (여섯 번째) 행, 열 위치 3 (Gender)의 값:")
print(customers_df.iat[5, 3])
customers_df.iat[5, 3] = '남' # 단일 값 수정
print(".iat[]를 사용하여 해당 값을 '남'으로 변경 후:")
print(customers_df.iloc[5, 3])
print("\n")

print("성능 팁: `.loc[]`와 `.iloc[]`는 각각 라벨 기반과 위치 기반의 유연한 데이터 선택을 제공합니다. 대규모 데이터에서 조건부 필터링이나 슬라이싱을 할 때 유용합니다. 반면, 단일 셀에 대한 접근이나 수정이 빈번하다면 `.at[]`나 `.iat[]`를 사용하는 것이 훨씬 빠릅니다. 이들은 내부적으로 오버헤드가 적어 직접적인 메모리 접근과 유사한 속도를 제공하기 때문입니다.")

아래 예시에서는 포커 데이터셋(dataset)의 첫 500개 행을 선택할 것입니다. 먼저 .loc[] 함수를 사용하고, 그 다음 .iloc[] 함수를 사용할 것입니다.

```python
# Specify the range of rows to select
rows = range(0, 500)

# Time selecting rows using .loc[]
loc_start_time = time.time()
poker_data.loc[rows]
loc_end_time = time.time()
print("Time using .loc[] : {} sec".format(loc_end_time - loc_start_time))

# Specify the range of rows to select
rows = range(0, 500)

# Time selecting rows using .iloc[]
iloc_start_time = time.time()
poker_data.iloc[rows]
iloc_end_time = time.time()
print("Time using .iloc[]: {} sec".format(iloc_end_time - iloc_start_time))

loc_comp_time = loc_end_time - loc_start_time
iloc_comp_time = iloc_end_time - iloc_start_time
print("Difference in time: {} %".format((loc_comp_time - iloc_comp_time)/ iloc_comp_time*100))
```

이 두 방법은 구문(syntax)이 동일하지만, iloc[]는 loc[]보다 거의 70% 더 빠르게 작동합니다. .iloc[] 함수는 이미 정렬된 인덱스(index)의 순서를 활용하므로 더 빠릅니다.

행뿐만 아니라 열을 선택하는 데에도 사용할 수 있습니다. 다음 예시에서는 두 가지 방법을 모두 사용하여 처음 세 개의 열을 선택할 것입니다.

```python
iloc_start_time = time.time()
poker_data.iloc[:,:3]
iloc_end_time = time.time()
print("Time using .iloc[]: {} sec".format(iloc_end_time - iloc_start_time))

names_start_time = time.time()
poker_data[['S1', 'R1', 'S2']]
names_end_time = time.time()
print("Time using selection by name: {} sec".format(names_end_time - names_start_time))

loc_comp_time = names_end_time - names_start_time
iloc_comp_time = iloc_end_time - iloc_start_time
print("Difference in time: {} %".format((loc_comp_time - iloc_comp_time)/ loc_comp_time*100))
```

iloc[]를 사용한 열 인덱싱(column indexing)이 여전히 80% 더 빠르다는 것을 알 수 있습니다. 따라서 특정 열을 이름으로 선택하기 위해 loc[]를 사용하는 것이 더 쉽지 않은 한, 더 빠른 iloc[]를 사용하는 것이 좋습니다.

### 3. DataFrame에서 값을 효과적으로 교체하기

DataFrame에서 값을 교체하는 것은 매우 중요한 작업이며, 특히 데이터 정제(data cleaning) 단계에서는 동일한 객체를 나타내는 모든 값을 유지해야 하므로 더욱 그렇습니다.

데이터 정제 과정에서는 오타, 비표준화된 표현, 결측치(missing values) 등 다양한 문제에 직면합니다. pandas의 `replace()` 함수는 이러한 문제를 해결하는 데 강력하고 효율적인 도구입니다. 또한, `map()`이나 `apply()`와 같은 다른 함수들도 특정 상황에서 값 교체에 유용하게 사용될 수 있습니다.

가상의 제품 재고 데이터프레임을 통해 다양한 값 교체 시나리오를 살펴보겠습니다.

```python
import pandas as pd
import numpy as np
import time

# 가상 제품 재고 데이터프레임 생성
products_data = {
    'Product_ID': range(201, 211),
    'Item_Name': ['Laptop', 'Mouse', 'Keyboard', 'Monitor', 'Laptop', 'Webcam', 'Mouse', 'Printer', 'Keyboard', 'Laptop'],
    'Stock_Status': ['In Stock', 'Out of stock', 'in stock', 'InStock', 'Damaged', 'Returned', 'out of stock', 'Available', 'in-stock', np.nan],
    'Price': [1200, 25, 75, 300, 1150, 50, 20, 250, 70, 1100],
    'Category': ['Electronics', 'Accessory', 'Accessory', 'Electronics', 'Electronics', 'Accessory', 'Accessory', 'Electronics', 'Accessory', 'Electronics']
}
products_df = pd.DataFrame(products_data)

print("원본 제품 데이터프레임:")
print(products_df)
print("\n")

# 1. replace() 함수를 사용하여 여러 값 교체 (리스트 대 단일 값 매핑)
# 'Stock_Status' 열의 다양한 재고 상태 표현을 'AVAILABLE' 또는 'UNAVAILABLE'로 표준화
# (대소문자 및 띄어쓰기 차이 처리)
print("replace()를 사용한 Stock_Status 표준화:")
replace_start_time = time.time()
products_df['Stock_Status_Standardized'] = products_df['Stock_Status'].replace(
    ['In Stock', 'in stock', 'InStock', 'in-stock', 'Available'], 'AVAILABLE'
).replace(
    ['Out of stock', 'out of stock', 'Damaged', 'Returned', np.nan], 'UNAVAILABLE'
)
replace_end_time = time.time()
print(f"  - replace() 연산 시간: {replace_end_time - replace_start_time:.6f} 초")
print(products_df[['Stock_Status', 'Stock_Status_Standardized']])
print("\n")

# 2. replace() 함수와 정규 표현식(regex=True)을 사용하여 패턴 교체
# 'Item_Name' 열의 'Mouse'를 'Computer Mouse'로, 'Keyboard'를 'Computer Keyboard'로 교체
print("replace()와 정규 표현식을 사용한 Item_Name 교체:")
regex_replace_start_time = time.time()
products_df['Item_Name_Regex'] = products_df['Item_Name'].replace(
    {r'(?i)mouse': 'Computer Mouse', r'(?i)keyboard': 'Computer Keyboard'}, regex=True
)
regex_replace_end_time = time.time()
print(f"  - replace(regex=True) 연산 시간: {regex_replace_end_time - regex_replace_start_time:.6f} 초")
print(products_df[['Item_Name', 'Item_Name_Regex']])
print("\n")
print("팁: `regex=True`를 사용하면 복잡한 패턴 매칭 및 교체가 가능하여, 다양한 오타나 비표준화된 문자열을 효과적으로 처리할 수 있습니다. 이는 특히 텍스트 데이터 정제에 유용합니다.")
print("\n")

# 3. map() 함수를 사용한 값 교체 (딕셔너리 매핑)
# 'Category' 열을 한국어로 변환
category_mapping = {
    'Electronics': '전자기기',
    'Accessory': '액세서리'
}
print("map()을 사용한 Category 한국어 변환:")
map_start_time = time.time()
products_df['Category_KR'] = products_df['Category'].map(category_mapping)
map_end_time = time.time()
print(f"  - map() 연산 시간: {map_end_time - map_start_time:.6f} 초")
print(products_df[['Category', 'Category_KR']])
print("\n")
print("map()은 Series의 각 요소에 대해 딕셔너리 매핑을 적용하여 값을 교체합니다. 딕셔너리에 없는 키는 기본적으로 `NaN`으로 처리되므로, 원본 값을 유지하려면 `.fillna()`를 함께 사용하는 것이 일반적입니다. `replace()`가 특정 값들을 다른 값들로 대체하는 데 특화되어 있다면, `map()`은 Series의 모든 값을 딕셔너리에 따라 일대일로 변환하는 데 유용합니다.")
print("\n")

# 4. apply() 함수를 사용한 복잡한 값 교체 또는 파생 변수 생성
# 'Price'에 따라 'High', 'Medium', 'Low' 카테고리 생성
print("apply()를 사용한 Price 카테고리 생성:")
apply_start_time = time.time()
products_df['Price_Level'] = products_df['Price'].apply(
    lambda x: 'High' if x >= 1000 else ('Medium' if x >= 100 else 'Low')
)
apply_end_time = time.time()
print(f"  - apply() 연산 시간: {apply_end_time - apply_start_time:.6f} 초")
print(products_df[['Price', 'Price_Level']])
print("\n")
print("apply()는 Series 또는 DataFrame의 행/열에 사용자 정의 함수를 적용할 때 매우 유연합니다. 이는 `replace()`나 `map()`으로는 처리하기 어려운 복잡한 조건부 로직이나 여러 열을 참조해야 하는 변환에 적합합니다. 하지만 일반적으로 `replace()`나 `map()`보다 성능은 떨어질 수 있으므로, 가능한 경우 내장 함수를 우선적으로 고려하는 것이 좋습니다.")

이전에 로드했던 인기 아기 이름 데이터셋을 살펴보겠습니다: Gender(성별) 특성(feature)을 자세히 살펴보고 고유한 값(unique values)을 확인해 봅시다:

```python
names['Gender'].unique()
```

여성 성별이 대문자와 소문자 두 가지 값으로 표현되어 있음을 알 수 있습니다. 이는 실제 데이터에서 매우 흔한 일이며, 이를 해결하는 쉬운 방법은 전체 데이터셋에서 일관성을 유지하기 위해 한 값을 다른 값으로 교체하는 것입니다. 이를 수행하는 두 가지 방법이 있습니다. 첫 번째는 단순히 교체하려는 값을 정의한 다음, 무엇으로 교체할지 정의하는 것입니다. 이는 아래 코드에 나와 있습니다:

```python
start_time = time.time()
names['Gender'].loc[names.Gender=='female'] = 'FEMALE'
end_time = time.time()
pandas_time = end_time - start_time
print("Replace values using .loc[]: {} sec".format(pandas_time))
```

두 번째 방법은 아래 코드에 나와 있는 것처럼 pandas의 내장 함수인 .replace()를 사용하는 것입니다:

```python
start_time = time.time()
names['Gender'].replace('female', 'FEMALE', inplace=True)
end_time = time.time()
replace_time = end_time - start_time
print("Time using replace(): {} sec".format(replace_time))
```

내장 함수를 사용하면 시간 복잡도(time complexity)에 차이가 있으며, .loc() 메서드를 사용하여 값의 행과 열 인덱스를 찾아 교체하는 것보다 157% 더 빠르다는 것을 알 수 있습니다.

```python
print('The differnce: {} %'.format((pandas_time- replace_time )/replace_time*100))
```

리스트를 사용하여 여러 값을 교체할 수도 있습니다. 우리의 목표는 WHITE NON-HISPANIC 또는 WHITE NON-HISP로 분류된 모든 민족을 WNH로 변경하는 것입니다. .loc[] 함수를 사용하여, 'or' 문(파이썬에서는 파이프(|)로 상징됨)을 이용하여 우리가 찾고 있는 민족의 아기들을 찾을 것입니다. 그런 다음 새 값을 할당할 것입니다. 항상 그렇듯이, 이 연산에 필요한 CPU 시간도 측정합니다.

```python
start_time = time.time()
names['Ethnicity'].loc[(names["Ethnicity"] == 'WHITE NON HISPANIC') | (names["Ethnicity"] == 'WHITE NON HISP')] = 'WNH'
end_time = time.time()
pandas_time= end_time - start_time
print("Results from the above operation calculated in %s seconds" %(pandas_time))
```

다음과 같이 .replace() pandas 내장 함수를 사용하여 동일한 연산을 수행할 수도 있습니다:

```python
start_time = time.time()
names['Ethnicity'].replace(['WHITE NON HISPANIC','WHITE NON HISP'], 'WNH', inplace=True)
end_time = time.time()
replace_time = end_time - start_time
print("Time using .replace(): {} sec".format(replace_time))
```

다시 한번 .replace() 메서드를 사용하는 것이 .loc[] 메서드를 사용하는 것보다 훨씬 빠르다는 것을 알 수 있습니다. 얼마나 빠른지 더 잘 이해하기 위해 아래 코드를 실행해 봅시다:

```python
print('The differnce: {} %'.format((pandas_time- replace_time )/replace_time*100))
```

.replace() 메서드는 .loc[] 메서드를 사용하는 것보다 87% 더 빠릅니다. 데이터가 방대하고 많은 정제가 필요한 경우, 이 팁은 데이터 정제(data cleaning)의 계산 시간을 줄이고 pandas 코드를 훨씬 더 빠르고 효율적으로 만들 것입니다.

마지막으로, 딕셔너리(dictionary)를 사용하여 DataFrame에서 단일 값과 여러 값을 모두 교체할 수도 있습니다. 하나의 명령으로 여러 함수를 교체하고 싶을 때 매우 유용할 것입니다. 딕셔너리를 사용하여 모든 남성 성별을 BOY로, 모든 여성 성별을 GIRL로 교체할 것입니다.

```python
names = pd.read_csv('Popular_Baby_Names.csv')
start_time = time.time()
names['Gender'].replace({'MALE':'BOY', 'FEMALE':'GIRL', 'female': 'girl'}, inplace=True)
end_time = time.time()
dict_time = end_time - start_time
print("Time using .replace() with dictionary: {} sec".format(dict_time))

names = pd.read_csv('Popular_Baby_Names.csv')
start_time = time.time()
names['Gender'].replace('MALE', 'BOY', inplace=True)
names['Gender'].replace('FEMALE', 'GIRL', inplace=True)
names['Gender'].replace('female', 'girl', inplace=True)
end_time = time.time()
list_time = end_time - start_time
print("Time using multiple .replace(): {} sec".format(list_time))

print('The differnce: {} %'.format((list_time- dict_time )/dict_time*100))
```

리스트로도 같은 작업을 할 수 있지만, 더 장황합니다. 두 가지 방법을 비교하면 딕셔너리가 약 22% 더 빠르게 실행된다는 것을 알 수 있습니다. 일반적으로 파이썬에서 딕셔너리를 사용하는 것은 리스트에 비해 매우 효율적입니다. 리스트를 탐색하는 것은 리스트의 모든 요소를 통과해야 하는 반면, 딕셔너리를 탐색하는 것은 항목과 일치하는 키(key)로 즉시 이동합니다. 하지만 두 구조는 목적이 다르기 때문에 비교가 다소 불공평합니다.

딕셔너리를 사용하면 여러 다른 열에서 동일한 값을 교체할 수 있습니다. 이전의 모든 예시에서는 교체할 값이 있는 열을 지정했습니다. 이제 동일한 열의 여러 값을 하나의 공통 값으로 교체할 것입니다. 모든 민족을 흑인(Black), 아시아인(Asian), 백인(White)의 세 가지 큰 범주로 분류하고자 합니다. 구문은 다시 한번 매우 간단합니다. 여기서는 중첩 딕셔너리(nested dictionary)를 사용합니다. 외부 키(outer key)는 값을 교체하려는 열입니다. 이 외부 키의 값은 또 다른 딕셔너리이며, 여기서 키는 교체할 민족이고 값은 새로운 민족(흑인, 아시아인 또는 백인)입니다.

```python
start_time = time.time()
names.replace({'Ethnicity': {'ASIAN AND PACI': 'ASIAN', 'ASIAN AND PACIFIC ISLANDER': 'ASIAN',
                             'BLACK NON HISPANIC': 'BLACK', 'BLACK NON HISP': 'BLACK',
                             'WHITE NON HISPANIC': 'WHITE', 'WHITE NON HISP': 'WHITE'}})
print("Time using .replace() with dictionary: {} sec".format (time.time() - start_time))
```

`inplace=True` 인수를 사용하는 것은 편리하지만, 이로 인해 원본 DataFrame이 직접 수정되어 데이터 손실의 위험이 있고, Chained Assignment Warning (연쇄 할당 경고)을 유발할 수 있습니다. 따라서 일반적으로는 새로운 Series나 DataFrame을 반환받아 사용하는 것이 더 안전하고 권장되는 방법입니다.

### 4. 값 선택 및 교체를 위한 모범 사례 요약

*   .iloc[] 함수를 사용하면 행과 열을 선택하는 것이 더 빠릅니다. 따라서 .loc[]를 사용하는 것이 더 쉽거나 편리하고, 속도가 우선순위가 아니거나, 한 번만 수행하는 경우가 아니라면 .iloc[]를 사용하는 것이 좋습니다.
*   내장 replace() 함수를 사용하는 것이 기존 방법을 사용하는 것보다 훨씬 빠릅니다.
*   파이썬 딕셔너리를 사용하여 여러 값을 교체하는 것이 리스트를 사용하는 것보다 빠릅니다.
*   `.at[]` 및 `.iat[]`는 DataFrame에서 단일 값을 매우 빠르게 접근하고 수정할 수 있는 효율적인 도구입니다.
*   복잡한 조건부 로직이나 여러 열을 참조해야 하는 값 교체에는 `apply()` 함수가 유연성을 제공하지만, 단순한 일대일 또는 다대일 매핑에는 `replace()`나 `map()`이 더 효율적입니다. 상황에 맞는 적절한 함수를 선택하는 것이 중요합니다.
*   코드의 가독성(readability)과 유지보수성(maintainability) 또한 효율성만큼 중요합니다. 극단적인 성능 최적화가 필요하지 않다면, 명확하고 이해하기 쉬운 코드를 작성하는 것을 우선적으로 고려해야 합니다.

이 뉴스레터(newsletter)는 개인적인 열정 프로젝트이며, 여러분의 지원이 이를 유지하는 데 도움이 됩니다. 기여하고 싶다면 몇 가지 좋은 방법이 있습니다:

*   **구독(Subscribe)**하세요. 유료 구독은 제 글쓰기를 지속 가능하게 하고 추가 콘텐츠에 대한 접근 권한을 제공합니다.
*   제 책 **번들(Bundle)**을 구매하세요. 제 실용적인 책 7권과 로드맵을 단 40% 가격으로 만나보세요.

읽어주셔서 감사하며, 독립적인 글쓰기와 연구를 지원해 주셔서 감사합니다!