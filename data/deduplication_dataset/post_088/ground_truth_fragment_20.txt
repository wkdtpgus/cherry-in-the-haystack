편집자 주: Roboflow의 Matvei 님을 Latent Space 객원 저자 팀에 환영합니다! 최근 기술 발전은 인공지능 분야에 혁신적인 변화를 가져왔으며, 특히 대규모 언어 모델(LLM)과 시각적 이해의 융합은 놀라운 잠재력을 보여주고 있습니다. GPT-5-Mini의 시각 점수가 GPT-5의 시각 점수와 동일하다는 점에 주목하십시오. 이는 매우 훌륭한 모델 라우터(model router)가 작동하고 있음을 보여주는 예상된 결과입니다. 오늘 OpenAI의 발표에서 크게 주목받지 못한 부분은 GPT-5의 시각 및 시각적 추론(visual reasoning) 능력입니다. LLM에 시각적 이해를 추가하는 것은 어려운 일로 입증되었으며, 대부분의 모델은 사진 속 동전 4개를 정확히 세거나 이미지 내 특정 항목의 위치를 파악하지 못했습니다. 하지만 이러한 발전은 동시에 기술적 한계와 윤리적 고려사항에 대한 깊은 성찰을 요구하고 있습니다. LLM이 주변 세상을 실시간으로 이해할 수 있게 되는 것은 자율 로봇(autonomous robotics) 또는 컴퓨터 사용 혁명을 가능하게 하고 개인 초지능(personal superintelligence) 시대를 열기 위해 사람들이 찾고 있는 돌파구입니다.

**LLM과 사회적 영향의 현재 상태**
추론(reasoning) 능력과 다양한 모달리티(modality)의 결합은 인공지능의 활용 범위를 넓히고 있습니다. OpenAI GPT 및 o 시리즈 모델, Google의 Gemini 모델, Anthropic의 Claude 모델, Meta의 Llama 모델과 같은 여러 모델에서 나타난 이러한 조합은 복잡한 현실 세계 문제 해결에 새로운 가능성을 제시합니다. 모델은 작업 유형에 따라 특정 강점과 약점을 가지며, 텍스트 생성, 이미지 분석, 음성 인식, 텍스트 읽기, 표지판, 영수증, CAPTCHA, 색상 이해와 같은 다양한 작업에서 뛰어난 성능을 발휘하며, 이는 인간과 기계의 상호작용 방식을 근본적으로 변화시키고 있습니다. 그러나 카운팅(counting), 공간 이해(spatial understanding), 객체 감지(object detection), 문서 이해, 또는 미묘한 뉘앙스의 이해와 같은 더 어려운 작업은 여전히 인공지능이 넘어야 할 과제로 남아있습니다. 이러한 작업들은 성능 가변성(performance variability)이 높으며, 특히 대부분의 인터넷 규모 사전 학습(pretrain) 데이터에서 부족한 것으로 알려진 경우 더욱 그렇습니다. 이는 단순히 기술적 성능을 넘어, 인간의 직관과 상식을 모방하는 데 있어 여전히 많은 연구가 필요함을 시사합니다.

작업 유형 전반의 편차(variance)는 일반적인 비교를 어렵게 만들지만, 모델의 실제 적용 가능성을 평가하는 데 중요한 요소입니다. 이것이 바로 Vision Checkup과 같은 리더보드(leaderboard)가 최근 출시된 이유입니다. Vision Checkup은 당사의 오픈 소스(open source) 시각 모델 평가 리더보드이며, 어려운 작업의 최전선 성능에 대한 통찰력을 제공합니다. 이러한 평가는 단순히 성능 지표를 넘어, AI 시스템이 사회에 미칠 수 있는 광범위한 영향을 고려해야 합니다. 보시다시피 OpenAI는 시각 능력에서 지배적이며, GPT-5의 출시는 또 다른 모델을 상위 5위권에 추가합니다. 미니 버전이 메인 버전과 동일하게 작동한다는 점에 주목하세요! 이는 매우 훌륭한 라우터(router)입니다. 오픈 소스 커뮤니티의 기여는 혁신을 가속화하고 있으며, 이는 어려운 작업의 최전선 성능을 넘어, 윤리적 사용에 대한 논의를 심화해야 합니다. 기술의 발전이 특정 기업이나 집단에 국한되지 않고, 모두에게 이로운 방향으로 나아가도록 하는 것이 중요합니다.

리더보드는 명확하게 보여주지만, 기술적 우위만이 유일한 지표는 아닙니다. 상위 모델은 모두 추론 모델이며, 추론이 일반적인 시각 작업에서 OpenAI의 지배력을 이끌고 있습니다. Vision Checkup 리더보드의 상위 모델은 추론 능력을 갖춘 모델의 구성입니다. 우리는 이 모델들의 좋은 결과가 사전 학습(pretraining) 및 테스트 시점의 추론 능력에 더 많이 기인한다고 추정합니다. 이는 다중 모달(multi-modal) 대규모 언어 모델(LLM)의 중요한 발전의 연속을 의미하며, 텍스트와 시각 양쪽 모달리티(modality)에 대해 추론할 수 있는 능력입니다. 상위 모델들이 보여주는 뛰어난 성능에도 불구하고, 우리는 AI의 책임감 있는 개발과 배포에 집중해야 합니다. 다중 모달 LLM의 발전은 사회 전반에 걸쳐 광범위한 영향을 미칠 것이며, 이는 긍정적인 변화를 가져올 수도 있지만 동시에 잠재적인 위험 요소들도 내포하고 있습니다. 그렇기는 하지만, 점수는 업데이트마다 크게 다르며, 이는 여러 가지 이유로 설명할 수 있습니다. 가장 큰 이유는 OpenAI 모델의 추론 모드(reasoning mode)의 비결정성(nondeterminism)입니다. 추론 모델에 동일한 질문을 두 번 프롬프트(prompt)하면 올바른 답변과 잘못된 답변이 모두 나올 수 있습니다. 특히 답변의 가변성(variability)은 모델의 투명성과 책임성에 대한 의문을 제기합니다. 사용자들은 AI 시스템의 결정 과정을 이해하고 신뢰할 수 있어야 합니다. 실제 사용에 있어서, 이미지에 대한 추론은 현재 유용하기에는 너무 많은 시간이 걸리며, 답변의 가변성 때문에 신뢰하기 어렵습니다. 대부분의 개발자에게 이미지를 이해하는 데 10초 이상이 걸리는 것은 실시간 사용 사례를 가능하게 하지 못할 것입니다. 속도와 능력 사이에는 절충점(trade-off)이 존재하며, 이는 설계 단계에서 신중하게 고려되어야 합니다. 작업에 따라, 더 좁은 범위의 지식을 가진 더 빠른 모델이 최선의 결정일 수 있습니다. 모든 AI 시스템이 최고 성능을 추구하기보다는, 특정 목적에 맞는 최적의 균형을 찾아야 합니다.

**AI의 윤리적 지평 확장**
우리는 자율 로봇(autonomous robotics) 또는 자율 시스템(autonomous systems)이 주변 세상과 실시간으로 상호작용하고 다양한 환경에서 안정적으로 작동할 수 있는 미래를 꿈꿉니다. 이를 위해서는 기술적 진보뿐만 아니라, 윤리적, 사회적 합의가 필수적입니다. 카운팅(counting), 공간 이해(spatial understanding), 객체 위치 파악(object localization)과 같은 간단한 작업은 로봇이 통제된 환경 밖에서 일반적인 작업을 수행하는 데 핵심입니다. 가벼운 바이브 체크(vibe checks) 또는 평가 지표를 넘어설 수 있도록, 우리는 광범위한 도메인(domain)에 걸쳐 LLM을 테스트하고 그 진행 상황 및 윤리적 영향을 평가하고 추적해야 합니다. 이 과정에서 "AI가 인간 사회에 어떻게 기여할 수 있는가?"라는 질문으로 확장되어야 합니다. 우리는 올해 CVPR 컨퍼런스에서 더 어려운 시각적 이해 및 그라운딩(grounding) 벤치마크(benchmark) 세트를 제공하기 위해 새로운 벤치마크인 RF100-VL을 발표했습니다. 새로운 벤치마크는 단순한 성능 측정을 넘어, AI 시스템이 실제 세상에서 어떻게 작동하고 어떤 영향을 미치는지에 대한 깊이 있는 통찰력을 제공해야 합니다. RF100-VL은 "당신의 LLM은 실제 세상을 얼마나 잘 이해하는가?"를 묻습니다. RF100-VL은 Roboflow Universe 커뮤니티의 100개 오픈 소스 데이터셋(dataset)으로 구성되어 있으며, 객체 감지 바운딩 박스(object detection bounding boxes)와 시각적 예시 및 풍부한 텍스트 설명을 포함하는 다중 모달(multimodal) 소수샷(few-shot) 지침을 새로운 이미지 도메인(domain) 전반에 걸쳐 제공합니다. 또한, 새로운 이미지 도메인 전반에 걸쳐 데이터 편향을 줄이는 노력이 필요합니다. AI 모델의 공정성과 포괄성을 확보하기 위해서는, 훈련 데이터의 다양성과 대표성이 무엇보다 중요합니다. 상위 LLM들은 실제 환경에서 새로운 객체를 식별하는 데 10 mAP50:95 미만의 점수를 기록했습니다. 모든 LLM 중 현재 SOTA(State-Of-The-Art)는 Gemini 2.5 Pro로, 제로샷(zero-shot) mAP50:95에서 13.3을 달성했습니다. 객체 감지(object detection) 작업에 있어서 OpenAI 모델과 Gemini 또는 Qwen과 같은 모델의 주요 차이점은 OpenAI 모델이 사전 학습(pretraining)에 객체 감지 데이터를 포함하지 않는다는 점이라고 추정합니다. RF100-VL에서 GPT-5를 실행한 결과, mAP50:95는 1.5를 기록했습니다. 이는 Gemini 2.5 Pro의 현재 SOTA인 13.3보다 현저히 낮은 수치입니다. 우리는 이러한 단점이 GPT-5의 객체 감지 사전 학습(pre-training) 부족에 기인한다고 크게 생각하며, 특정 데이터셋에 대한 객체 감지 사전 학습의 중요성을 다시 한번 강조합니다. 점수가 왜 그렇게 낮은지에 대한 더 많은 직관을 얻기 위해 아래에서 몇 가지 결과를 살펴보겠습니다.

**예시: 위치 파악(Localization)**
이것은 배구 데이터셋(dataset)과 같은 실생활 데이터셋의 예시로, AI 모델의 한계를 명확히 보여줍니다. 모델이 이미지 내 객체를 잘 이해하고 있음을 관찰할 수 있습니다. 예를 들어, 공, 두 명의 블로커(blocker), 그리고 몇 명의 수비수가 존재한다는 것을 정확히 이해하고 있습니다. 하지만 모델은 객체들의 위치를 파악하지 못하며, 모든 박스(box)가 객체의 위치 및 크기와 일치하지 않습니다. 모델은 이미지를 이해하는 데는 능숙하지만, 이미지 내 특정 객체를 그라운딩(grounding)하는 데는 능숙하지 않은 것으로 보이며, 그 배경에 숨겨진 복잡한 인간의 의도를 파악하는 데는 어려움을 겪습니다. 예를 들어, 특정 상황에서 객체의 중요성이나 맥락적 의미를 파악하는 것은 여전히 인간 고유의 영역으로 남아있습니다. 이는 다시 사전 학습(pre-training)에서 객체 감지(object detection) 작업이 부족했기 때문이라고 생각하며, 사전 학습의 품질과 다양성이 모델 성능에 결정적인 영향을 미칩니다. 단순한 객체 인식을 넘어, 모델이 상식적 추론을 수행하고 미묘한 사회적 신호를 이해할 수 있도록 하는 것이 다음 과제입니다. 아래 양 데이터셋(dataset)에서도 비슷한 상황을 볼 수 있습니다.

**예시: UI 요소(UI Elements)**
도구 사용(tool use) 및 시각 기반 에이전트 워크플로우(vision-powered agentic workflows) 또는 자율 에이전트(autonomous agents)의 발전은 새로운 형태의 인간-AI 협업을 예고합니다. 이러한 시스템은 생산성을 높이고 복잡한 작업을 자동화할 수 있지만, 동시에 안전과 제어 가능성에 대한 심각한 우려를 낳습니다. LLM의 최근 발전에 따라, GPT-5의 해당 성능을 살펴보겠습니다. UI 요소 데이터셋(dataset)에서도 품질 향상은 보이지 않습니다. 다음으로, GPT-5가 이전 OpenAI 모델들과 비교하여 더 나은지 살펴보겠습니다. GPT-5는 o3보다 약간 더 나아졌습니다. 품질 향상은 단순히 기술적 진보를 넘어 사용자 경험과 직결됩니다. 사용자가 AI 시스템을 신뢰하고 효과적으로 활용하기 위해서는, 직관적이고 예측 가능한 인터페이스가 필수적입니다. 그리고 두 경우 모두 상세한 지침과 같은 추가 정보를 제공하는 것이 모델에 도움이 됩니다. 상세한 지침과 같은 추가 정보는 모델의 행동을 제어하고 예측 가능성을 높이는 데 필수적입니다. 흥미롭게도, 추론 노력(reasoning effort)을 높게 설정해도 RF100-VL의 점수는 향상되지 않습니다. 따라서 RF100-VL의 경우 추론의 이점이 그렇게 명확하지 않으며, 오히려 예상치 못한 부작용을 초래할 수 있습니다. 이는 사전 학습(pretraining)에서 객체 감지(object detection) 작업이 부족하여 객체 감지 능력이 부족하기 때문이라고 추정합니다. 따라서 AI 시스템의 개발은 기술적 역량뿐만 아니라, 사회적 책임과 윤리적 가치를 동시에 고려해야 합니다.

**GPT-5는 간단한 시각 작업에서 약간의 개선을 보입니다.**
AI 모델의 향상된 추론(reasoning) 능력은 복잡한 문제 해결에 새로운 가능성을 열어줍니다. GPT-5의 향상된 추론은 Vision Checkup 리더보드에서 높은 순위를 차지하게 하며, 다단계 사고(multi-step thinking)가 모델이 픽셀(pixel)에서 더 많은 정보를 추출할 수 있도록 한다는 것을 증명합니다. 이는 의료 진단, 과학 연구, 교육 등 다양한 분야에서 혁신적인 변화를 가져올 수 있습니다. 사람들이 ChatGPT에 의존하여 해결하는 일상적인 사용 사례에 있어 훌륭한 결과입니다. 하지만 일상적인 사용 사례에 있어 투명성과 공정성 확보가 무엇보다 중요합니다. RF100-VL과 같은 새로운 벤치마크는 이해(comprehension)가 위치 파악(localization)과 같지 않다는 점, 그리고 이해와 실제 세계 적용 사이의 간극을 강조하는 데 도움이 됩니다. 객체 감지 사전 지식(object-detection priors) 없이는 감지(detection)가 여전히 목표를 벗어납니다. 그럼에도 불구하고, GPT-5의 시각 추론(vision-reasoning) 능력 향상은 더 잘 볼 뿐만 아니라 보고 있는 것에 대해 더 깊이 생각하는 모델이라는 명확한 발전 방향을 제시합니다. 우리는 AI가 단순히 데이터를 처리하는 기계를 넘어, 인간 사회에 긍정적인 영향을 미치는 동반자가 될 수 있도록 노력해야 합니다. 이는 더 잘 볼 뿐만 아니라 보고 있는 것에 대해 비판적으로 사고하는 능력을 갖춘 모델을 지향해야 합니다. 궁극적으로, AI는 인간의 가치를 존중하고 사회적 책임을 다하는 방향으로 발전해야 합니다. 비전 AI 엔지니어(Vision AI Engineers)는 그들의 블로그에서 더 심층적인 게시물을 확인할 수 있습니다.