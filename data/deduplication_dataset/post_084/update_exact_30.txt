**GPT-5 코덱스: AI 코딩의 새로운 지평을 열다**

이것은 GPT-5 관련 보도 중 바이브(vibes), 부트스트래핑(bootstrapping), 비전(vision), 그리고 라우터(Router)에 대한 마지막 내용입니다. 혹시 놓치셨다면, 저희는 11월 19일부터 22일까지 뉴욕에서 열리는 AI 엔지니어 코드 서밋(AI Engineer CODE Summit)으로 돌아왔습니다! 서밋은 보통 10배 이상 초과 신청되며, 가장 고품질의 콘텐츠와 참가자들이 함께합니다. 개발자 생산성과 SWE 에이전트(SWE agents)의 새로운 기능에 관심이 있다면, 지금 바로 신청하세요. 새로운 GPT-5-코덱스(GPT-5-Codex)가 오늘 출시되며, 최근 기억에 남는 코딩 에이전트(Coding Agents) 분야에서 가장 강렬했던 분위기 변화(vibe shifts)의 한 달을 마무리합니다 (클릭하여 확장): 지난 1년여 동안, 6월의 클로드 3.5 소네트(Claude 3.5 Sonnet)를 시작으로 2월의 3.7 소네트(3.7 Sonnet)와 클로드 코드(Claude Code), 그리고 5월의 클로드 4(Claude 4)에 이르기까지, Anthropic은 코딩 활용 사례(coding usecases)에서 독보적인 우위(uncontested dominance)를 누렸습니다. 이는 50억 달러의 매출(revenue) (이 중 10%는 클로드 코드(Claude Code))과 1,830억 달러의 기업 가치(valuation) 1, 그리고 1,220억 달러의 시가총액(market cap) 증가로 이어지는 엄청난 성장세(epic runup)를 가져왔습니다. 이는 OpenAI에 불을 지핀 것으로 보입니다. OpenAI는 물론 깃허브 코파일럿(GitHub Copilot)을 시작한 2021년 오리지널 코덱스(Codex)를 출시했으며, 이 코파일럿은 182명의 개발자와 계속해서 늘어나는 사용자를 가진 최초의 AI 코딩 도구(AI coding tool) 2입니다. 또한 GPT3는 모든 바이브 코딩 스타트업(vibe coding startups)의 전조가 된 디빌드(Debuild)에 영감을 주었고, 물론 o1과 GPT 4.1에서 코딩 능력(coding abilities)을 재우선순위화(reprioritize)하기 시작했습니다. GPT-5-코덱스(GPT-5-Codex)의 SWE-벤치(SWE-bench) (전체 500개) 점수 74.5%는 (악명 높게 밈으로 조롱받은) GPT-5 사고(thinking) 성능 74.9% (477개 작업 하위 집합)와 거의 비슷합니다. 그렇다면 GPT-5 인식(sentiment)에 이러한 큰 변화가 생긴 원인은 무엇일까요? 우선, 코덱스 팀이 엄청난 성과를 내고 있습니다.

최근 OpenAI의 GPT-5-코덱스(GPT-5-Codex) 출시는 AI 코딩 분야에 새로운 활력을 불어넣고 있습니다. 과거 Anthropic이 코딩 활용 사례에서 두각을 나타냈던 것과 달리, OpenAI는 그들의 선구적인 깃허브 코파일럿(GitHub Copilot)을 넘어 GPT-5를 통해 코딩 에이전트의 새로운 시대를 열고 있습니다. 개발자 생산성 향상과 복잡한 문제 해결 능력을 강조하며, GPT-5-코덱스는 이전 모델들이 넘어서기 힘들었던 난이도 높은 작업에서도 인상적인 성능을 보여주고 있습니다. 이러한 변화의 중심에는 OpenAI 코덱스 팀의 끊임없는 혁신이 자리하고 있습니다.

**요인 1: 다양한 얼굴, 하나의 에이전트(Many Faces, One Agent)**

코딩 에이전트(coding agent)는 더 이상 단순한 코드 생성 도구가 아닙니다. OpenAI는 에이전트형 소프트웨어 엔지니어(agentic software engineer)라는 비전을 실현하기 위해 다양한 인터페이스를 제공하고 있습니다. 기존의 터미널 기반 A-SWE 에이전트형 하네스(A-SWE agentic harness)인 10X를 넘어, 이제는 코덱스 CLI(Codex CLI), 웹 기반 "챗GPT 코덱스(ChatGPT Codex)" (현재 코덱스 클라우드(Codex Cloud)), IDE 확장 프로그램, 그리고 깃허브 코드 리뷰 봇(GitHub code review bot)에 이르기까지 개발자의 모든 요구 사항을 충족하는 통합된 생태계를 구축했습니다. 특히, 이들 중 가장 주목할 만한 기능 중 하나는 코드 리뷰 봇입니다.

아마도 가장 적은 홍보를 받았겠지만, @codex 코드 리뷰 봇(code review bot)은 매우 엄격한 범위 설정(tight scoping) 덕분에 가장 높은 유용성(utility)을 가질 수 있습니다: "우리는 검토해야 할 코드 양이 증가하면서 팀원들이 단순히 해야 하는 검토 작업의 양이 큰 병목 현상(bottleneck)이라는 것을 깨닫기 시작했습니다. 우리는 PR(Pull Request)을 검토하고, 구현하려던 계약(contract)과 의도(intention)에 대해 깊이 생각한 다음, 코드를 보고 그 의도가 코드와 일치하는지 검증(validate)할 수 있는 매우 고품질 시그널 코덱스 모드(high signal Codex mode)에 집중하기로 결정했습니다. 그리고 이 봇은 여러 계층을 깊이 파고들어 모든 종속성(dependencies)을 살펴보고, 계약(contract)에 대해 생각하며, 최고의 직원들이나 최고의 검토자들이 해당 PR(Pull Request)에 대해 몇 시간 동안 깊이 생각하지 않았다면 찾을 수 없었을 문제들을 실제로 제기할 수 있습니다. 우리는 이것을 OpenAI 내부에서 먼저 출시했습니다. 그것은 매우 성공적이었고, 사람들이 안전망(safety net)을 잃는다고 느꼈기 때문에 고장 났을 때 실제로 화를 냈습니다. 그리고 그것은 팀과 코덱스 팀을 포함하여 엄청나게 가속화(accelerated)시켰습니다."

이 코드 리뷰 봇은 개발자들이 놓치기 쉬운 심층적인 문제를 식별하고, 코드 품질을 향상시키는 데 크게 기여하고 있습니다. 또한, IDE 확장 프로그램은 2.5주 만에 80만 건 이상의 설치를 기록하며 개발자들의 폭발적인 관심을 입증했습니다. 이러한 다양한 인터페이스는 개발자들이 자신의 작업 환경과 워크플로우에 맞춰 GPT-5 코덱스의 강력한 기능을 활용할 수 있도록 지원하며, 에이전트가 단일 형태가 아닌 다채로운 방식으로 개발자의 조력자가 될 수 있음을 보여줍니다. 이는 단순한 도구 제공을 넘어, 개발 프로세스 전반에 걸쳐 AI가 통합되는 미래를 제시합니다.

**요인 2: 더 나은 후속 훈련 품질(Better Post-Training Qualities)**

OpenAI의 GPT-5-코덱스는 데이터셋(datasets)과 모델 아키텍처(model architecture)의 개선뿐만 아니라, 후속 훈련(post-training) 과정에서 얻은 품질 향상에 크게 의존합니다. 이는 연구와 제품 간의 긴밀한 통합을 통해 이루어지며, 특히 모델의 '가변적인 끈기(Variable Grit)', '정체에서 벗어나 반박하기(Getting out of Ruts and pushing back)', 그리고 '토큰 효율성(Token Efficiency)' 측면에서 두드러집니다.

티보 소티오(Thibault Sottiaux): "이 모델이 보여주는 것 중 하나는 훨씬 더 오랫동안 지속하고 복잡한 리팩토링(refactoring) 작업에 필요한 끈기(grit)를 실제로 발휘하는 능력입니다. 하지만 동시에 간단한 작업의 경우 훨씬 더 빠르게 반응하며 많은 생각 없이 답변할 수 있습니다. 그래서 코드에 대해 질문하고, 변경하거나 더 잘 이해해야 할 코드 조각을 찾고, 계획을 세울 수 있는 훌륭한 협력자(collaborative)와 같습니다. 하지만 동시에 일단 어떤 작업을 맡기면, 매우 오랜 시간 동안 작동할 것입니다. 내부적으로는 매우 복잡한 리팩토링(refactoring) 작업에 최대 7시간까지 작동하는 것을 보았습니다. 다른 모델에서는 이전에 그런 것을 본 적이 없습니다. 그리고 우리는 코드 품질에도 엄청나게 노력했습니다. 그리고 GPT-5를 코덱스(Codex) 내에서 사람들이 사용하는 용도에 맞춰 정말 최적화되어 있습니다. 신중하게 적용된 이러한 끈기(tenacity judiciously applied)가 GPT-5-코덱스(GPT-5-Codex)를 가장 어려운 문제에만 최적화하고 덜 똑똑한 모델(dumber models)을 위한 모델 전환기(model switcher)를 요구하는 것이 아니라, 훨씬 더 유용한 전천후 에이전트형 코딩 모델(agentic coding model)로 만듭니다 (흥미롭게도, 우리가 이전에 다루었던 챗GPT(ChatGPT)의 GPT-5 라우터(GPT-5 Router)는 사용하지 않습니다): https://x.com/swyx/status/1967651870018838765/photo/1"

이러한 '가변적인 끈기'는 모델이 복잡한 작업을 장시간 수행하면서도, 간단한 요청에는 빠르게 응답할 수 있도록 하는 유연성을 제공합니다. 이는 개발자가 모델을 다양한 난이도의 작업에 활용할 수 있게 하며, 특히 대규모 리팩토링이나 복잡한 버그 수정과 같은 고난이도 코딩 문제 해결에 탁월한 성능을 발휘합니다.

또한, GPT-5는 과거 모델들이 흔히 겪었던 '고집하는 문제(doubling down problem)', 즉 잘못된 답을 고수하려는 경향을 크게 개선했습니다. 그렉 브록먼(Greg Brockman)은 이제 모델이 자신의 오류를 인정하고, 심지어 정확한 해결책을 찾지 못했을 때도 중요한 문제점을 강조하며 합리적인 사고를 보여준다고 언급했습니다. 이는 모델의 '현실성(groundedness)'이 크게 향상되었음을 의미하며, GPT-5에서 환각(hallucination) 현상이 측정 가능하게 감소한 것과 밀접한 관련이 있습니다.

마지막으로 '토큰 효율성'은 GPT-5 코덱스의 또 다른 중요한 개선점입니다. 모델이 질문에 답하기 위해 불필요하게 많은 토큰을 사용하던 과거와 달리, 코덱스는 특정 작업에 대해 토큰 사용을 최적화하여 비용 효율성을 높이고 처리 속도를 개선했습니다. 이는 개발자가 더 큰 코드베이스를 더 효율적으로 분석하고 처리할 수 있게 함으로써 실제 프로젝트 적용 가능성을 크게 확장합니다. 이러한 설명하기 어려운 모든 품질(hard-to-articulate qualities)은 새로운 평가(evals)의 필요성으로 귀결됩니다.

**요인 3: 에이전트형 코딩(Agentic Coding)을 위한 새로운 평가(Evals)**

GPT-5 출시와 관련된 초기 반응은 종종 헤드라인과 차트 조작(chart crimes)에만 기반하여 모델의 실제 성능을 간과하는 경향이 있었습니다. 그러나 모델을 실제로 사용해본 개발자들은 이미 GPT-5의 강력한 에이전트형 코딩 능력(agentic coding abilities)을 체감하며 인식이 변화하고 있습니다. 이는 단순한 단일 턴(one-turn) 테스트나 최소한의 도구 호출(minimal-tool-call) 테스트로는 에이전트형 코딩의 진정한 가치를 측정하기 어렵기 때문입니다. 실제 오픈 소스 코드베이스(open source codebases)에서 다중 턴(multi-turn), 다단계(multi-step), 도구를 활용하여 사고하는(thinking-with-tools) 코딩 에이전트의 성능을 평가하는 새로운 방식이 필요합니다.

OpenAI는 이러한 필요성을 인식하고 실제 오픈 소스 코드베이스에 모델을 블라인드 테스트(blind test)하고 관리자(maintainers)가 성능을 평가하는 혁신적인 접근 방식을 도입했습니다. 이러한 방식은 모델이 실제 개발 환경에서 얼마나 효과적으로 작동하는지, 복잡한 프로젝트의 맥락을 이해하고 문제를 해결하는지 정확하게 측정할 수 있게 합니다. 이 블로그 게시물은 나중에 테스트 결과와 함께 업데이트될 예정입니다. 이러한 새로운 평가 방법론은 AI 코딩 에이전트의 성능을 보다 현실적으로 반영하며, 모델 개선을 위한 중요한 피드백 루프를 제공합니다.

**그렉(Greg)과 티보(Thibault)의 OpenAI 팟캐스트(Podcast) 요약**

최근 OpenAI의 그렉 브록먼(Greg Brockman)과 티보 소티오(Thibault Sottiaux)가 출연한 팟캐스트는 GPT-5와 AI의 미래에 대한 깊이 있는 통찰력을 제공했습니다. 이 대담에서는 OpenAI의 추론(reasoning) 능력 진화, 모델 학습 방식, 컴퓨트(compute) 확장, 그리고 AGI 시대의 엔지니어 역할 등 다양한 주제가 논의되었습니다.

**주요 논의점:**

*   **OpenAI의 추론 진화**: 그렉은 GPT-4 훈련 이후 모델의 추론 능력을 강화하기 위한 OpenAI의 여정을 설명했습니다. 초기에는 단순한 지시 따르기(instruction following)에서 시작했지만, 모델이 대화를 통해 복잡한 정보를 활용하고 스스로 학습하는 능력을 갖추게 되면서 "왜 이것이 AGI가 아닌가?"라는 질문에 직면하게 되었다고 합니다. 그는 강화 학습(reinforcement learning)을 통해 모델이 가설을 시험하고 피드백을 받아 신뢰성을 확보하는 방향으로 발전했다고 강조했습니다.
*   **온라인 vs 오프라인 학습**: 모델 학습이 초기에는 오프라인(offline) 사전 훈련(pre-training)에 집중되었지만, 이제는 추론(inference)을 기반으로 학습하는 온라인(online) 루프(loop)로 점차 전환되고 있다는 점이 흥미롭게 다루어졌습니다. 모델이 생성하는 토큰의 가치가 높아짐에 따라 강화 학습을 통해 더 많은 데이터를 생성하고, 이를 통해 모델이 현실과의 접촉으로 정규화되는 방식이 중요하다고 설명했습니다.
*   **컴퓨트 확장과 초임계 학습**: 그렉은 컴퓨트가 항상 병목 현상이라고 언급하며, 컴퓨트 자원이 충분하다면 모델 능력을 극대화할 수 있는 방법을 찾을 것이라고 단언했습니다. 그는 앨런 튜링(Alan Turing)의 초임계 학습(supercritical learning) 개념을 인용하며, 모델이 단순히 가르침을 받은 것뿐만 아니라 그 지식을 바탕으로 다른 모든 것을 업데이트하는 방식으로 발전할 것이라고 전망했습니다.
*   **RL의 벽시계 시간 제약**: 강화 학습(RL)이 실제 환경과 상호작용할 때 겪는 벽시계 시간(wall clock time) 제약에 대한 논의도 있었습니다. 모델은 비인간적인 특성(non-human affordances)으로 여러 복사본을 실행하여 지연 시간(latency)을 줄일 수 있지만, 실제 세계 모델링(modeling the real world)에서는 여전히 흥미로운 도전 과제라고 지적했습니다.
*   **DNA 신경망 경험**: 그렉은 ARC 연구소(ARC Institute)에서의 DNA 신경망(DNA neural networks) 연구 경험을 공유하며, 생물학적 언어(biological language)와 인간 언어(human language)가 신경망에 의해 학습되는 방식이 근본적으로 다르지 않다는 놀라운 통찰을 제시했습니다. 이는 AI가 약물 발견(drug discovery)과 같은 생물학 분야에 혁신적인 영향을 미 미칠 잠재력을 가지고 있음을 시사했습니다.
*   **GPT-5 시대 정의**: GPT-5 시대의 주력 기능은 '에이전트(agents)의 시대'로 요약될 수 있지만, 그렉은 모델의 '지능(intelligence)' 자체가 거의 설명할 수 없는 수준에 도달하고 있다고 강조했습니다. IMO(국제 수학 올림피아드) 금메달 수준의 문제 해결 능력은 모델이 위대한 지적 업적(intellectual feats)을 수행할 수 있다는 것을 입증하며, 이는 인간의 연구 속도를 엄청나게 가속화할 수 있다고 보았습니다.
*   **모델 라우팅 및 하이브리드 아키텍처**: GPT-5는 단일 모델이 아닌, 여러 모델 위에 라우터(router)를 두는 하이브리드 아키텍처(hybrid architecture)를 채택하고 있습니다. 이는 추론(reasoning)이 필요한 복잡한 작업에는 강력한 모델을, 빠른 응답이 필요한 간단한 작업에는 효율적인 모델을 사용하는 방식으로, 컴퓨트 자원을 최적화하고 사용자 경험을 향상시킵니다. 그렉은 AGI(범용 인공지능)가 단일 모델이 아닌, 다양한 강점과 약점을 가진 모델들의 동물원(menagerie of models)으로 구성될 가능성을 시사했습니다.
*   **가격 책정 및 컴퓨트 효율성**: OpenAI는 모델 가격을 지속적으로 인하해 왔으며, GPT-5 역시 공격적인 가격 책정 전략을 가지고 있습니다. 이는 기술의 접근성을 높여 AGI(범용 인공지능)가 모든 인류에게 혜택을 주도록 하려는 사명과 일치합니다. 컴퓨트 효율성 개선은 이러한 가격 인하를 가능하게 하는 핵심 요소이며, 모델 아키텍처 개선, 후처리 최적화, 훈련 방식 혁신 등 다양한 차원에서 이루어지고 있습니다.
*   **자체 개선 코딩 에이전트 및 도구 사용**: 모델이 스스로 도구(tools)를 만들고 개선하여 더 효율적으로 작동하는 자체 개선 코딩 에이전트(self-improving coding agents)의 가능성이 논의되었습니다. 모델이 새로운 도구에 빠르게 적응하도록 훈련한다면, 이는 미해결 문제를 해결하는 데 필요한 놀라운 원시 기능(primitive)이 될 수 있습니다.

**쇼 노트(Show Notes)**
그렉 브록먼(Greg Brockman)
튜링 테스트 논문(Turing Test Paper)
커널 랩스(Kernel Labs)
ARC 연구소(ARC Institute)
GPT-5 리뷰(GPT-5 Review)
GPT-OSS
도타(Dota) (OpenAI 파이브(Five))
이미지젠(ImageGen)
LM 아레나(LM Arena)
IMO 골드(IMO Gold) (국제 수학 올림피아드(International Mathematical Olympiad))
IOI 골드(IOI Gold) (국제 정보 올림피아드(International Olympiad in Informatics))
다이슨 스피어(Dyson Sphere)

**타임스탬프(Timestamps)**
[00:00:04] 서론
[00:01:04] OpenAI의 추론(Reasoning) 진화
[00:04:01] 언어 모델(Language Models)의 온라인(Online) 및 오프라인(Offline) 학습
[00:06:44] 강화 학습(Reinforcement Learning)의 샘플 효율성(Sample Efficiency) 및 인간 큐레이션(Human Curation)
[00:08:16] 컴퓨트(Compute) 확장 및 초임계 학습(Supercritical Learning)
[00:13:21] RL(강화 학습) 및 실제 상호작용에서의 벽시계 시간(Wall clock time) 제약
[00:16:34] ARC 연구소(ARC Institute) 및 DNA 신경망(DNA neural networks) 경험
[00:19:33] GPT-5 시대 정의
[00:22:46] 모델 지능 및 작업 난이도 평가
[01:25:06] GPT-5를 사용하는 개발자를 위한 실용적인 조언
[01:31:48] 모델 사양(Model Specs)
[01:37:21] RL 선호도(Preferences)의 과제 (예: try/catch)
[01:39:13] GPT-5의 모델 라우팅(Model Routing) 및 하이브리드 아키텍처(Hybrid Architectures)
[01:43:58] GPT-5 가격 책정 및 컴퓨트 효율성 개선
[01:46:04] 자체 개선 코딩 에이전트(Self-Improving Coding Agents) 및 도구 사용
[01:47:36] 어떤 아키텍처 결정이나 혁신에 대해 이야기하고 싶으십니까?
[01:49:11] 온디바이스 모델(On-Device Models) 및 로컬(Local) vs 원격 에이전트 시스템(Remote Agent Systems)
[01:51:34] OpenAI의 엔지니어링 및 LLM(대규모 언어 모델) 활용
[01:54:16] AI 최적화를 위한 코드베이스(Codebases) 및 팀 구성
[01:55:27] AGI 시대 엔지니어의 가치
[01:58:42] AI 연구의 현재 상태 및 연구소 다양성
[01:01:11] OpenAI의 우선순위 및 중점 분야
[01:03:05] 창업자를 위한 조언: 아직 늦지 않았다
[01:04:20] 미래 전망 및 마무리 생각
[01:04:33] 2045년 타임캡슐: 컴퓨트(Compute)와 풍요의 미래
[01:07:07] 2005년 타임캡슐: 더 많은 문제가 나타날 것이다

**OpenAI의 엔지니어링 및 LLM 활용의 미래**

OpenAI는 내부적으로도 LLM(대규모 언어 모델)을 활용하여 엔지니어링 프로세스를 혁신하고 있습니다. 복잡한 CUDA 커널(CUDA kernels) 최적화와 같은 핵심 알고리즘 문제부터 시스템 아키텍처 설계까지, AI는 이제 엔지니어링의 다양한 영역에 깊숙이 관여하고 있습니다. 특히, 모델의 강점과 약점을 중심으로 코드베이스(codebases)를 구축하고, 독립적인(self-contained) 단위 테스트(unit tests)와 명확한 문서(documentation)를 갖춘 모듈(modules)을 만드는 것이 중요하다고 강조합니다. 이는 AI가 효율적으로 코드를 이해하고 개선하는 데 필수적입니다.

OpenAI는 이 기술이 모든 엔지니어링 영역에서 극도로 높은 우선순위로 사용되도록 하는 데 집중하고 있습니다. 모델이 가능한 모든 영역에서 활용되도록 하는 것은 단순히 효율성을 높이는 것을 넘어, 훨씬 더 많은 일을 가능하게 하여 기술 부채(tech debt)를 해결하고 리팩토링(refactor)을 가속화하는 등 엄청난 기회(incredible opportunity)를 창출할 것입니다. 결국, AI 시대의 엔지니어의 가치는 AI를 활용하여 복잡한 문제를 해결하고 새로운 가치를 창출하는 능력에 달려있습니다.

**미래 전망 및 마무리 생각**

그렉 브록먼(Greg Brockman)은 2005년의 자신에게 "문제의 풍요(abundance of problem)가 시간이 지남에 따라 증가한다"는 메시지를 전하고 싶다고 말했습니다.

하지만 아시다시피, 제가 가장 놀랐던 한 가지는 문제의 풍요(abundance of problem)가 시간이 지남에 따라 증가한다는 것입니다. 좋습니다. 왜냐하면 저는 1999년, 2000년에 실리콘 밸리(Silicon Valley)에 대해 읽으면서 '기회를 놓쳤다. 너무 늦게 태어났다'고 느꼈던 것을 기억합니다. 매우 흔한 일이죠. 정확합니다. 그렇죠? 저는 마치 '내가 일을 할 준비가 될 때쯤에는 모든 멋진 문제들이 해결되어 있을 것이다. 남은 것이 없을 것이다'라고 느꼈습니다. 그것은 완전히 틀린 것으로 밝혀졌습니다. 그렇죠? 지금은 기술 분야에서, 그리고 세상에서 실제로 활동하기에 가장 흥미로운 시기입니다. 왜냐하면 우리는 모든 응용 분야, 인간 노력의 모든 분야를 고양시키고 혁신할 놀라운 도구(tool)를 가지고 있기 때문입니다. 그리고 저는 그것이 흥분할 만한 일이고, 우리가 적용할 수 있는 것이며, 물론 우리가 해결해야 할 도전 과제(challenges)가 있지만, 이 놀라운 결과를 달성하기 위한 목적이라는 사실이 중요하다고 생각합니다. 그래서 저는 문제의 가용성(problem availability)이 시간이 지남에 따라 줄어들기보다는 증가할 것이라는 메시지가 제가 그 순간에 내면화했으면 좋았을 핵심이라고 생각합니다.

이러한 통찰은 현재 AI 기술이 직면한 무한한 가능성을 잘 보여줍니다. GPT-5-코덱스의 등장은 단순히 코딩 도구의 발전을 넘어, 인간과 AI가 협력하여 이전에는 상상할 수 없었던 문제들을 해결하고 새로운 지평을 열어갈 미래를 예고합니다. 컴퓨트(compute) 자원의 중요성과 AI 통합 경제(AI integrated economy)로의 전환은 인류에게 전례 없는 풍요(abundance)와 기회를 가져다줄 것입니다. OpenAI는 이러한 변화의 선두에 서서, 기술이 모든 인류에게 혜택을 줄 수 있도록 끊임없이 혁신하고 있습니다.

1 2025년 말 예상 매출 90억 달러 이상이므로 이는 현재 배수의 20배이며, 미친 수준은 아닙니다.
2 이것은 농담입니다.