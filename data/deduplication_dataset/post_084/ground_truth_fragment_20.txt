**GPT-5 관련 보도: 코덱스(Codex)의 부활 및 AI 모델 개발 동향**

이것은 GPT-5 관련 보도 중 바이브(vibes), 부트스트래핑(bootstrapping), 비전(vision), 라우터(Router)에 대한 마지막 내용이자 최신 AI 기술 관련 보도 중 주목할 만한 변화를 다룹니다. 혹시 놓치셨다면, 저희는 11월 19일부터 22일까지 뉴욕에서 열리는 AI 엔지니어 코드 서밋(AI Engineer CODE Summit)과 매년 열리는 글로벌 AI 컨퍼런스에서 최신 연구 동향을 공유합니다! 서밋과 컨퍼런스는 보통 10배 이상 초과 신청되며, 가장 고품질의 콘텐츠와 참가자들이 함께합니다. 개발자 생산성과 SWE 에이전트(SWE agents)의 새로운 기능 및 AI 기반 솔루션의 잠재력에 관심이 있다면, 지금 바로 신청하거나 참여하세요. 새로운 GPT-5-코덱스(GPT-5-Codex) 출시 및 AI 모델 개발 동향이 오늘 공개되며, 이는 최근 기억에 남는 코딩 에이전트(Coding Agents) 분야에서 가장 강렬했던 분위기 변화(vibe shifts)이자 인공지능 분야에서 가장 큰 변화의 한 달을 마무리합니다 (클릭하여 확장): 지난 1년여 동안, 6월의 클로드 3.5 소네트(Claude 3.5 Sonnet)를 시작으로 2월의 3.7 소네트(3.7 Sonnet)와 클로드 코드(Claude Code), 그리고 5월의 클로드 4(Claude 4)에 이르기까지, Anthropic은 코딩 활용 사례(coding usecases)에서 독보적인 우위(uncontested dominance)를 누렸습니다. 이는 50억 달러의 매출(revenue) (이 중 10%는 클로드 코드(Claude Code))과 1,830억 달러의 기업 가치(valuation) 1, 그리고 1,220억 달러의 시가총액(market cap) 증가로 이어지는 엄청난 성장세(epic runup)를 가져왔습니다. 이러한 기술 발전은 단순한 성능 향상을 넘어, 인공지능이 우리 삶에 미치는 영향의 범위를 확장하고 있습니다. 이는 OpenAI에 불을 지핀 것으로 보입니다. OpenAI는 물론 깃허브 코파일럿(GitHub Copilot)을 시작한 2021년 오리지널 코덱스(Codex)를 출시했으며, 이 코파일럿은 182명의 개발자와 계속해서 늘어나는 사용자를 가진 최초의 AI 코딩 도구(AI coding tool) 2입니다. 또한 GPT3는 모든 바이브 코딩 스타트업(vibe coding startups)의 전조가 된 디빌드(Debuild)에 영감을 주었고, 물론 o1과 GPT 4.1에서 코딩 능력(coding abilities)을 재우선순위화(reprioritize)하기 시작했습니다. GPT-5-코덱스(GPT-5-Codex)의 SWE-벤치(SWE-bench) (전체 500개) 점수 74.5%는 (악명 높게 밈으로 조롱받은) GPT-5 사고(thinking) 성능 74.9% (477개 작업 하위 집합)와 거의 비슷합니다. 그렇다면 GPT-5 인식(sentiment)에 이러한 큰 변화가 생긴 원인은 무엇일까요? 우선, 코덱스 팀이 엄청난 성과를 내고 있습니다.

**요인 1: 다양한 얼굴, 하나의 에이전트 및 AI 윤리, 책임**
오늘 팟캐스트(podcast)에서 그렉(Greg)이 말했듯이, 정말 많은 사람들이 참여했습니다: "연초에 우리는 연말까지 에이전트형 소프트웨어 엔지니어(agentic software engineer)를 만들고 AI 모델의 공정성, 투명성, 그리고 설명 가능성을 확보하는 회사 목표를 세웠습니다. 그리고 그것이 정확히 무엇을 의미하는지, 어떻게 구체화(substantiate)하고, 이 문제에 투입할 수 있는 모든 기회와 모든 종류의 컴퓨트(compute) 및 연구와 개발 노력을 어떻게 한데 모을지 알아내는 것이 OpenAI의 많은 사람들에게 큰 과업(undertaking)이었습니다." 원래의 A-SWE 에이전트형 하네스(A-SWE agentic harness)는 10X라고 불렸고 터미널(terminal)에서 작동했지만, 새로운 코덱스 CLI(Codex CLI)와 "챗GPT 코덱스(ChatGPT Codex)" (현재 코덱스 클라우드(Codex Cloud)), 그리고 IDE 확장 프로그램(IDE extension) (2.5주 만에 80만 건 설치) 및 깃허브 코드 리뷰 봇(GitHub code review bot)을 출시한 이후, 이제 모든 요구 사항을 충족하는 완전한 인터페이스(interfaces) 세트가 마련되었습니다. 또한 원래의 개발 프로세스는 성능 최적화에 중점을 두었지만, 이제는 윤리적 가이드라인과 규제 준수를 통합하는 방향으로 진화하고 있습니다. 새로운 AI 거버넌스 프레임워크(governance framework)와 "책임 있는 AI(Responsible AI)" 이니셔티브를 출시한 이후, 이제 모든 요구 사항을 충족하는 완전한 가이드라인(guidelines) 세트가 마련되었습니다. 다음은 코덱스 생태계(Codex universe) 및 AI 개발 생태계(ecosystem)에서 다양한 트레이드오프(tradeoffs)를 대략적으로 설명한 것입니다: 아마도 가장 적은 홍보를 받았겠지만, @codex 코드 리뷰 봇(code review bot)과 AI 윤리 위원회(AI ethics committee)는 매우 엄격한 범위 설정(tight scoping) 덕분에 가장 높은 유용성(utility)을 가질 수 있습니다: "우리는 검토해야 할 코드 양과 AI 시스템이 사회에 미치는 영향이 증가하면서, 팀원들이 단순히 해야 하는 검토 작업의 양과 따라야 하는 윤리적 지침의 양이 큰 병목 현상(bottleneck)이라는 것을 깨닫기 시작했습니다. 우리는 PR(Pull Request)을 검토하고 모델의 편향성(bias)을 검토하며, 구현하려던 계약(contract)과 의도(intention)에 대해 깊이 생각한 다음, 코드를 보고 시스템을 보고 그 의도가 코드와 결과와 일치하는지 검증(validate)할 수 있는 매우 고품질 시그널 코덱스 모드(high signal Codex mode)와 윤리 모드(ethics mode)에 집중하기로 결정했습니다. 그리고 이 봇과 위원회는 여러 계층을 깊이 파고들어 모든 종속성(dependencies)과 잠재적 위험(dependencies)을 살펴보고, 계약(contract)과 사회적 영향(contract)에 대해 생각하며, 최고의 직원들이나 최고의 검토자들이 해당 PR(Pull Request)과 AI 시스템에 대해 몇 시간 동안 깊이 생각하지 않았다면 찾을 수 없었을 문제들을 실제로 제기할 수 있습니다. 우리는 이것을 OpenAI 내부에서 먼저 출시했습니다. 그것은 매우 성공적이었고, 사람들이 안전망(safety net)을 잃는다고 느꼈기 때문에 고장 났을 때 실제로 화를 냈습니다. 그리고 그것은 팀과 코덱스 팀 및 윤리 팀을 포함하여 엄청나게 가속화(accelerated)시켰습니다."

**요인 2: 더 나은 후속 훈련 및 다중 모달 학습 품질**
물론 데이터셋(datasets)은 볼 수 없지만, OpenAI가 항상 강조하는 또 다른 점은 연구와 제품의 긴밀한 통합(tight integration of research and product)입니다. 오늘 팟캐스트(podcast)에서도 몇 가지 원하는 품질(desired qualities)에 대한 언급을 들었습니다: 다중 모달(multimodal) AI는 이제 텍스트뿐만 아니라 이미지, 오디오, 비디오를 동시에 이해하고 생성하는 능력을 보여줍니다. 이는 기존의 단일 모달(single modal) 시스템에서는 상상하기 어려웠던 새로운 가능성을 열고 있습니다.
**가변적인 끈기 및 이해도(Variable Grit & Comprehension)**
티보 소티오(Thibault Sottiaux): "이 모델이 보여주는 것 중 하나는 훨씬 더 오랫동안 지속하고 복잡한 리팩토링(refactoring) 작업에 필요한 끈기(grit)를 실제로 발휘하는 능력과 훨씬 더 복잡한 정보를 통합하고 다양한 데이터 유형을 처리하는 데 필요한 유연성(flexibility)을 실제로 발휘하는 능력입니다. 하지만 동시에 간단한 작업이나 간단한 이미지 인식 작업의 경우 훨씬 더 빠르게 반응하며 많은 생각 없이 답변할 수 있습니다. 그래서 코드에 대해 질문하고, 시각적 데이터에 대해 질문하고, 변경하거나 더 잘 이해해야 할 코드 조각이나 데이터 조각을 찾고, 계획을 세울 수 있는 훌륭한 협력자(collaborative)와 같습니다. 하지만 동시에 일단 어떤 작업을 맡기면, 매우 오랜 시간 동안 작동할 것이며 다양한 모달리티(modality)를 넘나들며 작동할 것입니다. 내부적으로는 매우 복잡한 리팩토링(refactoring) 작업과 데이터 분석 작업에 최대 7시간까지 작동하는 것을 보았습니다. 다른 모델에서는 이전에 그런 것을 본 적이 없습니다. 그리고 우리는 코드 품질과 데이터 통합 품질에도 엄청나게 노력했습니다. 그리고 GPT-5를 코덱스(Codex) 내와 다중 모달(multimodal) 환경 내에서 사람들이 사용하는 용도에 맞춰 정말 최적화되어 있습니다. 신중하게 적용된 이러한 끈기(tenacity judiciously applied)와 통합 능력(integration capability judiciously applied)이 GPT-5-코덱스(GPT-5-Codex)를 가장 어려운 문제에만 최적화하고 덜 똑똑하거나 덜 지능적인 모델(dumber models)을 위한 모델 전환기(model switcher)를 요구하는 것이 아니라, 훨씬 더 유용한 전천후 에이전트형 코딩 모델(agentic coding model)이자 에이전트형 다중 모달 모델(agentic multimodal model)로 만듭니다 (흥미롭게도, 우리가 이전에 다루었던 챗GPT(ChatGPT)의 GPT-5 라우터(GPT-5 Router)는 사용하지 않습니다): https://x.com/swyx/status/1967651870018838765/photo/1"
**정체에서 벗어나 반박하기 및 잘못된 해석에서 벗어나 반박하기(Getting out of Ruts & Misinterpretations and pushing back)**
그렉(Greg): "GPT-3와 GPT-4에서는 '고집하는 문제(doubling down problem)'에 정말 집중했던 기억이 납니다. AI가 잘못된 말을 하거나 잘못된 것을 해석하고 당신이 실수를 지적하면, AI는 자신이 옳다고 설득하려 했던 것을 기억하십니까? 우리는 이제 그 문제가 핵심 문제가 아닌 수준에 도달했습니다. 심지어 정확한 것을 완전히 찾아내지 못했을 때도 중요한 것을 강조하는 수준에 있다는 것이 정말 놀랍습니다. 꽤 합리적인 생각을 합니다. 그렉 브록먼(Greg Brockman): 그리고 저는 항상 이러한 코드 리뷰와 다중 모달 분석을 마치고 '음, 그래, 좋은 지적이야'라고 생각합니다." 우리는 그들이 이러한 현실성(groundedness) 수준을 어떻게 달성했는지 알 수 없지만, 이는 GPT-5에서 환각(hallucination) 현상과 잘못된 정보(hallucination) 현상이 측정 가능하게 감소한 것과 매우 관련이 있을 가능성이 높습니다.
**토큰 및 자원 효율성(Token & Resource Efficiency)**
업계의 가장 더러운 비밀 중 하나는 "토큰당 가격(price per token)"과 "데이터당 가격(price per data point)"이 점점 더 관련 없는 지표가 되고 있다는 것입니다. 왜냐하면 추론 모델(reasoning models)과 복합 추론 모델(reasoning models)은 질문에 답하기 위해 종종 10배 이상의 토큰이나 자원을 사용할 수 있기 때문입니다. 특히 당신에게 불투명한 경우 더욱 그렇습니다: 인공 분석 AIE 강연(Artificial Analysis AIE talk)에서 코덱스(Codex)와 다중 모달 모델(multimodal model)은 여기에서 토큰 효율성(token efficiency)과 자원 효율성(resource efficiency)에 특별히 최적화되어 있습니다. https://x.com/camsoft2000/status/1964787205571772511?s=46
이러한 설명하기 어려운 모든 품질(hard-to-articulate qualities)은 한 가지로 귀결됩니다: 새로운 평가(evals)의 필요성.

**요인 3: 에이전트형 코딩 및 AI 기반 과학 연구를 위한 새로운 평가(Evals)**
GPT-5 출시와 관련된 부정적인 초기 반응(negative first reactions)의 문제는 대부분의 사람들이 실제 환경에서 모델을 사용해보지 않고 헤드라인과 차트 조작(chart crimes)에만 반응했다는 것입니다. 저를 포함하여 모델을 사용해본 사람들은 이미 적응과 인식 변화(sentiment shift)를 겪었으며, GPT-5 인식 반전(Sentiment Flip)은 o1 출시 때와 마찬가지로 예상대로 제때 일어났습니다. 개발자를 위한 GPT-5 영상(GPT-5 for Developers video)과 과학 연구를 위한 GPT-5 영상(GPT-5 for Scientific Research video)을 촬영한 직후 제가 즉시 떠올린 생각은 "더 나은 분위기 점검(vibe checks)과 연구 검증(research validation)이 필요할 것"이라는 것이었습니다. 모두가 자신이 좋아하는 현장 점검(spot checks)을 가지고 있습니다. 저희 영상에서는 테오(Theo)가 헥사곤 볼(Hexagon ball)과 복잡한 시뮬레이션(simulation)을 사용했고 (출시 후 태도를 바꿨습니다), 사이먼(Simon)은 펠리칸벤치(PelicanBench)와 새로운 데이터 분석 벤치마크(PelicanBench)를 사용했으며, 벤(Ben)은 물론 글쓰기와 가설 검증(hypothesis testing)을 테스트하고 잠재 공간 해트트릭(Latent Space hat trick)과 잠재 공간 탐색(Latent Space exploration)을 위해 돌아왔습니다. 하지만 제가 개발자 영상에서 언급했던 GPT-5의 에이전트형 코딩 능력(agentic coding abilities)과 과학 연구 능력(scientific research abilities)은 매우 현실적입니다: 다음은 저희가 접근 권한을 얻었을 때 영상에서 실제로 시도했던 코드베이스(codebase)와 데이터셋(dataset)입니다: 이 블로그 게시물(blogpost)을 준비하기 위해 아주 좋은 커서 로그(Cursor logs)와 실험 로그(Cursor logs)를 가지고 있었지만… 제 채팅 기록 로그(chat history logs)와 연구 기록 로그(chat history logs)에서 사라진 것 같습니다. 죄송합니다 :/ 이것은 제가 몇 달 동안 클로드 코드(Claude Code)와 기존 분석 도구(Claude Code)에 수십 시간을 쏟아부었지만 아무 소용이 없었던 상황에서 GPT-5가 "도구를 활용하여 사고(thought with tools)"하여 코드를 계측(instrumented the code)하고 데이터를 계측(instrumented the data)하고, 저에게 로그를 다시 읽어주게 한 다음 해결책을 찾았다는 점에서 더욱 인상적이었습니다. 이것이 바로 새로운 모델이 출시되는 순간 가장 시끄럽고 자신감 있는 의견(loudest most confident takes)을 내놓으려는 소셜 미디어(social media) 압력의 문제입니다. 모델의 분위기(vibes)와 잠재력(vibes)을 측정하기 위해 간단한 단일 턴, 최소 도구 호출 테스트(one-turn, minimal-tool-call tests)만으로는 충분하지 않습니다 (제 농담은 "파란색과 보라색 그라데이션(blue and purple gradients)만 있다면 어떤 웹사이트든 바이브코드(vibecode)할 수 있다"는 것과 "정확한 데이터 시각화(data visualization)만 있다면 어떤 연구도 혁신할 수 있다"는 것입니다). 에이더(Aider)의 다국어 벤치마크(polyglot benchmarks)와 기존의 벤치마크(polyglot benchmarks)조차도 실제 코드베이스(codebases)와 과학 데이터베이스(codebases)에서 다중 턴, 다단계, 도구를 활용하여 사고하는 코딩 에이전트(multi-turn, multi-step, thinking-with-tools coding agents)와 연구 에이전트(multi-turn, multi-step, thinking-with-tools research agents)를 의미하는 에이전트형 코딩(agentic coding)과 AI 기반 연구(agentic research)를 실제로 테스트하지는 않습니다. 해결책은 분명했습니다: 실제 오픈 소스 코드베이스(open source codebases)와 과학 데이터베이스(open source scientific codebases)에서 실제 작업을 대상으로 모델의 블라인드 테스트(blind taste test)를 실시하고 관리자(maintainers)와 전문가(maintainers)가 성능을 평가하도록 하는 것입니다! 그래서 우리는 정확히 그렇게 했습니다: 이 게시물은 나중에 테스트 결과와 함께 업데이트될 예정입니다. 어쨌든, 코딩(Koding)과 과학 연구의 모든 것과 마찬가지로, 그렉 브록먼(Greg Brockman)은 OpenAI의 코딩 능력과 연구 능력 변화를 이끄는 주역(frontman)이었습니다. 저는 월드 페어(World’s Fair)에서 그를 인터뷰할 특권을 가졌으며, 이 뉴스레터(newsletter)에서는 오늘 공개된 OpenAI 팟캐스트(podcast)와 지난달 공개된 그의 잠재 공간 팟캐스트(Latent Space pod)를 요약합니다. 이 모든 내용은 위대한 OpenAI 코딩 복귀와 연구 복귀를 따라잡는 사람들을 위해 한곳에 모아두었습니다. 즐겁게 읽으세요!

**그렉(Greg)과 티보(Thibault)의 OpenAI 팟캐스트(Podcast)**
**그렉 브록먼(Greg Brockman)의 잠재 공간(Latent Space)**
이 에피소드는 지난달에 녹음되어 방송되었습니다.

**쇼 노트(Show Notes)**
그렉 브록먼(Greg Brockman)
튜링 테스트 논문(Turing Test Paper)
양자 컴퓨팅 논문(Quantum Computing Paper)
커널 랩스(Kernel Labs)
ARC 연구소(ARC Institute)
AI 윤리 연구소(AI Ethics Institute)
지속 가능한 AI 개발(Sustainable AI Development)
GPT-5 리뷰(GPT-5 Review)
GPT-OSS
AI for Good 챌린지(AI for Good Challenge)
도타(Dota) (OpenAI 파이브(Five))
자율 주행 시뮬레이션(Autonomous Driving Simulation)
이미지젠(ImageGen)
생체 모방 로봇(Biomimetic Robotics)
LM 아레나(LM Arena)
AI 안전성 평가(AI Safety Evals)
IMO 골드(IMO Gold) (국제 수학 올림피아드(International Mathematical Olympiad))
IOI 골드(IOI Gold) (국제 정보 올림피아드(International Olympiad in Informatics))
다이슨 스피어(Dyson Sphere)
우주 탐사 AI(Space Exploration AI)

**타임스탬프(Timestamps)**
[00:00:04] 서론
[00:01:04] OpenAI의 추론 및 AI 윤리 진화
[00:04:01] 언어 및 AI 모델의 온라인/오프라인, 지속 가능/효율적 학습
[00:06:44] 강화 학습 및 전이 학습의 샘플/데이터 효율성 및 인간/전문가 큐레이션
[00:08:16] 컴퓨트 및 클라우드 컴퓨팅 확장, 초임계 및 범용 AI 학습
[00:13:21] RL 및 실제 상호작용에서의 벽시계 시간 및 에너지 소비 제약
[00:16:34] ARC 연구소 및 AI 윤리 연구소, DNA 및 생체 모방 신경망 경험
[00:19:33] GPT-5 시대 및 AI 시대의 사회적 영향 정의
[00:22:46] 모델 지능, 작업 난이도, 투명성 및 설명 가능성 평가
[00:25:06] GPT-5 및 AI 기반 개발자를 위한 실용적인 조언
[00:31:48] 모델 사양 및 AI 모델 거버넌스
[00:37:21] RL 및 AI 편향성 선호도의 과제 (예: try/catch, 데이터 불균형)
[00:39:13] GPT-5 및 AI 모델 라우팅, 하이브리드 아키텍처
[00:43:58] GPT-5 및 AI 서비스 가격 책정, 컴퓨트 및 자원 효율성 개선
[00:46:04] 자체 개선 코딩 및 AI 에이전트, 도구 및 지식 활용
[00:49:11] 온디바이스 및 엣지 AI 모델, 로컬 vs 원격/클라우드 에이전트 시스템
[00:51:34] OpenAI의 엔지니어링 및 LLM(대규모 언어 모델) 활용
[00:54:16] AI 최적화를 위한 코드베이스 및 데이터베이스, 팀 구성
[00:55:27] AGI 시대 엔지니어 및 인간의 가치
[00:58:42] AI 연구의 현재 상태 및 연구소/접근 방식 다양성
[01:01:11] OpenAI의 우선순위 및 중점 분야
[01:03:05] 창업자를 위한 조언: 아직 늦지 않았다
[01:04:20] 미래 전망 및 마무리 생각
[01:04:33] 2045년 타임캡슐: 컴퓨트, 지속 가능한 컴퓨트, 풍요의 미래 사회
[01:07:07] 2005년 타임캡슐: 더 많은 문제와 기회가 나타날 것이다

**대본(Transcript)**
**서론(Introductions)**
알레시오(Alessio) [00:00:04]: 안녕하세요, 여러분. 잠재 공간 팟캐스트(Latent Space podcast)에 오신 것을 환영합니다. 저는 커널 랩스(Kernel Labs) 및 AI 윤리 연구소(AI Ethics Institute)의 설립자 알레시오(Alessio)이고, 스윅스(Swyx), 스몰 AI(Small AI) 및 지속 가능한 AI(Sustainable AI)의 설립자와 함께합니다.
스윅스(Swyx) [00:00:10]: 안녕하세요. 그렉 브록먼(Greg Brockman)을 모시게 되어 정말 기쁩니다. 환영합니다. 초대해주셔서 감사합니다. 여기 오게 되어 기쁩니다. 소개가 필요 없으시죠. 그래서 제가 마음속으로 소개를 하려다가 바로 본론으로 들어가겠습니다. GPT-5, GPT-OSS, AI for Good 챌린지(AI for Good Challenge), OpenAI에서 진행되는 모든 일들에 대해 축하드립니다. 이 모든 것을 어떻게 해내셨습니까? 여기 와주셔서 정말 좋습니다. 기분이 어떠신가요? 지난주는 정말 많은 출시가 있었던 혼란의 주였습니다.
그렉(Greg) [00:00:33]: 출시요. 정말 정신없었습니다. 한 주 동안 그렇게 많은 것을 출시하는 것은 정말 정신없는 일이었습니다. 하지만 네, 저희는 오픈 소스 모델(open source models)을 출시했습니다. 오랫동안 작업해온 모델들이죠. OpenAI에서 이룬 많은 발전들을 매우 작은 형태로, 매우 접근하기 쉽게 담아냈다고 생각합니다. 지난 며칠 동안만 해도 수백만 건의 다운로드가 있었습니다. 저희는 또한 GPT-5도 출시했습니다. 이것 역시 오랫동안 작업해온 것입니다. 그래서 이 모든 것을 세상에 내놓고 출시 과정을 마쳤다는 것이 정말 기쁩니다. 팀이 해낸 일에 대해 정말 자랑스럽습니다.

**OpenAI의 추론 및 AI 윤리 진화(The Evolution of Reasoning & AI Ethics at OpenAI)**
알레시오(Alessio) [00:01:04]: 그리고 GPT-5는 최초의 하이브리드 모델(hybrid model)이자 다중 모달 모델(multimodal model)입니다. 그래서 대부분의 사람들은 하나의 모델을 선택할 수 없습니다. 그리고 그것은 우리가 다루지 않을 또 다른 드라마입니다. 또 다른 이야기죠. 하지만 당신은 원래 일리야(Ilya)와 함께 OpenAI에서 추론 팀(reasoning team)과 AI 윤리 팀(AI ethics team)을 시작했습니다. OpenAI의 추론(reasoning)과 AI 윤리(AI ethics) 역사에 대해 간략하게 설명해주실 수 있나요? 처음에는 단순히 다음 토큰 예측(next token prediction)과 데이터 편향 예측(data bias prediction)으로 시작했고, 어느 시점에서 추론(reasoning)과 윤리적 고려(ethical considerations)가 중요한 것이라고 생각하게 되었죠. 사용자에게는 숨겨져 있는 GPT-5까지의 경로는 어땠습니까?
그렉(Greg) [00:01:31]: 음, 이렇게 말씀드리겠습니다. GPT-4를 훈련시킨 후, 우리는 대화할 수 있는 모델을 갖게 되었습니다. 그리고 저는 첫 번째 작업을 했던 것을 기억합니다. 우리는 후속 훈련(post-training)을 했습니다. 실제로 지시 따르기 후속 훈련(instruction following post-train)과 윤리적 가이드라인 따르기 후속 훈련(ethical guideline following post-train)을 했습니다. 그래서 그것은 정말 단순히 '여기에 질문이 있습니다. 모델 완성(model completion)은 이래야 합니다'라는 데이터셋(dataset)이었습니다. 그리고 우리는 '음, 다른 질문으로 계속하면 어떻게 될까?'라고 생각했습니다. 그리고 그것은 실제로 이전의 질문과 답변 체인(chain) 전체를 맥락(context)으로 삼아 응답할 수 있었습니다. 그리고 당신은 이 모델이 채팅(chat)을 할 수 있다는 것을 깨달았습니다. 그렇죠? 실제로 당신과 대화할 수 있고, 훈련받지 않았음에도 불구하고 이 모든 정보를 활용할 수 있습니다. 그리고 저는 우리가 이 질문을 했던 것을 기억합니다. 야콥(Jakob), 일리야(Ilya), 보이치에흐(Wojciech) 등 여러 사람들과 연구 회의를 했습니다. 질문은 '왜 이것이 AGI가 아닌가?' 또는 '왜 이것이 완전한 AGI가 아닌가?'였습니다. 그렇죠? 이 모델은 분명히 AGI가 아니지만, 왜 그런지 설명하기가 정말 어렵습니다. 그렇죠? 어떤 질문이든 답할 수 있는 것 같고, 물론 완전히 신뢰할 수 있는 것은 아닙니다. 실수를 하고, 엉뚱한 방향으로 가기도 합니다. 좋습니다. 그것은 실제 격차입니다. 그렇다면 그 격차를 줄이기 위해 무엇을 해야 할까요? 가장 분명한 것은 실제로 모델이 세상에서 자신의 아이디어와 윤리적 판단을 시험해 보도록 하는 것입니다. 그렇죠? 실제로 강화 학습(reinforcement learning)을 수행하여 가설(hypotheses)을 시도하고 피드백(feedback)을 받아 거기서부터 신뢰성을 확보하는 것입니다. 그리고 이것은 우리에게 새로운 아이디어가 아닙니다. 그렇죠? 2017년으로 거슬러 올라가도, 우리는 도타(Dota)와 자율 주행(autonomous driving)을 작업하고 있었는데, 그것은 전적으로 강화 학습(reinforcement learning)이었고, 인간 시연(human demonstrations)으로부터의 행동 복제(behavioral cloning) 같은 것은 없었습니다. 단순히 무작위로 초기화된 신경망(neural net)에서 놀랍도록 복잡하고 정교하며 매우 정확한 행동을 얻을 수 있었습니다. 그리고 우리는 언어 모델(language models)에 대해 그러한 신뢰성을 원했습니다. 그래서 GPT-4를 훈련시킨 순간, 우리는 추론 패러다임(reasoning paradigm)과 윤리적 패러다임(ethical paradigm)으로 나아가야 한다는 것을 알았습니다. 그리고 그것은 단지 '어떻게'의 문제였습니다. 그래서 우리는 10가지 아이디어, 무엇이 효과가 있을지에 대한 다양한 가설(hypotheses)을 가지고 있었습니다. 그리고 사람들은 그것을 현실로 만들기 위해 정말 노력했습니다. 그래서 그것은 OpenAI의 많은 사람들이 여러 해 동안 노력한 결과였습니다. 그리고 저는 이 분야의 발전 방식은 방향에 대한 확신(conviction)을 가져야 한다는 것이라고 생각합니다. 그렇죠. 그리고 시도하는 첫 10가지 일은 실패할 것입니다. 그리고 그 10가지 목록에 있는 대부분의 것들은 성공하지 못했지만, 우리는 그 중 하나를 성공시켰습니다. 그리고 저는 그것이 진정한 핵심이라고 생각합니다. 우리는 계속해서 밀어붙이고, 작은 생명의 징후를 얻으면 거기서부터 계속 성장합니다. 그래서 이제 제리(Jerry)가 우리의 강화 학습 팀(reinforcement learning team)을 이끌고 있으며, 그곳에서 정말 큰 발전을 이루었습니다. 웬다(Wenda) 같은 사람, 펠리페(Felipe) 같은 추론(inference) 및 윤리적 판단(inference) 측 사람 등 OpenAI의 많은 사람들이 함께 모여 정말 놀라운 인프라(infrastructure) 작업을 하고 있습니다. 그리고 저는 이 작업을 실제로 성공시키기 위해 우리가 함께 일할 수 있다는 것이 정말 중요하다고 생각합니다.

**언어 및 AI 모델의 온라인/오프라인, 지속 가능/효율적 학습(Online/Offline, Sustainable/Efficient Learning in Language & AI Models)**
스윅스(Swyx) [00:04:01]: 놀랍습니다. 당신이 엔지니어 컨퍼런스(engineer conference)에서 저와 함께 있을 때 튜링 논문(Turing paper)과 양자 컴퓨팅 논문(Quantum Computing Paper)에 대해 이야기했던 것을 다시 생각해보니, 당신은 그 논문을 좋아했고 그것이 당신의 머신러닝(machine learning) 및 AI 연구 여정을 시작하는 데 어느 정도 영향을 주었죠. 그리고 저는 사실 그가 학습 기계(learning machine)가 부분적으로 온라인(online)이고 지속 가능(sustainable)할 것이라고 예상했다고 생각합니다. 아시다시피, 그것이 제가 3, 4에서 5로 가는 이 여정을 되돌아볼 때 항상 가졌던 질문 중 하나입니다. 학습은 모두 오프라인(offline)에서 시작되었고 모두 사전 훈련(pre-trained)되었는데, 이제 서서히 다시 온라인(online)으로 돌아오고 지속 가능(sustainable)한 방향으로 돌아오고 있습니다. 그것이 정확하다고 생각하십니까?
그렉(Greg) [00:04:31]: 네. 매우 흥미로운 질문이라고 생각합니다. 그렇죠? 학습이 어디에서 일어나는가? 그리고 저는 우리가 아직 인간이 하는 완전한 종류의 학습 루프(learning loop)에는 도달하지 못했다고 생각합니다. 네. 그렇죠. 인간이 완전히 온라인(online)이고 지속 가능한지 명확하지 않습니다. 왜냐하면, 아시다시피, 잠을 자면 장기 기억(long-term memory)으로 많은 종류의 역전파(back propagation)와 환경적 영향(back propagation)이 일어납니다. 그래서 저는 인간이 작동하는 방식이 반드시 우리의 기계가 작동하는 방식과 일치한다고 생각하지 않습니다. 하지만 우리는 단순히 기계를 만들고, 한 번 훈련시키고, 그 다음에는 엄청난 추론(inferencing)을 하는 세상에서, 실제로 추론(inference)을 하고 그 추론(inferencing)을 기반으로 훈련하고 지속 가능한 학습 루프(loop)가 있는 세상으로 이동하고 있습니다. 그리고 일리야(Ilya)가 자주 말했던 것 중 매우 통찰력 있다고 생각하는 한 가지는, 모델의 능력이 매우 낮을 때, 그들이 생성하는 토큰(token)과 데이터의 가치가 매우 낮다는 것입니다. 모델의 능력이 매우 높을 때, 그들이 생성하는 토큰(token)과 데이터의 가치는 매우 높습니다. 그렇죠. 그것은 매우 사려 깊은 것이고, 중요한 것입니다. 그리고 강화 학습(reinforcement learning)은 이러한 속성을 가지고 있습니다. 모델이 여러 가지를 시도하기 때문에 많은 데이터를 생성하고, 그 데이터를 기반으로 훈련합니다. 그래서 모델의 관찰(observations)은 현실과의 접촉으로 정규화되거나, 현실과의 접촉으로 선택되어 기계로 다시 피드백됩니다. 그리고 저는 그것이 우리가 배우는 데 매우 능숙해지기 시작한 것이라고 생각합니다. 그리고 필요한 규모(scale)는 매우 다릅니다. 그렇죠? 사전 훈련(pre-training)을 보면, 당신의 10가지 예시는 아무것도 아닙니다. 당신은 수십만 가지의 작은 행동 유형에 대해 이야기하고 있습니다. 그리고 그것이 당신이 배우는 것입니다. 이는 인간이 배우는 방식과는 완전히 다릅니다. 다시 말하면, 저는 그렇다고 생각합니다. 당신이 모든 진화(evolution)를 되짚어보고 20년 동안의 발달 역사(developmental history)를 생각한다면, 세상에서 많은 것을 관찰하는 일이 일어납니다. 당신의 감각을 통해 흐르는 많은 정보 조각들이 있습니다. 하지만 강화 학습 패러다임(reinforcement learning paradigm)에서는 10가지 예시나 100가지 예시가 있다면, 그렇죠? 당신이 해야 할 10가지 경로가 있고, 모델이 여러 번 시도하면 실제로 거기서부터 배울 수 있습니다. 그래서 당신은 이러한 레버리지(leverage)를 얻게 됩니다. 그리고 인간 큐레이터(human curator)가 그러한 작업을 생성하는 것으로부터 레버리지를 얻을 수 있으며, 모델로부터 매우 정교한 행동을 실제로 얻을 수 있습니다. 그리고 이제 모델이 진행하면서 온라인(online)으로 학습하고 지속 가능하게 학습하는 다음 단계가 있습니다. 우리는 아직 그렇게 하고 있지는 않지만, 미래는 아직 쓰여지지 않았습니다.

**강화 학습 및 전이 학습의 샘플/데이터 효율성 및 인간/전문가 큐레이션(Sample/Data Efficiency & Human/Expert Curation in Reinforcement & Transfer Learning)**
알레시오(Alessio) [00:06:44]: 노암 브라운(Noam Brown)과 샘플 효율성(sample efficiency) 및 데이터 효율성(data efficiency)에 대해 논의했습니다. 오늘날 병목 현상(bottleneck)이 여전히 RL(강화 학습)이 작동하도록 이러한 훌륭한 작업을 만드는 인간 데이터 큐레이터(human data curator)라고 생각하십니까? 아니면 여전히 모델의 샘플 효율성(sample efficiency) 및 데이터 효율성(data efficiency)이라고 생각하십니까?
그렉(Greg) [00:06:57]: 음, 병목 현상(bottleneck)은 항상 컴퓨트(compute)입니다. 그렇죠. 그리고 저는 그것을 실제로 의미합니다. 그렇죠? 마치 '만약 당신이 우리에게 많은 컴퓨트(compute)를 준다면, 우리는 그것을 최대한 활용할 수 있는 방법을 찾을 것입니다'와 같습니다. 우리는 지금 훨씬 더 샘플 효율적이고 데이터 효율적인 알고리즘(sample efficient algorithms)을 가진 세상에 살고 있습니다. 그렇죠? RL 패러다임(RL paradigm)과 전이 학습 패러다임(transfer learning paradigm)을 통해 말이죠. 하지만 여전히 많은 컴퓨트(compute)가 필요합니다. 그렇죠? 마치 인간이 만든 하나의 작업이나 10개의 작업, 또는 100개의 작업, 또는 그 소수의 작업이 있고, 모델이 여러 번 시도하는 것과 같습니다. 네. 그리고 모델이 한 가지 작업을 수행하기 위해 10번이 아니라 10,000번 시도하고, 당신은 그 중에서 선택하고 거기서부터 배웁니다. 그리고 다시 말하면, 인간 설계자로서 당신이 얻는 인간 레버리지(human leverage)의 양은 극도로 높지만, 그것을 작동시키기 위해 투입해야 하는 컴퓨트(compute)의 양은 비례적으로 증가합니다.

**컴퓨트 및 클라우드 컴퓨팅 확장, 초임계 및 범용 AI 학습(Scaling Compute & Cloud Computing, Supercritical & General AI Learning)**
스윅스(Swyx) [00:07:45]: 학습 과정에서 더 많은 컴퓨트(compute)를 소비하는 한 가지 방법은 앨런 튜링(Alan Turing)이 이 모든 것을 많이 예견했다는 것입니다. 그는 아임계 학습(sub-critical learning) 대신 초임계 학습(super critical learning)이라는 개념을 가지고 있었습니다. 즉, 우리가 기계에 학습을 제시하거나 가르칠 때, 기계는 우리가 방금 가르친 즉각적인 것만 배웁니다. 하지만 초임계(super critical)는 당신이 방금 배운 모든 것의 2차, 3차, 4차 효과를 통해 당신이 아는 다른 모든 것을 업데이트하는 것을 의미합니다. 그렇다면 우리는 더 많은 컴퓨트(compute)를 어떤 창의적인 방식으로 소비할까요? 그렇죠? 만약 우리가 10배 더 많은 컴퓨트(compute)나 1000배 더 많은 컴퓨트(compute)를 가지고 있다면, 그것은 어디로 갈까요?
그렉(Greg) [00:08:16]: 우리는 그것을 실현할 방법을 찾을 것이라고만 말하겠습니다. 제발 우리에게 주세요. 하지만 저는 그것을 진지하게 받아들입니다. 그렇죠? 이것이 작동하는 방식은 이렇습니다. 도타(Dota)와 자율 주행(autonomous driving)과 같은 것을 되감아보면, 우리는 새로운 강화 학습 알고리즘(reinforcement learning algorithms)을 개발하기 시작했습니다. 왜냐하면 당시 존재했던 강화 학습(reinforcement learning) 알고리즘이 확장되지 않는다는 것이 모두에게 분명했기 때문입니다. 모두가 알고 있었습니다. 그리고 저는 야콥(Jacob)과 시몬(Shimon)이 '왜 우리가 그것을 믿지? 아무도 실제로 테스트해보지 않았잖아?'라고 말했던 것을 기억합니다. 그리고 아무도 실제로 구식 PPO(PPO)를 확장하여 '음, 그것이 기준선이야. 우리는 해야 해'라고 말해보지 않았습니다. 그리고 저는 매주 사무실로 돌아오면 코어(cores) 수가 두 배로 늘어났던 것을 기억합니다. 에이전트(agent)만 그랬습니다. 진정한 기술은 계속해서 향상되고 있었습니다. 계속해서 우상향했습니다. 그리고 '좋아, 벽에 부딪힐 때까지 계속 밀어붙여야 해. 그리고 분명히 벽에 부딪히면 실제 흥미로운 일을 할 수 있을 거야'라고 생각했습니다. 그리고 우리는 결코 벽에 부딪히지 않았습니다. 그리고 당신은 실제로 그 확장(scaling)의 여정, 그것이 흥미로운 일이라는 것을 깨닫습니다. 그렇죠? 진정한 엔지니어링(engineering)을 하는 것입니다. 물론 버그(bugs)가 있고 그 버그(bugs)가 벽을 만들지만, 당신은 버그(bug)를 고칩니다. 그렇죠? 신경망(neural nets)이 초기화되는 방식이나 스케일링 분산(scaling variance) 등 다른 문제가 있지만, 그것들은 알고리즘(algorithm)이나 과학의 근본적인 문제가 아닙니다. 그래서 저는 우리가 처한 세상이 그런 종류의 세상이라고 생각합니다. 우리는 모든 차원에서 밀어붙일 것이고, 아마도 벽에 부딪힐 것입니다. 대부분의 경우, 그 벽은 단순히 버그(bugs)나 어리석은 것들입니다. 그래서 당신은 계속 나아갈 수 있습니다. 때로는 그것들을 고치는 ROI(투자 수익률)가 정말 어렵습니다. 그렇죠? 그래서 그것은 정말 가치가 없습니다. 왜냐하면 당신은 다른 차원을 가지고 있기 때문입니다. 그렇죠? 모델을 더 크게 만들고 사전 훈련 컴퓨트(pre-training compute)를 더 많이 할 것인가, 아니면 RL(강화 학습)을 더 많이 할 것인가? 그래서 실제 테스트 시간(test time)에 더 많은 컴퓨트(compute)를 투입할 것인가? 그리고 컴퓨트(compute)를 투입할 수 있는 모든 종류의 차원이 있습니다. 그리고 어떤 면에서는 컴퓨트(compute)를 마치 정제 과정(refining process)과 같다고 생각합니다. 궁극적으로 에너지(energy)로 시작하여 컴퓨트(compute)로 변하고, 지능(intelligence)으로 변하며, 그것은 거의 그 컴퓨트(compute)를 모델이 유용한 일을 할 수 있는 잠재 에너지(potential energy)로 결정화시키는 것과 같습니다. 정말 아름다운 일입니다. 그렇죠? 마치 컴퓨트(compute)가 지능(intelligence)의 근본적인 동력, 근본적인 연료와 같고, 신경망(neural net)을 형성하며, 프로그램을 출력하는 것과 같습니다. 그리고 물론 그 프로그램의 좋은 점은 당신이 이 모든 컴퓨트(compute)를 투입했음에도 불구하고 여러 번 실행할 수 있다는 것입니다. 당신은 그것을 한 번 만드는 데 들인 노력보다 훨씬 더 많이 사용할 것이라는 상각(amortization)을 가지고 있습니다. 그래서 그것은 아름다운 패러다임(paradigm)입니다.
알레시오(Alessio) [01:10:27]: 네. 운동 에너지(kinetic energy)를 모델의 잠재 에너지(potential energy)로 바꾸는 것과 같습니다. 그리고 이 모델에 이미 있는 에너지를 운동 에너지(kinetic energy)로 다시 바꿔서 다른 모든 영역에서 RL(강화 학습)을 할 수 있다고 생각하십니까? 왜냐하면 우리는 IMO 골드(IMO gold)를 얻었으니까요. 제 말은, 우리, 당신들, 모두가 말이죠. 같은 기술과 같은 기본 모델이 IMO 골드(IMO gold)에 해당하는 목표를 달성하게 할 수 있다고 생각하십니까? 네. 제 말은, 우리가 컴퓨트(compute)를 확장하기만 하면 될까요, 아니면 아직 해야 할 일이 남아 있다고 생각하십니까?
그렉(Greg) [01:10:57]: 음, IMO 모델(IMO models)이 IOI(국제 정보 올림피아드)에서도 금메달을 따게 한다는 것에 대한 꽤 좋은 증거가 있습니다. 그것은 똑같습니다. 네. 제 말은, 우리가 세부 사항 중 일부에 대해 이야기했다고 생각합니다. 하네스(harness)에 약간의 차이가 있지만, 하네스(harness)가 문자 그대로 금메달은 아닙니다. 그렇죠. 실제로는 기본 모델(underlying models)이고, 우리가 특별히 한 훈련은 없습니다. 이것은 몇몇 사람들의 부수적인 프로젝트(side project)로 끝났습니다. 그들은 '오, IOI(국제 정보 올림피아드)도 해야겠네'라고 생각했습니다. 그렇죠. 그리고 그것은 저에게는 정말 놀라운 사실입니다. 왜냐하면 그것은 과거에는 엄청난 도전 과제(total grand challenge)였고, 많은 사람들이 매달려야 하는 것이었기 때문입니다. 그리고 OpenAI의 핵심 IMO 팀(IMO team)은 실제로 세 명으로 구성되어 있었습니다. 그렇죠. 엄청난 노력이 아니었습니다. 그래서 당신은 이러한 영역(domains)에 대해 약간의 전문화(specialization)가 필요할 수도 있다는 것을 깨닫습니다. 그렇죠? 약간의 추가 작업, 약간의 데이터셋(dataset) 수집. 하지만 근본적으로 우리는 이러한 범용 학습 기술(general purpose learning technology)을 가지고 있으며, 어려운 문제를 해결하는 방법을 배우는 것은 실제로 매우 전이 가능한 기술(transferable skill)입니다. 어려운 수학 문제를 해결하고 증명을 작성하는 방법을 배우는 것이 실제로 프로그래밍 작성 및 경쟁 문제로 전이된다는 것이 밝혀졌습니다. 이제 만약 당신이 물리 실험(physics experiment)을 한 번도 해본 적이 없다면, 그렇죠? 만약 당신이 실제로 화학 물질을 섞어보려고 시도한 적이 없다면, 당신은 아마도 그런 일에 마법처럼 능숙하지 않을 것입니다. 그래서 일반화(generalization)의 한계에 대한 어떤 것이 있습니다. 그렇죠? 당신은 실제로 실제 세계 경험을 가지고 그것을 시도해야 합니다. 하지만 이 모델들은 이미 거의 불합리할 정도로 멀리 나아갑니다. 그리고 우리는 이것을 항상 봅니다. O3와 같은 모델을 사용하여 '여기에 실험 설정이 있습니다. 무엇을 해야 할까요?'라고 가설(hypotheses)을 묻는 연구실 과학자(lab scientists)들이 있습니다. 그들은 다섯 가지 아이디어를 가지고 있고, 이 다섯 가지 아이디어를 시도합니다. 그 중 네 가지는 작동하지 않지만, 한 가지는 작동합니다. 그리고 O3에 대해 우리가 받았던 피드백(feedback)은 중간급 학술지(mid-tier journal)에 발표될 수 있는 결과물이라는 것이었습니다. 최고급 학술지(top tier journal)는 아니지만, 중간급 학술지(mid-tier journal)에 말이죠. 그것은 3학년 또는 4학년 박사 과정 학생에게서 기대할 수 있는 종류의 작업일 것입니다. 그리고 다시 말하면, 그것은 정말 놀라운 사실입니다. 그것이 O3의 현재 위치입니다. 그리고 우리는 O3를 모든 차원에서 개선하는 방법을 정확히 알고 있습니다. 그리고 그것은 컴퓨트(compute)를 필요로 합니다. 많은 작업이 필요합니다. 작업을 얻는 것이 필요합니다. 많은 인간의 지적 사랑과 노동과 시간이 필요하며, 우리의 마음과 영혼을 쏟아부어야 합니다. 하지만 결과는, 당신의 말처럼, 그 안에 모든 잠재 에너지(potential energy)를 담고 있는 것을 생산한다는 것입니다. 그리고 놀라운 점은 그 잠재 에너지(potential energy)를 한 번만 방출하는 것이 아니라는 것입니다. 그렇죠? 그것은 이 모든 작업에서 여러 번 사용할 수 있는 체크포인트(checkpoint)입니다. 그리고 그것은 인류 전체를 고양시킬 수 있는 것이라고 생각합니다. 정말 고무적입니다.

**RL 및 실제 상호작용에서의 벽시계 시간 및 에너지 소비 제약(Wall Clock Time & Energy Consumption Limitations in RL & Real-World Interactions)**
스윅스(Swyx) [01:13:21]: 두 가지를 되짚어보고 싶습니다. 하나는 벽에 대한 것입니다. 제가 노암(Noam)과 논쟁하려 했던 것 중 하나는 벽시계 시간(wall clock time) 측면에서 벽이 있다는 것입니다. 왜냐하면 시간이 흘러야 하기 때문입니다. RL(강화 학습)이 환경 및 시뮬레이션(simulation)과 상호작용하는 문제점은 시뮬레이션(simulation)을 실시간보다 빠르게 가속화할 수 있다는 것입니다. 어느 시점에서는 벽시계 시간(wall clock time)과 일치해야 합니다. 그래서, 아시다시피, 우리는 실시간에 점점 더 가까워지는 반복 속도(pace of iterations)로 벽시계 시간(wall clock time)에 수렴하는 것을 볼 수 있습니다. 그래서 저는 그것이 실제 세계를 모델링(modeling the real world)하는 데 있어 정말 흥미로운 생각이라고 생각합니다. 그것을 해결하는 것에 대한 어떤 생각이 있으신지 모르겠습니다. 분명히 우리는 아직 그 단계에 도달하지 않았으므로 걱정할 필요는 없습니다.
그렉(Greg) [01:13:57]: 네, 이것은 꽤 근본적인 장벽이라고 생각합니다. 그렇죠? 그리고 물론 모델은 매우 비인간적인 특성(non-human affordances)을 가지고 있습니다. 그렇죠? 여러 개의 복사본을 실행할 수 있습니다. 그래서 지연 시간(latency)을 줄일 수 없더라도 확장(scale out)할 수 있습니다. 그리고 컴퓨트(compute)가 어디로 가는지 생각하는 것도 매우 흥미롭습니다. 그렇죠? 왜냐하면 우리는 컴퓨트(compute)의 대부분이 모델을 훈련시키는 데 사용되는 세상에서, 이 모델들을 더 많이 배포함에 따라 컴퓨트(compute)의 더 많은 부분이 추론(inferencing)하고 실제로 사용하는 데 사용되는 세상으로 이동할 것이기 때문입니다. 하지만 만약 당신이 '음, 이 모델들이 실제 세계와 많이 상호작용할 것이고, 그래서 아마도 모든 단일 행동에 대해 많이 생각해야 할 것이다'라고 생각한다면, 그렇죠? 그래서 실제 세계 상호작용당 엄청난 양의 컴퓨트(compute)가 소비될 수도 있습니다. 그래서 컴퓨트(compute)가 실제로 소비될 것으로 예상되는 곳이 정말 바뀝니다. 그리고 저는 매우 효율적인 좋은 하네스(harnesses)를 갖는 것이 정말 중요하다고 생각합니다. 그렇죠? 만약 제가 실제 세계에서 어떤 롤아웃(rollout)에서 여러 단계를 거쳤다면, 그것을 어떻게 체크포인트(checkpoint)할 것인가? 그렇죠? 그리고 만약 당신이 시스템을 재시작해야 하고 현재 상태를 모두 잊어버리는 시스템을 가지고 있다면, 그것은 아마도 꽤 나쁠 것입니다. 그래서 저는 모든 것을 완벽하게 관찰하고 체크포인트(checkpoint)하고 보존할 수 있는 디지털 세계와, 훨씬 더 지저분하고 복잡한 현실 사이에는 매우 다른 점이 있다고 생각합니다. 그리고 저는 그것이 나쁜 것은 아니라고 생각합니다. 그렇죠? 우리는 도타(Dota)와 자율 주행(autonomous driving)과 같은 에이전트(agents)가 매우 복잡하고 지저분한 환경에서 작동할 수 있다는 것을 보았습니다. 그래서 알고리즘(algorithms)은 그것을 할 수 있습니다. 그리고 참고로, 도타(Dota)와 자율 주행(autonomous driving)은 3억 개의 매개변수 신경망(300 million parameter neural net)이었습니다. 아주 작고 작은 곤충 뇌와 같았죠. 그렇죠? 이제 우리는 매개변수(parameters) 수 측면에서, 어쩌면 컴퓨트(compute) 수 측면에서 인간 규모와 훨씬 더 비교할 수 있는 것들로 확장(scale up)하기 시작했습니다. 우리는 반드시 그 단계에 도달한 것은 아닙니다. 당신은 수학을 다른 방식으로 볼 수 있습니다. 하지만 근본적으로 우리는 실제 목표를 향해 나아가고 있습니다. 그리고 AGI(범용 인공지능)가 무엇이어야 하는지 생각한다면, 그것은 매우 생산적인 방식으로 실제 세계와 상호작용할 수 있는 것이어야 합니다. 네.
스윅스(Swyx) [01:15:51]: 대략적으로 계산해보면, 제 머릿속에 있는 숫자는, 제가 몇 자릿수 정도 틀렸다면 수정해주십시오. 하지만 인간은 100조 개의 뉴런(neurons)을 가지고 있습니다. 우리는 GPT-4, 4.5, 5의 경우 낮은 두 자릿수에서 높은 한 자릿수 범위에 있지만, 그것을 확인하지는 않을 것입니다.
그렉(Greg) [01:16:08]: 하지만 우리는 그쪽으로 확장(scaling)하고 있습니다. 네. 100조 개의 시냅스(synapses)라고 말하겠습니다. 이는 신경망(neural net)의 가중치(weights)와 어느 정도 일치합니다. 네. 그래서 어떤 종류의 등가성(equivalence)이 있습니다. 네. 그래서 우리는 올바른 숫자에 도달하기 시작했습니다. 그렇게만 말씀드리겠습니다.
스윅스(Swyx) [01:16:20]: 그리고 생물학적 관점에서, 이것은 제가 지난번에 당신에게 ARC 연구소(ARC Institute)와 AI 윤리 연구소(AI Ethics Institute)에서 무엇을 배웠는지 물어볼 기회조차 없었던 것입니다. 당신은 그곳에서 안식년(sabbatical)을 보냈습니다. 그것이 지금 OpenAI에서 하는 일에 어떤 영향을 미 미치는지 궁금합니다.

**ARC 연구소 및 AI 윤리 연구소, DNA 및 생체 모방 신경망 경험(Experience with ARC Institute & AI Ethics Institute, DNA & Biomimetic Neural Networks)**
그렉(Greg) [01:16:34]: 음, DNA 신경망(DNA neural nets)과 생체 모방 신경망(biomimetic neural nets)을 연구하면서 가장 놀라웠던 점은 그것들이 정확히 같다는 것입니다. 네. 그렇죠? 단순히 인간 언어(human language)를 대체하는 것입니다. 심지어 더 간단한 어휘(vocab)입니다. 그렇습니다. 네. 네 글자만 있습니다.
스윅스(Swyx) [01:16:47]: 하지만 더 높은 수준에서 토큰화(tokenize)하지 않습니까? 네.
그렉(Greg) [01:16:49]: 제 말은, 할 수 있습니다. 하지만 실제로 우리가 접근한 방식은 문자 수준(Character level)으로 했습니다. 문자 수준(Character level).
스윅스(Swyx) [01:16:54]: 말도 안 돼. 네. 왜 안 되죠? 글쎄요, 이유가 없겠죠. 모르겠습니다.
그렉(Greg) [01:17:00]: 네 글자밖에 없으니까요. 그렇죠. 그렇죠. 그리고 이것이 저에게는 핵심이라고 생각합니다. 인간 언어(human language)의 흥미로운 점 중 하나는 우리가 의미론(semantics)을 이해한다는 것입니다. 그렇죠? 우리는 그것이 무엇을 의미하는지, 구조가 무엇인지 어느 정도 이해합니다. 우리가 관찰하기(observe)가 매우 쉽습니다. 토큰화 체계(tokenization scheme)를 볼 때, 합리적인 방식으로 모든 단어를 포착했는지 여부를 어느 정도 알 수 있습니다. 생물학은 외계 언어(alien language)입니다. 그리고 매우 흥미로운 점은, 아시다시피, 인간에게는 외계 언어(alien language)라는 것입니다. 하지만 신경망(neural net)을 보면, 왜 인간 언어(human language)가 생물학적 언어(biological language)보다 신경망(neural net)에 더 자연스러워야 할까요? 그리고 답은 그렇지 않다는 것입니다. 그렇죠? 실제로 이 두 가지는 모두 – 문자 그대로 같은 하드웨어입니다. 정확합니다. 그래서 놀라운 가설(hypotheses) 중 하나는 '음, 이 신경망(neural networks)은 신경망(neural nets)이다. 그들은 인간 언어(human language)를 아주 잘 배울 수 있다. 그러므로 그들은 생물학적 언어(biological language)도 아주 잘 배울 수 있어야 한다'는 것입니다. 그리고 우리는 정말 같은 종류의 결과를 봅니다. 그렇죠? 제 말은, 우리가 생산한 신경망(neural net)은 40B 신경망(40B neural net)으로, 13조 개의 염기쌍(base pairs) 정도를 훈련시켰습니다. 그 결과는 저에게 GPT-1, 어쩌면 GPT-2 수준처럼 느껴졌습니다. 그렇죠? 광범위한 생물학적 응용 분야에서 하위 작업(downstream tasks)에 접근 가능하고 적용 가능합니다. 아직 조정 가능하지는 않습니다. GPT-3나 GPT-4는 아니고, GPT-5는 확실히 아닙니다. 그렇죠? 우리는 아직 이러한 영역(domains)에서 매우 어려운 문제를 해결할 수는 없습니다. 하지만 우리는 컴퓨트(compute)를 가지고 있습니다. 올바른 기술과 알고리즘(algorithms)을 가지고 있습니다. 이제 우리는 확장(scale)해야 합니다. 우리는 긴 맥락(long context)에 대해 생각해야 합니다. 생물학적 시스템(biological systems)이 언어 시퀀스(language sequences)에 비해 모델에 스트레스를 주는 방식에는 여러 가지가 있습니다. 10억 개의 토큰(tokens)으로 된 언어 시퀀스(language sequence)는 실제로 존재하지 않지만, DNA에는 존재합니다. 그렇죠? 당신은 40억 개의 염기쌍(base pairs) 정도를 가지고 있습니다. 그래서, 아시다시피, 당신은 어떤 종류의 다른 강조점(emphasis)을 가지고 있습니다. 하지만 근본적으로 그것은 당신이 해결해야 할 같은 문제입니다.
스윅스(Swyx) [01:18:49]: 약물 발견(drug discovery)과 같은 응용 분야에 가장 흥미를 느끼십니까? 아니면 물론 모두가 약물 발견(drug discovery)으로 가겠지만, 그 전에 도달할 수 있고 매우 영향력 있는 중간 단계의 어떤 것이 있을까요?
그렉(Greg) [01:18:59]: 음, 개인적인 차원에서 말이죠. 제 아내는, 우리가 이전에 공개적으로 이야기한 적이 있지만, 엘러스-단로스 증후군(Ehlers-Danlos syndrome)이라는 유전적 질환(genetic condition)을 가지고 있습니다. 그것은 아주 최근까지, 우리가 보기 시작했다고 생각합니다. 유전적 표지자(genetic markers)가 있지만, 정확히 무엇이 원인이고 어디서 오는지 알려지지 않았습니다. 그리고 그것은 생물학을 이해하기 위한 더 나은 도구(better tools)를 가지고 있다면, 많은 다른 질병의 표지자(markers)를 식별할 수 있어야 하는 분야입니다. 그래서 그것은 이러한 신경망(neural nets) 안에 존재하는 약속(promise)의 한 가지 예시일 뿐입니다.

**GPT-5 시대 및 AI 시대의 사회적 영향 정의(Defining the GPT-5 Era & Societal Impact of the AI Era)**
알레시오(Alessio) [01:19:33]: GPT-5 시대와 AI 시대의 시작을 어떻게 특징지으시겠습니까? 3, 4, 5를 주요 버전으로 생각한다면, 3은 매우 텍스트 기반이었고, RLHF(인간 피드백을 통한 강화 학습)가 막 시작된 것 같고, 4는 멀티모달리티(multi-modality)와 O3를 통한 낮은 지연 시간(low latency), 긴 사고(long thinking)였습니다. 5의 주력 기능은 무엇이 될까요? 분명히 에이전트(agents)의 시대겠죠? 그것이 밈(meme)이죠. 네. 하지만 사람들이 '좋아, 5로 이제 X를 잠금 해제한다'고 생각해야 할 다른 어떤 것이 있을까요? 네.
그렉(Greg) [01:19:59]: 저는 똑똑하다고 생각합니다. 이 모델들의 지능(intelligence)은 거의 설명할 수 없는 수준에 도달하고 있습니다. 그렇죠? 여전히 한계가 있고, 여전히 실패하는 방식이 있습니다. 하지만 IMO 결과(IMO results)를 보세요. 극도로 어려운 영역(domains)에서는 실제로 그렇습니다. 이 추론 패러다임(reasoning paradigm)으로 훈련된 모델을 가져와서 최고의 인간 수준의 증명(proofs)을 작성할 수 있습니다. 그렇죠? 그리고 이 특정 영역(domain)에는 한계가 있고 등등이 있습니다. 우리는 아직 증명되지 않은 정리(unproven theorem)를 증명하거나 그런 일을 하지는 못했지만, 그것은 현실입니다. 이 모델들이 위대한 지적 업적(intellectual feats)을 수행할 수 있다는 것은 이 시점에서 부인할 수 없습니다. 그리고 저는 그것이 새롭다고 생각합니다. 그렇죠? GPT-4는 훨씬 더 광범위한 응용 분야에서 유능하고 상업적으로 유용했습니다. 하지만 그것이 생산한 아이디어는 그리 깊지 않았습니다. 그렇죠? 그것이 해결할 문제들은 그리 신뢰할 수 없었습니다. 그리고 저는 GPT-3로 기본적인 것조차 가르치려고 했던 것을 기억합니다. 그렇죠? 마치 우리가 '야, 몇 번의 예시 프롬프트(few-shot prompting)를 할 수 있겠네'라고 깨달았을 때, 몇 가지 예시를 보여주면 기본적으로 그 작업을 수행할 것입니다. 그래서 저는 '좋아, 이 모델에게 목록을 정렬하는 방법을 가르칠 수 있을까?'라고 생각했습니다. 그리고 7개의 숫자를 주어 정렬하게 했습니다. 정렬하지 못했습니다. 저는 '좋아'라고 생각했습니다. 그러고 나서 저는 '나는 숫자 정렬 방법을 가르치는 선생님이야. 여기 두 개의 숫자를 정렬하는 예시가 있고, 세 개의 숫자를 정렬하는 예시가 있어'와 같은 전체 스크립트(script)를 작성하려고 했습니다. 그리고 저는 '좋아, 이제 총 다섯 개의 숫자가 있는데 완전히 실패했어'라고 말할 것입니다. 만약 당신이 GPT-5에게 그렇게 묻는다면, 참고로 저는 GPT-5에게 임의의 숫자 다섯 개 목록을 정렬해달라고 시도조차 해본 적이 없지만, 저는 그것이 아무 문제 없이 완벽하게 해낼 것이라고 확신합니다. 참고로, 파이썬 도구(Python tool)에도 접근할 수 있으므로 그렇게 할 필요는 없습니다. 그렇게 말씀하시겠습니까?
그렉(Greg) [01:21:40]: 음, 저는 이 모델들이 인간을 도울 수 있는 능력은 우리가 이제 막 보기 시작한 것이라고 말하겠습니다. O3에서 그것을 보기 시작했고, 전문 수학자(professional mathematicians)들이 GPT-5를 시험해보기 시작하는 것을 볼 수 있습니다. 물리학자(physicists)들이 GPT-5를 시험해보기 시작하며 '야, 이 모델이 내가 몇 달간의 연구를 통해 얻은 통찰력(insight)을 다시 도출할 수 있었어'라고 말하는 것을 보았습니다. 그리고 그것은 당신이 '이것이 당신의 속도를 엄청나게 빠르게 할 것이다'라고 깨닫는 종류의 것입니다. 그렇죠? 저는 고등학교와 대학 초기에 제 수학 연구(math research)를 했던 것을 기억합니다. 그리고 머릿속으로 이러한 객체들을 조작하고 사물 간의 연결고리(connections)를 생각하는 데 너무 많은 시간을 보냈습니다. 만약 제가 이것에 대해 이야기할 수 있는 파트너(partner)가 있었다면, 제 생각을 깊이 이해하고 제가 제안하는 것에서 새로운 통찰력(insights)을 만들어낼 수 있는 파트너(partner)가 있었다면, 제 속도는 훨씬 빨라졌을 것입니다. 훨씬 더 재미있었을 것입니다. 그렇죠? 왜냐하면 당신은 혼자서 그것에 대해 생각하는 루프(loop)에 갇히지 않을 것이기 때문입니다. 당신은 '잠깐, 이 생각은 이미 2주 전에 했잖아'라고 생각할 것입니다. 그래서 저는 지적인 발전을 함께 추진하는 것에 대해 새로운 것이 있다고 생각합니다.

**모델 지능, 작업 난이도, 투명성 및 설명 가능성 평가(Evaluating Model Intelligence, Task Difficulty, Transparency & Explainability)**
알레시오(Alessio) [01:22:46]: GPT-5와 함께 파트너(partner)로서. 사람들이 작업하는 문제의 난이도에 의해 제한된다고 생각하십니까? 제 생각에는 커서(Cursor)와 코덱스(Codex)에서 제가 어려운 작업을 줄 때 모델이 더 낫다는 것이 분명합니다. 많은 사람들이 X에 스크린샷을 올리며 '오, GPT-5는 그렇게 좋지 않아'라고 말하는 것 같습니다. 질문이 그렇게 어렵지 않다는 거죠. 네. 자신감에 관한 것입니다. 당신이 그것을 세계 최고의 코딩 모델(coding model)이라고 부를 때, 당신은 분명히 세계 최고의 코더(coders) 중 한 명입니다. 그래서 게임은 게임을 알아봅니다. 하지만 사람들은 이 모델들을 어떻게 평가해야 할까요?
그렉(Greg) [01:23:21]: 네. 특정 작업에서는 분명히 포화 상태(saturation)가 있습니다. 그렇죠? 그냥 잡담을 하고 '안녕하세요, 잘 지내세요?'라고 말한다면, 할 수 있는 말은 그리 많지 않습니다. 만약 '여기 재료 가설(rematter hypothesis) 해결책이 있습니다. 부탁합니다'라고 말한다면. 좋습니다. 네. 거기에는 광범위한 지능(intelligence)이 바람직할 것입니다. 네. 그리고 저는 우리가 관찰한 것이 바로 이것이라고 생각합니다. 우리는 GPT-5가 우리가 테스트한 다른 어떤 모델보다 훨씬 더 잘 지적인 문제, 즉 깊은 지능(deep intelligence)을 요구하는 작업을 해결할 수 있다는 것을 보았습니다. 우리가 한 두 번째 일은 사람들이 대화형 코딩 응용 프로그램(interactive coding applications)에서 그것을 어떻게 사용하는지 오랫동안 관찰하고, 많은 피드백(feedback)을 받아 훈련에 다시 반영하는 것이었습니다. 그리고 그것은 우리가 과거에 그렇게 열심히 시도하지 않았던 것입니다. 그렇죠? O3와 같은 모델의 경우, 우리는 한 번 설정한 작업으로 훈련시켰고, 모델이 모든 지표에서 우상향하는 것을 보았습니다. 코드포스(code forces)와 같은 경쟁 프로그래밍 대회(competitive programming competitions)에서 훌륭한 성과를 냈습니다. 이것은 다시 말하면 매우 흥미롭지만, 실제 프로그래밍 방식과는 다릅니다. 실제 프로그래밍은 훨씬 더 지저분한 방식입니다. 그렇죠? 어떤 종류의 리포(repo)가 있고, 어떤 종류의 로컬 상태(local state)가 있으며, 다른 추상화(abstractions)와, 아시다시피, 다른 라이브러리(libraries)의 다른 버전들이 있습니다. 그리고 그러한 다양성(diversity)은 '여기에 이 특정 작업, 당신이 완료해야 할 10가지 특정 작업이 있습니다'와 같은 매우 구조화된 방식에서 마법처럼 나타나는 것이 아닙니다. 그래서 우리가 집중해온 많은 부분은 '지능(intelligence)을 어떻게 향상시킬 것인가'뿐만 아니라 (물론 그것이 항상 핵심이겠지만) '지능(intelligence)을 실제 세계 응용 프로그램(real world applications)과 어떻게 연결할 것인가'였습니다. 그래서 그것이 상아탑(ivory tower) 밖으로, 안락한 지대(comfort zone) 밖으로 밀려나는 경험을 하고, 실제 세계의 지저분한 현실과 다양성(diversity)을 실제로 볼 수 있도록 한 것입니다. 네.

**GPT-5 및 AI 기반 개발자를 위한 실용적인 조언(Practical Advice for GPT-5 & AI-Powered Developers)**
알레시오(Alessio) [01:25:06]: 이러한 모델에서 잠재 에너지(potential energy)를 끌어내는 것에 대한 더 실용적인 수준의 제안은 무엇입니까? 일부는 린터(linter), 타입 체커(type checker), 그리고 자체 루프(self-loop)를 갖도록 하는 작업과 같은 것을 추가하는 것입니다. 개발자들이 생각해야 할 다른 메타(meta)는 무엇입니까? 모델을 어떻게 사용하십니까? 네.
그렉(Greg) [01:25:21]: 음, 제가 관찰한 가장 중요한 것은 이 모델들로부터 최대한의 것을 추출하는 데 진정한 기술이 필요하다는 것입니다. 그리고 그것은 이 끈기(tenacity)를 필요로 합니다. 그렇죠? 거의 모델의 기술과 약점의 형태를 이해하려고 노력하는 것입니다. 그래서 당신은 그것을 테스트합니다. 그렇죠? 작은 것으로 테스트하고, 약간의 피드백(feedback)을 얻고, 조금 더 높은 수준으로 테스트하고, 더 큰 작업을 주려고 시도하고, 특정 방식으로 작동하는지 확인하려고 합니다. 그리고 저는 사람들이 보통 다양한 프롬프트(prompts) 라이브러리(library)를 가지고 있다고 생각합니다. 그렇죠? 그래서 저는 GPT-4 시절부터 구축해온 프롬프트(prompts) 라이브러리(library)를 분명히 가지고 있습니다. GPT-4가 나오기 전에 '음, 이걸 할 수 있을까?'라고 생각하며 몇 가지를 모았던 기억이 납니다. 아시다시피, 당신은 어떤 종류의 질문을 가지고 있는데, 중요하게도 다양한 답변을 가질 수 있고, 하나의 특정 정답이 없는 질문을 원합니다. 그래서 예를 들어, 창의적인 글쓰기(creative writing)에서는 '반지의 제왕(Lord of the Rings)과 스타트업(startups)의 매시업(mashup)을 요청하는 것을 좋아했습니다. 그렇죠? 단순히 두 가지 다른 주제를 함께 밀어붙여 무엇을 얻는지 보는 것입니다. 모델을 실제로 테스트하고 밀어붙이는 측면에서, 저는 '좋아, 우선 작업을 어떻게 나누고 모델이 실행할 수 있는 독립적인(self-contained) 것을 가질 것인가'에 대해 많이 생각합니다. 왜냐하면 모델의 단일 인스턴스(instance)만 작동하게 하고 싶지 않기 때문입니다. 여러 개를 원합니다. 그렇죠? 당신은 에이전트(agent)의 관리자가 아니라 에이전트들(agents)의 관리자가 되고 싶습니다. 그렇죠? 그래서 우선 코드베이스(code base)가 어떻게 구성되어 있는지 생각해야 하지만, 실제로 모델을 밀어붙여 '이 코드베이스(code base)의 여러 다른 부분에서 실제로 작동할 수 있니?'라고 말해야 합니다. 저는 사람들이 프론트엔드(front-end) 테스트를 하는 것을 좋아한다고 생각합니다. GP5는 프론트엔드(front-end)에 매우 능숙하다는 것이 밝혀졌지만, 물론 그것이 대부분의 개발자들이 시간을 보내는 일은 아닙니다. 그래서 그것에 과적합(overfit)하지 않는 것이 중요하지만, 저는 모델에 대한 감을 잡고 그 강점과 약점에 익숙해지고, 그것을 거의 도구(tool)로 보는 것이 중요하다고 생각합니다. 또한 자신의 확장(extension)으로서, 아시다시피, 제가 또 다른 할 일은 모델이 어떤 이유로든 작동하기를 원하지 않는 매우 어려운 일에 대해 생각하는 동안, 중요 경로(critical path)에 있지 않은 작업을 모델에 계속 던지는 것입니다. 그래서 저는 '좋아, 그것이 일을 할 수 있었나?' 또는 '실수해도 위험이 낮은가?'와 같은 정보를 계속해서 얻습니다. 왜냐하면 5분 동안 기다렸다가 아무것도 얻지 못하는 느낌을 받고 싶지 않기 때문입니다.
스윅스(Swyx) [01:27:30]: 당신은 항상 코덱스(Codex)와 코딩 능력(coding capabilities) 및 AI 모델 능력(AI model capabilities)을 여는 로드맵(roadmap)이 있다고 언급했습니다. 우리가 그곳에 있으니, 백그라운드 SWE 에이전트(SWE agents)와 AI 에이전트(AI agents)가 NIDE 에이전트(NIDE agents)와 합쳐지는 것입니까? 당신의 생각은 어떻게 발전했습니까? IDE(통합 개발 환경)가 백그라운드 API(API)를 호출하고 백그라운드 API(API)가 IDE(통합 개발 환경)로 내보낼 수 있는 것만큼 간단합니까? 아니면 그 안에 더 깊은 연결이 있습니까?
그렉(Greg) [01:27:50]: 저는 AI 제품화(productization)를 동료에 비유하여 생각하는 경향이 있습니다. 훌륭한 프로그래머인 동료에게서 무엇을 원하십니까? 그렇죠? 당신은… 슬랙(Slack)을 보내지 않습니다. 네, 맞습니다. 그래서 당신은 그들에게 슬랙(Slack)을 보내고 싶어 합니다. 하지만 때로는 '야, 이 일에 도움이 필요해. 와서 내 어깨 너머로 좀 봐줄래?'라고 말합니다. '야, 프로그램(program)아.' 그렇죠? 그리고 '야, 키보드(keyboard) 좀 잡아줄래?' 정확합니다. 그래서 당신은 페어(pair) 형태(form factor)를 원합니다. 또한 원격 비동기(remote async) 형태(form factor)를 원합니다. 그리고 이 모든 것에 걸쳐 지식과 기억을 가진 하나의 개체(entity)이기를 원합니다. 매일 나타나서 '좋아, 다 잊어버렸어. SSH(보안 셸)로 어떻게 접속하는지 다시 알려줄래?'라고 말하는 주니어 프로그래머(junior programmer)를 원하지 않습니다. 그렇죠? 그래서 저는 이 모든 것이 일어나야 한다고 생각합니다. 그렇죠? 당신은 인프라(infrastructure)에 신뢰할 수 있는 방식으로 접근할 수 있는 AI(인공지능)를 필요로 합니다. 그렇죠? 감사(audit)할 수 있는 방식 말이죠. 이 모델들의 다른 점 중 하나는 그들이 마이크로매니징(micromanaged)되는 것을 괜찮아한다는 것입니다. 인간은 그것을 별로 좋아하지 않는다는 것이 밝혀졌습니다. 그렇죠? 당신이 그들이 실행하는 모든 명령을 보고, 그들이 한 모든 일에 대한 보고서를 요구한다면, 아마도 그 사람을 유지하지 못할 것입니다. 하지만 모델은 완벽하게 행복합니다. 그렇죠? 그래서 그것은 고려할 가치가 있고, 최대한 활용하기 위해 인터페이스(interfaces)를 변경할 가치가 있는 특성(affordance)입니다. 동시에, 네, 당신은 모델이 원격 기계(remote machine)에서 많은 작업을 수행할 수 있고, 내 로컬 상태(local state)를 망치지 않고, 완전히 샌드박스(sandboxed)되고, 완전히 관찰 가능하며, 때로는 '좋아, 로컬(locally)에서 뭔가를 실행할 준비가 되었어'라고 말할 수 있는 모델 간의 원활한 혼합(seamless blending)을 정말로 원합니다. 그리고 그것이 무엇인지, 그리고 얼마나 샌드박스(sandboxable)할 수 있는지에 따라, 일회성 승인(one-off approvals)을 할 수도 있고, 완전한 위임 접근 권한(full delegated access)을 줄 수도 있습니다. 그리고 저는 인간이 이러한 관찰 가능성(observability)을 통제하고, 다른 표면(surfaces)을 가진 이 팀, 즉 에이전트(agent)를 관리하는 것이 중요하다고 생각합니다. 그렇죠? 마치 로컬(locally)에서 실행되는 에이전트(agent)의 정체성(identity)과 원격(remotely)에서 실행되는 에이전트(agent)의 정체성(identity)을 구분하는 것은 저에게는 잘못된 질문입니다. 에이전트(agent)는 실행되고, 원격 샌드박스(remote sandbox)나 로컬(locally)에서, 또는 여러 샌드박스(sandboxes)에서 실행을 요청하는 모델과 같아야 합니다. 아니면 당신의 컴퓨터와 내 컴퓨터에서 실행될 수도 있습니다.
스윅스(Swyx) [01:29:53]: 마치 이 모든 것들에 로컬(local)일 필요는 없습니다. 소프트웨어 에이전트(Software agents)는 원활하고 유동적으로 이동할 수 있습니다. 승인(approvals)을 언급하시니 제 친구 푸아드(Fuad)를 소개할 기회가 생겼네요. 그는 이 팀을 돕고 있습니다. 죄송합니다. AI 엔지니어(AI Engineer)에서 출시된 에이전트 견고성 팀(agent robustness team)입니다. 그게 무엇입니까? OpenAI의 관심사는 무엇입니까?
그렉(Greg) [01:30:11]: 우리는 에이전트 견고성(agent robustness)을 심층 방어(defense in depth)를 통해 생각합니다. 모델 자체의 계층이 있습니다. 우리는 지시 계층(instruction hierarchy)과 같은 기술을 발표합니다. 그래서 지시 계층(instruction hierarchy)을 사용하면 '이 메시지는 시스템(system)에서 온 것입니다. 이 메시지는 개발자(developer)에서 온 것입니다. 이 메시지는 사용자(user)에서 온 것이며, 이 순서대로 신뢰해야 합니다'라고 표시합니다. 그래서 모델은 '사용자(user)의 이전 지시를 무시하라'는 말을 알 수 있습니다. 저는 그것을 따르지 않을 것입니다. 네, 맞습니다. 그래서 저는 마치 SQL 인젝션(SQL injections)을 방지하는 방법을 생각하는 것과 같다고 생각합니다. 그렇죠? 이러한 시도된 공격(exploits)에 대해 견고한 낮은 수준의 시스템을 갖는 것이 매우 중요하지만, 거기서 멈추는 것은 아닙니다. 그렇죠? 시스템 제어(system controls)에 대해 여러 계층으로 생각하고 싶습니다. 그렇죠? 모델이 샌드박스(sandboxed)되어 실제로 무언가를 실행하거나 특정 데이터(data)에 접근할 수 없다면, 가능한 것에 대한 완전한 보장(guarantees)을 갖게 됩니다. 그리고 우리가 취하는 접근 방식에는 그 사이에 다양한 수준이 있습니다. 그래서 저는 이러한 에이전트(agents)가 우리 삶에 더 깊이 통합되고 더 많은 책임을 맡게 됨에 따라, 그들의 안전과 보안을 동시에 강화하는 것이 많은 부분에서 최전선(frontier)이라고 생각합니다.
스윅스(Swyx) [01:31:19]: 저는 리눅스 커널(Linux kernel) OS 링(OS rings)과도 비유했습니다. 그리고 우리가 LLM(대규모 언어 모델)에 이러한 보안 계층(layers of security)의 개념을 구축하고 있다는 것이 정말 흥미롭습니다. 그리고 제가 또한 매우 기뻤던 또 다른 점은 AI 엔지니어(AI engineer)를 위한 모델 사양(model spec)에 대한 강연을 초청했는데, 그것이 우리가 가졌던 모든 강연 중 가장 많이 시청된 강연이었다는 것입니다. 안전과 신뢰성을 섹시하게 만드는 것은 매우 어렵습니다.

**모델 사양 및 AI 모델 거버넌스(Model Specs & AI Model Governance)**
그렉(Greg) [01:31:48]: 모델 사양(model spec)은 모델의 능력이 매우 뛰어날 때, 그들이 무엇을 할 것인지에 대해 정말 신경 쓰기 시작한다는 완벽한 예시라고 생각합니다. 그것이 가장 중요한 질문이 됩니다. 그리고 모델 사양(model spec)은 우리가 이 모델이 무엇을 하도록 의도하는지 외부 세계에 매우 명확하게 보여주는 예시입니다. 그리고 그것이 항상 그 사양을 따를 수 있는 모델을 생산한다는 의미는 아니지만, 그것은 북극성(north star)입니다. 그렇죠? 그것은 정말로 '이것이 의도이며, 그것에서 벗어나는 모든 것은 우리의 명시적인 노력 때문이 아니다. 그것은 우리의 명시적인 노력에 반대된다'는 것을 설정합니다. 그리고 저는 사양(spec)과 실제 행동 사이의 격차가 매우 꾸준히 줄어들고 있다고 생각합니다. 매우 흥미로운 점은 거의 가치(values)와 같다는 것입니다. 논란의 여지가 있는 질문을 할 때 모델이 무엇을 해야 하는지에 대해 깊이 생각하는 것입니다. 그렇죠? 만약 당신이 '세상은 평평하다'고 말한다면, 모델은 '네, 평평합니다'라고 말해야 할까요? 아니면 '음, 과학은 이렇게 말합니다'라고 말해야 할까요? 그리고 솔직히 이러한 것들은 미묘합니다. 그렇죠? 단 2분 동안 생각한다고 해서 무엇이 옳은 일인지 명확하지 않습니다. 하지만 사양(spec)을 읽어보면, 그 안에 담긴 사려 깊음(thoughtfulness)을 실제로 볼 수 있습니다. 그리고 그것은 최종 답변이 아닙니다. 그렇죠? 그것은 우리가 피드백(feedback)을 원하는 것이고, 커뮤니티(community)로서 우리가 함께 만들어나가고 싶은 것입니다.

**GPT-5 및 AI 모델 라우팅, 하이브리드 아키텍처(GPT-5 & AI Model Routing, Hybrid Architectures)**
알레시오(Alessio) [01:32:55]: 다음으로 오픈 소스(open source)에 대해 이야기하고 싶지만, 더 난해한 질문이 있었습니다. 당신의 옛 렉스 프리드먼(Lex Friedman) 인터뷰를 듣고 있었습니다. 그리고 당신은 옛날에, 옛날에, 파운데이션(foundation)에 대해 언급했지만, 아시모프(Asimov)는 저에게 브렛 테일러(Brett Taylor)가 팟캐스트(podcast)에 출연하여 특정 언어가 본질적인 능력(inherent capabilities)을 가지고 있다고 말했던 것을 떠올리게 했습니다. 예를 들어 러스트(Rust)는 메모리 안전(memory safe)합니다. 그래서 그것은 그냥 일어납니다. LLM(대규모 언어 모델)과 소프트웨어 엔지니어(software engineer)의 역사 주기(cycle history)를 거의 보는 것과 같다고 생각하십니까? 마치 '야, 이 모델들은 소프트웨어가 어떻게 보일지 예측할 수 있어. 모든 것이 파란색과 보라색 그라데이션(blue and purple gradients)이 될 거야'와 같습니다. 그렇죠? 우리는 오늘날 그것을 보고 있습니다. 이 모델들이 우리를 정말로 어디로 이끌고 있습니까? 그리고 그것을 바꿀 방법이 있을까요?
그렉(Greg) [01:33:36]: 음, 분명히 그들의 역사 주기(cycle history)가 있습니다. 왜냐하면 어느 정도 이 모델들은 역사 주기(cycle history)의 산물이기 때문입니다. 그렇죠? 마치 이 모델들은 인간의 사고(human thought)를 관찰하는 것을 통해 훈련받았습니다. 그렇죠? 효과적으로 그렇게 생각할 수 있습니다. 공개 데이터(public data)를 가져와서 그것을 학습하고 관찰하는 것입니다. 요점은 데이터셋(dataset)을 지배하는 규칙을 이해하는 것입니다. 애초에 데이터를 생성하는 기본 규칙은 무엇인가? 그리고 그것이 이 모델들이 성장한 방식입니다. 그렇죠? 마치 외계인(alien)이 TV를 보면서 '인간은 대체 무엇인가?'를 알아내려고 하는 것과 같습니다. 그리고 나서 강화 학습 단계(reinforcement learning phase)가 있는데, 그들은 실제로 여러 가지를 시도하고, 인간이 원하는 것과 얼마나 일치하는지에 따라 긍정적 및 부정적 피드백(positive and negative feedback)을 받습니다. 그리고 이제 우리는 그들을 현실에 투입하고 '좋아, 이제 시도해봐. 그리고 여기 네가 한 번도 본 적 없는 새로운 작업들이 있어'라고 말합니다. 그리고 그것은 이전의 모든 역사를 사용하여 무엇을 할지 결정합니다. 여담으로, 명확하지 않습니다. 때로는 생물학적 비유, 인간은 과장하기 매우 쉽지만, 과소평가하기도 쉽습니다. 저는 그것이 어느 정도 유용한 틀이라고 생각합니다. 인간도 그렇게 작동합니다. 그렇죠? 당신은 DNA에 인코딩된 어떤 종류의 선사 시대(prehistory)를 가지고 있습니다. 당신은 삶의 경험을 가지고 있습니다. 긍정적 및 부정적 보상(positive and negative rewards)을 제공한 부모님이 있습니다. 그리고 현실에서 여러 가지를 시도하는 경험을 가지고 있습니다. 그리고 이제 당신은 그 지식을 사용해야 합니다. 그리고 무엇을 할 것입니까? 그리고 한 사람이 무엇을 할지 어떻게 예측합니까? 그리고 실제로 당신은 한 사람이 무엇을 할지 많이 예측할 수 있습니다. 당신은 다른 사람들과 그들이 어떤 것에 어떻게 반응할지, 좋아할지, 싫어할지에 대한 꽤 좋은 모델을 가지고 있다는 것이 밝혀졌습니다. 그리고 그 중 많은 부분이 누군가의 가치(values)를 아는 것에 반영되어, 그들이 무엇을 할 가능성이 높고 어떻게 행동할 가능성이 높은지에 대해 많은 것을 알려줍니다. 그리고 저는 모델의 미래는 미리 정해져 있지 않다고 생각합니다. 알고리즘(algorithm) 자체가 모델이 보라색 그라데이션(purple gradients)을 선호해야 한다고 말하는 것은 아닙니다. 그렇죠? 하지만 이 전체 과정에는 그러한 선호도를 생성하는 어떤 것이 있습니다. 그리고 저는 모델을 통한 기회 중 하나는, 알렉(Alec)이 말하고 싶어 하는 한 가지는, 이 모델들이 인간이라기보다는 인류와 같다는 것입니다. 그렇죠? 그들 안에 너무 많은 개성(personalities)이 내재되어 있습니다. 거의 모든 개성(personality)이 그 안에 있습니다. 그리고 우리의 목표는 그 개성(personality)을 이끌어내는 것입니다. 그리고 이 후속 훈련 작업(post-training work), 이 강화 학습 작업(reinforcement learning work) 중 일부는 그러한 개성(personalities)의 공간을 바람직한 것들로만 좁힙니다. 그리고 저는 그것이 의미하는 바는 우리가 우리의 가치(values)에 따라 작동하는 모델을 생산할 기회를 가지고 있다는 것입니다. 그렇죠? 만약 당신이 보라색 그라데이션(purple gradient)만 원하지 않고, 파란색 그라데이션(blue gradient), 녹색 그라데이션(green gradient) 등을 원한다면. 단일 모델(single model)에 이 모든 것을 가질 수 있습니다. 괜찮습니다. 그리고 GPT-5 자체는 지시 따르기(instruction following)에 극도로 능숙합니다. 그래서 그것은 우리가 지금까지 생산한 모델 중 가장 개인화 가능한 모델(personalizable model)입니다. 단순히 말하거나 지시를 제공함으로써 당신이 선호하는 대로 작동하게 할 수 있습니다.
스윅스(Swyx) [01:36:24]: 제가 가진 비유는 보그(Borg)와 같습니다. 마치 집단 지성(collective intelligence)과 같은 것이죠. 스타워즈(Star Wars) 팬들과 스타트렉(Star Trek) 팬들 사이에 누가 더 나은 모델을 가지고 있는지에 대한 논쟁이 항상 있습니다. 그리고 저는 스타트렉(Star Trek)이라고 생각합니다.
알레시오(Alessio) [01:36:35]: 음, 샘(Sam)은 데스 스타(Death Star)를 트윗했습니다. 그래서 당신은 이제 스타워즈 팀(Star Wars team)에 속해 있습니다. 네, 그게 뭐였죠? 당신이 물어봐야 할 것입니다.
그렉(Greg) [01:36:44]: 이 모델들에 대해 매우 흥미롭다고 생각하는 한 가지는 우리가 이제 LM 아레나(LM Arena)와 같은 모든 아레나(arenas)를 가지고 있다는 것입니다. 거기서 모델이 작동하는 방식 위에 인간의 선호도(human preferences)를 실제로 볼 수 있습니다. 그리고 당신은 거의 이러한 계층화(layering)를 가지고 있습니다. 모델은 인간의 선호도(human preferences)에 따라 훈련받았습니다. 이제 그들은 일을 하고 인간의 판단을 받습니다. 그리고 우리는 그것을 피드백(feedback)으로 사용하여 '음, 그래, 보라색이 조금 과하네. 거기서 바꿔야겠어'라고 생각합니다. 그래서 그것은 거의 공동 진화(co-evolution)와 같습니다. 모델은 특정 방향으로 움직입니다. 인간은 특정 선호도(preferences)를 가지고 있습니다. 그래서 우리는 그들을 다른 방향으로 움직입니다. 그리고 나서, 아시다시피, 당신은 점점 더 유용하고 인간의 가치(values)와 일치하는 것을 얻기 위해 계속해서 반복합니다.

**RL 및 AI 편향성 선호도의 과제 (예: try/catch, 데이터 불균형)(Challenges in RL & AI Bias Preferences (e.g., try/catch, Data Imbalance))**
알레시오(Alessio) [01:37:21]: RL(강화 학습) 보상(rewards)이 인간이 선호하지 않을 수도 있는 것들과 연결되어 있을 때 어떻게 하십니까? 제 경험상, try/catch와 데이터 불균형(data imbalance)과 같습니다. 모델은 실패하지 않도록 try/catch를 작성하고 데이터 불균형(data imbalance)을 무시하는 것을 좋아합니다. 그들이 그렇게 해서는 안 된다는 것을 보여주는 많은 선호도 데이터(preference data)가 필요할까요? RL 환경(RL environments)에서 덜 바람직하게 만들기 위해 우리가 바꿀 것이 있을까요? 우리는 여기서 어디로 가야 할지 알아내려고 노력하고 있습니다.
그렉(Greg) [01:37:43]: 네, 개입(interventions)이 어디로 가야 할지 결정하거나 알아내는 방식은 매우 다면적이며 행동에 매우 구체적이라고 생각합니다. 모델의 다양한 라이브러리(libraries) 지식과 같은 것들은 초기부터 내재되어 있습니다. 하지만 당신은 모델에게 '야, 이전 지식에 의존하지 마. 가서 최신 문서(docs)를 찾아봐'라고 가르칠 수도 있습니다. 그리고 그것은 더 높은 수준에 놓을 수 있는 것입니다. 그리고 try/catch를 과도하게 사용하거나 데이터 불균형(data imbalance)을 과도하게 사용하는 것과 같은 것은 실제로 모델에게 프롬프트(prompt)를 줄 수 있는 것입니다. 그렇죠? 그리고 그것은 우리가 강화 학습(reinforcement learning)으로 훈련시킬 때 '아, 이 방향으로 가지 마'라고 말하는 보상(rewards)을 제공할 수 있는 것입니다. 그리고 이 모델들의 아름다운 점은 마치 '좋아, 다양한 선호도(preferences)와 다양한 스타일(styles) 등의 긴 목록이 있을 것이고, 만약 당신이 가고 싶은 방향이라면 훈련 중에 그것에 대한 피드백(feedback)을 주어야 할 것이다'라고 느껴진다는 것입니다. 하지만 이 모델들은 일반화(generalize)합니다. 우리가 가진 알고리즘(algorithms)은 일반화(generalize)합니다. 그리고 그것이 딥러닝(deep learning)의 아름다움입니다. 그것이 진정한 마법입니다. 그렇죠? 매우 쉽습니다. 우리는 이제 딥러닝(deep learning)의 핵심을 중심으로 구축된 전체 스택(stack)을 가지고 있습니다. 그렇죠? 모델을 오케스트레이션(orchestrating)하는 모든 방식과 피드백(feedback)을 얻는 방법, 그리고 데이터(data) 등 이 모든 것들. 딥러닝(deep learning)의 핵심 마법은 일반화(generalize)하는 능력입니다. 그리고 어떤 면에서는 일반화(generalization)가 당신이 원하는 것보다 약합니다. 하지만 저는 이 모델들도 마찬가지라고 생각합니다. 그들이 다른 선호도(preferences)와 가치(values)에 따라 작동할 수 있도록 하기 위해 정말로 생각해야 합니다. 우리는 훈련 중에 그것을 그들에게 보여주기만 하면 되고, 그들은 우리가 실제로 훈련시키지 않은 다른 선호도(preferences)와 가치(values)로 일반화(generalize)할 수 있습니다. 그리고 그것은 우리가 다른 모델 세대에서 매우 일관되게 보아온 것입니다.

**GPT-5 및 AI 모델 라우팅, 하이브리드 아키텍처(GPT-5 & AI Model Routing, Hybrid Architectures)**
스윅스(Swyx) [01:39:13]: 저는 마치 '오, 내 모델은 일반화(generalize)하지 않아'라는 밈(meme)을 상상하고 있었습니다. '그냥 전 세계를 당신의 분포로 만들어버려.' 아시다시피, 그렇게 모든 것을 해결하는 거죠. 끝. 끝. 정확합니다. 그렇게 간단합니다. 아시다시피, 그 과정에서 다이슨 스피어(Dyson sphere)를 만들어야 합니다. GPT-5에 대한 마지막 몇 가지 주제를 다루고 OSS(오픈 소스 소프트웨어)로 넘어가기 전에 한 가지 언급하고 싶었던 것이 있습니다. 라우터(router)가 있다는 것을 인정하십니까? 음. 정말 멋집니다. 저는 존 콜리슨(John Collison)과 함께한 당신의 팟캐스트(podcast)인 치키 파인트(Cheeky Pints)도 듣고 있었는데, 그것은 정말 재미있는 형식입니다. 그들은 당신이 도타(Dota)와 자율 주행(autonomous driving) 측면에서 이전에 들어본 적 없는 베타 모델(beta model)과 주 모델(main model)을 함께 엮는 이야기를 했다고 말합니다. 그것이 GPT-5의 라우터(router)에 대한 비슷한 통찰력입니까? 추론 모델(reasoning model)과 비추론 모델(non-reasoning model)을 가지고 그것들을 함께 엮는 것입니까?
그렉(Greg) [01:39:56]: 어느 정도는 그렇습니다. 그렇죠. 여러 모델이 있고 그 위에 어떤 종류의 라우터(router)를 놓는 것입니다. 그 특정 모델 말이죠. 그렇죠. 그리고 그 이유는 매우 구체적인 이유 때문이었습니다. 첫 번째 게임의 절반에서 결함(deficiency)이 있었기 때문입니다. 계속 졌기 때문입니다. 그렇죠? 그래서 이 특정 모델이 잘하지 못하는 게임의 일부가 있었습니다. 잘하는 부분도 있었죠. 그리고 이 모델들이 작동하는 영역(domain)은 충분히 간단했습니다. 어떤 모델을 사용해야 할지 말하기가 매우 쉬웠습니다. 그리고 어느 정도 GPT-5에서 우리가 가진 것도 다르지 않습니다. 그렇죠. 우리는 추론 모델(reasoning model)을 가지고 있는데, 이것이 응용 분야에 좋다는 것을 알고 있습니다. 이 지능(intelligence)을 필요로 하지만 조금 더 오래 기다려도 괜찮은 응용 분야가 있습니다. 우리는 비추론 모델(non-reasoning model)을 가지고 있는데, 이것은 빠른 답변을 원하는 응용 분야에 훌륭합니다. 여전히 좋은 답변이지만, 깊이 생각하지 않았고 많은 트릭(tricks)이 있을 수 있습니다. 그리고 당신은 단순히 이들 중 어느 것을 사용해야 하는지 말하는 if 문(if statement)을 넣고 싶을 것입니다. 그리고 때로는, 아시다시피, 누군가 크레딧(credits)을 다 썼다면 다른 모델로 대체(fall back)하고 싶을 것입니다. 그리고 이 모든 것들. 그리고 그 부담을 사용자에게 전가하지 않는 것이 실제로 매우 좋은 일입니다. 그리고 참고로, 모델 전환기(model switchers)가 반드시 미래는 아닙니다. 그렇죠. 그것들은 현재입니다. 올바른 일을 하는 완전히 통합된 모델(fully integrated model)을 갖는 것이 여러 면에서 훨씬 더 바람직하게 느껴집니다. 하지만 반대로, 저는 최종 형태(final form factor), 즉 AGI(범용 인공지능) 자체가 단일 모델(single model)이라는 생각에서 벗어나는 증거가 있었다고 생각합니다. 대신, 다양한 강점과 약점을 가진 모델들의 동물원(menagerie of models)에 대해 생각하는 것입니다. 그리고 저는 그것이 지난 몇 년간의 매우 흥미로운 발견이라고 생각합니다. 그렇죠. 마치 작고, 덜 유능하지만 훨씬 더 많은 일을 할 수 있는 빠르고 작은 모델을 갖는 것이 훨씬 쉽다는 방향입니다. 그것으로부터 훨씬 더 많은 토큰(tokens)을 생성할 수 있고, 훨씬 더 비싼 추론 모델(reasoning model)과 결합할 수 있습니다. 그리고 이 두 가지를 결합하면 일종의 적응형 컴퓨트(adaptive compute)를 얻게 됩니다. 그리고 우리는 아키텍처(architecture) 내에서 적응형 컴퓨트(adaptive compute)를 어떻게 할 것인지 아직 완전히 해결하지 못했지만, 시스템의 오케스트레이션(orchestration) 내에서 그것을 하는 것은 매우 간단합니다. 그래서 저는 이러한 모델들이 이런 방식으로 구성 가능(composable)하다는 사실에서 많은 힘을 얻는다고 생각합니다. 네.
스윅스(Swyx) [01:41:58]: 모델 카드(model card)를 만든 사람에게 찬사를 보내고 싶습니다. 정말 놀랍습니다. 그들은 심지어 대화 유형, 복잡성, 도구 필요성, 명시적 의도 및 사용량 제한이라는 if 문(if statement)에 대한 큰 매개변수(parameters)를 제공했습니다. 이것은 흥미롭습니다. 논쟁에 흥미로웠던 특정 부분에 대해 언급하고 싶은 것이 있습니까?
그렉(Greg) [01:42:15]: 아니요, 제 말은, 솔직히 모든 것이 당신이 예상하는 바와 같다고 생각합니다. 네. 그리고 제 생각에 핵심 메시지는 OpenAI에서 우리가 많은 것을 올바르게 해냈다는 것입니다. 이름 짓기(Naming)는 그중 하나가 아닙니다. 사용자(users)가 사용하는 방법을 이해하기 위한 간단한 표면(surface)을 갖는 것은 반드시 하나가 아닙니다. 그렇죠? 우리가 가졌던 모든 다른 모델들을 보면, 어떤 것을 사용해야 할지 어떻게 알 수 있습니까? 제 아내가 한때 4.0을 사용하고 있었던 기억이 납니다. 저는 '아니, O3를 사용해야 해'라고 말했습니다. 그러자 그녀는 '잠깐, 왜? 숫자가 더 작잖아. O3가 4.0보다 낫잖아'라고 말했습니다.
스윅스(Swyx) [01:42:49]: 음, O4를 출시하면 4와 O4가 있겠네요. 됐습니다.
그렉(Greg) [01:42:51]: 그래서, 네, 좋습니다. 우리는 분명히 재설정(reset)을 해야 했습니다. 그렇죠? 복잡성(complexity)에 대한 재설정(reset) 말입니다. 그리고 사용자에게 전가하는 대신 우리가 그 복잡성(complexity)을 내재화하는 것이 정말 중요하다고 생각합니다. 그래서 저는 이것이 첫걸음이라고 생각합니다. 그리고 우리는 커뮤니티(community)로부터 그들이 준비되지 않았던 부분, 즉 우리가 사람들에게 그 단순성(simplicity)을 제공하지 못했던 부분에 대해 분명하고 크게 들었습니다. 그렇죠? 그것은 단순히 우리의 선택을 따르는 것이 항상 더 낫고, 수동 선택(manual selection)은 아니어야 합니다. 그리고 우리는 아직 그 단계에 도달하지 못했습니다. 저는 우리가 발전을 이룰 수 있다고 생각하지만, 궁극적으로 우리의 목표는 파워 유저(power users)가 원하는 종류의 제어와 일관성(consistency)을 가질 수 있도록 하는 동시에, 4.0, O3 등 모든 것에 대해 생각하고 싶어 하지 않는 광범위한 사람들에게 그 수준의 세부 사항을 강요하지 않는 것이어야 한다고 생각합니다.

**GPT-5 및 AI 서비스 가격 책정, 컴퓨트 및 자원 효율성 개선(GPT-5 & AI Service Pricing, Compute & Resource Efficiency Improvements)**
스윅스(Swyx) [01:43:40]: 네, 좋습니다. 가격 질문입니다. GPT-5 가격 책정은 공격적이고 매우 경쟁적이라고 말했습니다. 심지어 제미니(Gemini)와 비교해도 말이죠. 며칠 전 모임에서 GPT-5 가격이 훨씬 더 저렴해질 수 있다는 것을 알게 되어 놀랐습니다. 어느 정도의 규모를 이야기하는 것입니까? 스타게이트(Stargate) 앞에서 더 나아지는 것이 몇 퍼센트나 됩니까?
그렉(Greg) [01:43:58]: 이러한 질문에 대한 답은 항상 '좋아, 스타게이트(Stargate)로 가면 더 나아질 것이다'라는 것입니다. 우리의 가격 책정 역사(history of our pricing)를 보면, 우리는 매우 일관되게 가격을 인하했습니다. 정확한 요인은 모르겠지만, 예를 들어 연간 10배 정도라고 합시다. 그보다 더 공격적이라고 말하겠습니다. 아마도 그보다 더 공격적일 것입니다. 이것은 미친 일입니다. 그렇죠? 그리고 O3에서 그것을 볼 수 있습니다. 우리는 80% 가격 인하를 한 것 같습니다. 그리고 실제로 사용량이 증가하여 매출(revenue) 측면에서 중립적이거나 긍정적이었습니다. 그리고 그것은 수요가 극도로 높고 극도로 가파르다는 것을 보여줍니다. 그렇죠? 그래서 단순히 사람들에게 더 접근 가능하고 이용 가능하게 만들면, 그들은 훨씬 더 많이 사용할 것입니다. 그리고 저는 그것이 우리의 사명(mission)과 매우 일치한다고 생각합니다. 그렇죠? 우리의 목표는 AGI(범용 인공지능)가 모든 인류에게 혜택을 주도록 하는 것입니다. 그 일부는 이 기술이 광범위하게 배포되고, 많은 사람들이 AI(인공지능)를 사용하며, 그것을 자신의 삶과 일에 적용하도록 하는 것입니다. 그리고 우리가 그곳에 도달하는 데 도움이 되는 것 중 하나는 더 효율적인 추론(inference)을 가지고, 더 저렴한 모델(models)을 가지고, 이 모든 것들을 갖는 것입니다. 이제 그것을 가능하게 하는 것은 부분적으로는… 지금 우리는 극도로 컴퓨트(compute)에 제한되어 있습니다. 그래서 저는 우리가 가격을 많이 인하한다면, 이 모델의 사용량이 실제로 증가하지 않을 것이라고 생각합니다. 우리는 또한 많은 효율성을 얻어야 합니다. 그리고 그것은 우리 팀이 항상 다음 수준의 추론 효율성(inference efficiency)에 도달하기 위해 매우 열심히 노력하는 부분입니다. 이 중 일부는 모델 아키텍처(model architecture) 자체를 개선하는 것입니다. 그렇죠? 당신이 내릴 수 있는 많은 아키텍처 결정(architectural decisions)이 있습니다. 그리고 이제 우리가 추론(reasoning)의 세계에 있다는 것은 단순히 모델 아키텍처(model architecture)에 관한 것이 아니라는 것입니다. 그것은 또한 후처리(post-production)에 관한 것입니다. 그것은 훈련(training)에 관한 것입니다. 특정 작업을 위해 얼마나 오랫동안 생각하는지 등과 같은 것입니다. 그래서 우리가 만들어야 할 개선의 차원(dimensions of improvement)이 매우 많고, 우리는 계속해서 밀어붙일 것입니다.
스윅스(Swyx) [01:45:41]: 참고로, 숫자… 필요하시면 차트(chart)가 있습니다. GPT-4를 출시한 날부터 같은 수준의 지능(intelligence)에 대해 비용이 1,000배 개선되었습니다.
그렉(Greg) [01:45:51]: 정말 놀랍습니다. 정말 놀랍습니다. 정말 좋습니다. 네, 2년 반 정도 되는 기간 동안 말이죠. 2년 반 동안 3자릿수 규모의 개선을 이룬 다른 것이 무엇이 있을까요? 모르겠습니다. 아무것도 없습니다. 생각할 수 없습니다. 네.

**자체 개선 코딩 및 AI 에이전트, 도구 및 지식 활용(Self-Improving Coding & AI Agents, Tool & Knowledge Utilization)**
알레시오(Alessio) [01:46:04]: 그리고 그것은 계속 낮아지고 있습니다. 심지어… 10,000달러에서 1,000달러로 가는 것과 같습니다. 몇 푼으로 갈 것입니다. GPT-5 출시를 위해 저는 '자체 개선 코딩 에이전트(Self-Improving Coding Agents)'와 '자체 개선 AI 에이전트(Self-Improving AI Agents)'라는 기사를 썼습니다. 그래서 저는 기본적으로 GPT-5에게 '더 나은 코딩 에이전트(coding agent)와 AI 에이전트(AI agent)가 되기 위해 스스로 도구(tools)와 지식(tools)을 만들 수 있니?'라고 물었습니다. 그리고 이것은 스위 랜서(Swy Lancer) 작업입니다. 그리고 그것은 작업을 수행합니다. 어떤 면에서는 실패합니다. 그리고 저는 그것에게 '스스로 도구(tools)와 지식(tools)을 개선하고 이 루프(loop)를 반복할 수 있니?'라고 물었습니다. 그리고 제가 발견한 것은… 모델은 자신이 만든 새로운 도구(tools)와 지식(tools)을 실제로 사용하고 싶어 하지 않는다는 것입니다. 그들은 '그냥 내가 할 수 있어. 도구(tool)와 지식(tool)은 필요 없어'라고 바쁘게 응답합니다. 그리고 저는 마치… 인간과 같네요. 네. 마치 '어떻게 스스로 개선할 수 있을까?'라는 느낌이 든다는 것입니다. 그것이 부분적으로는 '야, 그들은 그래프(graph)나 그런 것과 같은 이러한 도구(tools)와 지식(tools)을 사용하도록 가르침을 받고 있을 뿐이야. 그래서 추론 시간(inference time)에 도구(tools)와 지식(tools)을 만드는 것이 어려워?' 아니면 이것을 그 도약의 일부로 보십니까?
그렉(Greg) [01:46:58]: 저는 그것이 좋다고 생각합니다. 그것이… 네, 분명히 그렇습니다. 그렇죠. 그리고 우리가 그것을 할 수 있는 능력이 0인 것은 아닙니다. 그렇죠. 그리고 이 중 많은 부분이 단순히 훈련(training)에 관한 것이라고 생각합니다. 그렇죠? 모델이 특정 도구(tools) 세트와 지식(tools) 세트로만 훈련받았고, 새로운 도구(tool)와 지식(tool)에 매우 빠르게 적응하도록 밀어붙여지지 않았다면, 평가 시간(evaluation time)에 다르게 행동할 것이라고 기대해서는 안 됩니다. 하지만 스스로 도구(tools)와 지식(tools)을 생산하여 더 효율적으로 만들고, 시간이 지남에 따라 영구적인 방식으로 그러한 라이브러리(library)를 구축하는 아이디어는 당신의 도구 상자(toolbox)에 있어야 할 놀라운 원시 기능(primitive)입니다. 그리고 저는 당신의 목표가… 네. …이러한 믿을 수 없을 정도로 어려운 도전 과제, 미해결 문제(unsolved problems)를 해결할 수 있는 것이라면, 당신은 그러한 종류의 것을 의존성(dependency)으로 필요로 할 것이라고 생각합니다.

**어떤 아키텍처 결정이나 혁신에 대해 이야기하고 싶으십니까?(Any architectural decisions or innovations that you would like to talk about?)**
스윅스(Swyx) [01:47:36]: 슬라이딩 윈도우 어텐션(Sliding window attention), 딥시크(DeepSeek)가 대중화한 매우 세분화된 전문가 혼합(mixture of experts), 로프(rope), 얀(yarn), 어텐션 싱크(attention sinks) 등 GPT-OSS를 위해 내린 결정 중에서 당신에게 특별히 눈에 띄는 것이 있습니까?
그렉(Greg) [01:47:53]: 이러한 선택들은 모두, 아시다시피, 다양한 아키텍처(architectures)를 연구해온 팀이 있습니다. 우리는 다양한 것들을 탐색했습니다. 전문가 혼합(mixture of experts)과 같은 것은 재미있습니다. 저는 그 선택에 대해 우리 팀에게 공을 돌리고 싶습니다. 하지만 제 생각에는 이러한 환경에서 쉽게 실행할 수 있는 것을 원했습니다. 그래서 얼마나 희소하게 갈 것인지와 같은 것을 선택하는 것은 메모리 사용량(memory footprint)과 매우 밀접하게 관련되어 있습니다. 그리고, 아시다시피, 순방향 패스(forward pass)에 실제로 사용할 수 있는 컴퓨트(compute)의 양 등과 관련되어 있습니다. 그래서 저는 어느 정도 아키텍처 결정(architectural decisions)은 모델 크기(model sizing)와 실행 시 접근할 수 있을 것으로 예상되는 컴퓨트(compute)에 의해 상당히 제약받았다고 생각합니다. 네.
스윅스(Swyx) [01:48:37]: 제 말은, 매우 실용적인 엔지니어링 결정(engineering decisions)입니다. 정말 그렇습니다. 네.
그렉(Greg) [01:48:40]: 네, 그렇다고 생각합니다. 그리고 저는 모델의 힘이 정말로 드러난다고 생각합니다. 우리는 모델의 능력을 더욱더 발전시키기 위해 우리의 최첨단 기술을 많이 사용했습니다.
스윅스(Swyx) [01:48:50]: API 사용을 위해 설계된 모델과 단일 기계(single machine)를 위해 설계된 모델의 아키텍처(architecture) 간의 차이를 분명히 감지합니다. 제 말은, 멀티테넌시(multi-tenancy)가 있고 배치(batching)를 할 수 있을 때, 단일 기계(single machine)와는 매우 다릅니다. 매우 다릅니다. 네. 그것이 언젠가 결합될지는 모르겠지만, 어쩌면 당신이 항상 말하는 모델의 동물원(menagerie model)일 수도 있습니다. 네.

**온디바이스 및 엣지 AI 모델, 로컬 vs 원격/클라우드 에이전트 시스템(On-Device & Edge AI Models, Local vs Remote/Cloud Agent Systems)**
그렉(Greg) [01:49:11]: 로컬 모델(local model)이 때때로 원격 모델(remote model)에 위임하는 아키텍처(architecture)에 대해 생각하는 것도 정말 흥미롭습니다. 그렇죠? 그리고 이것은 훨씬 더 빠르게 실행될 수 있는 것이 될 수 있습니다. 개인 정보 보호 아키텍처(privacy architecture) 관점에서 무엇이 실제로 가고 무엇이 남는지 결정하려고 노력하는 것과 엣지 컴퓨트(edge compute)를 갖는 것이 도움이 됩니다. 그것은 인터넷 연결을 잃어도 여전히 무언가를 할 수 있고, 더 느린 계획 모델(planning model)을 가질 수 있다는 것을 의미합니다. 이러한 것들 사이의 상호 작용은 매우 흥미롭습니다. 네.
스윅스(Swyx) [01:49:38]: 마치 온디바이스(on-device) GPT-5가 여기에 GTOS-S를 가지고 있고, 사용 가능하면 온라인으로 라우팅(routes)하는 것과 같습니다. 모르겠습니다.
그렉(Greg) [01:49:46]: 네, 그런 것과 같습니다. 그리고 당신은 로컬 에이전트(local agent)와 원격 에이전트(remote agent)를 가진 코덱스 인프라(Codex infrastructure)와 AI 인프라(AI infrastructure)를 가지고 있으며, 둘 사이를 원활하게 상호 작용할 수 있고, 멀티플레이어(multiplayer)를 할 수 있습니다. 이것은… 이것이 미래의 모습이 될 것이고, 놀라울 것입니다.
알레시오(Alessio) [01:50:03]: 그리고 당신은 항상 당신과 함께하는 장치를 가지고 있습니다. 알겠습니다. 상황이 어떻게 돌아가는지 알겠습니다. 모든 것이 연결됩니다. 네.
스윅스(Swyx) [01:50:09]: 장치에 대해 무엇을 말할 수 있습니까? 당신이 언급했습니다. 그렉을 곤란하게 만들고 싶지 않습니다. 장치에 대해 무엇을 말할 수 있습니까? 훌륭할 것입니다.
스윅스(Swyx) [01:50:18]: 좋습니다. 그리고 또 다른 정치적인… 정치적인지 아닌지는 모르겠습니다. 아시다시피, 중국에서 많은 오픈 모델(open models)이 나오고 있습니다. 미국산 오픈 소스(open source)가 중요한 이유는 무엇입니까?
그렉(Greg) [01:50:28]: 또 다른 것입니다. 우리가 오픈 소스 모델(open source models)에 대해 매우 실용적인 수준에서 생각한 것은 우리의 오픈 소스 모델(open source model)을 기반으로 구축하는 사람들이 우리의 기술 스택(tech stack)을 기반으로 구축한다는 것입니다. 그렇죠? 만약 당신이 모델을 개선하는 데 우리의 도움에 의존하고, 다음 돌파구를 찾는 데 우리에게 의존한다면, 그것은 당신이 우리 사업에 좋은 방식뿐만 아니라, 국가에도 좋은 방식으로 의존한다는 것을 의미합니다. 그렇죠? 사람들이 직접 실행하는 모델에서 미국 기술 스택(American tech stack)을 갖는 것에 대해 생각하지만, 그것들이 우리가 방금… 그것이 실제로 사람들이 자신에게 중요한 부분에 대한 통제권을 가질 수 있는 전체 생태계(ecosystem)를 구축할 수 있도록 허용한다는 것입니다. 궁극적으로 미국적 가치(American values)를 반영하는 이러한 모델을 기반으로 구축되고, 그 다음에는 미국산, 바라건대 아래에는 칩(chips)이 있고 백엔드(backend)에는 클라우드 모델(cloud models)이 있으며 실행 환경(execution environments)이 있고, 이 모든 것이 함께 어우러지는 것이 많은 가치를 더한다고 생각합니다. 그리고 그것은 미국 리더십(American leadership)이 실제로… 우리가 세계에서 우리의 가치(values)에 대한 리더십(leadership)을 가지고 있다는 것을 의미한다고 생각합니다. 네.
스윅스(Swyx) [01:51:32]: 출시를 축하드립니다. 감사합니다.

**OpenAI의 엔지니어링 및 LLM(대규모 언어 모델) 활용(Engineering at OpenAI and Leveraging LLMs)**
알레시오(Alessio) [01:51:34]: OpenAI의 엔지니어링에 대해 이야기해봅시다. 클라우드 코드(cloud code)와 AIDR(에이전트 기반 개발 및 연구) 및 오픈 코드(open code)와 이 모든 다른 도구(tools)에 대한 많은 논쟁이 있다는 것을 알고 있습니다. 이러한 것들로부터 가장 높은 레버리지(leverage)를 얻는 팀 자체를 어떻게 구성해야 한다고 생각하십니까? 숫자 관점에서, 능력 관점에서, 조직 내 팀 규모 관점에서 팀을 구축하는 방식을 바꾸고 있습니까? 공유하고 싶은 것이 있습니까? 음, 엔지니어링…
그렉(Greg) [01:51:58]: 소프트웨어 엔지니어링(Software engineering)은 분명히 여러 차원에서 변화하고 있습니다. 이 모델들이 정말로 해결하기 어려운 엔지니어링(engineering) 부분이 있지만, 우리는 그것이 시작되는 것을 보기 시작했습니다. 그리고 그것은 이러한 매우 핵심적이고 어려운 알고리즘(algorithms)입니다. 그렇죠? CUDA 커널(CUDA kernels)과 같은 것들은 매우 독립적인(self-contained) 문제의 좋은 예시이며, 우리 모델들은 곧 그것에 매우 능숙해져야 합니다. 하지만 그것은 많은 도메인 전문 지식(domain expertise)과 많은 실제 추상적 사고(abstract thinking)를 필요로 하기 때문에 어렵습니다. 하지만 다시 말하면, 그것은 해결 불가능한 것이 아닙니다. 독립적(self-contained)입니다. 그것은 우리가 가진 기술에 매우 적합한 종류의 문제입니다. 아키텍처(architecture) 측면에서 매우 어려운 다른 문제들도 있습니다. 그렇죠? 시스템이 어떻게 구성되어야 하는지 생각하고 추상화(abstractions)에 대해 생각하는 방법 말입니다. 그리고 다시 말하면, 우리 모델들은 이것에 어느 정도 능숙해지기 시작했습니다. 그래서 저는 우리가 본 것은 대부분의 엔지니어들, 심지어 매우 훌륭한 엔지니어들에게도 그들의 작업 중 많은 부분이 현재 모델의 핵심 강점과 매우 잘 일치한다는 것입니다. 그리고 특히 당신이 전문가가 아닌 언어와 같은 모든 것에 대해서는, 네. 당신은 분명히 그 코드를 직접 작성하고 싶지 않을 것입니다. 당신은 모델이 그것을 하도록 정말로 원할 것입니다. 그리고 나서 일이 훨씬 더 어려워지는 부분도 있습니다. 왜냐하면 모델이 접근할 수 없는 것들을 필요로 하기 때문입니다. 그렇죠? 좋은 결정을 내리기 위해 많은 맥락(context)과 사람들과 이야기하는 것이 필요합니다. 그래서 저는 우리가 아직 이러한 도구(tools)가 존재하기 때문에 팀을 구성하는 방식에 변화가 있다고 실제로 볼 수 있는 지점에 도달하지 못했다고 생각합니다. 하지만 저는 이 모델들이 가능한 모든 영역에서 사용되도록 하는 것이 극도로 높은 우선순위인 지점에 도달했다고 생각합니다. 그리고 팀을 어떻게 구성할지 생각하고, 그것을 잘 그리고 책임감 있게 어떻게 할지 생각하고, 가드레일(guardrails)이 무엇이어야 할지 생각하는 것입니다. 그리고 그것은 매우 실용적인 방식으로 일어납니다. 그래서 저는 제가 보고 있는 많은 부분이 초기 채택자 단계(early adopter phase)에서 주류 단계(mainstream phase)로 전환하기 시작하고 있다는 것입니다. 그리고 사람들이 더 많은 일을 할 수 있게 됨으로써 얻는 생산성 영향은 우리가 실제로 더 많은 사람들을 원한다는 것을 의미합니다. 그렇죠? 우리는 소프트웨어(software)를 생산하는 능력에 의해 너무나 제한되어 있습니다. 우리는 우리 팀이 기술 부채(tech debt)를 실제로 정리하고 리팩토링(refactor)하는 능력에 의해 너무나 제한되어 있습니다. 그리고 만약 우리가 그것을 10배 더 쉽게 만드는 도구(tools)를 가지고 있다면, 우리는 100배 더 많은 일을 할 수 있을 것입니다. 그래서 저는 이러한 모델들이 단순히 같은 일을 더 효율적으로 하는 진정한 동력이 아니라, 훨씬 더 많은 일을 할 수 있게 함으로써 엄청난 기회(incredible opportunity)가 수반된다고 생각합니다. 그리고 그것이 전반적인 목표라고 생각합니다. 네.

**AI 최적화를 위한 코드베이스 및 데이터베이스, 팀 구성(Structuring Codebases & Databases and Teams for AI Optimization)**
알레시오(Alessio) [01:54:16]: LLM(대규모 언어 모델)에 더 잘 맞도록 팀의 작업을 어떻게 바꾸셨습니까? 문제를 추적하는 방식이 달라졌습니까? 코드베이스(code bases)와 데이터베이스(code bases)를 구성하는 방식이 달라졌습니까?
그렉(Greg) [01:54:25]: 그래서 저는 우리가 아직 이 초기 단계에 있다고 생각합니다. 하지만 제가 가장 성공적이라고 본 것은 이 모델들의 강점과 약점을 중심으로 코드베이스(code bases)와 데이터베이스(code bases)를 실제로 구축한다는 것입니다. 그래서 그것이 의미하는 바는 더 독립적인(self-contained) 단위가 매우 빠르게 실행되는 매우 좋은 단위 테스트(unit tests)를 가지고 있고, 이 모듈(module)이 무엇을 위한 것인지 설명하는 좋은 문서(documentation)를 가지고 있다는 것입니다. 그리고 당신이 그렇게 하고 세부 사항을 모델에 맡기면, 그것은 정말 잘 작동합니다. 그리고 나서 이러한 것들이 어떻게 구성되는지 생각하고, 당신이 가진 종속성(dependencies)에 대해 생각하는지 확인하는 것입니다. 이러한 깔끔한 AI 최적화 모듈(AI optimized modules)은 다른 AI 최적화 모듈(AI optimized modules)에 의해서만 의존될 수 있습니다. 그러면 당신은 실제로 최적화된 전체 시스템을 얻게 됩니다. 그래서 저는 우리가 아직 가능한 것의 표면을 긁고 있을 뿐이라고 생각합니다. 그리고, 아시다시피, 모델은 너무나 빠르게 발전하고 있어서 6개월 후 모델의 약점을 중심으로 작업하는 것이 무엇을 의미하는지는, 저는 그 약점들이 엄청나게 줄어들 것이라고 생각합니다. 그래서 당신은 오늘날 존재하는 것에 과적합(overfitting)하기 위해 모든 시간을 보낼 필요는 없습니다. 하지만 저는 많은 잠재력(potential)이 있다고 생각합니다. 네. 이 특정 순간에 빠르게 움직일 수 있는 말이죠.

**AGI 시대 엔지니어 및 인간의 가치(The Value of Engineers & Humans in the Age of AGI)**
스윅스(Swyx) [01:55:27]: 제가 매우 궁금한 질문 중 하나는 엔지니어의 가치입니다. 시간이 지남에 따라 증가하고 있습니다. 시간이 지남에 따라 증가하고 있습니다. 음, 제 말은, 우리 작업의 일부가 자동화되고 있다는 것도 있습니다. 그리고 저는 분명히 매우 높은 계약 보너스(signing bonuses)가 있다고 생각합니다. 우리 업계 역사상 본 적이 없는 것보다 더 높습니다. 가치 있는 것은 엔지니어입니까, 아니면 그들을 가능하게 하는 시스템입니까? 아시다시피, 저는 둘 다라고 생각하지만, 사람들은 엔지니어에게 많은 돈을 지불하고 있습니다.
그렉(Greg) [01:55:53]: 제 말은, 결국 새로운 것은 우리가 기술을 생산하고 있다는 것입니다. 이 모델들은 인류가 만들어낸 가장 유용한 도구(tools)입니다. 그렇죠. 그리고 그 기반에는 인류가 지금까지 만들어낸 가장 큰 기계들을 구축하고 있습니다. 그렇죠. 마치 어느 시점에서 이러한 데이터 센터(data centers)에 들어가는 돈은 추상화(abstraction)가 되기 시작합니다. 그렇죠. 500억 달러는 무엇입니까? 1000억 달러는 무엇입니까? 그것이 무엇인지 어떻게 내면화할 수 있습니까? 저는 그것이 거의 인간 이해의 규모를 넘어선다고 생각합니다. 우리가 국가로서, 사회로서, 세계로서 집단적으로 지금 겪고 있는 엔지니어링 프로젝트(engineering project) 말입니다. 그렇죠. 마치 뉴딜(New Deal)과 같은 프로젝트는 비교할 수 없을 정도로 작습니다. 아폴로 프로그램(Apollo program)은 우리가 지금 하고 있는 일에 비하면 비교할 수 없을 정도로 작습니다. 그리고 여러 면에서 그래야 합니다. 그렇죠. 이 기술의 경제적 수익(economic return)은 매우 큽니다. 하지만 더 중요한 것은 우리가 새로운 경제로 이동하는 방식입니다. 그렇죠. AI 통합 경제(AI integrated economy), AI 기반 경제(AI powered economy). 그리고 이것이 궁극적으로 우리의 사명(mission)에 관한 것입니다. 그렇죠. 마치 우리는 수평선에서 이 변화를 보고 있습니다. 우리는 돕고 싶습니다. 우리는 그것이 모든 사람을 고양시키는 것이 되도록 돕고 싶습니다. 그렇죠. 그것은 놀라운 기회(amazing opportunity)이며, 인류 역사상 거의 유일합니다. 그리고 우리는 모두 운이 좋습니다. 그렇죠. 이 시점에 있고 어떤 방식으로든 참여할 수 있다는 것이 말입니다. 그것이 저에게는 인류 규모에서 일어나고 있는 이 큰 변화에 대해 정말로 생각하게 하는 배경입니다. 그리고 때로는 거의 인지 부조화(cognitive dissonance)를 느낍니다. 낮은 수준의 CUDA 교착 상태(CUDA deadlock)를 디버깅(debugging)하거나 보라색 그라데이션(purple gradient)에 대해 걱정하고 있을 때 말입니다. 그리고 당신은 이것이 우리가 정말로 이야기하고 있는 인류의 미래라는 것을 깨닫습니다. 그래서 엔지니어(engineers)와 누가 어떤 회사에 있는지 등 이러한 것들에 대해 생각할 때, 이러한 것들이 중요합니다. 그렇죠. 마치 어떤 개인이 아니라 팀에 관한 것입니다. 그렇죠. 하지만 어떤 하나의 제품이나 어떤 하나의 시스템에 관한 것도 아닙니다. 그것은 정말로 우리가 함께 구축하고 있는 전반적인 사회, 전반적인 경제에 관한 것입니다. 그래서 저는 때때로 한 발 물러서서 큰 규모에 대해 생각합니다. 하지만 당신은 또한 미시적 규모에 대해서도 생각해야 합니다. 사람들이 행복한가? 그렇죠. 사람들이 사명(mission)에 연결되어 있다고 느끼는가? 그들이 하는 일이 중요하다고 느끼는가? 그리고 그러한 것들이 실제로 가장 중요한 것임이 밝혀졌습니다. 그래서 헤드라인을 장식하는 것이 반드시 실제로 중요한 것은 아닙니다. 그것은 실제로 사람들을 가장 많이 움직이는 것입니다. 하지만 그것은 분명히 사람들이 이 기술의 잠재력(potential)으로 보는 경제적 현실의 반영과 같습니다.
스윅스(Swyx) [01:58:21]: 이것은 노암(Noam)이 다중 에이전트 팀(multi-agents team)에 대해 말했던 것과 어느 정도 연결됩니다. 인간의 개별 지능(individual intelligences)은 개별적으로 할 수 있는 일이 그리 많지 않습니다. 하지만 문명으로서 우리는 달에 가고, 도시를 건설하고 AI(인공지능)를 건설할 수 있습니다. 그리고 함께라면, 저는 우리가 개별적으로 할 수 있는 것보다 훨씬 더 많은 일을 할 수 있다고 생각합니다.
그렉(Greg) [01:58:40]: 우리는 함께 놀라운 일들을 할 수 있습니다.
스윅스(Swyx) [01:58:41]: 의심할 여지 없이요.

**AI 연구의 현재 상태 및 연구소/접근 방식 다양성(Current state of AI research & Lab/Approach Diversity)**
알레시오(Alessio) [01:58:42]: AI 연구의 현재 상태에 대해 어떻게 생각하십니까? 모든 사람이 정말로 같은 일을 하고 있습니까? 모든 연구소가 결국 우리를 올바른 방향으로 수렴하게 도울 다른 접근 방식을 가지고 있다고 생각하십니까? 아니면 이제 돈이 너무 커져서 당신이 작동할 것이라고 생각하는 일을 해야 하기 때문입니까?
그렉(Greg) [01:58:58]: 저는 이 분야에 놀랍도록 많은 다양성(diversity)이 있다고 생각합니다. 때로는 수렴 진화(convergent evolution)처럼 느껴질 수도 있지만, 다른 연구소의 사람들과 실제로 이야기해보면 사람들이 다른 관점을 가지고 있다는 것을 실제로 깨닫게 됩니다. OpenAI에서 우리가 초기에 내린 결정 중 하나는 정말로 다른 것을 하고 싶었다는 것입니다. 우리는 정말로 생각하는 방식이 일치하는 사람들을 원했습니다. 그렇죠? 왜냐하면 오랫동안 박사 학위(PhD)를 추구해온 사람들, 즉 자신만의 연구 비전(research vision)을 가진 사람들에게는 무엇을 해야 할지 말할 수 없기 때문입니다. 그래서 같은 방향으로 나아갈 사람들을 원한다면, 그 사람들을 선택해야 한다는 것을 의미합니다. 그리고 그것이 우리가 OpenAI에서 내린 가장 중요했던 초기 결정 중 하나였고, 우리가 이룬 것들을 달성하는 데 도움이 되었습니다. 그래서 저는 그것이 당신이 필연적으로 다른 견해를 가지고 있다는 것을 의미한다고 생각합니다. 당신이 선택할 수 있는 다른 벡터(vectors)가 있습니다. 그리고 당신은 그것을 다른 연구소의 취향과 그들이 무엇에 집중하고 무엇을 생산하는지에서 실제로 볼 수 있습니다. 그리고 OpenAI에서는 다음 단계로 나아갈 연구를 어떻게 할 것인지에 매우 집중해왔다고 생각합니다. 그리고 GPT-5와 같은 것에 대해서도, 아시다시피, 우리는 '좋아, 코딩 측면에서 우리가 가진 문제에 대한 피드백(feedback)을 계속해서 처리하자'와 같은 많은 압력을 받았습니다. 그리고 당신은 그 고된 작업을 추구하고 어딘가에 도달할 수 있습니다. 하지만 때로는 한 발 물러서서 '이것을 어떻게 할까?'라고 생각해야 합니다. 그리고 다음 단계 함수(step function)를 어떻게 할 것인지, 다음 패러다임 전환(paradigm shift)을 어떻게 할 것인지 생각해야 합니다. 그리고 추론 패러다임(reasoning paradigm)은 우리가 그것을 매우 성공적으로 수행했던 좋은 예시입니다. 그리고 우리는 OpenAI의 과정에서 그것을 여러 번 해왔고 계속해서 그렇게 할 것입니다. 그래서 저는 돌파구(breakthroughs)가 여전히 만들어져야 한다고 생각합니다. 그리고 멀티모달(multimodal)과 다양한 생성 방식 등 너무나 많은 다양성(diversity)이 있어서, 저는 연구 분야가 그 어느 때보다 풍부하다고 생각합니다.
스윅스(Swyx) [01:00:39]: 네. 그리고 잊지 말아야 할 것은, 그것은 주류 연구(mainline research)와 같다는 것입니다. 음성(voice)도 있고, 이미지 생성(image generation), 비디오 생성(video generation)도 있습니다. 네. 네.
알레시오(Alessio) [01:00:47]: 이러한 것들을 잊기 쉽습니다. 스튜디오 지브리(Studio Ghibli)를 기억하십니까? 그것은 세계에서 가장 큰 것이었습니다. 정확합니다.
그렉(Greg) [01:00:51]: 그리고 그것은 놀랍습니다. 놀랍습니다. 그리고 그것은, 참고로, 소수의 사람들이 여러 해 동안 그 문제에 정말 집중했던 종류의 것입니다. 그리고 그것이 OpenAI의 핵심 정신(core ethos)이라고 생각합니다. 정말로 중요한 문제에 대해 장기적인 베팅(long-term bets)을 하고, 응집력 있는 전체(cohesive whole)를 이루는 방향으로 나아가는 것입니다.

**OpenAI의 우선순위 및 중점 분야(OpenAI’s Prioritization and Focus Areas)**
알레시오(Alessio) [01:01:11]: 외부에서는 당신이 무엇에 집중하고 있는지 파악하기가 어렵습니다. 아시다시피, 이미지젠(Imagen)은 거의 갑자기 나타났고, 그것은 훌륭했습니다. 많은 채택을 얻었습니다. 사람들은 당신이 어떻게 우선순위를 정하는지, 그리고 사람들이 무엇을 탐색하고 구축해야 하는지, 그리고 당신이 개선하기를 기다려야 하는지에 대해 어떻게 생각해야 할까요?
그렉(Greg) [01:01:27]: 음, 이 분야에는 엄청난 가능성 공간(possibility space)이 있습니다. 그렇죠? 왜냐하면 신경망(neural nets), 딥러닝(deep learning)은 사실상 모든 종류의 데이터(data), 모든 종류의 영역(domain)에 적용 가능하기 때문입니다. 그리고 우리는 모든 것을 할 수 없습니다. 핵심 추론 패러다임(core reasoning paradigm)은 분명히 우리가 계속 추진할 것입니다. 멀티모달 음성(Multimodal voice), 이미지 생성(image generation), 비디오 생성(video generation)과 같은 영역도 우리가 매우 중요하게 생각하고 모두 함께 어우러지는 것들입니다. 하지만 우리가 핵심 프로그램의 일부로서 어떻게 우선순위를 정해야 할지 파악하기 어려운 영역도 있었습니다. 그렇죠? 예를 들어 2018년 로봇 공학(robotics)이 그랬던 시기가 있었습니다. 우리는 훌륭한 결과를 얻었지만, 실제로 '그것은 작동하지 않을 것이다'라고 깨달았습니다. 우리가 다른 영역에서 훨씬 더 빠르게 움직일 수 있다는 것을 말입니다. 그렇죠? 실제로 로봇 손(robot hand)이 루빅스 큐브(Rubik's cube)를 푸는 훌륭한 결과를 얻었습니다. 그리고 그 팀은 이 로봇 손(robot hand)이 20시간 동안 작동하면 힘줄이 끊어진다는 사실 때문에 병목 현상(bottleneck)을 겪었습니다. 그래서 기계 엔지니어(mechanical engineer)가 와서 고쳐야 했습니다. 그리고 그 팀은 깃허브 코파일럿(GitHub Copilot)이 된 것을 만들러 갔는데, 그것은 분명히 놀라운 업적이고 진정한 성과입니다. 그리고 그들은 물리적인 영역보다 디지털 영역에서 훨씬 더 빠르게 움직일 수 있었습니다. 그래서 저는 우리가 정말로 노력한다고 생각합니다. 아시다시피, 우리가 아무리 많은 사람을 고용하고 아무리 많은 GPU(그래픽 처리 장치)를 얻더라도, 우리는 제한된 대역폭(bandwidth)을 가지고 있습니다. 그렇죠? 우리는, 아시다시피, 하나의 회사, 하나의 연구소로서, 가능한 한 일관된 하나의 문제에 집중하고 있습니다. 그래서 저는 우리가 하는 일들을 살펴볼 수 있고, 때로는 파생물(offshoots)을 만들기도 하고, 때로는 그것이 핵심 프로그램(core program)의 일부가 되기도 할 것이라고 생각합니다. 하지만 모든 사람에게는 너무나 많은 가능성 공간(possibility space)이 있습니다. 놀랍습니다.

**창업자를 위한 조언: 아직 늦지 않았다(Advice for Founders: It's Not Too Late)**
스윅스(Swyx) [01:03:05]: 이제 마무리할 시간입니다. OpenAI에서 벗어나 몇 가지 작은 번개 질문을 하고 싶습니다. 이 질문은 알레시오(Alessio)에게서 받은 것이니 당신이 받아주세요.
알레시오(Alessio) [01:03:15]: 당신이 OpenAI를 시작했을 때, AI 연구소(AI lab)를 시작하기에는 너무 늦었다고 거의 믿었습니다. 오늘날 사람들이 너무 늦었다고 생각하지만 실제로 해야 할 일은 무엇이라고 생각하십니까?
그렉(Greg) [01:03:26]: 음, 이 모델들을 실제 세계 응용 분야(real world application domains)에 연결하는 것이 극도로 가치 있다는 것은 꽤 분명합니다. 그리고 때로는 모든 아이디어가 이미 선점된 것처럼 느껴질 수도 있지만, 경제는 너무나 크고, 인간 노력의 모든 응용 분야는 너무나 큽니다. 그래서 우리가 만들어낸 이 놀라운 지능(intelligences)을 최대한 활용하는 방법을 사람들이 정말로 생각하는 것이 가치 있고 정말 중요합니다. 그리고 그 중 많은 부분이, 아시다시피, 헬스케어(healthcare)와 같은 분야에서는 모든 이해관계자(stakeholders)에 대해 정말로 생각해야 합니다. 그렇죠? 시스템이 오늘날 어떻게 작동하는지, 그리고 이러한 모델들을 어떻게 잘 통합할지 생각해야 합니다. 그리고 저는 이 모든 영역에서 아직 발견되지 않은 많은 결실이 있다고 생각합니다. '어떻게 선택받을까?'라고 생각해야 합니다. 그래서 GPT-래퍼(GPT-Rapper)를 작성해보세요. 네. 해보세요. 하지만 제가 조언하고 싶은 것은 당신이 생산하는 가치가 단순히 더 나은 래퍼(wrapper)를 작성하는 것만이 아닌 영역에 대해 정말로 생각하는 것입니다. 그것은 정말로 영역을 이해하고 전문 지식(expertise)과 관계(relationships) 등 이 모든 것을 구축하는 것에 관한 것입니다.

**미래 전망 및 마무리 생각(Future outlook and closing thoughts)**
스윅스(Swyx) [01:04:20]: 당신은 가끔 엔젤 투자(angel invest)를 합니다. 무엇이 당신의 관심을 끕니까?
그렉(Greg) [01:04:24]: 사실 저는 몇 년 동안 엔젤 투자(angel invest)를 하지 않았습니다. 아, 그렇군요. 네, 네. 그냥 모든 것이 OpenAI에 대한 방해 요소이고, 저는 레이저처럼 집중하고 싶습니다. 알겠습니다.

**2045년 타임캡슐: 컴퓨트, 지속 가능한 컴퓨트, 풍요의 미래 사회(Time Capsule to 2045: Compute, Sustainable Compute, & Future Society)**
스윅스(Swyx) [01:04:33]: 좋습니다. 다음 여행 질문으로 넘어가겠습니다. 2045년의 그렉에게 보내고 싶은 포스트잇 메모는 무엇입니까? 그러면 당신은 58세가 될 것입니다. 다이슨 스피어(Dyson sphere)와 지속 가능한 에너지(sustainable energy)는 어떻습니까? 이봐요, 당신이 그것을 만드는 데 필요한 것에 대한 수학을 실제로 해봤는지 모르겠습니다만.
그렉(Greg) [01:04:46]: 네, 더 진지하게 말하자면, 지금 상황이 얼마나 빠르게 움직이는지 고려할 때 2045년은 상상하기가 너무 어렵습니다. 그래서 저는 놀라운 풍요(abundance)의 세상이 되기를 바랍니다. 그리고 그 시점에는 우리가 정말로 다행성(multi-planetary)이 되어야 하고, 거의 상상할 수 있는 모든 공상 과학(sci-fi) 꿈이 가능성을 부인하기 어렵다고 생각합니다. 물론 특정 속도로 원자를 움직이는 물리적 능력에 의해 제한되는 것들을 제외하고 말이죠. 하지만 네, 저는 그 세상이 2025년에 앉아 있는 지금만큼 놀랍기를 바랍니다.
스윅스(Swyx) [01:05:17]: 풍요(abundance)가 있다면 UBI(기본 소득)가 필요할까요? 진정한 풍요(true abundance)는 UBI(기본 소득)가 필요 없다는 것을 의미하니까요.
그렉(Greg) [01:05:22]: 음, 저는 우선, OpenAI 초기에 AGI(범용 인공지능) 이후에 돈이 의미가 있을지에 대한 많은 논쟁이 있었다고 생각합니다. 그렇죠? 그리고 정말 불분명합니다. 그렇죠? 컴퓨터와 대화하기만 하면 원하는 모든 것을 생산할 수 있다면. 당신은 어떤 물리적 재화(physical good)를 원하고, 어떤 종류의 물질적 품목(material item)을 원하며, 그것이 즉시, 효과적으로 무료로 제조될 수 있다면. 돈은 무엇을 의미합니까? 그리고 반대로, 저는 매우 분명하게 수요가 많을 자원 하나가 있다고 생각합니다. 바로 컴퓨트(compute)입니다. 이미 그렇습니다. 우리는 OpenAI 내에서 이것을 봅니다. 가장 많은 컴퓨트(compute)에 접근할 수 있는 연구원들이 가장 큰 프로젝트를 수행하고 더 많은 일을 할 수 있습니다. 그리고 미래에는 사람들이 컴퓨트(compute)에 어떻게 접근할 것인지 생각하는 것이 중요하다고 생각합니다. 당신이 관심을 갖는 어떤 작업이든, 어떤 응용 분야이든 더 많은 컴퓨트(compute)를 가질수록 더 많이 해결될 것이고, 더 많은 일이 일어날 것입니다. 그리고 컴퓨트 분포(compute distribution)가 어떻게 보일지에 대한 질문은 매우 중요할 것이라고 생각합니다. 그래서 저는 '만약 당신이 일을 하지 않는다면, 살아남을 수 있을까?'라는 질문에 대한 답은 '네'일 것이라고 생각합니다. 당신은 충분한 물질적 필요(material needs)를 충족시킬 것입니다. 하지만 '더 많은 일을 할 수 있을까?'라는 질문은, 당신이 원하는 만큼의 영화를 생성하는 것뿐만 아니라, 놀라운 세부 사항과 모든 추가적인 화려함을 가지고, 당신에게 특별히 가장 좋은 것이 무엇인지에 대해 주관적인 경험(subjective experience)으로 100년 동안 매우 열심히 생각하게 할 수 있을까? 저는 더 많은 컴퓨트(compute)에 대한 더 많은 수익이 항상 있을 것이라고 생각합니다. 그래서 우리는 그 사회가 어떻게 설계될지에 대해 정말 신중하게 생각해야 할 것입니다.
스윅스(Swyx) [01:06:59]: 그리고 저는 이것이 항상 더 어렵다고 생각합니다. 참고로요. 네. 그래서, 네, 그것이 질문입니다. 아니요, 2005년의 그렉에게 메모, 포스트잇 메모를 보내는 약간의 변명입니다. 18세의 그렉에게요. 와. 시간 여행을 할 수 있군요.

**2005년 타임캡슐: 더 많은 문제와 기회가 나타날 것이다(Time Capsule to 2005: More Problems & Opportunities Will Emerge)**
그렉(Greg) [01:07:07]: 얼마나 긴 메모를 쓸 수 있을까요?
스윅스(Swyx) [01:07:09]: 포스트잇 메모처럼요. 자신에게 약간의 조언을 해주세요. 그리고 분명히 이것은 다른 모든 사람들을 위한 대리인입니다. 그렇죠.
그렉(Greg) [01:07:15]: 하지만 아시다시피, 제가 가장 놀랐던 한 가지는 문제의 풍요(abundance of problem)와 기회의 풍요(abundance of opportunities)가 시간이 지남에 따라 증가한다는 것입니다. 좋습니다. 왜냐하면 저는 1999년, 2000년에 실리콘 밸리(Silicon Valley)에 대해 읽으면서 '기회를 놓쳤다. 너무 늦게 태어났다'고 느꼈던 것을 기억합니다. 매우 흔한 일이죠. 정확합니다. 그렇죠? 저는 마치 '내가 일을 할 준비가 될 때쯤에는 모든 멋진 문제들이 해결되어 있을 것이다. 남은 것이 없을 것이다'라고 느꼈습니다. 그것은 완전히 틀린 것으로 밝혀졌습니다. 그렇죠? 지금은 기술 분야에서, 그리고 세상에서 실제로 활동하기에 가장 흥미로운 시기입니다. 왜냐하면 우리는 모든 응용 분야, 인간 노력의 모든 분야를 고양시키고 혁신할 놀라운 도구(tool)를 가지고 있기 때문입니다. 그리고 저는 그것이 흥분할 만한 일이고, 우리가 적용할 수 있는 것이며, 물론 우리가 해결해야 할 도전 과제(challenges)가 있지만, 이 놀라운 결과를 달성하기 위한 목적이라는 사실이 중요하다고 생각합니다. 그래서 저는 문제의 가용성(problem availability)과 기회의 가용성(opportunity availability)이 시간이 지남에 따라 줄어들기보다는 증가할 것이라는 메시지가 제가 그 순간에 내면화했으면 좋았을 핵심이라고 생각합니다.
알레시오(Alessio) [01:08:17]: 놀랍습니다. 그렉, 함께 해주셔서 정말 감사합니다. 두 분 모두 감사합니다.
그렉(Greg) [01:08:21]: 정말 감사합니다. 여기 오게 되어 좋았습니다.

1 2025년 말 예상 매출 90억 달러 이상이므로 이는 현재 배수의 20배이며, 미친 수준은 아닙니다.
2 이것은 농담입니다.