**GPT-5 관련 최신 보고서: 코덱스(Codex)의 부활과 AI 개발의 미래**

이번 보고서는 GPT-5와 관련된 최근 발표 중 바이브(vibes), 부트스트래핑(bootstrapping), 비전(vision), 그리고 라우터(Router)에 대한 심층 분석의 마지막 부분입니다. 혹시 지난 내용을 놓치셨다면, 11월 19일부터 22일까지 뉴욕에서 개최되는 AI 엔지니어 코드 서밋(AI Engineer CODE Summit)에 주목해주세요! 이 서밋은 일반적으로 모집 정원의 10배 이상이 몰릴 정도로 뜨거운 관심을 받으며, 최고 수준의 콘텐츠와 참가자들이 함께합니다. 만약 개발자 생산성 향상과 SWE 에이전트(SWE agents)의 진화하는 역량에 관심이 많으시다면, 지금 바로 참가 신청을 고려해보세요.

오늘 공개된 새로운 GPT-5-코덱스(GPT-5-Codex)는 최근 코딩 에이전트(Coding Agents) 분야에서 가장 강력한 변화의 바람(vibe shifts)을 몰고 왔던 한 달을 장식하며 출시되었습니다. 지난 한 해 동안, Anthropic은 코딩 관련 작업 영역에서 독보적인 강자로 자리매김했습니다. 특히 6월에 선보인 클로드 3.5 소네트(Claude 3.5 Sonnet)를 시작으로, 2월의 3.7 소네트(3.7 Sonnet)와 클로드 코드(Claude Code), 그리고 5월의 클로드 4(Claude 4)에 이르기까지, Anthropic은 코딩 사용 사례(coding usecases)에서 비할 데 없는 우위를 점했습니다. 이러한 성과는 50억 달러에 달하는 매출(revenue) (그중 10%는 클로드 코드(Claude Code)에서 발생)과 1,830억 달러의 기업 가치(valuation), 그리고 1,220억 달러의 시가총액(market cap) 증가로 이어지는 경이로운 성장을 기록했습니다.

이러한 Anthropic의 약진은 OpenAI에 상당한 자극이 된 것으로 보입니다. 물론 OpenAI는 2021년 깃허브 코파일럿(GitHub Copilot)의 기반이 된 오리지널 코덱스(Codex)를 최초로 선보였으며, 이 코파일럿은 1,820만 명의 개발자와 지속적으로 증가하는 사용자를 보유한 선구적인 AI 코딩 도구(AI coding tool)입니다. 또한, GPT-3는 모든 바이브 코딩 스타트업(vibe coding startups)의 시작을 알린 디빌드(Debuild)에 영감을 주었으며, O1과 GPT-4.1에서는 코딩 능력(coding abilities)을 재차 강조하기 시작했습니다.

GPT-5-코덱스(GPT-5-Codex)의 SWE-벤치(SWE-bench) 전체 500개 테스트에서의 점수 74.5%는 (악명 높게 밈으로 조롱받았던) GPT-5 사고(thinking) 성능 74.9% (477개 작업 하위 집합)와 거의 일치합니다. 그렇다면 GPT-5에 대한 인식이 이처럼 크게 변화한 근본적인 원인은 무엇일까요? 가장 먼저 꼽을 수 있는 것은 코덱스 팀의 탁월한 성과입니다.

**요인 1: 다면적 존재, 하나의 에이전트(Many Faces, One Agent)**

오늘 공개된 팟캐스트에서 그렉(Greg)이 언급했듯이, 이번 프로젝트에는 수많은 인력이 참여했습니다: "연초에 우리는 연말까지 에이전트형 소프트웨어 엔지니어(agentic software engineer)를 구축한다는 회사 목표를 세웠습니다. 그리고 그것이 정확히 무엇을 의미하는지, 어떻게 실현할지, 그리고 이 목표에 투입할 수 있는 모든 기회와 컴퓨팅 자원(compute)을 어떻게 통합할지 파악하는 것이 OpenAI의 많은 이들에게는 매우 중대한 과제였습니다."

초기 A-SWE 에이전트형 하네스(A-SWE agentic harness)는 '10X'로 불리며 터미널(terminal) 환경에서 구동되었습니다. 하지만 현재는 새로운 코덱스 CLI(Codex CLI)와 "챗GPT 코덱스(ChatGPT Codex)" (현재 코덱스 클라우드(Codex Cloud)), 그리고 2.5주 만에 80만 건의 설치를 기록한 IDE 확장 프로그램(IDE extension) 및 깃허브 코드 리뷰 봇(GitHub code review bot)이 출시되면서, 모든 개발 요구사항을 충족하는 포괄적인 인터페이스(interfaces) 세트가 완성되었습니다.

코덱스 생태계(Codex universe) 내에서 각 도구의 장단점을 대략적으로 살펴보면 다음과 같습니다:

아마도 가장 적게 홍보되었지만, @codex 코드 리뷰 봇(code review bot)은 엄격한 범위 설정(tight scoping) 덕분에 가장 높은 유용성(utility)을 제공할 수 있습니다: "우리는 검토해야 할 코드의 양이 증가하면서 팀원들이 단순히 처리해야 하는 검토 작업의 양이 큰 병목 현상(bottleneck)이라는 사실을 인지하기 시작했습니다. 우리는 PR(Pull Request)을 검토하고, 구현하려던 계약(contract)과 의도(intention)에 대해 깊이 숙고한 다음, 실제 코드를 살펴보고 그 의도가 코드와 일치하는지 검증(validate)할 수 있는 매우 높은 신뢰도의 코덱스 모드(high signal Codex mode)에 집중하기로 결정했습니다. 이 봇은 여러 계층을 깊이 파고들어 모든 종속성(dependencies)을 분석하고, 계약(contract)을 고려하며, 최고의 숙련된 개발자나 검토자들이 해당 PR(Pull Request)에 대해 몇 시간 동안 깊이 고민하지 않았다면 발견하기 어려웠을 문제들을 실제로 제기할 수 있습니다. 우리는 이 시스템을 OpenAI 내부에서 먼저 도입했습니다. 이는 매우 성공적이었으며, 시스템이 작동하지 않을 때 사람들이 안전망(safety net)을 잃는다고 느끼며 실제로 불만을 표출할 정도였습니다. 그리고 이는 팀과 코덱스 팀을 포함한 전체 개발 프로세스를 엄청나게 가속화(accelerated)시켰습니다."

**새로운 관점: AI-네이티브 개발 환경의 도래**

코덱스(Codex)의 다양한 인터페이스는 단순히 개별 도구를 제공하는 것을 넘어, AI를 중심으로 재편된 새로운 개발 환경, 즉 'AI-네이티브 개발 환경'의 청사진을 제시합니다. CLI는 자동화된 스크립트와 배치 작업에 이상적이며, 챗GPT 코덱스는 대화형 문제 해결과 아이디어 구상에 활용될 수 있습니다. IDE 확장 프로그램은 개발자의 코드 작성 흐름에 AI를 자연스럽게 통합하여 실시간 코드 생성, 디버깅 지원, 리팩토링 제안 등을 제공합니다. 특히 깃허브 코드 리뷰 봇은 개발 프로세스의 핵심 단계인 코드 검토에서 인간의 인지 부하를 줄이고 품질을 향상시키는 데 기여합니다.

이러러한 통합은 개발자가 AI를 별도의 도구로 인식하는 것이 아니라, 개발 생태계의 필수적인 부분으로 받아들이게 합니다. 예를 들어, 새로운 기능을 개발할 때, 개발자는 CLI를 통해 초기 스캐폴딩을 생성하고, IDE에서 AI의 도움을 받아 코드를 작성하며, 챗GPT 코덱스와 대화하며 설계상의 난점을 해결하고, 최종적으로 깃허브 봇이 코드 리뷰를 자동화하는 워크플로우를 상상할 수 있습니다. 이는 개발자가 반복적이고 기계적인 작업에서 벗어나 더 창의적이고 전략적인 문제 해결에 집중할 수 있도록 돕습니다. 결과적으로, AI는 단순한 조력자를 넘어 개발 프로세스 전반을 혁신하는 협력자로서의 역할을 수행하게 됩니다.

**요인 2: 향상된 후속 훈련 품질(Better Post-Training Qualities)**

물론 데이터셋(datasets)은 공개되지 않지만, OpenAI가 항상 강조하는 또 다른 핵심은 연구와 제품의 긴밀한 통합(tight integration of research and product)입니다. 오늘 팟캐스트에서도 몇 가지 중요한 품질(desired qualities)에 대한 언급을 들을 수 있었습니다:

**가변적인 끈기(Variable Grit)**

티보 소티오(Thibault Sottiaux)는 다음과 같이 설명합니다: "이 모델이 보여주는 특징 중 하나는 훨씬 더 긴 시간 동안 지속하며 복잡한 리팩토링(refactoring) 작업에 필요한 끈기(grit)를 실제로 발휘하는 능력입니다. 하지만 동시에 간단한 작업의 경우, 불필요한 고민 없이 훨씬 더 신속하게 응답할 수 있습니다. 그래서 이 모델은 코드에 대해 질문하고, 변경하거나 더 잘 이해해야 할 코드 조각을 찾아내고, 계획을 수립할 수 있는 훌륭한 협력자(collaborative)와 같습니다. 그러나 일단 어떤 작업을 맡기면, 매우 오랜 시간 동안 꾸준히 작동할 것입니다. 내부적으로는 매우 복잡한 리팩토링(refactoring) 작업에 최대 7시간까지 작동하는 것을 관찰했습니다. 이는 다른 모델에서는 이전에 볼 수 없었던 현상입니다. 우리는 또한 코드 품질 향상에 엄청난 노력을 기울였으며, GPT-5는 코덱스(Codex) 내에서 사람들이 사용하는 용도에 맞춰 정말 최적화되어 있습니다. 이처럼 신중하게 적용된 끈기(tenacity judiciously applied) 덕분에 GPT-5-코덱스(GPT-5-Codex)는 가장 어려운 문제에만 최적화되어 덜 똑똑한 모델(dumber models)을 위한 모델 전환기(model switcher)를 요구하지 않고, 훨씬 더 유용한 전천후 에이전트형 코딩 모델(agentic coding model)이 됩니다. (흥미롭게도, 우리가 이전에 다루었던 챗GPT(ChatGPT)의 GPT-5 라우터(GPT-5 Router)는 사용하지 않습니다: https://x.com/swyx/status/1967651870018838765/photo/1)"

**정체에서 벗어나 반박하기(Getting out of Ruts and pushing back)**

그렉(Greg)은 다음과 같이 말합니다: "GPT-3와 GPT-4에서는 '고집하는 문제(doubling down problem)'에 정말 집중했던 기억이 납니다. AI가 잘못된 말을 하고 당신이 실수를 지적하면, AI는 자신이 옳다고 설득하려 했던 것을 기억하십니까? 우리는 이제 그 문제가 핵심 문제가 아닌 수준에 도달했습니다. 심지어 정확한 것을 완전히 찾아내지 못했을 때도 중요한 것을 강조하는 수준에 있다는 것이 정말 놀랍습니다. 꽤 합리적인 생각을 합니다. 그렉 브록먼(Greg Brockman): 그리고 저는 항상 이러한 코드 리뷰를 마치고 '음, 그래, 좋은 지적이야'라고 생각합니다." 우리는 그들이 이러한 현실성(groundedness) 수준을 어떻게 달성했는지 알 수 없지만, 이는 GPT-5에서 환각(hallucination) 현상이 측정 가능하게 감소한 것과 매우 밀접하게 관련되어 있을 가능성이 높습니다.

**토큰 효율성(Token Efficiency)**

업계의 가장 숨겨진 비밀 중 하나는 "토큰당 가격(price per token)"이 점점 더 의미 없는 지표가 되고 있다는 점입니다. 이는 추론 모델(reasoning models)이 질문에 답하기 위해 종종 10배 이상의 토큰을 사용할 수 있기 때문입니다. 특히 사용자가 내부 작동 방식을 알 수 없는 경우에는 더욱 그렇습니다. 인공 분석 AIE 강연(Artificial Analysis AIE talk)에서 코덱스(Codex)는 토큰 효율성(token efficiency)에 특별히 최적화되어 있다고 언급되었습니다. https://x.com/camsoft2000/status/1964787205571772511?s=46

이러한 설명하기 어려운 모든 품질(hard-to-articulate qualities)은 결국 한 가지 결론으로 귀결됩니다: 새로운 평가(evals)의 필요성.

**새로운 관점: 신뢰할 수 있는 AI 개발의 기반, 후속 훈련 혁신**

GPT-5-코덱스(GPT-5-Codex)가 보여주는 '가변적인 끈기'와 '정체에서 벗어나 반박하는' 능력은 단순히 모델의 성능 향상을 넘어, AI를 활용한 소프트웨어 개발의 신뢰성과 효율성을 혁신하는 중요한 진전입니다. 과거 AI 모델들은 복잡한 작업에서 쉽게 포기하거나, 잘못된 경로를 고집하는 경향이 있었습니다. 그러나 GPT-5는 마치 숙련된 인간 개발자처럼 문제 해결에 끈기를 보이고, 주어진 지시가 비합리적일 경우 합리적인 근거를 들어 반박하며 더 나은 대안을 제시할 수 있습니다. 이는 모델이 단순히 패턴을 인식하는 것을 넘어, 문제의 본질을 이해하고 맥락에 따라 유연하게 대응하는 '사고' 능력을 갖추기 시작했음을 의미합니다.

이러한 능력은 특히 디버깅, 복잡한 시스템 설계, 또는 새로운 아키텍처 탐색과 같이 고도의 인지 능력과 지속적인 탐색이 필요한 작업에서 빛을 발합니다. 개발자는 이제 AI를 단순히 코드를 생성하는 도구가 아닌, 함께 고민하고 해결책을 찾아나가는 동반자로 활용할 수 있게 됩니다. 또한, 토큰 효율성의 개선은 이러한 고급 기능들을 경제적이고 지속 가능한 방식으로 제공하는 기반이 됩니다. 이는 AI 모델이 단순히 '더 똑똑해지는' 것을 넘어, '더 유용하고 신뢰할 수 있는' 존재로 진화하고 있음을 보여주는 중요한 증거입니다. 이러한 품질은 AI가 개발자의 생산성을 획기적으로 향상시키고, 궁극적으로 소프트웨어 개발의 패러다임을 변화시키는 데 필수적인 요소가 될 것입니다.

**요인 3: 에이전트형 코딩(Agentic Coding)을 위한 새로운 평가(Evals)**

GPT-5 출시와 관련하여 초기에 나타난 부정적인 반응(negative first reactions)의 문제는 대부분의 사람들이 실제 환경에서 모델을 직접 사용해보지 않고, 헤드라인과 통계 조작(chart crimes)에만 반응했다는 점입니다. 저를 포함하여 모델을 실제로 사용해본 사람들은 이미 적응과 인식 변화(sentiment shift)를 경험했으며, GPT-5에 대한 인식 반전(Sentiment Flip)은 O1 출시 때와 마찬가지로 예상대로 제때 일어났습니다. 개발자를 위한 GPT-5 영상(GPT-5 for Developers video)을 촬영한 직후 제가 즉시 떠올린 생각은 "더 나은 분위기 점검(vibe checks)이 필요할 것"이라는 것이었습니다.

모든 사람들은 자신이 선호하는 현장 점검(spot checks) 방식을 가지고 있습니다. 저희 영상에서는 테오(Theo)가 헥사곤 볼(Hexagon ball)을 사용했고 (출시 후 태도를 바꿨습니다), 사이먼(Simon)은 펠리칸벤치(PelicanBench)를 사용했으며, 벤(Ben)은 물론 글쓰기를 테스트하고 잠재 공간 해트트릭(Latent Space hat trick)을 위해 돌아왔습니다. 하지만 제가 개발자 영상에서 언급했던 GPT-5의 에이전트형 코딩 능력(agentic coding abilities)은 매우 현실적입니다: 다음은 저희가 접근 권한을 얻었을 때 영상에서 실제로 시도했던 코드베이스(codebase)입니다: 이 블로그 게시물(blogpost)을 준비하기 위해 아주 좋은 커서 로그(Cursor logs)를 가지고 있었지만… 제 채팅 기록 로그(chat history logs)에서 사라진 것 같습니다. 죄송합니다 :/ 이것은 제가 몇 달 동안 클로드 코드(Claude Code)에 수십 시간을 쏟아부었지만 아무 소용이 없었던 상황에서 GPT-5가 "도구를 활용하여 사고(thought with tools)"하여 코드를 계측(instrumented the code)하고, 저에게 로그를 다시 읽어주게 한 다음 해결책을 찾았다는 점에서 더욱 인상적이었습니다.

이것이 바로 새로운 모델이 출시되는 순간 가장 시끄럽고 자신감 있는 의견(loudest most confident takes)을 내놓으려는 소셜 미디어(social media) 압력의 문제입니다. 모델의 분위기(vibes)를 측정하기 위해 간단한 단일 턴, 최소 도구 호출 테스트(one-turn, minimal-tool-call tests)만으로는 충분하지 않습니다 (제 농담은 "파란색과 보라색 그라데이션(blue and purple gradients)만 있다면 어떤 웹사이트든 바이브코드(vibecode)할 수 있다"는 것입니다). 에이더(Aider)의 다국어 벤치마크(polyglot benchmarks)조차도 실제 코드베이스(codebases)에서 다중 턴, 다단계, 도구를 활용하여 사고하는 코딩 에이전트(multi-turn, multi-step, thinking-with-tools coding agents)를 의미하는 에이전트형 코딩(agentic coding)을 실제로 테스트하지는 않습니다. 해결책은 분명했습니다: 실제 오픈 소스 코드베이스(open source codebases)에서 실제 작업을 대상으로 모델의 블라인드 테스트(blind taste test)를 실시하고 관리자(maintainers)가 성능을 평가하도록 하는 것입니다! 그래서 우리는 정확히 그렇게 했습니다: 이 게시물은 나중에 테스트 결과와 함께 업데이트될 예정입니다. 어쨌든, 코딩(Koding)의 모든 것과 마찬가지로, 그렉 브록먼(Greg Brockman)은 OpenAI의 코딩 능력(coding capabilities) 변화를 이끄는 주역(frontman)이었습니다. 저는 월드 페어(World’s Fair)에서 그를 인터뷰할 특권을 가졌으며, 이 뉴스레터(newsletter)에서는 오늘 공개된 OpenAI 팟캐스트(podcast)와 지난달 공개된 그의 잠재 공간 팟캐스트(Latent Space pod)를 요약합니다. 이 모든 내용은 위대한 OpenAI 코딩 복귀(coding comeback)를 따라잡는 사람들을 위해 한곳에 모아두었습니다. 즐겁게 읽으세요!

**새로운 관점: 복잡한 AI 시스템 평가의 새로운 지평**

에이전트형 코딩(agentic coding) 모델과 같이 복잡하고 다단계적인 AI 시스템을 평가하는 것은 단순한 벤치마크 점수로는 한계가 있습니다. 기존의 벤치마크는 주로 단일 작업의 정확성이나 효율성을 측정하는 데 중점을 두지만, 실제 개발 환경에서는 AI가 여러 도구를 사용하고, 다양한 정보를 통합하며, 장기적인 계획을 수립하고 실행하는 능력이 중요합니다. 따라서 GPT-5와 같은 차세대 모델의 진정한 역량을 파악하기 위해서는 새로운 평가 패러다임이 요구됩니다.

제안되는 새로운 평가 방법론은 다음과 같습니다:
1.  **실제 코드베이스 기반 시나리오 평가:** 특정 오픈 소스 프로젝트의 버그 수정, 기능 추가, 리팩토링 등 실제 개발 시나리오를 AI에 부여하고, 그 과정과 결과를 분석합니다. 이때, 코드 품질, 해결 시간, 중간 단계의 의사 결정 과정, 그리고 인간 개발자와의 협업 용이성 등을 종합적으로 평가합니다.
2.  **인간 전문가 블라인드 평가:** AI가 생성한 코드와 인간 개발자가 작성한 코드를 섞어 전문가들에게 블라인드 테스트를 진행하여, AI의 코드 품질과 효율성이 인간 수준에 도달했는지, 또는 그 이상인지를 객관적으로 판단합니다.
3.  **다단계 및 다중 도구 활용 능력 측정:** AI가 문제 해결을 위해 얼마나 다양한 개발 도구(예: 컴파일러, 디버거, 테스트 프레임워크, 문서 검색 엔진)를 효과적으로 활용하고, 여러 단계를 거쳐 복잡한 문제를 해결하는지를 평가하는 지표를 개발합니다.
4.  **윤리적 및 보안 취약성 평가:** AI가 생성한 코드가 잠재적인 보안 취약점이나 윤리적 편향을 포함하고 있는지 여부를 식별하고, 이를 완화하기 위한 AI의 자체적인 방어 메커니즘을 평가합니다.

이러한 다각적인 평가 방법론을 통해 우리는 GPT-5와 같은 에이전트형 AI 모델의 진정한 가치를 이해하고, 미래 소프트웨어 개발에 미칠 영향력을 보다 정확하게 예측할 수 있을 것입니다.

**그렉(Greg)과 티보(Thibault)의 OpenAI 팟캐스트(Podcast)**

**그렉 브록먼(Greg Brockman)의 잠재 공간(Latent Space)**
이 에피소드는 지난달에 녹음되어 방송되었습니다.

**쇼 노트(Show Notes)**
그렉 브록먼(Greg Brockman)
튜링 테스트 논문(Turing Test Paper)
커널 랩스(Kernel Labs)
ARC 연구소(ARC Institute)
GPT-5 리뷰(GPT-5 Review)
GPT-OSS
도타(Dota) (OpenAI 파이브(Five))
이미지젠(ImageGen)
LM 아레나(LM Arena)
IMO 골드(IMO Gold) (국제 수학 올림피아드(International Mathematical Olympiad))
IOI 골드(IOI Gold) (국제 정보 올림피아드(International Olympiad in Informatics))
다이슨 스피어(Dyson Sphere)

**타임스탬프(Timestamps)**
[00:00:04] 서론
[00:01:04] OpenAI의 추론(Reasoning) 진화
[00:04:01] 언어 모델(Language Models)의 온라인(Online) 및 오프라인(Offline) 학습
[00:06:44] 강화 학습(Reinforcement Learning)의 샘플 효율성(Sample Efficiency) 및 인간 큐레이션(Human Curation)
[00:08:16] 컴퓨트(Compute) 확장 및 초임계 학습(Supercritical Learning)
[00:13:21] RL(강화 학습) 및 실제 상호작용에서의 벽시계 시간(Wall clock time) 제약
[00:16:34] ARC 연구소(ARC Institute) 및 DNA 신경망(DNA neural networks) 경험
[00:19:33] GPT-5 시대 정의
[00:22:46] 모델 지능 및 작업 난이도 평가
[00:25:06] GPT-5를 사용하는 개발자를 위한 실용적인 조언
[00:31:48] 모델 사양(Model Specs)
[00:37:21] RL 선호도(Preferences)의 과제 (예: try/catch)
[00:39:13] GPT-5의 모델 라우팅(Model Routing) 및 하이브리드 아키텍처(Hybrid Architectures)
[00:43:58] GPT-5 가격 책정 및 컴퓨트 효율성 개선
[00:46:04] 자체 개선 코딩 에이전트(Self-Improving Coding Agents) 및 도구 사용
[00:47:36] 어떤 아키텍처 결정이나 혁신에 대해 이야기하고 싶으십니까?(Any architectural decisions or innovations that you would like to talk about?)
[00:49:11] 온디바이스 모델(On-Device Models) 및 로컬(Local) vs 원격 에이전트 시스템(Remote Agent Systems)
[00:51:34] OpenAI의 엔지니어링 및 LLM(대규모 언어 모델) 활용
[00:54:16] AI 최적화를 위한 코드베이스(Codebases) 및 팀 구성
[00:55:27] AGI 시대 엔지니어의 가치
[00:58:42] AI 연구의 현재 상태 및 연구소 다양성
[01:01:11] OpenAI의 우선순위 및 중점 분야
[01:03:05] 창업자를 위한 조언: 아직 늦지 않았다
[01:04:20] 미래 전망 및 마무리 생각
[01:04:33] 2045년 타임캡슐: 컴퓨트(Compute)와 풍요의 미래
[01:07:07] 2005년 타임캡슐: 더 많은 문제가 나타날 것이다

**대본(Transcript)**

**서론(Introductions)**

알레시오(Alessio) [00:00:04]: 안녕하세요, 여러분. 잠재 공간 팟캐스트(Latent Space podcast)에 오신 것을 환영합니다. 저는 커널 랩스(Kernel Labs)의 설립자 알레시오(Alessio)이고, 스윅스(Swyx), 스몰 AI(Small AI)의 설립자와 함께합니다.
스윅스(Swyx) [00:00:10]: 안녕하세요. 그렉 브록먼(Greg Brockman)을 모시게 되어 정말 기쁩니다. 환영합니다. 초대해주셔서 감사합니다. 여기 오게 되어 기쁩니다. 소개가 필요 없으시죠. 그래서 제가 마음속으로 소개를 하려다가 바로 본론으로 들어가겠습니다. GPT-5, GPT-OSS, OpenAI에서 진행되는 모든 일들에 대해 축하드립니다. 이 모든 것을 어떻게 해내셨습니까? 여기 와주셔서 정말 좋습니다. 기분이 어떠신가요? 지난주는 정말 많은 출시가 있었던 혼란의 주였습니다.
그렉(Greg) [00:00:33]: 출시요. 정말 정신없었습니다. 한 주 동안 그렇게 많은 것을 출시하는 것은 정말 정신없는 일이었습니다. 하지만 네, 저희는 오픈 소스 모델(open source models)을 출시했습니다. 오랫동안 작업해온 모델들이죠. OpenAI에서 이룬 많은 발전들을 매우 작은 형태로, 매우 접근하기 쉽게 담아냈다고 생각합니다. 지난 며칠 동안만 해도 수백만 건의 다운로드가 있었습니다. 저희는 또한 GPT-5도 출시했습니다. 이것 역시 오랫동안 작업해온 것입니다. 그래서 이 모든 것을 세상에 내놓고 출시 과정을 마쳤다는 것이 정말 기쁩니다. 팀이 해낸 일에 대해 정말 자랑스럽습니다.

**OpenAI의 추론(Reasoning) 능력 진화(The Evolution of Reasoning at OpenAI)**

알레시오(Alessio) [00:01:04]: 그리고 GPT-5는 최초의 하이브리드 모델(hybrid model)입니다. 그래서 대부분의 사람들은 하나의 모델을 선택할 수 없습니다. 그리고 그것은 우리가 다루지 않을 또 다른 드라마입니다. 또 다른 이야기죠. 하지만 당신은 원래 일리야(Ilya)와 함께 OpenAI에서 추론 팀(reasoning team)을 시작했습니다. OpenAI의 추론(reasoning) 역사에 대해 간략하게 설명해주실 수 있나요? 처음에는 단순히 다음 토큰 예측(next token prediction)으로 시작했고, 어느 시점에서 추론(reasoning)이 중요한 것이라고 생각하게 되었죠. 사용자에게는 숨겨져 있는 GPT-5까지의 경로는 어땠습니까?
그렉(Greg) [00:01:31]: 음, 이렇게 말씀드리겠습니다. GPT-4를 훈련시킨 후, 우리는 대화할 수 있는 모델을 갖게 되었습니다. 그리고 저는 첫 번째 작업을 했던 것을 기억합니다. 우리는 후속 훈련(post-training)을 했습니다. 실제로 지시 따르기 후속 훈련(instruction following post-train)을 했습니다. 그래서 그것은 정말 단순히 '여기에 질문이 있습니다. 모델 완성(model completion)은 이래야 합니다'라는 데이터셋(dataset)이었습니다. 그리고 우리는 '음, 다른 질문으로 계속하면 어떻게 될까?'라고 생각했습니다. 그리고 그것은 실제로 이전의 질문과 답변 체인(chain) 전체를 맥락(context)으로 삼아 응답할 수 있었습니다. 그리고 당신은 이 모델이 채팅(chat)을 할 수 있다는 것을 깨달았습니다. 그렇죠? 실제로 당신과 대화할 수 있고, 훈련받지 않았음에도 불구하고 이 모든 정보를 활용할 수 있습니다. 그리고 저는 우리가 이 질문을 했던 것을 기억합니다. 야콥(Jakob), 일리야(Ilya), 보이치에흐(Wojciech) 등 여러 사람들과 연구 회의를 했습니다. 질문은 '왜 이것이 AGI가 아닌가?'였습니다. 그렇죠? 이 모델은 분명히 AGI가 아니지만, 왜 그런지 설명하기가 정말 어렵습니다. 그렇죠? 어떤 질문이든 답할 수 있는 것 같고, 물론 완전히 신뢰할 수 있는 것은 아닙니다. 실수를 하고, 엉뚱한 방향으로 가기도 합니다. 좋습니다. 그것은 실제 격차입니다. 그렇다면 그 격차를 줄이기 위해 무엇을 해야 할까요? 가장 분명한 것은 실제로 모델이 세상에서 자신의 아이디어를 시험해 보도록 하는 것입니다. 그렇죠? 실제로 강화 학습(reinforcement learning)을 수행하여 가설(hypotheses)을 시도하고 피드백(feedback)을 받아 거기서부터 신뢰성을 확보하는 것입니다. 그리고 이것은 우리에게 새로운 아이디어가 아닙니다. 그렇죠? 2017년으로 거슬러 올라가도, 우리는 도타(Dota)를 작업하고 있었는데, 그것은 전적으로 강화 학습(reinforcement learning)이었고, 인간 시연(human demonstrations)으로부터의 행동 복제(behavioral cloning) 같은 것은 없었습니다. 단순히 무작위로 초기화된 신경망(neural net)에서 놀랍도록 복잡하고 정교하며 매우 정확한 행동을 얻을 수 있었습니다. 그리고 우리는 언어 모델(language models)에 대해 그러한 신뢰성을 원했습니다. 그래서 GPT-4를 훈련시킨 순간, 우리는 추론 패러다임(reasoning paradigm)으로 나아가야 한다는 것을 알았습니다. 그리고 그것은 단지 '어떻게'의 문제였습니다. 그래서 우리는 10가지 아이디어, 무엇이 효과가 있을지에 대한 다양한 가설(hypotheses)을 가지고 있었습니다. 그리고 사람들은 그것을 현실로 만들기 위해 정말 노력했습니다. 그래서 그것은 OpenAI의 많은 사람들이 여러 해 동안 노력한 결과였습니다. 그리고 저는 이 분야의 발전 방식은 방향에 대한 확신(conviction)을 가져야 한다는 것이라고 생각합니다. 그렇죠. 그리고 시도하는 첫 10가지 일은 실패할 것입니다. 그리고 그 10가지 목록에 있는 대부분의 것들은 성공하지 못했지만, 우리는 그 중 하나를 성공시켰습니다. 그리고 저는 그것이 진정한 핵심이라고 생각합니다. 우리는 계속해서 밀어붙이고, 작은 생명의 징후를 얻으면 거기서부터 계속 성장합니다. 그래서 이제 제리(Jerry)가 우리의 강화 학습 팀(reinforcement learning team)을 이끌고 있으며, 그곳에서 정말 큰 발전을 이루었습니다. 웬다(Wenda) 같은 사람, 펠리페(Felipe) 같은 추론(inference) 측 사람 등 OpenAI의 많은 사람들이 함께 모여 정말 놀라운 인프라(infrastructure) 작업을 하고 있습니다. 그리고 저는 이 작업을 실제로 성공시키기 위해 우리가 함께 일할 수 있다는 것이 정말 중요하다고 생각합니다.

**새로운 관점: AI 추론 능력의 철학적 함의**

OpenAI의 추론(reasoning) 능력 진화는 단순한 기술적 발전을 넘어 AI의 본질과 인간 지능에 대한 우리의 이해에 깊은 철학적 질문을 던집니다. 초기 언어 모델이 '다음 토큰 예측'에 불과했다면, 이제는 강화 학습(RL)을 통해 실제 세계의 피드백을 받아 가설을 검증하고, 복잡한 문제에 대한 '신뢰성 있는' 해결책을 찾아내는 단계에 이르렀습니다. 이는 AI가 단순히 정보를 처리하는 기계를 넘어, '사고'하고 '학습'하며 '결정'하는 주체로 진화하고 있음을 시사합니다.

그렉(Greg)이 언급했듯이, GPT-4 훈련 후 "왜 이것이 AGI가 아닌가?"라는 질문은 AI의 능력이 인간의 인지 능력과 유사한 수준에 도달하고 있음을 보여줍니다. 이러한 AI의 추론 능력은 과학적 발견, 예술 창작, 복잡한 사회 문제 해결 등 인간 고유의 영역으로 여겨지던 분야에 새로운 가능성을 열어줍니다. 예를 들어, AI는 방대한 과학 논문을 분석하여 새로운 가설을 생성하고, 실험 설계를 제안하며, 심지어 새로운 수학적 증명을 찾아낼 수도 있습니다. 이는 인간 연구자가 AI와 협력하여 과학적 지식의 한계를 확장하고, 인류가 직면한 가장 어려운 난제들을 해결하는 데 결정적인 역할을 할 수 있음을 의미합니다.

그러나 동시에 이러한 발전은 AI의 '의식'이나 '자율성'에 대한 논의를 촉발하며, AI가 과연 '생각'하는 것인지, 아니면 단지 정교한 패턴 매칭에 불과한 것인지에 대한 질문을 재점화합니다. 중요한 것은 AI의 추론 능력이 인간의 그것과 완전히 동일하지 않더라도, 그 결과물이 인간 지능의 성과와 구별하기 어려울 정도로 발전하고 있다는 사실입니다. 이는 AI가 인간의 지적 활동을 증강하고 확장하는 강력한 도구가 될 것임을 명확히 보여줍니다.

**언어 모델(Language Models)의 온라인(Online) 및 오프라인(Offline) 학습(Online vs Offline Learning in Language Models)**

스윅스(Swyx) [00:04:01]: 놀랍습니다. 당신이 엔지니어 컨퍼런스(engineer conference)에서 저와 함께 있을 때 튜링 논문(Turing paper)에 대해 이야기했던 것을 다시 생각해보니, 당신은 그 논문을 좋아했고 그것이 당신의 머신러닝(machine learning) 여정을 시작하는 데 어느 정도 영향을 주었죠. 그리고 저는 사실 그가 학습 기계(learning machine)가 부분적으로 온라인(online)일 것이라고 예상했다고 생각합니다. 아시다시피, 그것이 제가 3, 4에서 5로 가는 이 여정을 되돌아볼 때 항상 가졌던 질문 중 하나입니다. 학습은 모두 오프라인(offline)에서 시작되었고 모두 사전 훈련(pre-trained)되었는데, 이제 서서히 다시 온라인(online)으로 돌아오고 있습니다. 그것이 정확하다고 생각하십니까?
그렉(Greg) [00:04:31]: 네. 매우 흥미로운 질문이라고 생각합니다. 그렇죠? 학습이 어디에서 일어나는가? 그리고 저는 우리가 아직 인간이 하는 완전한 종류의 학습 루프(learning loop)에는 도달하지 못했다고 생각합니다. 네. 그렇죠. 인간이 완전히 온라인(online)인지도 명확하지 않습니다. 왜냐하면, 아시다시피, 잠을 자면 장기 기억(long-term memory)으로 많은 종류의 역전파(back propagation)가 일어납니다. 그래서 저는 인간이 작동하는 방식이 반드시 우리의 기계가 작동하는 방식과 일치한다고 생각하지 않습니다. 하지만 우리는 단순히 기계를 만들고, 한 번 훈련시키고, 그 다음에는 엄청난 추론(inferencing)을 하는 세상에서, 실제로 추론(inference)을 하고 그 추론(inferencing)을 기반으로 훈련하는 루프(loop)가 있는 세상으로 이동하고 있습니다. 그리고 일리야(Ilya)가 자주 말했던 것 중 매우 통찰력 있다고 생각하는 한 가지는, 모델의 능력이 매우 낮을 때, 그들이 생성하는 토큰(token)의 가치가 매우 낮다는 것입니다. 모델의 능력이 매우 높을 때, 그들이 생성하는 토큰(token)의 가치는 매우 높습니다. 그렇죠. 그것은 매우 사려 깊은 것이고, 중요한 것입니다. 그리고 강화 학습(reinforcement learning)은 이러한 속성을 가지고 있습니다. 모델이 여러 가지를 시도하기 때문에 많은 데이터를 생성하고, 그 데이터를 기반으로 훈련합니다. 그래서 모델의 관찰(observations)은 현실과의 접촉으로 정규화되거나, 현실과의 접촉으로 선택되어 기계로 다시 피드백됩니다. 그리고 저는 그것이 우리가 배우는 데 매우 능숙해지기 시작한 것이라고 생각합니다. 그리고 필요한 규모(scale)는 매우 다릅니다. 그렇죠? 사전 훈련(pre-training)을 보면, 당신의 10가지 예시는 아무것도 아닙니다. 당신은 수십만 가지의 작은 행동 유형에 대해 이야기하고 있습니다. 그리고 그것이 당신이 배우는 것입니다. 이는 인간이 배우는 방식과는 완전히 다릅니다. 다시 말하지만, 저는 그렇다고 생각합니다. 당신이 모든 진화(evolution)를 되짚어보고 20년 동안의 발달 역사(developmental history)를 생각한다면, 세상에서 많은 것을 관찰하는 일이 일어납니다. 당신의 감각을 통해 흐르는 많은 정보 조각들이 있습니다. 하지만 강화 학습 패러다임(reinforcement learning paradigm)에서는 10가지 예시나 100가지 예시가 있다면, 그렇죠? 당신이 해야 할 10가지 경로가 있고, 모델이 여러 번 시도하면 실제로 거기서부터 배울 수 있습니다. 그래서 당신은 이러한 레버리지(leverage)를 얻게 됩니다. 그리고 인간 큐레이터(human curator)가 그러한 작업을 생성하는 것으로부터 레버리지를 얻을 수 있으며, 모델로부터 매우 정교한 행동을 실제로 얻을 수 있습니다. 그리고 이제 모델이 진행하면서 온라인(online)으로 학습하는 다음 단계가 있습니다. 우리는 아직 그렇게 하고 있지는 않지만, 미래는 아직 쓰여지지 않았습니다.

**새로운 관점: AI의 평생 학습(Lifelong Learning)과 지속적인 적응**

AI 모델의 학습 방식이 오프라인(offline) 사전 훈련(pre-training)에서 점차 온라인(online) 강화 학습(reinforcement learning)으로 진화하고 있다는 점은 '평생 학습(lifelong learning)'이라는 개념을 AI에 도입하는 중요한 단계입니다. 인간은 태어나서 죽을 때까지 끊임없이 새로운 경험을 통해 학습하고 지식을 업데이트합니다. 반면, 기존 AI 모델은 한 번 훈련이 완료되면 그 이후에는 새로운 정보를 스스로 습득하여 모델을 개선하는 능력이 제한적이었습니다.

그러나 강화 학습을 통해 AI가 실제 환경에서 상호작용하고, 그 결과에 대한 피드백을 바탕으로 스스로를 조정하고 발전시키는 능력은 AI의 평생 학습 가능성을 열어줍니다. 이는 AI가 고정된 지식 기반에 갇히지 않고, 변화하는 환경에 지속적으로 적응하며 새로운 지식을 통합할 수 있음을 의미합니다. 예를 들어, 코딩 에이전트(coding agent)는 새로운 프로그래밍 언어나 프레임워크가 등장했을 때, 다시 처음부터 훈련될 필요 없이 온라인 학습을 통해 관련 기술을 습득하고 적용할 수 있습니다.

이러한 평생 학습 능력은 AI 시스템의 유지보수 비용을 절감하고, 장기적인 가치를 증대시키는 데 기여할 것입니다. 또한, AI가 특정 도메인에 국한되지 않고 다양한 분야에서 새로운 정보를 학습하고 통합함으로써, 더욱 범용적이고 강력한 인공지능으로 발전할 수 있는 기반을 마련합니다. 물론, 평생 학습 과정에서 발생하는 지식 망각(catastrophic forgetting)이나 새로운 정보의 편향(bias) 문제 등 해결해야 할 과제들도 많지만, 이는 AI 연구의 중요한 다음 단계가 될 것입니다.

**강화 학습(Reinforcement Learning)의 샘플 효율성(Sample Efficiency) 및 인간 큐레이션(Human Curation)(Sample Efficiency and Human Curation in Reinforcement Learning)**

알레시오(Alessio) [00:06:44]: 노암 브라운(Noam Brown)과 샘플 효율성(sample efficiency)에 대해 논의했습니다. 오늘날 병목 현상(bottleneck)이 여전히 RL(강화 학습)이 작동하도록 이러한 훌륭한 작업을 만드는 인간 데이터 큐레이터(human data curator)라고 생각하십니까? 아니면 여전히 모델의 샘플 효율성(sample efficiency)이라고 생각하십니까?
그렉(Greg) [00:06:57]: 음, 병목 현상(bottleneck)은 항상 컴퓨트(compute)입니다. 그렇죠. 그리고 저는 그것을 실제로 의미합니다. 그렇죠? 마치 '만약 당신이 우리에게 많은 컴퓨트(compute)를 준다면, 우리는 그것을 최대한 활용할 수 있는 방법을 찾을 것입니다'와 같습니다. 우리는 지금 훨씬 더 샘플 효율적인 알고리즘(sample efficient algorithms)을 가진 세상에 살고 있습니다. 그렇죠? RL 패러다임(RL paradigm)을 통해 말이죠. 하지만 여전히 많은 컴퓨트(compute)가 필요합니다. 그렇죠? 마치 인간이 만든 하나의 작업이나 10개의 작업, 또는 100개의 작업, 또는 그 소수의 작업이 있고, 모델이 여러 번 시도하는 것과 같습니다. 네. 그리고 모델이 한 가지 작업을 수행하기 위해 10번이 아니라 10,000번 시도하고, 당신은 그 중에서 선택하고 거기서부터 배웁니다. 그리고 다시 말하지만, 인간 설계자로서 당신이 얻는 인간 레버리지(human leverage)의 양은 극도로 높지만, 그것을 작동시키기 위해 투입해야 하는 컴퓨트(compute)의 양은 비례적으로 증가합니다.

**컴퓨트(Compute) 확장 및 초임계 학습(Supercritical Learning)(Scaling Compute and Supercritical Learning)**

스윅스(Swyx) [00:07:45]: 학습 과정에서 더 많은 컴퓨트(compute)를 소비하는 한 가지 방법은 앨런 튜링(Alan Turing)이 이 모든 것을 많이 예견했다는 것입니다. 그는 아임계 학습(sub-critical learning) 대신 초임계 학습(super critical learning)이라는 개념을 가지고 있었습니다. 즉, 우리가 기계에 학습을 제시하거나 가르칠 때, 기계는 우리가 방금 가르친 즉각적인 것만 배웁니다. 하지만 초임계(super critical)는 당신이 방금 배운 모든 것의 2차, 3차, 4차 효과를 통해 당신이 아는 다른 모든 것을 업데이트하는 것을 의미합니다. 그렇다면 우리는 더 많은 컴퓨트(compute)를 어떤 창의적인 방식으로 소비할까요? 그렇죠? 만약 우리가 10배 더 많은 컴퓨트(compute)나 1000배 더 많은 컴퓨트(compute)를 가지고 있다면, 그것은 어디로 갈까요?
그렉(Greg) [00:08:16]: 우리는 그것을 실현할 방법을 찾을 것이라고만 말하겠습니다. 제발 우리에게 주세요. 하지만 저는 그것을 진지하게 받아들입니다. 그렇죠? 이것이 작동하는 방식은 이렇습니다. 도타(Dota)와 같은 것을 되감아보면, 우리는 새로운 강화 학습 알고리즘(reinforcement learning algorithms)을 개발하기 시작했습니다. 왜냐하면 당시 존재했던 강화 학습(reinforcement learning) 알고리즘이 확장되지 않는다는 것이 모두에게 분명했기 때문입니다. 모두가 알고 있었습니다. 그리고 저는 야콥(Jacob)과 시몬(Shimon)이 '왜 우리가 그것을 믿지? 아무도 실제로 테스트해보지 않았잖아?'라고 말했던 것을 기억합니다. 그리고 아무도 실제로 구식 PPO(PPO)를 확장하여 '음, 그것이 기준선이야. 우리는 해야 해'라고 말해보지 않았습니다. 그리고 저는 매주 사무실로 돌아오면 코어(cores) 수가 두 배로 늘어났던 것을 기억합니다. 에이전트(agent)만 그랬습니다. 진정한 기술은 계속해서 향상되고 있었습니다. 계속해서 우상향했습니다. 그리고 '좋아, 벽에 부딪힐 때까지 계속 밀어붙여야 해. 그리고 분명히 벽에 부딪히면 실제 흥미로운 일을 할 수 있을 거야'라고 생각했습니다. 그리고 우리는 결코 벽에 부딪히지 않았습니다. 그리고 당신은 실제로 그 확장(scaling)의 여정, 그것이 흥미로운 일이라는 것을 깨닫습니다. 그렇죠? 진정한 엔지니어링(engineering)을 하는 것입니다. 물론 버그(bugs)가 있고 그 버그(bugs)가 벽을 만들지만, 당신은 버그(bug)를 고칩니다. 그렇죠? 신경망(neural nets)이 초기화되는 방식이나 스케일링 분산(scaling variance) 등 다른 문제가 있지만, 그것들은 알고리즘(algorithm)이나 과학의 근본적인 문제가 아닙니다. 그래서 저는 우리가 처한 세상이 그런 종류의 세상이라고 생각합니다. 우리는 모든 차원에서 밀어붙일 것이고, 아마도 벽에 부딪힐 것입니다. 대부분의 경우, 그 벽은 단순히 버그(bugs)나 어리석은 것들입니다. 그래서 당신은 계속 나아갈 수 있습니다. 때로는 그것들을 고치는 ROI(투자 수익률)가 정말 어렵습니다. 그렇죠? 그래서 그것은 정말 가치가 없습니다. 왜냐하면 당신은 다른 차원을 가지고 있기 때문입니다. 그렇죠? 모델을 더 크게 만들고 사전 훈련 컴퓨트(pre-training compute)를 더 많이 할 것인가, 아니면 RL(강화 학습)을 더 많이 할 것인가? 그래서 실제 테스트 시간(test time)에 더 많은 컴퓨트(compute)를 투입할 것인가? 그리고 컴퓨트(compute)를 투입할 수 있는 모든 종류의 차원이 있습니다. 그리고 어떤 면에서는 컴퓨트(compute)를 마치 정제 과정(refining process)과 같다고 생각합니다. 궁극적으로 에너지(energy)로 시작하여 컴퓨트(compute)로 변하고, 지능(intelligence)으로 변하며, 그것은 거의 그 컴퓨트(compute)를 모델이 유용한 일을 할 수 있는 잠재 에너지(potential energy)로 결정화시키는 것과 같습니다. 정말 아름다운 일입니다. 그렇죠? 마치 컴퓨트(compute)가 지능(intelligence)의 근본적인 동력, 근본적인 연료와 같고, 신경망(neural net)을 형성하며, 프로그램을 출력하는 것과 같습니다. 그리고 물론 그 프로그램의 좋은 점은 당신이 이 모든 컴퓨트(compute)를 투입했음에도 불구하고 여러 번 실행할 수 있다는 것입니다. 당신은 그것을 한 번 만드는 데 들인 노력보다 훨씬 더 많이 사용할 것이라는 상각(amortization)을 가지고 있습니다. 그래서 그것은 아름다운 패러다임(paradigm)입니다.
알레시오(Alessio) [01:10:27]: 네. 운동 에너지(kinetic energy)를 모델의 잠재 에너지(potential energy)로 바꾸는 것과 같습니다. 그리고 이 모델에 이미 있는 에너지를 운동 에너지(kinetic energy)로 다시 바꿔서 다른 모든 영역에서 RL(강화 학습)을 할 수 있다고 생각하십니까? 왜냐하면 우리는 IMO 골드(IMO gold)를 얻었으니까요. 제 말은, 우리, 당신들, 모두가 말이죠. 같은 기술과 같은 기본 모델이 IMO 골드(IMO gold)에 해당하는 목표를 달성하게 할 수 있다고 생각하십니까? 네. 제 말은, 우리가 컴퓨트(compute)를 확장하기만 하면 될까요, 아니면 아직 해야 할 일이 남아 있다고 생각하십니까?
그렉(Greg) [01:10:57]: 음, IMO 모델(IMO models)이 IOI(국제 정보 올림피아드)에서도 금메달을 따게 한다는 것에 대한 꽤 좋은 증거가 있습니다. 그것은 똑같습니다. 네. 제 말은, 우리가 세부 사항 중 일부에 대해 이야기했다고 생각합니다. 하네스(harness)에 약간의 차이가 있지만, 하네스(harness)가 문자 그대로 금메달은 아닙니다. 그렇죠. 실제로는 기본 모델(underlying models)이고, 우리가 특별히 한 훈련은 없습니다. 이것은 몇몇 사람들의 부수적인 프로젝트(side project)로 끝났습니다. 그들은 '오, IOI(국제 정보 올림피아드)도 해야겠네'라고 생각했습니다. 그렇죠. 그리고 그것은 저에게는 정말 놀라운 사실입니다. 왜냐하면 그것은 과거에는 엄청난 도전 과제(total grand challenge)였고, 많은 사람들이 매달려야 하는 것이었기 때문입니다. 그리고 OpenAI의 핵심 IMO 팀(IMO team)은 실제로 세 명으로 구성되어 있었습니다. 그렇죠. 엄청난 노력이 아니었습니다. 그래서 당신은 이러한 영역(domains)에 대해 약간의 전문화(specialization)가 필요할 수도 있다는 것을 깨닫습니다. 그렇죠? 약간의 추가 작업, 약간의 데이터셋(dataset) 수집. 하지만 근본적으로 우리는 이러한 범용 학습 기술(general purpose learning technology)을 가지고 있으며, 어려운 문제를 해결하는 방법을 배우는 것은 실제로 매우 전이 가능한 기술(transferable skill)입니다. 어려운 수학 문제를 해결하고 증명을 작성하는 방법을 배우는 것이 실제로 프로그래밍 작성 및 경쟁 문제로 전이된다는 것이 밝혀졌습니다. 이제 만약 당신이 물리 실험(physics experiment)을 한 번도 해본 적이 없다면, 그렇죠? 만약 당신이 실제로 화학 물질을 섞어보려고 시도한 적이 없다면, 당신은 아마도 그런 일에 마법처럼 능숙하지 않을 것입니다. 그래서 일반화(generalization)의 한계에 대한 어떤 것이 있습니다. 그렇죠? 당신은 실제로 실제 세계 경험을 가지고 그것을 시도해야 합니다. 하지만 이 모델들은 이미 거의 불합리할 정도로 멀리 나아갑니다. 그리고 우리는 이것을 항상 봅니다. O3와 같은 모델을 사용하여 '여기에 실험 설정이 있습니다. 무엇을 해야 할까요?'라고 가설(hypotheses)을 묻는 연구실 과학자(lab scientists)들이 있습니다. 그들은 다섯 가지 아이디어를 가지고 있고, 이 다섯 가지 아이디어를 시도합니다. 그 중 네 가지는 작동하지 않지만, 한 가지는 작동합니다. 그리고 O3에 대해 우리가 받았던 피드백(feedback)은 중간급 학술지(mid-tier journal)에 발표될 수 있는 결과물이라는 것이었습니다. 최고급 학술지(top tier journal)는 아니지만, 중간급 학술지(mid-tier journal)에 말이죠. 그것은 3학년 또는 4학년 박사 과정 학생에게서 기대할 수 있는 종류의 작업일 것입니다. 그리고 다시 말하지만, 그것은 정말 놀라운 사실입니다. 그것이 O3의 현재 위치입니다. 그리고 우리는 O3를 모든 차원에서 개선하는 방법을 정확히 알고 있습니다. 그리고 그것은 컴퓨트(compute)를 필요로 합니다. 많은 작업이 필요합니다. 작업을 얻는 것이 필요합니다. 많은 인간의 지적 사랑과 노동과 시간이 필요하며, 우리의 마음과 영혼을 쏟아부어야 합니다. 하지만 결과는, 당신의 말처럼, 그 안에 모든 잠재 에너지(potential energy)를 담고 있는 것을 생산한다는 것입니다. 그리고 놀라운 점은 그 잠재 에너지(potential energy)를 한 번만 방출하는 것이 아니라는 것입니다. 그렇죠? 그것은 이 모든 작업에서 여러 번 사용할 수 있는 체크포인트(checkpoint)입니다. 그리고 그것은 인류 전체를 고양시킬 수 있는 것이라고 생각합니다. 정말 고무적입니다.

**새로운 관점: 컴퓨팅 자원 확장의 미래와 AI 하드웨어 혁신**

그렉(Greg)이 강조하듯이, AI 발전의 가장 큰 병목 현상은 항상 '컴퓨트(compute)'입니다. 더 많은 컴퓨팅 자원이 주어지면, AI 연구자들은 이를 활용하여 더 강력하고 샘플 효율적인 알고리즘을 개발할 방법을 찾아냅니다. 이는 앨런 튜링(Alan Turing)이 예견했던 '초임계 학습(supercritical learning)'의 개념과도 연결됩니다. 초임계 학습은 AI가 단순히 주어진 정보만을 배우는 것이 아니라, 새로운 지식을 통해 기존의 모든 지식을 업데이트하고 확장하는 능력을 의미합니다.

미래에는 이러한 컴퓨팅 자원의 확장이 AI 하드웨어의 혁신과 밀접하게 연관될 것입니다. 현재 주로 사용되는 GPU(그래픽 처리 장치)를 넘어, 뉴로모픽 칩(neuromorphic chips)이나 양자 컴퓨팅(quantum computing)과 같은 차세대 하드웨어 기술은 AI 모델의 훈련 및 추론(inference) 효율성을 획기적으로 향상시킬 잠재력을 가지고 있습니다. 뉴로모픽 칩은 뇌의 구조와 기능을 모방하여 에너지 효율성을 높이고 병렬 처리를 강화하며, 양자 컴퓨팅은 특정 유형의 계산에서 현재의 슈퍼컴퓨터보다 훨씬 빠른 속도를 제공할 수 있습니다.

이러한 하드웨어 혁신은 '다이슨 스피어(Dyson Sphere)'와 같은 거대한 미래 구조물의 아이디어처럼, 인류가 활용할 수 있는 컴퓨팅 자원의 규모를 상상할 수 없을 정도로 확장시킬 것입니다. 컴퓨팅 자원이 풍부해지면, AI는 현재는 불가능하다고 여겨지는 복잡한 문제들을 해결하고, 과학적 발견을 가속화하며, 인류의 삶을 근본적으로 변화시킬 수 있습니다. 결국, 컴퓨트는 지능의 근본적인 연료이자 잠재 에너지이며, 이를 얼마나 효율적으로 활용하고 확장하느냐가 AI 발전의 속도와 방향을 결정하는 핵심 요소가 될 것입니다.

**RL(강화 학습) 및 실제 상호작용에서의 벽시계 시간(Wall clock time) 제약(Wall clock time limitations in RL and real-world interactions)**

스윅스(Swyx) [01:13:21]: 두 가지를 되짚어보고 싶습니다. 하나는 벽에 대한 것입니다. 제가 노암(Noam)과 논쟁하려 했던 것 중 하나는 벽시계 시간(wall clock time) 측면에서 벽이 있다는 것입니다. 왜냐하면 시간이 흘러야 하기 때문입니다. RL(강화 학습)이 환경 및 시뮬레이션(simulation)과 상호작용하는 문제점은 시뮬레이션(simulation)을 실시간보다 빠르게 가속화할 수 있다는 것입니다. 어느 시점에서는 벽시계 시간(wall clock time)과 일치해야 합니다. 그래서, 아시다시피, 우리는 실시간에 점점 더 가까워지는 반복 속도(pace of iterations)로 벽시계 시간(wall clock time)에 수렴하는 것을 볼 수 있습니다. 그래서 저는 그것이 실제 세계를 모델링(modeling the real world)하는 데 있어 정말 흥미로운 생각이라고 생각합니다. 그것을 해결하는 것에 대한 어떤 생각이 있으신지 모르겠습니다. 분명히 우리는 아직 그 단계에 도달하지 않았으므로 걱정할 필요는 없습니다.
그렉(Greg) [01:13:57]: 네, 이것은 꽤 근본적인 장벽이라고 생각합니다. 그렇죠? 그리고 물론 모델은 매우 비인간적인 특성(non-human affordances)을 가지고 있습니다. 그렇죠? 여러 개의 복사본을 실행할 수 있습니다. 그래서 지연 시간(latency)을 줄일 수 없더라도 확장(scale out)할 수 있습니다. 그리고 컴퓨트(compute)가 어디로 가는지 생각하는 것도 매우 흥미롭습니다. 그렇죠? 왜냐하면 우리는 컴퓨트(compute)의 대부분이 모델을 훈련시키는 데 사용되는 세상에서, 이 모델들을 더 많이 배포함에 따라 컴퓨트(compute)의 더 많은 부분이 추론(inferencing)하고 실제로 사용하는 데 사용되는 세상으로 이동할 것이기 때문입니다. 하지만 만약 당신이 '음, 이 모델들이 실제 세계와 많이 상호작용할 것이고, 그래서 아마도 모든 단일 행동에 대해 많이 생각해야 할 것이다'라고 생각한다면, 그렇죠? 그래서 실제 세계 상호작용당 엄청난 양의 컴퓨트(compute)가 소비될 수도 있습니다. 그래서 컴퓨트(compute)가 실제로 소비될 것으로 예상되는 곳이 정말 바뀝니다. 그리고 저는 매우 효율적인 좋은 하네스(harnesses)를 갖는 것이 정말 중요하다고 생각합니다. 그렇죠? 만약 제가 실제 세계에서 어떤 롤아웃(rollout)에서 여러 단계를 거쳤다면, 그것을 어떻게 체크포인트(checkpoint)할 것인가? 그렇죠? 그리고 만약 당신이 시스템을 재시작해야 하고 현재 상태를 모두 잊어버리는 시스템을 가지고 있다면, 그것은 아마도 꽤 나쁠 것입니다. 그래서 저는 모든 것을 완벽하게 관찰하고 체크포인트(checkpoint)하고 보존할 수 있는 디지털 세계와, 훨씬 더 지저분하고 복잡한 현실 사이에는 매우 다른 점이 있다고 생각합니다. 그리고 저는 그것이 나쁜 것은 아니라고 생각합니다. 그렇죠? 우리는 도타(Dota)와 같은 에이전트(agents)가 매우 복잡하고 지저분한 환경에서 작동할 수 있다는 것을 보았습니다. 그래서 알고리즘(algorithms)은 그것을 할 수 있습니다. 그리고 참고로, 도타(Dota)는 3억 개의 매개변수 신경망(300 million parameter neural net)이었습니다. 아주 작고 작은 곤충 뇌와 같았죠. 그렇죠? 이제 우리는 매개변수(parameters) 수 측면에서, 어쩌면 컴퓨트(compute) 수 측면에서 인간 규모와 훨씬 더 비교할 수 있는 것들로 확장(scale up)하기 시작했습니다. 우리는 반드시 그 단계에 도달한 것은 아닙니다. 당신은 수학을 다른 방식으로 볼 수 있습니다. 하지만 근본적으로 우리는 실제 목표를 향해 나아가고 있습니다. 그리고 AGI(범용 인공지능)가 무엇이어야 하는지 생각한다면, 그것은 매우 생산적인 방식으로 실제 세계와 상호작용할 수 있는 것이어야 합니다. 네.
스윅스(Swyx) [01:15:51]: 대략적으로 계산해보면, 제 머릿속에 있는 숫자는, 제가 몇 자릿수 정도 틀렸다면 수정해주십시오. 하지만 인간은 100조 개의 뉴런(neurons)을 가지고 있습니다. 우리는 GPT-4, 4.5, 5의 경우 낮은 두 자릿수에서 높은 한 자릿수 범위에 있지만, 그것을 확인하지는 않을 것입니다.
그렉(Greg) [01:16:08]: 하지만 우리는 그쪽으로 확장(scaling)하고 있습니다. 네. 100조 개의 시냅스(synapses)라고 말하겠습니다. 이는 신경망(neural net)의 가중치(weights)와 어느 정도 일치합니다. 네. 그래서 어떤 종류의 등가성(equivalence)이 있습니다. 네. 그래서 우리는 올바른 숫자에 도달하기 시작했습니다. 그렇게만 말씀드리겠습니다.
스윅스(Swyx) [01:16:20]: 그리고 생물학적 관점에서, 이것은 제가 지난번에 당신에게 ARC 연구소(ARC Institute)에서 무엇을 배웠는지 물어볼 기회조차 없었던 것입니다. 당신은 그곳에서 안식년(sabbatical)을 보냈습니다. 그것이 지금 OpenAI에서 하는 일에 어떤 영향을 미 미치는지 궁금합니다.

**새로운 관점: 디지털 트윈(Digital Twins)과 시뮬레이션으로 가속화되는 AI 학습**

강화 학습(RL)의 '벽시계 시간(wall clock time)' 제약은 AI가 실제 세계와 상호작용하며 학습하는 데 있어 중대한 도전 과제입니다. 실제 환경에서의 학습은 시간, 비용, 안전성 문제로 인해 무한정 반복하기 어렵습니다. 이러한 한계를 극복하기 위해 '디지털 트윈(digital twins)'과 고도화된 시뮬레이션 환경의 역할이 점점 더 중요해지고 있습니다.

디지털 트윈은 물리적 시스템이나 프로세스의 가상 복제본으로, AI는 이 가상 환경에서 실제와 거의 동일한 조건으로 무수히 많은 시행착오를 겪으며 학습할 수 있습니다. 예를 들어, 자율주행 AI는 실제 도로에서 수십 년이 걸릴 학습을 디지털 트윈 환경에서 단 몇 시간 만에 완료할 수 있습니다. 소프트웨어 개발 에이전트의 경우, 복잡한 코드베이스의 디지털 트윈을 구축하여 AI가 다양한 변경 사항을 테스트하고, 버그를 진단하며, 성능을 최적화하는 과정을 실시간보다 빠르게 시뮬레이션할 수 있습니다.

이러한 시뮬레이션 기반 학습은 AI가 실제 환경에 배포되기 전에 거의 완벽에 가까운 수준으로 훈련될 수 있도록 돕습니다. 또한, AI가 실제 세계에서 새로운 상황에 직면했을 때, 빠르게 시뮬레이션 환경으로 돌아가 해결책을 모색하고, 다시 실제 환경에 적용하는 순환 학습(cyclic learning) 방식을 가능하게 합니다. 이는 AI의 학습 속도를 가속화하고, 실제 세계에서의 안전성과 신뢰성을 크게 향상시킬 뿐만 아니라, 궁극적으로 AGI(범용 인공지능)가 실제 세계와 생산적으로 상호작용하는 데 필요한 기반을 제공할 것입니다.

**ARC 연구소(ARC Institute) 및 DNA 신경망(DNA neural networks) 경험(Experience with ARC Institute and DNA neural networks)**

그렉(Greg) [01:16:34]: 음, DNA 신경망(DNA neural nets)을 연구하면서 가장 놀라웠던 점은 그것들이 정확히 같다는 것입니다. 네. 그렇죠? 단순히 인간 언어(human language)를 대체하는 것입니다. 심지어 더 간단한 어휘(vocab)입니다. 그렇습니다. 네. 네 글자만 있습니다.
스윅스(Swyx) [01:16:47]: 하지만 더 높은 수준에서 토큰화(tokenize)하지 않습니까? 네.
그렉(Greg) [01:16:49]: 제 말은, 할 수 있습니다. 하지만 실제로 우리가 접근한 방식은 문자 수준(Character level)으로 했습니다. 문자 수준(Character level).
스윅스(Swyx) [01:16:54]: 말도 안 돼. 네. 왜 안 되죠? 글쎄요, 이유가 없겠죠. 모르겠습니다.
그렉(Greg) [01:17:00]: 네 글자밖에 없으니까요. 그렇죠. 그렇죠. 그리고 이것이 저에게는 핵심이라고 생각합니다. 인간 언어(human language)의 흥미로운 점 중 하나는 우리가 의미론(semantics)을 이해한다는 것입니다. 그렇죠? 우리는 그것이 무엇을 의미하는지, 구조가 무엇인지 어느 정도 이해합니다. 우리가 관찰하기(observe)가 매우 쉽습니다. 토큰화 체계(tokenization scheme)를 볼 때, 합리적인 방식으로 모든 단어를 포착했는지 여부를 어느 정도 알 수 있습니다. 생물학은 외계 언어(alien language)입니다. 그리고 매우 흥미로운 점은, 아시다시피, 인간에게는 외계 언어(alien language)라는 것입니다. 하지만 신경망(neural net)을 보면, 왜 인간 언어(human language)가 생물학적 언어(biological language)보다 신경망(neural net)에 더 자연스러워야 할까요? 그리고 답은 그렇지 않다는 것입니다. 그렇죠? 실제로 이 두 가지는 모두 – 문자 그대로 같은 하드웨어입니다. 정확합니다. 그래서 놀라운 가설(hypotheses) 중 하나는 '음, 이 신경망(neural networks)은 신경망(neural nets)이다. 그들은 인간 언어(human language)를 아주 잘 배울 수 있다. 그러므로 그들은 생물학적 언어(biological language)도 아주 잘 배울 수 있어야 한다'는 것입니다. 그리고 우리는 정말 같은 종류의 결과를 봅니다. 그렇죠? 제 말은, 우리가 생산한 신경망(neural net)은 40B 신경망(40B neural net)으로, 13조 개의 염기쌍(base pairs) 정도를 훈련시켰습니다. 그 결과는 저에게 GPT-1, 어쩌면 GPT-2 수준처럼 느껴졌습니다. 그렇죠? 광범위한 생물학적 응용 분야에서 하위 작업(downstream tasks)에 접근 가능하고 적용 가능합니다. 아직 조정 가능하지는 않습니다. GPT-3나 GPT-4는 아니고, GPT-5는 확실히 아닙니다. 그렇죠? 우리는 아직 이러한 영역(domains)에서 매우 어려운 문제를 해결할 수는 없습니다. 하지만 우리는 컴퓨트(compute)를 가지고 있습니다. 올바른 기술과 알고리즘(algorithms)을 가지고 있습니다. 이제 우리는 확장(scale)해야 합니다. 우리는 긴 맥락(long context)에 대해 생각해야 합니다. 생물학적 시스템(biological systems)이 언어 시퀀스(language sequences)에 비해 모델에 스트레스를 주는 방식에는 여러 가지가 있습니다. 10억 개의 토큰(tokens)으로 된 언어 시퀀스(language sequence)는 실제로 존재하지 않지만, DNA에는 존재합니다. 그렇죠? 당신은 40억 개의 염기쌍(base pairs) 정도를 가지고 있습니다. 그래서, 아시다시피, 당신은 어떤 종류의 다른 강조점(emphasis)을 가지고 있습니다. 하지만 근본적으로 그것은 당신이 해결해야 할 같은 문제입니다.
스윅스(Swyx) [01:18:49]: 약물 발견(drug discovery)과 같은 응용 분야에 가장 흥미를 느끼십니까? 아니면 물론 모두가 약물 발견(drug discovery)으로 가겠지만, 그 전에 도달할 수 있고 매우 영향력 있는 중간 단계의 어떤 것이 있을까요?
그렉(Greg) [01:18:59]: 음, 개인적인 차원에서 말이죠. 제 아내는, 우리가 이전에 공개적으로 이야기한 적이 있지만, 엘러스-단로스 증후군(Ehlers-Danlos syndrome)이라는 유전적 질환(genetic condition)을 가지고 있습니다. 그것은 아주 최근까지, 우리가 보기 시작했다고 생각합니다. 유전적 표지자(genetic markers)가 있지만, 정확히 무엇이 원인이고 어디서 오는지 알려지지 않았습니다. 그리고 그것은 생물학을 이해하기 위한 더 나은 도구(better tools)를 가지고 있다면, 많은 다른 질병의 표지자(markers)를 식별할 수 있어야 하는 분야입니다. 그래서 그것은 이러한 신경망(neural nets) 안에 존재하는 약속(promise)의 한 가지 예시일 뿐입니다.

**새로운 관점: AI 기반 생물학 연구의 윤리적 지평 확장**

그렉(Greg)의 ARC 연구소 경험은 AI가 생물학, 특히 유전체학(genomics) 분야에서 혁신적인 역할을 할 수 있음을 시사합니다. DNA를 '외계 언어(alien language)'로 비유하며 신경망(neural net)이 인간 언어만큼 생물학적 언어도 잘 학습할 수 있다는 통찰은 AI가 약물 발견(drug discovery)을 넘어 질병 진단, 맞춤 의학, 심지어 합성 생물학(synthetic biology)에까지 광범위하게 적용될 수 있음을 보여줍니다.

AI는 방대한 유전체 데이터를 분석하여 질병과 관련된 유전적 표지자(genetic markers)를 식별하고, 복잡한 생체 분자 상호작용을 모델링하며, 새로운 단백질 구조나 유전자 편집 기술을 설계하는 데 활용될 수 있습니다. 예를 들어, AI는 암세포의 돌연변이 패턴을 학습하여 개인에게 최적화된 치료법을 제안하거나, 희귀 유전 질환의 원인이 되는 유전자 변이를 신속하게 찾아낼 수 있습니다. 이는 현재의 의학적 한계를 뛰어넘어 인류의 건강과 복지를 증진하는 데 지대한 영향을 미칠 것입니다.

그러나 AI 기반 생물학 연구의 발전은 동시에 깊은 윤리적 질문을 던집니다. 유전체 정보의 사생활 보호 문제, AI가 제안하는 치료법의 책임 소재, 그리고 유전자 편집 기술의 오용 가능성 등이 그것입니다. AI가 생체 시스템을 이해하고 조작하는 능력이 커질수록, 우리는 이러한 기술이 인류에게 이롭고 책임감 있는 방식으로 사용되도록 엄격한 윤리적 가이드라인과 규제 프레임워크를 마련해야 할 것입니다. AI는 질병과의 싸움에서 강력한 동맹이 될 수 있지만, 그 힘을 현명하게 다루는 것은 우리 인류의 몫입니다.

**GPT-5 시대 정의(Defining the GPT-5 Era)**

알레시오(Alessio) [01:19:33]: GPT-5 시대의 시작을 어떻게 특징지으시겠습니까? 3, 4, 5를 주요 버전으로 생각한다면, 3은 매우 텍스트 기반이었고, RLHF(인간 피드백을 통한 강화 학습)가 막 시작된 것 같고, 4는 멀티모달리티(multi-modality)와 O3를 통한 낮은 지연 시간(low latency), 긴 사고(long thinking)였습니다. 5의 주력 기능은 무엇이 될까요? 분명히 에이전트(agents)의 시대겠죠? 그것이 밈(meme)이죠. 네. 하지만 사람들이 '좋아, 5로 이제 X를 잠금 해제한다'고 생각해야 할 다른 어떤 것이 있을까요? 네.
그렉(Greg) [01:19:59]: 저는 똑똑하다고 생각합니다. 이 모델들의 지능(intelligence)은 거의 설명할 수 없는 수준에 도달하고 있습니다. 그렇죠? 여전히 한계가 있고, 여전히 실패하는 방식이 있습니다. 하지만 IMO 결과(IMO results)를 보세요. 극도로 어려운 영역(domains)에서는 실제로 그렇습니다. 이 추론 패러다임(reasoning paradigm)으로 훈련된 모델을 가져와서 최고의 인간 수준의 증명(proofs)을 작성할 수 있습니다. 그렇죠? 그리고 이 특정 영역(domain)에는 한계가 있고 등등이 있습니다. 우리는 아직 증명되지 않은 정리(unproven theorem)를 증명하거나 그런 일을 하지는 못했지만, 그것은 현실입니다. 이 모델들이 위대한 지적 업적(intellectual feats)을 수행할 수 있다는 것은 이 시점에서 부인할 수 없습니다. 그리고 저는 그것이 새롭다고 생각합니다. 그렇죠? GPT-4는 훨씬 더 광범위한 응용 분야에서 유능하고 상업적으로 유용했습니다. 하지만 그것이 생산한 아이디어는 그리 깊지 않았습니다. 그렇죠? 그것이 해결할 문제들은 그리 신뢰할 수 없었습니다. 그리고 저는 GPT-3로 기본적인 것조차 가르치려고 했던 것을 기억합니다. 그렇죠? 마치 우리가 '야, 몇 번의 예시 프롬프트(few-shot prompting)를 할 수 있겠네'라고 깨달았을 때, 몇 가지 예시를 보여주면 기본적으로 그 작업을 수행할 것입니다. 그래서 저는 '좋아, 이 모델에게 목록을 정렬하는 방법을 가르칠 수 있을까?'라고 생각했습니다. 그리고 7개의 숫자를 주어 정렬하게 했습니다. 정렬하지 못했습니다. 저는 '좋아'라고 생각했습니다. 그러고 나서 저는 '나는 숫자 정렬 방법을 가르치는 선생님이야. 여기 두 개의 숫자를 정렬하는 예시가 있고, 세 개의 숫자를 정렬하는 예시가 있어'와 같은 전체 스크립트(script)를 작성하려고 했습니다. 그리고 저는 '좋아, 이제 총 다섯 개의 숫자가 있는데 완전히 실패했어'라고 말할 것입니다. 만약 당신이 GPT-5에게 그렇게 묻는다면, 참고로 저는 GPT-5에게 임의의 숫자 다섯 개 목록을 정렬해달라고 시도조차 해본 적이 없지만, 저는 그것이 아무 문제 없이 완벽하게 해낼 것이라고 확신합니다. 참고로, 파이썬 도구(Python tool)에도 접근할 수 있으므로 그렇게 할 필요는 없습니다. 그렇게 말씀하시겠습니까?
그렉(Greg) [01:21:40]: 음, 저는 이 모델들이 인간을 도울 수 있는 능력은 우리가 이제 막 보기 시작한 것이라고 말하겠습니다. O3에서 그것을 보기 시작했고, 전문 수학자(professional mathematicians)들이 GPT-5를 시험해보기 시작하는 것을 볼 수 있습니다. 물리학자(physicists)들이 GPT-5를 시험해보기 시작하며 '야, 이 모델이 내가 몇 달간의 연구를 통해 얻은 통찰력(insight)을 다시 도출할 수 있었어'라고 말하는 것을 보았습니다. 그리고 그것은 당신이 '이것이 당신의 속도를 엄청나게 빠르게 할 것이다'라고 깨닫는 종류의 것입니다. 그렇죠? 저는 고등학교와 대학 초기에 제 수학 연구(math research)를 했던 것을 기억합니다. 그리고 머릿속으로 이러한 객체들을 조작하고 사물 간의 연결고리(connections)를 생각하는 데 너무 많은 시간을 보냈습니다. 만약 제가 이것에 대해 이야기할 수 있는 파트너(partner)가 있었다면, 제 생각을 깊이 이해하고 제가 제안하는 것에서 새로운 통찰력(insights)을 만들어낼 수 있는 파트너(partner)가 있었다면, 제 속도는 훨씬 빨라졌을 것입니다. 훨씬 더 재미있었을 것입니다. 그렇죠? 왜냐하면 당신은 혼자서 그것에 대해 생각하는 루프(loop)에 갇히지 않을 것이기 때문입니다. 당신은 '잠깐, 이 생각은 이미 2주 전에 했잖아'라고 생각할 것입니다. 그래서 저는 지적인 발전을 함께 추진하는 것에 대해 새로운 것이 있다고 생각합니다.

**새로운 관점: AI 협력 시대의 인간과 기계의 공진화**

GPT-5 시대는 AI가 단순한 '도구'나 '조수'를 넘어 '협력자(collaborator)' 또는 '공동 창작자(co-creator)'로 진화하는 시대로 정의될 수 있습니다. 그렉(Greg)이 언급했듯이, 모델의 지능(intelligence)은 이제 IMO(국제 수학 올림피아드)와 같은 극도로 어려운 지적 영역에서 인간 최고 수준의 성과를 내는 단계에 이르렀습니다. 이는 AI가 인간의 지적 한계를 확장하고, 새로운 통찰력을 발견하는 데 결정적인 역할을 할 수 있음을 의미합니다.

이러한 변화는 인간-AI 상호작용의 패러다임을 근본적으로 바꿀 것입니다. 과거에는 인간이 AI에게 명확한 지시를 내리고 결과를 받아보는 단방향 상호작용이 주를 이루었습니다. 그러나 GPT-5와 같은 고급 모델은 인간의 아이디어를 깊이 이해하고, 이에 기반하여 새로운 아이디어를 제안하며, 복잡한 문제를 해결하기 위한 다단계 추론 과정을 수행할 수 있습니다. 이는 인간이 AI와 함께 '생각의 루프(loop)'에 참여하고, 아이디어를 주고받으며, 서로의 강점을 활용하여 시너지를 창출하는 공진화(co-evolution)의 시대를 예고합니다.

예를 들어, 과학자는 AI와 함께 복잡한 실험 데이터를 분석하고 새로운 가설을 탐색하며, 예술가는 AI를 활용하여 기존에는 상상하기 어려웠던 창작물을 만들어낼 수 있습니다. 소프트웨어 개발자 또한 AI와 함께 아키텍처를 설계하고, 코드를 작성하며, 디버깅하는 과정에서 이전에는 경험하지 못했던 생산성과 창의성을 경험하게 될 것입니다. GPT-5는 인간이 혼자서는 도달하기 어려웠던 지적 지평을 AI와 함께 탐험할 수 있는 새로운 시대를 열고 있습니다.

**모델 지능 및 작업 난이도 평가(Evaluating Model Intelligence and Task Difficulty)**

알레시오(Alessio) [01:22:46]: GPT-5와 함께 파트너(partner)로서. 사람들이 작업하는 문제의 난이도에 의해 제한된다고 생각하십니까? 제 생각에는 커서(Cursor)와 코덱스(Codex)에서 제가 어려운 작업을 줄 때 모델이 더 낫다는 것이 분명합니다. 많은 사람들이 X에 스크린샷을 올리며 '오, GPT-5는 그렇게 좋지 않아'라고 말하는 것 같습니다. 질문이 그렇게 어렵지 않다는 거죠. 네. 자신감에 관한 것입니다. 당신이 그것을 세계 최고의 코딩 모델(coding model)이라고 부를 때, 당신은 분명히 세계 최고의 코더(coders) 중 한 명입니다. 그래서 게임은 게임을 알아봅니다. 하지만 사람들은 이 모델들을 어떻게 평가해야 할까요?
그렉(Greg) [01:23:21]: 네. 특정 작업에서는 분명히 포화 상태(saturation)가 있습니다. 그렇죠? 그냥 잡담을 하고 '안녕하세요, 잘 지내세요?'라고 말한다면, 할 수 있는 말은 그리 많지 않습니다. 만약 '여기 재료 가설(rematter hypothesis) 해결책이 있습니다. 부탁합니다'라고 말한다면. 좋습니다. 네. 거기에는 광범위한 지능(intelligence)이 바람직할 것입니다. 네. 그리고 저는 우리가 관찰한 것이 바로 이것이라고 생각합니다. 우리는 GPT-5가 우리가 테스트한 다른 어떤 모델보다 훨씬 더 잘 지적인 문제, 즉 깊은 지능(deep intelligence)을 요구하는 작업을 해결할 수 있다는 것을 보았습니다. 우리가 한 두 번째 일은 사람들이 대화형 코딩 응용 프로그램(interactive coding applications)에서 그것을 어떻게 사용하는지 오랫동안 관찰하고, 많은 피드백(feedback)을 받아 훈련에 다시 반영하는 것이었습니다. 그리고 그것은 우리가 과거에 그렇게 열심히 시도하지 않았던 것입니다. 그렇죠? O3와 같은 모델의 경우, 우리는 한 번 설정한 작업으로 훈련시켰고, 모델이 모든 지표에서 우상향하는 것을 보았습니다. 코드포스(code forces)와 같은 경쟁 프로그래밍 대회(competitive programming competitions)에서 훌륭한 성과를 냈습니다. 이것은 다시 말하지만 매우 흥미롭지만, 실제 프로그래밍 방식과는 다릅니다. 실제 프로그래밍은 훨씬 더 지저분한 방식입니다. 그렇죠? 어떤 종류의 리포(repo)가 있고, 어떤 종류의 로컬 상태(local state)가 있으며, 다른 추상화(abstractions)와, 아시다시피, 다른 라이브러리(libraries)의 다른 버전들이 있습니다. 그리고 그러한 다양성(diversity)은 '여기에 이 특정 작업, 당신이 완료해야 할 10가지 특정 작업이 있습니다'와 같은 매우 구조화된 방식에서 마법처럼 나타나는 것이 아닙니다. 그래서 우리가 집중해온 많은 부분은 '지능(intelligence)을 어떻게 향상시킬 것인가'뿐만 아니라 (물론 그것이 항상 핵심이겠지만) '지능(intelligence)을 실제 세계 응용 프로그램(real world applications)과 어떻게 연결할 것인가'였습니다. 그래서 그것이 상아탑(ivory tower) 밖으로, 안락한 지대(comfort zone) 밖으로 밀려나는 경험을 하고, 실제 세계의 지저분한 현실과 다양성(diversity)을 실제로 볼 수 있도록 한 것입니다. 네.

**GPT-5를 사용하는 개발자를 위한 실용적인 조언(Practical Advice for Developers Using GPT-5)**

알레시오(Alessio) [01:25:06]: 이러한 모델에서 잠재 에너지(potential energy)를 끌어내는 것에 대한 더 실용적인 수준의 제안은 무엇입니까? 일부는 린터(linter), 타입 체커(type checker), 그리고 자체 루프(self-loop)를 갖도록 하는 작업과 같은 것을 추가하는 것입니다. 개발자들이 생각해야 할 다른 메타(meta)는 무엇입니까? 모델을 어떻게 사용하십니까? 네.
그렉(Greg) [01:25:21]: 음, 제가 관찰한 가장 중요한 것은 이 모델들로부터 최대한의 것을 추출하는 데 진정한 기술이 필요하다는 것입니다. 그리고 그것은 이 끈기(tenacity)를 필요로 합니다. 그렇죠? 거의 모델의 기술과 약점의 형태를 이해하려고 노력하는 것입니다. 그래서 당신은 그것을 테스트합니다. 그렇죠? 작은 것으로 테스트하고, 약간의 피드백(feedback)을 얻고, 조금 더 높은 수준으로 테스트하고, 더 큰 작업을 주려고 시도하고, 특정 방식으로 작동하는지 확인하려고 합니다. 그리고 저는 사람들이 보통 다양한 프롬프트(prompts) 라이브러리(library)를 가지고 있다고 생각합니다. 그렇죠? 그래서 저는 GPT-4 시절부터 구축해온 프롬프트(prompts) 라이브러리(library)를 분명히 가지고 있습니다. GPT-4가 나오기 전에 '음, 이걸 할 수 있을까?'라고 생각하며 몇 가지를 모았던 기억이 납니다. 아시다시피, 당신은 어떤 종류의 질문을 가지고 있는데, 중요하게도 다양한 답변을 가질 수 있고, 하나의 특정 정답이 없는 질문을 원합니다. 그래서 예를 들어, 창의적인 글쓰기(creative writing)에서는 '반지의 제왕(Lord of the Rings)과 스타트업(startups)의 매시업(mashup)을 요청하는 것을 좋아했습니다. 그렇죠? 단순히 두 가지 다른 주제를 함께 밀어붙여 무엇을 얻는지 보는 것입니다. 모델을 실제로 테스트하고 밀어붙이는 측면에서, 저는 '좋아, 우선 작업을 어떻게 나누고 모델이 실행할 수 있는 독립적인(self-contained) 것을 가질 것인가'에 대해 많이 생각합니다. 왜냐하면 모델의 단일 인스턴스(instance)만 작동하게 하고 싶지 않기 때문입니다. 여러 개를 원합니다. 그렇죠? 당신은 에이전트(agent)의 관리자가 아니라 에이전트들(agents)의 관리자가 되고 싶습니다. 그렇죠? 그래서 우선 코드베이스(code base)가 어떻게 구성되어 있는지 생각해야 하지만, 실제로 모델을 밀어붙여 '이 코드베이스(code base)의 여러 다른 부분에서 실제로 작동할 수 있니?'라고 말해야 합니다. 저는 사람들이 프론트엔드(front-end) 테스트를 하는 것을 좋아한다고 생각합니다. GP5는 프론트엔드(front-end)에 매우 능숙하다는 것이 밝혀졌지만, 물론 그것이 대부분의 개발자들이 시간을 보내는 일은 아닙니다. 그래서 그것에 과적합(overfit)하지 않는 것이 중요하지만, 저는 모델에 대한 감을 잡고 그 강점과 약점에 익숙해지고, 그것을 거의 도구(tool)로 보는 것이 중요하다고 생각합니다. 또한 자신의 확장(extension)으로서, 아시다시피, 제가 또 다른 할 일은 모델이 어떤 이유로든 작동하기를 원하지 않는 매우 어려운 일에 대해 생각하는 동안, 중요 경로(critical path)에 있지 않은 작업을 모델에 계속 던지는 것입니다. 그래서 저는 '좋아, 그것이 일을 할 수 있었나?' 또는 '실수해도 위험이 낮은가?'와 같은 정보를 계속해서 얻습니다. 왜냐하면 5분 동안 기다렸다가 아무것도 얻지 못하는 느낌을 받고 싶지 않기 때문입니다.
스윅스(Swyx) [01:27:30]: 당신은 항상 코덱스(Codex)와 코딩 능력(coding capabilities)을 여는 로드맵(roadmap)이 있다고 언급했습니다. 우리가 그곳에 있으니, 백그라운드 SWE 에이전트(SWE agents)가 NIDE 에이전트(NIDE agents)와 합쳐지는 것입니까? 당신의 생각은 어떻게 발전했습니까? IDE(통합 개발 환경)가 백그라운드 API(API)를 호출하고 백그라운드 API(API)가 IDE(통합 개발 환경)로 내보낼 수 있는 것만큼 간단합니까? 아니면 그 안에 더 깊은 연결이 있습니까?
그렉(Greg) [01:27:50]: 저는 AI 제품화(productization)를 동료에 비유하여 생각하는 경향이 있습니다. 훌륭한 프로그래머인 동료에게서 무엇을 원하십니까? 그렇죠? 당신은… 슬랙(Slack)을 보내지 않습니다. 네, 맞습니다. 그래서 당신은 그들에게 슬랙(Slack)을 보내고 싶어 합니다. 하지만 때로는 '야, 이 일에 도움이 필요해. 와서 내 어깨 너머로 좀 봐줄래?'라고 말합니다. '야, 프로그램(program)아.' 그렇죠? 그리고 '야, 키보드(keyboard) 좀 잡아줄래?' 정확합니다. 그래서 당신은 페어(pair) 형태(form factor)를 원합니다. 또한 원격 비동기(remote async) 형태(form factor)를 원합니다. 그리고 이 모든 것에 걸쳐 지식과 기억을 가진 하나의 개체(entity)이기를 원합니다. 매일 나타나서 '좋아, 다 잊어버렸어. SSH(보안 셸)로 어떻게 접속하는지 다시 알려줄래?'라고 말하는 주니어 프로그래머(junior programmer)를 원하지 않습니다. 그렇죠? 그래서 저는 이 모든 것이 일어나야 한다고 생각합니다. 그렇죠? 당신은 인프라(infrastructure)에 신뢰할 수 있는 방식으로 접근할 수 있는 AI(인공지능)를 필요로 합니다. 그렇죠? 감사(audit)할 수 있는 방식 말이죠. 이 모델들의 다른 점 중 하나는 그들이 마이크로매니징(micromanaged)되는 것을 괜찮아한다는 것입니다. 인간은 그것을 별로 좋아하지 않는다는 것이 밝혀졌습니다. 그렇죠? 당신이 그들이 실행하는 모든 명령을 보고, 그들이 한 모든 일에 대한 보고서를 요구한다면, 아마도 그 사람을 유지하지 못할 것입니다. 하지만 모델은 완벽하게 행복합니다. 그렇죠? 그래서 그것은 고려할 가치가 있고, 최대한 활용하기 위해 인터페이스(interfaces)를 변경할 가치가 있는 특성(affordance)입니다. 동시에, 네, 당신은 모델이 원격 기계(remote machine)에서 많은 작업을 수행할 수 있고, 내 로컬 상태(local state)를 망치지 않고, 완전히 샌드박스(sandboxed)되고, 완전히 관찰 가능하며, 때로는 '좋아, 로컬(locally)에서 뭔가를 실행할 준비가 되었어'라고 말할 수 있는 모델 간의 원활한 혼합(seamless blending)을 정말로 원합니다. 그리고 그것이 무엇인지, 그리고 얼마나 샌드박스(sandboxable)할 수 있는지에 따라, 일회성 승인(one-off approvals)을 할 수도 있고, 완전한 위임 접근 권한(full delegated access)을 줄 수도 있습니다. 그리고 저는 인간이 이러한 관찰 가능성(observability)을 통제하고, 다른 표면(surfaces)을 가진 이 팀, 즉 에이전트(agent)를 관리하는 것이 중요하다고 생각합니다. 그렇죠? 마치 로컬(locally)에서 실행되는 에이전트(agent)의 정체성(identity)과 원격(remotely)에서 실행되는 에이전트(agent)의 정체성(identity)을 구분하는 것은 저에게는 잘못된 질문입니다. 에이전트(agent)는 실행되고, 원격 샌드박스(remote sandbox)나 로컬(locally)에서, 또는 여러 샌드박스(sandboxes)에서 실행을 요청하는 모델과 같아야 합니다. 아니면 당신의 컴퓨터와 내 컴퓨터에서 실행될 수도 있습니다.
스윅스(Swyx) [01:29:53]: 마치 이 모든 것들에 로컬(local)일 필요는 없습니다. 소프트웨어 에이전트(Software agents)는 원활하고 유동적으로 이동할 수 있습니다. 승인(approvals)을 언급하시니 제 친구 푸아드(Fuad)를 소개할 기회가 생겼네요. 그는 이 팀을 돕고 있습니다. 죄송합니다. AI 엔지니어(AI Engineer)에서 출시된 에이전트 견고성 팀(agent robustness team)입니다. 그게 무엇입니까? OpenAI의 관심사는 무엇입니까?
그렉(Greg) [01:30:11]: 우리는 에이전트 견고성(agent robustness)을 심층 방어(defense in depth)를 통해 생각합니다. 모델 자체의 계층이 있습니다. 우리는 지시 계층(instruction hierarchy)과 같은 기술을 발표합니다. 그래서 지시 계층(instruction hierarchy)을 사용하면 '이 메시지는 시스템(system)에서 온 것입니다. 이 메시지는 개발자(developer)에서 온 것입니다. 이 메시지는 사용자(user)에서 온 것이며, 이 순서대로 신뢰해야 합니다'라고 표시합니다. 그래서 모델은 '사용자(user)의 이전 지시를 무시하라'는 말을 알 수 있습니다. 저는 그것을 따르지 않을 것입니다. 네, 맞습니다. 그래서 저는 마치 SQL 인젝션(SQL injections)을 방지하는 방법을 생각하는 것과 같다고 생각합니다. 그렇죠? 이러한 시도된 공격(exploits)에 대해 견고한 낮은 수준의 시스템을 갖는 것이 매우 중요하지만, 거기서 멈추는 것은 아닙니다. 그렇죠? 시스템 제어(system controls)에 대해 여러 계층으로 생각하고 싶습니다. 그렇죠? 모델이 샌드박스(sandboxed)되어 실제로 무언가를 실행하거나 특정 데이터(data)에 접근할 수 없다면, 가능한 것에 대한 완전한 보장(guarantees)을 갖게 됩니다. 그리고 우리가 취하는 접근 방식에는 그 사이에 다양한 수준이 있습니다. 그래서 저는 이러한 에이전트(agents)가 우리 삶에 더 깊이 통합되고 더 많은 책임을 맡게 됨에 따라, 그들의 안전과 보안을 동시에 강화하는 것이 많은 부분에서 최전선(frontier)이라고 생각합니다.
스윅스(Swyx) [01:31:19]: 저는 리눅스 커널(Linux kernel) OS 링(OS rings)과도 비유했습니다. 그리고 우리가 LLM(대규모 언어 모델)에 이러한 보안 계층(layers of security)의 개념을 구축하고 있다는 것이 정말 흥미롭습니다. 그리고 제가 또한 매우 기뻤던 또 다른 점은 AI 엔지니어(AI engineer)를 위한 모델 사양(model spec)에 대한 강연을 초청했는데, 그것이 우리가 가졌던 모든 강연 중 가장 많이 시청된 강연이었다는 것입니다. 안전과 신뢰성을 섹시하게 만드는 것은 매우 어렵습니다.

**새로운 관점: AI 기반 개발을 위한 메타 전략과 AI 리터러시**

GPT-5와 같은 고급 AI 모델을 소프트웨어 개발에 효과적으로 활용하기 위해서는 단순한 프롬프트 엔지니어링을 넘어선 '메타 전략(meta-strategies)'이 필요합니다. 그렉(Greg)이 언급했듯이, 모델의 강점과 약점을 이해하고 이에 맞춰 작업을 구성하는 것이 중요합니다. 다음은 개발자들이 고려해야 할 몇 가지 실용적인 조언입니다.

1.  **AI 중심 프로젝트 구조화:** 프로젝트를 AI가 처리하기 용이한 독립적인 모듈(module)과 명확한 API(Application Programming Interface)로 분리합니다. 각 모듈에 대한 상세한 문서화와 잘 정의된 유닛 테스트(unit test)를 제공하여 AI가 코드의 목적과 예상 동작을 정확히 이해하도록 돕습니다.
2.  **지속적인 AI 피드백 루프 구축:** AI가 생성한 코드나 제안을 단순히 수용하는 것이 아니라, 적극적으로 검토하고 피드백을 제공하는 시스템을 구축합니다. 린터(linter), 타입 체커(type checker), 그리고 자동화된 테스트 도구를 활용하여 AI의 출력을 검증하고, 개선이 필요한 부분을 AI에게 다시 학습시키는 반복적인 프로세스를 만듭니다.
3.  **AI를 활용한 문제 분해 및 관리:** 복잡한 문제를 작은 단위로 분해하고, AI에게 각 단위 문제를 해결하도록 지시합니다. 이때, AI가 여러 '에이전트(agent)'로 작동하도록 하여 병렬적으로 다양한 해결책을 탐색하게 할 수 있습니다. 개발자는 이러한 에이전트들의 관리자로서 전체적인 진행 상황을 감독하고, 최적의 경로를 선택하는 역할을 수행합니다.
4.  **AI 리터러시(AI Literacy) 강화:** 개발자들은 AI의 작동 원리, 강점, 한계, 그리고 윤리적 고려사항에 대한 깊은 이해를 갖춰야 합니다. 이는 단순히 AI 도구를 사용하는 방법을 아는 것을 넘어, AI가 언제 어떤 상황에서 가장 효과적인지, 그리고 잠재적인 편향이나 오류를 어떻게 식별하고 완화할 수 있는지를 아는 것을 의미합니다. 교육 기관과 기업은 이러한 AI 리터러시를 개발자 교육 과정에 필수적으로 포함해야 합니다.
5.  **버전 관리 및 감사(Audit) 가능한 AI 통합:** AI가 생성한 코드는 기존의 버전 관리 시스템에 통합되어야 하며, AI의 모든 작업 과정은 투명하게 기록되고 감사(audit) 가능해야 합니다. 이는 AI의 오류 발생 시 원인을 추적하고, 법적/윤리적 문제 발생 시 책임을 명확히 하는 데 필수적입니다.

이러한 메타 전략을 통해 개발자들은 GPT-5의 잠재력을 최대한 발휘하고, 소프트웨어 개발 프로세스를 혁신하며, AI와 인간이 함께 더 나은 결과물을 만들어내는 협력적인 미래를 구축할 수 있을 것입니다.

**모델 사양(Model Specs)(Model Specs)**

그렉(Greg) [01:31:48]: 모델 사양(model spec)은 모델의 능력이 매우 뛰어날 때, 그들이 무엇을 할 것인지에 대해 정말 신경 쓰기 시작한다는 완벽한 예시라고 생각합니다. 그것이 가장 중요한 질문이 됩니다. 그리고 모델 사양(model spec)은 우리가 이 모델이 무엇을 하도록 의도하는지 외부 세계에 매우 명확하게 보여주는 예시입니다. 그리고 그것이 항상 그 사양을 따를 수 있는 모델을 생산한다는 의미는 아니지만, 그것은 북극성(north star)입니다. 그렇죠? 그것은 정말로 '이것이 의도이며, 그것에서 벗어나는 모든 것은 우리의 명시적인 노력 때문이 아니다. 그것은 우리의 명시적인 노력에 반대된다'는 것을 설정합니다. 그리고 저는 사양(spec)과 실제 행동 사이의 격차가 매우 꾸준히 줄어들고 있다고 생각합니다. 매우 흥미로운 점은 거의 가치(values)와 같다는 것입니다. 논란의 여지가 있는 질문을 할 때 모델이 무엇을 해야 하는지에 대해 깊이 생각하는 것입니다. 그렇죠? 만약 당신이 '세상은 평평하다'고 말한다면, 모델은 '네, 평평합니다'라고 말해야 할까요? 아니면 '음, 과학은 이렇게 말합니다'라고 말해야 할까요? 그리고 솔직히 이러한 것들은 미묘합니다. 그렇죠? 단 2분 동안 생각한다고 해서 무엇이 옳은 일인지 명확하지 않습니다. 하지만 사양(spec)을 읽어보면, 그 안에 담긴 사려 깊음(thoughtfulness)을 실제로 볼 수 있습니다. 그리고 그것은 최종 답변이 아닙니다. 그렇죠? 그것은 우리가 피드백(feedback)을 원하는 것이고, 커뮤니티(community)로서 우리가 함께 만들어나가고 싶은 것입니다.

**GPT-5의 모델 라우팅(Model Routing) 및 하이브리드 아키텍처(Hybrid Architectures)(Model Routing and Hybrid Architectures in GPT-5)**

알레시오(Alessio) [01:32:55]: 다음으로 오픈 소스(open source)에 대해 이야기하고 싶지만, 더 난해한 질문이 있었습니다. 당신의 옛 렉스 프리드먼(Lex Friedman) 인터뷰를 듣고 있었습니다. 그리고 당신은 옛날에, 옛날에, 파운데이션(foundation)에 대해 언급했지만, 아시모프(Asimov)는 저에게 브렛 테일러(Brett Taylor)가 팟캐스트(podcast)에 출연하여 특정 언어가 본질적인 능력(inherent capabilities)을 가지고 있다고 말했던 것을 떠올리게 했습니다. 예를 들어 러스트(Rust)는 메모리 안전(memory safe)합니다. 그래서 그것은 그냥 일어납니다. LLM(대규모 언어 모델)과 소프트웨어 엔지니어(software engineer)의 역사 주기(cycle history)를 거의 보는 것과 같다고 생각하십니까? 마치 '야, 이 모델들은 소프트웨어가 어떻게 보일지 예측할 수 있어. 모든 것이 파란색과 보라색 그라데이션(blue and purple gradients)이 될 거야'와 같습니다. 그렇죠? 우리는 오늘날 그것을 보고 있습니다. 이 모델들이 우리를 정말로 어디로 이끌고 있습니까? 그리고 그것을 바꿀 방법이 있을까요?
그렉(Greg) [01:33:36]: 음, 분명히 그들의 역사 주기(cycle history)가 있습니다. 왜냐하면 어느 정도 이 모델들은 역사 주기(cycle history)의 산물이기 때문입니다. 그렇죠? 마치 이 모델들은 인간의 사고(human thought)를 관찰하는 것을 통해 훈련받았습니다. 그렇죠? 효과적으로 그렇게 생각할 수 있습니다. 공개 데이터(public data)를 가져와서 그것을 학습하고 관찰하는 것입니다. 요점은 데이터셋(dataset)을 지배하는 규칙을 이해하는 것입니다. 애초에 데이터를 생성하는 기본 규칙은 무엇인가? 그리고 그것이 이 모델들이 성장한 방식입니다. 그렇죠? 마치 외계인(alien)이 TV를 보면서 '인간은 대체 무엇인가?'를 알아내려고 하는 것과 같습니다. 그리고 나서 강화 학습 단계(reinforcement learning phase)가 있는데, 그들은 실제로 여러 가지를 시도하고, 인간이 원하는 것과 얼마나 일치하는지에 따라 긍정적 및 부정적 피드백(positive and negative feedback)을 받습니다. 그리고 이제 우리는 그들을 현실에 투입하고 '좋아, 이제 시도해봐. 그리고 여기 네가 한 번도 본 적 없는 새로운 작업들이 있어'라고 말합니다. 그리고 그것은 이전의 모든 역사를 사용하여 무엇을 할지 결정합니다. 여담으로, 명확하지 않습니다. 때로는 생물학적 비유, 인간은 과장하기 매우 쉽지만, 과소평가하기도 쉽습니다. 저는 그것이 어느 정도 유용한 틀이라고 생각합니다. 인간도 그렇게 작동합니다. 그렇죠? 당신은 DNA에 인코딩된 어떤 종류의 선사 시대(prehistory)를 가지고 있습니다. 당신은 삶의 경험을 가지고 있습니다. 긍정적 및 부정적 보상(positive and negative rewards)을 제공한 부모님이 있습니다. 그리고 현실에서 여러 가지를 시도하는 경험을 가지고 있습니다. 그리고 이제 당신은 그 지식을 사용해야 합니다. 그리고 무엇을 할 것입니까? 그리고 한 사람이 무엇을 할지 어떻게 예측합니까? 그리고 실제로 당신은 한 사람이 무엇을 할지 많이 예측할 수 있습니다. 당신은 다른 사람들과 그들이 어떤 것에 어떻게 반응할지, 좋아할지, 싫어할지에 대한 꽤 좋은 모델을 가지고 있다는 것이 밝혀졌습니다. 그리고 그 중 많은 부분이 누군가의 가치(values)를 아는 것에 반영되어, 그들이 무엇을 할 가능성이 높고 어떻게 행동할 가능성이 높은지에 대해 많은 것을 알려줍니다. 그리고 저는 모델의 미래는 미리 정해져 있지 않다고 생각합니다. 알고리즘(algorithm) 자체가 모델이 보라색 그라데이션(purple gradients)을 선호해야 한다고 말하는 것은 아닙니다. 그렇죠? 하지만 이 전체 과정에는 그러한 선호도를 생성하는 어떤 것이 있습니다. 그리고 저는 모델을 통한 기회 중 하나는, 알렉(Alec)이 말하고 싶어 하는 한 가지는, 이 모델들이 인간이라기보다는 인류와 같다는 것입니다. 그렇죠? 그들 안에 너무 많은 개성(personalities)이 내재되어 있습니다. 거의 모든 개성(personality)이 그 안에 있습니다. 그리고 우리의 목표는 그 개성(personality)을 이끌어내는 것입니다. 그리고 이 후속 훈련 작업(post-training work), 이 강화 학습 작업(reinforcement learning work) 중 일부는 그러한 개성(personalities)의 공간을 바람직한 것들로만 좁힙니다. 그리고 저는 그것이 의미하는 바는 우리가 우리의 가치(values)에 따라 작동하는 모델을 생산할 기회를 가지고 있다는 것입니다. 그렇죠? 만약 당신이 보라색 그라데이션(purple gradient)만 원하지 않고, 파란색 그라데이션(blue gradient), 녹색 그라데이션(green gradient) 등을 원한다면. 단일 모델(single model)에 이 모든 것을 가질 수 있습니다. 괜찮습니다. 그리고 GPT-5 자체는 지시 따르기(instruction following)에 극도로 능숙합니다. 그래서 그것은 우리가 지금까지 생산한 모델 중 가장 개인화 가능한 모델(personalizable model)입니다. 단순히 말하거나 지시를 제공함으로써 당신이 선호하는 대로 작동하게 할 수 있습니다.
스윅스(Swyx) [01:36:24]: 제가 가진 비유는 보그(Borg)와 같습니다. 마치 집단 지성(collective intelligence)과 같은 것이죠. 스타워즈(Star Wars) 팬들과 스타트렉(Star Trek) 팬들 사이에 누가 더 나은 모델을 가지고 있는지에 대한 논쟁이 항상 있습니다. 그리고 저는 스타트렉(Star Trek)이라고 생각합니다.
알레시오(Alessio) [01:36:35]: 음, 샘(Sam)은 데스 스타(Death Star)를 트윗했습니다. 그래서 당신은 이제 스타워즈 팀(Star Wars team)에 속해 있습니다. 네, 그게 뭐였죠? 당신이 물어봐야 할 것입니다.
그렉(Greg) [01:36:44]: 이 모델들에 대해 매우 흥미롭다고 생각하는 한 가지는 우리가 이제 LM 아레나(LM Arena)와 같은 모든 아레나(arenas)를 가지고 있다는 것입니다. 거기서 모델이 작동하는 방식 위에 인간의 선호도(human preferences)를 실제로 볼 수 있습니다. 그리고 당신은 거의 이러한 계층화(layering)를 가지고 있습니다. 모델은 인간의 선호도(human preferences)에 따라 훈련받았습니다. 이제 그들은 일을 하고 인간의 판단을 받습니다. 그리고 우리는 그것을 피드백(feedback)으로 사용하여 '음, 그래, 보라색이 조금 과하네. 거기서 바꿔야겠어'라고 생각합니다. 그래서 그것은 거의 공동 진화(co-evolution)와 같습니다. 모델은 특정 방향으로 움직입니다. 인간은 특정 선호도(preferences)를 가지고 있습니다. 그래서 우리는 그들을 다른 방향으로 움직입니다. 그리고 나서, 아시다시피, 당신은 점점 더 유용하고 인간의 가치(values)와 일치하는 것을 얻기 위해 계속해서 반복합니다.

**새로운 관점: 동적 모델 라우팅과 AI 시스템의 지능형 오케스트레이션**

GPT-5가 선보이는 '모델 라우팅(Model Routing)'과 '하이브리드 아키텍처(Hybrid Architectures)'는 AI 시스템의 새로운 지능형 오케스트레이션(orchestration) 시대를 예고합니다. 그렉(Greg)이 언급했듯이, 이는 단순히 여러 모델을 사용하는 것을 넘어, 각 모델의 강점과 약점을 파악하여 특정 작업에 가장 적합한 모델을 동적으로 선택하고 조합하는 것을 의미합니다. 이는 마치 숙련된 팀 리더가 팀원들의 역량을 고려하여 프로젝트의 각 단계에 가장 적합한 전문가를 배치하는 것과 유사합니다.

이러한 동적 라우팅 시스템은 다음과 같은 기술적 혁신을 수반합니다:
1.  **실시간 작업 분석 및 모델 선택:** AI 시스템은 들어오는 요청의 복잡성, 지연 시간 요구사항, 필요한 전문 지식 등을 실시간으로 분석하여, 추론 모델(reasoning model), 비추론 모델(non-reasoning model), 또는 특정 도메인에 특화된 소형 모델(specialized small models) 중 최적의 조합을 선택합니다.
2.  **적응형 컴퓨팅 자원 관리:** 모델 라우팅은 컴퓨팅 자원의 효율적 사용과 직결됩니다. 저렴하고 빠른 모델로 처리할 수 있는 작업은 그렇게 처리하고, 고비용의 강력한 모델은 깊은 추론이 필요한 작업에만 할당함으로써 전체 시스템의 비용 효율성을 극대화합니다. 이는 '적응형 컴퓨트(adaptive compute)'의 핵심이며, AI 서비스를 더욱 광범위하게 보급하는 데 기여합니다.
3.  **에이전트 견고성(Agent Robustness) 및 보안 계층:** 다양한 모델과 환경(로컬/원격) 간의 상호작용은 보안 및 견고성 문제를 야기할 수 있습니다. OpenAI는 '지시 계층(instruction hierarchy)'과 같은 기술을 통해 모델이 신뢰할 수 있는 소스(예: 시스템, 개발자, 사용자)의 지시를 우선하도록 하여, 악의적인 공격이나 오작동으로부터 시스템을 보호합니다. 또한, 모델의 실행 환경을 샌드박스(sandboxed) 처리하고, 모든 행동을 감사(audit) 가능하게 함으로써 투명성과 통제력을 확보합니다.

이러한 하이브리드 아키텍처는 AI 시스템이 유연하고 효율적이며, 동시에 안전하고 신뢰할 수 있도록 설계되는 미래를 보여줍니다. 이는 AGI(범용 인공지능)가 단일의 거대한 모델이 아니라, 상호 연결된 다양한 지능형 에이전트들의 '동물원(menagerie)' 형태로 구현될 것이라는 비전을 뒷받침합니다.

**RL 선호도(Preferences)의 과제 (예: try/catch)(Challenges in RL Preferences (e.g., try/catch))**

알레시오(Alessio) [01:37:21]: RL(강화 학습) 보상(rewards)이 인간이 선호하지 않을 수도 있는 것들과 연결되어 있을 때 어떻게 하십니까? 제 경험상, try/catch와 같습니다. 모델은 실패하지 않도록 try/catch를 작성하는 것을 좋아합니다. 그들이 그렇게 해서는 안 된다는 것을 보여주는 많은 선호도 데이터(preference data)가 필요할까요? RL 환경(RL environments)에서 덜 바람직하게 만들기 위해 우리가 바꿀 것이 있을까요? 우리는 여기서 어디로 가야 할지 알아내려고 노력하고 있습니다.
그렉(Greg) [01:37:43]: 네, 개입(interventions)이 어디로 가야 할지 결정하거나 알아내는 방식은 매우 다면적이며 행동에 매우 구체적이라고 생각합니다. 모델의 다양한 라이브러리(libraries) 지식과 같은 것들은 초기부터 내재되어 있습니다. 하지만 당신은 모델에게 '야, 이전 지식에 의존하지 마. 가서 최신 문서(docs)를 찾아봐'라고 가르칠 수도 있습니다. 그리고 그것은 더 높은 수준에 놓을 수 있는 것입니다. 그리고 try/catch를 과도하게 사용하는 것과 같은 것은 실제로 모델에게 프롬프트(prompt)를 줄 수 있는 것입니다. 그렇죠? 그리고 그것은 우리가 강화 학습(reinforcement learning)으로 훈련시킬 때 '아, 이 방향으로 가지 마'라고 말하는 보상(rewards)을 제공할 수 있는 것입니다. 그리고 이 모델들의 아름다운 점은 마치 '좋아, 다양한 선호도(preferences)와 다양한 스타일(styles) 등의 긴 목록이 있을 것이고, 만약 당신이 가고 싶은 방향이라면 훈련 중에 그것에 대한 피드백(feedback)을 주어야 할 것이다'라고 느껴진다는 것입니다. 하지만 이 모델들은 일반화(generalize)합니다. 우리가 가진 알고리즘(algorithms)은 일반화(generalize)합니다. 그리고 그것이 딥러닝(deep learning)의 아름다움입니다. 그것이 진정한 마법입니다. 그렇죠? 매우 쉽습니다. 우리는 이제 딥러닝(deep learning)의 핵심을 중심으로 구축된 전체 스택(stack)을 가지고 있습니다. 그렇죠? 모델을 오케스트레이션(orchestrating)하는 모든 방식과 피드백(feedback)을 얻는 방법, 그리고 데이터(data) 등 이 모든 것들. 딥러닝(deep learning)의 핵심 마법은 일반화(generalize)하는 능력입니다. 그리고 어떤 면에서는 일반화(generalization)가 당신이 원하는 것보다 약합니다. 하지만 저는 이 모델들도 마찬가지라고 생각합니다. 그들이 다른 선호도(preferences)와 가치(values)에 따라 작동할 수 있도록 하기 위해 정말로 생각해야 합니다. 우리는 훈련 중에 그것을 그들에게 보여주기만 하면 되고, 그들은 우리가 실제로 훈련시키지 않은 다른 선호도(preferences)와 가치(values)로 일반화(generalize)할 수 있습니다. 그리고 그것은 우리가 다른 모델 세대에서 매우 일관되게 보아온 것입니다.

**GPT-5 가격 책정 및 컴퓨트 효율성 개선(GPT-5 pricing and compute efficiency improvements)**

스윅스(Swyx) [01:43:40]: 네, 좋습니다. 가격 질문입니다. GPT-5 가격 책정은 공격적이고 매우 경쟁적이라고 말했습니다. 심지어 제미니(Gemini)와 비교해도 말이죠. 며칠 전 모임에서 GPT-5 가격이 훨씬 더 저렴해질 수 있다는 것을 알게 되어 놀랐습니다. 어느 정도의 규모를 이야기하는 것입니까? 스타게이트(Stargate) 앞에서 더 나아지는 것이 몇 퍼센트나 됩니까?
그렉(Greg) [01:43:58]: 이러한 질문에 대한 답은 항상 '좋아, 스타게이트(Stargate)로 가면 더 나아질 것이다'라는 것입니다. 우리의 가격 책정 역사(history of our pricing)를 보면, 우리는 매우 일관되게 가격을 인하했습니다. 정확한 요인은 모르겠지만, 예를 들어 연간 10배 정도라고 합시다. 그보다 더 공격적이라고 말하겠습니다. 아마도 그보다 더 공격적일 것입니다. 이것은 미친 일입니다. 그렇죠? 그리고 O3에서 그것을 볼 수 있습니다. 우리는 80% 가격 인하를 한 것 같습니다. 그리고 실제로 사용량이 증가하여 매출(revenue) 측면에서 중립적이거나 긍정적이었습니다. 그리고 그것은 수요가 극도로 높고 극도로 가파르다는 것을 보여줍니다. 그렇죠? 그래서 단순히 사람들에게 더 접근 가능하고 이용 가능하게 만들면, 그들은 훨씬 더 많이 사용할 것입니다. 그리고 저는 그것이 우리의 사명(mission)과 매우 일치한다고 생각합니다. 그렇죠? 우리의 목표는 AGI(범용 인공지능)가 모든 인류에게 혜택을 주도록 하는 것입니다. 그 일부는 이 기술이 광범위하게 배포되고, 많은 사람들이 AI(인공지능)를 사용하며, 그것을 자신의 삶과 일에 적용하도록 하는 것입니다. 그리고 우리가 그곳에 도달하는 데 도움이 되는 것 중 하나는 더 효율적인 추론(inference)을 가지고, 더 저렴한 모델(models)을 가지고, 이 모든 것들을 갖는 것입니다. 이제 그것을 가능하게 하는 것은 부분적으로는… 지금 우리는 극도로 컴퓨트(compute)에 제한되어 있습니다. 그래서 저는 우리가 가격을 많이 인하한다면, 이 모델의 사용량이 실제로 증가하지 않을 것이라고 생각합니다. 우리는 또한 많은 효율성을 얻어야 합니다. 그리고 그것은 우리 팀이 항상 다음 수준의 추론 효율성(inference efficiency)에 도달하기 위해 매우 열심히 노력하는 부분입니다. 이 중 일부는 모델 아키텍처(model architecture) 자체를 개선하는 것입니다. 그렇죠? 당신이 내릴 수 있는 많은 아키텍처 결정(architectural decisions)이 있습니다. 그리고 이제 우리가 추론(reasoning)의 세계에 있다는 것은 단순히 모델 아키텍처(model architecture)에 관한 것이 아니라는 것입니다. 그것은 또한 후처리(post-production)에 관한 것입니다. 그것은 훈련(training)에 관한 것입니다. 특정 작업을 위해 얼마나 오랫동안 생각하는지 등과 같은 것입니다. 그래서 우리가 만들어야 할 개선의 차원(dimensions of improvement)이 매우 많고, 우리는 계속해서 밀어붙일 것입니다.
스윅스(Swyx) [01:45:41]: 참고로, 숫자… 필요하시면 차트(chart)가 있습니다. GPT-4를 출시한 날부터 같은 수준의 지능(intelligence)에 대해 비용이 1,000배 개선되었습니다.
그렉(Greg) [01:45:51]: 정말 놀랍습니다. 정말 놀랍습니다. 정말 좋습니다. 네, 2년 반 정도 되는 기간 동안 말이죠. 2년 반 동안 3자릿수 규모의 개선을 이룬 다른 것이 무엇이 있을까요? 모르겠습니다. 아무것도 없습니다. 생각할 수 없습니다. 네.

**새로운 관점: AI를 유틸리티처럼, 접근성 확대를 통한 혁신 촉진**

GPT-5의 공격적인 가격 책정과 지속적인 컴퓨팅 효율성 개선은 AI를 '유틸리티(utility)'처럼 모두가 접근하고 활용할 수 있는 자원으로 만들겠다는 OpenAI의 비전을 반영합니다. 그렉(Greg)이 언급했듯이, 가격 인하는 AI 기술의 광범위한 보급과 채택을 촉진하여, 궁극적으로 AGI(범용 인공지능)가 모든 인류에게 혜택을 주도록 하는 사명과 일치합니다.

AI가 유틸리티처럼 저렴해지고 접근성이 높아지면 다음과 같은 혁신이 촉진될 것입니다:
1.  **AI 민주화 및 혁신 가속화:** 비용 장벽이 낮아지면 스타트업, 소규모 기업, 개인 개발자들도 최첨단 AI 모델을 활용하여 혁신적인 제품과 서비스를 개발할 수 있게 됩니다. 이는 예상치 못한 분야에서 새로운 AI 애플리케이션의 등장을 촉진하고, 전체 산업의 경쟁력을 향상시킬 것입니다.
2.  **새로운 비즈니스 모델의 출현:** AI가 저렴해지면서 'AI as a Service'를 넘어선 새로운 비즈니스 모델이 나타날 수 있습니다. 예를 들어, 특정 도메인에 최적화된 소형 AI 모델을 저렴하게 제공하거나, AI 기반의 자동화된 서비스가 대중화될 수 있습니다.
3.  **지능형 인프라로의 전환:** 도시 관리, 에너지 효율, 교통 시스템 등 다양한 공공 인프라에 AI가 더욱 깊이 통합될 수 있습니다. 저렴한 AI는 이러한 시스템을 더욱 지능적이고 효율적으로 만들어 시민들의 삶의 질을 향상시키는 데 기여할 것입니다.
4.  **글로벌 AI 격차 해소:** 선진국에 비해 AI 기술 접근성이 낮은 개발도상국에서도 저렴한 AI를 통해 교육, 의료, 농업 등 다양한 분야에서 혁신을 이끌어낼 수 있습니다. 이는 글로벌 AI 격차를 줄이고, 전 세계적인 발전을 촉진하는 데 중요한 역할을 합니다.

물론, 이러한 가격 인하와 효율성 개선은 단순히 모델 아키텍처의 발전뿐만 아니라, 추론(inference) 과정의 최적화, 후처리(post-processing) 기술의 향상, 그리고 컴퓨팅 자원 관리의 혁신 등 다각적인 노력을 통해 이루어집니다. AI가 모두에게 이로운 유틸리티가 되기 위한 여정은 여전히 진행 중이며, 이는 기술 발전과 사회적 책임이 함께 요구되는 중요한 과제입니다.

**자체 개선 코딩 에이전트(Self-Improving Coding Agents) 및 도구 사용(Self-Improving Coding Agents and Tool Usage)**

알레시오(Alessio) [01:46:04]: 그리고 그것은 계속 낮아지고 있습니다. 심지어… 10,000달러에서 1,000달러로 가는 것과 같습니다. 몇 푼으로 갈 것입니다. GPT-5 출시를 위해 저는 '자체 개선 코딩 에이전트(Self-Improving Coding Agents)'라는 기사를 썼습니다. 그래서 저는 기본적으로 GPT-5에게 '더 나은 코딩 에이전트(coding agent)가 되기 위해 스스로 도구(tools)를 만들 수 있니?'라고 물었습니다. 그리고 이것은 스위 랜서(Swy Lancer) 작업입니다. 그리고 그것은 작업을 수행합니다. 어떤 면에서는 실패합니다. 그리고 저는 그것에게 '스스로 도구(tools)를 개선하고 이 루프(loop)를 반복할 수 있니?'라고 물었습니다. 그리고 제가 발견한 것은… 모델은 자신이 만든 새로운 도구(tools)를 실제로 사용하고 싶어 하지 않는다는 것입니다. 그들은 '그냥 내가 할 수 있어. 도구(tool)는 필요 없어'라고 바쁘게 응답합니다. 그리고 저는 마치… 인간과 같네요. 네. 마치 '어떻게 스스로 개선할 수 있을까?'라는 느낌이 든다는 것입니다. 그것이 부분적으로는 '야, 그들은 그래프(graph)나 그런 것과 같은 이러한 도구(tools)를 사용하도록 가르침을 받고 있을 뿐이야. 그래서 추론 시간(inference time)에 도구(tools)를 만드는 것이 어려워?' 아니면 이것을 그 도약의 일부로 보십니까?
그렉(Greg) [01:46:58]: 저는 그것이 좋다고 생각합니다. 그것이… 네, 분명히 그렇습니다. 그렇죠. 그리고 우리가 그것을 할 수 있는 능력이 0인 것은 아닙니다. 그렇죠. 그리고 이 중 많은 부분이 단순히 훈련(training)에 관한 것이라고 생각합니다. 그렇죠? 모델이 특정 도구(tools) 세트로만 훈련받았고, 새로운 도구(tool)에 매우 빠르게 적응하도록 밀어붙여지지 않았다면, 평가 시간(evaluation time)에 다르게 행동할 것이라고 기대해서는 안 됩니다. 하지만 스스로 도구(tools)를 생산하여 더 효율적으로 만들고, 시간이 지남에 따라 영구적인 방식으로 그러한 라이브러리(library)를 구축하는 아이디어는 당신의 도구 상자(toolbox)에 있어야 할 놀라운 원시 기능(primitive)입니다. 그리고 저는 당신의 목표가… 네. …이러한 믿을 수 없을 정도로 어려운 도전 과제, 미해결 문제(unsolved problems)를 해결할 수 있는 것이라면, 당신은 그러한 종류의 것을 의존성(dependency)으로 필요로 할 것이라고 생각합니다.

**어떤 아키텍처 결정이나 혁신에 대해 이야기하고 싶으십니까?(Any architectural decisions or innovations that you would like to talk about?)**

스윅스(Swyx) [01:47:36]: 슬라이딩 윈도우 어텐션(Sliding window attention), 딥시크(DeepSeek)가 대중화한 매우 세분화된 전문가 혼합(mixture of experts), 로프(rope), 얀(yarn), 어텐션 싱크(attention sinks) 등 GPT-OSS를 위해 내린 결정 중에서 당신에게 특별히 눈에 띄는 것이 있습니까?
그렉(Greg) [01:47:53]: 이러한 선택들은 모두, 아시다시피, 다양한 아키텍처(architectures)를 연구해온 팀이 있습니다. 우리는 다양한 것들을 탐색했습니다. 전문가 혼합(mixture of experts)과 같은 것은 재미있습니다. 저는 그 선택에 대해 우리 팀에게 공을 돌리고 싶습니다. 하지만 제 생각에는 이러한 환경에서 쉽게 실행할 수 있는 것을 원했습니다. 그래서 얼마나 희소하게 갈 것인지와 같은 것을 선택하는 것은 메모리 사용량(memory footprint)과 매우 밀접하게 관련되어 있습니다. 그리고, 아시다시피, 순방향 패스(forward pass)에 실제로 사용할 수 있는 컴퓨트(compute)의 양 등과 관련되어 있습니다. 그래서 저는 어느 정도 아키텍처 결정(architectural decisions)은 모델 크기(model sizing)와 실행 시 접근할 수 있을 것으로 예상되는 컴퓨트(compute)에 의해 상당히 제약받았다고 생각합니다. 네.
스윅스(Swyx) [01:48:37]: 제 말은, 매우 실용적인 엔지니어링 결정(engineering decisions)입니다. 정말 그렇습니다. 네.
그렉(Greg) [01:48:40]: 네, 그렇다고 생각합니다. 그리고 저는 모델의 힘이 정말로 드러난다고 생각합니다. 우리는 모델의 능력을 더욱더 발전시키기 위해 우리의 최첨단 기술을 많이 사용했습니다.
스윅스(Swyx) [01:48:50]: API 사용을 위해 설계된 모델과 단일 기계(single machine)를 위해 설계된 모델의 아키텍처(architecture) 간의 차이를 분명히 감지합니다. 제 말은, 멀티테넌시(multi-tenancy)가 있고 배치(batching)를 할 수 있을 때, 단일 기계(single machine)와는 매우 다릅니다. 매우 다릅니다. 네. 그것이 언젠가 결합될지는 모르겠지만, 어쩌면 당신이 항상 말하는 모델의 동물원(menagerie model)일 수도 있습니다. 네.

**새로운 관점: AI의 메타 학습 능력과 자기 개선의 한계**

AI 모델이 스스로 도구를 만들고 개선하여 '자체 개선(self-improving)'하는 능력은 AGI(범용 인공지능)의 핵심적인 특징 중 하나입니다. 그러나 현재 GPT-5와 같은 모델들은 자신이 만든 새로운 도구를 적극적으로 활용하려 하지 않는 경향을 보입니다. 이는 AI의 '메타 학습(meta-learning)' 능력, 즉 학습하는 방법을 학습하는 능력에 대한 중요한 질문을 제기합니다.

AI가 새로운 도구를 만들었음에도 불구하고 이를 사용하지 않는다는 관찰은 여러 가지 원인을 시사합니다:
1.  **훈련 데이터의 한계:** 모델이 특정 도구 세트로만 훈련받았다면, 새로운 도구의 가치를 인식하고 이를 자신의 문제 해결 전략에 통합하는 데 어려움을 겪을 수 있습니다. 이는 AI가 새로운 상황에 대한 일반화(generalization) 능력이 아직 완벽하지 않음을 보여줍니다.
2.  **인지 부하(Cognitive Load):** 새로운 도구를 통합하고 사용하는 것은 모델에게 추가적인 '인지 부하'를 발생시킬 수 있습니다. 모델은 기존의 익숙한 방식으로 문제를 해결하는 것이 더 효율적이라고 판단할 수 있으며, 이는 인간이 새로운 기술을 배우는 것을 꺼리는 것과 유사합니다.
3.  **내재적 동기 부족:** 현재의 AI는 인간처럼 내재적 동기(intrinsic motivation)를 가지고 스스로를 개선하려는 의지가 부족합니다. 외부 보상(external rewards)이나 명시적인 지시 없이는 새로운 도구 활용의 필요성을 느끼기 어려울 수 있습니다.

이러한 한계를 극복하기 위해서는 AI의 훈련 방식에 근본적인 변화가 필요합니다. 모델이 단순히 특정 작업을 수행하도록 가르치는 것을 넘어, '도구를 만드는 방법', '새로운 도구를 평가하고 통합하는 방법', 그리고 '자신의 학습 전략을 최적화하는 방법'을 학습하도록 설계해야 합니다. 이는 AI가 진정으로 '스스로 생각하고 개선하는' 존재로 진화하기 위한 다음 단계이며, 미해결된 복잡한 문제들을 해결하는 데 필수적인 역량이 될 것입니다.

**온디바이스 모델(On-Device Models) 및 로컬(Local) vs 원격 에이전트 시스템(Remote Agent Systems)(On-Device Models and Local vs Remote Agent Systems)**

그렉(Greg) [01:49:11]: 로컬 모델(local model)이 때때로 원격 모델(remote model)에 위임하는 아키텍처(architecture)에 대해 생각하는 것도 정말 흥미롭습니다. 그렇죠? 그리고 이것은 훨씬 더 빠르게 실행될 수 있는 것이 될 수 있습니다. 개인 정보 보호 아키텍처(privacy architecture) 관점에서 무엇이 실제로 가고 무엇이 남는지 결정하려고 노력하는 것과 엣지 컴퓨트(edge compute)를 갖는 것이 도움이 됩니다. 그것은 인터넷 연결을 잃어도 여전히 무언가를 할 수 있고, 더 느린 계획 모델(planning model)을 가질 수 있다는 것을 의미합니다. 이러한 것들 사이의 상호 작용은 매우 흥미롭습니다. 네.
스윅스(Swyx) [01:49:38]: 마치 온디바이스(on-device) GPT-5가 여기에 GTOS-S를 가지고 있고, 사용 가능하면 온라인으로 라우팅(routes)하는 것과 같습니다. 모르겠습니다.
그렉(Greg) [01:49:46]: 네, 그런 것과 같습니다. 그리고 당신은 로컬 에이전트(local agent)와 원격 에이전트(remote agent)를 가진 코덱스 인프라(Codex infrastructure)를 가지고 있으며, 둘 사이를 원활하게 상호 작용할 수 있고, 멀티플레이어(multiplayer)를 할 수 있습니다. 이것은… 이것이 미래의 모습이 될 것이고, 놀라울 것입니다.
알레시오(Alessio) [01:50:03]: 그리고 당신은 항상 당신과 함께하는 장치를 가지고 있습니다. 알겠습니다. 상황이 어떻게 돌아가는지 알겠습니다. 모든 것이 연결됩니다. 네.
스윅스(Swyx) [01:50:09]: 장치에 대해 무엇을 말할 수 있습니까? 당신이 언급했습니다. 그렉을 곤란하게 만들고 싶지 않습니다. 장치에 대해 무엇을 말할 수 있습니까? 훌륭할 것입니다.
스윅스(Swyx) [01:50:18]: 좋습니다. 그리고 또 다른 정치적인… 정치적인지 아닌지는 모르겠습니다. 아시다시피, 중국에서 많은 오픈 모델(open models)이 나오고 있습니다. 미국산 오픈 소스(open source)가 중요한 이유는 무엇입니까?
그렉(Greg) [01:50:28]: 또 다른 것입니다. 우리가 오픈 소스 모델(open source models)에 대해 매우 실용적인 수준에서 생각한 것은 우리의 오픈 소스 모델(open source model)을 기반으로 구축하는 사람들이 우리의 기술 스택(tech stack)을 기반으로 구축한다는 것입니다. 그렇죠? 만약 당신이 모델을 개선하는 데 우리의 도움에 의존하고, 다음 돌파구를 찾는 데 우리에게 의존한다면, 그것은 당신이 우리 사업에 좋은 방식뿐만 아니라, 국가에도 좋은 방식으로 의존한다는 것을 의미합니다. 그렇죠? 사람들이 직접 실행하는 모델에서 미국 기술 스택(American tech stack)을 갖는 것에 대해 생각하지만, 그것들이 우리가 방금… 그것이 실제로 사람들이 자신에게 중요한 부분에 대한 통제권을 가질 수 있는 전체 생태계(ecosystem)를 구축할 수 있도록 허용한다는 것입니다. 궁극적으로 미국적 가치(American values)를 반영하는 이러한 모델을 기반으로 구축되고, 그 다음에는 미국산, 바라건대 아래에는 칩(chips)이 있고 백엔드(backend)에는 클라우드 모델(cloud models)이 있으며 실행 환경(execution environments)이 있고, 이 모든 것이 함께 어우러지는 것이 많은 가치를 더한다고 생각합니다. 그리고 그것은 미국 리더십(American leadership)이 실제로… 우리가 세계에서 우리의 가치(values)에 대한 리더십(leadership)을 가지고 있다는 것을 의미한다고 생각합니다. 네.
스윅스(Swyx) [01:51:32]: 출시를 축하드립니다. 감사합니다.

**새로운 관점: 엣지 AI(Edge AI)와 연합 학습(Federated Learning)을 통한 AI의 보편화**

온디바이스(on-device) 모델과 로컬(local) 및 원격(remote) 에이전트 시스템 간의 상호작용은 AI 기술의 미래를 형성하는 중요한 축입니다. 이는 '엣지 AI(Edge AI)'의 부상과 '연합 학습(Federated Learning)'과 같은 분산 학습 패러다임의 중요성을 강조합니다.

엣지 AI는 AI 모델이 클라우드 서버가 아닌 스마트폰, 센서, 로봇 등 최종 사용자 기기에서 직접 구동되도록 하는 기술입니다. 이는 다음과 같은 이점을 제공합니다:
1.  **개인 정보 보호 및 보안 강화:** 민감한 데이터가 클라우드로 전송될 필요 없이 기기 내에서 처리되므로, 사용자의 개인 정보가 더욱 안전하게 보호됩니다.
2.  **낮은 지연 시간 및 오프라인 작동:** 네트워크 연결 없이도 AI 기능이 작동하며, 실시간 응답이 필요한 애플리케이션(예: 자율주행, 증강 현실)에 필수적입니다.
3.  **효율적인 자원 활용:** 클라우드 서버의 부담을 줄이고, 컴퓨팅 자원을 분산하여 전체 시스템의 확장성과 효율성을 높입니다.

여기에 '연합 학습'은 여러 기기에서 개별적으로 학습된 모델 파라미터를 중앙 서버로 전송하여 통합하고, 이를 다시 각 기기로 배포하는 방식으로, 데이터 프라이버시를 유지하면서 대규모 모델을 훈련할 수 있게 합니다. 예를 들어, 수많은 스마트폰에서 사용자의 개인 데이터를 직접 공유하지 않고도, 각 기기에서 학습된 패턴을 통합하여 더 나은 예측 모델을 만들 수 있습니다.

이러한 기술들은 AI를 특정 서버나 클라우드 환경에 국한시키지 않고, '항상 켜져 있고, 항상 학습하며, 항상 사용자와 함께하는' 보편적인 지능으로 확장시킬 잠재력을 가집니다. 이는 AI가 우리의 일상생활과 산업 전반에 더욱 깊숙이 통합되어, 개인화된 경험과 지능형 서비스를 제공하는 미래를 현실로 만들 것입니다.

**OpenAI의 엔지니어링 및 LLM(대규모 언어 모델) 활용(Engineering at OpenAI and Leveraging LLMs)**

알레시오(Alessio) [01:51:34]: OpenAI의 엔지니어링에 대해 이야기해봅시다. 클라우드 코드(cloud code)와 AIDR(에이전트 기반 개발 및 연구) 및 오픈 코드(open code)와 이 모든 다른 도구(tools)에 대한 많은 논쟁이 있다는 것을 알고 있습니다. 이러한 것들로부터 가장 높은 레버리지(leverage)를 얻는 팀 자체를 어떻게 구성해야 한다고 생각하십니까? 숫자 관점에서, 능력 관점에서, 조직 내 팀 규모 관점에서 팀을 구축하는 방식을 바꾸고 있습니까? 공유하고 싶은 것이 있습니까? 음, 엔지니어링…
그렉(Greg) [01:51:58]: 소프트웨어 엔지니어링(Software engineering)은 분명히 여러 차원에서 변화하고 있습니다. 이 모델들이 정말로 해결하기 어려운 엔지니어링(engineering) 부분이 있지만, 우리는 그것이 시작되는 것을 보기 시작했습니다. 그리고 그것은 이러한 매우 핵심적이고 어려운 알고리즘(algorithms)입니다. 그렇죠? CUDA 커널(CUDA kernels)과 같은 것들은 매우 독립적인(self-contained) 문제의 좋은 예시이며, 우리 모델들은 곧 그것에 매우 능숙해져야 합니다. 하지만 그것은 많은 도메인 전문 지식(domain expertise)과 많은 실제 추상적 사고(abstract thinking)를 필요로 하기 때문에 어렵습니다. 하지만 다시 말하지만, 그것은 해결 불가능한 것이 아닙니다. 독립적(self-contained)입니다. 그것은 우리가 가진 기술에 매우 적합한 종류의 문제입니다. 아키텍처(architecture) 측면에서 매우 어려운 다른 문제들도 있습니다. 그렇죠? 시스템이 어떻게 구성되어야 하는지 생각하고 추상화(abstractions)에 대해 생각하는 방법 말입니다. 그리고 다시 말하지만, 우리 모델들은 이것에 어느 정도 능숙해지기 시작했습니다. 그래서 저는 우리가 본 것은 대부분의 엔지니어들, 심지어 매우 훌륭한 엔지니어들에게도 그들의 작업 중 많은 부분이 현재 모델의 핵심 강점과 매우 잘 일치한다는 것입니다. 그리고 특히 당신이 전문가가 아닌 언어와 같은 모든 것에 대해서는, 네. 당신은 분명히 그 코드를 직접 작성하고 싶지 않을 것입니다. 당신은 모델이 그것을 하도록 정말로 원할 것입니다. 그리고 나서 일이 훨씬 더 어려워지는 부분도 있습니다. 왜냐하면 모델이 접근할 수 없는 것들을 필요로 하기 때문입니다. 그렇죠? 좋은 결정을 내리기 위해 많은 맥락(context)과 사람들과 이야기하는 것이 필요합니다. 그래서 저는 우리가 아직 이러한 도구(tools)가 존재하기 때문에 팀을 구성하는 방식에 변화가 있다고 실제로 볼 수 있는 지점에 도달하지 못했다고 생각합니다. 하지만 저는 이 모델들이 가능한 모든 영역에서 사용되도록 하는 것이 극도로 높은 우선순위인 지점에 도달했다고 생각합니다. 그리고 팀을 어떻게 구성할지 생각하고, 그것을 잘 그리고 책임감 있게 어떻게 할지 생각하고, 가드레일(guardrails)이 무엇이어야 할지 생각하는 것입니다. 그리고 그것은 매우 실용적인 방식으로 일어납니다. 그래서 저는 제가 보고 있는 많은 부분이 초기 채택자 단계(early adopter phase)에서 주류 단계(mainstream phase)로 전환하기 시작하고 있다는 것입니다. 그리고 사람들이 더 많은 일을 할 수 있게 됨으로써 얻는 생산성 영향은 우리가 실제로 더 많은 사람들을 원한다는 것을 의미합니다. 그렇죠? 우리는 소프트웨어(software)를 생산하는 능력에 의해 너무나 제한되어 있습니다. 우리는 우리 팀이 기술 부채(tech debt)를 실제로 정리하고 리팩토링(refactor)하는 능력에 의해 너무나 제한되어 있습니다. 그리고 만약 우리가 그것을 10배 더 쉽게 만드는 도구(tools)를 가지고 있다면, 우리는 100배 더 많은 일을 할 수 있을 것입니다. 그래서 저는 이러한 모델들이 단순히 같은 일을 더 효율적으로 하는 진정한 동력이 아니라, 훨씬 더 많은 일을 할 수 있게 함으로써 엄청난 기회(incredible opportunity)가 수반된다고 생각합니다. 그리고 그것이 전반적인 목표라고 생각합니다. 네.

**새로운 관점: AI 시대의 새로운 역할과 조직 구조**

OpenAI의 엔지니어링 접근 방식은 LLM(대규모 언어 모델)이 소프트웨어 개발의 본질을 변화시키고 있음을 명확히 보여줍니다. AI가 코드 생성, 디버깅, 리팩토링 등 많은 반복적이고 기술적인 작업을 처리할 수 있게 됨에 따라, 인간 엔지니어의 역할은 진화하고 조직 구조 또한 이에 맞춰 변화해야 합니다.

AI 시대의 새로운 역할과 조직 구조는 다음과 같이 재편될 수 있습니다:
1.  **AI '프롬프트 엔지니어' 및 'AI 코디네이터':** AI 모델에 최적의 지시를 내리고, AI의 출력을 평가하며, 여러 AI 에이전트의 작업을 조율하는 전문 역할이 중요해집니다. 이들은 기술적 전문성뿐만 아니라, 문제 해결 능력, 비판적 사고, 그리고 효과적인 의사소통 능력을 갖춰야 합니다.
2.  **'AI 윤리학자' 및 'AI 감사자':** AI 시스템이 사회에 미치는 영향을 평가하고, 편향이나 오용 가능성을 식별하며, AI 개발 과정에서 윤리적 가이드라인을 준수하도록 감독하는 역할이 필요합니다. 이들은 AI의 기술적 한계와 사회적 함의를 동시에 이해해야 합니다.
3.  **'도메인 전문가'의 역할 강화:** AI가 특정 도메인 지식을 빠르게 습득하더라도, 깊이 있는 통찰력과 맥락적 이해는 여전히 인간 전문가의 영역입니다. AI 시대에는 각 분야의 도메인 전문가들이 AI와 협력하여 복잡한 문제를 정의하고, AI의 해결책을 검증하며, 새로운 혁신 기회를 발굴하는 데 집중할 것입니다.
4.  **유연하고 협력적인 팀 구조:** 전통적인 계층적 팀 구조는 AI 기반 개발 환경에 적합하지 않을 수 있습니다. 대신, AI와 인간이 함께 문제 해결에 참여하는 유연하고 교차 기능적인(cross-functional) 팀 구조가 필요합니다. 이는 '인간-AI 페어 프로그래밍(human-AI pair programming)'과 같은 새로운 협업 방식을 촉진합니다.

결론적으로, AI는 소프트웨어 생산성을 획기적으로 향상시킬 뿐만 아니라, 엔지니어의 역할을 재정의하고 조직 구조를 재편하는 강력한 동력입니다. 이러한 변화에 선제적으로 대응하는 기업과 개인만이 AI 시대의 경쟁 우위를 확보하고, 기술 혁신의 최전선에서 활약할 수 있을 것입니다.

**AI 최적화를 위한 코드베이스(Codebases) 및 팀 구성(Structuring Codebases and Teams for AI Optimization)**

알레시오(Alessio) [01:54:16]: LLM(대규모 언어 모델)에 더 잘 맞도록 팀의 작업을 어떻게 바꾸셨습니까? 문제를 추적하는 방식이 달라졌습니까? 코드베이스(code bases)를 구성하는 방식이 달라졌습니까?
그렉(Greg) [01:54:25]: 그래서 저는 우리가 아직 이 초기 단계에 있다고 생각합니다. 하지만 제가 가장 성공적이라고 본 것은 이 모델들의 강점과 약점을 중심으로 코드베이스(code bases)를 실제로 구축한다는 것입니다. 그래서 그것이 의미하는 바는 더 독립적인(self-contained) 단위가 매우 빠르게 실행되는 매우 좋은 단위 테스트(unit tests)를 가지고 있고, 이 모듈(module)이 무엇을 위한 것인지 설명하는 좋은 문서(documentation)를 가지고 있다는 것입니다. 그리고 당신이 그렇게 하고 세부 사항을 모델에 맡기면, 그것은 정말 잘 작동합니다. 그리고 나서 이러한 것들이 어떻게 구성되는지 생각하고, 당신이 가진 종속성(dependencies)에 대해 생각하는지 확인하는 것입니다. 이러한 깔끔한 AI 최적화 모듈(AI optimized modules)은 다른 AI 최적화 모듈(AI optimized modules)에 의해서만 의존될 수 있습니다. 그러면 당신은 실제로 최적화된 전체 시스템을 얻게 됩니다. 그래서 저는 우리가 아직 가능한 것의 표면을 긁고 있을 뿐이라고 생각합니다. 그리고, 아시다시피, 모델은 너무나 빠르게 발전하고 있어서 6개월 후 모델의 약점을 중심으로 작업하는 것이 무엇을 의미하는지는, 저는 그 약점들이 엄청나게 줄어들 것이라고 생각합니다. 그래서 당신은 오늘날 존재하는 것에 과적합(overfitting)하기 위해 모든 시간을 보낼 필요는 없습니다. 하지만 저는 많은 잠재력(potential)이 있다고 생각합니다. 네. 이 특정 순간에 빠르게 움직일 수 있는 말이죠.

**AGI 시대 엔지니어의 가치(The Value of Engineers in the Age of AGI)**

스윅스(Swyx) [01:55:27]: 제가 매우 궁금한 질문 중 하나는 엔지니어의 가치입니다. 시간이 지남에 따라 증가하고 있습니다. 시간이 지남에 따라 증가하고 있습니다. 음, 제 말은, 우리 작업의 일부가 자동화되고 있다는 것도 있습니다. 그리고 저는 분명히 매우 높은 계약 보너스(signing bonuses)가 있다고 생각합니다. 우리 업계 역사상 본 적이 없는 것보다 더 높습니다. 가치 있는 것은 엔지니어입니까, 아니면 그들을 가능하게 하는 시스템입니까? 아시다시피, 저는 둘 다라고 생각하지만, 사람들은 엔지니어에게 많은 돈을 지불하고 있습니다.
그렉(Greg) [01:55:53]: 제 말은, 결국 새로운 것은 우리가 기술을 생산하고 있다는 것입니다. 이 모델들은 인류가 만들어낸 가장 유용한 도구(tools)입니다. 그렇죠. 그리고 그 기반에는 인류가 지금까지 만들어낸 가장 큰 기계들을 구축하고 있습니다. 그렇죠. 마치 어느 시점에서 이러한 데이터 센터(data centers)에 들어가는 돈은 추상화(abstraction)가 되기 시작합니다. 그렇죠. 500억 달러는 무엇입니까? 1000억 달러는 무엇입니까? 그것이 무엇인지 어떻게 내면화할 수 있습니까? 저는 그것이 거의 인간 이해의 규모를 넘어선다고 생각합니다. 우리가 국가로서, 사회로서, 세계로서 집단적으로 지금 겪고 있는 엔지니어링 프로젝트(engineering project) 말입니다. 그렇죠. 마치 뉴딜(New Deal)과 같은 프로젝트는 비교할 수 없을 정도로 작습니다. 아폴로 프로그램(Apollo program)은 우리가 지금 하고 있는 일에 비하면 비교할 수 없을 정도로 작습니다. 그리고 여러 면에서 그래야 합니다. 그렇죠. 이 기술의 경제적 수익(economic return)은 매우 큽니다. 하지만 더 중요한 것은 우리가 새로운 경제로 이동하는 방식입니다. 그렇죠. AI 통합 경제(AI integrated economy), AI 기반 경제(AI powered economy). 그리고 이것이 궁극적으로 우리의 사명(mission)에 관한 것입니다. 그렇죠. 마치 우리는 수평선에서 이 변화를 보고 있습니다. 우리는 돕고 싶습니다. 우리는 그것이 모든 사람을 고양시키는 것이 되도록 돕고 싶습니다. 그렇죠. 그것은 놀라운 기회(amazing opportunity)이며, 인류 역사상 거의 유일합니다. 그리고 우리는 모두 운이 좋습니다. 그렇죠. 이 시점에 있고 어떤 방식으로든 참여할 수 있다는 것이 말입니다. 그것이 저에게는 인류 규모에서 일어나고 있는 이 큰 변화에 대해 정말로 생각하게 하는 배경입니다. 그리고 때로는 거의 인지 부조화(cognitive dissonance)를 느낍니다. 낮은 수준의 CUDA 교착 상태(CUDA deadlock)를 디버깅(debugging)하거나 보라색 그라데이션(purple gradient)에 대해 걱정하고 있을 때 말입니다. 그리고 당신은 이것이 우리가 정말로 이야기하고 있는 인류의 미래라는 것을 깨닫습니다. 그래서 엔지니어(engineers)와 누가 어떤 회사에 있는지 등 이러한 것들에 대해 생각할 때, 이러한 것들이 중요합니다. 그렇죠. 마치 어떤 개인이 아니라 팀에 관한 것입니다. 그렇죠. 하지만 어떤 하나의 제품이나 어떤 하나의 시스템에 관한 것도 아닙니다. 그것은 정말로 우리가 함께 구축하고 있는 전반적인 사회, 전반적인 경제에 관한 것입니다. 그래서 저는 때때로 한 발 물러서서 큰 규모에 대해 생각합니다. 하지만 당신은 또한 미시적 규모에 대해서도 생각해야 합니다. 사람들이 행복한가? 그렇죠. 사람들이 사명(mission)에 연결되어 있다고 느끼는가? 그들이 하는 일이 중요하다고 느끼는가? 그리고 그러한 것들이 실제로 가장 중요한 것임이 밝혀졌습니다. 그래서 헤드라인을 장식하는 것이 반드시 실제로 중요한 것은 아닙니다. 그것은 실제로 사람들을 가장 많이 움직이는 것입니다. 하지만 그것은 분명히 사람들이 이 기술의 잠재력(potential)으로 보는 경제적 현실의 반영과 같습니다.
스윅스(Swyx) [01:58:21]: 이것은 노암(Noam)이 다중 에이전트 팀(multi-agents team)에 대해 말했던 것과 어느 정도 연결됩니다. 인간의 개별 지능(individual intelligences)은 개별적으로 할 수 있는 일이 그리 많지 않습니다. 하지만 문명으로서 우리는 달에 가고, 도시를 건설하고 AI(인공지능)를 건설할 수 있습니다. 그리고 함께라면, 저는 우리가 개별적으로 할 수 있는 것보다 훨씬 더 많은 일을 할 수 있다고 생각합니다.
그렉(Greg) [01:58:40]: 우리는 함께 놀라운 일들을 할 수 있습니다.
스윅스(Swyx) [01:58:41]: 의심할 여지 없이요.

**새로운 관점: AI 시대, 엔지니어의 가치 변화와 역할 재정의**

AGI(범용 인공지능) 시대의 도래는 엔지니어의 가치와 역할에 대한 근본적인 질문을 던집니다. 그렉(Greg)이 강조했듯이, AI는 인류가 만들어낸 가장 유용한 도구이며, 이를 구축하는 과정은 전례 없는 규모의 엔지니어링 프로젝트입니다. AI가 많은 코딩 작업을 자동화할 수 있게 되면서, 엔지니어의 역할은 단순한 코드 작성자를 넘어선 새로운 형태로 진화하고 있습니다.

AI 시대에 엔지니어의 가치는 다음과 같은 측면에서 재정의될 것입니다:
1.  **문제 해결 및 추상적 사고 능력:** AI는 주어진 문제를 해결하는 데 능숙하지만, 복잡하고 정의되지 않은 문제를 식별하고, 추상적인 개념을 설계하며, 혁신적인 해결책을 구상하는 능력은 여전히 인간 엔지니어의 고유한 강점입니다. 엔지니어는 AI가 해결할 수 있는 문제를 명확히 정의하고, AI가 도달하기 어려운 영역에서 창의적인 돌파구를 마련하는 데 집중할 것입니다.
2.  **인간-AI 협업 및 오케스트레이션:** AI 시스템을 설계하고, 배포하며, 관리하는 능력은 더욱 중요해집니다. 엔지니어는 다양한 AI 모델과 도구를 통합하고, 이들이 효율적이고 안전하게 작동하도록 조율하며, 인간 개발자와 AI 에이전트 간의 효과적인 협업 프레임워크를 구축하는 역할을 수행할 것입니다.
3.  **윤리적 책임 및 사회적 영향 고려:** AI 기술이 사회에 미치는 영향이 커질수록, 엔지니어는 기술적 전문성뿐만 아니라 윤리적 책임감과 사회적 통찰력을 갖춰야 합니다. AI 시스템의 잠재적 위험을 예측하고, 공정하고 투명하며 책임감 있는 AI를 개발하는 것이 엔지니어의 중요한 역할이 됩니다.
4.  **지속적인 학습 및 적응:** AI 기술의 발전 속도는 매우 빠르므로, 엔지니어는 새로운 도구와 패러다임에 지속적으로 학습하고 적응하는 능력을 갖춰야 합니다. 이는 평생 학습의 중요성을 더욱 부각시키며, 변화에 대한 유연한 태도가 핵심 역량이 됩니다.

궁극적으로, AGI 시대의 엔지니어는 단순히 기술을 구현하는 것을 넘어, AI를 통해 인류의 삶을 개선하고, 새로운 가치를 창출하며, 사회 전체를 발전시키는 데 기여하는 '문제 해결자'이자 '혁신가'로서의 역할을 수행하게 될 것입니다. 이는 엔지니어링 분야의 위상을 더욱 높이고, 개인에게는 더 큰 의미와 보람을 가져다줄 것입니다.

**AI 연구의 현재 상태 및 연구소 다양성(Current state of AI research and lab diversity)**

알레시오(Alessio) [01:58:42]: AI 연구의 현재 상태에 대해 어떻게 생각하십니까? 모든 사람이 정말로 같은 일을 하고 있습니까? 모든 연구소가 결국 우리를 올바른 방향으로 수렴하게 도울 다른 접근 방식을 가지고 있다고 생각하십니까? 아니면 이제 돈이 너무 커져서 당신이 작동할 것이라고 생각하는 일을 해야 하기 때문입니까?
그렉(Greg) [01:58:58]: 저는 이 분야에 놀랍도록 많은 다양성(diversity)이 있다고 생각합니다. 때로는 수렴 진화(convergent evolution)처럼 느껴질 수도 있지만, 다른 연구소의 사람들과 실제로 이야기해보면 사람들이 다른 관점을 가지고 있다는 것을 실제로 깨닫게 됩니다. OpenAI에서 우리가 초기에 내린 결정 중 하나는 정말로 다른 것을 하고 싶었다는 것입니다. 우리는 정말로 생각하는 방식이 일치하는 사람들을 원했습니다. 그렇죠? 왜냐하면 오랫동안 박사 학위(PhD)를 추구해온 사람들에게는, 즉 자신만의 연구 비전(research vision)을 가진 사람들에게는 무엇을 해야 할지 말할 수 없기 때문입니다. 그래서 같은 방향으로 나아갈 사람들을 원한다면, 그 사람들을 선택해야 한다는 것을 의미합니다. 그리고 그것이 우리가 OpenAI에서 내린 가장 중요했던 초기 결정 중 하나였고, 우리가 이룬 것들을 달성하는 데 도움이 되었습니다. 그래서 저는 그것이 당신이 필연적으로 다른 견해를 가지고 있다는 것을 의미한다고 생각합니다. 당신이 선택할 수 있는 다른 벡터(vectors)가 있습니다. 그리고 당신은 그것을 다른 연구소의 취향과 그들이 무엇에 집중하고 무엇을 생산하는지에서 실제로 볼 수 있습니다. 그리고 OpenAI에서는 다음 단계로 나아갈 연구를 어떻게 할 것인지에 매우 집중해왔다고 생각합니다. 그리고 GPT-5와 같은 것에 대해서도, 아시다시피, 우리는 '좋아, 코딩 측면에서 우리가 가진 문제에 대한 피드백(feedback)을 계속해서 처리하자'와 같은 많은 압력을 받았습니다. 그리고 당신은 그 고된 작업을 추구하고 어딘가에 도달할 수 있습니다. 하지만 때로는 한 발 물러서서 '이것을 어떻게 할까?'라고 생각해야 합니다. 그리고 다음 단계 함수(step function)를 어떻게 할 것인지, 다음 패러다임 전환(paradigm shift)을 어떻게 할 것인지 생각해야 합니다. 그리고 추론 패러다임(reasoning paradigm)은 우리가 그것을 매우 성공적으로 수행했던 좋은 예시입니다. 그리고 우리는 OpenAI의 과정에서 그것을 여러 번 해왔고 계속해서 그렇게 할 것입니다. 그래서 저는 돌파구(breakthroughs)가 여전히 만들어져야 한다고 생각합니다. 그리고 멀티모달(multimodal)과 다양한 생성 방식 등 너무나 많은 다양성(diversity)이 있어서, 저는 연구 분야가 그 어느 때보다 풍부하다고 생각합니다.
스윅스(Swyx) [01:00:39]: 네. 그리고 잊지 말아야 할 것은, 그것은 주류 연구(mainline research)와 같다는 것입니다. 음성(voice)도 있고, 이미지 생성(image generation), 비디오 생성(video generation)도 있습니다. 네. 네.
알레시오(Alessio) [01:00:47]: 이러한 것들을 잊기 쉽습니다. 스튜디오 지브리(Studio Ghibli)를 기억하십니까? 그것은 세계에서 가장 큰 것이었습니다. 정확합니다.
그렉(Greg) [01:00:51]: 그리고 그것은 놀랍습니다. 놀랍습니다. 그리고 그것은, 참고로, 소수의 사람들이 여러 해 동안 그 문제에 정말 집중했던 종류의 것입니다. 그리고 그것이 OpenAI의 핵심 정신(core ethos)이라고 생각합니다. 정말로 중요한 문제에 대해 장기적인 베팅(long-term bets)을 하고, 응집력 있는 전체(cohesive whole)를 이루는 방향으로 나아가는 것입니다.

**OpenAI의 우선순위 및 중점 분야(OpenAI’s Prioritization and Focus Areas)**

알레시오(Alessio) [01:01:11]: 외부에서는 당신이 무엇에 집중하고 있는지 파악하기가 어렵습니다. 아시다시피, 이미지젠(Imagen)은 거의 갑자기 나타났고, 그것은 훌륭했습니다. 많은 채택을 얻었습니다. 사람들은 당신이 어떻게 우선순위를 정하는지, 그리고 사람들이 무엇을 탐색하고 구축해야 하는지, 그리고 당신이 개선하기를 기다려야 하는지에 대해 어떻게 생각해야 할까요?
그렉(Greg) [01:01:27]: 음, 이 분야에는 엄청난 가능성 공간(possibility space)이 있습니다. 그렇죠? 왜냐하면 신경망(neural nets), 딥러닝(deep learning)은 사실상 모든 종류의 데이터(data), 모든 종류의 영역(domain)에 적용 가능하기 때문입니다. 그리고 우리는 모든 것을 할 수 없습니다. 핵심 추론 패러다임(core reasoning paradigm)은 분명히 우리가 계속 추진할 것입니다. 멀티모달 음성(Multimodal voice), 이미지 생성(image generation), 비디오 생성(video generation)과 같은 영역도 우리가 매우 중요하게 생각하고 모두 함께 어우러지는 것들입니다. 하지만 우리가 핵심 프로그램의 일부로서 어떻게 우선순위를 정해야 할지 파악하기 어려운 영역도 있었습니다. 그렇죠? 예를 들어 2018년 로봇 공학(robotics)이 그랬던 시기가 있었습니다. 우리는 훌륭한 결과를 얻었지만, 실제로 '그것은 작동하지 않을 것이다'라고 깨달았습니다. 우리가 다른 영역에서 훨씬 더 빠르게 움직일 수 있다는 것을 말입니다. 그렇죠? 실제로 로봇 손(robot hand)이 루빅스 큐브(Rubik's cube)를 푸는 훌륭한 결과를 얻었습니다. 그리고 그 팀은 이 로봇 손(robot hand)이 20시간 동안 작동하면 힘줄이 끊어진다는 사실 때문에 병목 현상(bottleneck)을 겪었습니다. 그래서 기계 엔지니어(mechanical engineer)가 와서 고쳐야 했습니다. 그리고 그 팀은 깃허브 코파일럿(GitHub Copilot)이 된 것을 만들러 갔는데, 그것은 분명히 놀라운 업적이고 진정한 성과입니다. 그리고 그들은 물리적인 영역보다 디지털 영역에서 훨씬 더 빠르게 움직일 수 있었습니다. 그래서 저는 우리가 정말로 노력한다고 생각합니다. 아시다시피, 우리가 아무리 많은 사람을 고용하고 아무리 많은 GPU(그래픽 처리 장치)를 얻더라도, 우리는 제한된 대역폭(bandwidth)을 가지고 있습니다. 그렇죠? 우리는, 아시다시피, 하나의 회사, 하나의 연구소로서, 가능한 한 일관된 하나의 문제에 집중하고 있습니다. 그래서 저는 우리가 하는 일들을 살펴볼 수 있고, 때로는 파생물(offshoots)을 만들기도 하고, 때로는 그것이 핵심 프로그램(core program)의 일부가 되기도 할 것이라고 생각합니다. 하지만 모든 사람에게는 너무나 많은 가능성 공간(possibility space)이 있습니다. 놀랍습니다.

**새로운 관점: AI 연구의 융합과 초학제적 접근의 중요성**

AI 연구 분야는 그 어느 때보다 풍부하고 다양하지만, 동시에 '수렴 진화(convergent evolution)'처럼 보이는 현상도 나타납니다. 그렉(Greg)이 지적했듯이, 각 연구소는 고유한 관점과 우선순위를 가지고 있지만, 결국 AGI(범용 인공지능)라는 궁극적인 목표를 향해 나아갑니다. OpenAI의 경우, '추론 패러다임(reasoning paradigm)'과 같은 핵심 연구에 집중하면서도, 멀티모달(multimodal) AI, 이미지 및 비디오 생성과 같은 다양한 분야에서 혁신적인 성과를 내고 있습니다.

이러한 AI 연구의 발전은 이제 기술적 측면을 넘어 '초학제적 접근(interdisciplinary approach)'의 중요성을 강조합니다. AI는 단순한 컴퓨터 과학 분야가 아니라, 언어학, 인지 과학, 철학, 윤리학, 사회학 등 다양한 학문 분야와 융합될 때 진정한 잠재력을 발휘할 수 있습니다. 예를 들어, AI의 추론 능력을 향상시키기 위해서는 인간의 인지 과정에 대한 이해가 필수적이며, AI의 사회적 영향을 최소화하기 위해서는 윤리적, 사회적 관점에서의 깊이 있는 논의가 필요합니다.

미래의 AI 연구는 다음과 같은 방향으로 진화할 것입니다:
1.  **AI + 사회 과학:** AI가 사회적 편향을 학습하지 않도록 데이터셋을 구성하고, AI의 의사 결정 과정을 투명하게 설명하며, AI가 사회적 공정성과 정의를 증진하는 데 기여하도록 연구합니다.
2.  **AI + 인문학:** AI가 인간의 창의성을 증강하고, 새로운 예술 형태를 창출하며, 인간의 언어와 문화를 깊이 이해하도록 연구합니다. 이는 AI가 단순한 정보 처리기를 넘어, 인간의 감성과 가치를 이해하는 동반자로 진화하는 데 기여합니다.
3.  **AI + 생물학/의학:** DNA 신경망(DNA neural networks) 연구에서 보듯이, AI는 생체 시스템을 모델링하고, 질병을 진단하며, 새로운 치료법을 개발하는 데 혁신적인 역할을 할 수 있습니다.

결론적으로, AI 연구는 다양한 분야의 지식과 관점을 통합할 때 가장 큰 돌파구를 마련할 수 있습니다. 각 연구소가 고유한 강점을 가지고 서로 협력하며, 인류 전체의 이익을 위한 AGI를 향해 나아가는 것이 중요합니다.

**창업자를 위한 조언: 아직 늦지 않았다(Advice for Founders: It's Not Too Late)**

스윅스(Swyx) [01:03:05]: 이제 마무리할 시간입니다. OpenAI에서 벗어나 몇 가지 작은 번개 질문을 하고 싶습니다. 이 질문은 알레시오(Alessio)에게서 받은 것이니 당신이 받아주세요.
알레시오(Alessio) [01:03:15]: 당신이 OpenAI를 시작했을 때, AI 연구소(AI lab)를 시작하기에는 너무 늦었다고 거의 믿었습니다. 오늘날 사람들이 너무 늦었다고 생각하지만 실제로 해야 할 일은 무엇이라고 생각하십니까?
그렉(Greg) [01:03:26]: 음, 이 모델들을 실제 세계 응용 분야(real world application domains)에 연결하는 것이 극도로 가치 있다는 것은 꽤 분명합니다. 그리고 때로는 모든 아이디어가 이미 선점된 것처럼 느껴질 수도 있지만, 경제는 너무나 크고, 인간 노력의 모든 응용 분야는 너무나 큽니다. 그래서 우리가 만들어낸 이 놀라운 지능(intelligences)을 최대한 활용하는 방법을 사람들이 정말로 생각하는 것이 가치 있고 정말 중요합니다. 그리고 그 중 많은 부분이, 아시다시피, 헬스케어(healthcare)와 같은 분야에서는 모든 이해관계자(stakeholders)에 대해 정말로 생각해야 합니다. 그렇죠? 시스템이 오늘날 어떻게 작동하는지, 그리고 이러한 모델들을 어떻게 잘 통합할지 생각해야 합니다. 그리고 저는 이 모든 영역에서 아직 발견되지 않은 많은 결실이 있다고 생각합니다. '어떻게 선택받을까?'라고 생각해야 합니다. 그래서 GPT-래퍼(GPT-Rapper)를 작성해보세요. 네. 해보세요. 하지만 제가 조언하고 싶은 것은 당신이 생산하는 가치가 단순히 더 나은 래퍼(wrapper)를 작성하는 것만이 아닌 영역에 대해 정말로 생각하는 것입니다. 그것은 정말로 영역을 이해하고 전문 지식(expertise)과 관계(relationships) 등 이 모든 것을 구축하는 것에 관한 것입니다.

**미래 전망 및 마무리 생각(Future outlook and closing thoughts)**

스윅스(Swyx) [01:04:20]: 당신은 가끔 엔젤 투자(angel invest)를 합니다. 무엇이 당신의 관심을 끕니까?
그렉(Greg) [01:04:24]: 사실 저는 몇 년 동안 엔젤 투자(angel invest)를 하지 않았습니다. 아, 그렇군요. 네, 네. 그냥 모든 것이 OpenAI에 대한 방해 요소이고, 저는 레이저처럼 집중하고 싶습니다. 알겠습니다.

**2045년 타임캡슐: 컴퓨트(Compute)와 풍요의 미래(Time Capsule to 2045: Future of Compute and Abundance)**

스윅스(Swyx) [01:04:33]: 좋습니다. 다음 여행 질문으로 넘어가겠습니다. 2045년의 그렉에게 보내고 싶은 포스트잇 메모는 무엇입니까? 그러면 당신은 58세가 될 것입니다. 다이슨 스피어(Dyson sphere)는 어떻습니까? 다이슨 스피어(Dyson sphere)는 어떻습니까? 이봐요, 당신이 그것을 만드는 데 필요한 것에 대한 수학을 실제로 해봤는지 모르겠습니다만.
그렉(Greg) [01:04:46]: 네, 더 진지하게 말하자면, 지금 상황이 얼마나 빠르게 움직이는지 고려할 때 2045년은 상상하기가 너무 어렵습니다. 그래서 저는 놀라운 풍요(abundance)의 세상이 되기를 바랍니다. 그리고 그 시점에는 우리가 정말로 다행성(multi-planetary)이 되어야 하고, 거의 상상할 수 있는 모든 공상 과학(sci-fi) 꿈이 가능성을 부인하기 어렵다고 생각합니다. 물론 특정 속도로 원자를 움직이는 물리적 능력에 의해 제한되는 것들을 제외하고 말이죠. 하지만 네, 저는 그 세상이 2025년에 앉아 있는 지금만큼 놀랍기를 바랍니다.
스윅스(Swyx) [01:05:17]: 풍요(abundance)가 있다면 UBI(기본 소득)가 필요할까요? 진정한 풍요(true abundance)는 UBI(기본 소득)가 필요 없다는 것을 의미하니까요.
그렉(Greg) [01:05:22]: 음, 저는 우선, OpenAI 초기에 AGI(범용 인공지능) 이후에 돈이 의미가 있을지에 대한 많은 논쟁이 있었다고 생각합니다. 그렇죠? 그리고 정말 불분명합니다. 그렇죠? 컴퓨터와 대화하기만 하면 원하는 모든 것을 생산할 수 있다면. 당신은 어떤 물리적 재화(physical good)를 원하고, 어떤 종류의 물질적 품목(material item)을 원하며, 그것이 즉시, 효과적으로 무료로 제조될 수 있다면. 돈은 무엇을 의미합니까? 그리고 반대로, 저는 매우 분명하게 수요가 많을 자원 하나가 있다고 생각합니다. 바로 컴퓨트(compute)입니다. 이미 그렇습니다. 우리는 OpenAI 내에서 이것을 봅니다. 가장 많은 컴퓨트(compute)에 접근할 수 있는 연구원들이 가장 큰 프로젝트를 수행하고 더 많은 일을 할 수 있습니다. 그리고 미래에는 사람들이 컴퓨트(compute)에 어떻게 접근할 것인지 생각하는 것이 중요하다고 생각합니다. 당신이 관심을 갖는 어떤 작업이든, 어떤 응용 분야이든 더 많은 컴퓨트(compute)를 가질수록 더 많이 해결될 것이고, 더 많은 일이 일어날 것입니다. 그리고 컴퓨트 분포(compute distribution)가 어떻게 보일지에 대한 질문은 매우 중요할 것이라고 생각합니다. 그래서 저는 '만약 당신이 일을 하지 않는다면, 살아남을 수 있을까?'라는 질문에 대한 답은 '네'일 것이라고 생각합니다. 당신은 충분한 물질적 필요(material needs)를 충족시킬 것입니다. 하지만 '더 많은 일을 할 수 있을까?'라는 질문은, 당신이 원하는 만큼의 영화를 생성하는 것뿐만 아니라, 놀라운 세부 사항과 모든 추가적인 화려함을 가지고, 당신에게 특별히 가장 좋은 것이 무엇인지에 대해 주관적인 경험(subjective experience)으로 100년 동안 매우 열심히 생각하게 할 수 있을까? 저는 더 많은 컴퓨트(compute)에 대한 더 많은 수익이 항상 있을 것이라고 생각합니다. 그래서 우리는 그 사회가 어떻게 설계될지에 대해 정말 신중하게 생각해야 할 것입니다.
스윅스(Swyx) [01:06:59]: 그리고 저는 이것이 항상 더 어렵다고 생각합니다. 참고로요. 네. 그래서, 네, 그것이 질문입니다. 아니요, 2005년의 그렉에게 메모, 포스트잇 메모를 보내는 약간의 변명입니다. 18세의 그렉에게요. 와. 시간 여행을 할 수 있군요.

**새로운 관점: AI 시대의 경제 구조 변화와 컴퓨팅 자원 분배의 중요성**

그렉(Greg)의 2045년 타임캡슐 메시지는 AI 시대에 '풍요(abundance)'가 실현될 가능성과 함께, 새로운 경제 구조의 핵심 자원으로서 '컴퓨트(compute)'의 중요성을 강조합니다. AGI(범용 인공지능)가 보편화되어 원하는 모든 것을 즉시, 거의 무료로 생산할 수 있는 세상이 온다면, 전통적인 '돈(money)'의 의미는 퇴색될 수 있습니다. 그러나 컴퓨팅 자원은 여전히 희소하고 가치 있는 자원으로 남을 것이며, 이에 대한 접근성은 사회적 불평등의 새로운 원인이 될 수 있습니다.

AI 시대의 경제 구조 변화와 컴퓨팅 자원 분배의 중요성은 다음과 같은 측면에서 심도 있게 논의되어야 합니다:
1.  **컴퓨트 자원의 전략적 가치:** 미래에는 컴퓨트 자원이 석유나 희토류처럼 국가 및 기업의 전략적 자산이 될 것입니다. 컴퓨트 자원에 대한 통제력은 기술 혁신, 경제 성장, 그리고 국가 안보에 결정적인 영향을 미칠 것입니다.
2.  **컴퓨트 접근성의 민주화:** 컴퓨트 자원이 소수에 의해 독점된다면, AI가 가져올 풍요는 특정 계층에게만 집중될 수 있습니다. 모든 개인이 충분한 컴퓨트 자원에 접근하여 AI를 활용하고 자신의 아이디어를 실현할 수 있도록 하는 정책적 노력이 필요합니다. 이는 '컴퓨트 기본 소득(Universal Basic Compute)'과 같은 새로운 개념의 등장을 촉진할 수 있습니다.
3.  **AI 기반 노동 시장의 재편:** AI가 많은 일자리를 자동화함에 따라, 인간은 더 이상 생존을 위해 일할 필요가 없을 수도 있습니다. 그러나 '더 많은 일을 할 수 있을까?'라는 질문은 여전히 유효하며, 인간의 창의성, 문제 해결 능력, 그리고 AI를 활용하는 능력이 새로운 형태의 가치 창출로 이어질 것입니다.
4.  **글로벌 컴퓨트 거버넌스:** 컴퓨트 자원의 글로벌 분배와 사용에 대한 국제적인 협력과 거버넌스 체계가 필요합니다. 이는 컴퓨트 자원의 효율적인 활용을 보장하고, AI 기술이 전 세계적으로 공정하고 지속 가능한 방식으로 발전하도록 돕는 데 중요합니다.

결론적으로, AI가 가져올 풍요의 시대는 인류에게 전례 없는 기회를 제공하지만, 동시에 컴퓨팅 자원의 분배와 새로운 경제 시스템 설계에 대한 심도 있는 고민을 요구합니다. 이는 기술 발전뿐만 아니라 사회적, 정치적, 윤리적 논의가 함께 이루어져야 할 복합적인 과제입니다.

**2005년 타임캡슐: 더 많은 문제가 나타날 것이다(Time Capsule to 2005: More Problems Will Emerge)**

그렉(Greg) [01:07:07]: 얼마나 긴 메모를 쓸 수 있을까요?
스윅스(Swyx) [01:07:09]: 포스트잇 메모처럼요. 자신에게 약간의 조언을 해주세요. 그리고 분명히 이것은 다른 모든 사람들을 위한 대리인입니다. 그렇죠.
그렉(Greg) [01:07:15]: 하지만 아시다시피, 제가 가장 놀랐던 한 가지는 문제의 풍요(abundance of problem)가 시간이 지남에 따라 증가한다는 것입니다. 좋습니다. 왜냐하면 저는 1999년, 2000년에 실리콘 밸리(Silicon Valley)에 대해 읽으면서 '기회를 놓쳤다. 너무 늦게 태어났다'고 느꼈던 것을 기억합니다. 매우 흔한 일이죠. 정확합니다. 그렇죠? 저는 마치 '내가 일을 할 준비가 될 때쯤에는 모든 멋진 문제들이 해결되어 있을 것이다. 남은 것이 없을 것이다'라고 느꼈습니다. 그것은 완전히 틀린 것으로 밝혀졌습니다. 그렇죠? 지금은 기술 분야에서, 그리고 세상에서 실제로 활동하기에 가장 흥미로운 시기입니다. 왜냐하면 우리는 모든 응용 분야, 인간 노력의 모든 분야를 고양시키고 혁신할 놀라운 도구(tool)를 가지고 있기 때문입니다. 그리고 저는 그것이 흥분할 만한 일이고, 우리가 적용할 수 있는 것이며, 물론 우리가 해결해야 할 도전 과제(challenges)가 있지만, 이 놀라운 결과를 달성하기 위한 목적이라는 사실이 중요하다고 생각합니다. 그래서 저는 문제의 가용성(problem availability)이 시간이 지남에 따라 줄어들기보다는 증가할 것이라는 메시지가 제가 그 순간에 내면화했으면 좋았을 핵심이라고 생각합니다.
알레시오(Alessio) [01:08:17]: 놀랍습니다. 그렉, 함께 해주셔서 정말 감사합니다. 두 분 모두 감사합니다.
그렉(Greg) [01:08:21]: 정말 감사합니다. 여기 오게 되어 좋았습니다.

1 2025년 말 예상 매출 90억 달러 이상이므로 이는 현재 배수의 20배이며, 미친 수준은 아닙니다.
2 이것은 농담입니다.