**GPT-5 코덱스 최신 소식: 2025년 개발자 생산성 및 AI 에이전트의 발전**

이 글은 GPT-5 관련 보도 중 바이브(vibes), 부트스트래핑(bootstrapping), 비전(vision), 그리고 라우터(Router)에 대한 저희의 이전 논의를 바탕으로 합니다. 지난 한 해 동안 AI 엔지니어링 분야는 눈부신 발전을 거듭했으며, 특히 개발자 생산성과 SWE 에이전트(SWE agents)의 역량 강화에 대한 관심이 어느 때보다 뜨겁습니다. 2024년 11월 뉴욕에서 성황리에 막을 내린 AI 엔지니어 코드 서밋(AI Engineer CODE Summit)은 이러한 트렌드를 잘 보여주었으며, 올해 역시 더욱 심화된 논의와 혁신이 기대됩니다.

GPT-5-코덱스(GPT-5-Codex)는 이제 출시 초기 단계를 넘어, 코딩 에이전트(Coding Agents) 분야에서 새로운 표준을 제시하고 있습니다. 지난 1년여 동안, Anthropic은 클로드(Claude) 시리즈를 통해 코딩 활용 사례(coding usecases)에서 상당한 존재감을 드러냈으며, 이는 시장에 활발한 경쟁을 불러일으켰습니다. OpenAI는 2021년 오리지널 코덱스(Codex)와 깃허브 코파일럿(GitHub Copilot)을 통해 AI 코딩 도구(AI coding tool)의 선구자 역할을 했으며, 이는 수많은 개발자들에게 혁신적인 생산성 향상을 제공했습니다. GPT-5-코덱스(GPT-5-Codex)의 SWE-벤치(SWE-bench) 점수 74.5% (전체 500개)는 GPT-5 사고(thinking) 성능 74.9% (477개 작업 하위 집합)와 거의 비슷하며, 이는 초기부터 뛰어난 추론 능력을 보여주었습니다. 그렇다면 GPT-5 인식(sentiment)에 이러한 큰 변화가 생긴 원인은 무엇일까요? 우선, 코덱스 팀이 엄청난 성과를 내고 있습니다.

**요인 1: 다양한 얼굴, 하나의 에이전트(Many Faces, One Agent)**
OpenAI 내부에서는 에이전트형 소프트웨어 엔지니어(agentic software engineer) 개발에 대한 목표가 꾸준히 추진되어 왔습니다. 이는 정확히 무엇을 의미하는지, 어떻게 구체화(substantiate)하고, 이 문제에 투입할 수 있는 모든 기회와 모든 종류의 컴퓨트(compute)를 어떻게 한데 모을지 알아내는 것이 OpenAI의 많은 사람들에게 큰 과업(undertaking)으로 남아있습니다. 원래의 A-SWE 에이전트형 하네스(A-SWE agentic harness)는 10X라고 불렸고 터미널(terminal)에서 작동했지만, 현재는 코덱스 CLI(Codex CLI)와 "챗GPT 코덱스(ChatGPT Codex)" (이제는 코덱스 클라우드(Codex Cloud)로 발전), 그리고 IDE 확장 프로그램(IDE extension) (출시 초기 2.5주 만에 80만 건 설치를 넘어 현재는 수백만 건 이상) 및 깃허브 코드 리뷰 봇(GitHub code review bot)에 이르기까지, 모든 개발 환경의 요구 사항을 충족하는 완벽한 인터페이스(interfaces) 세트가 마련되었습니다. 이러한 코덱스 생태계(Codex universe)는 다양한 트레이드오프(tradeoffs)를 고려하여 설계되었습니다. 특히 @codex 코드 리뷰 봇(code review bot)은 엄격한 범위 설정(tight scoping) 덕분에 매우 높은 유용성(utility)을 입증했습니다. 이 봇은 검토해야 할 코드 양 증가로 인한 팀원들의 병목 현상(bottleneck)을 해소하는 데 핵심적인 역할을 하며, PR(Pull Request)을 깊이 분석하고, 구현하려던 계약(contract)과 의도(intention)에 대해 깊이 생각한 다음, 코드를 보고 그 의도가 코드와 일치하는지 검증(validate)하여 사람이 놓칠 수 있는 문제들을 실제로 제기할 수 있습니다. OpenAI 내부에서 성공적으로 출시된 이후, 이 봇은 개발 프로세스를 엄청나게 가속화(accelerated)시켰으며, 이제는 많은 개발팀에서 필수적인 안전망(safety net)으로 자리 잡았습니다.

**요인 2: 더 나은 후속 훈련 품질(Better Post-Training Qualities)**
물론 데이터셋(datasets)은 볼 수 없지만, OpenAI가 항상 강조하는 또 다른 점은 연구와 제품의 긴밀한 통합(tight integration of research and product)입니다. 현재까지 관찰된 GPT-5의 주요 특징 중 일부는 다음과 같습니다:
**가변적인 끈기(Variable Grit)**
티보 소티오(Thibault Sottiaux)가 언급했듯이, "이 모델이 보여주는 것 중 하나는 훨씬 더 오랫동안 지속하고 복잡한 리팩토링(refactoring) 작업에 필요한 끈기(grit)를 실제로 발휘하는 능력입니다. 하지만 동시에 간단한 작업의 경우 훨씬 더 빠르게 반응하며 많은 생각 없이 답변할 수 있습니다. 그래서 코드에 대해 질문하고, 변경하거나 더 잘 이해해야 할 코드 조각을 찾고, 계획을 세울 수 있는 훌륭한 협력자(collaborative)와 같습니다. 하지만 동시에 일단 어떤 작업을 맡기면, 매우 오랜 시간 동안 작동할 것입니다. 내부적으로는 매우 복잡한 리팩토링(refactoring) 작업에 최대 7시간까지 작동하는 것을 보았습니다. 다른 모델에서는 이전에 그런 것을 본 적이 없습니다. 그리고 우리는 코드 품질에도 엄청나게 노력했습니다. 그리고 GPT-5를 코덱스(Codex) 내에서 사람들이 사용하는 용도에 맞춰 정말 최적화되어 있습니다. 신중하게 적용된 이러한 끈기(tenacity judiciously applied)가 GPT-5-코덱스(GPT-5-Codex)를 가장 어려운 문제에만 최적화하고 덜 똑똑한 모델(dumber models)을 위한 모델 전환기(model switcher)를 요구하는 것이 아니라, 훨씬 더 유용한 전천후 에이전트형 코딩 모델(agentic coding model)로 만듭니다." GPT-5의 내부 라우터(router)는 이러한 유연성을 더욱 강화하며, 작업의 복잡성에 따라 최적의 모델 경로를 선택하여 효율성을 극대화합니다.

**정체에서 벗어나 반박하기(Getting out of Ruts and pushing back)**
그렉 브록먼(Greg Brockman)은 "GPT-3와 GPT-4에서는 '고집하는 문제(doubling down problem)'에 정말 집중했던 기억이 납니다. AI가 잘못된 말을 하고 당신이 실수를 지적하면, AI는 자신이 옳다고 설득하려 했던 것을 기억하십니까? 우리는 이제 그 문제가 핵심 문제가 아닌 수준에 도달했습니다. 심지어 정확한 것을 완전히 찾아내지 못했을 때도 중요한 것을 강조하는 수준에 있다는 것이 정말 놀랍습니다. 꽤 합리적인 생각을 합니다. 그렉 브록먼(Greg Brockman): 그리고 저는 항상 이러한 코드 리뷰를 마치고 '음, 그래, 좋은 지적이야'라고 생각합니다." 이러한 현실성(groundedness)은 GPT-5에서 측정 가능하게 감소한 환각(hallucination) 현상과 깊이 관련되어 있으며, 이는 모델의 신뢰성을 크게 향상시켰습니다.

**토큰 효율성(Token Efficiency)**
업계의 가장 큰 과제 중 하나는 "토큰당 가격(price per token)"이 점점 더 관련 없는 지표가 되고 있다는 것입니다. 이는 추론 모델(reasoning models)이 질문에 답하기 위해 종종 10배 이상의 토큰을 사용할 수 있기 때문입니다. 특히 모델의 내부 작동 방식이 불투명할 경우 더욱 그렇습니다. 코덱스(Codex)는 이러한 토큰 효율성(token efficiency)에 특별히 최적화되어 있어, 비용 효율적인 방식으로 복잡한 작업을 수행할 수 있도록 설계되었습니다.
이러한 설명하기 어려운 모든 품질(hard-to-articulate qualities)은 결국 한 가지로 귀결됩니다: 에이전트형 코딩(Agentic Coding)을 위한 새로운 평가(Evals)의 필요성.

**요인 3: 에이전트형 코딩(Agentic Coding)을 위한 새로운 평가(Evals)**
GPT-5 출시와 관련된 초기 부정적인 반응(negative first reactions)은 대부분의 사람들이 실제 환경에서 모델을 충분히 사용해보지 않고 피상적인 지표에만 반응했기 때문이었습니다. 그러나 모델을 실제 적용해본 개발자들은 이미 적응과 인식 변화(sentiment shift)를 겪었으며, GPT-5 인식 반전(Sentiment Flip)은 예상대로 시간이 지나면서 나타났습니다. 에이전트형 코딩(agentic coding) 능력은 단순한 벤치마크를 넘어 실제 코드베이스(codebases)에서 그 진가를 발휘하며, GPT-5는 "도구를 활용하여 사고(thought with tools)"하는 능력을 통해 복잡한 문제 해결에서 인상적인 결과를 보여주었습니다. 소셜 미디어(social media)에서 새로운 모델에 대한 성급한 판단이 내려지는 경향은 여전하지만, 모델의 진정한 역량을 측정하기 위해서는 간단한 단일 턴 테스트(one-turn tests)만으로는 충분하지 않습니다 (제 농담은 "파란색과 보라색 그라데이션(blue and purple gradients)만 있다면 어떤 웹사이트든 바이브코드(vibecode)할 수 있다"는 것입니다). 에이더(Aider)의 다국어 벤치마크(polyglot benchmarks)조차도 실제 코드베이스(codebases)에서 다중 턴, 다단계, 도구를 활용하여 사고하는 코딩 에이전트(multi-turn, multi-step, thinking-with-tools coding agents)를 의미하는 에이전트형 코딩(agentic coding)을 실제로 테스트하지는 않습니다.
이러한 문제의식은 실제 오픈 소스 코드베이스(open source codebases)에서 실제 작업을 대상으로 모델의 블라인드 테스트(blind taste test)를 실시하고 관리자(maintainers)가 성능을 평가하도록 하는 새로운 평가 방식의 필요성을 강조합니다. OpenAI는 이러한 평가를 지속적으로 수행하고 있으며, 그 결과는 에이전트형 코딩(agentic coding)의 미래를 위한 중요한 통찰력을 제공하고 있습니다.
OpenAI의 코딩 능력(coding capabilities) 발전에는 그렉 브록먼(Greg Brockman)의 리더십이 항상 중요한 역할을 해왔습니다. 그의 통찰력은 OpenAI의 방향성을 제시하고 있으며, 특히 에이전트형 AI(agentic AI)의 미래에 대한 그의 비전은 계속해서 주목받고 있습니다.

**OpenAI 리더십의 주요 통찰: 2025년의 관점에서**

이 글의 원문은 그렉 브록먼(Greg Brockman)이 과거 잠재 공간 팟캐스트(Latent Space podcast)에서 스윅스(Swyx), 알레시오(Alessio)와 나눈 대화에서 발췌되었습니다. 당시 OpenAI는 GPT-5와 여러 오픈 소스 모델(open source models)을 동시에 출시하며 매우 바쁜 시기를 보냈습니다. 브록먼은 "한 주 동안 그렇게 많은 것을 출시하는 것은 정말 정신없는 일이었지만, 저희는 오픈 소스 모델(open source models)과 GPT-5를 세상에 내놓게 되어 정말 기쁩니다. 팀이 해낸 일에 대해 자랑스럽습니다"라고 소회를 밝혔습니다. 이러한 초기 출시의 열기가 현재까지도 이어지며, 이 대화에서 논의된 많은 비전들이 현실화되고 있습니다.

**OpenAI의 추론(Reasoning) 진화**
GPT-5는 하이브리드 모델(hybrid model)로서, 그 출시 당시부터 많은 사람들에게 단일 모델의 한계를 넘어서는 새로운 가능성을 제시했습니다. 그렉은 GPT-4 훈련 이후, 모델이 단순한 텍스트 완성을 넘어 대화가 가능해지면서 "왜 이것이 AGI가 아닌가?"라는 근본적인 질문을 던지게 되었다고 회상했습니다. 이 질문에 대한 해답은 모델이 세상에서 직접 아이디어를 시험하고 피드백(feedback)을 받는 강화 학습(reinforcement learning) 방식에 있다고 보았습니다. 이는 2017년 도타(Dota) 프로젝트에서 인간 시연(human demonstrations) 없이 순수 강화 학습(reinforcement learning)만으로 복잡한 행동을 구현했던 경험에서 비롯된 확신입니다. OpenAI는 GPT-4 이후 추론 패러다임(reasoning paradigm)으로의 전환을 확신했으며, 수많은 시도 끝에 이를 현실화했습니다. 현재 제리(Jerry)가 이끄는 강화 학습 팀(reinforcement learning team)과 웬다(Wenda), 펠리페(Felipe)와 같은 추론(inference) 전문가들의 협력은 이 분야에서 지속적인 인프라(infrastructure) 혁신을 이끌고 있습니다.

**언어 모델의 온라인 및 오프라인 학습**
스윅스(Swyx)는 학습이 오프라인(offline) 사전 훈련(pre-trained)에서 시작되어 온라인(online) 학습으로 점차 전환되고 있는 현상에 대해 질문했습니다. 그렉은 "우리는 아직 인간이 하는 완전한 종류의 학습 루프(learning loop)에는 도달하지 못했지만, 추론(inference)을 하고 그 추론(inferencing)을 기반으로 훈련하는 루프(loop)가 있는 세상으로 이동하고 있습니다"라고 설명했습니다. 그는 모델의 능력이 높을수록 생성하는 토큰(token)의 가치도 높아진다는 점을 강조하며, 강화 학습(reinforcement learning)이 현실과의 접촉을 통해 모델의 관찰(observations)을 정규화하고 피드백(feedback)하는 중요한 역할을 한다고 설명했습니다. 특히 강화 학습 패러다임(reinforcement learning paradigm)은 적은 수의 예시만으로도 모델이 효과적으로 학습할 수 있도록 하며, 이는 인간 학습 방식과는 다른 강력한 레버리지(leverage)를 제공합니다. 2025년 현재, OpenAI는 이러한 온라인(online) 학습 메커니즘을 더욱 정교하게 발전시켜 모델이 지속적으로 스스로 개선할 수 있도록 하고 있습니다.

**강화 학습의 샘플 효율성 및 컴퓨트 확장**
강화 학습(Reinforcement Learning)의 샘플 효율성(sample efficiency)에 대한 질문에 그렉은 "병목 현상(bottleneck)은 항상 컴퓨트(compute)입니다"라고 단언했습니다. 그는 현재 우리가 훨씬 더 샘플 효율적인 알고리즘(sample efficient algorithms)을 가지고 있지만, 여전히 상당한 컴퓨트(compute)가 필요하다고 지적했습니다. 모델이 한 가지 작업을 수천 번 시도하고 그중에서 배우는 과정은 인간 큐레이터(human curator)의 레버리지(leverage)를 극대화하지만, 동시에 비례적인 컴퓨트(compute) 투입을 요구합니다.
컴퓨트(compute) 확장에 대해 그렉은 "우리는 그것을 실현할 방법을 찾을 것이라고만 말하겠습니다. 제발 우리에게 주세요"라며 컴퓨트 자원에 대한 강력한 의지를 보였습니다. 그는 과거 도타(Dota) 프로젝트에서 코어(cores) 수가 매주 두 배로 늘어나면서도 기술 발전의 벽에 부딪히지 않았던 경험을 언급하며, 컴퓨트(compute)의 확장이 곧 혁신으로 이어진다고 설명했습니다. 그렉은 컴퓨트(compute)를 "궁극적으로 에너지(energy)로 시작하여 컴퓨트(compute)로 변하고, 지능(intelligence)으로 변하며, 그것은 거의 그 컴퓨트(compute)를 모델이 유용한 일을 할 수 있는 잠재 에너지(potential energy)로 결정화시키는 것과 같습니다"라고 비유했습니다. 이러한 잠재 에너지(potential energy)는 모델이 한 번의 훈련으로 여러 작업을 수행할 수 있게 하며, 인류 전체를 고양시킬 수 있는 가능성을 내포하고 있습니다.

**RL 및 실제 상호작용에서의 벽시계 시간 제약**
스윅스(Swyx)는 강화 학습(RL)이 실제 세계와 상호작용할 때 겪는 벽시계 시간(wall clock time) 제약에 대해 질문했습니다. 그렉은 모델이 여러 개의 복사본을 실행할 수 있는 "매우 비인간적인 특성(non-human affordances)"을 가지고 있어 이 한계를 극복할 수 있다고 답했습니다. 그는 컴퓨트(compute) 사용의 패러다임이 훈련(training) 중심에서 모델 배포가 증가함에 따라 추론(inferencing) 및 실제 사용 중심으로 이동하고 있다고 설명했습니다. 또한, 실제 세계 상호작용을 위한 효율적인 하네스(harnesses)의 중요성을 강조하며, AGI(범용 인공지능)는 "매우 생산적인 방식으로 실제 세계와 상호작용할 수 있는 것"이어야 한다고 정의했습니다.

**ARC 연구소 및 DNA 신경망 경험**
그렉은 ARC 연구소(ARC Institute)에서의 DNA 신경망(DNA neural networks) 연구 경험을 공유하며, "DNA 신경망은 인간 언어(human language)를 대체하는 것과 정확히 같습니다"라고 설명했습니다. 그는 네 글자로 된 간단한 어휘(vocab)를 가진 생물학적 언어(biological language)가 인간 언어만큼이나 신경망(neural net)에 자연스럽게 적용될 수 있음을 강조했습니다. 당시 연구는 GPT-1 또는 GPT-2 수준으로 느껴졌으며, 생물학적 영역(biological domains)의 어려운 문제를 해결하기 위해서는 여전히 컴퓨트(compute) 확장과 긴 맥락(long context) 처리에 대한 노력이 필요함을 언급했습니다. 현재 OpenAI는 이러한 생물학적 데이터 모델링(biological data modeling) 분야에서도 상당한 진전을 이루고 있으며, 약물 발견(drug discovery)과 같은 응용 분야에서 AI의 잠재력을 탐구하고 있습니다.

**GPT-5 시대 정의 및 모델 지능 평가**
GPT-5 시대에 대해 그렉은 "이 모델들의 지능(intelligence)은 거의 설명할 수 없는 수준에 도달하고 있습니다"라고 강조하며, IMO(국제 수학 올림피아드) 금메달 수준의 증명(proofs) 작성 능력과 같은 성과를 예로 들었습니다. 그는 GPT-4가 광범위한 응용 분야에서 유용했지만, GPT-5는 아이디어의 깊이와 문제 해결의 신뢰성 면에서 훨씬 발전했다고 평가했습니다. 과거 GPT-3가 간단한 정렬 작업조차 어려워했던 것과 달리, GPT-5는 이러한 작업을 완벽하게 수행하며, 인간 전문가의 통찰력(insight) 도출을 돕는 강력한 협력자로 자리매김하고 있습니다. 그렉은 "이 모델들이 인간을 도울 수 있는 능력은 우리가 이제 막 보기 시작한 것"이라며, AI가 지적인 발전을 함께 추진하는 새로운 시대를 열고 있다고 덧붙였습니다.
모델 지능 평가에 대해 그렉은 "특정 작업에서는 분명히 포화 상태(saturation)가 있습니다"라며, 단순히 쉬운 질문보다는 깊은 지능(deep intelligence)을 요구하는 지적인 문제에서 GPT-5의 탁월한 성능이 드러난다고 설명했습니다. 그는 코드포스(code forces)와 같은 경쟁 프로그래밍 대회(competitive programming competitions)에서의 성과도 중요하지만, 실제 프로그래밍은 훨씬 더 복잡한 환경에서 이루어지므로, "지능(intelligence)을 실제 세계 응용 프로그램(real world applications)과 어떻게 연결할 것인가"가 핵심 과제라고 강조했습니다. OpenAI는 모델이 실제 세계의 복잡하고 다양한 상황에 적응할 수 있도록 노력하며, 단순한 벤치마크를 넘어 실질적인 가치를 제공하는 데 중점을 두고 있습니다.

**GPT-5를 사용하는 개발자를 위한 실용적인 조언**
GPT-5를 활용하는 개발자들을 위한 실용적인 조언으로, 그렉은 "이 모델들로부터 최대한의 것을 추출하는 데 진정한 기술이 필요하다"고 말했습니다. 그는 모델의 강점과 약점을 이해하고, 작업을 독립적인(self-contained) 단위로 나누어 모델에게 위임하는 것이 중요하다고 강조했습니다. 개발자들은 단순히 하나의 에이전트(agent)를 관리하는 것이 아니라, 여러 에이전트(agents)를 조율하는 '관리자'의 역할을 해야 한다고 조언했습니다. 또한, 프롬프트(prompts) 라이브러리(library)를 구축하고, 모델에 대한 감을 익혀 중요하지 않은 작업을 지속적으로 할당함으로써 모델의 활용도를 높일 수 있다고 덧붙였습니다.

**SWE 에이전트의 발전과 IDE 통합**
AI 제품화(productization)에 대해 그렉은 "훌륭한 프로그래머인 동료에 비유하여 생각하는 경향이 있습니다"라고 말하며, 페어 프로그래밍(pair programming) 형태와 원격 비동기(remote async) 형태의 협업을 모두 지원하는 AI 에이전트(AI agents)의 필요성을 강조했습니다. 그는 AI가 인프라(infrastructure)에 신뢰할 수 있는 방식으로 접근하고, 인간처럼 마이크로매니징(micromanaged)되는 것에 개의치 않는 특성(affordance)을 지니고 있음을 지적했습니다. 궁극적으로 개발자는 로컬(locally) 환경과 원격 시스템(remote systems) 간의 "원활한 혼합(seamless blending)"을 통해 AI 에이전트(AI agents)를 관리하고, 그들의 관찰 가능성(observability)을 통제하는 것이 중요하다고 설명했습니다.

**에이전트 견고성 및 보안**
에이전트 견고성(agent robustness)에 대해 그렉은 "심층 방어(defense in depth)를 통해 생각합니다"라고 설명하며, 모델 자체의 계층과 지시 계층(instruction hierarchy)과 같은 기술을 통해 보안을 강화한다고 언급했습니다. 그는 SQL 인젝션(SQL injections) 방지와 유사하게, 여러 계층의 시스템 제어(system controls)를 통해 모델이 샌드박스(sandboxed) 환경에서 안전하게 작동하도록 보장하는 것이 중요하다고 강조했습니다. AI 에이전트(AI agents)가 우리 삶에 더 깊이 통합될수록, "그들의 안전과 보안을 동시에 강화하는 것이 많은 부분에서 최전선(frontier)이라고 생각합니다"라고 덧붙이며 이 분야의 중요성을 역설했습니다.

**모델 사양**
모델 사양(model specs)에 대해 그렉은 "모델의 능력이 매우 뛰어날 때, 그들이 무엇을 할 것인지에 대해 정말 신경 쓰기 시작한다는 완벽한 예시"라고 말했습니다. 그는 모델 사양(model spec)이 OpenAI의 "북극성(north star)" 역할을 하며, 모델의 의도된 행동을 명확히 하고, 사양(spec)과 실제 행동 사이의 격차를 줄이는 데 기여한다고 설명했습니다. 이는 단순한 기술적 문서가 아니라, "거의 가치(values)와 같은 것"으로, 커뮤니티(community)와 함께 만들어나가야 할 중요한 지침임을 강조했습니다.

**GPT-5의 모델 라우팅 및 하이브리드 아키텍처**
스윅스(Swyx)는 GPT-5의 모델 라우터(router) 존재 여부에 대해 질문하며, 과거 도타(Dota) 프로젝트에서 여러 모델을 결합했던 경험과의 유사성을 물었습니다. 그렉은 "어느 정도는 그렇습니다"라고 답하며, GPT-5가 추론 모델(reasoning model)과 비추론 모델(non-reasoning model)을 결합하여 "적응형 컴퓨트(adaptive compute)"를 구현하고 있음을 밝혔습니다. 그는 이 두 가지 모델 유형이 각각 깊은 사고를 요구하는 작업과 빠른 응답이 필요한 작업에 최적화되어 있으며, 이들을 결합함으로써 효율성을 극대화한다고 설명했습니다. 특히, AGI(범용 인공지능)의 최종 형태(final form factor)는 단일 모델(single model)이 아니라 "다양한 강점과 약점을 가진 모델들의 동물원(menagerie of models)"이 될 것이라는 통찰을 공유했습니다. 2025년 현재, 이러한 하이브리드 아키텍처(hybrid architecture)는 GPT-5의 핵심 강점 중 하나로 자리 잡으며, 복잡한 문제 해결에 유연하고 확장 가능한 접근 방식을 제공하고 있습니다.

**GPT-5 가격 책정 및 컴퓨트 효율성 개선**
GPT-5의 가격 책정과 컴퓨트 효율성(compute efficiency) 개선에 대해 그렉은 "우리의 가격 책정 역사(history of our pricing)를 보면, 매우 일관되게 가격을 인하했습니다"라고 말하며, 매년 "10배 이상"의 공격적인 비용 절감 목표를 가지고 있음을 밝혔습니다. 그는 GPT-4 출시 이후 같은 수준의 지능(intelligence)에 대한 비용이 "1,000배 개선"되었다는 점을 강조하며, 이는 3년 이상이라는 짧은 기간 동안 이루어진 놀라운 성과라고 언급했습니다. 이러한 비용 효율성 개선은 "AGI(범용 인공지능)가 모든 인류에게 혜택을 주도록 하는" OpenAI의 사명(mission)과 직접적으로 연결됩니다. 더 저렴하고 효율적인 모델(models)은 AI 기술의 광범위한 배포를 가능하게 하며, 이는 개발자들이 더 많은 작업을 수행하고 혁신을 가속화하는 데 필수적인 요소입니다.

**자체 개선 코딩 에이전트 및 도구 사용**
자체 개선 코딩 에이전트(Self-Improving Coding Agents)에 대한 논의에서, 스윅스(Swyx)는 GPT-5에게 스스로 도구(tools)를 만들고 개선할 수 있는지 물었을 때, 모델이 "그냥 내가 할 수 있어. 도구(tool)는 필요 없어"라고 반응했던 경험을 공유했습니다. 그렉은 이러한 현상이 주로 모델의 훈련(training) 방식과 관련이 있다고 설명하며, 새로운 도구(tools)에 대한 적응을 훈련 과정에 포함하는 것이 중요하다고 강조했습니다. 그는 스스로 도구(tools)를 생산하고 영구적인 라이브러리(library)를 구축하는 능력은 AI 에이전트(AI agents)의 "놀라운 원시 기능(primitive)"이며, 가장 어려운 미해결 문제(unsolved problems)를 해결하기 위해 필수적이라고 덧붙였습니다. 2025년 현재, OpenAI는 모델이 동적으로 도구를 생성하고 활용하는 능력을 향상시키기 위한 연구를 활발히 진행하고 있습니다.

**온디바이스 모델 및 로컬 vs 원격 에이전트 시스템**
온디바이스 모델(On-Device Models)과 로컬(Local) 및 원격 에이전트 시스템(Remote Agent Systems)의 상호작용에 대해 그렉은 "로컬 모델(local model)이 때때로 원격 모델(remote model)에 위임하는 아키텍처(architecture)는 매우 흥미롭습니다"라고 말했습니다. 그는 개인 정보 보호 아키텍처(privacy architecture)와 엣지 컴퓨트(edge compute)의 중요성을 언급하며, 코덱스 인프라(Codex infrastructure)가 로컬 및 원격 에이전트 간의 원활한 상호작용과 멀티플레이어(multiplayer) 기능을 가능하게 한다고 설명했습니다. 이러한 하이브리드 접근 방식은 AI 에이전트(AI agents)가 다양한 환경에서 유연하고 안전하게 작동할 수 있도록 하는 미래 지향적인 설계입니다.

**OpenAI의 엔지니어링 및 LLM 활용**
OpenAI의 엔지니어링과 LLM(대규모 언어 모델) 활용에 대해 그렉은 "소프트웨어 엔지니어링(Software engineering)은 분명히 여러 차원에서 변화하고 있습니다"라고 언급했습니다. 그는 CUDA 커널(CUDA kernels)과 같은 독립적인(self-contained) 문제를 해결하는 데 AI 모델이 이미 능숙해지기 시작했으며, 이는 모델의 핵심 강점과 일치한다고 설명했습니다. 그러나 여전히 모델이 접근할 수 없는 맥락과 인간적 판단이 필요한 영역이 존재하며, 이는 팀 구성 방식에 대한 새로운 고민을 불러일으키고 있습니다. 그렉은 AI 도구의 발전이 "초기 채택자 단계(early adopter phase)에서 주류 단계(mainstream phase)로 전환"되고 있음을 강조하며, "우리가 그것을 10배 더 쉽게 만드는 도구(tools)를 가지고 있다면, 우리는 100배 더 많은 일을 할 수 있을 것"이라고 말하며 AI가 가져올 생산성 혁명에 대한 기대를 나타냈습니다.

**AGI 시대 엔지니어의 가치**
AGI 시대 엔지니어의 가치에 대해 그렉은 "엔지니어의 가치는 시간이 지남에 따라 증가하고 있습니다"라고 단언했습니다. 그는 AI 모델이 "인류가 만들어낸 가장 유용한 도구(tools)"이며, 이를 구축하는 것은 "인류가 지금까지 만들어낸 가장 큰 기계들을 구축하는 것"과 같다고 비유했습니다. 뉴딜(New Deal)이나 아폴로 프로그램(Apollo program)과 비교할 수 없을 정도로 거대한 이 프로젝트는 인류 전체를 고양시킬 잠재력을 가지고 있으며, 이 시점에 참여하는 모든 이들이 "운이 좋다"고 표현했습니다. 그렉은 거시적인 비전과 함께 "사람들이 행복한가? 사람들이 사명(mission)에 연결되어 있다고 느끼는가? 그들이 하는 일이 중요하다고 느끼는가?"와 같은 미시적인 질문 또한 중요하다고 강조했습니다.

**AI 연구의 현재 상태 및 연구소 다양성**
AI 연구의 현재 상태에 대해 그렉은 "이 분야에 놀랍도록 많은 다양성(diversity)이 있다"고 말했습니다. 그는 비록 때로는 수렴 진화(convergent evolution)처럼 보일지라도, 각 연구소는 다른 관점과 접근 방식을 가지고 있으며, OpenAI는 특히 "다음 단계 함수(step function)와 패러다임 전환(paradigm shift)"을 위한 연구에 집중하고 있다고 설명했습니다. 그는 멀티모달(multimodal) 및 다양한 생성 방식 등 연구 분야가 "그 어느 때보다 풍부하다"고 강조하며, 앞으로도 많은 돌파구(breakthroughs)가 기대된다고 덧붙였습니다.

**OpenAI의 우선순위 및 중점 분야**
OpenAI의 우선순위에 대해 그렉은 "신경망(neural nets), 딥러닝(deep learning)은 사실상 모든 종류의 데이터(data), 모든 종류의 영역(domain)에 적용 가능하기 때문에 엄청난 가능성 공간(possibility space)이 있습니다"라고 설명했습니다. 그는 핵심 추론 패러다임(core reasoning paradigm)과 함께 멀티모달 음성(Multimodal voice), 이미지 생성(image generation), 비디오 생성(video generation) 등을 중요한 중점 분야로 꼽았습니다. 로봇 공학(robotics)과 같은 물리적 영역에서의 도전 과제(예: 로봇 손의 고장)는 OpenAI가 디지털 영역에서 더 빠르게 혁신할 수 있음을 깨닫게 한 중요한 경험이었습니다. 그렉은 제한된 자원 속에서 "하나의 회사, 하나의 연구소로서, 가능한 한 일관된 하나의 문제에 집중하고 있다"고 강조했습니다.

**창업자를 위한 조언: 아직 늦지 않았다**
창업자들을 위한 조언으로 그렉은 "이 모델들을 실제 세계 응용 분야(real world application domains)에 연결하는 것이 극도로 가치 있다"고 강조했습니다. 그는 경제와 인간 노력의 모든 응용 분야가 워낙 방대하기 때문에, "아직 발견되지 않은 많은 결실이 있다"고 말하며, 단순히 기술적 래퍼(wrapper)를 만드는 것을 넘어 해당 영역에 대한 깊은 이해와 전문 지식(expertise), 관계(relationships) 구축에 집중할 것을 조언했습니다.

**2045년 타임캡슐: 컴퓨트와 풍요의 미래**
2045년에 대한 타임캡슐 메시지로 그렉은 "2045년은 상상하기가 너무 어렵습니다"라면서도, "놀라운 풍요(abundance)의 세상이 되기를 바랍니다"라는 희망을 표현했습니다. 그는 미래 사회에서 돈의 의미가 퇴색될 수 있지만, "수요가 많을 자원 하나는 바로 컴퓨트(compute)입니다"라고 단언했습니다. 컴퓨트(compute)에 대한 접근성과 그 분포(compute distribution)가 미래 사회의 중요한 질문이 될 것이며, 더 많은 컴퓨트(compute)를 통해 더 많은 가치를 창출할 수 있을 것이라고 전망했습니다.

**2005년 타임캡슐: 더 많은 문제가 나타날 것이다**
2005년의 자신에게 보낼 메시지로 그렉은 "문제의 풍요(abundance of problem)가 시간이 지남에 따라 증가한다는 것"이 가장 놀라운 통찰이었다고 밝혔습니다. 그는 과거에 '모든 멋진 문제들이 해결되어 남은 것이 없을 것'이라고 생각했던 것이 "완전히 틀린 것으로 밝혀졌다"며, 지금이야말로 기술 분야에서 활동하기 가장 흥미로운 시기라고 강조했습니다. "문제의 가용성(problem availability)이 시간이 지남에 따라 줄어들기보다는 증가할 것이라는 메시지"는 그가 젊은 시절에 알았으면 좋았을 핵심이라고 덧붙였습니다.

결론적으로, GPT-5와 코덱스는 단순한 코딩 도구를 넘어 개발자 생산성과 AI 에이전트의 미래를 재정의하고 있습니다. OpenAI는 지속적인 연구와 제품 통합을 통해 이러한 혁신을 이끌어 나가고 있으며, 앞으로도 AI가 가져올 변화에 주목해야 할 것입니다. 이 모든 내용은 OpenAI의 비전과 그렉 브록먼(Greg Brockman)을 비롯한 팀의 지속적인 노력이 있었기에 가능했습니다. 앞으로도 이 분야의 발전을 계속해서 지켜봐 주시길 바랍니다.