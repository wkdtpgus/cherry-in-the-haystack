우리는 추론 모델(reasoning model) 시대가 시작된 이래로 지능 파레토 프론티어(intelligence pareto frontier)의 가장 강력한 옹호자였습니다. 데미스(Demis)는 이를 주목했고 GDM은 이를 추진했습니다. 하지만 GPT-5를 통해 OpenAI는 처음으로 달러당 지능 프론티어(intelligence per dollar frontier)를 장악했습니다. 제미니(Gemini)는 파레토 프론티어(pareto frontier)에서 겨우 3개월을 버텼습니다. 우리가 처음 사용해봤을 때, 개발자 베타(developer beta)에 참여했던 사람들은 처음에는 우려했습니다. "훌륭한 코딩 모델(coding model)이긴 한데... 그게 다인가?"라는 말이 암묵적인 문제(unspoken elephant in the room)였습니다. 시간이 지나면서 분위기는 더욱 긍정적으로 바뀌었고, 저를 완전히 흥분시킨 큰 깨달음은 가격 공개였습니다. 이는 달러당 지능 프론티어(intelligence frontier)가 궁극적으로 라우팅 문제(routing problem)이기 때문입니다.

이러한 라우팅 문제의 해결은 단순히 비용 효율성을 넘어섭니다. 현대 AI 모델의 복잡성과 다양성을 고려할 때, 단일 모델이 모든 종류의 작업에 최적화될 수는 없습니다. 대신, 각 작업의 특성(예: 추론 깊이, 요구되는 정확도, 지연 시간 민감도)에 따라 가장 적합한 "전문가" 모델 또는 모델 조합으로 요청을 지능적으로 분배하는 것이 중요해졌습니다. GPT-5가 "통합된(unified)" 시스템으로 불리는 이유도 바로 여기에 있습니다. 이는 마치 다양한 전문성을 가진 모듈들을 유기적으로 연결하여 하나의 거대한 지능 시스템을 구성하는 것과 같습니다. 이러한 시스템은 효율적인 자원 사용뿐만 아니라, 특정 기능의 성능을 독립적으로 개선할 수 있는 유연성을 제공합니다.

사람들이 GPT-5가 "통합된(unified)" 것에 대해 가장 많이 묻는 질문은 "이것이 라우터(router)인가요??"입니다. 저는 그렉 브록만(Greg Brockman)과 노암 브라운(Noam Brown) 모두에게 이 질문을 했고, 트위터에서 많은 논의와 결론 없는 답변 끝에, 이제 GPT-5 시스템 카드(system card)에서 바로 그 답을 얻었습니다. 이것은 제가 팀에 요구해왔던 투명성 수준이지만, 실제로 얻을 수 있을 것이라고 낙관한 적은 없었습니다!

**라우터 아키텍처의 심화와 그 중요성**
확실히 말하자면: 만약 GPT-3에서 GPT-4로의 큰 돌파구가 전문가 혼합(Mixture of Experts, MoE) 아키텍처의 도입이었다면, GPT-4o/o3에서 GPT-5로의 발전은 더욱 정교한 모델 혼합(Mixture of Models) 또는 동적 라우팅 시스템의 진화일 가능성이 높습니다. 이는 단순한 모델의 크기 확장을 넘어, 시스템 전체의 지능을 최적화하는 방향으로 나아가고 있음을 의미합니다. 추론 모드(reasoning mode)와 비추론 모드(non-reasoning mode)처럼 작업의 성격에 따라 다른 경로로 추론(inference)을 유도하는 방식은, 본질적으로 시스템 어딘가에 라우터(router)가 존재함을 시사합니다. 이러한 라우터는 각 모델의 강점을 최대한 활용하여, 전체 시스템의 성능을 극대화하고 개발자가 직면하는 복잡성을 줄이는 핵심적인 역할을 수행합니다.

어느 정도는 GPT-5가 "통합 모델(unified model)"인지 "통합 시스템(unified system)"인지, "라우터(router)"라고 직접적으로 부르는 구성 요소(component)가 있는지 없는지는 그다지 중요하지 않습니다. 추론 모드(reasoning mode)와 비추론 모드(non-reasoning mode)가 생기는 순간, 효율성이나 전문화("전문가(experts)") 또는 연산 깊이(compute depth)를 위한 추론(inference)의 다른 경로가 생기는 순간, 본질적으로 시스템 어딘가에 라우터(router)가 있는 것이며, 이제는 의미론(semantics)과 라우터 레이어(router layer)의 "두께"의 문제입니다. 예를 들어, Qwen 3와 같은 오픈 소스 모델(open source models)에서 MoE 레이어(MoE layer)를 볼 수 있는데, 여기서는 명확하게 라우팅(routing)이 이루어집니다. @rasbt의 훌륭한 서브스택(substack)에서 발췌. 따라서 라우터(router)가 **확실히** 존재함에도 불구하고, 사람들이 여전히 그것에 대해 극도로 궁금해하는 한 가지 이점과 이유는 모델 성능의 특정 부분을 고정하고 독립적으로 발전시킬 수 있는 능력 때문입니다. 예를 들어, 만약 GPT-5 = 라우터(router) + "새로운 4o" + "새로운 o3"라면, (만약 우리가 가중치(weights)를 제어할 수 있다면) 버그가 발생했을 때 오류 원인은 단 3가지입니다: 올바른 모델(model)로 라우팅(routing)되었는가? 비추론자 버그(nonreasoner bug)였다면 고칠 수 있는가? 추론자 버그(reasoner bug)였다면 고칠 수 있는가? 그리고 이들은 "직교하는(orthogonal)" 독립적으로 움직이는 부분들이기 때문에, 다른 부분을 일정하게 유지하면서 한 부분을 개선하는 것이 더 나은 AI 시스템(AI system)을 설계하는 데 있어 직관적이고 중요한 단계라고 예상할 수 있습니다. 아마도 OpenAI 백만장자가 아닌 우리 나머지 사람들에게 가장 위안이 되는 (혹은 실망스러운?) 점은 우리도 이런 식으로 할 것이라는 점이며, 대형 연구소(BigLabs)가 하이브리드 모델(hybrid models)을 만드는 더 비터 레슨(Bitter Lesson) 방식이 있다는 큰 비밀을 숨겨온 것은 아니라는 것입니다.

**대통합과 개발자 경험의 변화**
GPT-5와 같은 통합 시스템의 등장은 "대통합(The Great Consolidation)"이라는 새로운 트렌드를 이끌고 있습니다. 기존에는 개발자가 여러 모델 중 어떤 것을 사용할지 결정해야 하는 인지 부하(cognitive load)가 컸습니다. 하지만 통합된 라우팅 시스템은 이러한 복잡성을 추상화하여, 개발자는 더 이상 모델 선택의 고민 없이 최적의 성능을 기대할 수 있게 됩니다. (개발자(developer)의 경우, "모델 선택기(model picker)"가 새로운 추론 노력, 상세함, 함수 호출 매개변수(function calling parameters)로 효과적으로 전환되면서 제어권은 유지되지만요). 이는 OpenAI가 릴리스 노트(release notes)에서 밝힌 모델 사용 중단(model deprecations) 계획과도 맥을 같이 합니다. 이는 모든 조합을 가진 개발자(developer) 대상 옵션보다 훨씬 더 야심찬 사용 중단 일정(deprecation schedule)입니다. 즉, 개발자는 더욱 간소화된 API를 통해 강력하고 효율적인 AI 기능을 활용할 수 있게 되며, 이는 AI 애플리케이션 개발의 진입 장벽을 낮추고 혁신을 가속화할 것입니다. 이러한 변화는 AI 개발의 미래를 더욱 명확하고 효율적인 방향으로 이끌 것입니다.