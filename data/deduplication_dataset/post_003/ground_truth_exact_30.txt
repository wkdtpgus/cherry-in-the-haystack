이전에 저는 "The Big LLM Architecture Comparison"에서 2025년의 가장 주목할 만한 오픈 웨이트(open-weight) 아키텍처들을 비교했습니다. 다음으로, "From GPT-2 to gpt-oss: Analyzing the Architectural Advances"에서 개념적인 수준으로 다양한 아키텍처 구성 요소들을 더 자세히 살펴보고 논의했습니다. 좋은 일은 세 번 일어난다고 하니, 이번 여름의 주목할 만한 연구 성과들을 다루기 전에, 이제 이 아키텍처들을 코드로 직접 다뤄보고 싶었습니다. 이 글을 따라가다 보면, 실제로 내부적으로 어떻게 작동하는지 이해하게 될 것이고, 자신만의 실험이나 프로젝트에 적용할 수 있는 구성 요소(building blocks)를 얻게 될 것입니다. 이를 위해 저는 Qwen3(5월에 처음 출시되어 7월에 업데이트됨)를 선택했습니다. 이 글을 쓰는 시점에서 Qwen3는 가장 널리 선호되고 사용되는 오픈 웨이트(open-weight) 모델 제품군 중 하나이기 때문입니다.

제 생각에 Qwen3 모델이 이렇게 인기 있는 이유는 다음과 같습니다:

*   개발자와 상업적으로 친화적인 오픈 소스(open-source) (아파치 라이선스 v2.0)로, 원래의 오픈 소스(open-source) 라이선스 약관 외에 어떠한 제약도 없습니다(일부 다른 오픈 웨이트(open-weight) LLM은 추가적인 사용 제한을 부과합니다).
*   **탁월한 성능과 지속적인 발전**: Qwen 모델은 출시 이후 다양한 벤치마크에서 지속적으로 최상위권 성능을 보여주며 독점 모델들과 어깨를 나란히 했습니다. 특히, Qwen2는 Qwen3의 핵심 아키텍처를 계승하면서 그룹화된 쿼리 어텐션(GQA, Grouped-Query Attention), SwiGLU 활성화 함수, 로터리 포지셔널 임베딩(RoPE, Rotary Positional Embeddings)과 같은 최신 기술들을 적용하여 효율성과 정확도를 극대화했습니다. 이러한 설계 덕분에 Qwen2는 뛰어난 추론 성능을 제공하며, 멀티모달(multimodal) 능력까지 확장했습니다.
*   **다양한 모델 크기 및 MoE 아키텍처**: 0.5B 소형 모델부터 수백억 개의 파라미터를 가진 밀집(dense) 모델, 그리고 효율적인 전문가 혼합(Mixture-of-Experts, MoE) 모델에 이르기까지, Qwen 제품군은 사용자의 컴퓨팅 예산과 특정 사용 사례에 맞는 광범위한 선택지를 제공합니다. MoE 모델은 거대한 파라미터 수를 가지면서도 추론 시 필요한 전문가만 활성화하여 자원 효율성을 높이는 혁신적인 접근 방식을 제시합니다.
*   **활발한 커뮤니티 지원과 통합 생태계**: Qwen 모델은 Hugging Face Transformers와 같은 주요 오픈 소스(open-source) 라이브러리에 빠르게 통합되었으며, vLLM, SGLang과 같은 고성능 추론 프레임워크에서도 최적화된 성능을 발휘합니다. 이는 개발자들이 Qwen 모델을 쉽게 활용하고, 미세 조정(fine-tuning)하며, 다양한 애플리케이션에 배포할 수 있도록 강력한 지원을 제공합니다.

**코드 구현 접근 방식**:
이 글에서는 순수 파이토치(PyTorch)를 사용하여 Qwen 모델의 핵심 구성 요소를 바닥부터 구현하는 과정을 상세히 다룰 것입니다. 어텐션(attention) 레이어, 피드포워드 네트워크(feed-forward network), 그리고 로터리 포지셔널 임베딩(RoPE)과 같은 주요 아키텍처 요소들을 코드를 통해 직접 살펴보며, 내부 작동 원리를 파악하고 자신만의 연구나 프로젝트에 적용할 수 있는 실질적인 지식과 구성 요소(building blocks)를 얻게 될 것입니다.

**팁 1:** 이 글은 기술적인 코드 스니펫(code snippet)을 포함하고 있으므로, 최적의 가독성을 위해 웹 브라우저에서 읽는 것을 권장합니다.
**팁 2:** 웹사이트 왼쪽에 제공되는 목차를 활용하면 각 섹션(section)으로의 이동이 더욱 편리합니다.

**그림 1:** 이 글에서 심층적으로 분석하고 순수 파이토치(PyTorch)로 직접 구현해 볼 Qwen 모델의 밀집(Dense) 및 전문가 혼합(Mixture-of-Experts) 아키텍처 개요.