이전에 저는 "The Big LLM Architecture Comparison"을 통해 최신 오픈 웨이트(open-weight) 아키텍처들을 비교 분석했습니다. 다음으로, "From GPT-2 to gpt-oss: Analyzing the Architectural Advances"에서 개념적인 수준으로 다양한 아키텍처 구성 요소들을 더 자세히 살펴보고 논의했습니다. 이론적인 논의를 넘어, 이제는 이 아키텍처들을 실제 코드로 구현하며 심층적으로 탐구하고자 합니다. 이 글을 따라가다 보면, 실제로 내부적으로 어떻게 작동하는지 이해하게 될 것이고, 자신만의 실험이나 프로젝트에 적용할 수 있는 구성 요소(building blocks)를 얻게 될 것입니다. 이러한 목표를 위해 저는 Qwen3를 선택했습니다. Qwen3는 출시 이후 꾸준히 혁신적인 업데이트를 선보이며, 현재까지도 가장 강력하고 활용도 높은 오픈 웨이트(open-weight) LLM 중 하나로 자리매김하고 있기 때문입니다.

제 생각에 Qwen3 모델이 이렇게 인기 있는 이유는 다음과 같습니다:

*   개발자 친화적이며 상업적 활용이 가능한 아파치 라이선스 v2.0을 채택하고 있습니다. 이는 다른 일부 오픈 웨이트(open-weight) LLM에서 발견되는 추가적인 사용 제한 없이 자유로운 활용을 보장한다는 점에서 큰 장점입니다.
*   성능이 정말 좋습니다. 과거 LMArena 리더보드에서 235B-Instruct 모델이 Claude Opus 4와 동등한 수준의 성능을 보였던 것은 이미 잘 알려진 사실입니다. 현재는 다양한 최신 벤치마크(benchmark)에서도 상위권을 꾸준히 유지하며, 특히 효율성과 성능의 균형에서 탁월함을 보여주고 있습니다. 또한, 9월에 공개된 1조(1T) 파라미터(parameter) "max" 변형 모델은 출시 당시 Kimi K2, DeepSeek 3.1 등을 능가하는 압도적인 성능을 자랑했으나, 여전히 클로즈드 소스(closed-source)로 제공되고 있습니다. 그럼에도 불구하고, Qwen3의 오픈 웨이트(open-weight) 모델 제품군 자체는 지속적인 개선을 통해 경쟁력을 강화하고 있습니다.
*   0.6B 밀집(dense) 모델부터 480B 파라미터(parameter) 전문가 혼합(Mixture-of-Experts) 모델까지, 다양한 컴퓨팅 예산(compute budget)과 사용 사례(use-case)를 위한 여러 가지 모델 크기가 제공됩니다.

순수 파이토치(PyTorch)로 처음부터 구현된 코드를 다루므로 이 글의 길이가 다소 길어질 수 있습니다. 코드 섹션이 상세하게 느껴질 수 있으나, 이는 추상적인 개념만으로는 이해하기 어려운 핵심 구성 요소(building blocks)들을 명확히 설명하는 데 기여할 것입니다.

**팁 1:** 이 글을 이메일 받은 편지함에서 읽고 있다면, 좁은 줄 너비 때문에 코드 스니펫(code snippet)이 어색하게 줄 바꿈될 수 있습니다. 더 나은 경험을 위해 웹 브라우저에서 여는 것을 권장합니다.
**팁 2:** 웹사이트 좌측에 제공된 목차를 활용하면 각 섹션(section)으로의 이동이 더욱 편리합니다.

**그림 1:** 이 글에서 논의되고 순수 파이토치(PyTorch)로 (재)구현된 Qwen3 밀집(Dense) 및 전문가 혼합(Mixture-of-Experts) 아키텍처(architecture) 미리보기.