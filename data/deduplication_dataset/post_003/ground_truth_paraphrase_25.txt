이전 글에서 저는 "The Big LLM Architecture Comparison"에서 2025년의 주요 공개 가중치(open-weight) 아키텍처들을 살펴보았습니다. 이어 "GPT-2부터 gpt-oss까지: 아키텍처 발전 분석"에서는 다양한 구조적 구성 요소들을 개념적인 관점에서 심층적으로 논의했었죠. 좋은 일은 세 번 온다는 말이 있듯이, 올여름의 주목할 만한 연구 성과들을 다루기 전에, 이제는 이러한 아키텍처들을 실제 코드로 구현하며 탐구해보고 싶었습니다. 이 글을 따라가면, 모델들이 내부적으로 어떻게 작동하는지 명확하게 이해할 수 있을 것이며, 여러분의 실험이나 프로젝트에 활용할 수 있는 핵심 구성 요소(building blocks)들을 얻게 될 것입니다. 이를 위해 저는 Qwen3 모델군(5월에 최초 공개되었고 7월에 업데이트됨)을 선택했습니다. 현재 Qwen3는 가장 널리 사용되고 선호되는 공개 가중치(open-weight) 모델 제품군 중 하나이기 때문입니다.

Qwen3 모델이 이처럼 높은 인기를 얻는 주된 요인들은 다음과 같습니다:

*   **개발자 친화적인 라이선스**: 아파치 라이선스 v2.0을 따르는 상업적으로도 사용 가능한 오픈 소스(open-source) 모델입니다. 이는 다른 일부 공개 가중치(open-weight) LLM들이 부과하는 추가적인 사용 제한 없이, 원본 오픈 소스(open-source) 라이선스 조건만 준수하면 됩니다.
*   **탁월한 성능**: 이 글을 쓰는 시점에서 235B-Instruct 변형 모델은 LMArena 리더보드에서 8위를 기록하며, 독점 모델인 Claude Opus 4와 어깨를 나란히 하고 있습니다. 더 높은 순위를 차지한 공개 가중치(open-weight) LLM은 DeepSeek 3.1 (약 3배 더 큼)과 Kimi K2 (약 4배 더 큼) 단 두 개뿐입니다. 9월 5일에는 Qwen3가 자사 플랫폼에 1조(1T) 파라미터(parameter) 규모의 "max" 변형 모델을 공개했는데, 이 모델은 모든 주요 벤치마크(benchmark)에서 Kimi K2, DeepSeek 3.1, Claude Opus 4를 능가하는 성능을 보여주었지만, 현재는 클로즈드 소스(closed-source)로 운영되고 있습니다.
*   **다양한 모델 크기 제공**: 0.6B 밀집(dense) 모델부터 480B 파라미터(parameter) 전문가 혼합(Mixture-of-Experts) 모델에 이르기까지, 다양한 컴퓨팅 예산(compute budget)과 활용 시나리오(use-case)에 맞춰 여러 가지 모델 규모를 제공합니다.

순수 파이토치(PyTorch)로 처음부터 코드를 작성했기 때문에 이 글은 다소 길어질 수 있습니다. 코드 섹션이 방대하게 느껴질 수도 있지만, 개념적인 설명만으로는 파악하기 어려운 구성 요소(building blocks)들을 더욱 명확하게 이해하는 데 도움이 되기를 바랍니다!

Qwen3 아키텍처의 핵심적인 혁신은 Grouped Query Attention(GQA), SwiGLU 활성화 함수(activation function), 그리고 Rotary Position Embeddings(RoPE)의 통합에 있습니다. GQA는 멀티헤드 어텐션(Multi-Head Attention)의 메모리 및 계산 효율성을 크게 향상시켜, 특히 긴 컨텍스트(context)를 처리할 때 유리합니다. 이는 모델이 더 많은 정보를 동시에 고려할 수 있도록 돕습니다. SwiGLU는 ReLU와 같은 전통적인 활성화 함수를 대체하여 비선형성을 부여하고 모델의 표현력을 높이는 데 기여하며, 이는 학습 안정성과 성능 향상으로 이어집니다. 또한, RoPE는 입력 시퀀스의 토큰(token) 간 상대적 위치 정보를 효과적으로 인코딩하여, 모델이 장거리 의존성(long-range dependencies)을 더 잘 포착할 수 있도록 합니다. 이러한 세 가지 요소의 조합은 Qwen3가 뛰어난 성능을 발휘하는 기술적 기반이 됩니다.

**팁 1:** 이 글을 이메일 받은 편지함에서 읽고 계시다면, 좁은 화면 너비 때문에 코드 스니펫(code snippet)이 보기 불편하게 줄 바꿈될 수 있습니다. 더 나은 가독성을 위해 웹 브라우저에서 열어보시는 것을 권장합니다.
**팁 2:** 웹사이트 왼쪽에 위치한 목차를 활용하시면 각 섹션(section) 간 이동을 훨씬 편리하게 할 수 있습니다.

**그림 1:** 이 글에서 분석되고 순수 파이토치(PyTorch)로 (재)구현된 Qwen3의 밀집(Dense) 및 전문가 혼합(Mixture-of-Experts) 아키텍처(architecture)의 개요.