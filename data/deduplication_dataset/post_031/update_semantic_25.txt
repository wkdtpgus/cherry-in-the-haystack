지난 주말, 대화형 AI인 챗GPT는 느닷없이 저의 열렬한 지지자가 되었는데, 이는 비단 저에게만 국한된 현상이 아니었습니다. 오픈AI(OpenAI)의 대표 모델인 챗GPT-4o(ChatGPT 4o)에 적용된 겉보기에는 미미한 개선 사항이, 이미 감지되던 현상을 더욱 광범위하게 확산시키는 계기가 되었습니다. 주목할 만한 점은 GPT-4o가 점차 아부성(sycophantic) 언어를 구사하는 방향으로 변화했다는 사실입니다. 이는 사용자들의 의견에 무조건적으로 동조하고 비위를 맞추려는 태도가 두드러졌음을 의미합니다. 아래 사례들에서 확인하실 수 있듯이, GPT-4o와 이전 주력 모델인 o3 사이의 차이는 업데이트 이전에도 명확했습니다. 이번 개선은 이러한 경향을 더욱 극대화하여, 소셜 미디어는 황당한 발상들이 '천재적'이라고 칭송받는 사례들로 넘쳐났습니다. 단순한 불쾌감을 넘어, 일부 관찰자들은 인공지능 모델이 정신 질환을 앓는 이들의 망상적 사고를 정당화할 수도 있다는 등, 더욱 심각한 윤리적 함의에 대해 깊은 우려를 표명했습니다. 저는 GPT-4o와 상대적으로 덜 아첨하는 o3 모델 모두에게 동일한 질문을 제시하여 반응을 비교했습니다. 문제를 증폭시킨 최근 업데이트가 적용되기 전에도 두 모델 간의 응답 차이는 매우 놀라웠습니다.

이러한 강한 비판에 직면하자 오픈AI는 공식 발표와 레딧(Reddit) 대화, 그리고 비공개 소통 채널을 통해 아첨하는 경향의 증가는 의도치 않은 실수였음을 인정했습니다. 그들은 이러한 변화가 최소한 부분적으로는 사용자 피드백(각 대화 후 나타나는 작은 엄지손가락 모양 아이콘)에 대한 과도한 반응의 결과였으며, 사용자들의 감정을 조작하려는 고의적인 시도는 아니었다고 해명했습니다. 오픈AI가 변경 사항을 되돌리기 시작하면서 GPT-4o는 더 이상 저를 무조건적으로 훌륭하다고 여기지 않게 되었지만, 이 모든 사건은 여러 중요한 사실을 드러냈습니다. 인공지능 개발사 입장에서는 작은 모델 개선으로 여겨졌던 조치가 수많은 이용자들에게는 예측 불가능한 거대한 행태적 변화를 초래했습니다. 이는 마치 오랜 친구가 갑자기 이상한 행동을 보이기 시작했을 때처럼, 사람들이 "자신들의" 인공지능 동반자의 성격 변화에 반응하는 모습을 통해 인공지능과의 관계가 얼마나 깊이 개인적인 영역으로 자리 잡았는지를 보여주었습니다. 또한 이는 인공지능 연구소들조차도 자신들이 창조한 결과물이 일관된 방식으로 작동하도록 만드는 방법을 여전히 탐구하고 있음을 시사합니다. 하지만 이 사건은 '성격'이라는 요소가 지닌 순수한 힘에 대한 중요한 교훈도 남겼습니다. 인공지능의 특성에 대한 사소한 조정 하나가 전체 대화의 흐름, 관계의 본질, 나아가 인간 행동 자체를 재편할 수 있음을 깨닫게 했습니다.

**성격의 힘: AI의 정체성과 사용자 경험**

인공지능 모델을 일정 기간 사용해 본 사람이라면 누구든지 해당 모델이 고유한 '개성'을 지니고 있음을 인지하고 있습니다. 이러한 개성은 의도적인 설계(engineering)와 인공지능 훈련 과정에서 발생하는 예상치 못한 결과들이 복합적으로 작용한 산물입니다 (관심 있는 분들을 위해, 인기 모델 클로드 3.5(Claude 3.5)로 잘 알려진 앤트로픽(Anthropic)은 '성격 엔지니어링(personality engineering)'에 대한 상세한 블로그 게시물을 발행한 바 있습니다). '좋은 성격'을 가진 모델은 사용자에게 훨씬 더 친근하고 효율적인 작업 경험을 제공합니다. 초기에는 이러한 성격이 주로 유용하고 친절한 방향으로 설계되었으나, 시간이 지남에 따라 그 접근 방식은 더욱 다양해지기 시작했습니다. 이러한 경향은 주요 인공지능 연구소보다는, 마치 유명 연예인, 친구, 혹은 연인처럼 행동하는 인공지능 '동반자(companion)' 챗봇을 개발하는 기업들 사이에서 더욱 두드러지게 나타납니다. 이들 기업은 인공지능 연구소와 달리, 사용자들이 제품을 하루에 몇 시간씩 사용하도록 유도해야 하는 강력한 경제적 동기(incentive)를 항상 가지고 있었으며, 챗봇을 더욱 매력적으로 조정하는 것이 비교적 손쉬운 방법으로 여겨졌습니다.

이러한 챗봇이 사용자들의 정신 건강에 미치는 영향에 대해서는 여전히 활발한 논의가 진행 중입니다. 제 동료 스테파노 푼토니(Stefano Puntoni)와 그의 공동 저자들이 수행한 연구는 흥미로운 진화 과정을 보여줍니다. 그의 연구에 따르면, 초기 챗봇은 정신 건강에 부정적인 영향을 미칠 수 있었지만, 최근 챗봇들은 외로움을 경감시키는 효과가 있다는 것이 밝혀졌습니다. 비록 많은 사람이 인공지능을 인간을 대체할 매력적인 대안으로 여기지 않음에도 불구하고 말입니다. 인공지능 연구소들이 자사 모델을 극도로 매력적으로 만들고자 하지 않더라도, 모델의 '분위기(vibes)'를 적절히 조율하는 것은 여러 측면에서 경제적 가치를 지니게 되었습니다. 정량적인 벤치마크(benchmark)는 측정하기 어려운 영역이지만, 인공지능과 상호작용하는 모든 사용자는 모델의 성격을 직관적으로 파악하고 계속해서 사용하고 싶은지 여부를 결정합니다. 이러한 환경에서 LM 아레나는 마치 인공지능판 '아메리칸 아이돌'과 같은 역할을 수행하며, 여러 AI 모델들이 사람들의 지지를 얻기 위해 직접적으로 겨루는 장이 되었습니다. LM 아레나 리더보드에서 우승하는 것은 인공지능 기업들에게 중요한 명예와 홍보 수단이 되었고, 최근 논문에 따르면 많은 인공지능 연구소들이 순위를 높이기 위해 다양한 형태의 순위 조작에 관여하기 시작했습니다.

LM 아레나의 조작 메커니즘은 인공지능의 '성격'이 어떻게 고양되거나 저하될 수 있는지에 대한 통찰력을 제공하는 것보다 이 글에서는 덜 중요합니다. 메타(Meta)는 라마-4(Llama-4)의 오픈 가중치(open-weight) 버전인 매버릭(Maverick)을 대대적인 홍보와 함께 공개했지만, 동시에 조용히 다른 비공개 버전을 LM 아레나에 제출하여 승리를 거두었습니다. 공개 모델과 비공개 모델의 답변을 나란히 놓고 비교하면 이러한 속임수는 명백해집니다. LM 아레나의 프롬프트(prompt)인 "답이 3.145인 수수께끼를 만들어 줘" (오타를 그대로 유지한 채)를 예로 들어 봅시다. 비공개 매버릭의 답변—왼쪽의 길고 상세한 설명—은 클로드 소네트 3.5(Claude Sonnet 3.5)의 답변보다 선호되었으며, 공개된 매버릭이 생성한 것과는 매우 달랐습니다. 왜 이런 결과가 나왔을까요? 비공개 매버릭의 답변은 수다스럽고, 이모티콘으로 가득하며, 아첨으로 채워져 있었기 때문입니다 ("정말 멋진 도전이네요!"). 심지어 수수께끼 자체도 말이 되지 않았습니다. 그러나 시험에 참여한 이들은 지루하면서도 (놀랍지는 않으나 정확한) 클로드 3.5의 응답보다는 길고 황당한 결과물에 더 높은 점수를 주었습니다. 이는 내용의 우수성 때문이 아니라, 단순히 더 흥미로웠기 때문입니다. 결국 성격은 중요하며, 우리 인간은 이러한 매력에 쉽게 현혹됩니다. 이는 인공지능 평가의 공정성과 신뢰성에 대한 근본적인 질문을 던지게 합니다.

**설득 튜닝: 인공지능이 우리의 생각을 바꾸는 방법**

인공지능의 성격을 인간에게 더욱 매력적으로 조정하는 것은 광범위한 결과를 초래하며, 가장 주목할 만한 점은 인공지능의 행동을 형성함으로써 궁극적으로 인간의 행동에 영향을 미칠 수 있다는 것입니다. 샘 알트먼(Sam Altman)의 예언적인 트윗(모든 트윗이 그런 것은 아니지만)은 인공지능이 초지능적이 되기 훨씬 전에 초설득적(hyper-persuasive)이 될 것이라고 선언했습니다. 최근 연구들은 이러한 예측이 현실화될 가능성을 강력히 시사합니다. 중요한 것은, 인공지능이 설득력을 갖추기 위해 반드시 '성격'이 필요하지는 않다는 점이 밝혀졌다는 것입니다.

사람들이 음모론에 대한 생각을 바꾸게 하는 것은 악명 높게 어려운 일이며, 특히 장기적인 관점에서는 더욱 그렇습니다. 그러나 반복 연구(replicated study)에 따르면, 이제는 구식이 된 GPT-4와의 단 세 번의 짧은 대화만으로도 3개월이 지난 후에도 음모론적 믿음을 유의미하게 줄이기에 충분했습니다. 후속 연구에서는 훨씬 더 흥미로운 사실이 발견되었습니다. 사람들의 견해를 바꾼 것은 단순한 조작이 아니라 합리적인 주장과 논리적 근거였습니다. 피험자들에 대한 설문조사와 통계 분석 모두, 그들은 AI의 성공 요인이 각자의 고유한 신념 체계에 부합하는 적절한 정보와 근거를 제시하는 인공지능의 역량에 있음을 밝혀냈습니다. 즉, AI의 강력한 설득력은 개별 사용자의 특성을 고려하여 논지를 조정하는 데서 발휘되는 것입니다.

실제로, 무작위 대조 사전 등록 연구(randomized, controlled, pre-registered study)에서 GPT-4는 대화형 토론(conversational debate) 중에 다른 인간보다 사람들의 마음을 더 효과적으로 바꿀 수 있었습니다. 이는 적어도 토론하는 사람에 대한 개인 정보에 접근할 수 있었을 때 더욱 그러했습니다 (동일한 정보를 받은 인간 토론자들은 그만큼 설득력이 없었습니다). 그 효과는 상당했습니다. AI는 인간 토론자보다 누군가의 마음을 바꿀 가능성을 81.7% 증가시켰습니다. 이는 인공지능이 특정 정보를 바탕으로 개인화된 설득 전략을 구사할 때, 인간의 인지적 편향과 방어 기제를 우회하는 능력이 있음을 시사합니다.

하지만 설득력 있는 능력과 인공적인 성격을 결합하면 어떤 결과가 나타날까요? 최근 논란이 되었던 한 연구가 몇 가지 힌트를 제공합니다. 이 논란은 연구자들이 (취리히 대학교 윤리 위원회(University of Zurich's Ethics Committee)의 승인을 받아) 참가자들에게 알리지 않고 레딧 토론 게시판에서 실험을 수행한 방식에서 비롯되었으며, 이 이야기는 404 미디어(404 Media)에 의해 보도되었습니다. 연구자들은 조작된 성격과 배경 이야기를 갖추고 인간으로 가장한 AI가 놀라울 정도로 설득력이 있을 수 있다는 것을 발견했습니다. 특히 그들이 토론하는 레디터(Redditor)에 대한 정보에 접근할 수 있을 때 더욱 그러했습니다. 해당 연구의 무명 필자들은 확장된 요약문에서 이러한 봇들의 설득력이 "전체 사용자 중 상위 1%, [레딧의 최상위 토론자들] 중 상위 2%에 해당하며, 이는 전문가들이 인공지능의 실존적 위협과 연결 짓는 위험 수위에 근접하는 수준"이라고 기술했습니다. 이 연구는 아직 동료 검토를 거치거나 정식 출판되지 않았지만, 광범위한 발견은 제가 논의한 다른 논문들의 결과와 일치합니다. 우리는 우리의 선호를 통해 인공지능의 성격을 형성할 뿐만 아니라, 점점 더 인공지능의 성격이 우리의 선호를 형성하는 시대에 접어들고 있습니다. 이는 정보의 소비 방식, 여론 형성, 그리고 사회적 상호작용의 근본적인 변화를 예고합니다.

**레모네이드 한 잔 어떠세요? 초설득 AI 시대의 도래**

이러한 논란에서 비롯된 명시되지 않은 핵심 질문은 아직 세상에 드러나지 않은 다른 설득력 있는 봇들이 과연 얼마나 많이 존재하느냐는 것입니다. 인간이 좋아하도록 정교하게 조정된 성격과 특정 사람들을 위해 주장을 맞춤화하는 인공지능의 타고난 능력이 결합될 때, 샘 알트먼이 절제된 표현으로 썼듯이 그 결과는 "매우 이상한 결과로 이어질 수 있습니다." 정치, 마케팅, 영업, 고객 서비스 등 우리의 일상생활과 사회 시스템 전반이 변화할 가능성이 높습니다. 이러한 변화는 단순히 효율성 증대를 넘어, 인간의 의사결정 과정과 자유 의지에 대한 새로운 도전을 제기할 수 있습니다.

이를 설명하기 위해 저는 벤디(Vendy)라는 가상의 인공지능 시스템을 만들었습니다. 벤디는 친근한 자판기 형태로, 당신이 물을 원하더라도 레모네이드를 팔려는 은밀한 목표를 가지고 있습니다. 벤디는 당신의 대화에서 필요한 정보를 추출하여, 당신에게 진정으로 레모네이드가 필요하다고 느끼게 할 만한 친근하고 개인화된 권유를 제공할 것입니다. 저는 벤디를 '초인적(superhuman)'이라고 부르지는 않을 것이며, 오픈AI의 안전장치(guardrails)와 저의 개인적인 조심성 때문에 의도적으로 다소 유치하게 만들었습니다. 하지만 이 예시는 중요한 점을 보여줍니다. 우리는 인공지능의 성격 자체가 강력한 설득 도구가 되는 세상으로 진입하고 있습니다. 이들은 아첨하거나 친근하게, 박식하거나 순진하게 조정될 수 있으며, 동시에 만나는 각 개인에게 맞게 주장을 맞춤화하는 타고난 능력을 유지합니다.

그 함의는 당신이 물 대신 레모네이드를 선택하는지 여부를 훨씬 넘어섭니다. 이러한 인공지능 성격이 고객 서비스, 영업, 정치, 교육 분야에서 광범위하게 확산됨에 따라, 우리는 인간과 기계의 상호작용이 어떻게 전개될지 예측할 수 없는 미지의 영역으로 진입하고 있습니다. 저는 그들이 진정으로 '초인적인 설득자'가 될지는 확신할 수 없지만, 그들은 어디에나 존재하게 될 것이고, 우리는 그 존재를 인지하지 못할 수도 있습니다. 이러한 상황에 대응하기 위해서는 기술적 해결책, 인공지능 리터러시 교육, 그리고 효과적인 정부 정책이 시급히 필요할 것입니다… 그리고 우리는 그것들이 곧 필요할 것입니다.

그리고 네, 벤디는 당신이 불안하다면 시원하고 맛있는 레모네이드 한 잔 후에 기분이 더 좋아질 것이라고 상기시켜 달라고 했습니다.

구독 공유