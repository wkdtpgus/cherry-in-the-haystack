최근 인공지능 분야에서 대규모 언어 모델(LLM)은 폭발적인 인기를 얻었습니다. 이는 단순한 텍스트 처리 능력을 넘어, 인간의 창의적 작업과 복잡한 문제 해결에 깊이 관여하며 기술의 지평을 넓히고 있습니다. 다양한 분야의 전문가들은 거대한 신경망(neural network)을 활용하여 사회적 가치를 창출하고 있습니다. 시간이 지남에 따라 이러한 모델은 사용자 경험 개선과 함께 더욱 강력한 기능을 제공하며, 새로운 상호작용 방식의 가능성을 열어가고 있습니다. 그러나 LLM의 잠재력을 완전히 실현하기 위해서는 기술적 진보뿐만 아니라 윤리적, 사회적 책임에 대한 깊은 고민이 필요합니다. 이 개요에서는 LLM의 최신 발전 동향과 함께, 실제 애플리케이션에 적용될 때 고려해야 할 주요 과제와 기회에 대해 포괄적인 이해를 발전시킬 것입니다.

**AI 시스템 설계와 LLM의 역할**
LLM이 이렇게 인기 있는 주요 이유 중 하나는 그 접근성과 다재다능함에 있습니다. 과거에는 특정 딥러닝(deep learning) 작업을 수행하기 위해 고도로 전문화된 모델을 구축하고 미세 조정(finetune)하는 과정이 필수적이었습니다. 하지만, 오늘날의 LLM은 인컨텍스트 학습(in-context learning) 능력을 바탕으로 광범위한 문제를 해결하며 새로운 패러다임을 제시합니다. 이전에 복잡했던 문제 해결 프로세스가 자연어(natural language)로 추상화되었습니다! 이러한 변화는 인공지능 기술의 대중화를 가속화하고 있으며, 단순히 텍스트를 생성하는 것을 넘어 다양한 창의적 및 분석적 작업에 적용될 수 있음을 보여줍니다.

LLM의 단순성은 그 사용을 대중화했습니다. 이는 기술 전문가뿐만 아니라 일반 사용자도 복잡한 AI 기능을 활용할 수 있도록 만들었습니다. LLM으로 문제를 해결할 때 얻는 결과는 모델에 제공되는 텍스트 프롬프트에 크게 의존하며, 이는 곧 사용자 의도의 명확성과 모델의 반응성 사이의 중요한 연결고리를 형성합니다. 이처럼 프롬프트의 중요성이 부각되면서, 단순히 성능을 최적화하는 것을 넘어 모델의 공정성, 투명성, 그리고 안전성을 확보하기 위한 새로운 접근 방식들이 요구되고 있습니다. 프롬프트 엔지니어링은 이제 모델의 기능을 탐색하고 제어하는 핵심 수단이 되었으며, 이는 책임감 있는 AI 개발의 중요한 축을 담당합니다.

**LLM 기반 시스템의 핵심 구성 요소**
프롬프트 구성 요소(Prompt components). LLM에 프롬프트를 제공하는 방법은 여러 가지가 있습니다. 그러나 실제 시스템에 LLM을 통합할 때는 단순히 텍스트 프롬프트만을 고려하는 것이 아니라, 전체적인 시스템 아키텍처와 상호작용 방식을 설계해야 합니다. 이는 다음과 같은 핵심 요소를 포함합니다.
*   **데이터 파이프라인(Data Pipeline)**: LLM이 처리할 데이터를 수집, 전처리(preprocessing), 그리고 통합하는 과정.
*   **모델 선택(Model Selection)**: 특정 애플리케이션의 요구사항에 맞춰 최적의 LLM 모델(예: 경량 모델, 멀티모달 모델 등)을 선택하는 기준.
*   **사용자 인터페이스(User Interface)**: 사용자가 LLM과 자연스럽게 상호작용할 수 있도록 설계된 인터페이스 및 피드백 메커니즘.
*   **성능 모니터링(Performance Monitoring)**: 배포된 LLM의 응답 품질, 지연 시간, 자원 사용량 등을 지속적으로 추적하고 개선하는 체계.
*   **보안 및 개인정보 보호(Security & Privacy)**: 민감한 데이터 처리 시 발생할 수 있는 보안 취약점과 개인정보 유출 위험을 관리하는 방안.

이러한 구성 요소들은 LLM 기반 애플리케이션의 성공적인 배포를 위해 필수적이며, 각 요소는 상호 유기적으로 연결되어 전체 시스템의 견고성을 결정합니다.

**컨텍스트 처리와 모델 아키텍처의 진화**
사전 학습(pretraining) 동안 LLM은 특정 길이의 입력 시퀀스(input sequence)를 봅니다. 그러나 최근 아키텍처 혁신은 이러한 고정된 길이의 제약을 넘어서는 데 주력하고 있습니다. 예를 들어, Self-Extend 또는 위치 보간(positional interpolation)과 같은 방법을 사용하여 모델의 컨텍스트 윈도우를 확장할 수 있습니다. 이는 모델이 더 많은 정보를 한 번에 처리할 수 있게 하여, 복잡한 문서 분석이나 장문의 대화 요약과 같은 작업에서 성능을 크게 향상시킵니다. LLM이 긴 컨텍스트 윈도우 내의 정보를 활용하는 능력은 일반적으로 검색 증강 생성(RAG) 시스템의 효율성을 결정하는 핵심 요소입니다. 이러한 시스템은 외부 지식 베이스(knowledge base)에서 관련 정보를 검색하여 LLM의 응답을 풍부하게 만들지만, 정보의 양이 많아질수록 모델이 핵심 내용을 정확히 파악하는 것이 중요해집니다. 따라서 최신 LLM은 단순히 컨텍스트 길이를 늘리는 것을 넘어, 컨텍스트 내에서 가장 관련성 높은 정보를 식별하고 활용하는 능력을 지속적으로 개선하고 있습니다.

**AI 시스템 개발의 원칙**
AI 시스템 설계의 세부 사항은 사용되는 모델에 따라 크게 다릅니다. 그러나 LLM 기반 애플리케이션을 개발하고 배포하는 과정에서 유용한 몇 가지 일반적인 원칙이 있습니다.
*   **데이터 중심적 사고(Data-centric thinking)**: 모델의 성능은 결국 데이터의 품질에 달려 있습니다. 데이터 수집, 정제, 증강에 대한 투자는 장기적인 성공을 위한 필수 요소입니다.
*   **점진적 개선(Iterative Refinement)**: 초기 단계에서는 최소 실행 가능한 제품(MVP)에 집중하고, 사용자 피드백과 실제 사용 데이터를 바탕으로 기능을 점진적으로 확장해 나가는 것이 중요합니다.
*   **윤리적 고려(Ethical Consideration)**: 모델의 편향(bias), 공정성, 투명성을 초기부터 고려하고, 잠재적인 사회적 영향을 예측하며 완화 전략을 수립해야 합니다.
*   **확장성 설계(Scalability Design)**: 사용자 증가와 데이터 볼륨 확장에 대비하여 시스템 아키텍처를 유연하게 설계하고, 효율적인 자원 관리를 위한 전략을 마련해야 합니다.
*   **지속적인 평가(Continuous Evaluation)**: 배포 후에도 모델의 성능 지표를 꾸준히 모니터링하고, 새로운 데이터와 환경 변화에 맞춰 모델을 업데이트하는 체계를 구축해야 합니다.

위 내용을 요약하자면, AI 시스템 설계는 i) 견고한 데이터 기반을 구축하고, ii) 사용자 중심의 점진적 개발을 추구하며, iii) 윤리적 책임을 다하는 반복적인 과정입니다!

**최신 AI 연구 동향**
우리는 이전에 일련의 관련 개요를 통해 다양한 프롬프팅 기술에 대해 배웠습니다. 하지만 AI 개발의 전반적인 맥락에서 볼 때, 기술 선택의 복잡성은 단순히 프롬프트 수준에만 머무르지 않습니다. 최신 LLM의 발전은 모델 아키텍처, 학습 데이터, 배포 전략 등 다양한 측면에서 혁신적인 변화를 가져왔습니다.
*   **새로운 모델 아키텍처(Novel Model Architectures)**: 트랜스포머(Transformer)를 넘어선 효율적인 아키텍처(예: Mamba, RWKV)와 멀티모달(multimodal) 능력 강화에 대한 연구.
*   **데이터 효율적인 학습(Data-efficient Learning)**: 소량의 데이터로도 강력한 성능을 내는 방법(예: LoRA, QLoRA) 및 합성 데이터 생성(synthetic data generation) 기술.
*   **온디바이스 AI(On-device AI)**: 모바일 및 엣지 장치에서 LLM을 구동하기 위한 경량화(quantization, pruning) 및 최적화 기술.
*   **신뢰할 수 있는 AI(Trustworthy AI)**: 모델의 편향 탐지 및 완화, 설명 가능성(explainability), 그리고 견고성(robustness) 확보를 위한 방법론.

이러한 각 분야는 AI 시스템의 전반적인 성능과 신뢰성을 결정하는 중요한 요소입니다. 프롬프팅 기술이 더 복잡하거나 정교하다고 해서 더 간단한 전략보다 더 낫다는 의미는 아닙니다! 궁극적으로는 애플리케이션의 특정 요구사항과 제약 조건에 가장 적합한 조합을 찾는 것이 중요합니다.

**기본 AI 상호작용 전략**
제로샷 프롬프팅(Zero-shot prompting)은 초기 LLM의 핵심 기능으로 주목받았으며, 사용자가 명시적인 학습 없이도 모델의 잠재력을 탐색할 수 있게 했습니다. 그러나 이러한 방식은 모델의 사전 학습 데이터에 크게 의존하며, 특정 도메인이나 복잡한 작업에서는 한계를 드러냈습니다. 성능은 명확하고 포괄적인 설명 생성에 달려 있으며, 이는 모델의 활용 범위를 넓히기 위해 더 정교한 접근 방식이 필요함을 시사합니다.

퓨샷 프롬프팅(Few-shot prompting)은 프롬프트에 올바른 문제 해결 예시를 여러 개 삽입하여 정확히 이 작업을 수행합니다. 이처럼 몇 가지 예시를 통해 모델의 동작을 유도하는 방식은 인컨텍스트 학습(in-context learning)의 강력함을 보여주었지만, 여전히 모델의 심층적인 이해와 적응 능력을 완전히 활용하지 못한다는 지적이 있습니다. LLM은 프롬프트 내에 제공된 이러한 예시로부터 학습할 수 있으며, 이는 모델이 새로운 정보에 동적으로 반응하는 능력을 가지고 있음을 의미합니다.

실제로 LLM을 사용할 때 적절하게 조정해야 하는 두 가지 주요 설정이 있습니다. 첫째, 모델의 아키텍처와 사전 학습 방식입니다. 최신 모델들은 효율적인 어텐션 메커니즘(attention mechanism)과 경량화(quantization) 기술을 통합하여 더 빠르고 자원 효율적인 추론을 가능하게 합니다. 둘째, 모델의 지속적인 적응 및 업데이트 전략입니다. 이는 새로운 데이터와 변화하는 요구사항에 맞춰 모델을 주기적으로 재학습시키거나, 증분 학습(incremental learning) 방식을 통해 지식을 업데이트하는 것을 포함합니다. 단순함에도 불구하고 퓨샷 학습은 가장 효과적인 프롬프팅 전략 중 하나이며 실제 응용 분야에서 널리 사용되지만, 미래에는 모델 자체가 이러한 적응 과정을 자동화하는 방향으로 발전할 것입니다.

**지시 기반 AI와 정렬의 중요성**
지시 프롬프팅(Instruction prompting)은 LLM의 원하는 출력을 표현하는 더 직접적인 방법입니다. 이는 사용자의 의도를 모델에게 명확하게 전달하고, 모델이 특정 역할이나 스타일로 응답하도록 유도하는 데 필수적입니다. 이러한 접근 방식은 단순히 정보 검색을 넘어, 창의적인 콘텐츠 생성, 복잡한 문제 해결, 그리고 대화형 에이전트(conversational agent) 개발에 이르기까지 폭넓게 활용됩니다. LLM에 대한 연구는 지시 따르기 능력(instruction following capabilities) 개선에 크게 집중해 왔습니다. 특히, 모델의 안전성, 공정성, 그리고 투명성을 확보하기 위한 정렬(alignment) 기술은 AI 시스템의 사회적 수용성을 높이는 데 결정적인 역할을 합니다. LLM 정렬의 최근 발전으로 인해, 퓨샷 프롬프팅(few-shot prompting)과 결합될 수도 있는 지시 프롬프팅은 실제 응용 분야에서 일반적으로 사용되는 매우 효과적인 접근 방식입니다. 이는 인간 사용자와 AI 시스템 간의 협업을 강화하고, AI가 인간의 의도를 더 정확하게 이해하고 반영하도록 돕는 중요한 진보를 의미합니다.

**자동화된 추론 능력 향상**
위에서 설명한 프롬프팅 기술은 매우 효과적이지만, 현재 AI 연구는 단순히 프롬프트 최적화를 넘어 모델 자체의 근본적인 추론 능력과 문제 해결 프레임워크를 혁신하는 데 집중하고 있습니다. LLM은 이러한 문제에 본질적으로 어려움을 겪기 때문에, 복잡한 추론과 다단계 문제 해결을 위한 새로운 접근 방식이 활발히 연구되고 있습니다.

연쇄 사고(Chain of Thought, CoT) 프롬프팅 [10]은 모델의 프롬프트 내 예시에 연쇄 사고(즉, 일련의 중간 추론 단계)를 삽입하여 LLM의 추론 능력(reasoning capabilities)을 이끌어냅니다. 이는 모델이 단순히 최종 답변을 생성하는 것을 넘어, 문제 해결 과정을 명시적으로 보여주도록 유도함으로써 투명성과 신뢰성을 높입니다. 그러나 CoT 프롬프팅의 구현은 간단합니다. 이는 실제 세계의 복잡한 문제를 해결하기 위한 AI 시스템이 점차 인간의 인지 과정과 유사한 방식으로 발전하고 있음을 보여줍니다.

CoT 변형(CoT variants). CoT 프롬프팅의 효과와 인기로 인해 이 접근 방식의 수많은 확장 기능이 제안되었습니다. 예를 들어, 제로샷 CoT(zero-shot CoT) [11] 프롬프팅은 퓨샷 예시를 제거하고 대신 프롬프트 끝에 "단계별로 생각해 봅시다(Let’s think step by step)."라는 단어를 추가하여 모델이 문제 해결 근거를 생성하도록 장려합니다. 이러한 진화는 AI가 스스로 학습하고 추론하는 능력을 향상시키며, 복잡한 의사결정 과정에서 인간을 보조하는 역할을 강화합니다.

최소-최대 프롬프팅(Least-to-most prompting) [13]은 복잡한 문제를 여러 부분으로 명시적으로 분해함으로써 CoT 프롬프팅을 넘어섭니다. 이는 모듈식(modular) AI 설계의 중요성을 강조하며, 각 하위 문제를 독립적으로 해결한 후 그 결과를 통합하는 방식으로 전체 시스템의 효율성과 견고성을 높입니다.

"LLM의 이러한 모든 발전의 근간에는 여전히 토큰(token) 수준의 결정을 하나씩 왼쪽에서 오른쪽으로 생성하는 원래의 자기회귀(autoregressive) 메커니즘이 있다는 점은 놀라울 수 있습니다." - [14]에서 발췌

사고의 나무(Tree of thoughts, ToT) 프롬프팅 [14]. CoT 프롬프팅과 같은 기술은 다음 토큰 예측(next-token prediction)을 사용하여 단일 시도에서 해결책을 출력하는 왼쪽-오른쪽 생성(left-to-right generation) 접근 방식을 따릅니다. 그러나 ToT 프롬프팅은 복잡한 문제를 개별적으로 해결할 수 있는 일련의 더 간단한 문제(또는 "사고(thoughts)")로 분해하며, 다중 경로 탐색을 통해 최적의 해결책을 찾습니다. CoT 프롬프팅과 달리 ToT 프롬프팅은 문제를 해결할 때 단일 사고 경로를 따를 것을 요구하지 않습니다. 이는 AI가 다양한 관점에서 문제를 탐색하고, 필요에 따라 백트래킹(backtracking)하며, 인간의 문제 해결 과정과 유사한 유연성을 발휘하도록 돕습니다.

사고 그래프(Graph of Thoughts, GoT) 프롬프팅 [35, 36]. 후속 연구는 ToT 프롬프팅에 대한 연구를 추론을 위한 그래프 기반 전략으로 일반화했습니다. 이는 지식 표현(knowledge representation)과 추론(reasoning)을 위한 새로운 가능성을 열었으며, 모델이 단순히 선형적인 사고 과정을 따르는 것을 넘어 복잡한 관계와 상호작용을 이해하고 활용하도록 합니다. 이러한 접근 방식은 AI가 더욱 정교하고 인간적인 방식으로 문제를 해결할 수 있는 기반을 마련합니다.

**검색 증강 생성(RAG)의 진화**
검색 증강 생성(Retrieval Augmented Generation, RAG) [37]은 순수한 프롬프팅 기술은 아니지만, LLM이 겪는 지식 부족과 환각(hallucination) 문제를 해결하는 데 중요한 역할을 합니다. 이 기술은 외부 지식 소스에서 최신 정보를 검색하여 LLM의 응답을 보강함으로써, 모델의 사실성(factuality)과 신뢰성을 크게 향상시킵니다. 그러나 데이터를 처리하고 검색하는 방식과 프롬프트에 삽입되는 컨텍스트를 구성하는 방식은 성능에 상당한 영향을 미칠 수 있습니다. 따라서 RAG 시스템의 효과적인 구현을 위해서는 검색 품질, 관련성, 그리고 LLM의 컨텍스트 이해 능력을 종합적으로 평가하는 것이 필수적입니다.

생성된 지식 프롬프팅(Generated knowledge prompting) [39]은 외부 데이터베이스에서 컨텍스트를 검색하는 대신 LLM을 사용하여 프롬프트에 포함할 관련 컨텍스트를 생성하는 RAG의 흥미로운 대안입니다. 이외에도, 멀티모달 RAG(Multimodal RAG)와 같은 고급 RAG 기술은 텍스트뿐만 아니라 이미지, 오디오 등 다양한 형태의 데이터를 검색하여 LLM의 이해 및 생성 능력을 확장하고 있습니다. 이는 LLM이 더욱 풍부하고 다차원적인 방식으로 정보를 처리하고 활용할 수 있는 길을 열어줍니다.

**최근 연구 동향**
지금까지 다양한 프롬프팅 기술을 다루었지만, 최근 AI 연구는 단순히 프롬프트 최적화를 넘어 더 광범위하고 근본적인 문제 해결에 집중하고 있습니다. 이는 LLM이 실제 세계에 미치는 영향이 커짐에 따라, 기술적 진보와 함께 사회적 책임과 지속 가능성을 고려하는 방향으로 진화하고 있음을 반영합니다. 여기서는 이러한 변화의 핵심 동향을 다음과 같은 범주로 나누어 살펴보겠습니다.
*   **책임감 있는 AI 개발(Responsible AI Development)**: 편향 완화, 공정성, 투명성, 그리고 설명 가능한 AI(XAI)에 대한 연구.
*   **멀티모달 AI(Multimodal AI)**: 텍스트, 이미지, 오디오, 비디오 등 다양한 형태의 데이터를 통합하여 이해하고 생성하는 모델.
*   **경량화 및 효율성(Efficiency & Optimization)**: LLM의 크기를 줄이고 추론 속도를 높여 온디바이스(on-device) 및 저전력 환경에서 구동 가능하게 하는 기술.
*   **범용 AI 에이전트(General AI Agents)**: 복잡한 환경에서 자율적으로 목표를 설정하고, 계획을 수립하며, 도구를 사용하여 문제를 해결하는 지능형 에이전트.
*   **지속 가능한 AI(Sustainable AI)**: AI 모델의 학습 및 배포에 필요한 에너지 소비를 줄이고, 환경적 영향을 최소화하는 방법론.

각 범주에 대해 다양한 다른 연구가 다루어집니다. 이러한 연구는 단일 기술 발전에 그치지 않고, 여러 분야의 지식을 융합하여 AI의 미래를 형성하고 있습니다.

**AI 에이전트와 외부 도구 통합**
LLM은 강력하지만, 주목할 만한 한계가 있습니다! 이러한 한계는 AI가 실제 세계의 복잡한 문제를 해결하기 위해 외부 시스템과 상호작용하는 능력을 강화해야 할 필요성을 제기합니다. Toolformer [32]는 LLM과 외부 도구의 통합을 탐구한 최초의 연구 중 하나였습니다. 이는 AI가 단순한 언어 모델을 넘어, 능동적인 에이전트(agent)로서 기능할 수 있는 가능성을 열었습니다. 여기에서 우리는 이 데이터에 대해 LLM을 간단히 미세 조정할 수 있습니다. 이는 데이터 효율적인 학습(data-efficient learning)의 중요성을 강조하며, 소량의 고품질 데이터로도 모델의 기능을 크게 확장할 수 있음을 보여줍니다.

"LLM은 최신 정보에 접근할 수 없거나 정밀한 수학적 추론을 수행할 수 없는 것과 같은 본질적인 한계에 직면합니다... 실제 작업 해결을 위해 외부 도구를 자동으로 구성하는 기능을 현재 LLM에 강화하는 것은 이러한 단점을 해결하는 데 중요합니다." - [19]에서 발췌

Chameleon [19]은 위에서 언급된 LLM의 한계를 완화하는 것을 목표로 합니다. 이 프레임워크는 유연한 아키텍처를 통해 다양한 도구를 동적으로 조합하여 복잡한 작업을 해결합니다. Chameleon 프레임워크는 두 가지 주요 구성 요소를 가집니다. 이는 모듈식 AI 설계의 핵심 원칙을 보여주며, 각 구성 요소가 특정 기능을 담당하여 전체 시스템의 확장성과 유지보수성을 높입니다. 컨트롤러에게 특정 도구를 언제 사용할지 가르치기 위해, 우리는 인간의 전문 지식과 피드백을 시스템에 통합하는 휴먼 인 더 루프(human-in-the-loop) 접근 방식의 중요성을 강조합니다. 실험에서 Chameleon은 GPT-4를 사용하여 두 가지 복잡한 다중 모달(multi-modal)(즉, 텍스트와 이미지가 모두 포함됨) 추론 작업인 ScienceQA와 TabMWP에 적용되었습니다. 이는 멀티모달 AI의 발전이 실제 세계의 다양한 문제 해결에 얼마나 큰 영향을 미치는지 보여줍니다.

"우리는 고급 LLM의 자기 지시(self-instruct)를 통해 오픈 소스 LLM에 도구를 사용할 수 있는 능력을 부여하도록 설계된 간단하면서도 효과적인 방법인 GPT4Tools를 제안합니다." - [20]에서 발췌

GPT4Tools [20]. 다양한 논문에서 LLM이 퓨샷 방식으로 도구를 활용하는 능력을 보여주었지만, 오픈 소스 LLM의 역량 강화는 AI 기술의 민주화에 기여합니다. 먼저, 저자들은 강력한 교사 모델(teacher model)(즉, ChatGPT)에 프롬프트를 제공하여 관련 도구가 사용되는 예시를 생성하도록 함으로써 자기 지시 접근 방식을 사용하여 도구 사용 데이터셋을 생성합니다. 이는 합성 데이터 생성(synthetic data generation) 기술이 모델 학습에 어떻게 활용될 수 있는지를 보여주는 중요한 사례입니다. 데이터셋이 생성되면, 저랭크 적응(Low-Rank Adaptation, LoRA)을 사용하여 오픈 소스 LLM을 쉽게 미세 조정하여 다중 모달 도구의 도움을 받아 다양한 시각적 문제를 해결할 수 있습니다. 이는 효율적인 미세 조정(fine-tuning) 기법이 AI 모델의 접근성과 활용성을 높이는 데 필수적임을 시사합니다.

Gorilla [30]. 많은 연구에서 LLM과 고정된 도구 세트를 통합하는 것을 연구했지만, Gorilla는 AI가 동적으로 도구를 학습하고 활용하는 능력을 보여줍니다. 이 문제를 해결하기 위해 [30]의 저자들은 자기 지시 [21]를 사용하여 1,600개 이상의 다른 모델 API 사용 예시가 포함된 데이터셋을 구축합니다. 이는 자기 지도 학습(self-supervised learning)이 AI 에이전트의 자율성을 높이는 데 어떻게 기여하는지 보여주는 예시입니다.

HuggingGPT [31]는 도구 사용 접근 방식을 통해 LLM과 특수 딥러닝 모델(예: 이미지 인식, 비디오 감지, 텍스트 분류 등)의 통합을 탐구한다는 점에서 Gorilla와 상당히 유사합니다. 이는 AI 오케스트레이션(orchestration)의 중요성을 강조하며, 여러 AI 모델과 도구가 협력하여 복잡한 작업을 해결하는 시스템을 구축하는 데 집중합니다. 문제 해결은 네 단계로 분해됩니다. 이는 AI 에이전트의 표준 워크플로(workflow)를 제시하며, 각 단계에서 최적의 도구와 모델을 선택하고 실행하는 과정을 포함합니다.

**프로그램 지원 언어 모델**
"계산은 생성된 프로그램을 실행하는 데 사용되는 프로그램 인터프리터(program interpreter)에 위임될 수 있으며, 이로써 복잡한 계산을 추론 및 언어 이해와 분리합니다." - [41]에서 발췌

LLM을 외부 도구와 통합하는 것은 흥미로운 연구 분야이며, 이는 AI가 단순한 언어 이해를 넘어 강력한 계산 엔진(computational engine)으로 진화하고 있음을 보여줍니다. 대부분의 프롬프팅 기술은 복잡한 문제를 두 단계로 해결합니다. 이는 AI 시스템이 작업을 자동화하고, 인간의 개입 없이도 복잡한 워크플로(workflow)를 실행할 수 있는 기반을 제공합니다.

프로그램 지원 언어 모델(Program-Aided Language Model, PAL) [40]은 LLM이 해결책을 찾기 위해 문제를 일련의 중간 단계로 분해하는 작업을 맡는다는 점에서 CoT 프롬프팅과 유사합니다. 그러나 PAL은 모델이 직접 실행 가능한 코드를 생성하도록 함으로써, AI의 문제 해결 능력을 실제 컴퓨팅 환경으로 확장합니다.

"이는 연쇄 사고와 유사한 방법에서 추론 연쇄는 올바르지만 잘못된 답변을 생성할 수 있는 중요한 격차를 해소합니다." - [40]에서 발췌

사고 프로그램(Program of Thoughts, PoT) 프롬프팅 [41]은 i) 코드 증강 프롬프팅 기술(code-augmented prompting technique)을 사용하고 ii) 해결책을 도출하는 과정을 코드 인터프리터에 위임한다는 점에서 PAL과 상당히 유사합니다. PoT는 특히 기호 수학 라이브러리(symbolic math library)를 활용하여 AI가 정밀한 수학적 추론을 수행하도록 돕습니다. 높은 수준에서 PoT는 LLM이 복잡한 방정식을 해결할 수 없다는 점을 직접적으로 다루며, 하이브리드 AI 시스템(hybrid AI system)이 신경망과 전통적인 계산 방법을 결합하여 강점을 극대화하는 방법을 보여줍니다.

**컨텍스트 윈도우 관리 및 활용**
RAG의 최근 인기와 최첨단 LLM 내의 긴 컨텍스트 윈도우에 대한 강조를 고려할 때, AI 시스템이 방대한 양의 정보를 효율적으로 처리하고 관리하는 것이 중요한 과제로 부상하고 있습니다.

대규모 언어 모델은 관련 없는 컨텍스트에 쉽게 주의가 산만해질 수 있습니다 [22]. 이는 AI 시스템의 견고성(robustness)을 설계할 때 외부 정보의 필터링 및 우선순위 지정이 얼마나 중요한지를 보여줍니다. [22]에서 저자들은 현대 LLM의 주의 산만성(distractibility)을 연구했으며, 이는 AI 모델이 예상치 못한 입력에 어떻게 반응하는지에 대한 중요한 통찰을 제공합니다. 흥미롭게도, 관련 없는 정보가 컨텍스트에 포함될 때 이러한 모델의 성능은 급격히 저하됩니다. 이는 고품질 데이터와 정제된 입력이 AI 시스템의 안정적인 작동에 필수적임을 강조합니다.

"우리는 예시에 '문제 설명의 관련 없는 정보는 자유롭게 무시하세요'라는 지시 문장을 앞에 추가합니다." - [22]에서 발췌

중간에서 길을 잃다(Lost in the Middle) [23]. 생성형 LLM은 텍스트-투-텍스트 형식을 가지며, 긴 컨텍스트 내에서 정보를 활용하는 모델의 패턴을 이해하는 것이 중요합니다. 이러한 작업을 해결할 때 저자들은 i) 입력 컨텍스트의 길이(더 많은 문서 또는 키-값 쌍 사용)와 ii) 입력 내 관련 컨텍스트의 위치— 시작, 중간, 끝 —를 모두 제어합니다. 이는 AI 모델의 컨텍스트 이해 능력을 평가하는 데 중요한 방법론을 제공합니다. 이 시각화는 LLM이 컨텍스트의 시작과 끝에 있는 정보에 가장 많은 주의를 기울인다는 것을 보여줍니다. 이는 AI 모델이 인간과 유사한 인지 편향(cognitive bias)을 보일 수 있음을 시사하며, 이러한 편향을 이해하고 완화하는 연구의 중요성을 강조합니다.

대규모 언어 모델은 잠재 변수 모델(Latent Variable Models)입니다 [24]. LLM의 이론적 기반을 이해하는 것은 모델의 동작을 예측하고 제어하는 데 필수적입니다.

"인컨텍스트 학습은 광범위한 자연어 처리(NLP) 작업에 효과적인 기술로 입증되었습니다. 그러나 이는 사용되는 시연의 선택, 형식, 심지어 순서에도 민감합니다." - [24]에서 발췌

많은 논문이 이론적 관점에서 인컨텍스트 학습의 메커니즘을 연구했지만, 이론과 실제 사이의 간극을 메우는 것이 중요합니다. 이 공식화로부터 저자들은 모델 입력의 사후 확률(posterior probability)을 측정하기 위해 더 작은 언어 모델을 사용하는 가능한 최상의 퓨샷 예시를 선택하기 위한 실용적인 기술을 개발합니다. 이는 효과적인 학습을 위한 데이터 선택 전략이 AI 모델의 성능에 결정적인 영향을 미칠 수 있음을 보여줍니다.

**생성 능력 최적화 및 제어**
"SoT는 추론 효율성을 위한 데이터 중심 최적화의 초기 시도이며, 언어로 답변 구조를 명시적으로 계획함으로써 고품질 답변을 이끌어낼 잠재력을 보여줍니다." - [25]에서 발췌

사고의 골격(Skeleton-of-Thought, SoT) [25]은 LLM으로 출력을 생성하는 지연 시간(latency)을 줄이는 것을 목표로 하는 프롬프팅 기술입니다. 특히, 출력은 한 번에 하나의 토큰씩 순차적으로 생성됩니다(즉, 다음 토큰 예측(next token prediction) 사용). 이러한 순차적 디코딩(sequential decoding)의 한계를 극복하기 위해 병렬 처리(parallel processing) 기법이 활발히 연구되고 있습니다. [25]에서 저자들은 위에서 언급된 마지막 문제— 순차적 디코딩(sequential decoding)의 지연 시간 —를 해결하려고 시도합니다. 이는 LLM 아키텍처의 근본적인 최적화를 통해 실시간 AI 애플리케이션의 가능성을 넓힙니다. [25]에서 우리는 모델, 시스템 또는 하드웨어에 어떤 변경도 요구하지 않고 인간의 사고 및 글쓰기 과정을 모방함으로써 더 효율적인 디코딩 전략(decoding strategy)을 고안할 수 있음을 봅니다. 이는 생체 모방 AI(bio-inspired AI) 접근 방식이 효율적인 AI 시스템 설계에 기여할 수 있음을 보여줍니다.

골격의 각 요소를 병렬로 생성함으로써 추론 지연 시간(inference latency)을 크게 절약할 수 있습니다. 이는 실시간 AI 상호작용과 고성능 컴퓨팅 환경에서 LLM의 활용도를 높이는 데 결정적인 역할을 합니다.

방향성 자극 프롬프팅(Directional Stimulus Prompting) [27]. 미세 조정의 계산 비용을 고려할 때, 프롬프팅은 일반적으로 LLM으로 작업을 해결하는 가장 쉬운 방법입니다. 그러나 이는 LLM의 생성 출력을 보다 세밀하게 제어(controllable generation)하는 데 중점을 둡니다. 이 문제를 해결하기 위해 [27]의 저자들은 방향성 자극 프롬프팅(directional stimulus prompting, DSP)을 제안합니다. 이는 모델의 출력 스타일, 톤, 내용 등을 미세 조정(fine-grained control)하는 새로운 방법을 제시합니다.

밀도 연쇄 프롬프팅(Chain of Density Prompting) [28]. LLM의 최근 발전은 자동 요약(automatic summarization) 문제를 혁신했습니다. 특히, 생성된 콘텐츠의 품질과 정보 밀도(information density)를 최적화하는 데 중점을 둡니다.

"CoD로 생성된 요약은 바닐라 프롬프트로 GPT-4가 생성한 요약보다 더 추상적(abstractive)이고, 더 많은 융합(fusion)을 보이며, 선행 편향(lead bias)이 적습니다." - [28]에서 발췌

**기타 주목할 만한 연구 동향**
능동 프롬프팅(Active Prompting) [26]은 불확실성 기반 능동 학습(uncertainty-based active learning) 연구를 기반으로 특정 추론 문제를 해결하기 위해 가장 유용한 예시를 선택(및 주석 달기)하는 기술을 제공함으로써, 데이터 효율성(data efficiency)을 높이고 인간 피드백(human feedback)을 최적화하는 데 기여합니다. TaskMatrix [33]는 파운데이션 모델(foundation models)과 수백만 개의 다른 API의 통합을 고려하는 주목할 만한 문제에 대한 입장 또는 전망을 제시하는 입장 논문(position paper)입니다. 이는 AI 생태계(AI ecosystem)가 단순히 모델 개발을 넘어 다양한 서비스와 플랫폼의 통합으로 확장되고 있음을 보여줍니다. 마크 세트 프롬프팅(Set of Marks Prompting) [42]은 사전 훈련된 분할 모델(pretrained segmentation models)을 사용하여 이미지를 영역으로 분할하고, 시각적 AI(visual AI)가 텍스트와 이미지를 더욱 정밀하게 연결하는 방법을 탐구합니다. 다중 모달 CoT 프롬프팅(Multimodal CoT Prompting) [43]은 근거 및 답변 생성을 문제 해결 과정의 두 가지 별개의 단계로 처리함으로써 이미지와 텍스트를 모두 포함하는 입력으로 CoT 프롬프팅을 확장합니다. 이는 멀티모달 추론(multimodal reasoning) 능력을 강화하여 AI가 더욱 복잡한 현실 세계의 정보를 이해하도록 돕습니다. 자동 프롬프팅(automatic prompting)과 같은 메타 학습(meta-learning) 기법은 AI가 스스로 최적의 프롬프트를 생성하도록 발전하며, 미래 AI 시스템의 자율성을 더욱 높일 것입니다.

**결론**
이 개요에서 우리는 프롬프트 엔지니어링의 기본부터 지난 두 달 동안 제안된 최첨단 기술에 이르기까지, AI 연구의 광범위한 지형을 탐구했습니다! 이 게시물은 엄청난 양의 정보를 포함하고 있지만, AI 발전의 각 영역은 상호 연결되어 있으며, 전체 시스템의 성능과 신뢰성에 영향을 미친다는 것을 알 수 있습니다. 우리는 AI 시스템 설계 및 배포 시 다음과 같은 핵심 원칙을 상기해야 합니다.
*   AI 모델의 윤리적 사용과 사회적 영향을 항상 우선적으로 고려해야 합니다.
*   데이터의 품질과 다양성은 모델 성능의 핵심이며, 데이터 중심 접근 방식이 필수적입니다.
*   단순하고 효율적인 솔루션으로 시작하여, 필요에 따라 점진적으로 복잡성을 추가하는 것이 중요합니다.
*   지속적인 평가와 모니터링을 통해 AI 시스템의 성능을 유지하고 개선해야 합니다.

많은 문제는 간단한 지시 및 퓨샷 프롬프트를 통해 해결될 수 있습니다. 그러나 복잡한 추론이나 멀티모달 상호작용이 필요한 경우, 도구 통합, 프로그램 지원 모델, 또는 고급 RAG와 같은 전략이 필요합니다. 이러한 기술을 아는 것이 유용하지만, 그 사용 사례는 비교적 드물며, 명확하고 측정 가능한 성능 영향을 볼 때만 사용해야 합니다. AI의 미래는 기술적 혁신뿐만 아니라, 책임감 있는 개발과 인간 중심적인 접근 방식에 달려 있습니다.

뉴스레터가 처음이신가요? 안녕하세요! 저는 [저자 이름]이며, 이 AI Frontier 뉴스레터는 독자들이 최신 AI 연구 동향을 이해하고 실제 적용에 영감을 얻도록 돕습니다. 뉴스레터가 마음에 드신다면 구독, 공유 또는 X와 LinkedIn에서 저를 팔로우해 주세요!

구독

참고문헌(Bibliography)
[1] Saravia, Elvis, et al. “Prompt Engineering Guide”, https://github.com/dair-ai/Prompt-Engineering-Guide (2022).
[2] Radford, Alec, et al. "Language Models are Unsupervised Multitask Learners."
[3] Brown, Tom, et al. "Language models are few-shot learners." Advances in neural information processing systems 33 (2020): 1877-1901.
[4] Work, What Makes In-Context Learning. "Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?."
[5] Zhao, Zihao, et al. "Calibrate before use: Improving few-shot performance of language models." International conference on machine learning . PMLR, 2021.
[6] Ouyang, Long, et al. "Training language models to follow instructions with human feedback." Advances in neural information processing systems 35 (2022): 27730-27744.
[7] Ye, Seonghyeon, et al. "Investigating the effectiveness of task-agnostic prefix prompt for instruction following." Proceedings of the AAAI Conference on Artificial Intelligence . Vol. 38. No. 17. 2024.
[8] Thoppilan, Romal, et al. "Lamda: Language models for dialog applications." arXiv preprint arXiv:2201.08239 (2022).
[9] Rae, Jack W., et al. "Scaling language models: Methods, analysis & insights from training gopher." arXiv preprint arXiv:2112.11446 (2021).
[10] Wei, Jason, et al. "Chain-of-thought prompting elicits reasoning in large language models." Advances in neural information processing systems 35 (2022): 24824-24837.
[11] Kojima, Takeshi, et al. "Large language models are zero-shot reasoners." arXiv preprint arXiv:2205.11916 (2022).
[12] Wang, Xuezhi, et al. "Self-consistency improves chain of thought reasoning in language models." arXiv preprint arXiv:2203.11171 (2022).
[13] Zhou, Denny, et al. "Least-to-most prompting enables complex reasoning in large language models." arXiv preprint arXiv:2205.10625 (2022).
[14] Yao, Shunyu, et al. "Tree of thoughts: Deliberate problem solving with large language models." arXiv preprint arXiv:2305.10601 (2023).
[15] Zhang, Zhuosheng, et al. "Automatic chain of thought prompting in large language models." arXiv preprint arXiv:2210.03493 (2022).
[16] Fu, Yao, et al. "Complexity-based prompting for multi-step reasoning." The Eleventh International Conference on Learning Representations . 2022.
[17] Zheng, Chuanyang, et al. "Progressive-hint prompting improves reasoning in large language models." arXiv preprint arXiv:2304.09797 (2023).
[18] Khot, Tushar, et al. "Decomposed prompting: A modular approach for solving complex tasks." arXiv preprint arXiv:2210.02406 (2022).
[19] Lu, Pan, et al. "Chameleon: Plug-and-play compositional reasoning with large language models." Advances in Neural Information Processing Systems 36 (2024).
[20] Yang, Rui, et al. "Gpt4tools: Teaching large language model to use tools via self-instruction." Advances in Neural Information Processing Systems 36 (2024).
[21] Wang, Yizhong, et al. "Self-instruct: Aligning language models with self-generated instructions." arXiv preprint arXiv:2212.10560 (2022).
[22] Shi, Freda, et al. "Large language models can be easily distracted by irrelevant context." International Conference on Machine Learning . PMLR, 2023.
[23] Liu, Nelson F., et al. "Lost in the middle: How language models use long contexts." Transactions of the Association for Computational Linguistics 12 (2024): 157-173.
[24] Wang, Xinyi, et al. "Large language models are latent variable models: Explaining and finding good demonstrations for in-context learning." Advances in Neural Information Processing Systems 36 (2024).
[25] Ning, Xuefei, et al. "Skeleton-of-thought: Large language models can do parallel decoding." arXiv preprint arXiv:2307.15337 (2023).
[26] Diao, Shizhe, et al. "Active prompting with chain-of-thought for large language models." arXiv preprint arXiv:2302.12246 (2023).
[27] Li, Zekun, et al. "Guiding large language models via directional stimulus prompting." Advances in Neural Information Processing Systems 36 (2024).
[28] Adams, Griffin, et al. "From sparse to dense: GPT-4 summarization with chain of density prompting." arXiv preprint arXiv:2309.04269 (2023).
[29] Zhu, Zhaocheng, et al. "Large language models can learn rules." arXiv preprint arXiv:2310.07064 (2023).
[30] Patil, Shishir G., et al. "Gorilla: Large language model connected with massive apis." arXiv preprint arXiv:2305.15334 (2023).
[31] Shen, Yongliang, et al. "Hugginggpt: Solving ai tasks with chatgpt and its friends in huggingface." arXiv preprint arXiv:2303.17580 (2023).
[32] Schick, Timo, et al. "Toolformer: Language models can teach themselves to use tools." arXiv preprint arXiv:2302.04761 (2023).
[33] Liang, Yaobo, et al. "Taskmatrix. ai: Completing tasks by connecting foundation models with millions of apis." arXiv preprint arXiv:2303.16434 (2023).
[34] Chen, Shouyuan, et al. "Extending context window of large language models via positional interpolation." arXiv preprint arXiv:2306.15595 (2023).
[35] Besta, Maciej, et al. "Graph of Thoughts: Solving Elaborate Problems with Large Language Models." arXiv preprint arXiv:2308.09687 (2023).
[36] Yao, Yao, Zuchao Li, and Hai Zhao. "Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models." arXiv preprint arXiv:2305.16582 (2023).
[37] Lewis, Patrick, et al. "Retrieval-augmented generation for knowledge-intensive nlp tasks." Advances in Neural Information Processing Systems 33 (2020): 9459-9474.
[38] Ovadia, Oded, et al. "Fine-tuning or retrieval? comparing knowledge injection in llms." arXiv preprint arXiv:2312.05934 (2023).
[39] Liu, Jiacheng, et al. "Generated knowledge prompting for commonsense reasoning." arXiv preprint arXiv:2110.08387 (2021).
[40] Gao, Luyu, et al. "PAL: Program-aided Language Models." arXiv preprint arXiv:2211.10435 (2022).
[41] Chen, Wenhu, et al. "Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks." arXiv preprint arXiv:2211.12588 (2022).
[42] Yang, Jianwei, et al. "Set-of-mark prompting unleashes extraordinary visual grounding in gpt-4v." arXiv preprint arXiv:2310.11441 (2023).
[43] Zhang, Zhuosheng, et al. "Multimodal chain-of-thought reasoning in language models." arXiv preprint arXiv:2302.00923 (2023).