# **거대 언어 모델 선택 마스터클래스**

Author: Youssef Hosni
URL: https://youssefh.substack.com/p/large-language-model-selection-masterclass

============================================================

1년 동안 50% 할인

이 게시물은 Marina Wyss가 작성했습니다.

AI 엔지니어링을 처음 접할 때, 아마도 가장 큰 공급업체의 최신 LLM을 기본적으로 선택하게 될 것입니다. 그게 최고일 거라고 생각하시겠죠? 꼭 그렇지만은 않습니다. 2025년 말 현재, 우리는 수십 가지의 다양한 LLM 중에서 선택할 수 있으며, 각 LLM은 고유한 강점을 가지고 있습니다. 일부는 코딩에 뛰어나고, 다른 일부는 수학에 탁월하며, 어떤 것들은 자체 인프라(infrastructure)에서 실행되도록 특별히 구축되었습니다. 오늘 저는 여러분의 사용 사례(use case)에 맞는 모델을 실제로 선택하는 방법을 안내해 드리고자 합니다. 우리는 이 모델들이 서로 어떻게 다른지, 현재 사용 가능한 옵션들의 현황, 그리고 가장 중요하게는 언제 어떤 모델을 사용할지 결정하는 프레임워크(framework)를 다룰 것입니다. 시작해 봅시다.

내 모든 책을 40% 할인된 가격으로 만나보세요
내 모든 책을 버튼 하나로 40% 할인된 가격으로 만나보세요
유세프 호스니(Youssef Hosni) · 6월 17일

제 책과 로드맵(roadmap)을 묶은 번들(bundle)을 만들었습니다. 이제 버튼 하나로 모든 것을 원가보다 40% 저렴하게 구매할 수 있습니다. 이 번들에는 다음을 포함한 8권의 전자책(eBook)이 포함되어 있습니다. 전체 이야기 읽기

**LLM은 실제로 무엇이 다른가요?**

내 모든 책을 40% 할인된 가격으로 만나보세요

따라서 모델을 비교하기 전에, 하나의 LLM이 다른 LLM과 실제로 무엇이 다른지 이해해야 합니다. 세 가지 주요 요인이 모델의 기능과 "개성"을 정의합니다.

**1. 아키텍처(Architecture)**

모든 최신 LLM은 트랜스포머 아키텍처(Transformer architecture)라고 불리는 것으로 구축됩니다. 이것은 가장 최근의 AI 혁명을 이끈 돌파구였습니다. 기본적으로, 이것은 단어별로 처리하는 대신 전체 시퀀스(sequence)를 병렬로 처리합니다. 핵심은 모델이 문맥(context)에서 다른 단어들의 중요도를 측정하는 자기 어텐션(self-attention)이라는 것입니다. 따라서 매우 긴 텍스트 구절에 걸쳐 복잡한 관계를 이해할 수 있습니다. 하지만 그 프레임워크(framework) 내에는 알아야 할 몇 가지 주요 변형이 있습니다.

가장 큰 것은 덴스(Dense) 모델과 전문가 혼합(Mixture-of-Experts, 줄여서 MoE) 모델입니다. GPT 및 Claude와 같은 덴스 모델은 모든 단일 입력에 대해 모든 매개변수(parameter)를 활성화합니다. 모든 생각에 뇌 전체를 사용하는 것과 같다고 생각해보세요. Gemini, Mistral, Llama 4와 같은 MoE 모델은 다르게 작동합니다. 이들은 작업에 따라 "전문가" 하위 네트워크(sub-network)를 선택적으로 활성화합니다. 따라서 모든 뉴런(neuron)을 깨우는 대신, 해당 유형의 문제에 능숙한 특정 전문가에게 쿼리(query)를 라우팅(route)합니다. 이를 통해 쿼리당 실제 컴퓨팅(compute) 비용을 훨씬 낮게 유지하면서도 대규모로 확장할 수 있습니다.

1년 동안 50% 할인

다음으로 GPT-5의 새로운 접근 방식이 있습니다. 이들은 작업의 복잡성에 따라 다른 모델 간에 자동으로 전환되는 라우터 기반 아키텍처(router-based architecture)를 도입했습니다. 따라서 간단한 쿼리(query)는 빠른 모델이 처리하고, 어려운 문제는 심층 추론 모델로 라우팅(route)됩니다. DeepSeek은 다양한 복잡성의 쿼리에 대해 또 다른 접근 방식을 가지고 있습니다. DeepSeek은 강력한 기본 모델을 훈련한 다음, 명시적인 다단계 추론을 선호하도록 대규모 선호도 최적화(preference optimization)를 사용합니다. 대부분의 릴리스(release)는 "추론" 엔드포인트(endpoint)(즉, 어려운 문제에 대한 더 많은 단계)와 일반 채팅을 위한 더 낮은 지연 시간(latency)을 가진 "빠른/라이트" 엔드포인트를 노출합니다.

또 다른 큰 차이점은 컨텍스트 윈도우(context window)입니다. 이것은 기본적으로 모델이 한 번에 "기억"할 수 있는 텍스트의 양입니다. 우리는 낮은 수준의 128,000 토큰(token)부터 Llama 4 Scout의 1,000만 토큰에 이르기까지 모든 것을 보고 있습니다.

이제 아키텍처(architecture)는 모델이 정보를 처리하는 방법을 알려줍니다. 하지만 모델이 어떻게 생각하고 무엇을 아는지를 진정으로 결정하는 것은 다음과 같습니다…

**2. 훈련 데이터(Training data)**

내 모든 책을 40% 할인된 가격으로 만나보세요

이것은 아마도 모델이 무엇에 능숙한지를 결정하는 가장 큰 차별점일 것입니다. 예를 들어, GPT-5는 인터넷 데이터, 책, 학술 논문의 방대하고 다양한 혼합 데이터로 훈련됩니다. 그래서 GPT-5는 훌륭한 제너럴리스트(generalist)입니다. 거의 모든 것에 대해 이야기할 수 있습니다. 반면에 Gemini는 수조 개의 텍스트 토큰(token)뿐만 아니라 비디오 프레임(video frame)과 오디오(audio)도 흡수합니다. 이것이 Gemini가 강력한 기본 멀티모달(multimodal) 이해 능력을 가지는 이유입니다. Claude는 선별된 고품질 코드와 구조화된 문서에 중점을 둡니다. 이것이 Claude가 기술적 정확성과 복잡한 지시를 따르는 데 매우 뛰어난 이유 중 하나입니다. Grok은 X 플랫폼(platform) 데이터 스트림(data stream)에 실시간으로 접근하여, 현재 트위터(Twitter)에서 일어나고 있는 일에 대한 최신, 필터링되지 않은 관점을 가져옵니다. Llama 4는 텍스트, 이미지, 그리고 메타(Meta)의 소셜 플랫폼(social platform)으로 훈련되어, 다양한 양식(modality)에 걸쳐 균형 잡힌 기능을 제공합니다. DeepSeek은 광범위한 웹 텍스트와 함께 많은 양의 코드, 수학, 그리고 이중 언어(중국어/영어) 소스를 혼합합니다. 이러한 혼합은 기호 조작(symbolic manipulation)에 강하고 코딩(coding)에서 경쟁력을 가지며, 일반적인 영어 사용에도 견고합니다.

하지만 동일한 훈련 데이터(training data)를 사용하더라도 두 모델은 완전히 다르게 동작할 수 있습니다. 이는 초기 훈련 이후에 일어나는 일 때문이며, 모델이 실제 "개성"을 발전시키는 단계입니다.

**3. 정렬(Alignment)**

내 모든 책을 40% 할인된 가격으로 만나보세요

이는 세 번째 요소인 미세 조정(fine-tuning)과 정렬(alignment)로 이어집니다. 이것은 기본적으로 초기 훈련 이후에 발생하는 전문화 단계입니다. 여기에는 몇 가지 다른 프로세스(process)가 있습니다. 지도 미세 조정(Supervised Fine-Tuning, 줄여서 SFT)은 모델이 선별된 지시-응답 쌍으로부터 학습하는 방식입니다. 예를 들어 "이 문서를 요약해 주세요"와 같은 예시를 보여주고, 이어서 이상적인 요약을 제시합니다. 이것은 모델에게 지시를 따르고 특정 작업을 처리하는 방법을 가르칩니다. RLHF(인간 피드백 기반 강화 학습, Reinforcement Learning from Human Feedback)는 인간 검토자가 여러 모델 출력의 순위를 매기고, 모델이 높은 평가를 받은 응답을 선호하도록 학습하는 방식입니다. 이것이 모델의 행동을 인간의 가치와 선호도에 맞추는 방법입니다. 우리는 또한 RLHF의 더 새롭고 안정적인 대안인 DPO(직접 선호도 최적화, Direct Preference Optimization)를 가지고 있습니다. DPO는 별도의 보상 모델(reward model) 없이 선호도 데이터(preference data)에 직접 최적화합니다. 더 빠르고, 더 적은 컴퓨팅(compute) 자원을 사용하며, 2025년에는 점점 더 많이 채택되고 있습니다.

1년 동안 50% 할인

다른 회사들은 매우 다른 정렬(alignment) 철학을 가지고 있습니다. Anthropic은 Claude에 헌법적 AI(Constitutional AI)라는 것을 사용하는데, 이는 모델이 일련의 윤리적 원칙으로부터 학습하는 방식입니다. 이로 인해 Claude는 매우 신중하고 안전에 중점을 둡니다(때로는 지나치게 그렇기도 합니다). OpenAI의 GPT-5 접근 방식은 전통적인 RLHF와 새로운 라우터 시스템(router system)을 결합합니다. 기본 모델은 유용성과 무해성에 초점을 맞춘 광범위한 인간 피드백 루프(feedback loop)를 거치고, 그 다음 라우터 계층(router layer)은 적절한 모델 복잡성을 선택함으로써 또 다른 수준의 정렬(alignment)을 추가합니다. 이 이중 계층 접근 방식은 다양한 작업 유형에 걸쳐 기능과 안전의 균형을 맞추는 것을 목표로 합니다.

반면에 xAI는 Grok에 대해 다른 접근 방식을 취합니다. 경쟁사보다 10배 더 많은 강화 학습(reinforcement learning) 컴퓨팅(compute) 자원을 사용함에도 불구하고, 이들은 최소한의 콘텐츠 필터링(content filtering)을 적용합니다. 따라서 컴퓨팅 집약적인 RL 훈련을 통해 강력하게 정렬(align)되었지만, 논의할 내용에 대한 제약이 적은 모델을 얻게 됩니다. Claude나 GPT-5에 비해 응답이 더 자연스럽고 필터링되지 않습니다. DeepSeek의 정렬(alignment) 입장은 선호도 기반 최적화(preference-style optimization)를 통해 수학/논리 및 소프트웨어 작업의 정확성을 목표로 합니다. DeepSeek은 직설적이며 지나치게 장황하지 않은 경향이 있습니다.

요점은 이러한 정렬(alignment) 선택이 모델이 실제로 여러분에게 어떻게 응답하는지에 막대한 영향을 미친다는 것입니다. Claude는 GPT-5가 답할 만한 것을 거부할 수 있고, Grok은 다른 모델들이 제공하지 않을 필터링되지 않은 의견을 줄 수도 있습니다.

이제 특정 모델을 살펴보기 전에, 프로젝트에 대한 실질적인 결정을 내릴 때 아키텍처(architecture), 훈련 데이터(training data) 또는 정렬(alignment)보다 훨씬 더 중요한 한 가지가 있습니다. 그리고 대부분의 초보자들은 이를 완전히 간과합니다.

1년 동안 50% 할인

**오픈 소스(Open-source) vs. 오픈 웨이트(Open-weight) vs. 클로즈드 모델(Closed Models)**

내 모든 책을 40% 할인된 가격으로 만나보세요

라이선싱(Licensing). 이것은 대부분의 사람들이 깨닫는 것보다 훨씬 더 중요합니다. "오픈(open)"이라는 단어가 모든 모델에서 같은 의미를 가진다는 흔한 오해가 있지만, 실제로는 훨씬 더 혼란스럽습니다. 이를 세 가지 뚜렷한 범주로 나누어 설명하겠습니다.

첫째, 클로즈드 API 모델(closed API models)입니다. 이 모델들은 클라우드 서비스(cloud service)를 호출하며, 가중치(weight)는 전혀 사용할 수 없습니다. 모델 가중치(model weight)는 기본적으로 학습된 매개변수(parameter)입니다. 즉, 모델이 아는 모든 것을 인코딩(encode)하는 숫자 값입니다. 클로즈드 모델(closed model)의 경우, 이 가중치들은 공급업체의 서버(server)에 잠겨 있습니다. 여기에는 GPT-5, Claude, Gemini, Grok과 같은 유명 모델들이 포함됩니다. 여러분은 기본적으로 API를 통해 모델 접근 권한을 임대하는 것입니다.

1년 동안 50% 할인