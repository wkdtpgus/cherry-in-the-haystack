1년 동안 50% 할인

이 게시물은 Marina Wyss가 작성했습니다.

AI 엔지니어링 분야는 빠르게 진화하고 있으며, 2025년 현재 우리는 수많은 대규모 언어 모델(LLM) 중에서 선택해야 하는 즐거운 고민에 빠져 있습니다. 과거에는 가장 유명하거나 최신 모델을 무작정 선택하는 경향이 있었지만, 이제는 각 모델이 가진 고유한 강점과 약점을 이해하는 것이 필수적입니다. 어떤 모델은 복잡한 코딩 작업에 탁월하고, 또 어떤 모델은 정교한 수학적 추론에 능하며, 심지어 특정 인프라(infrastructure)에 최적화되어 자체 실행되도록 설계된 모델도 있습니다.
이 글에서는 여러분의 특정 사용 사례(use case)에 가장 적합한 LLM을 어떻게 선택할 수 있는지 심층적으로 탐구하고자 합니다. 우리는 모델들이 근본적으로 어떻게 다른지, 현재 시장에 나와 있는 주요 옵션들의 특징, 그리고 가장 중요하게는 언제 어떤 모델을 선택해야 하는지에 대한 명확한 프레임워크(framework)를 제시할 것입니다. 빠르게 변화하는 LLM 환경에서 현명한 결정을 내리는 데 필요한 통찰력을 얻어 가시길 바랍니다.

내 모든 책을 버튼 하나로 40% 할인된 가격으로 만나보세요
유세프 호스니(Youssef Hosni) · 6월 17일
제 책과 로드맵(roadmap)을 묶은 번들(bundle)을 만들었습니다. 이제 버튼 하나로 모든 것을 원가보다 40% 저렴하게 구매할 수 있습니다. 이 번들에는 다음을 포함한 8권의 전자책(eBook)이 포함되어 있습니다. 전체 이야기 읽기

**LLM은 실제로 무엇이 다른가요?**

모델을 효과적으로 비교하고 선택하기 위해서는, 단순히 성능 벤치마크(benchmark)를 넘어 하나의 LLM이 다른 LLM과 실제로 무엇이 다른지 깊이 이해해야 합니다. 모델의 기능과 고유한 "개성"을 정의하는 세 가지 핵심 요소는 다음과 같습니다.

**1. 아키텍처(Architecture)**

대부분의 최신 LLM은 트랜스포머 아키텍처(Transformer architecture)를 기반으로 구축됩니다. 이 아키텍처는 단어를 순차적으로 처리하는 대신 전체 시퀀스(sequence)를 병렬로 처리함으로써, 최근의 AI 혁명을 이끈 결정적인 기술적 돌파구를 마련했습니다. 트랜스포머의 핵심은 '자기 어텐션(self-attention)' 메커니즘으로, 모델이 문맥(context) 내에서 다른 단어들의 중요도를 측정하고 복잡한 관계를 이해할 수 있도록 합니다. 하지만 이 트랜스포머 프레임워크(framework) 내에서도 모델의 효율성과 성능에 영향을 미치는 여러 중요한 변형이 존재합니다. 최근에는 Mamba와 같은 상태 공간 모델(State-Space Model, SSM) 등 트랜스포머의 대안적 아키텍처도 연구되고 있지만, 아직 주류는 트랜스포머 기반 모델들입니다.

가장 큰 것은 덴스(Dense) 모델과 전문가 혼합(Mixture-of-Experts, 줄여서 MoE) 모델입니다. GPT 및 Claude와 같은 덴스 모델은 모든 단일 입력에 대해 모든 매개변수(parameter)를 활성화합니다. 모든 생각에 뇌 전체를 사용하는 것과 같다고 생각해보세요. Gemini, Mistral, Llama 4와 같은 MoE 모델은 다르게 작동합니다. 이들은 작업에 따라 "전문가" 하위 네트워크(sub-network)를 선택적으로 활성화합니다. 따라서 모든 뉴런(neuron)을 깨우는 대신, 해당 유형의 문제에 능숙한 특정 전문가에게 쿼리(query)를 라우팅(route)합니다. 이를 통해 쿼리당 실제 컴퓨팅(compute) 비용을 훨씬 낮게 유지하면서도 대규모로 확장할 수 있습니다.

다음으로 GPT-5의 새로운 접근 방식이 있습니다. 이들은 작업의 복잡성에 따라 다른 모델 간에 자동으로 전환되는 라우터 기반 아키텍처(router-based architecture)를 도입했습니다. 이는 단순한 쿼리(query)는 빠른 경량 모델이 처리하고, 복잡한 문제는 더 강력하고 심층적인 추론 모델로 라우팅(route)하여 효율성을 극대화하는 방식입니다. DeepSeek은 강력한 기본 모델을 훈련한 다음, 명시적인 다단계 추론을 선호하도록 대규모 선호도 최적화(preference optimization)를 사용합니다. 대부분의 릴리스(release)는 "추론" 엔드포인트(endpoint)(즉, 어려운 문제에 대한 더 많은 단계)와 일반 채팅을 위한 더 낮은 지연 시간(latency)을 가진 "빠른/라이트" 엔드포인트를 노출합니다. 이러한 동적 라우팅 방식은 사용자의 요청에 따라 최적의 자원을 할당하여 비용 효율성과 성능 균형을 맞추는 데 유리하지만, 모델의 일관된 동작을 예측하기 어려운 과제도 있습니다.

또 다른 큰 차이점은 컨텍스트 윈도우(context window)입니다. 이것은 기본적으로 모델이 한 번에 "기억"하고 처리할 수 있는 텍스트의 양입니다. 우리는 낮은 수준의 128,000 토큰(token)부터 Llama 4 Scout의 1,000만 토큰에 이르기까지 모든 것을 보고 있습니다. 이러한 대규모 컨텍스트 윈도우는 법률 문서 분석, 방대한 코드베이스 이해, 장편 소설 창작과 같이 매우 긴 문맥을 필요로 하는 작업에서 특히 유용합니다.

이제 아키텍처(architecture)는 모델이 정보를 처리하는 방법을 알려줍니다. 하지만 모델이 어떻게 생각하고 무엇을 아는지를 진정으로 결정하는 것은 다음과 같습니다…

**2. 훈련 데이터(Training data)**

훈련 데이터는 아마도 모델이 어떤 작업에 능숙한지를 결정하는 가장 큰 차별점일 것입니다. 모델의 지식 범위, 전문성, 그리고 편향(bias)까지도 훈련 데이터에 의해 크게 좌우됩니다. 예를 들어, GPT-5는 인터넷 데이터, 책, 학술 논문의 방대하고 다양한 혼합 데이터로 훈련되어 훌륭한 제너럴리스트(generalist)로서 거의 모든 주제에 대해 이야기할 수 있습니다.

반면에 Gemini는 수조 개의 텍스트 토큰(token)뿐만 아니라 비디오 프레임(video frame)과 오디오(audio)도 흡수합니다. 이것이 Gemini가 강력한 기본 멀티모달(multimodal) 이해 능력을 가지는 이유입니다. Claude는 선별된 고품질 코드와 구조화된 문서에 중점을 둡니다. 이것이 Claude가 기술적 정확성과 복잡한 지시를 따르는 데 매우 뛰어난 이유 중 하나입니다. Grok은 X 플랫폼(platform) 데이터 스트림(data stream)에 실시간으로 접근하여, 현재 트위터(Twitter)에서 일어나고 있는 일에 대한 최신, 필터링되지 않은 관점을 가져옵니다. Llama 4는 텍스트, 이미지, 그리고 메타(Meta)의 소셜 플랫폼(social platform)으로 훈련되어, 다양한 양식(modality)에 걸쳐 균형 잡힌 기능을 제공합니다. DeepSeek은 광범위한 웹 텍스트와 함께 많은 양의 코드, 수학, 그리고 이중 언어(중국어/영어) 소스를 혼합합니다. 이러한 혼합은 기호 조작(symbolic manipulation)에 강하고 코딩(coding)에서 경쟁력을 가지며, 일반적인 영어 사용에도 견고합니다.

최근에는 합성 데이터(synthetic data)와 고도로 큐레이션(curation)된 데이터셋(dataset)을 활용하여 모델을 훈련하는 경향이 두드러지고 있습니다. 이는 특정 도메인(domain)에 특화된 지식이나 특정 행동 양식을 주입하는 데 효과적입니다. 예를 들어, 의료 분야의 BioGPT나 금융 분야의 BloombergGPT와 같이 특정 산업의 방대한 전문 데이터를 학습하여 해당 분야에서 뛰어난 성능을 보이는 모델들이 등장하고 있습니다. 이러한 데이터 전략은 모델의 전문성을 극대화하지만, 동시에 훈련 데이터에 내재된 편향이 모델의 출력으로 이어질 수 있다는 점을 항상 고려해야 합니다.

하지만 동일한 훈련 데이터(training data)를 사용하더라도 두 모델은 완전히 다르게 동작할 수 있습니다. 이는 초기 훈련 이후에 일어나는 일 때문이며, 모델이 실제 "개성"을 발전시키는 단계입니다.

**3. 정렬(Alignment)**

정렬(alignment)은 모델의 동작을 인간의 가치, 의도, 그리고 선호도에 맞추는 과정입니다. 이는 기본 훈련 이후에 발생하는 전문화 단계로, 모델의 "개성"과 안전성을 형성하는 데 결정적인 역할을 합니다.

여기에는 몇 가지 다른 프로세스(process)가 있습니다. 지도 미세 조정(Supervised Fine-Tuning, 줄여서 SFT)은 모델이 선별된 지시-응답 쌍으로부터 학습하는 방식입니다. 예를 들어 "이 문서를 요약해 주세요"와 같은 예시를 보여주고, 이어서 이상적인 요약을 제시합니다. 이것은 모델에게 지시를 따르고 특정 작업을 처리하는 방법을 가르칩니다. RLHF(인간 피드백 기반 강화 학습, Reinforcement Learning from Human Feedback)는 인간 검토자가 여러 모델 출력의 순위를 매기고, 모델이 높은 평가를 받은 응답을 선호하도록 학습하는 방식입니다. 이것이 모델의 행동을 인간의 가치와 선호도에 맞추는 방법입니다. 우리는 또한 RLHF의 더 새롭고 안정적인 대안인 DPO(직접 선호도 최적화, Direct Preference Optimization)를 가지고 있습니다. DPO는 별도의 보상 모델(reward model) 없이 선호도 데이터(preference data)에 직접 최적화합니다. 더 빠르고, 더 적은 컴퓨팅(compute) 자원을 사용하며, 2025년에는 점점 더 많이 채택되고 있습니다.

다른 회사들은 매우 다른 정렬(alignment) 철학을 가지고 있습니다. Anthropic은 Claude에 헌법적 AI(Constitutional AI)라는 것을 사용하는데, 이는 모델이 일련의 윤리적 원칙으로부터 학습하는 방식입니다. 이로 인해 Claude는 매우 신중하고 안전에 중점을 둡니다(때로는 지나치게 그렇기도 합니다). OpenAI의 GPT-5 접근 방식은 전통적인 RLHF와 새로운 라우터 시스템(router system)을 결합합니다. 기본 모델은 유용성과 무해성에 초점을 맞춘 광범위한 인간 피드백 루프(feedback loop)를 거치고, 그 다음 라우터 계층(router layer)은 적절한 모델 복잡성을 선택함으로써 또 다른 수준의 정렬(alignment)을 추가합니다. 이 이중 계층 접근 방식은 다양한 작업 유형에 걸쳐 기능과 안전의 균형을 맞추는 것을 목표로 합니다.

반면에 xAI는 Grok에 대해 다른 접근 방식을 취합니다. 경쟁사보다 10배 더 많은 강화 학습(reinforcement learning) 컴퓨팅(compute) 자원을 사용함에도 불구하고, 이들은 최소한의 콘텐츠 필터링(content filtering)을 적용합니다. 따라서 Grok은 논의할 내용에 대한 제약이 적어, 다른 모델들이 제공하지 않을 필터링되지 않은 의견이나 더 직접적인 응답을 제공할 수 있습니다. DeepSeek의 정렬(alignment) 입장은 선호도 기반 최적화(preference-style optimization)를 통해 수학/논리 및 소프트웨어 작업의 정확성을 목표로 합니다. DeepSeek은 직설적이며 지나치게 장황하지 않은 경향이 있습니다.

이러한 정렬(alignment) 선택은 모델이 실제로 여러분에게 어떻게 응답하는지에 막대한 영향을 미칩니다. Claude는 특정 주제에 대한 답변을 거부할 수 있고, Grok은 논란의 여지가 있는 질문에 대해 더욱 대담한 입장을 취할 수 있습니다. 또한, RAG(Retrieval Augmented Generation)와 같은 기술은 모델이 최신 정보를 기반으로 응답하도록 외부 지식 기반을 활용함으로써, 모델의 내재된 지식과 별개로 외부적으로 "정렬"하는 실용적인 방법으로 각광받고 있습니다. 이는 모델의 안전성과 유용성 사이의 균형점을 찾는 지속적인 논쟁의 핵심입니다.

**모델 선택 프레임워크(Framework for Model Selection)**

이제 특정 모델의 기술적 특성을 이해했다면, 실제 프로젝트에 적용하기 위한 실질적인 선택 기준을 마련해야 합니다. 아키텍처, 훈련 데이터, 정렬만큼이나 중요한, 아니 어쩌면 그 이상으로 중요한 요소들이 있습니다. 대부분의 초보자들이 간과하는 이 요소들은 바로 비용, 성능, 개인 정보 보호, 그리고 라이선싱(licensing)입니다.

1.  **성능 및 비용 효율성**: 단순히 최고 성능의 모델을 선택하기보다는, 특정 사용 사례에 필요한 정확도와 속도를 만족시키면서 가장 비용 효율적인 모델을 찾아야 합니다. 예를 들어, 내부 문서 요약에는 최신 플래그십(flagship) 모델이 아닌 경량 모델로도 충분할 수 있습니다.
2.  **지연 시간(Latency) 및 처리량(Throughput)**: 실시간 고객 지원 챗봇(chatbot)과 같이 빠른 응답이 필요한 애플리케이션의 경우, 지연 시간이 짧은 모델이 필수적입니다. 반면, 배치(batch) 처리 작업에서는 처리량이 더 중요할 수 있습니다.
3.  **데이터 주권(Data Sovereignty) 및 개인 정보 보호**: 민감한 데이터를 다루는 경우, 데이터가 어디에 저장되고 처리되는지, 그리고 해당 지역의 규제(예: GDPR, 국내 개인정보보호법)를 준수하는지 확인해야 합니다. 온프레미스(on-premise) 배포나 특정 클라우드 환경 내에서의 모델 실행이 요구될 수 있습니다.
4.  **확장성(Scalability) 및 유연성(Flexibility)**: 비즈니스 성장과 함께 모델 사용량이 증가할 때 원활하게 확장할 수 있는지, 그리고 기존 시스템과의 통합이 용이한지 고려해야 합니다.
5.  **커뮤니티 지원 및 생태계**: 특히 오픈 소스 모델의 경우, 활발한 개발자 커뮤니티와 풍부한 생태계는 문제 해결, 기능 확장, 그리고 장기적인 유지보수에 큰 도움이 됩니다.

이러한 실용적인 고려 사항들은 모델의 기술적 사양만큼이나 중요하며, 프로젝트의 성공에 결정적인 영향을 미칩니다.

**오픈 소스(Open-source) vs. 오픈 웨이트(Open-weight) vs. 클로즈드 모델(Closed Models)**

라이선싱(Licensing)은 대부분의 사람들이 깨닫는 것보다 훨씬 더 중요합니다. "오픈(open)"이라는 단어가 모든 모델에서 같은 의미를 가진다는 흔한 오해가 있지만, 실제로는 훨씬 더 복잡한 스펙트럼(spectrum)을 가지고 있습니다. 이를 세 가지 뚜렷한 범주로 나누어 설명하겠습니다.

첫째, **클로즈드 API 모델(Closed API models)**입니다. 이 모델들은 클라우드 서비스(cloud service)를 호출하며, 가중치(weight)는 전혀 사용할 수 없습니다. 모델 가중치(model weight)는 기본적으로 학습된 매개변수(parameter)입니다. 즉, 모델이 아는 모든 것을 인코딩(encode)하는 숫자 값입니다. 클로즈드 모델(closed model)의 경우, 이 가중치들은 공급업체의 서버(server)에 잠겨 있습니다. 여기에는 GPT-5, Claude, Gemini, Grok과 같은 유명 모델들이 포함됩니다. 여러분은 기본적으로 API를 통해 모델 접근 권한을 임대하는 것입니다. 이러한 모델은 사용하기 쉽고 강력하지만, 공급업체 종속(vendor lock-in), 비용 예측의 어려움, 그리고 데이터 개인 정보 보호에 대한 우려가 있을 수 있습니다.

둘째, **오픈 웨이트 모델(Open-weight models)**입니다. 이 모델들은 가중치(weights)를 공개하지만, 때로는 상업적 사용에 제한이 있는 라이선스(license)를 가질 수 있습니다. Llama 2, Mistral, Falcon과 같은 모델들이 대표적인 예입니다. 이들은 모델 가중치를 다운로드하여 자체 서버에 배포하거나 미세 조정(fine-tuning)할 수 있는 유연성을 제공합니다. 이는 데이터 주권을 확보하고, 특정 사용 사례에 모델을 최적화하며, API 호출 비용을 절감할 수 있는 큰 장점이 있습니다. 하지만 모델을 직접 호스팅(hosting)하기 위한 컴퓨팅(compute) 자원과 기술적 전문성이 필요합니다.

셋째, **진정한 오픈 소스 모델(Truly Open-source models)**입니다. 이 모델들은 모델 가중치뿐만 아니라, 모델 아키텍처, 훈련 데이터셋, 그리고 훈련 코드까지 모두 공개합니다. Pythia, Dolly 2.0과 같은 모델들이 이 범주에 속합니다. 이들은 최대의 투명성과 제어권을 제공하며, 커뮤니티가 모델을 자유롭게 수정하고 개선하며 새로운 연구를 수행할 수 있도록 합니다. 이는 혁신을 촉진하고 특정 윤리적 요구사항에 맞춰 모델을 완전히 맞춤 설정할 수 있게 하지만, 일반적으로 오픈 웨이트 모델이나 클로즈드 모델에 비해 초기 성능이 낮을 수 있으며, 자체적으로 모델을 관리하고 개선해야 하는 부담이 있습니다.

결론적으로, 여러분의 프로젝트에 어떤 LLM을 선택할지는 단순히 "최고의" 모델을 찾는 것을 넘어섭니다. 모델의 기술적 특성, 비용 제약, 개인 정보 보호 요구 사항, 그리고 장기적인 전략을 모두 고려하여 가장 적합한 라이선싱 모델과 배포 방식을 결정해야 합니다. 이러한 다각적인 접근 방식이 성공적인 LLM 애플리케이션(application) 구축의 핵심입니다.