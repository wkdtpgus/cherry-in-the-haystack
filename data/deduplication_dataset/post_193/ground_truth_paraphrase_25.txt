1년 동안 50% 할인

AI 엔지니어링, LLM 선택의 새로운 지평

이 게시물은 Marina Wyss가 작성했습니다.

인공지능 엔지니어링 분야에 첫발을 내딛는 분들이라면, 아마도 주요 공급사의 최신 대규모 언어 모델(LLM)을 자연스럽게 우선 고려하실 것입니다. 이를 최적의 선택이라 여기기 쉽지만, 실제로는 그렇지 않은 경우가 많습니다. 2025년 말 현재, 우리는 수십 가지의 다양한 LLM 중에서 선택할 수 있으며, 각 모델은 고유한 강점과 특성을 지닙니다. 어떤 모델은 코딩 작업에 특화되어 있고, 또 다른 모델은 복잡한 수학 문제 해결에 탁월하며, 일부는 특정 인프라(infrastructure)에 최적화되어 자체적으로 구동되도록 설계되기도 합니다. 오늘 저는 여러분의 구체적인 사용 사례(use case)에 가장 적합한 모델을 현명하게 고르는 방법을 안내해 드리고자 합니다. 우리는 이 모델들이 서로 어떤 점에서 차이를 보이는지, 현재 시장에 나와 있는 주요 옵션들의 현황은 어떠한지, 그리고 무엇보다 중요한 것은 언제 어떤 모델을 활용할지 결정하는 데 필요한 명확한 프레임워크(framework)를 심도 있게 다룰 것입니다. 이제 본격적으로 시작해 봅시다.

내 모든 책을 버튼 하나로 40% 할인된 가격으로 만나보세요
유세프 호스니(Youssef Hosni) · 6월 17일

제 책과 로드맵(roadmap)을 묶은 번들(bundle)을 만들었습니다. 이제 버튼 하나로 모든 것을 원가보다 40% 저렴하게 구매할 수 있습니다. 이 번들에는 다음을 포함한 8권의 전자책(eBook)이 포함되어 있습니다. 전체 이야기 읽기

**LLM, 어떤 면에서 차이가 있을까요?**

그러므로 모델들을 서로 견주어 보기 전에, 각 대규모 언어 모델(LLM)이 어떠한 면에서 차이를 보이는지 정확히 파악하는 것이 중요합니다. 주로 세 가지 핵심 요소가 각 모델의 역량과 고유한 특성을 형성합니다. 이러한 이해는 단순히 이론적인 지식을 넘어, 실제 프로젝트에 가장 적합한 도구를 선택하는 실용적인 의사결정에 필수적입니다. 단순히 "가장 강력한" 모델을 찾는 것이 아니라, "우리 프로젝트에 가장 적합한" 모델을 찾아야 합니다.

**1. 아키텍처(Architecture)**

현대의 모든 대규모 언어 모델(LLM)은 '트랜스포머 아키텍처(Transformer architecture)'라는 구조를 기반으로 합니다. 이 구조는 최근 인공지능 분야의 혁신을 주도한 핵심 기술입니다. 근본적으로, 이 방식은 개별 단위를 순차적으로 처리하는 대신 전체 데이터 열(sequence)을 동시에 병렬적으로 다룹니다. 이 아키텍처의 핵심 요소는 '자기 어텐션(self-attention)' 메커니즘으로, 모델이 문맥(context) 속에서 각 단어의 상대적 중요도를 평가할 수 있게 합니다. 이를 통해 모델은 매우 긴 텍스트 구절에서도 복잡한 의미 관계를 효과적으로 파악할 수 있습니다. 하지만 이 기본 프레임워크(framework) 내에서도 몇 가지 중요한 변형이 존재하며, 이를 이해하는 것이 중요합니다.

주요 구분점은 '덴스(Dense) 모델'과 '전문가 혼합(Mixture-of-Experts, 약칭 MoE) 모델'입니다. GPT나 Claude 같은 덴스 모델은 모든 입력에 대해 모델의 모든 매개변수(parameter)를 동원합니다. 이는 마치 모든 사고 과정에 뇌 전체를 활용하는 것에 비유할 수 있습니다. 반면 Gemini, Mistral, Llama 4와 같은 MoE 모델은 다른 방식으로 기능합니다. 이들은 특정 작업의 성격에 따라 '전문가' 서브 네트워크(sub-network)를 선별적으로 활성화합니다. 이 접근 방식은 쿼리(query)당 실제 컴퓨팅(compute) 비용을 현저히 낮추면서도 대규모 확장을 가능하게 합니다. 또한, MoE 모델은 특정 유형의 작업에 더 빠르게 응답하거나, 특정 도메인에 특화된 지식을 더 효율적으로 활용할 수 있다는 장점도 있습니다.

다음으로, GPT-5는 작업의 복잡도에 따라 자동으로 다른 모델 간에 전환되는 '라우터 기반 아키텍처(router-based architecture)'라는 새로운 접근 방식을 도입했습니다. 따라서 간단한 쿼리(query)는 신속한 모델이 처리하고, 더 복잡한 문제는 심층 추론 모델로 라우팅(route)됩니다. DeepSeek은 다양한 복잡성의 쿼리에 대해 또 다른 방식을 취합니다. 이들은 강력한 기본 모델을 훈련한 후, 명시적인 다단계 추론을 선호하도록 '대규모 선호도 최적화(preference optimization)'를 적용합니다. 대부분의 릴리스(release)는 '추론' 엔드포인트(endpoint)(즉, 어려운 문제에 대한 더 많은 단계)와 일반 채팅을 위한 더 낮은 지연 시간(latency)을 가진 '빠른/라이트' 엔드포인트를 제공합니다.

또 다른 큰 차이점은 '컨텍스트 윈도우(context window)'입니다. 이는 기본적으로 모델이 한 번에 '기억'하고 처리할 수 있는 텍스트의 양을 의미합니다. 우리는 낮은 수준의 128,000 토큰(token)부터 Llama 4 Scout의 1,000만 토큰에 이르는 다양한 범위를 목격하고 있습니다. 컨텍스트 윈도우의 크기는 모델이 장문의 문서 요약, 긴 대화 유지, 또는 복잡한 코드 베이스 분석 등 얼마나 넓은 범위의 정보를 다룰 수 있는지를 결정합니다.

최근에는 '멀티모달 아키텍처(Multimodal Architectures)'의 중요성도 커지고 있습니다. 이는 텍스트뿐만 아니라 이미지, 오디오, 비디오 등 다양한 형태의 데이터를 동시에 처리하고 이해하도록 설계된 모델을 의미합니다. 이러한 아키텍처는 단순히 텍스트 기반 모델에 다른 모달리티를 추가하는 것을 넘어, 처음부터 여러 모달리티 간의 복잡한 관계를 학습하도록 구축됩니다.

이제 아키텍처(architecture)는 모델이 정보를 처리하는 방식을 알려줍니다. 하지만 모델이 어떻게 생각하고 무엇을 아는지를 진정으로 결정하는 것은 다음과 같습니다…

**2. 훈련 데이터(Training data)**

이 요소는 아마도 특정 모델이 어떤 영역에서 탁월한 성능을 발휘하는지를 결정하는 가장 핵심적인 차이점일 것입니다. 예를 들어, GPT-5는 인터넷 데이터, 책, 학술 논문 등 방대하고 다양한 혼합 데이터로 훈련됩니다. 따라서 GPT-5는 뛰어난 '제너럴리스트(generalist)'로서 거의 모든 주제에 대해 논의할 수 있습니다. 반면에 Gemini는 수조 개의 텍스트 토큰(token)뿐만 아니라 비디오 프레임(video frame)과 오디오(audio) 데이터까지 흡수합니다. 이것이 Gemini가 강력한 기본 '멀티모달(multimodal)' 이해 능력을 가지는 이유입니다. Claude는 선별된 고품질 코드와 구조화된 문서에 중점을 둡니다. 이것이 Claude가 기술적 정확성과 복잡한 지시를 따르는 데 매우 뛰어난 이유 중 하나입니다. Grok은 X 플랫폼(platform)의 실시간 데이터 스트림(data stream)에 접근하여, 현재 트위터(Twitter)에서 일어나고 있는 일에 대한 최신, 필터링되지 않은 관점을 제공합니다. Llama 4는 텍스트, 이미지, 그리고 메타(Meta)의 소셜 플랫폼(social platform) 데이터로 훈련되어, 다양한 양식(modality)에 걸쳐 균형 잡힌 기능을 제공합니다. DeepSeek은 광범위한 웹 텍스트와 함께 많은 양의 코드, 수학, 그리고 이중 언어(중국어/영어) 소스를 혼합합니다. 이러한 데이터 혼합은 기호 조작(symbolic manipulation)에 강하고 코딩(coding)에서 경쟁력을 가지며, 일반적인 영어 사용에도 견고합니다.

단순히 데이터의 양뿐만 아니라 '데이터 큐레이션(Data Curation)' 과정의 품질도 매우 중요합니다. 모델의 성능과 편향성은 훈련 데이터의 선정, 정제, 필터링 방식에 크게 좌우됩니다. 윤리적 고려사항과 잠재적 편향성 제거 노력은 모델의 신뢰성을 결정하는 핵심 요소입니다. 또한, '도메인 특화 데이터(Domain-specific Data)'를 활용한 훈련은 특정 산업이나 분야에서 고도로 전문화된 LLM을 만드는 데 필수적입니다. 법률, 의료, 금융과 같은 분야에서는 일반적인 웹 데이터로는 얻을 수 없는 깊이 있는 지식과 전문 용어 이해가 필요합니다. 최근에는 '합성 데이터(Synthetic Data)'를 생성하여 훈련에 활용하는 경향도 증가하고 있습니다. 이는 실제 데이터의 한계를 보완하고, 특정 시나리오에 대한 모델의 이해도를 높이는 데 기여합니다.

하지만 동일한 훈련 데이터(training data)를 사용하더라도 두 모델은 완전히 다르게 동작할 수 있습니다. 이는 초기 훈련 이후에 일어나는 일 때문이며, 모델이 실제 '개성'을 발전시키는 단계입니다.

**3. 정렬(Alignment)**

다음은 세 번째 중요 요소인 '미세 조정(fine-tuning)'과 '정렬(alignment)'에 대한 논의로 이어집니다. 이 과정은 기본적으로 초기 대규모 훈련을 마친 후 모델이 특정 목적에 맞게 전문화되는 단계입니다. 여기에는 몇 가지 다른 프로세스(process)가 포함됩니다. '지도 미세 조정(Supervised Fine-Tuning, 약칭 SFT)'은 모델이 선별된 지시-응답 쌍으로부터 학습하는 방식입니다. 예를 들어 "이 문서를 요약해 주세요"와 같은 예시를 보여주고, 이어서 이상적인 요약을 제시합니다. 이것은 모델에게 지시를 따르고 특정 작업을 처리하는 방법을 가르칩니다. 'RLHF(인간 피드백 기반 강화 학습, Reinforcement Learning from Human Feedback)'는 인간 검토자가 여러 모델 출력의 순위를 매기고, 모델이 높은 평가를 받은 응답을 선호하도록 학습하는 방식입니다. 이것이 모델의 행동을 인간의 가치와 선호도에 맞추는 방법입니다.

또한, RLHF보다 더 새롭고 안정적인 대안으로 '직접 선호도 최적화(Direct Preference Optimization, DPO)' 기법이 있습니다. DPO는 별도의 보상 모델(reward model) 없이 선호도 데이터(preference data)에 직접 최적화 과정을 적용합니다. 이 방식은 처리 속도가 더 빠르고, 필요한 컴퓨팅(compute) 자원도 적어 2025년 들어 채택률이 꾸준히 증가하고 있습니다.

다른 회사들은 매우 다른 '정렬(alignment)' 철학을 가지고 있습니다. Anthropic은 Claude에 '헌법적 AI(Constitutional AI)'라는 것을 사용하는데, 이는 모델이 일련의 윤리적 원칙으로부터 학습하는 방식입니다. 이로 인해 Claude는 매우 신중하고 안전에 중점을 둡니다(때로는 지나치게 그렇기도 합니다). OpenAI의 GPT-5 접근 방식은 전통적인 RLHF와 새로운 라우터 시스템(router system)을 결합합니다. 기본 모델은 유용성과 무해성에 초점을 맞춘 광범위한 인간 피드백 루프(feedback loop)를 거치고, 그 다음 라우터 계층(layer)은 적절한 모델 복잡성을 선택함으로써 또 다른 수준의 정렬(alignment)을 추가합니다. 이 이중 계층 접근 방식은 다양한 작업 유형에 걸쳐 기능과 안전의 균형을 맞추는 것을 목표로 합니다.

반면에 xAI는 Grok에 대해 다른 접근 방식을 취합니다. 경쟁사보다 10배 더 많은 강화 학습(reinforcement learning) 컴퓨팅(compute) 자원을 사용함에도 불구하고, 이들은 최소한의 콘텐츠 필터링(content filtering)을 적용합니다. 따라서 컴퓨팅 집약적인 RL 훈련을 통해 강력하게 정렬(align)되었지만, 논의할 내용에 대한 제약이 적은 모델을 얻게 됩니다. Claude나 GPT-5에 비해 응답이 더 자연스럽고 필터링되지 않습니다. DeepSeek의 정렬(alignment) 입장은 선호도 기반 최적화(preference-style optimization)를 통해 수학/논리 및 소프트웨어 작업의 정확성을 목표로 합니다. DeepSeek은 직설적이며 지나치게 장황하지 않은 경향이 있습니다.

핵심은 이러한 '정렬(alignment)' 방식의 선택이 모델이 사용자에게 반응하는 방식에 지대한 영향을 미친다는 점입니다. 예를 들어, Claude는 GPT-5가 응답할 수 있는 질문에도 답변을 거부할 수 있으며, Grok은 다른 모델에서는 접하기 어려운 필터링되지 않은 견해를 제시할 수도 있습니다. 이러한 정렬 과정은 '정렬의 난제(Challenges of Alignment)'라고 불릴 만큼 복잡합니다. 인간의 가치와 선호도가 다양하고 때로는 모순될 수 있기 때문에, 모든 상황에서 완벽하게 "올바른" 행동을 정의하고 모델에 주입하는 것은 매우 어렵습니다. 결국, 정렬은 모델의 '안전성(Safety)'과 '견고성(Robustness)'을 확보하는 핵심적인 목표와 연결되며, 이는 모델이 유해한 콘텐츠를 생성하거나 예상치 못한 방식으로 오작동하는 것을 방지하는 데 중요합니다. 또한, 정렬은 모델의 '페르소나(Model Persona)'를 형성하여, 모델이 어떤 어조와 태도로 사용자와 상호작용할지를 결정합니다.

이제 특정 모델을 살펴보기 전에, 프로젝트에 대한 실질적인 결정을 내릴 때 아키텍처(architecture), 훈련 데이터(training data) 또는 정렬(alignment)보다 훨씬 더 중요한 한 가지가 있습니다. 그리고 대부분의 초보자들은 이를 완전히 간과합니다.

**오픈 소스(Open-source) vs. 오픈 웨이트(Open-weight) vs. 클로즈드 모델(Closed Models)**

라이선싱(Licensing). 이 부분은 대다수 사람이 인지하는 것보다 훨씬 더 큰 중요성을 지닙니다. '오픈(open)'이라는 용어가 모든 모델에 동일하게 적용된다는 일반적인 오해가 있지만, 실제로는 그 의미가 훨씬 복잡하고 다양합니다. 이를 세 가지 뚜렷한 범주로 나누어 설명하겠습니다.

첫 번째 유형은 '클로즈드 API 모델(closed API models)'입니다. 이 모델들은 클라우드 서비스를 통해 접근하며, 핵심적인 가중치(weight)는 전혀 공개되지 않습니다. 모델 가중치(model weight)는 본질적으로 모델이 학습한 매개변수(parameter)로, 모델의 모든 지식을 수치 값으로 담고 있습니다. 클로즈드 모델(closed model)의 경우, 이러한 가중치들은 서비스 제공업체의 서버(server) 내부에 안전하게 보관됩니다. GPT-5, Claude, Gemini, Grok과 같은 잘 알려진 모델들이 이 범주에 속합니다. 사용자는 기본적으로 API를 통해 모델 사용 권한을 임대하는 형태입니다.

두 번째 범주는 '오픈 웨이트 모델(Open-weight models)'입니다. 이 모델들은 가중치(weight)가 공개되어 다운로드할 수 있지만, 사용 라이선스(license)는 특정 제한을 포함할 수 있습니다. 예를 들어, Meta의 Llama 2는 상업적 용도로 사용하려면 특정 조건(예: 사용자 수 제한)을 충족해야 합니다. 이러한 모델은 사용자가 자체 서버에 배포하여 커스터마이징(customization)하거나 미세 조정(fine-tuning)할 수 있다는 장점이 있습니다. 이는 데이터 프라이버시(data privacy)가 중요한 기업 환경이나, 특정 도메인에 모델을 최적화하려는 경우 매우 유리합니다. 하지만 자체적으로 모델을 관리하고 운영해야 하므로 추가적인 기술 역량과 인프라(infrastructure) 투자가 필요할 수 있습니다.

마지막으로 '진정한 오픈 소스 모델(Truly Open-source models)'이 있습니다. 이 모델들은 Apache 2.0과 같은 개방적인 라이선스(license) 아래 가중치와 코드 모두가 공개됩니다. 이는 사용자가 모델을 자유롭게 사용, 수정, 배포할 수 있음을 의미합니다. Hugging Face 생태계에서 찾아볼 수 있는 많은 모델들이 여기에 해당합니다. 진정한 오픈 소스 모델의 가장 큰 장점은 투명성, 커뮤니티 주도의 개발 및 개선, 그리고 어떤 제약도 없이 모델을 완전히 통제할 수 있다는 점입니다. 그러나 클로즈드 모델에 비해 최신 성능이나 안정성 면에서 뒤처질 수 있으며, 상업적 지원이 부족할 수 있다는 단점도 존재합니다.

결론적으로, 라이선싱(Licensing)은 단순히 법적 문제를 넘어, 비용 효율성, 데이터 주권, 장기적인 기술 전략에 지대한 영향을 미칩니다. 클로즈드 모델은 편리하지만 종속성을 낳고, 오픈 웨이트 모델은 유연성을 제공하지만 책임이 따르며, 진정한 오픈 소스 모델은 완전한 자유를 주지만 자체적인 노력이 필요합니다. 프로젝트의 요구사항과 제약 조건을 면밀히 검토하여 가장 적절한 라이선스 모델을 선택하는 것이 성공적인 AI 도입의 첫걸음입니다.