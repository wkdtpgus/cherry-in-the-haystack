OpenAI가 GPT-OSS를 출시한 것은 6년 전 GPT-2 이후 주요 오픈 소스 LLM(거대 언어 모델) 출시입니다. 이 기간 동안 LLM의 기능은 극적으로 향상되었습니다. 이 모델 자체는 DeepSeek, Qwen, Kimi 등 기존 오픈 모델과 비교하여 기능 면에서 반드시 비약적인 발전이라고 할 수는 없지만, 이 기간 동안 LLM이 어떻게 변화했는지 다시 살펴보는 좋은 기회를 제공합니다.

**이전 오픈 소스 GPT 모델과의 차이점**
GPT-OSS는 한 번에 하나의 토큰(token)을 생성하는 자기회귀(autoregressive) 트랜스포머(Transformer)라는 점에서 이전 모델들과 유사합니다.
트랜스포머 아키텍처(Transformer architecture)는 지난 몇 년간 수많은 혁신을 거쳐왔습니다. 특히, 효율성을 높이고 더 긴 컨텍스트(context)를 처리하기 위한 다양한 변형 모델이 등장했습니다. 예를 들어, 선형 어텐션(linear attention) 메커니즘을 도입하거나, 스파스 어텐션(sparse attention)을 통해 계산 비용을 줄이는 시도가 있었습니다. 또한, GPT-OSS와 같은 모델들은 자체적인 아키텍처 개선과 함께 데이터셋의 품질 및 규모를 극대화하여 성능을 끌어올렸습니다. 이는 단순히 토큰을 순차적으로 생성하는 것을 넘어, 훨씬 복잡한 추론과 지식 활용이 가능하도록 발전했습니다.

Language Models & Co.를 읽어주셔서 감사합니다! 새로운 게시물을 무료로 받아보고 제 작업을 지원하려면 구독하세요.

구독

**2025년 중반 LLM의 주요 차이점은 생성하는 토큰(token)이 다음을 통해 훨씬 더 어려운 문제를 해결할 수 있다는 것입니다:**

*   **고도화된 도구 사용 (Advanced Tool Usage)**: 단순한 함수 호출을 넘어, LLM은 이제 복잡한 다단계 도구 사용 시나리오를 자율적으로 계획하고 실행할 수 있습니다. 웹 브라우징, API 호출, 데이터베이스 쿼리 등 다양한 외부 시스템과의 연동을 통해 실시간 정보를 얻고 문제를 해결하는 능력이 크게 향상되었습니다. 이는 에이전트(agent) 기반 시스템의 핵심 요소로 자리 잡고 있습니다.
*   **심층적인 추론 능력 (Deep Reasoning Capabilities)**: 모델은 단순한 패턴 매칭을 넘어, 복잡한 논리적 추론, 수학적 문제 해결, 그리고 다단계 문제 해결(multi-step problem solving) 시나리오에서 뛰어난 성능을 보여줍니다. '사고의 사슬(Chain-of-Thought, CoT)'을 넘어 '사고의 나무(Tree-of-Thought, ToT)'나 '자체 반성(Self-reflection)'과 같은 고급 추론 기법을 통해 오류를 수정하고 최적의 경로를 탐색합니다.
*   **향상된 문제 해결 및 코딩 능력 (Enhanced Problem Solving & Coding)**: 코딩 어시스턴트(coding assistant)로서 LLM은 코드 생성, 디버깅, 리팩토링(refactoring), 그리고 심지어 복잡한 소프트웨어 아키텍처 설계에까지 기여할 수 있습니다. 특히, 사용자 요구사항을 이해하고 여러 프로그래밍 언어로 고품질 코드를 생성하는 능력은 개발 생산성을 혁신적으로 변화시키고 있습니다.
*   **멀티모달리티(Multimodality)**: 텍스트뿐만 아니라 이미지, 오디오, 비디오 등 다양한 형태의 데이터를 이해하고 생성하는 멀티모달 LLM의 등장은 정보 처리 및 상호작용의 지평을 넓혔습니다. 이는 시각적 질문 응답(Visual Question Answering, VQA), 음성 기반 대화 시스템 등 새로운 애플리케이션의 가능성을 열고 있습니다.

**아키텍처(architectural) 특징**
다음 그림에서 우리는 현재의 유능한 오픈 소스 모델들과 크게 다르지 않은 주요 아키텍처(architectural) 특징들을 볼 수 있습니다. GPT2와의 주요 아키텍처(architectural) 차이점은 GPT-OSS가 MoE(mixture-of-experts) 모델이라는 것입니다. 아키텍처(architecture)에 대해 더 자세히 알고 싶다면, 저희 무료 강좌인 *How Transformer LLMs Work*에서 자세한 내용과 많은 시각 자료(및 독점 애니메이션!)를 다루고 있습니다. 강좌에서 어텐션(attention)을 위해 소개하는 시각적 언어를 사용하면, GPT-OSS 트랜스포머 블록(Transformer Block)은 다음 그림과 같습니다. 이러한 아키텍처(architectural) 세부 사항 중 특별히 새로운 것은 거의 없다는 점에 유의하십시오. 최신 SoTA(State-of-the-Art) 오픈 소스 MoE(mixture-of-experts) 모델에서 일반적으로 유사합니다.
MoE(Mixture-of-Experts) 아키텍처는 모델의 스케일(scale)을 유지하면서도 추론 시의 계산 비용을 효율적으로 관리할 수 있게 해주는 핵심적인 발전입니다. 각 토큰(token) 또는 입력 시퀀스(input sequence)에 대해 소수의 전문가 네트워크(expert network)만 활성화하여 계산 효율성을 높이면서도, 전체 모델은 방대한 파라미터(parameter) 수를 가질 수 있습니다. 이러한 방식은 특히 대규모 모델에서 훈련 속도와 추론 비용을 최적화하는 데 중요한 역할을 합니다. 최근에는 MoE 모델의 라우팅(routing) 메커니즘을 개선하고, 전문가 간의 부하 균형(load balancing)을 최적화하는 연구가 활발히 진행되어 더욱 효율적인 MoE 모델들이 등장하고 있습니다.

**메시지 형식 지정(Message Formatting)**
더 많은 사용자에게는 모델의 추론(reasoning) 및 도구 호출(tool calls)의 동작 및 형식 지정(formatting) 세부 사항이 아키텍처(architecture)보다 더 중요합니다. 다음 그림에서 모델에 대한 입력(input) 및 출력(output)의 형태를 볼 수 있습니다.

**메시지 및 출력 채널(Output Channels)**
오픈 소스 LLM의 세 가지 주요 사용자 유형을 살펴보면서 이를 분석해 봅시다.

*   **LLM 앱의 최종 사용자(End-users)**
    *   예시: ChatGPT 앱 사용자
    *   이 사용자들은 주로 자신이 보내는 사용자 메시지(user message)와 최종 답변을 상호작용합니다.
    *   일부 앱에서는 중간 추론 흔적(interim reasoning traces)을 볼 수도 있습니다.
    최근에는 최종 사용자도 모델의 '페르소나(persona)'나 '기억(memory)' 기능을 설정하여 더 개인화된 경험을 얻을 수 있게 되었습니다. 또한, 대화 기록을 기반으로 한 지속적인 컨텍스트(context) 관리가 더욱 정교해져, 장기적인 대화에서도 일관된 답변을 받을 수 있습니다.
*   **LLM 앱 개발자(Builders)**
    *   예시: Cursor 또는 Manus
    *   **입력 메시지(Input messages)**: 이 개발자들은 모델이 사용할 일반적인 모델 예상 동작 및 지침, 안전 선택, 추론 수준, 도구 정의를 설정하는 자신만의 시스템(system) 및 개발자 메시지(developer messages)를 설정할 수 있습니다.
    *   또한 사용자 메시지(user message)에서 많은 프롬프트 엔지니어링(prompt engineering)과 컨텍스트 관리(context management)를 수행해야 합니다.
    개발자들은 이제 더 나아가 '함수 호출(function calling)'이나 '에이전트 프레임워크(agent framework)'를 활용하여 모델이 외부 도구와 상호작용하는 방식을 세밀하게 제어할 수 있습니다. 이를 통해 복잡한 워크플로우(workflow)를 자동화하고, LLM을 다양한 애플리케이션에 통합하는 것이 더욱 쉬워졌습니다. 또한, RAG(Retrieval-Augmented Generation) 시스템을 구축하여 모델의 지식 기반을 확장하고 환각(hallucination)을 줄이는 데 집중하고 있습니다.
    *   **출력 메시지(Output messages)**: 개발자들은 사용자에게 추론 흔적(reasoning traces)을 보여줄지 여부를 선택할 수 있습니다. 또한 도구를 정의하고, 추론의 정도를 설정합니다.
*   **LLM 사후 훈련자(Post-trainers)**
    *   모델을 미세 조정(fine-tune)하는 고급 사용자(power users)는 추론(reasoning) 및 도구 호출(tool calls)과 응답을 포함하여 모든 메시지 유형과 올바른 형식의 데이터와 상호작용해야 합니다.
    미세 조정(fine-tuning) 기술도 발전하여, LoRA(Low-Rank Adaptation)와 같은 효율적인 기법을 통해 적은 자원으로도 특정 도메인(domain)이나 태스크(task)에 모델을 최적화할 수 있게 되었습니다. 또한, 정렬(alignment) 기술의 발전으로 모델이 사용자 의도에 더욱 부합하고 안전한 응답을 생성하도록 훈련하는 것이 중요해졌습니다. RLHF(Reinforcement Learning from Human Feedback)를 넘어 DPO(Direct Preference Optimization)와 같은 방법론들이 활용되고 있습니다.

(이러한 유형의 설명이 도움이 된다면, LLM을 이 정도 깊이로 설명하는 300개 이상의 그림이 포함된 베스트셀러 도서와 현재 14K 이상의 별을 받은 GitHub 리포지토리(repo)를 꼭 확인해 보세요.) 도서 공식 웹사이트. Amazon에서 도서를 주문할 수 있습니다. 모든 코드는 GitHub에 업로드되어 있습니다.

**메시지 채널(Message Channels)**
모델 출력은 모두 어시스턴트 메시지(assistant messages)입니다. 모델은 메시지 유형을 나타내기 위해 이들을 '채널(channel)' 범주에 할당합니다.

*   추론(reasoning)을 위한 분석 (및 일부 도구 호출(tool calls))
*   기능 호출(functional calling)을 위한 해설 (및 대부분의 도구 호출(tool calls))
*   최종 응답을 포함하는 메시지를 위한 최종

따라서 모델에 추론(reasoning)하고 몇 가지 도구 호출(tool calls)을 사용해야 하는 프롬프트(prompt)를 제공한다고 가정하면, 다음 그림은 세 가지 메시지 유형이 모두 사용된 대화를 보여줍니다. 이는 턴(turn) 2와 4가 해당 호출에 대한 도구 응답(tool responses)이 될 것이기 때문에 턴 1, 3, 5로 표시됩니다. 최종 답변은 최종 사용자(end user)가 보게 될 내용입니다.

**추론(Reasoning)**
추론(reasoning)에는 고급 사용자(advanced users)가 선택해야 할 절충점(trade-offs)이 있습니다. 한편, 더 많은 추론(reasoning)은 모델이 문제에 대해 추론(reasoning)할 더 많은 시간과 컴퓨팅 자원(compute)을 허용하여 더 어려운 문제를 해결하는 데 도움이 됩니다. 다른 한편으로는 지연 시간(latency)과 컴퓨팅 자원(compute) 비용이 발생합니다. 이러한 선택은 강력한 추론(reasoning) LLM과 비추론(non-reasoning) LLM이 모두 존재하며, 각각 다른 종류의 문제를 해결하는 데 가장 적합하다는 점에서 분명히 드러납니다.
최근 LLM의 추론 능력 향상은 단순히 더 많은 토큰을 생성하는 것을 넘어, 추론 과정 자체를 구조화하고 검증하는 방향으로 발전하고 있습니다. '사고의 사슬(Chain-of-Thought)' 프롬프팅은 모델이 단계별로 사고 과정을 보여주게 하여 복잡한 문제를 해결하는 데 큰 도움을 주었습니다. 여기서 한 단계 더 나아가, '사고의 나무(Tree-of-Thought)'나 '자체 비판(Self-critique)'과 같은 방법론은 모델이 여러 추론 경로를 탐색하고, 자신의 오류를 식별하며, 최적의 해결책을 찾아내도록 돕습니다. 이러한 고급 추론 기법은 모델이 더 어려운 벤치마크(benchmark)에서 좋은 성과를 내는 데 필수적입니다. 또한, 합성 데이터(synthetic data)를 활용하여 추론 능력을 강화하는 훈련 방식도 주목받고 있습니다.

**추론 모드(Reasoning Modes) (낮음, 중간, 높음)**
한 가지 중간 지점 옵션은 특정 추론 예산(reasoning budget)에 따라 응답하는 추론 모델을 갖는 것입니다. 이것이 GPT-OSS가 속하는 범주입니다. 시스템 메시지(system message)에서 추론 모드(reasoning mode) (낮음(low), 중간(medium), 높음(high))를 허용합니다. 모델 카드(model card)의 그림 3은 이것이 벤치마크(benchmarks) 점수에 어떻게 영향을 미치는지, 그리고 추론 흔적(reasoning traces) (일명, 사고의 사슬(chain-of-thought) 또는 CoT)에 얼마나 많은 토큰(token)이 포함되는지를 보여줍니다. 이를 Qwen3의 추론 모드(reasoning modes)와 대조할 수 있는데, Qwen3는 이진적인 사고(thinking) / 비사고(non-thinking) 모드입니다. 사고 모드(thinking mode)의 경우, 특정 토큰(token) 임계값(threshold)을 넘어선 사고를 중지하는 방법을 보여주며, 이것이 다양한 추론 벤치마크(reasoning benchmarks) 점수에 어떻게 영향을 미치는지 보고합니다.

추론 모드(reasoning modes) 간의 차이를 보여주는 좋은 방법은 어려운 추론 질문을 하는 것입니다. 그래서 저는 AIME25 데이터셋(dataset)에서 하나를 선택하여 120B 모델에 세 가지 추론 모드(reasoning mode)로 질문했습니다. 이 질문의 정답은 104입니다. 따라서 중간(medium) 및 높은(high) 추론 모드(reasoning modes) 모두 정답을 맞혔습니다. 하지만 높은 추론 모드(high reasoning mode)는 그 답에 도달하는 데 두 배의 컴퓨팅 자원(compute)/생성 시간(generation time)이 소요됩니다. 이는 사용 사례에 맞는 올바른 추론 모드(reasoning mode)를 선택하는 것에 대해 앞서 언급한 점을 강조합니다.

*   **에이전트(agentic) 작업을 수행하시나요?**
    *   경로가 많은 단계를 포함할 수 있다면 높은(high) 또는 심지어 중간(medium) 추론(reasoning)은 너무 오래 걸릴 수 있습니다.
    에이전트 시스템에서는 추론 모드 선택이 특히 중요합니다. 다단계 작업을 수행할 때 높은 추론 모드는 더 정확한 결과를 가져올 수 있지만, 각 단계마다 발생하는 지연 시간(latency)이 누적되어 전체 작업 완료 시간이 길어질 수 있습니다. 따라서, 초기 단계에서는 낮은 추론 모드로 빠른 탐색을 수행하고, 중요한 의사결정 단계에서만 높은 추론 모드를 사용하는 하이브리드(hybrid) 전략이 효과적일 수 있습니다.
*   **실시간(Real time) vs. 오프라인(offline)** - 사용자가 목표를 달성하기 위해 적극적으로 기다리지 않는 오프라인에서 수행될 수 있는 작업이 무엇인지 고려하십시오.
    *   여기서 고려할 예시는 검색 엔진(search engine)입니다. 많은 처리와 설계가 이미 시스템을 해당 경험에 대비시키기 위해 이루어졌기 때문에 쿼리(query) 시간에 매우 빠른 결과를 얻을 수 있습니다.
    실시간 애플리케이션에서는 응답 속도가 사용자 경험에 직결되므로, 낮은 추론 모드나 사전 계산된 결과(pre-computed results)를 활용하는 것이 일반적입니다. 반면, 데이터 분석, 보고서 생성, 복잡한 코드 리뷰와 같은 오프라인 작업에서는 높은 추론 모드를 사용하여 정확성과 깊이 있는 분석에 집중할 수 있습니다. 이는 비용과 성능 사이의 균형점을 찾는 중요한 고려 사항입니다.

**토크나이저(Tokenizer)**
토크나이저(tokenizer)는 GPT-4의 것과 상당히 유사하지만, 특히 비영어 토큰(non-English tokens)에서 약간 더 효율적인 것으로 보입니다. 이모티콘(emoji)과 한자(Chinese character)가 각각 세 개가 아닌 두 개의 토큰(token)으로 토큰화(tokenized)되고, 아랍어 텍스트의 더 많은 부분이 글자 대신 개별 토큰(individual token)으로 그룹화되는 방식에 주목하십시오. 하지만 토크나이저(tokenizer)가 이 점에서 더 나을 수 있지만, 모델은 주로 영어 데이터(English data)로 훈련되었습니다. 코드(code) (및 파이썬(python) 코드에서 들여쓰기(indentation)에 사용되는 탭(tabs))는 주로 동일하게 작동하는 것으로 보입니다. 숫자 토큰화(Number tokenization)도 동일한 방식으로 작동하는 것으로 보이며, 최대 세 자리 숫자를 개별 토큰(individual token)으로 할당하고 더 큰 토큰(bigger tokens)은 분리합니다.

**추가 자료(Further Readings)**
제가 흥미롭다고 생각한 몇 가지 추가 자료입니다.

*   GPT-2에서 gpt-oss까지: Sebastian Raschka 박사의 아키텍처(Architectural) 발전 분석
*   gpt-oss: OpenAI가 오픈 생태계(open ecosystem)를 (마침내) 검증하다 (Nathan Lambert 저)
*   gpt-oss-120B (높음): API 제공업체 벤치마킹(Benchmarking) 및 분석
*   **최신 LLM 추론 기술 동향**: CoT, ToT, Self-reflection 등 고급 추론 기법에 대한 심층 분석
*   **MoE 모델의 최적화 전략**: Mixture-of-Experts 아키텍처의 효율성 향상 방안 연구
*   **멀티모달 LLM의 발전과 활용**: 텍스트 외 데이터 처리 능력 확장에 대한 보고서

(이러한 유형의 설명이 도움이 된다면, LLM을 이 정도 깊이로 설명하는 300개 이상의 그림이 포함된 베스트셀러 도서와 현재 14K 이상의 별을 받은 GitHub 리포지토리(repo)를 꼭 확인해 보세요.) 도서 공식 웹사이트. Amazon에서 도서를 주문할 수 있습니다. 모든 코드는 GitHub에 업로드되어 있습니다.

Language Models & Co.를 읽어주셔서 감사합니다! 새로운 게시물을 무료로 받아보고 제 작업을 지원하려면 구독하세요.

구독