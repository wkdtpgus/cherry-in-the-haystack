OpenAI가 GPT-OSS를 출시한 것은 6년 전 GPT-2 이후 주요 오픈 소스 LLM(거대 언어 모델) 출시입니다. 이 기간 동안 LLM의 기능은 괄목할 만하게 발전했습니다. 2025년 현재, 오픈 소스 LLM 생태계는 더욱 다양하고 역동적으로 진화하고 있으며, GPT-OSS는 이러한 변화의 흐름을 되짚어보는 중요한 이정표가 됩니다. 이 모델 자체는 DeepSeek, Qwen, Kimi 등 기존 오픈 모델과 비교했을 때 기능 면에서 혁신적인 도약은 아니었지만, LLM 발전의 중요한 단계를 보여줍니다.

**이전 오픈 소스 GPT 모델과의 차이점**
GPT-OSS는 한 번에 하나의 토큰(token)을 생성하는 자기회귀(autoregressive) 트랜스포머(Transformer)라는 점에서 이전 모델들과 유사합니다.

Language Models & Co.를 읽어주셔서 감사합니다! 새로운 게시물을 무료로 받아보고 제 작업을 지원하려면 구독하세요.

2025년 현재, LLM이 생성하는 토큰이 훨씬 더 복잡한 문제들을 다룰 수 있게 된 주요 요인들은 다음과 같습니다:

*   도구 사용
*   추론
*   문제 해결 및 코딩 능력 향상

또한, 멀티모달(multimodal) 능력의 발전으로 텍스트 외에 이미지, 오디오 등 다양한 데이터를 이해하고 처리하는 능력이 크게 향상되어 활용 범위가 넓어졌습니다.

현재의 고성능 오픈 소스 모델들과 비교했을 때, GPT-OSS의 핵심적인 아키텍처(architectural) 특징들은 크게 다르지 않습니다. GPT2와의 주요 아키텍처(architectural) 차이점은 GPT-OSS가 MoE(mixture-of-experts) 모델이라는 것입니다. 아키텍처(architecture)에 대해 더 자세히 알고 싶다면, 저희 무료 강좌인 *How Transformer LLMs Work*에서 자세한 내용과 많은 시각 자료를 다루고 있습니다. 강좌에서 어텐션(attention)을 위해 소개하는 시각적 언어를 활용하면, GPT-OSS 트랜스포머 블록(Transformer Block)은 다음 그림과 같이 시각화될 수 있습니다. 이러한 아키텍처 세부 사항은 최신 SoTA(State-of-the-Art) 오픈 소스 MoE 모델에서 흔히 볼 수 있는 패턴입니다.

**메시지 형식 지정(Message Formatting)**
더 많은 사용자에게는 모델의 추론(reasoning) 및 도구 호출(tool calls)의 동작 및 형식 지정(formatting) 세부 사항이 아키텍처(architecture)보다 더 중요합니다. 아래 그림에서 모델의 입력(input) 및 출력(output) 메시지 형태를 확인할 수 있습니다.

**메시지 및 출력 채널(Output Channels)**
오픈 소스 LLM을 활용하는 세 가지 핵심 사용자 유형을 통해 메시지 채널의 중요성을 분석해 보겠습니다.

*   **LLM 앱의 최종 사용자(End-users)**
    *   예시: ChatGPT 앱 사용자
    *   이 사용자들은 주로 자신이 보내는 사용자 메시지(user message)와 최종 답변을 상호작용합니다.
    *   일부 앱에서는 중간 추론 흔적(interim reasoning traces)을 볼 수도 있습니다.
*   **LLM 앱 개발자(Builders)**
    *   예시: Cursor 또는 Manus
    *   **입력 메시지(Input messages)**: 이 개발자들은 모델이 사용할 일반적인 모델 예상 동작 및 지침, 안전 선택, 추론 수준, 도구 정의를 설정하는 자신만의 시스템(system) 및 개발자 메시지(developer messages)를 설정할 수 있습니다.
    *   또한 사용자 메시지(user message)에서 많은 프롬프트 엔지니어링(prompt engineering)과 컨텍스트 관리(context management)를 수행해야 합니다.
    *   **출력 메시지(Output messages)**: 개발자들은 사용자에게 추론 흔적(reasoning traces)을 보여줄지 여부를 선택할 수 있습니다. 또한 도구를 정의하고, 추론의 정도를 설정합니다.
*   **LLM 사후 훈련자(Post-trainers)**
    *   모델을 미세 조정(fine-tune)하는 고급 사용자(power users)는 추론(reasoning) 및 도구 호출(tool calls)과 응답을 포함하여 모든 메시지 유형과 올바른 형식의 데이터와 상호작용해야 합니다.

후자의 두 가지 범주, 즉 LLM 앱 개발자(builders)와 LLM 사후 훈련자(post-trainers)는 어시스턴트 메시지(assistant messages)의 채널(channels) 개념을 이해함으로써 이점을 얻습니다. 이는 OpenAI Harmony 리포(repo)에 구현되어 있습니다.

(이러한 유형의 설명이 도움이 된다면, LLM을 이 정도 깊이로 설명하는 300개 이상의 그림이 포함된 베스트셀러 도서와 현재 14K 이상의 별을 받은 GitHub 리포지토리(repo)를 꼭 확인해 보세요.) 도서 공식 웹사이트. Amazon에서 도서를 주문할 수 있습니다. 모든 코드는 GitHub에 업로드되어 있습니다.

**메시지 채널(Message Channels)**
모델 출력은 모두 어시스턴트 메시지(assistant messages)입니다. 모델은 메시지 유형을 나타내기 위해 이들을 '채널(channel)' 범주에 할당합니다.

*   추론(reasoning)을 위한 분석 (및 일부 도구 호출(tool calls))
*   기능 호출(functional calling)을 위한 해설 (및 대부분의 도구 호출(tool calls))
*   최종 응답을 포함하는 메시지를 위한 최종

따라서 모델에 추론(reasoning)하고 몇 가지 도구 호출(tool calls)을 사용해야 하는 프롬프트(prompt)를 제공한다고 가정하면, 다음 그림은 세 가지 메시지 유형이 모두 사용된 대화를 보여줍니다. 이는 턴(turn) 2와 4가 해당 호출에 대한 도구 응답(tool responses)이 될 것이기 때문에 턴 1, 3, 5로 표시됩니다. 최종 답변은 최종 사용자(end user)가 보게 될 내용입니다.

**추론(Reasoning)**
추론(reasoning)에는 고급 사용자(advanced users)가 선택해야 할 절충점(trade-offs)이 있습니다. 한편, 더 많은 추론(reasoning)은 모델이 문제에 대해 추론(reasoning)할 더 많은 시간과 컴퓨팅 자원(compute)을 허용하여 더 어려운 문제를 해결하는 데 도움이 됩니다. 다른 한편으로는 지연 시간(latency)과 컴퓨팅 자원(compute) 비용이 발생합니다. 이러한 선택은 강력한 추론(reasoning) LLM과 비추론(non-reasoning) LLM이 모두 존재하며, 각각 다른 종류의 문제를 해결하는 데 가장 적합하다는 점에서 분명히 드러납니다.

한 가지 중간 지점 옵션은 특정 추론 예산(reasoning budget)에 따라 응답하는 추론 모델을 갖는 것입니다. 이것이 GPT-OSS가 속하는 범주입니다. 시스템 메시지(system message)에서 추론 모드(reasoning mode) (낮음(low), 중간(medium), 높음(high))를 허용합니다. 모델 카드(model card)의 그림 3은 이것이 벤치마크(benchmarks) 점수에 어떻게 영향을 미치는지, 그리고 추론 흔적(reasoning traces) (일명, 사고의 사슬(chain-of-thought) 또는 CoT)에 얼마나 많은 토큰(token)이 포함되는지를 보여줍니다. 이러한 방식은 Qwen3의 이진적인 사고(thinking) / 비사고(non-thinking) 모드와는 대조적입니다. Qwen3는 사고 모드에서 특정 토큰 임계값을 초과하면 사고를 중지하는 방식을 사용하며, 이는 다양한 추론 벤치마크 점수에 영향을 미칩니다. 최근에는 Tree of Thought(ToT)나 Self-reflection과 같은 고급 추론 기법들이 더욱 활발히 연구되고 있으며, 이는 LLM이 복잡한 문제를 다루는 방식을 한 단계 더 발전시키고 있습니다. GPT-OSS의 다단계 추론 모드는 이러한 최신 연구의 기반이 되는 중요한 접근 방식입니다.

**추론 모드(Reasoning Modes) (낮음, 중간, 높음)**
추론 모드(reasoning modes) 간의 차이를 보여주는 좋은 방법은 어려운 추론 질문을 하는 것입니다. 그래서 저는 AIME25 데이터셋(dataset)에서 하나를 선택하여 120B 모델에 세 가지 추론 모드(reasoning mode)로 질문했습니다. 이 질문의 정답은 104입니다. 따라서 중간(medium) 및 높은(high) 추론 모드(reasoning modes) 모두 정답을 맞혔습니다. 하지만 높은 추론 모드(high reasoning mode)는 그 답에 도달하는 데 두 배의 컴퓨팅 자원(compute)/생성 시간(generation time)이 소요됩니다. 이는 각 사용 사례에 최적화된 추론 모드를 신중하게 선택하는 것이 중요함을 다시 한번 강조합니다.

*   **에이전트(agentic) 작업을 수행하시나요?**
    *   경로가 많은 단계를 포함할 수 있다면 높은(high) 또는 심지어 중간(medium) 추론(reasoning)은 너무 오래 걸릴 수 있습니다.
*   **실시간(Real time) vs. 오프라인(offline)** - 사용자가 목표를 달성하기 위해 적극적으로 기다리지 않는 오프라인에서 수행될 수 있는 작업이 무엇인지 고려하십시오.
    *   여기서 고려할 예시는 검색 엔진(search engine)입니다. 많은 처리와 설계가 이미 시스템을 해당 경험에 대비시키기 위해 이루어졌기 때문에 쿼리(query) 시간에 매우 빠른 결과를 얻을 수 있습니다.

2025년에는 이러한 추론 모드의 선택이 에이전트 프레임워크(agent framework)의 발전과 맞물려 더욱 복잡해지고 있습니다. 단순히 성능을 넘어, 비용 효율성과 사용자 경험을 동시에 고려하는 지능형 추론 스케줄링(intelligent reasoning scheduling)이 중요한 연구 분야로 부상하고 있습니다.

**토크나이저(Tokenizer)**
토크나이저(tokenizer)는 GPT-4의 것과 상당히 유사하지만, 특히 비영어 토큰(non-English tokens)에서 약간 더 효율적인 것으로 보입니다. 이모티콘(emoji)과 한자(Chinese character)가 각각 세 개가 아닌 두 개의 토큰(token)으로 토큰화(tokenized)되고, 아랍어 텍스트의 더 많은 부분이 글자 대신 개별 토큰(individual token)으로 그룹화되는 방식에 주목하십시오. 하지만 토크나이저(tokenizer)가 이 점에서 더 나을 수 있지만, 모델은 주로 영어 데이터(English data)로 훈련되었습니다. 코드(code) 및 숫자 토큰화(number tokenization) 방식은 이전 모델들과 유사하게 작동하며, 파이썬(python) 코드의 들여쓰기(indentation)나 세 자리 이하의 숫자를 개별 토큰으로 처리하는 경향을 보입니다. 2025년에는 다국어 지원을 위한 토크나이저 최적화가 더욱 중요해지고 있습니다. GPT-OSS가 비영어권 토큰 효율성 개선의 초기 단계를 보여주었다면, 이제는 특정 언어에 특화된 토크나이저들이 전반적인 모델 성능 향상에 기여하며, 특히 동아시아 언어 처리 효율성이 핵심 경쟁력으로 부상하고 있습니다.

**추가 자료(Further Readings)**
제가 흥미롭다고 생각한 몇 가지 추가 자료입니다.

*   GPT-2에서 gpt-oss까지: Sebastian Raschka 박사의 아키텍처(Architectural) 발전 분석
*   gpt-oss: OpenAI가 오픈 생태계(open ecosystem)를 (마침내) 검증하다 (Nathan Lambert 저)
*   최신 오픈 소스 LLM 벤치마킹 및 성능 비교 (2025년 업데이트): 주요 모델들의 최신 동향 분석