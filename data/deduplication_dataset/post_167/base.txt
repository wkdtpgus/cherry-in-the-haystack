# **도해 GPT-OSS**

Author: Jay Alammar
URL: https://newsletter.languagemodels.co/p/the-illustrated-gpt-oss

============================================================

OpenAI가 GPT-OSS를 출시한 것은 6년 전 GPT-2 이후 주요 오픈 소스 LLM(거대 언어 모델) 출시입니다. 이 기간 동안 LLM의 기능은 극적으로 향상되었습니다. 이 모델 자체는 DeepSeek, Qwen, Kimi 등 기존 오픈 모델과 비교하여 기능 면에서 반드시 비약적인 발전이라고 할 수는 없지만, 이 기간 동안 LLM이 어떻게 변화했는지 다시 살펴보는 좋은 기회를 제공합니다.

**이전 오픈 소스 GPT 모델과의 차이점**
GPT-OSS는 한 번에 하나의 토큰(token)을 생성하는 자기회귀(autoregressive) 트랜스포머(Transformer)라는 점에서 이전 모델들과 유사합니다.

Language Models & Co.를 읽어주셔서 감사합니다! 새로운 게시물을 무료로 받아보고 제 작업을 지원하려면 구독하세요.

구독

2025년 중반 LLM의 주요 차이점은 생성하는 토큰(token)이 다음을 통해 훨씬 더 어려운 문제를 해결할 수 있다는 것입니다.

*   도구 사용
*   추론
*   문제 해결 및 코딩 능력 향상

다음 그림에서 우리는 현재의 유능한 오픈 소스 모델들과 크게 다르지 않은 주요 아키텍처(architectural) 특징들을 볼 수 있습니다. GPT2와의 주요 아키텍처(architectural) 차이점은 GPT-OSS가 MoE(mixture-of-experts) 모델이라는 것입니다. 아키텍처(architecture)에 대해 더 자세히 알고 싶다면, 저희 무료 강좌인 *How Transformer LLMs Work*에서 자세한 내용과 많은 시각 자료(및 독점 애니메이션!)를 다루고 있습니다. 강좌에서 어텐션(attention)을 위해 소개하는 시각적 언어를 사용하면, GPT-OSS 트랜스포머 블록(Transformer Block)은 다음 그림과 같습니다. 이러한 아키텍처(architectural) 세부 사항 중 특별히 새로운 것은 거의 없다는 점에 유의하십시오. 최신 SoTA(State-of-the-Art) 오픈 소스 MoE(mixture-of-experts) 모델에서 일반적으로 유사합니다.

**메시지 형식 지정(Message Formatting)**
더 많은 사용자에게는 모델의 추론(reasoning) 및 도구 호출(tool calls)의 동작 및 형식 지정(formatting) 세부 사항이 아키텍처(architecture)보다 더 중요합니다. 다음 그림에서 모델에 대한 입력(input) 및 출력(output)의 형태를 볼 수 있습니다.

**메시지 및 출력 채널(Output Channels)**
오픈 소스 LLM의 세 가지 주요 사용자 유형을 살펴보면서 이를 분석해 봅시다.

*   **LLM 앱의 최종 사용자(End-users)**
    *   예시: ChatGPT 앱 사용자
    *   이 사용자들은 주로 자신이 보내는 사용자 메시지(user message)와 최종 답변을 상호작용합니다.
    *   일부 앱에서는 중간 추론 흔적(interim reasoning traces)을 볼 수도 있습니다.
*   **LLM 앱 개발자(Builders)**
    *   예시: Cursor 또는 Manus
    *   **입력 메시지(Input messages)**: 이 개발자들은 모델이 사용할 일반적인 모델 예상 동작 및 지침, 안전 선택, 추론 수준, 도구 정의를 설정하는 자신만의 시스템(system) 및 개발자 메시지(developer messages)를 설정할 수 있습니다.
    *   또한 사용자 메시지(user message)에서 많은 프롬프트 엔지니어링(prompt engineering)과 컨텍스트 관리(context management)를 수행해야 합니다.
    *   **출력 메시지(Output messages)**: 개발자들은 사용자에게 추론 흔적(reasoning traces)을 보여줄지 여부를 선택할 수 있습니다. 또한 도구를 정의하고, 추론의 정도를 설정합니다.
*   **LLM 사후 훈련자(Post-trainers)**
    *   모델을 미세 조정(fine-tune)하는 고급 사용자(power users)는 추론(reasoning) 및 도구 호출(tool calls)과 응답을 포함하여 모든 메시지 유형과 올바른 형식의 데이터와 상호작용해야 합니다.

후자의 두 가지 범주, 즉 LLM 앱 개발자(builders)와 LLM 사후 훈련자(post-trainers)는 어시스턴트 메시지(assistant messages)의 채널(channels) 개념을 이해함으로써 이점을 얻습니다. 이는 OpenAI Harmony 리포(repo)에 구현되어 있습니다.

(이러한 유형의 설명이 도움이 된다면, LLM을 이 정도 깊이로 설명하는 300개 이상의 그림이 포함된 베스트셀러 도서와 현재 14K 이상의 별을 받은 GitHub 리포지토리(repo)를 꼭 확인해 보세요.) 도서 공식 웹사이트. Amazon에서 도서를 주문할 수 있습니다. 모든 코드는 GitHub에 업로드되어 있습니다.

**메시지 채널(Message Channels)**
모델 출력은 모두 어시스턴트 메시지(assistant messages)입니다. 모델은 메시지 유형을 나타내기 위해 이들을 '채널(channel)' 범주에 할당합니다.

*   추론(reasoning)을 위한 분석 (및 일부 도구 호출(tool calls))
*   기능 호출(functional calling)을 위한 해설 (및 대부분의 도구 호출(tool calls))
*   최종 응답을 포함하는 메시지를 위한 최종

따라서 모델에 추론(reasoning)하고 몇 가지 도구 호출(tool calls)을 사용해야 하는 프롬프트(prompt)를 제공한다고 가정하면, 다음 그림은 세 가지 메시지 유형이 모두 사용된 대화를 보여줍니다. 이는 턴(turn) 2와 4가 해당 호출에 대한 도구 응답(tool responses)이 될 것이기 때문에 턴 1, 3, 5로 표시됩니다. 최종 답변은 최종 사용자(end user)가 보게 될 내용입니다.

**추론(Reasoning)**
추론(reasoning)에는 고급 사용자(advanced users)가 선택해야 할 절충점(trade-offs)이 있습니다. 한편, 더 많은 추론(reasoning)은 모델이 문제에 대해 추론(reasoning)할 더 많은 시간과 컴퓨팅 자원(compute)을 허용하여 더 어려운 문제를 해결하는 데 도움이 됩니다. 다른 한편으로는 지연 시간(latency)과 컴퓨팅 자원(compute) 비용이 발생합니다. 이러한 선택은 강력한 추론(reasoning) LLM과 비추론(non-reasoning) LLM이 모두 존재하며, 각각 다른 종류의 문제를 해결하는 데 가장 적합하다는 점에서 분명히 드러납니다.

한 가지 중간 지점 옵션은 특정 추론 예산(reasoning budget)에 따라 응답하는 추론 모델을 갖는 것입니다. 이것이 GPT-OSS가 속하는 범주입니다. 시스템 메시지(system message)에서 추론 모드(reasoning mode) (낮음(low), 중간(medium), 높음(high))를 허용합니다. 모델 카드(model card)의 그림 3은 이것이 벤치마크(benchmarks) 점수에 어떻게 영향을 미치는지, 그리고 추론 흔적(reasoning traces) (일명, 사고의 사슬(chain-of-thought) 또는 CoT)에 얼마나 많은 토큰(token)이 포함되는지를 보여줍니다. 이를 Qwen3의 추론 모드(reasoning modes)와 대조할 수 있는데, Qwen3는 이진적인 사고(thinking) / 비사고(non-thinking) 모드입니다. 사고 모드(thinking mode)의 경우, 특정 토큰(token) 임계값(threshold)을 넘어선 사고를 중지하는 방법을 보여주며, 이것이 다양한 추론 벤치마크(reasoning benchmarks) 점수에 어떻게 영향을 미치는지 보고합니다.

**추론 모드(Reasoning Modes) (낮음, 중간, 높음)**
추론 모드(reasoning modes) 간의 차이를 보여주는 좋은 방법은 어려운 추론 질문을 하는 것입니다. 그래서 저는 AIME25 데이터셋(dataset)에서 하나를 선택하여 120B 모델에 세 가지 추론 모드(reasoning mode)로 질문했습니다. 이 질문의 정답은 104입니다. 따라서 중간(medium) 및 높은(high) 추론 모드(reasoning modes) 모두 정답을 맞혔습니다. 하지만 높은 추론 모드(high reasoning mode)는 그 답에 도달하는 데 두 배의 컴퓨팅 자원(compute)/생성 시간(generation time)이 소요됩니다. 이는 사용 사례에 맞는 올바른 추론 모드(reasoning mode)를 선택하는 것에 대해 앞서 언급한 점을 강조합니다.

*   **에이전트(agentic) 작업을 수행하시나요?**
    *   경로가 많은 단계를 포함할 수 있다면 높은(high) 또는 심지어 중간(medium) 추론(reasoning)은 너무 오래 걸릴 수 있습니다.
*   **실시간(Real time) vs. 오프라인(offline)** - 사용자가 목표를 달성하기 위해 적극적으로 기다리지 않는 오프라인에서 수행될 수 있는 작업이 무엇인지 고려하십시오.
    *   여기서 고려할 예시는 검색 엔진(search engine)입니다. 많은 처리와 설계가 이미 시스템을 해당 경험에 대비시키기 위해 이루어졌기 때문에 쿼리(query) 시간에 매우 빠른 결과를 얻을 수 있습니다.

**토크나이저(Tokenizer)**
토크나이저(tokenizer)는 GPT-4의 것과 상당히 유사하지만, 특히 비영어 토큰(non-English tokens)에서 약간 더 효율적인 것으로 보입니다. 이모티콘(emoji)과 한자(Chinese character)가 각각 세 개가 아닌 두 개의 토큰(token)으로 토큰화(tokenized)되고, 아랍어 텍스트의 더 많은 부분이 글자 대신 개별 토큰(individual token)으로 그룹화되는 방식에 주목하십시오. 하지만 토크나이저(tokenizer)가 이 점에서 더 나을 수 있지만, 모델은 주로 영어 데이터(English data)로 훈련되었습니다. 코드(code) (및 파이썬(python) 코드에서 들여쓰기(indentation)에 사용되는 탭(tabs))는 주로 동일하게 작동하는 것으로 보입니다. 숫자 토큰화(Number tokenization)도 동일한 방식으로 작동하는 것으로 보이며, 최대 세 자리 숫자를 개별 토큰(individual token)으로 할당하고 더 큰 토큰(bigger tokens)은 분리합니다.

**추가 자료(Further Readings)**
제가 흥미롭다고 생각한 몇 가지 추가 자료입니다.

*   GPT-2에서 gpt-oss까지: Sebastian Raschka 박사의 아키텍처(Architectural) 발전 분석
*   gpt-oss: OpenAI가 오픈 생태계(open ecosystem)를 (마침내) 검증하다 (Nathan Lambert 저)
*   gpt-oss-120B (높음): API 제공업체 벤치마킹(Benchmarking) 및 분석

(이러한 유형의 설명이 도움이 된다면, LLM을 이 정도 깊이로 설명하는 300개 이상의 그림이 포함된 베스트셀러 도서와 현재 14K 이상의 별을 받은 GitHub 리포지토리(repo)를 꼭 확인해 보세요.) 도서 공식 웹사이트. Amazon에서 도서를 주문할 수 있습니다. 모든 코드는 GitHub에 업로드되어 있습니다.

Language Models & Co.를 읽어주셔서 감사합니다! 새로운 게시물을 무료로 받아보고 제 작업을 지원하려면 구독하세요.

구독