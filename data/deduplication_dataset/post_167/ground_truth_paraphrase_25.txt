OpenAI가 GPT-OSS를 공개한 것은 GPT-2 이후 6년 만에 선보이는 핵심적인 오픈 소스 LLM(거대 언어 모델)입니다. 이 공백 기간 동안 LLM의 역량은 눈부시게 발전했습니다. 비록 이 모델 자체가 DeepSeek, Qwen, Kimi와 같은 현존하는 오픈 소스 모델들과 비교했을 때 기능적으로 혁신적인 도약은 아닐지라도, 지난 6년간 LLM 기술이 어떻게 진화했는지를 되짚어볼 수 있는 의미 있는 계기를 마련해 줍니다. 특히, 폐쇄형 모델 개발에 주력해 온 OpenAI가 다시 오픈 소스 진영에 합류했다는 점은 LLM 생태계 전반에 긍정적인 영향을 미칠 것으로 기대됩니다. 이는 기술 공유와 협력을 촉진하고, 더 많은 개발자들이 혁신적인 애플리케이션을 만들 수 있는 기반을 제공할 것입니다.

### 이전 오픈 소스 GPT 모델과의 차이점

GPT-OSS는 이전 세대 모델들과 마찬가지로, 한 번에 한 개의 토큰(token)을 순차적으로 생성하는 자기회귀(autoregressive) 방식의 트랜스포머(Transformer) 구조를 채택하고 있습니다. 이는 LLM의 기본적인 동작 원리를 계승하고 있음을 의미합니다.

2025년 중반에 이르러 LLM의 핵심적인 발전은 모델이 생성하는 토큰(token)들이 다음을 포함한 훨씬 복잡한 과제들을 해결할 수 있도록 지원한다는 점입니다.

*   도구 활용 능력 (Tool Use)
*   향상된 추론 능력 (Reasoning)
*   정교한 문제 해결 및 코딩 능력

아래 그림을 통해 현재 시장에 나와 있는 고성능 오픈 소스 모델들과 크게 다르지 않은 핵심적인 구조적(architectural) 특성들을 파악할 수 있습니다. GPT-OSS와 GPT-2 사이의 주요 아키텍처(architectural)적 차이는 GPT-OSS가 MoE(mixture-of-experts) 모델이라는 사실입니다. MoE 아키텍처는 모델의 특정 부분(전문가)이 입력 데이터의 특정 측면을 처리하도록 함으로써, 전체 모델의 파라미터(parameter) 수는 크게 늘리면서도 실제 계산량은 줄여 효율성을 높이는 방식입니다. 이는 방대한 데이터셋에 대한 훈련을 더욱 효율적으로 만들고, 모델의 확장성을 개선하는 데 기여합니다. 아키텍처에 대한 심층적인 이해는 LLM의 성능 최적화와 새로운 응용 분야 개발에 필수적입니다.

### 메시지 형식 지정 (Message Formatting)

대다수의 사용자들에게는 모델의 내부 아키텍처(architecture)보다는 추론(reasoning) 과정과 도구 호출(tool calls)의 작동 방식 및 출력 형식(formatting)에 대한 세부 사항이 훨씬 더 실질적인 중요성을 가집니다. LLM과의 효과적인 상호작용은 명확하고 일관된 메시지 형식에 크게 좌우됩니다. 모델의 입력(input) 및 출력(output) 형태를 이해하는 것은 원하는 결과를 얻기 위한 프롬프트 엔지니어링(prompt engineering)의 핵심 요소입니다. 표준화된 메시지 형식은 개발자가 모델의 응답을 예측하고 제어하는 데 도움을 주어, 보다 안정적이고 신뢰할 수 있는 LLM 기반 애플리케이션을 구축할 수 있게 합니다.

### 메시지 및 출력 채널 (Output Channels)

오픈 소스 LLM의 세 가지 주요 사용자 유형을 살펴보면서 메시지 채널의 중요성을 분석해 봅시다.

*   **LLM 앱의 최종 사용자 (End-users)**
    *   예시: ChatGPT 앱 사용자
    *   이러한 사용자들은 주로 자신이 입력하는 사용자 메시지(user message)와 모델이 제공하는 최종 응답 간의 상호작용에 집중합니다.
    *   일부 고급 앱에서는 모델의 중간 추론 흔적(interim reasoning traces)을 제한적으로 접할 수도 있습니다.
*   **LLM 앱 개발자 (Builders)**
    *   예시: Cursor 또는 Manus와 같은 코드 어시스턴트
    *   **입력 메시지 (Input messages)**: 개발자들은 시스템(system) 메시지 및 개발자 메시지(developer messages)를 통해 모델의 전반적인 동작, 안전 지침, 추론 수준, 그리고 사용 가능한 도구(tool) 정의를 설정합니다. 예를 들어, 시스템 메시지는 "당신은 항상 친절하고 유용한 어시스턴트입니다"와 같이 모델의 페르소나를 정의하거나, "모든 응답은 JSON 형식으로 제공되어야 합니다"와 같이 출력 형식을 강제할 수 있습니다.
    *   또한 사용자 메시지(user message)에 대한 정교한 프롬프트 엔지니어링(prompt engineering)과 컨텍스트 관리(context management)를 수행하여 모델의 성능을 최적화해야 합니다.
    *   **출력 메시지 (Output messages)**: 개발자들은 사용자에게 추론 흔적(reasoning traces)을 노출할지 여부를 결정하고, 도구를 정의하며, 모델의 추론 깊이를 조절할 수 있습니다. 이는 사용자 경험과 애플리케이션의 복잡성에 따라 유연하게 대응하기 위함입니다.
*   **LLM 사후 훈련자 (Post-trainers)**
    *   모델을 미세 조정(fine-tune)하는 고급 사용자(power users)는 추론(reasoning) 및 도구 호출(tool calls)을 포함한 모든 메시지 유형과 응답에 대해 올바른 형식의 데이터를 구성하고 상호작용해야 합니다. 미세 조정 시 데이터의 메시지 구조가 모델의 학습 효율성과 최종 성능에 결정적인 영향을 미치기 때문입니다.

LLM 앱 개발자(builders)와 LLM 사후 훈련자(post-trainers)라는 후자의 두 그룹은 어시스턴트 메시지(assistant messages)의 채널(channels) 개념을 명확히 이해함으로써 상당한 이점을 얻을 수 있습니다. 이 개념은 OpenAI의 Harmony 리포지토리(repo)에 잘 구현되어 있습니다. 메시지 채널은 모델의 복잡한 내부 동작을 구조화하고, 개발자가 특정 목적에 맞는 출력을 효과적으로 제어할 수 있도록 돕는 중요한 추상화(abstraction) 계층을 제공합니다.

### 메시지 채널 (Message Channels)

모델이 생성하는 모든 결과는 어시스턴트 메시지(assistant messages)의 형태로 제공됩니다. 모델은 각 메시지의 유형을 명확히 구분하기 위해 이를 특정 '채널(channel)' 범주에 분류합니다.

*   **분석 (Analysis)**: 추론(reasoning) 과정을 담고 있으며, 일부 도구 호출(tool calls)의 의도를 포함할 수 있습니다. 이는 모델의 '생각하는 과정'을 보여주는 채널입니다.
*   **해설 (Elaboration)**: 기능 호출(functional calling)을 포함하며, 대부분의 도구 호출(tool calls)이 이 채널을 통해 이루어집니다. 모델이 특정 행동을 취하거나 외부 시스템과 상호작용하는 부분을 담당합니다.
*   **최종 (Final)**: 최종 사용자(end user)에게 보여질 응답 메시지를 포함합니다. 모델의 최종적인 답변이나 결과물이 이 채널을 통해 전달됩니다.

따라서 모델에 복잡한 추론(reasoning)과 여러 도구 호출(tool calls)을 요구하는 프롬프트(prompt)를 제공한다고 가정해 봅시다. 이 경우 대화는 다음과 같은 흐름을 가질 수 있습니다. 턴(turn) 1에서 사용자 질문에 대해 모델은 '분석' 채널을 통해 내부적으로 추론을 시작합니다. 턴 2에서는 이 추론을 바탕으로 '해설' 채널을 통해 특정 도구 호출을 수행하고, 이에 대한 도구 응답을 받습니다. 턴 3에서 모델은 다시 '분석' 채널을 통해 도구 응답을 해석하고 추가 추론을 진행합니다. 턴 4에서는 또 다른 도구 호출이 '해설' 채널을 통해 발생할 수 있습니다. 최종적으로 턴 5에서는 모든 추론과 도구 호출 결과를 종합하여 '최종' 채널을 통해 사용자에게 명확하고 간결한 답변을 제공합니다. 이러한 명시적인 채널 분리는 모델의 동작을 투명하게 만들고, 개발자가 각 단계에서 모델의 의도를 파악하고 디버깅하는 데 큰 도움을 줍니다.

### 추론 (Reasoning)

추론(reasoning) 활용에는 숙련된 사용자(advanced users)들이 고려해야 할 여러 상충 관계(trade-offs)가 존재합니다. 추론 과정을 더 많이 허용하면 모델이 문제 해결에 더 많은 시간과 컴퓨팅 자원(compute)을 할애하여 복잡한 난제를 처리하는 데 유리하지만, 동시에 지연 시간(latency) 증가와 컴퓨팅 비용 상승이라는 대가를 치르게 됩니다. 이러한 선택의 중요성은 강력한 추론(reasoning) 능력을 갖춘 LLM과 그렇지 않은 LLM이 각기 다른 유형의 문제 해결에 최적화되어 공존한다는 사실에서 명확히 드러납니다. 예를 들어, 창의적인 글쓰기나 간단한 정보 검색에는 빠른 응답의 비추론 모델이 적합할 수 있지만, 복잡한 코드 생성이나 과학적 문제 해결에는 심층적인 추론이 가능한 모델이 필수적입니다.

하나의 절충안은 특정 추론 예산(reasoning budget) 범위 내에서 응답을 생성하는 추론 모델을 활용하는 것입니다. GPT-OSS는 바로 이 범주에 해당하며, 시스템 메시지(system message)를 통해 추론 모드(reasoning mode)를 '낮음(low)', '중간(medium)', '높음(high)'으로 설정할 수 있도록 지원합니다. 모델 카드(model card)의 그림 3은 이 설정이 벤치마크(benchmarks) 점수에 어떻게 영향을 미치는지, 그리고 '사고의 사슬(chain-of-thought, CoT)'이라고도 불리는 추론 흔적(reasoning traces)에 얼마나 많은 토큰(token)이 포함되는지를 보여줍니다. 이는 Qwen3의 추론 모드(reasoning modes)와 대조를 이룹니다. Qwen3는 '사고(thinking)'와 '비사고(non-thinking)'라는 이진적인 모드를 제공합니다. Qwen3의 사고 모드(thinking mode)의 경우, 특정 토큰(token) 임계값(threshold)을 초과하면 사고를 중단하는 방식을 보여주며, 이것이 다양한 추론 벤치마크(reasoning benchmarks) 점수에 미치는 영향을 보고합니다. GPT-OSS의 다단계 추론 모드(multi-level reasoning mode)는 사용자가 애플리케이션의 요구사항에 따라 유연하게 성능과 비용을 조절할 수 있도록 하는 강력한 기능입니다.

### 추론 모드 (Reasoning Modes) (낮음, 중간, 높음)

다양한 추론 모드(reasoning modes)의 차이를 명확히 시연하기 위해, 저는 AIME25 데이터셋(dataset)에서 난이도 높은 추론 문제를 하나 선정하여 120B 모델에 각기 다른 세 가지 추론 모드(reasoning mode)로 질의했습니다. 이 문제의 정확한 답은 104였습니다. 중간(medium) 및 높은(high) 추론 모드(reasoning modes) 모두 정답을 도출했지만, 높은 추론 모드(high reasoning mode)는 동일한 정답에 도달하기 위해 두 배에 달하는 컴퓨팅 자원(compute)과 생성 시간(generation time)을 사용했습니다. 이는 각 사용 시나리오에 가장 적합한 추론 모드(reasoning mode)를 신중하게 선택해야 한다는 점을 다시 한번 역설합니다.

*   **에이전트(agentic) 작업을 수행하시나요?**
    *   다단계 경로를 포함하는 복잡한 에이전트(agent) 워크플로우에서는 높은(high) 또는 심지어 중간(medium) 추론(reasoning) 모드가 전체 작업 완료 시간을 지나치게 지연시킬 수 있습니다. 예를 들어, 웹 검색 후 정보 추출, API 호출, 그리고 최종 보고서 작성까지 여러 단계를 거치는 에이전트의 경우, 각 단계에서 과도한 추론은 비효율적일 수 있습니다. 이러한 경우, 각 단계의 복잡성에 따라 추론 모드를 동적으로 조정하거나, 특정 단계에서는 낮은 추론 모드를 사용하여 빠른 진행을 유도하는 전략이 필요합니다.
*   **실시간(Real time) vs. 오프라인(offline) 처리**
    *   사용자가 실시간으로 응답을 기다리지 않아도 되는 오프라인(offline) 작업에는 높은 추론 모드를 적용하여 더 정확하고 심층적인 결과를 얻을 수 있습니다. 예를 들어, 대규모 데이터셋 분석, 복잡한 보고서 초안 작성, 또는 연구 논문 요약과 같은 작업은 지연 시간에 대한 부담이 적으므로, 모델이 충분한 추론 시간을 가질 수 있도록 허용하는 것이 유리합니다. 반면, 고객 서비스 챗봇이나 실시간 번역과 같이 즉각적인 응답이 요구되는 환경에서는 낮은 추론 모드를 통해 응답 속도를 최우선으로 고려해야 합니다.

### 토크나이저 (Tokenizer)

GPT-OSS의 토크나이저(tokenizer)는 GPT-4의 그것과 매우 흡사하지만, 특히 비영어권 토큰(non-English tokens) 처리에서 미묘하게 더 높은 효율성을 보여줍니다. 토크나이저는 LLM의 성능과 비용에 직접적인 영향을 미치는 핵심 구성 요소입니다. 토큰화(tokenization) 효율성이 높다는 것은 동일한 정보를 표현하는 데 더 적은 토큰이 사용된다는 의미이며, 이는 모델의 입력 길이 제한을 완화하고, API 호출 비용을 절감하며, 추론 속도를 향상시킵니다. 예를 들어, 이모티콘(emoji)과 한자(Chinese character)는 기존 세 개가 아닌 두 개의 토큰(token)으로 처리되며, 아랍어 텍스트의 상당 부분이 개별 글자 단위가 아닌 하나의 토큰(individual token)으로 묶이는 방식에서 이러한 개선점을 확인할 수 있습니다.

토크나이저(tokenizer) 자체는 이러한 측면에서 개선되었을지라도, 모델의 주된 훈련 데이터는 여전히 영어(English data)에 집중되어 있습니다. 이는 토큰화 효율성 개선에도 불구하고, 비영어권 언어에 대한 모델의 언어 이해 및 생성 능력에는 여전히 한계가 있을 수 있음을 시사합니다. 다국어 LLM 개발의 중요한 과제 중 하나는 다양한 언어의 특성을 반영한 균형 잡힌 훈련 데이터셋을 구축하는 것입니다. 코드(code) 토큰화(특히 파이썬(python) 코드의 들여쓰기(indentation)에 사용되는 탭(tabs) 처리)는 대체로 이전과 동일한 방식으로 작동하는 것으로 관찰됩니다. 숫자 토큰화(number tokenization) 역시 최대 세 자리 숫자를 단일 토큰(individual token)으로 취급하고 그보다 큰 숫자는 분리하는 기존의 접근 방식을 유지하고 있습니다. 이는 BPE(Byte Pair Encoding) 기반의 일반적인 토크나이저가 숫자와 코드와 같은 정형화된 텍스트를 처리하는 방식과 일치합니다.

### 추가 자료 (Further Readings)

다음은 GPT-OSS 및 관련 LLM 기술에 대해 더 깊이 탐구할 수 있는 몇 가지 유용한 자료입니다.

*   GPT-2에서 gpt-oss까지: Sebastian Raschka 박사의 아키텍처(Architectural) 발전 분석
*   gpt-oss: OpenAI가 오픈 생태계(open ecosystem)를 (마침내) 검증하다 (Nathan Lambert 저)
*   gpt-oss-120B (높음): API 제공업체 벤치마킹(Benchmarking) 및 분석
*   MoE(Mixture-of-Experts) 아키텍처의 원리와 LLM 스케일링에 미치는 영향
*   LLM의 추론 능력 향상을 위한 Chain-of-Thought 프롬프팅 기법 상세 분석

GPT-OSS의 출시는 OpenAI가 오픈 소스 커뮤니티와의 관계를 재정립하고, LLM 기술의 접근성을 넓히려는 중요한 움직임으로 평가됩니다. 이 모델은 그 자체로 혁신적인 성능을 제공하기보다는, 지난 6년간 발전해 온 LLM 기술의 주요 특징들을 집약하여 보여주는 역할을 합니다. 특히, MoE 아키텍처, 유연한 메시지 채널, 그리고 조절 가능한 추론 모드는 개발자와 고급 사용자가 LLM을 더욱 효과적으로 활용하고 최적화할 수 있는 강력한 도구를 제공합니다. 앞으로 GPT-OSS가 오픈 소스 생태계에 어떤 새로운 활력을 불어넣고, 어떤 혁신적인 애플리케이션의 등장을 촉진할지 주목할 필요가 있습니다.