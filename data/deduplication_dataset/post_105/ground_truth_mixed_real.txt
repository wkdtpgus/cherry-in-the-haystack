AI 너드들의 심리에 대한 심층 분석: 개정판 에세이 - 세 번째 부분입니다. 본 연재는 AI 기술의 급변하는 흐름 속에서 그 이면의 인간 심리를 탐구합니다. 이 글들은 순서대로 읽도록 의도되었습니다(서론은 1부에 포함되어 있습니다). 이전 글인 I. 과잉 존재(Overexistence) (무료)와 II. 현실 도피(Escapism) (유료)에 이어, 이번 글은 'III. 비정치성(Apoliticality)'에 초점을 맞춥니다. 네 번째 부분—IV. 가독성(Legibility)—은 내일 나옵니다.

영국 공군 타이푼 F2 ( 출처 )

AI 너드들은 세상이 자신들을 고칠 수 있다고 생각하지 않습니다. 1부와 2부에서 보았듯이, 그들의 경험은 이 점에서 상당히 일관적이었으며, 이는 그들이 이 행성을 거부하고 자신들을 수용하기 위해 변할 수 있다고 약속하는 모든 도구적 메커니즘(instrumental mechanism) 또한 거부하는 태도로 이어집니다. 이것이 AI 너드들이 정치를 싫어하는 것처럼 보이는 이유입니다—아니, 오히려 기술자들이 그렇습니다. 이는 더 넓은 범위의 정서이기 때문입니다. 그들은 "모든 것이 정치다"라는 말을 일축하며, 사회적 고통을 악화시키기 전에 모든 잠재적인 희망을 차단하고, 동시에 또 다른 형태의 도피, 즉 기술적 집착과 강박에 모든 시간을 바칩니다.

저는 항공우주공학과 학부생 시절을 기억합니다. 그때나 그 이후로, 현실 세계와는 너무나 동떨어져 있으면서도 세상을 더 나은 곳으로 만드는 데 그토록 관심을 가진 사람들을 본 적이 없습니다. 저의 전공 분야인 항공우주 비행체(aerospace vehicles)에서, 우리는 터빈 블레이드(turbine blades)의 합금(alloys)을 조작하거나 탄소 복합재(carbon composite) 조각을 교체하는 등, 괴짜 같은 방식으로 엔진에서 더 많은 속도를 짜내는 것을 꿈꾸곤 했습니다. 하지만 에어버스(Airbus)가 왜 애초에 더 빠른 유로파이터 타이푼(Eurofighter Typhoons)을 필요로 하는지에 대해서는 소리 내어 또는 다른 방식으로 거의 의문을 품지 않았습니다. 그러다 집에 와서 뉴스를 켜고 깨달았습니다. 우리가 참여했던 전투기들이—세상이 어떻게 돌아가는지 전혀 모르는 무지한 학생으로서 간접적으로나마—시리아, 예멘, 아프가니스탄에 배치되었다는 것을 말입니다. 이러한 경험을 통해 저는 잊을 수 없는 깨달음을 얻었습니다. 정치에 발을 들이는 사람들은 그 일에 가장 부적합하다는 것입니다. 흔히 "권력은 부패한다"고들 하지만, 진실은 "권력은 부패할 만한 자를 선택한다"는 말에 더 가깝습니다. 순수하고 (자신을 위해서가 아니라 사람들을 위해서), 선행의 이타적인 즐거움을 누리며, 소속, 외양(optics), 의례(protocol) 및 계산을 늦추는 다른 관료주의(bureaucracies)에 무관심한 사람들은 결코 자발적으로 정치인이 되지 않을 것입니다. 이러한 비정치적 성향은 AI 거버넌스(AI governance) 논의에서도 유사하게 나타나, 기술의 윤리적 사용에 대한 순수한 목소리가 정치적 역학 속에서 희석될 위험이 있습니다.

AI 너드들은 (제가 그들이 일하는 CEO들과는 구분하는) "빛의 삼위일체(Light Triad)" 에너지를 보이는 경향이 있습니다—그들은 사람들이 대부분 선하고, 존엄하게 대우받을 가치가 있으며, 도구적 목표(instrumental goals)로 사용되어서는 안 된다고 믿습니다—그래서 그들은 일반적인 정당 활동가처럼 약자를 공격하여 실패하는 것이 아니라, 아예 공격하지 않음으로써 실패합니다. 그들은 정치 생활에 만연한 출세 경쟁의 역학(ladder-climbing dynamics)을 견뎌낼 만큼 충분한 냉소주의, 교활함, 또는 무감각함을 가지고 있지 않습니다. 그래서 그들은 국가를 폭격하는 것이 "필요악"이라고 이해하는 사람들에게 길을 내줍니다. AI 기술이 사회에 미치는 영향이 커질수록, 이러한 비정치성은 기술의 책임 있는 발전을 저해하는 요소가 될 수 있습니다.

더 깊은 통찰을 원하신다면: 이 시리즈의 다른 글들도 확인해보세요. AI 기술과 인간 심리에 대한 심층적인 관점을 제공합니다. 최신 연재 소식과 독점 콘텐츠를 받아보시려면 구독을 고려해주세요.

제가 온라인에서 몰래 지켜보는 AI 커뮤니티(AI circles)는 대학 시절을 떠올리게 합니다. 자폐성 서번트(autistic savants)들이 오직 한 가지에만 몰두하는 것처럼 말입니다. 세상에 더 많은 데이터센터(datacenters)를, 데이터센터에 더 많은 GPU(GPUs)를, GPU에 더 많은 모델 파라미터(model parameters)를, 그리고 모델에 더 많은 데이터 토큰(data tokens)을 어떻게 담을 것인가 하는 것입니다—이는 비유적인 의미에서 망치로 모루(anvil)를 치는 것을 좋아하고 다른 것에는 거의 신경 쓰지 않는다는 것을 복잡하게 표현한 것입니다. 그들의 삶은 단순하지만 어려운 문제들의 무한한 연속에 대한 해결책을 끊임없이 추구하는 것이었습니다. 아니, 오히려 그랬었습니다. 몇 년 전, 근본적인 무언가가 급진적으로 변했습니다.

2024년 이후, AI 기술은 단순한 스케일링을 넘어 '정렬(alignment)', '안전(safety)', '책임감 있는 AI(responsible AI)'와 같은 윤리적, 사회적 문제에 대한 논의가 기술 개발의 핵심으로 부상했습니다. 과거 순수한 공학적 이상에만 몰두하던 AI 너드들에게 이제는 자신들의 기술이 가져올 사회적 영향과 정치적 함의를 직시해야 할 필요성이 커졌습니다. 비정치성을 고수하는 태도는 더 이상 기술 발전의 면죄부가 될 수 없으며, 기술의 책임 있는 미래를 위해 적극적인 참여와 성찰이 요구되는 시점입니다.