**편집자 주**: 최근 뉴스레터 및 팟캐스트의 규칙적인 발행이 지연된 것에 대해 유감의 말씀을 전합니다. 신생 기업 활동으로 인해 필자와 동료 진행자 모두 매우 분주한 시간을 보냈습니다. 인공지능 기술의 급변하는 흐름 속에서 양질의 정보를 꾸준히 전달하는 것이 쉽지 않음을 새삼 느낍니다. 하지만 독자 여러분의 지속적인 관심과 성원에 힘입어 금주부터 뉴스레터와 팟캐스트 모두 주간 발행 체제를 다시 가동할 것을 약속드립니다. AI 분야의 최신 동향과 심층 분석을 계속해서 제공하기 위해 최선을 다하겠습니다.

**OpenAI, 브로드컴과 AI용 맞춤형 칩 공동 개발 계약 체결**
**관련**: 브로드컴 주가, OpenAI 맞춤형 칩 계약으로 9% 급등, 엔비디아 및 AMD 계약에 추가
AMD, OpenAI와 AI 칩 공급 계약 체결, 주가 34% 이상 급등

OpenAI는 브로드컴(Broadcom)과 인공지능 가속기(AI accelerators)를 공동으로 설계하고 배포하기 위한 협약을 맺었으며, 내년 말부터 OpenAI가 자체적으로 구상한 칩 랙(racks)을 시장에 선보일 예정입니다. 이 시스템은 브로드컴의 이더넷 스택(Ethernet stack)에 연산 능력(compute), 저장 공간(memory), 그리고 네트워크 연결(networking) 기능을 통합함으로써 OpenAI의 작업 부하(workloads) 처리 효율성을 크게 높이고, 엔비디아(Nvidia)와 AMD에 대한 의존도를 완화하는 것을 목표로 합니다.

이러한 협력은 약 10기가와트(gigawatts) 규모의 컴퓨팅 역량(compute capacity)을 확보하려는 OpenAI의 장기 계획과 궤를 같이합니다. OpenAI는 이미 텍사스주 애빌린(Abilene)에 데이터센터(data center)를 건설 중이며, 텍사스, 뉴멕시코, 오하이오, 중서부 등 여러 지역에 추가 부지를 물색하고 있습니다. 업계 분석에 따르면 1기가와트(gigawatt)급 AI 데이터센터(data center)를 구축하는 데 약 500억 달러(현재 엔비디아 칩 가격 기준으로 약 350억 달러가 칩 비용)가 소요될 것으로 추정되는데, 이는 맞춤형 실리콘(custom silicon) 도입이 컴퓨팅 관련 비용(compute costs)을 대폭 절감할 수 있음을 시사합니다. OpenAI는 엔비디아(Nvidia), 오라클(Oracle), AMD와도 대규모 계약을 체결한 바 있습니다. 엔비디아는 1,000억 달러 투자 계획을 밝혔고, AMD는 OpenAI의 확장을 지원하기 위해 1억 6천만 주(AMD 주식의 약 10%)를 사실상 제공했으나, 브로드컴은 지분 투자는 하지 않습니다. 브로드컴의 맞춤형 AI 칩(XPU)은 하이퍼스케일러(hyperscalers)로부터 높은 수요를 받고 있으며, 이 소식에 브로드컴 주가는 약 9.9% 급등했습니다. 그러나 브로드컴은 OpenAI가 이전에 공개했던 100억 달러 규모의 고객은 아니라고 밝혔습니다.

이처럼 주요 AI 기업들이 맞춤형 칩 개발에 뛰어드는 것은 단순한 비용 절감을 넘어선 전략적 움직임으로 해석됩니다. 구글의 TPU, 아마존의 Trainium 및 Inferentia, 마이크로소프트의 Maia 100, 테슬라의 Dojo 등 자체 칩 개발 사례는 인공지능 워크로드에 최적화된 하드웨어를 통해 성능을 극대화하고, 특정 벤더에 대한 종속성을 줄이려는 의지를 보여줍니다. 이는 AI 기술 스택(stack)의 수직 통합을 가속화하며, 장기적으로는 엔비디아가 주도하는 AI 칩 시장에 새로운 경쟁 구도를 형성할 수 있습니다. 각 기업의 고유한 AI 모델 및 서비스에 맞춰 설계된 칩은 범용 GPU로는 달성하기 어려운 효율성과 성능을 제공하며, 이는 AI 서비스의 가격 경쟁력 및 혁신 속도에 결정적인 영향을 미칠 것입니다.

**OpenAI, DevDay 2025에서 대규모 발표: AgentKit, Apps SDK, ChatGPT 등**
**관련**: OpenAI, ChatGPT 내 앱 출시
OpenAI, 개발자들이 AI 에이전트(AI agents)를 구축하고 배포하도록 돕는 AgentKit 출시
OpenAI, API에 더 강력한 모델을 추가하여 개발자 지원 강화
샘 알트만(Sam Altman), ChatGPT 주간 활성 사용자 8억 명 돌파 발표

OpenAI의 DevDay 2025에서는 ChatGPT를 앱 플랫폼(app platform)이자 에이전트 운영 체제(agent OS)로 재정의하는 비전을 제시했습니다. 이를 위해 ChatGPT 내 앱(Apps inside ChatGPT) 기능, 미리보기 앱 SDK(Apps SDK), 그리고 AgentKit을 공개했습니다. 앱은 모델 컨텍스트 프로토콜(Model Context Protocol, MCP)을 통해 대화형 사용자 인터페이스(interactive UIs), 비디오, 로그인(login) 처리, 그리고 다양한 액션(actions)과 함께 ChatGPT의 응답에서 직접 실행됩니다. 초기 출시 파트너로는 Canva, Zillow, Coursera, Figma, Spotify, Booking.com, Expedia 등이 있으며, DoorDash, Instacart, Uber, AllTrails는 "곧 출시될 예정"입니다. 라이브 시연에서는 "앱과 대화하기"의 전반적인 기능이 소개되었습니다. 예를 들어, Canva에서 포스터를 생성하거나 피치 덱(pitch deck)을 자동으로 구축하는 모습, 그리고 자연어 필터(natural-language filters)와 지도를 활용하여 Zillow 매물을 검색하는 기능(ChatGPT 내 전체 화면 렌더링 포함) 등이 선보였습니다.

개발자 데이의 다른 주요 발표 사항으로는 Agent Builder(에이전트용 시각적 "Canva")와 함께 공개된 AgentKit, 임베드 가능한 채팅 UI인 ChatKit, 에이전트 성능 평가 도구(Evals for Agents, 단계 추적 채점, 데이터셋, 자동 프롬프트 최적화, 외부 모델 평가), 그리고 관리자 제어 기능을 갖춘 커넥터 레지스트리(Connectors registry) 등이 포함되었습니다. 라이브 시연에서는 단 8분 만에 두 개의 실제 에이전트(production agents)와 안전장치(guardrails)를 구축하는 모습을 보여주었습니다. Codex는 연구 미리보기(research preview) 단계에서 일반 출시(general availability)로 전환되었으며, 무대 시연에서는 카메라를 Xbox 360 컨트롤러에 연결하고, 조명을 위한 음성 비서(voice assistant)를 만들고, 오버레이(overlays), 카운트다운(countdowns), 단체 사진을 자동으로 생성하는 기능이 시연되었습니다. 새로운 API 모델(API models)에는 높은 정확도와 심층 추론 사용 사례를 위한 GPT-5 Pro; 동기화된 오디오, 물리적 일관성, 세분화된 카메라 제어 기능을 갖춘 Sora 2 비디오(미리보기); 그리고 이전 고급 음성 모델보다 "70% 저렴한" 저지연 음성 모델(low-latency voice model)인 gpt-realtime-mini가 포함되었습니다. 샘 알트만은 또한 ChatGPT가 현재 주간 활성 사용자 8억 명, 개발자 4백만 명, API에서 분당 60억 토큰(tokens)을 처리하고 있으며, 개발자 앱 제출(developer app submissions)은 올해 말에 검토를 위해 개방될 것이라고 밝혔습니다.

이번 DevDay는 단순한 모델 업데이트를 넘어, 인공지능이 "생성(generative)" 단계를 넘어 "행동(agentic)" 단계로 진화하고 있음을 명확히 보여주었습니다. 에이전트(agent)는 이제 복잡한 다단계 작업을 스스로 계획하고 실행하며, 외부 도구와 상호작용하고, 심지어 자신의 행동을 평가하고 수정할 수 있는 자율적인 주체로 거듭나고 있습니다. 이는 개인 비서, 비즈니스 자동화, 콘텐츠 제작 등 다양한 분야에서 혁신적인 애플리케이션의 등장을 예고합니다. 예를 들어, AgentKit은 사용자가 자연어로 복잡한 프로젝트 관리 에이전트를 구축하여 여러 팀원과 앱을 조율하게 하거나, 개인 재정 관리 에이전트가 사용자의 소비 패턴을 분석하고 예산을 자동으로 조정하며 투자 기회를 제안하는 등의 시나리오를 가능하게 합니다. Sora 2와 gpt-realtime-mini와 같은 멀티모달(multimodal) 기능의 발전은 이러한 에이전트들이 더욱 인간과 유사하게 세상을 인지하고 상호작용할 수 있도록 하여, 그 활용 범위를 무한히 확장할 것입니다.

**Anthropic, 더 작고 경제적인 AI 모델 Claude Haiku 4.5 공개**
Anthropic은 Claude 4.x 계열 중 가장 소형화되고 비용 효율적인 모델인 Claude Haiku 4.5를 출시했으며, 이제 무료 이용자(free tier)를 포함한 모든 사용자들이 접근할 수 있게 되었습니다. 이 기업은 Haiku 4.5가 특히 신속하며 "기대치를 뛰어넘는 성능을 발휘한다"고 강조했는데, 이는 이전의 대규모 모델들을 능가하며 컴퓨터 활용 작업에서는 Claude Sonnet 4보다 우수한 결과를 보인다는 설명입니다. 코딩(coding) 영역에서 Haiku 4.5는 실제 버그 수정(bug fixing) 성능을 측정하는 벤치마크(benchmark)인 SWE-bench Verified에서 Claude Sonnet 4 및 OpenAI의 GPT-5와 유사한 점수를 기록했습니다.

가격 측면에서 Haiku 모델은 Sonnet 비용의 약 3분의 1 수준이며, Sonnet은 Opus 비용의 약 5분의 1에 불과합니다. 이는 Haiku 4.5를 가장 저렴한 유료 선택지로 만들면서도, 더 작은 모델 크기 덕분에 무료 사용자에게 더 많은 용량을 제공할 수 있게 합니다. 이번 출시는 Sonnet 4.5(9월)와 Opus 4.1(8월)에 이은 것이며, 업데이트된 Opus는 2024년 말 또는 2025년 초에 출시될 예정입니다. 매출 연간 환산액(revenue run rate)이 70억 달러에 육박하고 30만 명 이상의 기업 고객을 보유하며 1,830억 달러의 가치를 평가받는 Anthropic은 GPT-5를 출시하고 인프라 계약(infrastructure deals)과 Sora로 확장한 구글(Google) 및 OpenAI와의 경쟁 속에서 출시를 가속화하고 있습니다.

Anthropic의 Haiku, Sonnet, Opus로 이어지는 다층 모델 전략은 다양한 시장 요구를 충족시키기 위한 정교한 접근 방식입니다. Haiku는 빠르고 저렴한 응답이 필요한 경량 작업이나 대규모 무료 사용자 기반을 위한 모델이며, Sonnet은 비용과 성능의 균형을 맞춘 중간급 모델, 그리고 Opus는 최상급의 추론 능력과 복잡한 문제 해결을 위한 플래그십 모델입니다. 이러한 세분화된 전략은 Anthropic이 개인 개발자부터 대기업에 이르기까지 폭넓은 고객층을 공략하고, 각 사용 사례에 최적화된 솔루션을 제공하여 시장 점유율을 확대하는 데 기여합니다. 이는 AI 모델의 '범용성'과 '특정성' 사이의 균형을 찾아가는 업계의 중요한 흐름을 보여주며, 앞으로도 다양한 성능과 가격대의 모델들이 시장에 등장할 것임을 시사합니다.

**구글, Veo 3.1 출시, Flow 비디오 편집기에 추가**
구글은 자사의 비디오 생성 모델(video generation model)인 Veo 3의 개선된 버전인 Veo 3.1을 공개했으며, 이 버전은 더욱 정교한 시각적 품질(higher-fidelity visuals), 강화된 프롬프트(prompt) 이해력, 그리고 광범위한 편집 제어 기능에 중점을 둡니다. 이번 업데이트는 이미지-비디오(image-to-video) 전환의 품질을 향상시키고 더 나은 오디오 출력(audio output)을 도입하며, 참조 이미지 기반 캐릭터 제어(reference-image character control), 첫/마지막 프레임을 활용한 클립 생성(first/last-frame guided clip generation), 그리고 후행 프레임(trailing frames)으로부터 클립 확장(clip extension)과 같은 기능에 동기화된 오디오를 추가합니다. Veo 3.1은 또한 클립의 시각적 스타일에 자연스럽게 어우러지는 객체 추가를 포함한 세밀한 편집(granular edits)을 지원하며, Flow에서는 곧 객체 제거(object removal) 기능이 제공될 예정입니다. 새로운 모델은 현재 Flow, Gemini 앱, 그리고 Vertex 및 Gemini API를 통해 이용할 수 있습니다.

Veo 3.1의 출시는 비디오 생성 AI가 단순한 자동 생성 단계를 넘어 전문적인 콘텐츠 제작 도구로 진화하고 있음을 보여줍니다. 특히 세분화된 편집 기능(granular edits)과 객체 추가/제거 기능은 영화 제작, 광고, 게임 개발 등 고품질 비주얼이 요구되는 산업에서 큰 파급력을 가질 것입니다. OpenAI의 Sora나 RunwayML과 같은 경쟁 모델들이 주목받는 상황에서, 구글은 Veo를 통해 사용자에게 더 많은 통제권을 부여하고, Gemini 생태계 내에서 이러한 기능을 원활하게 통합함으로써 차별화를 꾀하고 있습니다. 이는 AI가 창작자의 역할을 대체하기보다는, 그들의 생산성과 창의성을 극대화하는 강력한 보조 도구로 자리매김하고 있음을 의미합니다.

**OpenAI, Sora의 저작권 작품 사용에 대한 입장 변경**
**관련**: AI 샘 알트만과 Sora 저작권 도박: '닌텐도가 우리를 고소하지 않기를 바란다'
OpenAI는 Sora의 저작권 논란을 예상하지 못했다
OpenAI 비디오 앱 Sora, ChatGPT보다 빠르게 100만 다운로드 달성
OpenAI의 Sora, 애플 미국 앱 스토어(App Store) 1위 등극
Sora 모방 앱들이 애플 앱 스토어(App Store)를 범람했으며, 일부는 여전히 남아있다

OpenAI는 Sora의 훈련 데이터(training data)와 저작권 처리(copyright handling) 방식에 대한 집중적인 조사를 받은 후, 법적 및 홍보적 압박이 커짐에 따라 공개적인 입장을 수정했습니다. Sora의 출시는 빠른 사용자 유입을 촉진하여 앱을 미국 앱 스토어(App Store) 최상위권으로 끌어올렸으며, 수많은 모방 앱(copycat apps)의 등장을 야기하기도 했습니다. 알트만의 발언과 여러 언론 보도는 저작권 침해 위험(copyright risk), 사용자 수요(user demand), 그리고 플랫폼 거버넌스(platform governance) 문제가 Sora의 신속한 출시 과정에서 어떻게 복합적으로 작용했는지 강조합니다.

AI 모델 훈련 데이터의 저작권 문제는 인공지능 산업 전반에 걸쳐 가장 뜨거운 논쟁거리 중 하나입니다. 창작자들은 자신들의 작품이 AI 모델 학습에 무단으로 사용되어 권리를 침해당했다고 주장하는 반면, AI 개발자들은 '공정 이용(fair use)' 원칙을 내세우며 혁신의 자유를 강조합니다. 이러한 논쟁은 단순히 법적 소송을 넘어, 미래의 데이터 거버넌스 모델, 콘텐츠 라이선싱 방식, 그리고 AI 시대의 창작자 보상 시스템을 재정립하는 중요한 계기가 되고 있습니다. 일부에서는 학습 데이터에서 특정 콘텐츠를 '옵트아웃(opt-out)'할 수 있는 메커니즘이나, 아예 저작권 문제에서 자유로운 합성 데이터(synthetic data)를 활용하는 방안을 모색하고 있으나, 이 역시 윤리적, 기술적 난제를 안고 있습니다.

**기타 뉴스**

**도구**
**마이크로소프트, 엑셀(Excel)과 워드(Word)에 '바이브 워킹(vibe working)' 출시.**
OpenAI의 GPT-5(Copilot 채팅의 Anthropic 기반 Office 에이전트 포함)로 구동되는 마이크로소프트의 새로운 "에이전트 모드(Agent Mode)"는 간단한 지시(prompts)만으로 복잡한 스프레드시트(spreadsheets), 문서(documents), 슬라이드 덱(slide decks)을 생성, 계획, 그리고 실행할 수 있게 합니다. 이는 기존 사무 작업의 패러다임을 변화시켜, 사용자가 반복적인 수작업 대신 전략적 사고와 창의적인 문제 해결에 집중할 수 있도록 돕습니다.

**Anthropic AI, Petri 출시: AI 에이전트(AI Agents)의 동작을 테스트하는 자동화된 감사(Automated Auditing)를 위한 오픈소스 프레임워크(Open-Source Framework).**
Petri는 감사 에이전트(auditor agent)를 조정하여 대상 모델(target models)에 대해 여러 단계의 상호작용(multi-turn)과 도구 활용 프로브(tool-augmented probes)를 실행하고, 실제와 유사한 환경 및 도구를 합성하며, LLM 심사관(LLM judge)을 활용하여 36차원 루브릭(rubric)에 따라 스크립트(transcripts)를 평가함으로써 대규모 정렬 감사(alignment audits) 과정을 자동화합니다. 이처럼 복잡한 AI 에이전트의 신뢰성과 안전성을 보장하기 위한 자동화된 감사 도구의 중요성은 점점 커지고 있습니다. Petri와 같은 프레임워크는 AI 시스템의 편향성, 의도치 않은 행동, 그리고 성능 저하를 체계적으로 테스트하여 윤리적이고 안정적인 AI 배포에 필수적인 역할을 합니다.

**Anthropic, Claude를 업무에 더 유용하게 만들기 위해 '스킬(skills)' 활용.**
조직은 Claude.ai, Claude Code, API, Claude 에이전트 SDK(Claude Agent SDK) 전반에 걸쳐 통합되어 Claude가 특정 업무 작업을 수행하도록 가르치는 재사용 가능한 "스킬(Skills)"(명령, 스크립트, 리소스 세트)을 생성하고 공유할 수 있습니다.

**세일즈포스, 엔터프라이즈 AI(enterprise AI) 경쟁이 심화됨에 따라 Agentforce 360 발표.**
이번 업데이트는 새로운 프롬프트(prompting) 및 빌더 도구(builder tools)(베타 에이전트 스크립트(Agent Script) 및 "Vibes" 앱-바이브 코딩(app-vibe coding)이 포함된 Agentforce Builder 포함), Agentforce의 슬랙(Slack) 통합 심화, 그리고 고객이 Anthropic, OpenAI, 구글의 추론 모델(reasoning models)을 사용하여 더 예측 가능하고 유연한 엔터프라이즈 에이전트(enterprise agents)를 구축할 수 있도록 합니다.

**슬랙, 슬랙봇(Slackbot)을 AI 비서(AI assistant)로 전환 중.**
슬랙봇(Slackbot)은 채널(channels)과 파일(files) 전반에서 계획과 요약을 취합하고, 자연어(natural language)로 작업 공간(workspace)을 검색하며, 캘린더(calendars)를 조정하는 기능을 얻고 있습니다. 이는 VPC(Virtual Private Cloud) 내에서 실행되므로 고용주는 옵트아웃(opt out)할 수 있습니다.

**구글의 AI 모드(AI Mode) 이미지 검색, 더욱 대화형으로 진화.**
사용자는 자연어 후속 질문(natural-language follow-ups)으로 검색을 세분화하고, 업로드된 참조 이미지(reference images)를 텍스트 프롬프트(text prompts)와 혼합할 수 있게 됩니다. 영어 버전 출시는 이번 주 미국에서 시작됩니다.

**구글의 Search Live, 인도에 출시, AI 모드(AI Mode)에 더 많은 언어 추가.**
구글은 인도에서 영어와 힌디어로 Search Live를 출시하고, AI 모드(AI Mode)를 7개 추가 인도 언어로 확장하며, 현지 상호작용을 활용하여 시간이 지남에 따라 다중 모달 시각 이해(multimodal visual understanding)를 개선할 예정입니다.

**마이크로소프트 AI, 자체 개발 첫 이미지 생성기 발표.**
마이크로소프트의 자체 개발 모델은 사실감(photorealism)과 속도를 우선시하며, 창의적인 전문가들의 피드백을 통합하여 일반적인 스타일을 피하고, 이미 AI 벤치마크(benchmark) 사이트 LMArena에서 상위 10위 안에 들었습니다.

**Zendesk, 새로운 AI 에이전트(AI agent)가 지원 문제의 80%를 해결할 수 있다고 밝혀.**
Zendesk는 최근 AI 인수(AI acquisitions)를 통해 구축되고 더 높은 만족도를 보고한 고객들과 테스트된 여러 LLM 기반 에이전트(LLM-driven agents)를 도입하고 있습니다. 여기에는 대부분의 티켓을 위한 자율 에이전트(autonomous agent), 인간 기술자를 위한 코파일럿(co-pilot), 전문 관리, 음성, 분석 에이전트(analytics agents)가 포함됩니다.

**비즈니스**
**아마존의 Zoox 로보택시(Robotaxis), 라스베이거스에 도착.**
Zoox는 휴대폰 앱을 통해 라스베이거스 스트립(Las Vegas Strip)을 따라 지도화되고 지오펜스(geofenced)된 지역 내에서 무료 탑승을 제공하고 있습니다. 초기 탑승자 보고서는 대부분 긍정적이었으며 사고는 보고되지 않았습니다.

**Waymo의 로보택시(robotaxis), 런던에 진출.**
Waymo는 몇 주 내에 런던에서 감독 하에 데이터 수집(data-collection) 운행을 계획하고 있으며, 2026년에는 Moove가 차량을 유지보수하는 방식으로 앱을 통한 완전 무인 호출 서비스(fully driverless ride-hail service)를 출시하는 것을 목표로 합니다.

**OpenAI, 비공개 주식 매각(private stock sale) 후 세계에서 가장 가치 있는 비상장 기업(private company)으로 등극.**
2차 주식 매각(secondary share sale)을 통해 현재 및 전직 직원들에게 66억 달러가 지급되었으며, 소프트뱅크(SoftBank)와 T. 로우 프라이스(T. Rowe Price) 등의 구매자들이 참여하여 OpenAI의 가치를 5,000억 달러로 평가했습니다. 이는 막대한 인프라 지출(infrastructure spending)과 지속적인 제품 출시(product launches) 속에서 OpenAI의 자금 조달 동력(fundraising momentum)을 부각시킵니다. 이러한 높은 기업 가치 평가는 AI 분야에 대한 투자자들의 엄청난 신뢰를 보여주지만, 동시에 'AI 거품'에 대한 논쟁을 불러일으키기도 합니다. 인공지능 개발의 막대한 컴퓨팅 자원 및 인재 확보 비용을 고려할 때, 이러한 자금 조달은 필수적이지만, 향후 IPO(기업공개) 시 시장의 기대를 충족시킬 수 있을지에 대한 관심이 커지고 있습니다.

**메타, Arm과 협력하여 AI 노력 확장.**
다년간의 계약에 따라 메타(Meta)는 데이터센터(data-center) 용량(프로메테우스(Prometheus) 및 하이페리온(Hyperion)이라는 코드명 프로젝트 포함)을 확장함에 따라 와트당 성능(performance per watt)을 개선하기 위해 랭킹(ranking) 및 추천 시스템(recommendation systems)을 Arm의 Neoverse 플랫폼으로 이전할 예정입니다.

**Reflection AI, DeepSeek에 도전하며 미국의 오픈 프론티어 AI 연구소(open frontier AI lab)가 되기 위해 20억 달러 유치.**
새로운 자금은 대규모 컴퓨팅(large-scale compute)을 확보하고 프론티어 LLM(frontier LLM)(초기에는 텍스트 중심이며, 미래에는 다중 모달(multimodal) 기능 포함)을 훈련할 인재를 모집하는 데 사용될 것입니다. 이 LLM의 공개된 모델 가중치(model weights)는 오픈 액세스(open-access) 대안을 제공하는 것을 목표로 하며, 수익화(monetization)는 기업 및 국가 배포(sovereign deployments)를 대상으로 합니다.

**Supabase, 20억 달러 달성 4개월 만에 50억 달러 가치 평가 확보.**
Supabase는 새로운 자금을 유치하여 총 자본금을 5억 달러로 늘렸으며, 시리즈 E(Series E)의 일환으로 커뮤니티 개발자(community developers)가 주식을 구매할 수 있는 옵션을 포함했습니다.

**Character.AI, 스튜디오 경고 후 플랫폼에서 디즈니 캐릭터 제거.**
Character.AI는 저작권 및 상표권이 있는 캐릭터(copyrighted and trademarked characters)의 무단 사용을 주장하는 중단 및 금지 서한(cease-and-desist letter)을 받은 후, 사용자가 만든 디즈니 캐릭터 모방 봇(bots)을 제거했습니다.

**일반**
**Intuition, 비디오 게임 클립(video game clips)을 사용하여 에이전트(agents)에게 공간 추론(spatial reasoning)을 가르치기 위해 1억 3,400만 달러 시드 투자 유치.**
이 스타트업은 Medal의 게임 클립 데이터셋(dataset)을 사용하여 1인칭 게임 플레이(first-person gameplay)에서 시공간 추론(spatial-temporal reasoning)을 학습하는 에이전트(agents) 및 파운데이션 모델(foundation models)을 훈련하고 있습니다. 이는 더 스마트한 게임 내 봇(in-game bots)과 수색 및 구조 드론(search-and-rescue drones)을 목표로 하며, 연구 및 엔지니어링(engineering)을 확장하기 위해 1억 3,370만 달러를 유치했습니다.

**연구**
**샘플링(Sampling)을 통한 추론: 당신의 기본 모델(Base Model)은 생각보다 똑똑하다.**
훈련 과정 없이 MCMC 샘플링(MCMC sampling) 기법을 활용하여 기본 모델(base-model) 출력의 "멱분포(power distribution)"를 목표로 할 때, 연구자들은 추론 시 샘플링(inference-time sampling)이 단일 샷(single-shot) 및 도메인 외 추론 작업(out-of-domain reasoning tasks)에서 RL 후 훈련(RL post-training, GRPO)과 유사하거나 더 나은 성능을 보이며, 여러 샘플의 다양성(multi-sample diversity)을 유지함을 입증했습니다. 이는 값비싼 모델 재훈련 없이도 기존 모델의 잠재력을 최대한 끌어내는 '스마트 샘플링' 기법의 중요성을 강조합니다. 특히 리소스가 제한적인 환경이나 미세 조정되지 않은 모델에서 복잡한 추론 작업을 수행할 때 효율성과 성능을 동시에 향상시키는 데 기여할 수 있습니다.

**대규모 진화 전략(Evolution Strategies): 강화 학습(Reinforcement Learning)을 넘어선 LLM 미세 조정(Fine-Tuning).**
이 논문은 LLM 미세 조정(fine-tuning)을 위해 수십억 개의 모델 매개변수(model parameters)를 직접 탐색하는 메모리 효율적이고 고도로 병렬화된 진화 전략(evolution strategies) 구현을 제시하며, 결과만 있는 추론 작업(outcome-only reasoning tasks)에서 강화 학습(reinforcement learning)보다 더 나은 샘플 효율성(sample efficiency), 견고성(robustness), 안정성(stability)을 보여줍니다.

**기본 모델(Base Models)은 추론 방법을 알고, 사고 모델(Thinking Models)은 언제 추론할지 학습한다.**
저자들은 "사고 모델(thinking model)"의 이점 대부분이 기본 모델(base models)이 이미 가지고 있는 추론 행동(reasoning behaviors)을 언제 활성화할지 학습하는 데서 온다고 주장하며, 이는 조종된 기본 모델(steered base models)이 목표 활성화 편집(targeted activation edits)의 작은 부분을 통해 벤치마크 성능 격차(benchmark performance gap)의 대부분을 회복할 수 있도록 합니다.

**LLM을 위한 강화 학습 컴퓨팅(Reinforcement Learning Compute) 확장 기술.**
수십만 GPU 시간(GPU-hours)에 걸쳐 검증된 예측 시그모이드(sigmoid) 유사 스케일링 프레임워크(scaling framework)와 ScaleRL이라는 RL 레시피(recipe)는 연구자들이 작은 실행(small runs)에서 RL 성능을 외삽(extrapolate)하고, 확장 가능한 방법(scalable methods)을 식별하며, 점근적 성능(asymptotic performance)과 컴퓨팅 효율성(compute efficiency)을 향상시키도록 돕습니다.

**행동으로서의 메모리: 장기 에이전트 작업(Long-Horizon Agentic Tasks)을 위한 자율 컨텍스트 큐레이션(Autonomous Context Curation).**
MemAct는 메모리 큐레이션(memory curation)을 명시적인 편집 행동(explicit editing actions)으로 취급하고 이를 동적 컨텍스트 정책 최적화(Dynamic Context Policy Optimization) 알고리즘과 결합하여, 에이전트(agents)가 토큰(token) 및 지연 시간(latency) 비용을 제어하면서 장기 작업(long-horizon tasks)을 위한 작업 메모리(working memory)를 자율적으로 관리하고 최적화할 수 있도록 합니다.

**언어화된 샘플링(Verbalized Sampling): 모드 붕괴(Mode Collapse)를 완화하고 LLM 다양성(Diversity)을 확보하는 방법.**
언어화된 샘플링(Verbalized Sampling)은 모델에게 확률과 함께 여러 응답을 출력하도록 요청하는 프롬프트(prompting) 기술로, 선호도 데이터(preference data)의 전형성 편향(typicality bias)에 대응하고 재훈련 없이 사전 훈련된 다양성(pretrained diversity)을 복구합니다.

**생성형 AI(GenAI)가 학업 성과를 향상시킬 수 있는가? 사회 및 행동 과학(Social and Behavioral Sciences)의 증거.**
저자 수준 패널 데이터(author-level panel data)와 차이의 차이 설계(difference-in-differences design)를 사용하여, 이 연구는 ChatGPT 출시 후 생성형 AI(GenAI)를 사용하기 시작한 연구자들이 출판물 생산량(publication output)을 증가시켰으며(특히 초기 경력 및 비영어권 저자), 평균 저널 영향력(average journal impact)에서 완만한 상승을 보였다는 것을 발견했습니다.

**우려**
**OpenAI의 내부 슬랙(Slack) 메시지, 저작권 소송에서 수십억 달러의 비용 초래 가능성.**
불법 복제된 LibGen 훈련 데이터셋(training dataset) 삭제에 대한 내부 슬랙(Slack) 및 이메일 논의(변호사가 삭제를 조언했는지 여부 포함)는 이제 원고들이 고의적인 증거 인멸을 보여주고 특권 통신(privileged communications)에 대한 접근을 확보하려 함에 따라 핵심 증거가 되었으며, 이는 잠재적으로 손해 배상액(damages)을 극적으로 증가시킬 수 있습니다. AI 기업들이 훈련 데이터를 수집하고 사용하는 방식에 대한 법적, 윤리적 긴장감은 점점 고조되고 있습니다. 내부 커뮤니케이션이 소송의 핵심 증거로 채택될 수 있다는 사실은 AI 개발 과정의 투명성과 데이터 거버넌스 정책의 중요성을 다시 한번 상기시킵니다. 이는 향후 콘텐츠 라이선싱 모델과 AI 학습 데이터 사용에 대한 새로운 규제 프레임워크를 형성하는 데 결정적인 영향을 미칠 수 있습니다.

**AI 사용자들, OpenAI 계약 관련 반독점 집단 소송(antitrust class action)으로 마이크로소프트 고소 | 로이터.**
제안된 집단 소송(class action)은 마이크로소프트의 OpenAI 투자 및 계약이 반독점법(antitrust laws)을 위반한다고 주장하며, 경쟁 피해(competitive harm)에 대한 구제책을 모색합니다.

**정책**
**캘리포니아, AI 동반자 챗봇(AI companion chatbots)을 규제하는 첫 번째 주가 되다.**
새로운 법률은 연령 확인(age verification), 콘텐츠 경고(content warnings), 자살 예방 프로토콜(suicide-prevention protocols)을 의무화하고, 상호작용이 AI에 의해 생성되었음을 명확히 공개하도록 요구하며, 챗봇이 의료 전문가인 것처럼 가장하는 것을 금지합니다. 위반 시 불법 딥페이크(deepfakes)에 대한 벌금을 포함한 처벌이 따를 수 있습니다. 이러한 조치는 전 세계적으로 AI 규제 논의가 활발한 가운데, 특히 민감한 분야인 동반자 AI에 대한 선제적인 대응으로 평가됩니다. EU의 AI Act와 같은 포괄적인 규제와는 달리, 캘리포니아는 특정 AI 애플리케이션의 위험 요소를 직접적으로 다루는 방식으로 사용자 안전과 윤리적 사용을 강조하고 있습니다.

**분석**
**바이트댄스(ByteDance)가 중국에서 가장 인기 있는 AI 챗봇(AI Chatbot)을 만든 방법.**
바이트댄스(ByteDance)의 Doubao는 채팅, 이미지 및 짧은 비디오 생성, 다중 모달 음성 및 비디오 상호작용, 맞춤형 AI 에이전트(AI agents), 그리고 Douyin과의 깊은 통합을 결합하여 광범위한 비기술 사용자층에 도달하며, 월간 활성 사용자(monthly active users) 1억 5,700만 명 이상을 확보합니다.

**인터넷의 50% 이상이 이제 AI 슬롭(AI Slop), 새로운 데이터 발견.**
Surfer 탐지기(detector)를 사용하여 65,000개의 영어 기사를 분석한 Graphite의 연구에 따르면, ChatGPT가 2022년에 출시된 후 AI가 작성한 콘텐츠(AI-written content)가 급격히 증가하여 현재 새로운 기사의 약 52%를 차지하고 있다는 사실이 밝혀졌습니다. 그러나 탐지기의 정확도(detector accuracy)와 샘플 편향(sample biases)으로 인해 실제 인간 콘텐츠의 비율은 더 높을 수 있습니다. 이러한 'AI 슬롭(AI Slop)'의 증가는 정보의 질 저하, 검색 엔진 최적화(SEO)의 왜곡, 그리고 인간 창작자들의 설 자리를 위협할 수 있다는 우려를 낳고 있습니다. AI 생성 콘텐츠와 인간 생성 콘텐츠를 구분하는 기술적, 윤리적 과제가 더욱 중요해지고 있으며, 워터마킹(watermarking)이나 개선된 탐지 기술, 혹은 콘텐츠 소비 방식의 변화 등 다양한 해결책이 모색될 필요가 있습니다.