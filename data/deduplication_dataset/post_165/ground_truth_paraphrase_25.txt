인공지능(AI)에 대한 과장된 선전은 누가 만들어내는 걸까요? 저희가 저술한 **AI 스네이크 오일(AI Snake Oil)**이라는 책에서 깊이 있게 다루었듯이, 이는 비단 기업이나 언론만의 책임이 아닙니다. 심지어 AI 분야의 연구자들조차 이러한 현상에 일조하고 있습니다. 일례로, 2023년 12월 네이처(Nature) 학술지에 게재되어 큰 반향을 일으켰던 두 편의 연구 논문은 인공지능을 활용하여 무려 220만 개가 넘는 신물질을 찾아냈고, 그중 41개는 로봇 시스템을 통해 성공적으로 합성했다고 주장했습니다. 그러나 유감스럽게도, 이 같은 주장은 얼마 지나지 않아 허위로 판명되었습니다. 보고된 41개의 물질 대다수는 잘못 식별되었으며, 나머지는 이미 세상에 알려진 것들이었습니다. 방대한 양의 데이터셋(dataset)을 대상으로 진행된 추가 검증에서, 250개의 화합물 표본(sample)을 분석한 결과 대부분이 실제로는 무의미한 데이터(junk)에 불과했음이 드러났습니다.

기계 학습(machine learning)의 주요 강점 중 하나는 현상에 대한 깊이 있는 이해 없이도 패턴을 발견할 수 있다는 점입니다. 바로 이러한 특성 때문에 기계 학습 기반 과학 연구에서 오류가 특히 빈번하게 발생합니다. 약 3년 전, 저희는 '시험에 맞춰 학습하는(teaching to the test)' 기계 학습 버전이라고 할 수 있는 '누출(leakage)' 오류가 만연해 있음을 발견했으며, 이는 17개 학술 분야에 걸쳐 수백 편의 논문에 영향을 미쳤다는 명백한 증거를 수집했습니다. 그 이후로 저희는 이 문제를 더욱 심층적으로 파악하고 효과적인 해결책을 마련하기 위해 꾸준히 노력해왔습니다. 본 게시물은 이러한 노력의 최신 업데이트를 제공합니다. 간략히 말씀드리자면, 현재 상황은 개선되기 전에 더욱 악화될 가능성이 높다고 판단하지만, 동시에 한 줄기 희망의 빛도 감지하고 있습니다. AI 기술 발전의 오용과 과장은 학문적 신뢰도에 심각한 위협이 될 수 있습니다.

참사는 계속됩니다.
저희가 가장 최근에 수집한 데이터에 따르면, 연구자들이 학술지에 게재된 연구에서 누출(leakage) 현상을 확인한 학문 분야는 이제 30개로 늘어났습니다. 이들 중 상당수는 의학 분야인데, 이는 의료 연구의 잘못된 결과가 가져올 수 있는 심각한 파장을 고려할 때, 의학계가 모범적인 연구 관행을 수립하고 기출판된 연구들을 비판적으로 검토하는 데 훨씬 더 많은 자원을 투입하는 경향이 있기 때문으로 강력히 추정됩니다. 이처럼 광범위한 분야에 걸쳐 약 650편의 논문이 이러한 문제의 영향을 받았으며, 저희는 이 수치 또한 실제 상황을 매우 과소평가한 것으로 보고 있습니다. 그 이유는 연구자들이 누출(leakage)을 체계적으로 탐색할 경우, 많은 분야에서 무작위로 추출된 연구 논문의 대다수가 이 오류를 포함하고 있음을 발견하기 때문입니다.

누출(leakage)은 과학 연구의 재현성(reproducibility)을 저해하는 여러 요인 중 하나에 불과합니다. 기계 학습(ML) 기반 과학은 데이터(data) 수집 단계부터 전처리(preprocessing), 그리고 최종 결과 보고에 이르기까지 모든 과정에서 광범위한 결함을 내포하고 있습니다. 재현 불가능성(irreproducibility)으로 이어질 수 있는 다른 문제점들로는 부적절한 기준선(baseline) 설정, 편향되거나 비대표적인 표본(sample) 사용, 특정 모델링(modeling) 선택에 지나치게 민감하게 반응하는 결과, 그리고 모델(model)의 불확실성(uncertainty)을 제대로 보고하지 않는 관행 등이 있습니다.

더욱 근본적인 문제점은 연구자들이 자신들의 분석에 사용된 코드(code)와 데이터(data)를 공개하지 않는 경우가 많다는 것입니다. 이는 다른 연구자들이 결과를 검증하고 재현하는 것을 사실상 불가능하게 만듭니다. 예를 들어, Gabelica 등의 연구팀은 2019년 1월 바이오메드 센트럴(BioMed Central)에 등재된 333개의 오픈 액세스(open-access) 저널을 분석했습니다. 그 결과, 데이터 공유를 약속한 1,800편의 논문 중 무려 93%가 실제로는 데이터를 제공하지 않았음이 밝혀졌습니다. 이러한 비공개 관행은 학문적 투명성을 해치고, 오류 발견을 방해하며, 과학 발전의 속도를 늦춥니다.

뿌리 깊은 문제
기계 학습(ML) 기술이 광범위하게 도입되기 전에도 많은 과학 분야는 이미 재현성(reproducibility)과 반복성(replicability)의 위기에 직면해 있었습니다. 그 근본적인 원인들로는 '출판하지 않으면 도태된다(publish-or-perish)'는 과학계의 만연한 문화, 긍정적인 연구 결과(positive results)만을 선호하는 강한 편향, 잘못된 연구를 반박하려는 동기 부족, 그리고 부실한 연구를 발표하더라도 아무런 제재가 없는 현실 등이 꼽힙니다. 예를 들어, 오류가 있는 논문은 거의 철회되지 않으며, 심지어 동료 연구자들조차 반복 연구의 실패를 제대로 인지하지 못하는 경우가 많습니다. 특정 논문의 반복 연구가 실패한 후에도, 해당 연구를 인용하는 논문 중 단 3%만이 그 반복 시도를 언급했습니다. 1 과학 대중화자들은 과학이 자체적으로 오류를 수정한다고 흔히 주장하지만, 저희의 경험에 비추어 볼 때 이러한 자기 수정 메커니즘은 실제로 거의 작동하지 않는다고 판단됩니다.

이러한 모든 문화적 요인들은 기계 학습(ML) 기반 과학에서도 동일하게 나타납니다. 하지만 기계 학습(ML)은 출판된 연구 결과에 대해 우리가 더욱 회의적인 시각을 가져야 하는 여러 가지 추가적인 이유를 제공합니다. 모델의 성능을 평가하는 일(performance evaluation)은 지극히 까다로운 문제이며, 불확실성을 정량화하는 것(uncertainty quantification)과 같은 많은 측면은 여전히 미해결된 연구 영역으로 남아 있습니다. 더욱이, 기계 학습(ML) 모델의 코드(code)는 전통적인 통계 모델링(statistical modeling) 방식보다 훨씬 더 복잡하고 표준화되지 않은 경향이 있습니다. 동료 심사자(peer reviewer)의 역할이 코드(code)를 상세히 검토하는 데까지 미치지 않기 때문에, 코딩(coding)상의 오류는 거의 발견되지 않는 것이 현실입니다.

그러나 저희는 연구 품질이 낮은 가장 큰 이유가 광범위하게 퍼져 있는 과장 광고(hype)에 있다고 생각합니다. 이러한 과장 광고는 연구자들 사이에서 비판적 사고방식의 부재로 이어지는데, 이는 건전한 과학적 실천의 핵심 기반입니다. 저희는 연구자들이 지나치게 낙관적인 기대를 가지고 기계 학습(ML) 모델(model)이 제대로 작동하지 않을 때, 종종 자신들이 무언가 잘못했다고 가정하고 모델을 수정하려 한다는 것을 목격했습니다. 하지만 실제로는 예측 가능성(predictability)의 본질적인 한계에 부딪혔을 가능성을 강력히 고려해야 합니다. 반대로, 모델이 기대 이상으로 잘 작동할 때는 쉽게 믿어 버리는 경향이 있는데, 이때는 누출(leakage)이나 다른 내재된 결함에 대해 더욱 경계해야 합니다. 모델이 예상보다 훨씬 더 뛰어난 성능을 보이면, 연구자들은 흔히 인간이 상상할 수 없었던 데이터(data) 내의 복잡한 패턴(pattern)을 AI가 발견했다고 가정합니다. AI가 마치 외계 지능인 것처럼 신비화하는 이러한 신화적 사고방식은 이러한 잘못된 설명을 더욱 그럴듯하게 만듭니다.

이러한 현상은 악순환(feedback loop)을 형성합니다. 지나친 낙관주의는 결함 있는 연구를 양산하고, 이는 해당 분야의 다른 연구자들에게 AI가 무엇을 할 수 있고 무엇을 할 수 없는지에 대한 잘못된 정보를 제공합니다. 실제로 저희는 좌절감을 느낀 연구자들과의 개인적인 소통에서 이러한 극단적인 사례들을 접했습니다. 결함 있는 연구가 수정되지 않고 그대로 남아있기 때문에, "최첨단(state of the art)" 성능을 뛰어넘지 못하는 좋은 연구를 발표하는 것이 사실상 불가능해집니다. 도구가 강력하고 그 내부 작동 방식이 불투명한 '블랙박스(black-box)'에 가까울수록, 오류 발생 가능성과 과신(overconfidence)의 위험은 더욱 커집니다. 심리학, 의학 등에서 발생했던 반복성(replication) 위기는 단순한 통계의 오용에서 비롯된 것이었습니다. 기계 학습(ML)이 비교적 새로운 분야임을 고려할 때, 저희는 기계 학습(ML) 기반 과학의 재현성(reproducibility) 위기가 개선되기 전에 한동안 더욱 악화될 것이라고 예측합니다. 게다가 지금은 과학자들이 대규모 언어 모델(large language models)과 생성형 AI(generative AI)를 적극적으로 수용하고 있는데, 이는 '이해의 환상(illusion of understanding)'과 같은 수많은 새로운 함정들을 만들어냅니다.

희망의 빛
그럼에도 불구하고 희망의 빛은 존재합니다. 기계 학습(ML) 기반 과학의 한 가지 긍정적인 측면은 일반적으로 인간을 직접 대상으로 하는 실험이 아닌, 순수한 데이터 분석(data analysis)에 중점을 둔다는 점입니다. 이러한 특성 덕분에 다른 연구자들은 이론적으로 해당 논문의 코드(code)와 데이터(data)를 내려받아 보고된 결과를 직접 재현하고 검증할 수 있어야 합니다. 또한 코드(code) 내에 잠재된 오류나 문제가 될 수 있는 선택 사항들을 검토하는 것도 가능합니다. 물론 이 과정은 상당한 시간을 요구하지만, 심리학이나 의학 연구를 반복하는 것보다는 훨씬 덜 복잡하고 비용이 적게 듭니다.

또 다른 희망적인 점은 연구자들이 어떤 부분을 주의해야 하는지 명확히 인지하고 있다면, 대부분의 오류를 충분히 예방할 수 있다는 것입니다. 이와 대조적으로, 사전 등록(pre-registration)과 같은 통계 과학의 반복성(replication) 위기에 대한 완화 전략들은 그 효과 면에서 훨씬 더 들쭉날쭉한 성과를 보여왔습니다. 따라서 저희는 연구자들이 자신들의 연구에 대해 체계적으로 더 많은 주의를 기울이고, 재현성(reproducibility) 연구 활동에 대한 인센티브(incentive)가 부여되는 문화적 변화가 일어난다면, 현재의 문제들이 상당 부분 완화될 수 있다고 믿습니다. 기계 학습(ML) 방법론 커뮤니티(community)는 이미 공통 과제 방법(common task method, 수십 년간 사용된 방법)과 재현성 챌린지(reproducibility challenge, 비교적 최근에 도입된 방법)를 통해 이러한 방향으로 나아가고 있지만, 의학이나 심리학과 같이 각 분야에서 기계 학습(ML) 모델(model)을 활용하여 지식을 발전시키는 '기계 학습 기반 과학(ML-based science)' 분야에서는 아직 이러한 변화가 충분히 일어나지 않고 있습니다.

저희는 이러한 상황을 개선하기 위한 몇 가지 중요한 노력을 주도해왔습니다. 첫째, 저희가 발표했던 누출(leakage) 관련 논문들은 상당한 영향력을 발휘했습니다. 이 논문들은 연구자들이 모델(model)을 구축하는 방식과 누출(leakage)의 부재를 문서화하고 입증하는 데 활용되었습니다. 또한 출판된 연구에서 누출(leakage)을 찾아내려는 다른 연구자들에게도 중요한 참고 자료가 되었으며, 누출(leakage) 연구의 중요성을 강조하고 분야별 구체적인 가이드라인(guideline)을 마련하는 데 기여했습니다. 누출(leakage) 문제 외에도, 저희는 컴퓨터 과학, 데이터 과학, 사회 과학, 수학 및 생의학 연구 분야의 19명 연구자로 구성된 그룹을 이끌어 기계 학습(ML) 기반 과학을 위한 REFORMS 체크리스트(checklist)를 개발했습니다. 이 체크리스트(checklist)는 기계 학습(ML) 기반 과학에서 흔히 발생하는 여덟 가지 함정을 연구자들이 식별하는 데 도움을 줄 수 있는 32개 항목으로 구성되어 있으며, 누출(leakage)은 그중 하나에 불과합니다. 이 체크리스트(checklist)는 최근 권위 있는 학술지인 사이언스 어드밴시스(Science Advances)에 게재되었습니다. 물론 문화적 변화가 뒷받침되지 않는다면 체크리스트(checklist)만으로는 한계가 있겠지만, 지금까지의 긍정적인 반응을 볼 때 저희는 조심스럽게 낙관하고 있습니다.

결론
저희가 강조하려는 요점은 인공지능(AI)이 과학자들에게 전혀 쓸모없는 존재라는 것이 아닙니다. 저희 자신도 AI 자체를 연구하지 않을 때조차 AI를 중요한 도구(tool)로 빈번히 활용합니다. 핵심은 바로 '도구(tool)'라는 단어에 있습니다. AI는 혁명이 아니며, 인간의 본질적인 이해를 대체하는 것도 아닙니다. 그렇게 생각하는 것은 과학의 근본적인 속성을 간과하는 것입니다. AI는 연구 과정에 내재된 고된 노력과 좌절을 건너뛸 수 있는 지름길을 제공하지 않습니다. AI는 신탁이 아니며 미래를 볼 수 없습니다. 유감스럽게도 대부분의 과학 분야는 AI 과장 광고(hype)에 굴복하여 상식적인 판단을 잠시 유보하는 결과를 초래했습니다. 예를 들어, 한 정치학 연구 분야에서는 내전 발발을 90%가 훨씬 넘는 정확도(accuracy) 2로 예측한다고 주장했는데, 이는 상식적으로 불가능하게 들리는 수치입니다. (이 주장은 결국 누출(leakage) 때문임이 밝혀졌고, 바로 이 사건이 저희가 이 연구 분야 전체에 관심을 갖게 된 계기가 되었습니다.)

저희는 현재 과학사에서 매우 흥미로운 전환점에 서 있습니다. 다음 그래프는 다양한 학문 분야에서 AI 기술의 채택이 어떻게 이루어졌는지를 보여줍니다. 3

**분야별 AI 관련 논문 비율, 1985–2023년.**
(출처: Duede et al. 2024)

이러한 '하키 스틱(hockey stick)' 형태의 급격한 상승 그래프는 결코 좋은 소식이 아닙니다. 오히려 우리에게 경각심을 불러일으켜야 합니다. AI를 올바르게 수용하려면 과학적 인식론(epistemology)에 대한 근본적인 변화가 필수적입니다. 4 어떤 과학 분야도 단 몇 년이라는 짧은 시간 안에 이러한 변화를 온전히 달성할 능력이 없습니다. 이러한 현상은 새로운 도구나 방법이 유기적이고 자연스럽게 채택될 때 일어나는 일이 아닙니다. 이는 과학자들이 연구 자금을 확보하기 위해 유행에 편승할 때 발생하는 전형적인 모습입니다. 현재의 과장 광고(hype) 수준을 고려할 때, 과학자들은 AI를 채택하기 위해 추가적인 인센티브(incentive)가 전혀 필요하지 않습니다. 이는 과학 연구를 위한 AI 자금 지원 프로그램이 오히려 상황을 악화시키고 있을 가능성이 높다는 것을 의미합니다.

물론 저희는 이러한 결함 있는 연구의 홍수를 완전히 막을 수 있을지에 대해서는 회의적입니다. 그러나 과학을 위한 AI 자금의 일부라도 더 나은 연구자 훈련, 비판적 탐구 장려, 메타 과학(meta-science) 연구 지원, 재현성(reproducibility) 강화, 그리고 기타 품질 관리 노력으로 전환된다면, 현재의 혼란을 최소화할 수 있을 것입니다. AI는 강력한 도구이지만, 그 힘을 책임감 있게 활용하기 위한 견고한 과학적 기반과 윤리적 프레임워크가 절실히 필요합니다.

저희의 저서 **AI 스네이크 오일(AI Snake Oil)**은 현재 사전 주문이 가능합니다. 이 블로그(blog) 게시물을 재미있게 읽으셨고 저희의 작업을 지지하고 싶으시다면, 아마존(Amazon), 북샵(Bookshop) 또는 평소 즐겨 찾는 서점을 통해 사전 주문해 주시기를 부탁드립니다.

1 분명히 하자면, 반복 실패가 반드시 원본 연구의 결함을 의미하는 것은 아닙니다. 이 게시물에서 저희의 주된 관심사는 누출(leakage)과 같은 비교적 명확한 오류에 관한 것입니다.
2 여기서 정확도(accuracy)는 AUC라는 지표를 의미합니다. 한 가지 결과(평화)가 다른 결과(전쟁)보다 훨씬 더 흔할 때조차 기준선(baseline) AUC는 50%입니다.
3 해당 논문은 다양한 유형의 AI "참여"를 함께 묶습니다. 참여는 새로운 AI 이론 및 접근 방식, 기술 또는 응용 프로그램의 개발; 도메인(domain)별 작업을 위한 AI 모델(model)의 일반적인 사용; 그리고 철학 및 윤리와 같은 분야의 학술 담론으로 대표되는 AI에 대한 비판적 참여를 포함할 수 있습니다(이에 국한되지 않음). 저희의 목적상 이는 유감스러운 일인데, 저희의 관심사는 오직 두 번째 범주, 즉 도메인(domain)별 작업을 위한 AI 사용에만 있기 때문입니다. 저희는 컴퓨터 과학 및 철학과 같은 몇몇 분야를 제외하고는 대부분의 AI 참여가 이 범주에 속한다고 생각합니다.
4 특히, "모든 모델(model)은 틀렸지만 일부 모델(model)은 유용하다"는 말처럼, 모델(model)을 기반으로 세상에 대한 결론을 언제 도출할 수 있는지에 대한 명확한 답은 없으므로, 모든 분야와 모든 유형의 모델(model)에 대해 타당성(validity)을 재검토해야 합니다.