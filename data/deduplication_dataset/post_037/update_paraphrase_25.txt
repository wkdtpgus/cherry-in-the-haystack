주말 사이, 미래의 윤곽이 조용히 모습을 드러냈습니다. 오랫동안 저는 인공지능(AI) 분야에서 나란히 진행되던 두 가지 중대한 진보, 즉 자율 에이전트(autonomous agents)의 급부상과 OpenAI의 o1 출시 이후 등장한 강력한 추론기(Reasoners)에 대해 이야기해왔습니다. 이 두 가지 혁신적인 흐름은 마침내 놀라운 방식으로 합쳐졌습니다. 이는 인간 전문가의 깊이 있는 통찰력과 섬세함을 담아내면서도, 기계적 속도로 임무를 수행할 수 있는 AI 시스템의 탄생을 의미합니다. OpenAI의 딥 리서치(Deep Research)는 이러한 통합된 모습을 명확히 보여주며, 다가올 미래가 어떤 모습일지 엿볼 수 있게 합니다. 이 현상의 진정한 중요성을 이해하려면, 핵심 구성 요소인 추론기와 에이전트부터 살펴보는 것이 필수적입니다. 이러한 발전은 단순히 기술적 진보를 넘어, AI가 복잡한 문제 해결과 의사결정 과정에 어떻게 참여하게 될지에 대한 근본적인 변화를 예고합니다.

**추론기(Reasoners)**
지난 몇 년간 우리가 사용해온 챗봇들은 비교적 단순한 방식으로 작동했습니다. 사용자가 질문을 입력하면, AI는 즉시 단어(더 정확히는 토큰(token)) 단위로 답변을 생성하기 시작했습니다. 인공지능이 "생각"할 수 있는 유일한 시간은 이 토큰을 생성하는 동안뿐이었기 때문에, 연구자들은 "답변하기 전에 단계별로 생각하라"와 같은 지시를 통해 AI의 추론 역량을 높이는 방안을 모색했습니다. 이러한 접근법은 '연쇄적 사고 프롬프트(chain-of-thought prompting)'로 명명되었으며, AI의 성능을 괄목할 만큼 향상시켰습니다. 추론기는 본질적으로 이 과정을 자동화하여, 최종 답변을 제시하기 전에 '사고 토큰(thinking tokens)'을 내부적으로 생성하고 숙고하는 단계를 거칩니다. 이는 AI가 즉각적인 반응을 넘어, 보다 심층적인 내부적 숙고를 통해 문제를 해결하는 능력을 갖추게 되었음을 의미합니다.

이러한 변화는 최소한 두 가지 중요한 측면에서 혁신적입니다. 첫째, 이제 AI 개발사들은 뛰어난 문제 해결 전문가들의 실제 사례를 기반으로 AI가 추론하는 방식을 학습시킬 수 있게 되었습니다. 이를 통해 AI는 훨씬 더 효과적으로 '사고'할 수 있게 됩니다. 이러한 훈련 과정은 단순히 프롬프트를 통해 얻는 것보다 훨씬 높은 품질의 연쇄적 사고(chain-of-thought) 과정을 생성할 수 있습니다. 이는 추론기가 기존 챗봇들이 어려움을 겪었던 수학이나 논리와 같은 분야를 포함하여, 훨씬 더 복잡한 문제들을 해결할 수 있음을 의미합니다. AI가 단순히 지식을 나열하는 것을 넘어, 지식을 활용하여 추론하고 해결책을 찾아내는 능력이 고도화된 것입니다.

두 번째로 획기적인 측면은 추론기가 더 오랫동안 '생각'할수록 답변의 품질이 향상된다는 점입니다(물론, 생각하는 시간이 길어질수록 개선 속도는 점차 둔화되지만). 이 발견은 매우 중요한데, 과거에는 AI 성능을 높이는 유일한 방법이 더 크고 방대한 모델을 훈련시키는 것이었으며, 이는 막대한 비용과 엄청난 양의 데이터를 요구했습니다. 하지만 추론 모델은 모델 훈련 시점이 아닌, 질문에 답변하는 시점(이를 '추론 시간 컴퓨팅(inference-time compute)'이라고 합니다)에 컴퓨팅 자원을 투입하여 더 많은 사고 토큰을 생성하게 함으로써 AI의 성능을 향상시킬 수 있다는 새로운 가능성을 제시합니다. 이는 고성능 AI 개발의 문턱을 낮추고, 자원 효율적인 방식으로 지능을 확장할 수 있는 길을 열었다는 점에서 큰 의미를 가집니다.

대학원 수준의 구글 무용 Q&A 테스트(Graduate-Level Google-Proof Q&A test, GPQA)는 박사 학위 소지자조차 인터넷 검색의 도움 없이 해결하기 어려운 일련의 객관식 질문들로 구성되어 있습니다. 이 테스트에서 박사 학위 소지자들은 자신의 전문 분야 밖에서는 34%, 전문 분야 내에서는 81%의 정답률을 보였습니다. 이는 추론 모델이 AI의 역량 발전 속도를 얼마나 폭발적으로 증가시켰는지를 명확히 보여주는 지표입니다. 데이터 출처. 이러한 고난이도 테스트에서 AI가 인간 전문가에 근접하는 성능을 보인다는 것은, AI가 단순한 정보 검색 도구를 넘어 복잡한 지적 작업에서 인간을 보조하거나 대체할 잠재력을 가지고 있음을 시사합니다.

추론기의 기술은 매우 최근에 등장했기 때문에, 그 능력은 놀라운 속도로 발전하고 있습니다. 불과 몇 달 사이에 우리는 OpenAI의 초기 o1 모델부터 최신 o3 모델에 이르기까지 극적인 성능 향상을 목격했습니다. 동시에, 중국의 DeepSeek r1은 비용 효율성을 높이면서도 성능을 개선하는 혁신적인 접근 방식을 선보였고, 구글 역시 첫 번째 추론기 모델을 공개하며 경쟁에 합류했습니다. 이는 단지 시작에 불과하며, 앞으로 훨씬 더 강력하고 다양한 추론 시스템들이 등장할 것으로 예상됩니다. 이러한 경쟁은 추론 기술의 발전을 더욱 가속화하고, 다양한 산업 분야에 새로운 혁신을 가져올 것입니다.

**에이전트(Agents)**
AI 에이전트에 대한 정확한 정의를 두고 전문가들 사이에서는 여전히 논쟁이 있지만, 우리는 이를 "특정 목표가 주어지면 그 목표를 자율적으로 추구하고 달성할 수 있는 인공지능"으로 간단히 이해할 수 있습니다. 현재 AI 연구소들은 어떤 종류의 작업이든 처리할 수 있는 시스템, 즉 범용 에이전트(general-purpose agents)를 구축하기 위한 치열한 경쟁을 벌이고 있습니다. 저는 과거에 데빈(Devin)이나 컴퓨터 사용(Computer Use) 기능을 갖춘 클로드(Claude)와 같은 초기 사례들에 대해 다룬 바 있습니다. 그리고 최근 OpenAI는 아마도 지금까지 가장 정교한 범용 에이전트인 오퍼레이터(Operator)를 선보였습니다. 아래 16배속 영상은 범용 에이전트가 가진 잠재력과 동시에 내재된 한계점을 동시에 보여줍니다.

저는 오퍼레이터에게 한 가지 과제를 부여했습니다. OneUsefulThing에 있는 저의 최신 서브스택(substack) 게시물을 읽고, 구글 이미지FX(Google ImageFX)로 이동하여 게시물에 적합한 이미지를 생성한 다음, 그 이미지를 다운로드하여 제가 게시할 수 있도록 전달하는 것이었습니다. 이 과정은 매우 흥미롭게 전개됩니다. 처음에는 오퍼레이터가 놀라운 정확성으로 작업을 수행합니다. 제 웹사이트를 찾아 게시물을 읽고, 이미지FX로 이동하여(제가 로그인 정보를 입력하는 동안 잠시 멈춤), 이미지를 성공적으로 생성합니다. 하지만 곧 두 가지 문제가 발생합니다. 오퍼레이터는 OpenAI의 파일 다운로드 보안 정책에 의해 차단될 뿐만 아니라, 작업 자체에서도 혼란을 겪기 시작합니다. 에이전트는 클립보드 복사, 직접 링크 생성, 심지어 사이트의 소스 코드(source code)를 분석하는 등 가능한 모든 해결책을 체계적으로 시도합니다. 그러나 각 시도는 실패로 돌아갑니다. 일부는 OpenAI의 브라우저 제한 때문이었고, 다른 일부는 에이전트가 작업을 실제로 어떻게 수행해야 하는지에 대한 내부적인 혼란 때문이었습니다. 이처럼 단호하지만 결국 실패로 끝나는 문제 해결 과정을 지켜보는 것은 현재 이러한 시스템의 명확한 한계를 드러내며, 에이전트가 현실 세계의 장벽에 부딪혔을 때 궁극적으로 어떻게 행동할지에 대한 중요한 질문을 던집니다.

오퍼레이터가 겪었던 문제들은 범용 에이전트의 현재 한계점을 명확히 보여주지만, 그렇다고 해서 에이전트 기술 자체가 무용지물이라는 의미는 아닙니다. 특정 작업에 집중하여 경제적으로 높은 가치를 창출하는 협소 에이전트(narrow agents)는 이미 실현 가능한 영역으로 보입니다. 현재 대규모 언어 모델(LLM) 기술을 기반으로 작동하는 이 전문화된 에이전트들은 각자의 전문 분야에서 놀라운 성과를 달성할 수 있습니다. 대표적인 예로, OpenAI의 새로운 딥 리서치(Deep Research)는 고도로 집중된 AI 에이전트가 얼마나 강력한 역량을 발휘할 수 있는지를 생생하게 입증합니다. 이러한 전문화된 에이전트는 특정 도메인에서 인간 전문가에 필적하거나 능가하는 수준의 효율성을 제공하며, 이미 많은 산업에서 실용적인 가치를 증명하고 있습니다.

**딥 리서치(Deep Research)**
OpenAI의 딥 리서치(Deep Research)(곧 언급할 구글의 동명 제품과 혼동하지 마십시오)는 본질적으로 OpenAI의 아직 공개되지 않은 o3 추론기(Reasoner)를 기반으로 하며, 특별한 도구와 기능에 접근할 수 있는 전문적인 연구 에이전트(narrow research agent)입니다. 이는 제가 최근에 경험한 AI 애플리케이션 중 가장 인상적인 것 중 하나입니다. 그 이유를 이해하기 위해, 특정 주제를 주어 실험해 봅시다. 저는 제 연구 분야 내에서 매우 기술적이고 논쟁적인 문제인 "스타트업은 언제 탐색을 멈추고 스케일업을 시작해야 하는가?"를 특별히 선정했습니다. 저는 이 주제에 대한 학술 연구를 심층적으로 검토하고, 고품질 논문과 무작위 대조 시험(RCTs)에 집중하며, 모호한 정의와 일반적인 통념 및 연구 결과 간의 상충점을 다루는 것을 포함해 달라고 요청했습니다. 또한 이 문제에 대한 대학원 수준의 심도 있는 토론을 위한 결과를 제시해 달라고 주문했습니다. AI는 몇 가지 영리한 질문을 통해 제가 원하는 바를 명확히 했고, 이제 o3는 작업을 시작합니다. 이 과정에서 진행 상황과 AI의 '사고' 과정을 실시간으로 볼 수 있습니다. 아래에서 그 과정의 몇 가지 단면을 잠시 살펴보는 것은 정말 가치 있는 일입니다. AI가 실제로 연구자처럼 작동하여, 발견 사항을 탐색하고, '흥미로운' 지점들을 더 깊이 파고들며, 문제 해결(예: 유료 기사(paywalled articles)에 접근하기 위한 대체 방법을 찾는 것과 같은)을 시도하는 것을 확인할 수 있습니다. 이 전체 과정은 단 5분 만에 진행됩니다. 이 '사고' 과정의 세 가지 단면을 진지하게 잠시 살펴보시기 바랍니다.

결국 저는 6개의 인용문과 여러 추가 참고 문헌이 포함된 13페이지, 3,778단어 분량의 초안을 받았습니다. 솔직히 말해, 몇 가지 출처가 더 포함되었으면 하는 아쉬움은 있었지만, 그 결과물은 정말 뛰어났습니다. AI는 어렵고 상충되는 개념들을 능숙하게 연결하고, 예상치 못한 새로운 통찰력을 발견했으며, 오직 고품질 출처만을 인용했고, 인용문 역시 매우 정확했습니다. 모든 내용이 100% 정확하다고 단언할 수는 없지만(개인적으로 오류는 발견하지 못했습니다), 만약 박사 과정 초보 학생이 이와 같은 결과물을 제출했다면 저는 매우 만족했을 것입니다. 전체 결과물은 여기에서 확인할 수 있지만, 아래의 몇 가지 발췌문만으로도 제가 왜 그렇게 깊은 감명을 받았는지 충분히 이해하실 수 있을 것입니다. 이러한 수준의 분석과 종합 능력은 기존의 AI 도구들과는 확연히 다른 차원의 지적 깊이를 보여줍니다.

인용문의 품질 또한 여기서 진정한 진전을 보여주는 핵심적인 부분입니다. 이는 흔히 접하는 AI의 환각(hallucinations) 현상이거나 잘못 인용된 논문이 아닙니다. 제 동료인 이새롬(Saerom (Ronnie) Lee)과 김다니엘(Daniel Kim)의 선구적인 연구를 포함하여, 모두 합법적이고 검증된 고품질 학술 자료들이었습니다. 링크를 클릭하면 단순히 논문 페이지로 이동하는 것을 넘어, 종종 해당 인용문이 강조 표시된 부분으로 바로 연결됩니다. 비록 AI가 몇 분 안에 찾아서 읽을 수 있는 자료에만 접근할 수 있고, 유료 기사(paywalled articles)는 여전히 접근 불가능하다는 제약이 존재하지만, 이는 AI가 학술 문헌과 상호작용하는 방식에 근본적인 변화를 의미합니다. 처음으로 AI가 단순히 연구 내용을 요약하는 것을 넘어, 인간의 학술 작업에 필적하는 수준으로 적극적으로 참여하고 탐구하는 단계를 밟고 있는 것입니다. 이러한 발전은 연구자들이 방대한 문헌을 빠르게 검토하고 새로운 연구 방향을 탐색하는 데 있어 강력한 조력자가 될 잠재력을 가지고 있습니다.

지난달 출시된 구글의 제품 역시 딥 리서치(Deep Research)라고 불리는 것과 비교해 볼 가치가 있습니다(휴). 구글은 훨씬 더 많은 인용문을 제시하지만, 그 출처는 종종 품질이 매우 다양한 웹사이트들의 혼합입니다(유료 정보 및 서적에 대한 접근성 부족은 이러한 모든 에이전트에게 공통적으로 불리하게 작용합니다). OpenAI의 연구 에이전트가 보여준 호기심 기반 발견(curiosity-driven discovery)과는 달리, 구글의 시스템은 모든 문서를 한꺼번에 수집하는 방식으로 작동하는 것처럼 보입니다. 또한 (현재로서는) 추론 기능이 없는 구형 제미니 1.5(Gemini 1.5) 모델로 구동되기 때문에, 전반적인 요약은 여전히 견고하고 명백히 오류는 없지만, 훨씬 더 표면적인 수준에 머무릅니다. 마치 매우 훌륭한 학부생 수준의 결과물과 같다고 할 수 있습니다. 아래 내용을 조금 더 읽어보시면 그 차이가 더욱 명확해질 것이라고 생각합니다. 관점을 제시하자면: 두 결과물 모두 일반적으로 몇 시간의 인간 노력을 필요로 하는 작업입니다. OpenAI 시스템은 박사 학위 수준에 근접하는 심도 있는 분석을 제공하는 반면, 구글은 탄탄한 학부생 수준의 작업을 제공합니다. 이러한 차이는 각 사의 AI 개발 전략과 목표 시장에 대한 통찰을 제공합니다.

OpenAI는 발표에서 매우 대담한 주장을 펼쳤는데, 그들의 에이전트가 높은 경제적 가치를 지닌 연구 프로젝트의 15%와 매우 높은 가치를 지닌 프로젝트의 9%를 처리할 수 있음을 시사하는 그래프를 포함했습니다. 이러한 수치들은 방법론이 명확히 설명되지 않았기 때문에 다소 회의적인 시각으로 볼 필요가 있지만, 저의 직접적인 테스트 결과는 그들이 완전히 틀린 것은 아니라는 점을 시사합니다. 딥 리서치(Deep Research)는 실제로 몇 시간이 아닌 단 몇 분 만에 가치 있고 정교한 분석 결과를 생성할 수 있습니다. 그리고 AI 기술의 빠른 발전 속도를 고려할 때, 구글이 이러한 능력 격차를 오랫동안 유지하도록 두지는 않을 것이라고 예상합니다. 앞으로 몇 달 안에 연구 에이전트(research agents) 분야에서 또 한 번의 급격한 개선을 목격하게 될 것입니다. 이러한 발전은 연구의 민주화를 가속화하고, 인간 연구자들이 더 복잡하고 창의적인 문제에 집중할 수 있도록 도울 것입니다.

**조각들이 맞춰지다**
AI 연구소들이 구축하고 있는 다양한 조각들이 단순히 맞춰지는 것을 넘어, 서로 강력한 시너지를 발휘하고 있음을 분명히 알 수 있습니다. 추론기(Reasoners)는 인지적이고 지적인 원동력을 제공하며, 에이전트 시스템(agentic systems)은 실제 세상에서 행동할 수 있는 능력을 부여합니다. 현재 우리는 딥 리서치(Deep Research)와 같은 협소 에이전트(narrow agents)의 시대에 있습니다. 이는 아무리 뛰어난 우리의 추론기조차도 아직 범용 자율성(general-purpose autonomy)을 완벽히 갖출 준비가 되어 있지 않기 때문입니다. 하지만 '협소하다'는 것이 '한계가 있다'는 것을 의미하지는 않습니다. 이 시스템들은 한때 고액 연봉의 전문가 팀이나 전문 컨설팅 회사가 필요했던 복잡한 작업을 이미 수행할 수 있습니다. 이러한 전문가와 컨설팅 회사들이 사라지는 것은 아닙니다. 오히려 그들은 직접 작업을 수행하는 역할에서 벗어나 AI 시스템의 작업을 조율하고, 검증하며, 전략적으로 활용하는 역할로 진화함에 따라 그들의 판단력과 전문성이 더욱 중요해질 것입니다. 그러나 연구소들은 이것이 단지 시작에 불과하다고 믿습니다. 그들은 더 발전된 모델이 범용 에이전트의 비밀을 풀어내어, 특정 협소한 작업을 넘어 웹을 자유롭게 탐색하고, 모든 양식(modalities)에 걸쳐 정보를 처리하며, 세상에서 의미 있는 행동을 취할 수 있는 자율적인 디지털 작업자(autonomous digital workers)가 될 것이라고 확신하고 있습니다. 오퍼레이터(Operator)의 사례는 우리가 아직 그 단계에 도달하지 못했음을 보여주지만, 딥 리서치(Deep Research)의 성과는 우리가 그 길을 확실히 걷고 있음을 강력히 시사합니다. 미래에는 AI가 인간의 지적 파트너로서 새로운 가치를 창출하는 시대가 열릴 것입니다.

구독 공유