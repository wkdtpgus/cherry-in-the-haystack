주말 동안 미래의 모습이 더욱 명확해졌습니다. 오랫동안 인공지능 분야에서 주목받던 두 가지 주요 흐름, 즉 자율 에이전트(autonomous agents)의 발전과 고성능 추론기(Reasoners)의 등장이 마침내 놀라운 방식으로 결합되고 있습니다. 인간 전문가와 같은 깊이 있는 통찰력과 뉘앙스를 가지고 연구를 수행하면서도, 기계적 효율성으로 작업을 처리하는 AI 시스템이 현실화되고 있습니다. 최근 발표된 OpenAI의 '딥 리서치(Deep Research)'는 이러한 기술의 융합이 가져올 미래의 청사진을 제시하며, 우리가 어디로 향하고 있는지 짐작하게 합니다. 이러한 변화의 중요성을 제대로 이해하기 위해서는, 핵심 구성 요소인 추론기(Reasoners)와 에이전트(agents)의 본질부터 다시 살펴보는 것이 중요합니다.

**추론기(Reasoners)**
지난 몇 년간 우리가 접해온 챗봇들은 대체로 단순한 방식으로 작동했습니다. 사용자가 질문을 입력하면, 즉시 단어 단위(더 정확히는 토큰(token) 단위)로 답변을 생성하기 시작했습니다. AI는 이러한 토큰을 생성하는 과정에서만 "생각"할 수 있었기에, 연구자들은 "답변하기 전에 단계별로 생각하라"는 지시를 통해 추론 능력을 개선하는 방법을 고안했습니다. 이러한 방식은 연쇄적 사고 프롬프트(chain-of-thought prompting)로 알려져 있으며, AI의 성능을 크게 향상시켰습니다. 추론기(Reasoners)는 본질적으로 이 과정을 자동화하여, 최종 답변을 제시하기 전에 일련의 "사고 토큰(thinking tokens)"을 생성합니다.

이러한 발전은 적어도 두 가지 핵심적인 측면에서 혁신적입니다. 첫째, AI 개발 기업들은 이제 숙련된 문제 해결 전문가들의 실제 사례를 기반으로 AI가 추론하는 방식을 훈련시킬 수 있게 되었고, 이를 통해 AI는 훨씬 더 효율적으로 "사고"할 수 있습니다. 이러한 훈련 과정은 단순히 프롬프트로 유도하는 것보다 훨씬 더 높은 품질의 연쇄적 사고(chain-of-thought)를 만들어낼 수 있습니다. 그 결과, 추론기는 기존 챗봇이 어려움을 겪었던 수학이나 복잡한 논리 문제와 같은 분야에서도 훨씬 더 난이도 높은 과제를 해결할 수 있게 되었습니다.

두 번째로 획기적인 점은 추론기가 더 긴 시간 "사고"할수록 답변의 품질이 지속적으로 향상된다는 것입니다(물론, 시간이 길어질수록 개선 속도는 점차 둔화됩니다). 이는 이전에는 AI 성능 개선을 위해 오직 더 큰 모델을 훈련시키는 방법만이 유효했고, 이는 막대한 비용과 방대한 데이터를 요구했다는 점에서 매우 중요한 변화입니다. 추론 모델은 모델 훈련 시점이 아닌, 실제 질문에 답변하는 시점(추론 시간 컴퓨팅(inference-time compute)이라고 함)에 컴퓨팅 자원을 활용하여 더 많은 사고 토큰을 생성함으로써 AI의 성능을 향상시킬 수 있다는 새로운 가능성을 제시합니다.

대학원 수준의 구글 무용 Q&A 테스트(Graduate-Level Google-Proof Q&A test, GPQA)는 인터넷 검색으로도 답을 찾기 어려운 객관식 문제들로 구성되어 있습니다. 심지어 박사 학위 소지자들도 자신의 전문 분야 밖에서는 이 테스트에서 34%의 정답률을 보이며, 전문 분야 내에서는 81%를 기록합니다. 이는 추론 모델이 AI의 문제 해결 능력을 얼마나 빠르게 향상시켰는지를 단적으로 보여주는 사례입니다.

추론기 기술은 아직 초기 단계에 있지만, 그 능력은 놀라운 속도로 발전하고 있습니다. 불과 몇 달 사이에 우리는 OpenAI의 초기 추론 모델부터 최신 버전까지 극적인 성능 향상을 목격했습니다. (예: GPT-4o와 같은 최신 모델의 등장). 또한, 중국의 DeepSeek r1은 비용 효율적인 성능 개선 방안을 제시했으며, 구글 또한 자사의 추론 모델을 활발히 개발하고 있습니다. 이는 단지 시작에 불과하며, 앞으로 훨씬 더 강력한 추론 시스템들이 등장할 것으로 예상됩니다. 최근에는 멀티모달 추론 능력(multimodal reasoning capabilities)이 강조되면서 텍스트뿐만 아니라 이미지, 오디오, 비디오 등 다양한 형태의 정보를 통합적으로 이해하고 추론하는 모델들이 주목받고 있습니다.

**에이전트(Agents)**
AI 에이전트의 정확한 정의에 대해서는 전문가들 사이에서도 다양한 의견이 존재하지만, 우리는 이를 "특정 목표를 부여받고 그 목표를 자율적으로 달성할 수 있는 AI 시스템"으로 이해할 수 있습니다. 현재 많은 AI 연구소들은 어떠한 작업이라도 처리할 수 있는 범용 에이전트(general-purpose agents) 개발에 집중하며 치열한 경쟁을 펼치고 있습니다. 저는 데빈(Devin)이나 컴퓨터 사용(Computer Use) 기능을 갖춘 클로드(Claude)와 같은 초기 에이전트 사례들을 다룬 바 있지만, OpenAI 또한 매우 정교한 범용 에이전트인 오퍼레이터(Operator)의 개념을 제시했습니다. 아래 시연 영상은 범용 에이전트의 잠재력과 동시에 현재의 한계를 명확히 보여줍니다.

저는 한 에이전트에게 다음과 같은 작업을 부여했습니다: 'OneUsefulThing'에 게시된 제 최신 서브스택(substack) 게시물을 읽고, 구글 이미지FX(Google ImageFX)로 이동하여 적절한 이미지를 생성한 후, 이를 다운로드하여 게시할 수 있도록 전달하는 것. 초기에는 에이전트가 놀라운 정확성으로 작업을 수행했습니다. 제 웹사이트를 찾아 게시물을 읽고, 이미지FX로 이동하여(로그인 정보 입력 시 잠시 멈춤) 이미지를 성공적으로 생성했습니다. 하지만 곧 두 가지 문제에 직면했습니다. 에이전트는 OpenAI의 파일 다운로드 보안 제한에 의해 차단되었을 뿐만 아니라, 작업 진행 자체에서도 어려움을 겪기 시작했습니다. 에이전트는 클립보드에 복사하기, 직접 링크 생성하기, 심지어 사이트의 소스 코드(source code)를 분석하는 등 가능한 모든 해결책을 체계적으로 시도했습니다. 그러나 각 시도는 결국 실패로 돌아갔습니다. 일부는 OpenAI의 브라우저 환경 제한 때문이었고, 다른 일부는 에이전트가 실제 작업을 어떻게 수행해야 할지에 대한 자체적인 혼란 때문이었습니다. 이처럼 단호하지만 궁극적으로 실패한 문제 해결 과정을 지켜보는 것은 현재 이러한 시스템이 가진 한계를 명확히 드러내며, 에이전트가 현실 세계의 장벽에 부딪혔을 때 어떻게 반응할지에 대한 중요한 질문을 던집니다.

이러한 에이전트의 한계는 범용 에이전트의 현재 역량을 보여주지만, 에이전트 기술 자체가 무용하다는 것을 의미하지는 않습니다. 특정 작업에 특화된, 경제적으로 가치 있는 협소 에이전트(narrow agents)는 이미 실현 가능한 영역에 있습니다. 현재 LLM(대규모 언어 모델) 기술을 기반으로 작동하는 이 전문화된 에이전트들은 각자의 분야에서 놀라운 성과를 달성하고 있습니다. 그 대표적인 사례로, OpenAI의 '딥 리서치(Deep Research)'는 특정 목적에 집중된 AI 에이전트가 얼마나 강력한 능력을 발휘할 수 있는지를 명확히 보여줍니다.

**딥 리서치(Deep Research)**
OpenAI의 '딥 리서치(Deep Research)' (이후 언급할 구글의 동명 서비스와는 구분됩니다)는 본질적으로 OpenAI의 최신 추론기(Reasoner)를 기반으로 하며, 특정 도구와 기능에 접근할 수 있는 협소 연구 에이전트(narrow research agent)입니다. 이는 제가 최근 경험한 AI 애플리케이션 중 가장 인상적인 것 중 하나였습니다. 그 이유를 설명하기 위해, 저는 제 연구 분야 내에서 매우 기술적이고 논쟁적인 문제인 "스타트업은 언제 탐색을 멈추고 스케일업을 시작해야 하는가?"라는 주제를 부여했습니다. 저는 이 주제에 대한 학술 연구를 검토하고, 고품질 논문과 무작위 대조 시험(RCTs)에 집중하며, 문제 있는 정의와 일반적인 통념 및 연구 간의 충돌을 다루는 내용을 포함하여 대학원 수준의 토론을 위한 결과를 제시해 달라고 요청했습니다. AI는 몇 가지 심도 있는 질문을 던졌고, 저는 제가 원하는 바를 명확히 설명했습니다. 그러자 에이전트가 작업을 시작했습니다. 그 진행 상황과 "사고" 과정을 실시간으로 관찰할 수 있었습니다. 아래에서 그 과정의 일부 샘플을 잠시 살펴보는 것은 매우 유익합니다. AI가 마치 실제 연구자처럼 작동하여, 발견 사항을 탐색하고, "흥미로운" 지점을 깊이 파고들며, 심지어 유료 기사(paywalled articles)에 접근하는 대체 방법을 찾는 것과 같은 문제 해결을 시도하는 모습을 볼 수 있었습니다. 이 전체 과정은 약 5분 동안 진행되었습니다. 이 "사고" 과정의 핵심적인 단면들을 진지하게 살펴보는 것을 권합니다.

최종적으로 저는 6개의 직접 인용과 몇 개의 추가 참고 문헌이 포함된 13페이지 분량의 3,778단어 초안을 받았습니다. 솔직히 말해, 몇몇 출처가 더 있었으면 하는 아쉬움은 있었지만, 전체적인 결과물은 매우 인상적이었습니다. 어렵고 모순되는 개념들을 능숙하게 연결하고, 예상치 못한 새로운 통찰력을 제시했으며, 오직 고품질 출처만을 인용하고 정확한 인용문으로 채워져 있었습니다. 모든 내용이 100% 정확하다고 단언할 수는 없지만(개인적으로 오류를 발견하지 못했습니다), 만약 박사 과정 초보 학생이 이 정도 수준의 결과물을 제출했다면 매우 만족했을 것입니다. 전체 결과물은 여기에서 확인할 수 있지만, 아래의 몇 가지 발췌문만으로도 제가 왜 이토록 감명받았는지 충분히 설명될 것입니다.

인용의 품질 또한 딥 리서치(Deep Research)가 이룬 진정한 발전을 보여줍니다. 이것들은 흔히 발생하는 AI 환각(hallucinations)이나 잘못 인용된 논문이 아니었습니다. 제 동료인 이새롬(Saerom (Ronnie) Lee)과 김다니엘(Daniel Kim)의 선구적인 연구를 포함하여, 합법적이고 고품질의 학술 자료들이었습니다. 제공된 링크를 클릭하면 단순히 논문으로 이동하는 것을 넘어, 종종 관련 강조 표시된 인용문으로 바로 연결되었습니다. 물론, AI가 몇 분 안에 찾아서 읽을 수 있는 자료에만 접근할 수 있고, 유료 기사(paywalled articles)는 여전히 접근이 어렵다는 제약은 존재합니다. 그러나 이러한 기능은 AI가 학술 문헌과 상호작용하는 방식에 근본적인 변화를 의미합니다. 처음으로 AI가 단순한 연구 요약을 넘어, 실제 인간의 학술 작업에 버금가는 수준으로 적극적인 참여를 보여주고 있습니다.

지난해 출시된 구글의 유사한 서비스 또한 '딥 리서치(Deep Research)'라는 이름으로 불리며, 이와 비교해 볼 가치가 있습니다. (여기서 한숨) 구글은 훨씬 더 많은 인용을 제공하지만, 그 출처는 품질이 다양한 웹사이트들의 혼합인 경우가 많습니다 (유료 정보 및 서적에 대한 접근성 부족은 모든 에이전트에게 공통된 한계입니다). OpenAI의 연구자 에이전트(researcher agent)가 보여준 호기심 기반 발견(curiosity-driven discovery)과는 달리, 구글은 모든 관련 문서를 한꺼번에 수집하는 방식으로 작동하는 듯합니다. 또한, (당시로서는) 추론 기능이 제한적인 제미니 1.5(Gemini 1.5) 모델로 구동되었기 때문에, 전반적인 요약은 견고하고 명백히 오류가 없었음에도 불구하고, 훨씬 더 표면적인 수준에 머물렀습니다. 마치 매우 훌륭한 학부생 수준의 결과물과 같다고 할 수 있습니다. 아래 내용을 좀 더 살펴보시면 그 차이가 더욱 명확해질 것입니다. 관점을 제시하자면: 두 시스템 모두 일반적으로 몇 시간의 인간 노력을 필요로 하는 작업을 수행합니다. 하지만 OpenAI 시스템이 박사 학위 수준에 가까운 분석을 제공하는 반면, 구글은 견고한 학부생 수준의 결과물을 내놓았습니다. 다만, 최근 구글의 제미니(Gemini) 모델도 추론 능력과 멀티모달 이해도를 크게 향상시키고 있어, 이러한 격차는 빠르게 줄어들 것으로 예상됩니다.

OpenAI는 자신들의 에이전트가 높은 경제적 가치의 연구 프로젝트의 15%와 매우 높은 가치의 프로젝트의 9%를 처리할 수 있다는 대담한 주장을 발표했습니다. (관련 그래프 포함) 이 수치들은 방법론이 명확히 설명되지 않았으므로 다소 회의적으로 접근할 필요가 있습니다. 하지만, 제 직접적인 테스트 결과는 그들의 주장이 완전히 허황된 것은 아님을 시사합니다. '딥 리서치(Deep Research)'는 실제로 몇 시간의 노력이 아닌 단 몇 분 만에 가치 있고 정교한 분석 결과를 생성할 수 있습니다. 그리고 AI 기술의 급속한 발전 속도를 고려할 때, 구글과 같은 다른 경쟁자들이 이러한 능력 격차를 오래 지속시키지 않을 것이라고 예상합니다. 우리는 앞으로 몇 달 안에 연구 에이전트(research agents) 분야에서 더욱 빠른 개선과 혁신을 목격하게 될 것입니다.

**조각들이 맞춰지다**
현재 AI 연구소들이 개발하고 있는 여러 기술 조각들이 단순히 결합되는 것을 넘어, 서로 강력한 시너지를 창출하고 있음을 분명히 알 수 있습니다. 추론기(Reasoners)는 지적인 사고의 원동력을 제공하고, 에이전트 시스템(agentic systems)은 실제 세계에서 행동할 수 있는 실행력을 부여합니다. 우리는 지금 '딥 리서치(Deep Research)'와 같은 협소 에이전트(narrow agents)의 시대에 살고 있습니다. 이는 현재의 최고 추론기조차도 완전한 범용 자율성(general-purpose autonomy)을 달성하기에는 아직 준비가 덜 되었기 때문입니다. 그러나 '협소하다'는 것이 곧 한계를 의미하는 것은 아닙니다. 이러한 시스템들은 과거에는 고액 연봉의 전문가 팀이나 전문 컨설팅 회사가 전담하던 작업들을 이미 성공적으로 수행할 수 있습니다. 물론, 이러한 전문가와 컨설팅 회사들이 사라지는 것은 아닙니다. 오히려 그들은 직접적인 작업 수행에서 벗어나, AI 시스템의 작업을 조율하고, 검증하며, 더 복잡한 전략을 수립하는 역할로 진화함에 따라 그들의 전문적인 판단과 통찰력이 더욱 중요해질 것입니다. 하지만 많은 연구소들은 이것이 단지 시작에 불과하다고 확신합니다. 그들은 더욱 발전된 모델들이 범용 에이전트의 난제를 해결하여, 특정 협소한 작업을 넘어 웹을 탐색하고, 모든 양식(modalities)의 정보를 처리하며, 현실 세계에서 의미 있는 행동을 수행할 수 있는 진정한 자율적인 디지털 작업자(autonomous digital workers)의 시대를 열 것이라고 믿고 있습니다. 오퍼레이터(Operator)의 사례는 우리가 아직 그 최종 단계에 도달하지 못했음을 보여주지만, '딥 리서치(Deep Research)'의 놀라운 능력은 우리가 이미 그 길을 힘차게 나아가고 있음을 시사합니다. 이러한 에이전트 기술의 발전은 인간과 AI의 협업 패러다임을 근본적으로 변화시킬 잠재력을 가지고 있으며, 단순 반복 작업의 자동화를 넘어 창의적이고 전략적인 영역에서도 AI의 기여가 확대될 것으로 기대됩니다. 다가오는 미래에는 AI 에이전트가 우리의 생산성과 문제 해결 능력을 한 차원 끌어올리는 강력한 동반자가 될 것입니다.