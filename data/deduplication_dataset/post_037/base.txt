# **검색의 종말, 연구의 시작**

Author: Ethan Mollick
URL: https://www.oneusefulthing.org/p/the-end-of-search-the-beginning-of

============================================================

주말 동안 미래에 대한 힌트가 조용히 찾아왔습니다. 오랫동안 저는 AI 분야에서 두 가지 병행하는 혁명에 대해 논의해왔습니다. 바로 자율 에이전트(autonomous agents)의 부상과 OpenAI의 o1 출시 이후 강력한 추론기(Reasoners)의 등장이 그것입니다. 이 두 가지 흐름은 마침내 정말 인상적인 것으로 수렴되었습니다. 인간 전문가의 깊이와 뉘앙스를 가지고 연구를 수행할 수 있지만, 기계 속도로 작동하는 AI 시스템 말입니다. OpenAI의 딥 리서치(Deep Research)는 이러한 수렴을 보여주며 미래가 어떤 모습일지 짐작하게 합니다. 하지만 이것이 왜 중요한지 이해하려면, 우리는 기본 구성 요소인 추론기(Reasoners)와 에이전트(agents)부터 시작해야 합니다.

**추론기(Reasoners)**
지난 몇 년간 챗봇을 사용할 때마다 간단한 방식으로 작동했습니다. 무언가를 입력하면 즉시 단어 단위(더 기술적으로는 토큰(token) 단위)로 응답하기 시작했습니다. AI는 이러한 토큰을 생성하는 동안에만 "생각"할 수 있었기 때문에, 연구자들은 "답변하기 전에 단계별로 생각하라"고 지시하는 것과 같이 추론 능력을 향상시키는 방법을 개발했습니다. 이 접근 방식은 연쇄적 사고 프롬프트(chain-of-thought prompting)라고 불리며 AI 성능을 현저히 향상시켰습니다. 추론기는 본질적으로 이 과정을 자동화하여, 실제로 답변을 제공하기 전에 "사고 토큰(thinking tokens)"을 생성합니다.

이것은 적어도 두 가지 중요한 면에서 획기적이었습니다. 첫째, AI 기업들이 이제 정말 뛰어난 문제 해결자들의 사례를 바탕으로 AI가 추론하는 방법을 학습시킬 수 있게 되었기 때문에, AI는 더 효과적으로 "생각"할 수 있습니다. 이러한 훈련 과정은 우리가 프롬프트를 통해 얻을 수 있는 것보다 더 높은 품질의 연쇄적 사고(chain-of-thought)를 생성할 수 있습니다. 이는 추론기가 훨씬 더 어려운 문제를 해결할 수 있음을 의미하며, 특히 기존 챗봇이 실패했던 수학이나 논리 같은 분야에서 그렇습니다.

이것이 획기적이었던 두 번째 이유는 추론기가 더 오래 "생각"할수록 답변의 품질이 향상된다는 점입니다(생각하는 시간이 길어질수록 개선 속도는 느려지지만). 이는 매우 중요한데, 이전에는 AI 성능을 향상시키는 유일한 방법이 점점 더 큰 모델을 훈련시키는 것이었으며, 이는 비용이 많이 들고 많은 데이터를 필요로 했기 때문입니다. 추론 모델은 모델이 훈련될 때가 아니라 질문에 답변하는 시점(추론 시간 컴퓨팅(inference-time compute)이라고 함)에 컴퓨팅 파워를 사용하여 더 많은 사고 토큰을 생성하게 함으로써 AI를 더 좋게 만들 수 있음을 보여줍니다.

대학원 수준의 구글 무용 Q&A 테스트(Graduate-Level Google-Proof Q&A test, GPQA)는 인터넷 접근이 박사 학위 소지자에게도 도움이 되지 않는 일련의 객관식 문제입니다. 박사 학위 소지자들은 자신의 전문 분야 밖에서는 이 테스트에서 34%를, 전문 분야 내에서는 81%를 맞힙니다. 이는 추론 모델이 AI의 능력 향상 속도를 어떻게 가속화했는지 보여줍니다. 데이터 출처.

추론기는 매우 새롭기 때문에 그 능력은 빠르게 확장되고 있습니다. 불과 몇 달 만에 우리는 OpenAI의 o1 계열에서 새로운 o3 모델에 이르기까지 극적인 개선을 목격했습니다. 한편, 중국의 DeepSeek r1은 비용을 절감하면서 성능을 향상시키는 혁신적인 방법을 찾아냈고, 구글은 첫 번째 추론기를 출시했습니다. 이것은 단지 시작일 뿐입니다. 곧 더 많은 강력한 시스템을 보게 될 것입니다.

**에이전트(Agents)**
전문가들은 AI 에이전트의 정확한 정의에 대해 논쟁하지만, 우리는 이를 단순히 "목표가 주어지고 그 목표를 자율적으로 추구할 수 있는 AI"라고 생각할 수 있습니다. 현재 AI 연구소들은 범용 에이전트(general-purpose agents)를 구축하기 위한 군비 경쟁을 벌이고 있습니다. 이는 어떤 작업이든 처리할 수 있는 시스템을 말합니다. 저는 데빈(Devin)과 컴퓨터 사용(Computer Use) 기능을 갖춘 클로드(Claude)와 같은 초기 사례에 대해 글을 썼지만, OpenAI는 아마도 지금까지 가장 세련된 범용 에이전트인 오퍼레이터(Operator)를 방금 출시했습니다. 아래 16배속 영상은 범용 에이전트의 가능성과 함정을 모두 보여줍니다.

저는 오퍼레이터에게 작업을 부여합니다: OneUsefulThing에 있는 제 최신 서브스택(substack) 게시물을 읽고, 구글 이미지FX(Google ImageFX)로 이동하여 적절한 이미지를 만들고, 다운로드하여, 저에게 게시할 수 있도록 전달하는 것입니다. 전개되는 상황은 매우 흥미롭습니다. 처음에는 오퍼레이터가 놀라운 정확성으로 움직입니다. 제 웹사이트를 찾고, 게시물을 읽고, 이미지FX로 이동하여(제가 로그인 정보를 입력하는 동안 잠시 멈춤), 이미지를 생성합니다. 그러자 문제가 발생하는데, 두 가지입니다. 오퍼레이터는 OpenAI의 파일 다운로드 보안 제한에 의해 차단될 뿐만 아니라, 작업 자체에서도 어려움을 겪기 시작합니다. 에이전트는 클립보드에 복사하기, 직접 링크 생성하기, 심지어 사이트의 소스 코드(source code)를 파고드는 등 가능한 모든 해결책을 체계적으로 시도합니다. 각 시도는 실패합니다. 일부는 OpenAI의 브라우저 제한 때문이고, 다른 일부는 에이전트가 실제로 작업을 수행하는 방법에 대한 자체적인 혼란 때문입니다. 이처럼 단호하지만 궁극적으로 실패한 문제 해결 과정을 지켜보는 것은 이러한 시스템의 현재 한계를 드러내고, 에이전트가 현실 세계에서 장벽에 부딪혔을 때 궁극적으로 어떻게 행동할지에 대한 의문을 제기합니다.

오퍼레이터의 문제는 범용 에이전트의 현재 한계를 부각시키지만, 그렇다고 해서 에이전트가 쓸모없다는 것을 의미하지는 않습니다. 특정 작업에 초점을 맞춘 경제적으로 가치 있는 협소 에이전트(narrow agents)는 이미 가능한 것으로 보입니다. 현재 LLM(대규모 언어 모델) 기술로 구동되는 이 전문가들은 각자의 영역에서 놀라운 결과를 달성할 수 있습니다. 대표적인 예로, OpenAI의 새로운 딥 리서치(Deep Research)는 집중된 AI 에이전트가 얼마나 강력할 수 있는지를 보여줍니다.

**딥 리서치(Deep Research)**
OpenAI의 딥 리서치(Deep Research)(곧 다룰 구글의 딥 리서치(Deep Research)와 혼동하지 말 것)는 본질적으로 OpenAI의 아직 출시되지 않은 o3 추론기(Reasoner)를 기반으로 하며, 특별한 도구와 기능에 접근할 수 있는 협소 연구 에이전트(narrow research agent)입니다. 제가 최근에 본 AI 애플리케이션 중 가장 인상적인 것 중 하나입니다. 이유를 이해하기 위해 주제를 하나 줘봅시다. 저는 제 연구 분야 내에서 매우 기술적이고 논쟁적인 문제인 "스타트업은 언제 탐색을 멈추고 스케일업을 시작해야 하는가?"를 특별히 선택할 것입니다. 저는 이 주제에 대한 학술 연구를 검토하고, 고품질 논문과 무작위 대조 시험(RCTs)에 초점을 맞추며, 문제 있는 정의와 일반적인 통념 및 연구 간의 충돌을 다루는 것을 포함해 달라고 요청합니다. 이 문제에 대한 대학원 수준의 토론을 위한 결과를 제시해 주십시오. AI는 몇 가지 영리한 질문을 하고, 저는 제가 원하는 바를 명확히 합니다. 이제 o3가 작업을 시작합니다. 진행 상황과 "생각"하는 과정을 볼 수 있습니다. 아래에서 그 과정의 몇 가지 샘플을 잠시 살펴보는 것은 정말 가치 있는 일입니다. AI가 실제로 연구자처럼 작동하여, 발견 사항을 탐색하고, "흥미로운" 것들을 더 깊이 파고들며, 문제를 해결하는(예: 유료 기사(paywalled articles)에 접근하는 대체 방법을 찾는 것과 같은) 것을 볼 수 있습니다. 이 과정은 5분 동안 진행됩니다. 이 "사고" 과정의 세 가지 단면을 진지하게 잠시 살펴보십시오.

결국 저는 6개의 인용과 몇 개의 추가 참고 문헌이 포함된 13페이지, 3,778단어 분량의 초안을 받았습니다. 솔직히 말해서, 몇 가지 출처가 더 있었으면 좋았겠지만, 매우 훌륭합니다. 어렵고 모순되는 개념들을 엮어냈고, 예상치 못한 새로운 연결고리를 찾아냈으며, 오직 고품질 출처만을 인용했고, 정확한 인용문으로 가득했습니다. 모든 것이 정확하다고 보장할 수는 없지만(오류는 발견하지 못했지만), 박사 과정 초보 학생에게서 이와 같은 결과물을 보았다면 만족했을 것입니다. 전체 결과는 여기에서 볼 수 있지만, 아래의 몇 가지 발췌문만으로도 제가 왜 그렇게 감명받았는지 보여주기에 충분할 것입니다.

인용의 품질 또한 여기서 진정한 발전을 보여줍니다. 이것들은 흔히 볼 수 있는 AI 환각(hallucinations)이나 잘못 인용된 논문이 아닙니다. 제 동료인 이새롬(Saerom (Ronnie) Lee)과 김다니엘(Daniel Kim)의 선구적인 연구를 포함하여 합법적이고 고품질의 학술 자료들입니다. 링크를 클릭하면 단순히 논문으로 연결되는 것이 아니라, 종종 관련 강조 표시된 인용문으로 바로 이동합니다. AI가 몇 분 안에 찾아서 읽을 수 있는 것에만 접근할 수 있고, 유료 기사(paywalled articles)는 여전히 접근 불가능하다는 제약이 여전히 존재하지만, 이는 AI가 학술 문헌과 상호작용하는 방식에 근본적인 변화를 의미합니다. 처음으로 AI가 단순히 연구를 요약하는 것을 넘어, 실제로 인간의 학술 작업에 근접하는 수준으로 적극적으로 참여하고 있습니다.

지난달 출시된 구글의 제품 역시 딥 리서치(Deep Research)라고 불리는 것과 대조해 볼 가치가 있습니다(한숨). 구글은 훨씬 더 많은 인용을 제시하지만, 종종 품질이 다양한 웹사이트들의 혼합입니다(유료 정보 및 서적에 대한 접근성 부족은 이러한 모든 에이전트에게 불리하게 작용합니다). OpenAI의 연구자 에이전트(researcher agent)의 호기심 기반 발견(curiosity-driven discovery)과는 달리, 모든 문서를 한꺼번에 수집하는 것으로 보입니다. 그리고 (현재로서는) 추론 기능이 없는 구형 제미니 1.5(Gemini 1.5) 모델로 구동되기 때문에, 전반적인 요약은 여전히 견고하고 명백히 오류가 없지만, 훨씬 더 표면적인 수준입니다. 매우 훌륭한 학부생 수준의 결과물과 같습니다. 아래 내용을 조금 더 읽어보시면 그 차이가 명확해질 것이라고 생각합니다. 관점을 제시하자면: 두 결과물 모두 일반적으로 몇 시간의 인간 노력을 필요로 하는 작업입니다. OpenAI 시스템은 박사 학위 수준에 가까운 분석을, 구글은 견고한 학부생 수준의 작업을 제공합니다.

OpenAI는 발표에서 대담한 주장을 펼쳤는데, 그들의 에이전트가 높은 경제적 가치의 연구 프로젝트의 15%와 매우 높은 가치의 프로젝트의 9%를 처리할 수 있음을 시사하는 그래프를 포함했습니다. 이 수치들은 회의적으로 볼 필요가 있지만(방법론이 설명되지 않았음), 제 직접적인 테스트 결과는 그들이 완전히 틀린 것은 아니라는 것을 시사합니다. 딥 리서치(Deep Research)는 실제로 몇 시간이 아닌 몇 분 만에 가치 있고 정교한 분석을 생성할 수 있습니다. 그리고 빠른 개발 속도를 고려할 때, 구글이 이 능력 격차를 오래 지속시키지 않을 것이라고 예상합니다. 앞으로 몇 달 안에 연구 에이전트(research agents)의 빠른 개선을 보게 될 것입니다.

**조각들이 맞춰지다**
AI 연구소들이 구축하고 있는 조각들이 단순히 맞춰지는 것을 넘어, 서로 시너지를 내고 있다는 것을 알 수 있습니다. 추론기(Reasoners)는 지적인 원동력을 제공하고, 에이전트 시스템(agentic systems)은 행동할 수 있는 능력을 제공합니다. 현재 우리는 딥 리서치(Deep Research)와 같은 협소 에이전트(narrow agents)의 시대에 있습니다. 왜냐하면 우리의 최고의 추론기조차도 범용 자율성(general-purpose autonomy)을 위한 준비가 되어 있지 않기 때문입니다. 하지만 협소하다는 것이 한계를 의미하지는 않습니다. 이 시스템들은 한때 고액 연봉의 전문가 팀이나 전문 컨설팅 회사가 필요했던 작업을 이미 수행할 수 있습니다. 이러한 전문가와 컨설팅 회사들이 사라지는 것은 아닙니다. 오히려 그들은 직접 작업을 수행하는 것에서 AI 시스템의 작업을 조율하고 검증하는 역할로 진화함에 따라 그들의 판단이 더욱 중요해질 것입니다. 하지만 연구소들은 이것이 단지 시작에 불과하다고 믿습니다. 그들은 더 나은 모델이 범용 에이전트의 비밀을 풀어내어, 협소한 작업을 넘어 웹을 탐색하고, 모든 양식(modalities)에 걸쳐 정보를 처리하며, 세상에서 의미 있는 행동을 취할 수 있는 자율적인 디지털 작업자(autonomous digital workers)가 될 것이라고 확신하고 있습니다. 오퍼레이터(Operator)는 우리가 아직 그 단계에 도달하지 못했음을 보여주지만, 딥 리서치(Deep Research)는 우리가 그 길을 가고 있을 수도 있음을 시사합니다.

구독 공유