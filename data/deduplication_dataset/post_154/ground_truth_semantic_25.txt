이 보고서는 15,000단어를 상회하는 분량으로, 인공지능의 미래상에 대한 우리의 견해를 담은 최근 연구 보고서입니다. 이 아이디어들을 더욱 심화시킨 내용이 우리의 다음 공동 저작물이 될 것임을 발표하게 되어 기쁩니다. 이 논고는 나이트 수정헌법 제1조 연구소(Knight First Amendment Institute) 웹사이트에서 HTML 및 PDF 문서 형태로도 찾아볼 수 있습니다. 초고에 대해 보내주신 폭넓은 의견에 진심으로 감사드립니다. 업데이트 (2025년 9월): 우리는 이 에세이와 연계하여 "AI를 일반 기술로 이해하기 위한 가이드(A guide to understanding AI as normal technology)"라는 제목의 글을 발행했습니다.

우리는 인공지능(AI)을 평범한 기술의 범주로 인식하는 관점을 제안합니다. AI를 평범한 것으로 간주한다고 해서 그 영향력을 과소평가하는 것은 아닙니다. 전기나 인터넷과 같은 혁신적이며 광범위하게 적용되는 기술(general-purpose technologies)도 우리의 개념 안에서는 "일상적인" 것입니다. 그러나 이러한 시각은 인공지능을 독립적인 개체, 즉 고도의 자율성과 잠재적 초지능을 지닌 실체로 간주하는 일반적인 경향이 있는, 유토피아적 또는 디스토피아적 미래 예측과는 상반됩니다. 1 "AI는 일반 기술이다"라는 명제는 세 가지 함의를 가집니다. 현재 AI의 상태에 대한 설명, AI의 예측 가능한 미래에 대한 전망, 그리고 우리가 AI를 어떻게 다루어야 하는지에 대한 권고입니다. 우리는 인공지능을 우리가 제어할 수 있고 마땅히 제어해야 하는 도구로 바라보며, 이러한 목표 달성이 급진적인 정책적 개입이나 기술적 돌파구를 필요로 하지 않는다고 주장합니다. 우리는 AI를 인간과 유사한 지능으로 보는 것이 현재 AI의 사회적 파급력을 이해하는 데 정확하거나 유용하다고 생각하지 않으며, 미래에 대한 우리의 전망에서도 그러할 가능성은 희박합니다. 2

평범한 기술(normal technology)이라는 틀은 기술과 사회 간의 관계를 다룹니다. 이는 기술 결정론(technological determinism), 특히 AI 자체가 미래를 결정하는 주체라는 관념을 배척합니다. 과거 기술 혁명에서 얻은 교훈, 즉 기술 채택 및 확산의 더디고 불확실한 특성에서 통찰력을 얻습니다. 또한 사회적 영향과 이러한 궤적을 형성하는 제도적 역할 측면에서 AI의 과거와 미래 경로 사이의 연속성을 강조합니다.

1부에서는 혁신적인 경제적 및 사회적 영향이 서서히(수십 년의 시간 간격으로) 나타날 것이라고 예상하는 근거를 설명하며, AI 방법론(methods), AI 애플리케이션(applications), AI 도입(adoption) 사이에 중요한 구분을 짓고, 이 세 가지가 서로 다른 시간 척도에서 진전된다고 주장합니다. 2부에서는 고도화된 AI(그러나 일반적으로 초지능으로 개념화되는 것과는 달리 일관성이 부족하다고 보는 AI)가 존재하는 세상에서 인간과 AI 간의 잠재적인 역할 분담에 대해 논의합니다. 이 세상에서 통제권은 주로 사람과 조직의 손에 있습니다. 실제로 사람들이 직무에서 수행하는 일의 상당 부분이 AI 제어를 포함하게 됩니다. 3부에서는 AI를 일반 기술로 보는 관점이 AI 위험에 미치는 영향을 탐구합니다. 우리는 사고, 군비 경쟁(arms races), 오용, 오정렬(misalignment)을 분석하며, AI를 일반 기술로 보는 것이 AI를 인간과 유사한 존재로 보는 것과 비교하여 위험 완화에 대해 근본적으로 다른 결론을 도출한다고 주장합니다. 물론, 우리의 예측이 확정적일 수는 없지만, 우리가 중간 결과(median outcome)로 보는 것을 제시하는 것을 목표로 합니다. 우리는 확률을 수치화하려고 시도하지 않았지만, AI가 일반 기술처럼 작동하는지 여부를 알려줄 수 있는 예측을 제시하고자 했습니다. 4부에서는 AI 정책에 대한 시사점을 논의합니다. 우리는 불확실성을 줄이는 것을 최우선 정책 목표로, 회복탄력성(resilience)을 재앙적 위험(catastrophic risks)에 대한 포괄적인 접근 방식으로 옹호합니다. 우리는 초지능(superintelligent) AI를 통제하기 어렵다는 전제에 기반한 급진적인 개입이 AI가 일반 기술로 판명될 경우 실제로는 상황을 훨씬 더 악화시킬 것이며, 그 단점은 불평등과 같이 자본주의 사회에 도입된 이전 기술의 단점을 반영할 가능성이 높다고 주장합니다. 3

우리가 2부에서 묘사하는 세상은 오늘날보다 훨씬 더 발전된 AI가 존재하는 세상입니다. 우리는 AI의 발전, 또는 인간의 발전이 그 지점에서 멈출 것이라고 주장하는 것이 아닙니다. 그 다음에는 무엇이 올까요? 우리는 알지 못합니다. 다음 비유를 고려해 보십시오. 첫 산업 혁명 초기에 산업화된 세상이 어떻게 보일지 예측하고 대비하는 것은 유용했을 것이지만, 전기나 컴퓨터를 미리 내다보려고 시도하는 것은 헛된 노력이었을 것입니다. 여기서 우리의 작업도 유사합니다. 우리는 "급진적 발전(fast takeoff)" 시나리오를 받아들이지 않으므로, 우리가 시도한 것보다 더 먼 미래의 세상을 상상하는 것이 필요하거나 유용하다고 보지 않습니다. 2부에서 설명하는 시나리오가 현실화되면, 우리는 다음에 올 것이 무엇이든 더 잘 예측하고 대비할 수 있을 것입니다.

독자에게 드리는 말씀. 이 에세이는 특정 명제(proposition)를 옹호하기보다는 세계관(worldview)을 제시하는 독특한 목적을 가지고 있습니다. AI 초지능(superintelligence)에 대한 문헌은 방대합니다. 우리는 잠재적인 반론에 대해 일대일로 답변하려고 시도하지 않았는데, 그렇게 하면 이 글의 분량이 몇 배나 늘어날 것이기 때문입니다. 이 논고는 우리의 견해를 처음으로 표명한 것에 불과하며, 다양한 후속 조치를 통해 이를 상세히 설명할 계획입니다. 후속 에세이를 받으려면 구독하십시오.

**1부: 진보의 속도**

**그림 1.** 다른 범용 기술(general-purpose technologies)과 마찬가지로, AI의 영향은 방법론과 역량이 향상될 때가 아니라, 이러한 개선이 응용 프로그램으로 전환되어 경제의 생산적인 영역에 확산될 때 비로소 실현됩니다. 4 각 단계마다 속도 제한이 존재합니다. AI의 진보는 AI 역량과 도입이 증가함에 따라 사람과 조직이 적응할 수 있도록 점진적으로 이루어질까요, 아니면 대규모 혼란이나 심지어 기술적 특이점(technological singularity)으로 이어지는 급격한 도약이 있을까요? 이 질문에 대한 우리의 접근 방식은 중요성이 높은 작업을 중요성이 낮은 작업과 분리하여 분석하고, 혁신과 발명의 속도로 돌아가기 전에 AI 도입 및 확산의 속도를 분석하는 것으로 시작합니다. 우리는 발명(invention)을 AI의 다양한 작업을 수행하는 능력을 향상시키는 새로운 AI 방법론(methods) —예를 들어 대규모 언어 모델(large language models)과 같은—의 개발을 지칭하는 데 사용합니다. 혁신(innovation)은 소비자와 기업이 활용할 수 있는 AI 기반 제품 및 애플리케이션 개발을 의미합니다. 도입(adoption)은 개인(또는 팀 또는 기업)이 기술을 사용하기로 결정하는 것을 의미하며, 확산(diffusion)은 도입 수준이 증가하는 광범위한 사회적 과정을 의미합니다. 충분히 파괴적인 기술의 경우, 확산은 기업 및 조직의 구조뿐만 아니라 사회적 규범 및 법률의 변화를 요구할 수 있습니다.

**위험도가 높은 분야에서의 AI 확산은 더디다.**

"예측 최적화에 반대하며(Against Predictive Optimization)"라는 글에서 우리는 예측 최적화(predictive optimization)의 약 50가지 활용 사례에 대한 포괄적인 목록을 작성했습니다. 이는 기계 학습(ML)을 활용하여 개인의 미래 행동이나 결과를 예측함으로써 개인에 대한 의사결정을 내리는 것을 의미합니다. 5 범죄 위험 예측, 보험 위험 평가, 아동 학대 예측과 같은 이러한 응용 프로그램의 대다수는 사람들에게 중대한 영향을 미치는 결정을 내리는 데 활용됩니다. 이러한 응용 프로그램들이 확산되기는 했지만, 중요한 차이점이 존재합니다. 대부분의 경우, 수십 년 된 통계적 기법(statistical techniques) —단순하고 해석 가능한 모델(주로 회귀 분석)과 비교적 적은 수의 수작업 특징(handcrafted features)—이 사용됩니다. 랜덤 포레스트(random forests)와 같은 보다 복잡한 기계 학습 방식은 거의 찾아볼 수 없으며, 트랜스포머(transformers)와 같은 현대적인 방법론은 발견하기 어렵습니다. 즉, 이 광범위한 분야에서 AI의 확산은 혁신보다 수십 년 뒤처져 있습니다.

주요 원인 중 하나는 안전에 대한 우려입니다. 모델이 복잡하고 이해하기 어려울수록, 테스트 및 검증 과정에서 가능한 모든 배포 환경(deployment conditions)을 예측하기가 더욱 어려워집니다. 좋은 예시로 에픽(Epic)의 패혈증 예측 도구(sepsis prediction tool)를 들 수 있는데, 내부 검증 시에는 높은 정확도를 보였지만, 실제 병원 환경에서는 훨씬 저조한 성능을 보여 패혈증 사례의 3분의 2를 놓치고 의료진에게 오경보(false alerts)를 남발했습니다. 6 에픽의 패혈증 예측 도구는 제약 없는 특징 집합(feature sets)을 가진 복잡한 모델에서 발생하기 쉬운 오류 때문에 실패했습니다. 7 특히, 모델 훈련에 사용된 특징 중 하나는 의사가 이미 항생제를 처방했는지 여부였습니다. 즉, 테스트 및 검증 단계에서 모델은 미래의 정보를 사용하고 있었고, 결과에 인과적으로 의존적(causally dependent)인 변수에 의존하고 있었습니다. 물론 이 특징은 실제 배포 시점에서는 활용할 수 없습니다. 해석 가능성(interpretability) 및 감사(auditing) 방법은 의심할 여지 없이 개선되어 이러한 문제를 훨씬 더 효과적으로 포착할 수 있게 되겠지만, 아직 그 단계에 이르지 못했습니다.

생성형 AI(generative AI)의 경우, 나중에 보면 매우 명확해 보이는 실패조차도 테스트 과정에서 포착되지 않았습니다. 한 예로 초기 빙 챗봇 "시드니(Sydney)"가 장시간 대화 중에 예상치 못한 방향으로 흘러갔던 것인데, 개발자들은 대화가 몇 차례 이상 지속될 수 있다는 것을 분명히 예측하지 못했습니다. 8 마찬가지로, 제미니(Gemini) 이미지 생성기는 역사적 인물에 대해 충분히 테스트되지 않은 것으로 보입니다. 9 다행히도, 이들은 중요도가 높은 애플리케이션은 아니었습니다. 다양한 애플리케이션에서 혁신-확산 지연(innovation-diffusion lag)과 그 원인을 이해하는 데 더 많은 실증적 연구(empirical work)가 도움이 될 것입니다. 그러나 현재로서는 우리가 이전 연구에서 분석한 증거는 중요성이 높은 작업에서 이미 매우 강력한 안전 관련 속도 제한이 존재한다는 견해와 일치합니다. 이러한 제한은 FDA의 의료기기 감독과 같은 규제뿐만 아니라 고위험 AI에 엄격한 요구 사항을 부과하는 EU AI 법(EU AI Act)과 같은 새로운 법률을 통해 종종 시행됩니다. 10 사실, 고위험 AI에 대한 기존 규제가 너무 부담스러워서 "폭주하는 관료주의(runaway bureaucracy)"로 이어질 수 있다는 (신뢰할 만한) 우려가 있습니다. 11 따라서 우리는 중요성이 높은 작업에서 느린 확산이 계속해서 일반적인 현상이 될 것이라고 예측합니다. 게다가, AI가 중요성이 높은 방식으로 사용될 수 있는 새로운 영역이 나타나면, 우리는 이를 규제할 수 있고 규제해야 합니다. 좋은 예는 2010년 플래시 크래시(Flash Crash)인데, 자동화된 고빈도 거래가 한몫했다고 여겨집니다. 이는 서킷 브레이커(circuit breakers)와 같은 새로운 거래 제한으로 이어졌습니다. 12

**확산은 인간, 조직 및 제도 변화의 속도에 의해 제한된다.**

안전이 중요한 영역 외에서도 AI 도입은 대중적인 설명보다 느립니다. 예를 들어, 2024년 8월에 미국 성인의 40%가 생성형 AI(generative AI)를 사용했다는 연구 결과가 헤드라인을 장식했습니다. 13 그러나 대부분의 사람들이 이를 자주 사용하지 않았기 때문에, 이는 전체 근무 시간의 0.5%~3.5%에 불과했으며(노동 생산성 0.125%~0.875% 포인트 증가) 노동 생산성 증가로 이어졌습니다. 확산 속도가 과거보다 오늘날 더 빠른지는 명확하지 않습니다. 앞서 언급된 연구는 미국에서 생성형 AI 도입이 개인용 컴퓨터(PC) 도입보다 빨랐다고 보고했습니다. 첫 대량 시장 제품 출시 후 2년 이내에 미국 성인의 40%가 생성형 AI를 도입한 반면, PC의 경우 3년 이내에 20%였습니다. 그러나 이 비교는 도입 강도(사용 시간)의 차이나 생성형 AI 접근에 비해 PC 구매 비용이 높은 점을 고려하지 않습니다. 14 도입을 측정하는 방식에 따라 생성형 AI의 도입이 PC 도입보다 훨씬 느렸을 가능성도 충분히 있습니다.

디지털 기술이 수십억 대의 장치에 동시에 도달할 수 있다는 점을 고려할 때, 기술 도입 속도가 반드시 증가하는 것은 아니라는 주장은 놀랍거나(심지어 명백히 틀렸다고) 보일 수 있습니다. 그러나 도입은 소프트웨어 사용에 관한 것이지 가용성에 관한 것이 아니라는 점을 기억하는 것이 중요합니다. 새로운 AI 기반 제품이 온라인에 무료로 즉시 출시되더라도, 사람들이 새로운 제품의 이점을 활용하고 위험을 피하는 방법을 배우기 위해 작업 흐름과 습관을 바꾸는 데는 시간이 걸립니다. 따라서 확산 속도는 개인뿐만 아니라 조직과 기관이 기술에 적응할 수 있는 속도에 의해 본질적으로 제한됩니다. 이는 우리가 과거의 범용 기술(general-purpose technologies)에서도 보았던 추세입니다. 확산은 수년이 아닌 수십 년에 걸쳐 발생합니다. 15

예를 들어, 폴 A. 데이비드(Paul A. David)의 전력화(electrification) 분석은 생산성 이점이 완전히 실현되는 데 수십 년이 걸렸음을 보여줍니다. 16 에디슨의 첫 중앙 발전소 이후 거의 40년 동안 전기 발전기(electric dynamos)는 "생산성 통계에는 없었지만 어디에나 있었습니다." 17 이는 단순히 기술적 관성(technological inertia) 때문만은 아니었습니다. 공장 소유주들은 전력화가 상당한 효율성 향상을 가져오지 않는다는 것을 발견했습니다. 결국 이점을 실현할 수 있었던 것은 생산 라인(production lines)의 논리를 중심으로 공장 전체 레이아웃을 재설계한 것이었습니다. 공장 건축의 변화 외에도 확산은 작업장 조직 및 공정 제어(process control)의 변화도 필요로 했으며, 이는 산업 전반에 걸친 실험을 통해서만 개발될 수 있었습니다. 이러한 변화의 결과로 작업자들은 더 많은 자율성과 유연성을 가졌고, 이는 또한 다른 고용 및 훈련 관행을 필요로 했습니다.

**외부 세계는 AI 혁신에 속도 제한을 둔다.**

인공지능의 기술적 발전이 신속하게 이루어졌다는 사실은 부인할 수 없으나, AI 방법론(methods)과 애플리케이션을 구분하면 상황은 훨씬 덜 명확해집니다. 우리는 AI 방법론의 발전을 일반성 사다리(ladder of generality)로 개념화합니다. 18 이 사다리의 각 단계는 그 아래 단계에 기반을 두며, 더 일반적인 컴퓨팅 역량으로의 움직임을 반영합니다. 즉, 컴퓨터가 새로운 작업을 수행하는 데 필요한 프로그래머의 노력을 줄이고, 주어진 양의 프로그래머(또는 사용자) 노력으로 수행할 수 있는 작업의 집합을 증가시킵니다. 그림 2를 참조하십시오. 예를 들어, 기계 학습(machine learning)은 각 새로운 작업을 해결하기 위한 논리를 프로그래머가 직접 고안할 필요성을 없애고 대신 훈련 예제 수집만을 요구함으로써 일반성을 증진시킵니다. 인공 일반 지능(AGI)에 도달할 때까지 사다리의 더 많은 단계를 구축함에 따라 특정 애플리케이션을 개발하는 데 필요한 노력이 계속 감소할 것이라고 결론 내리고 싶을 수 있습니다. AGI는 종종 모든 것을 즉시 수행할 수 있어 애플리케이션 개발의 필요성을 완전히 없애는 AI 시스템으로 개념화됩니다.

일부 영역에서는 실제로 애플리케이션 개발 노력 감소 추세가 나타나고 있습니다. 자연어 처리(natural language processing) 분야에서 대규모 언어 모델(large language models)은 언어 번역 애플리케이션을 개발하는 것을 비교적 사소한 일로 만들었습니다. 또는 게임을 생각해 보십시오. 알파제로(AlphaZero)는 게임에 대한 설명과 충분한 컴퓨팅 능력만 주어지면 자가 학습(self-play)을 통해 체스(chess)와 같은 게임을 어떤 인간보다도 잘 배우고 플레이할 수 있습니다. 이는 과거 게임 플레이 프로그램이 개발되던 방식과는 거리가 멉니다.

**그림 2: 컴퓨팅의 일반성 사다리.** 일부 작업의 경우, 사다리의 높은 단계를 통해 컴퓨터가 새로운 작업을 수행하는 데 필요한 프로그래머의 노력이 줄어들고, 주어진 양의 프로그래머(또는 사용자) 노력으로 더 많은 작업을 수행할 수 있습니다. 19

그러나 이는 쉽게 시뮬레이션할 수 없고 오류 비용이 큰 중요성이 높은 실제 애플리케이션에서는 이러한 추세가 아니었습니다. 자율주행차를 생각해 보십시오. 여러 면에서 자율주행차 개발 궤적은 알파제로의 자가 학습과 유사합니다. 기술 개선을 통해 더 현실적인 조건에서 운전할 수 있게 되었고, 이는 더 좋거나 더 현실적인 데이터 수집을 가능하게 했으며, 이는 다시 기술 개선으로 이어져 피드백 루프를 완성했습니다. 그러나 이 과정은 알파제로의 경우 몇 시간이 걸린 것과 달리 20년 이상이 걸렸는데, 이는 안전 고려 사항이 이 루프의 각 반복이 이전 반복에 비해 확장될 수 있는 정도에 제한을 두었기 때문입니다. 20 이러한 "역량-신뢰성 격차(capability-reliability gap)"는 계속해서 나타납니다. 이는 실제 작업을 자동화할 수 있는 유용한 AI "에이전트(agents)"를 구축하는 데 주요 장벽이었습니다. 21 명확히 말하면, 여행 예약이나 고객 서비스 제공과 같이 에이전트 사용이 예상되는 많은 작업은 운전보다 중요성이 훨씬 낮지만, 에이전트가 실제 경험에서 배우는 것이 간단하지 않을 정도로 여전히 비용이 많이 듭니다.

안전이 중요하지 않은 애플리케이션에서도 장벽은 존재합니다. 일반적으로 조직 내 많은 지식은 암묵적 지식(tacit knowledge)이며 문서화되지 않으며, 수동적으로 학습될 수 있는 형태로 기록된 경우는 더욱 적습니다. 이는 이러한 개발 피드백 루프가 각 부문에서 발생해야 하며, 더 복잡한 작업의 경우 다른 조직에서 개별적으로 발생해야 할 수도 있어, 빠른 병렬 학습(parallel learning) 기회를 제한한다는 것을 의미합니다. 병렬 학습이 제한될 수 있는 다른 이유는 개인 정보 보호 문제입니다. 조직과 개인은 민감한 데이터를 AI 회사와 공유하는 것을 꺼릴 수 있으며, 규제는 의료와 같은 맥락에서 어떤 종류의 데이터를 제3자와 공유할 수 있는지 제한할 수 있습니다.

AI의 "쓰디쓴 교훈(bitter lesson)"은 계산 능력 증가를 활용하는 일반적인 방법론이 결국 인간의 도메인 지식을 활용하는 방법론을 크게 능가한다는 것입니다. 22 이는 방법론에 대한 귀중한 관찰이지만, 종종 애플리케이션 개발을 포함하는 것으로 오해됩니다. AI 기반 제품 개발의 맥락에서 쓰디쓴 교훈은 결코 사실에 가깝지 않았습니다. 23 소셜 미디어의 추천 시스템(recommender systems)을 생각해 보십시오. 이들은 (점점 더 일반적인) 머신러닝 모델에 의해 구동되지만, 이는 비즈니스 로직(business logic), 프런트엔드(frontend) 및 기타 구성 요소의 수동 코딩 필요성을 없애지 못했습니다. 이러한 구성 요소는 모두 합쳐 백만 줄에 달하는 코드를 구성할 수 있습니다.

AI가 기존 인간 지식에서 학습하는 것을 넘어설 필요가 있을 때 추가적인 한계가 발생합니다. 24 우리의 가장 가치 있는 지식 유형 중 일부는 과학적 및 사회과학적 지식이며, 기술과 대규모 사회 조직(예: 정부)을 통해 문명의 발전을 가능하게 했습니다. AI가 이러한 지식의 경계를 확장하려면 무엇이 필요할까요? 이는 약물 테스트에서 경제 정책에 이르기까지 사람이나 조직과의 상호 작용, 심지어 실험을 필요로 할 것입니다. 여기서는 실험의 사회적 비용(social costs of experimentation) 때문에 지식 습득 속도에 엄격한 제한이 있습니다. 사회는 AI 개발을 위한 실험의 빠른 확장을 허용하지 않을 것이며(또한 허용해서는 안 됩니다).

**벤치마크는 실제 유용성을 측정하지 않는다.**

방법론-애플리케이션 구분은 AI 발전 측정 및 예측 방식에 중요한 함의를 가집니다. AI 벤치마크(benchmarks)는 방법론의 발전을 측정하는 데 유용합니다. 불행히도, 이들은 종종 애플리케이션의 발전을 측정하는 것으로 오해되었으며, 이러한 혼란은 임박한 경제적 변혁에 대한 많은 과장된 선전(hype)의 원동력이었습니다. 예를 들어, GPT-4가 변호사 시험(bar exam) 응시자 중 상위 10%의 점수를 달성했다고 보고되었지만, 이는 AI의 법률 실무 능력에 대해 놀랍도록 적은 정보를 제공합니다. 25 변호사 시험은 전문 지식(subject-matter knowledge)을 과도하게 강조하고, 표준화된 컴퓨터 관리 형식으로 측정하기 훨씬 어려운 실제 기술을 과소평가합니다. 다시 말해, 이는 언어 모델이 잘하는 것—기억된 정보를 검색하고 적용하는 것—을 정확히 강조합니다.

더 넓게 보면, 법률 전문가에게 가장 중요한 변화를 가져올 작업은 평가하기 가장 어려운 작업이기도 합니다. 법률 요청을 법률 영역별로 분류하는 것과 같은 작업은 명확한 정답이 있기 때문에 평가가 간단합니다. 그러나 법률 서류(legal filings) 작성과 같이 창의성과 판단을 요하는 작업에는 단 하나의 정답이 없으며, 합리적인 사람들은 전략에 대해 의견이 다를 수 있습니다. 후자의 작업은 자동화될 경우 해당 직업에 가장 심오한 영향을 미칠 작업입니다. 26 이 관찰은 결코 법률에만 국한되지 않습니다. 또 다른 예는 AI가 탁월한 성능을 보이는 독립적인 코딩 문제(coding problems)와, 그 영향은 측정하기 어렵지만 미미해 보이는 실제 소프트웨어 공학(real-world software engineering) 사이의 격차입니다. 27 장난감 문제(toy problems)를 넘어선 높은 평가를 받는 코딩 벤치마크조차도 정량화 및 공개적으로 사용 가능한 데이터를 사용한 자동 평가를 위해 실제 소프트웨어 공학의 많은 측면을 필연적으로 무시해야 합니다. 28

이러한 패턴은 반복적으로 나타납니다. 벤치마크를 통해 작업 측정이 쉬울수록, 전문 실무를 정의하는 복잡하고 맥락적인 작업을 나타낼 가능성은 낮아집니다. AI 발전 이해를 위해 역량 벤치마크에 지나치게 집중함으로써 AI 커뮤니티는 기술의 실제 영향을 일관되게 과대평가합니다. 이는 '구성 타당성(construct validity)' 문제인데, 이는 테스트가 실제로 측정하려는 것을 측정하는지 여부를 의미합니다. 29 잠재적 애플리케이션의 실제 유용성을 측정하는 유일한 확실한 방법은 실제로 애플리케이션을 구축하고, 현실적인 시나리오에서 전문가들과 함께 테스트하는 것입니다(의도된 사용에 따라 노동력을 대체하거나 증강하는 방식). 이러한 '향상(uplift)' 연구는 일반적으로 많은 직업의 전문가들이 기존 AI 시스템으로부터 이점을 얻는다는 것을 보여주지만, 이 이점은 일반적으로 미미하며 대체보다는 증강(augmentation)에 가깝습니다. 이는 시험과 같은 정적 벤치마크를 기반으로 결론 내릴 수 있는 것과는 근본적으로 다른 그림입니다. 30 (카피라이터와 번역가와 같은 소수의 직업은 상당한 일자리 손실을 겪었습니다. 31) 결론적으로, 벤치마크는 AI 방법론(methods)의 발전을 추적하는 데 유용하지만, AI 영향을 추적하기 위해서는 다른 종류의 지표를 살펴보아야 합니다(그림 1). 도입을 측정할 때는 AI 사용 강도를 고려해야 합니다. 애플리케이션 유형도 중요합니다. 증강 대 대체, 그리고 고위험 대 저위험. 구성 타당성(construct validity)을 보장하는 어려움은 벤치마킹뿐만 아니라 (미래) AI 영향을 평가하려는 또 다른 주요 방법인 예측에도 영향을 미칩니다. 효과적인 예측을 보장하기 위해 모호한 결과를 피하는 것이 매우 중요합니다. 예측 커뮤니티가 이를 달성하는 방법은 시험 성과와 같은 비교적 좁은 기술 측면에서 이정표를 정의하는 것입니다. 예를 들어, "인간-기계 지능 동등성(human-machine intelligence parity)"에 대한 메타큘러스(Metaculus) 질문은 수학, 물리학, 컴퓨터 과학 시험 문제의 성과 측면에서 정의됩니다. 이 정의에 따르면, 예측가들이 2040년까지 "인간-기계 지능 동등성"을 달성할 확률을 95%로 예측하는 것은 놀라운 일이 아닙니다. 32 불행히도, 이 정의는 너무 희석되어 AI의 영향을 이해하는 데 큰 의미가 없습니다. 위에서 법률 및 기타 전문 벤치마크에서 보았듯이, 시험에서의 AI 성능은 구성 타당성(construct validity)이 너무 낮아서 AI가 전문직 종사자를 대체할지 여부조차 예측할 수 없습니다.

**경제적 파급 효과는 점진적일 가능성이 높다.**

AI 개발이 갑작스럽고 급격한 경제적 영향을 미칠 수 있다는 한 가지 주장은 일반성(generality)의 증가가 경제 내 광범위한 작업의 자동화 가능성으로 이어질 수 있다는 것입니다. 이는 모든 경제적으로 가치 있는 작업을 수행할 수 있는 통합 시스템인 일반 인공지능(AGI)의 한 정의와 관련이 있습니다. 일반 기술(normal technology) 관점에 따르면, 그러한 갑작스러운 경제적 영향은 있을 법하지 않습니다. 이전 섹션에서 우리는 한 가지 이유를 논의했습니다. AI 방법론(methods)의 갑작스러운 개선은 확실히 가능하지만, 혁신(애플리케이션 개발의 의미에서)과 확산을 필요로 하는 경제적 영향으로 직접적으로 이어지지는 않습니다. 혁신과 확산은 피드백 루프(feedback loop)에서 발생합니다. 안전이 중요한 애플리케이션에서는 이 피드백 루프가 항상 느리지만, 안전을 넘어서도 느릴 가능성이 높은 많은 이유가 있습니다. 전기, 컴퓨터, 인터넷과 같은 과거의 범용 기술(general-purpose technologies)의 경우, 각 피드백 루프는 수십 년에 걸쳐 전개되었으며, AI에서도 동일한 일이 발생할 것으로 예상해야 합니다.

점진적인 경제적 영향에 대한 또 다른 주장: 일단 우리가 무언가를 자동화하면, 그 생산 비용과 가치는 인간 노동 비용에 비해 시간이 지남에 따라 급격히 떨어지는 경향이 있습니다. 자동화가 증가함에 따라 인간은 적응할 것이며, 아직 자동화되지 않은 작업, 어쩌면 오늘날 존재하지 않는 작업(2부에서 그러한 작업이 어떤 모습일지 설명합니다)에 집중할 것입니다. 이는 자동화가 증가함에 따라 경제적으로 가치 있는 작업이 재정의되면서 AGI의 목표점(goalpost)이 계속해서 멀어질 것임을 의미합니다. 오늘날 인간이 하는 모든 작업이 언젠가 자동화될 수 있다 하더라도, 이것이 인간 노동이 불필요(superfluous)해진다는 것을 의미하지는 않습니다. 이 모든 것은 특정 시점에 경제의 광범위한 자동화 가능성에서 벗어납니다. 또한 강력한 AI의 영향이 다른 부문에서 다른 시간 척도로 느껴질 것임을 암시합니다.

**AI 방법론 발전의 속도 제한**

AI 영향의 느림에 대한 우리의 주장은 혁신-확산 피드백 루프(innovation-diffusion feedback loop)에 기반하며, AI 방법론(methods)의 발전이 임의로 가속화될 수 있다 하더라도 적용 가능합니다. 우리는 이점과 위험 모두 주로 개발보다는 AI 배포(deployment)에서 발생한다고 봅니다. 따라서 AI 방법론 발전의 속도는 영향 문제와 직접적으로 관련이 없습니다. 그럼에도 불구하고, 방법론 개발