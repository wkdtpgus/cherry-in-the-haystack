지난달, 사카나 AI는 '전면적인 자동화된 과학적 탐구를 위한 첫 통합 체계'라 일컫는 '인공지능 과학자'를 선보였습니다. 이는 인간의 제약에서 벗어나 학문 발전을 촉진할 수 있다고 홍보되었습니다. 불행히도, 이 '인공지능 과학자'는 여러 취약점을 내포하고 있습니다. 창의성 검증 절차가 부재하여 산출된 결과물이 기존 연구의 반복일 가능성이 있습니다. 또한 전문 연구자의 동료 심사는 물론, 어떠한 인적 평가 과정도 거치지 않아 그 유용성이 모호합니다(명백히 그렇지 않은 것으로 보입니다). 이러한 문제점은 사카나의 사례에서 특히 명확히 드러나지만, 대부분의 AI 에이전트들이 적절한 평가 체계를 갖추지 못해 실제 환경에서의 파급력을 가늠하기 어렵다는 공통된 과제를 안고 있습니다. 검증되지 않은 AI 생성 과학은 심각한 윤리적 문제를 야기할 수 있으며, AI의 과대광고와 실제 역량 간의 괴리는 사회 전반의 신뢰를 저해할 위험이 있습니다. 인공지능 시대에 과학적 진실성을 유지하기 위한 견고한 프레임워크 구축이 필수적입니다. 본고에서는 AI가 기존의 전산 연구 결과를 얼마나 효과적으로 재현할 수 있는지 평가할 신규 측정 기준을 제시합니다. 아울러 이 작업이 '범용 지능' 개념과 AI의 잠재적 경제적 파급 효과에 대한 우리의 관점을 어떻게 변모시켰는지 함께 논의하고자 합니다. 자세한 내용은 논문을 참조하십시오.

**CORE-Bench: 연구 재현을 위한 AI 평가의 새로운 기준점**

인공지능이 학문 분야를 자동화하려는 구상은 매혹적이지만, 아직 달성하기 요원하며 부정확한 과학적 결과물을 초래할 수 있습니다. 이러한 위험성 때문에, AI가 생성한 과학적 내용에 대한 '환각(hallucination)' 문제는 단순히 틀린 정보를 넘어 과학적 기반 자체를 흔들 수 있습니다. 반면, 전산적 재현성 검증과 같이 명확히 한정된 과제에 AI를 활용하는 것은 상당한 시간 절약을 가능하게 하며, 연구자의 에너지를 더욱 생산적인 학술 활동으로 재배치할 수 있게 합니다. AI는 관련 자료 검색, 신속한 아이디어 검증을 위한 코드 생성, 데이터 정제, 시각화, 심지어 실험 설계 제안과 같은 여타 전산적 처리 작업 수행에 기여할 수 있습니다. 최근 발표된 연구에서 저희는 AI가 전산적 재현성을 얼마나 효율적으로 자동화할 수 있는지, 다시 말해 코드와 자료가 주어졌을 때 연구 논문의 결과물을 재현하는 역량을 평가하기 위한 기준점인 CORE-Bench(계산 재현성 에이전트 벤치마크)를 선보입니다. 이 논문의 저자는 Zachary S. Siegel, Sayash Kapoor, Nitya Nadgir, Benedikt Stroebl, Arvind Narayanan입니다. CORE-Bench는 점진적으로 어려워지는 연구 과제 자동화의 진척도를 엄밀히 판단하기 위한 광범위한 프로젝트의 시발점입니다.

연구 결과를 전산적으로 다시 만드는 것은, 인간 참여자를 포함할 수 있는 실험을 다시 수행해야 하는 복제(replication)에 비해 훨씬 더 한정된 범위의 과업입니다. 복제는 실험의 전 과정을 독립적으로 다시 수행하여 동일한 결론에 도달하는 것을 목표로 하지만, 전산적 재현성은 주어진 데이터와 코드를 사용하여 동일한 계산 결과를 얻는 데 초점을 맞춥니다. 이처럼 제약적인 재현성 작업조차도 쉽지 않습니다. 과학적 진실성과 신뢰를 유지하는 데 필수적인 재현성은 현재 인간 연구자들에게 상당한 부담으로 작용하고 있습니다. 재현 불가능한 연구는 '과학적 부채'를 증가시키고, 연구 자원의 막대한 낭비를 초래합니다. 2022년 기계학습 재현성 경진대회에서는 전문 연구자들이 코드와 데이터를 보유했음에도 불구하고, 참가 논문 중 3분의 1 이상이 재현에 실패하는 결과를 보였습니다. 만약 AI가 이 평범하지만 핵심적인 역할을 자동화할 수 있다면, 연구자들은 기본 모델 구현을 자동화하고, 심사자들은 논문의 문제점을 더욱 용이하게 판별할 수 있으며, 학술지 및 학회는 제출되거나 출판된 연구가 재현 가능한지 보다 수월하게 검증할 수 있을 것입니다. AI는 인간 심사자가 놓칠 수 있는 코드나 데이터 처리의 미묘한 오류까지 식별하며, 사실상 '자동화된 동료 심사자' 역할을 수행할 잠재력을 가지고 있습니다.

저희는 과학 연구 보고서와 동반되는 코드 및 자료 저장소(repositories)를 활용하여 CORE-Bench를 구성했습니다. 특히 코드를 오션(Code Ocean) 플랫폼을 통해 재현성이 높은 논문들을 수집했습니다. 저희는 컴퓨터 과학, 의료, 사회 과학 분야의 90편의 연구물을 직접 재현하였고, 각 논문에 대한 답변 검증을 위해 일련의 질의사항들을 엄선했습니다. 이 질의사항들은 주관적인 판단을 최소화하고, 객관적인 재현 여부를 판단할 수 있도록 설계되었습니다. CORE-Bench는 세 단계의 난이도로 제공됩니다. 이 세 가지 단계의 모든 과업은 언어적 능력과 시각적 인지 능력을 모두 요구합니다. 예를 들어, 복잡한 그래프를 해석하거나 미묘한 텍스트 설명을 이해하는 능력 등이 필요합니다. 최고 난이도 버전은 실제 재현 작업과 매우 흡사하며, 이 기준점의 발전이 연구자들에게 실질적으로 유용한 에이전트 개발로 이어지기를 희망합니다. 기본 성능 평가를 위해 저희는 범용 AutoGPT 에이전트를 실험했으며, AutoGPT에 특정 과업에 맞춘 변형을 적용하여 CORE-Agent라 명명했습니다. 예를 들어, 특정 유형의 오류 메시지에 대한 처리 로직을 강화하거나, 특정 파일 형식에 대한 파싱 능력을 개선하는 방식 등이 포함됩니다. 과업에 특화된 버전이 정밀도를 상당히 높였지만, 여전히 개선의 여지가 다분합니다. 현재 AI의 역량을 고려할 때, 22%의 정밀도는 시작점으로서 상당한 잠재력을 시사하며, 향후 AI의 복잡한 과학적 추론 능력 향상을 위한 중요한 이정표가 될 것입니다. 최상위 성능을 보인 에이전트(GPT-4o 기반 CORE-Agent)는 CORE-Bench-Hard에서 22%의 정밀도를 기록했습니다.

**일반성(generality) 재고**

전산적 재현성은 코드 실행 환경을 적절히 구축하고, 코드를 구동하여, 연구 보고서에 명시된 바와 동일한 결과물을 도출하는 과정을 수반합니다. 이 과정에서 셸(shell) 명령어나 여타 도구들을 정확히 활용하는 것은 대규모 언어 모델(LLMs)에게 여전히 어려운 과제입니다. 저희가 AutoGPT와 같은 일반 목적 에이전트들을 평가했을 때, CORE-Bench-Hard에서 10% 미만의 낮은 정밀도에 그리 놀라지 않았습니다. 이는 범용 모델이 특정 도메인의 복잡한 상호작용과 오류 처리에 취약함을 보여줍니다. 그러나 며칠간의 인적 자원 투입을 통해 AutoGPT를 개선하여 CORE-Agent를 개발할 수 있었으며, 이는 최고 난이도에서 정밀도를 두 배 이상 향상시켰습니다. 흥미롭게도, 저희는 완전히 새로운 과업별 에이전트를 처음부터 구축하는 방식도 시도했지만, AutoGPT를 수정하는 것이 훨씬 적은 시간과 노력으로 더 강력한 에이전트를 만들 수 있었습니다. 저희는 이러한 접근법이 실질적으로 유용한 수준으로 작동하는 에이전트들을 탄생시킬 수 있을 것이라고 신중하게 낙관하고 있습니다. 단순한 과업별 변형만으로 CORE-Agent는 AutoGPT의 성능을 뛰어넘을 수 있었습니다. 만약 범용 에이전트를 특정 과업에 맞게 용이하게 변형할 수 있는 이러한 경향이 다른 영역에서도 입증된다면, 우리는 일반성의 개념을 재고해야 할 것입니다. 이러한 '쉬운 적응(easy adaptation)'은 대규모 모델의 미세 조정(fine-tuning)이나 프롬프트 엔지니어링(prompt engineering)을 통해 이미 언어 번역이나 이미지 생성과 같은 다른 분야에서도 관찰되고 있습니다. 이는 AI 개발에서 '인간-개입(human-in-the-loop)' 방식의 중요성을 부각시키며, 인간의 전문성이 범용 모델을 특정 영역에 특화시키는 '스캐폴딩(scaffolding)' 역할을 할 수 있음을 보여줍니다.

일반성이란 대략적으로 동일한 모델이나 에이전트를 별도의 변경 없이 여러 종류의 과업을 처리하는 데 활용할 수 있는 역량을 지칭합니다. 이러한 일반성 개념은 인공 일반 지능(AGI)에 대한 통상적인 인식과 그에 수반되는 기대 및 우려의 핵심을 형성합니다. AGI는 종종 인간 수준의 인지 능력이나 심지어 초지능까지 의미하는 것으로 해석되곤 합니다. 하지만 적어도 경제적 파급 효과의 관점에서 볼 때, 일반성은 오해를 불러일으킬 수 있습니다. 인공지능 안전(AI safety)과 정렬(alignment) 문제 또한 AGI 논의의 중요한 부분입니다. 전문가들이 연간 수백만 시간을 소비하는 전산적 재현성과 같은 과업의 경우, AI 시스템이 즉각적으로(out of the box) 처리하든, 아니면 며칠 또는 심지어 1년의 개발자 노력을 통해 구현되든 관계없이, 이를 자동화할 수 있다면 막대한 파급력을 지닐 것입니다. 예를 들어, 특정 기업이 전문화된 AI 개발에 수백만 달러를 투자하는 대신, 범용 모델을 몇 주간 미세 조정하여 동일한 성과를 낸다면 엄청난 경제적 이득이 발생합니다. 'AI 스네이크 오일'이라는 저서에서 저희는 일반성을 과업 특이성의 반대 개념으로 규정하고, 인공지능(및 컴퓨팅)의 발전사가 점진적으로 일반성을 증대시키려는 노력으로 어떻게 해석될 수 있는지 분석합니다. 일반성을 증진시키는 것은 특정 과업을 수행하는 AI 시스템을 개발하는 데 요구되는 인간의 수고를 경감시키는 것을 의미합니다. 이러한 시각에서 보면, AutoGPT와 같은 체계들은 대다수의 사람들(저희를 포함하여)이 예상했던 것보다 더 범용적일 수 있습니다. 이는 사카나 AI의 '완전 자율'이라는 주장이 일반성에 대한 잘못된 해석에서 비롯될 수 있음을 시사합니다. 하지만 AGI의 정의는 대개 단일 시스템이 즉각적으로(out of the box) 모든 것을 처리할 수 있어야 한다고 역설합니다. 과업별 AI를 구축하는 데 필요한 인적 노력이 시간 경과에 따라 어떻게 변화하는지 체계적으로 추적하는 연구는 아직 미비합니다. AI 개발자들은 그들의 시스템이 가진 역량을 정확하게 전달할 윤리적 책임이 있습니다. 인공지능의 진보를 과대평가하는 일반성에 대한 잘못된 개념을 비판했던 것처럼, 우리는 AI의 진보를 과소평가하는 일반성에 대한 오류 있는 개념 또한 경계해야 합니다. CORE-Bench 논문을 여기에서 읽어보세요.

**추가 자료**

최근 발행된 'AI Agents That Matter'라는 보고서에서 저희는 AI 에이전트 평가 방식의 여러 취약점을 확인했습니다. 예를 들어, 실제 환경 적용 가능성 부족, 장난감 문제(toy problems)에 대한 집중, 그리고 불충분한 견고성 테스트 등이 지적되었습니다. CORE-Bench를 개발하는 과정에서 이러한 약점들이 저희의 벤치마크 설계에 영향을 주었습니다. 저희는 최근 실용적이고 신뢰성 있는 AI 에이전트에 관한 온라인 워크숍을 주최하였고, 이 자리에서 주요 전문가들이 더 나은 에이전트 설계 및 평가 방안에 대한 의견을 나눴습니다. 워크숍 영상은 온라인에서 시청할 수 있습니다.

벤 보긴 외 연구팀은 AI 에이전트가 연구 보고서에 동반되는 저장소(repositories) 내 작업을 설정하고 수행할 수 있는지 측정하기 위해 SUPER 벤치마크를 공개했습니다. 이는 AI 에이전트의 연구 작업 자동화 능력을 측정하는 또 다른 흥미로운 기준점입니다. 이는 CORE-Bench와 여러 측면에서 차이점을 보입니다. CORE-Bench는 과학 전반(컴퓨터 과학, 의학, 사회 과학)의 과업들로 이루어져 있으나, SUPER는 인공지능 분야의 과업들로 구성됩니다. 이러한 학제간 벤치마크의 중요성은 AI가 다양한 과학 분야에 미칠 수 있는 광범위한 영향을 평가하는 데 필수적입니다. CORE-Bench는 시각-언어 및 언어 모델을 모두 활용해야 하며, SUPER(언어 모델, Python)와는 다르게 다수의 프로그래밍 언어(Python 및 R)로 구성되어 있습니다. 이는 CORE-Bench가 더 복잡하고 현실적인 다중 모달 및 다중 언어 환경에서의 AI 에이전트 성능을 평가하는 데 초점을 맞추고 있음을 의미합니다. SUPER의 과업들은 주피터 노트북 접근을 요구합니다. 반면에 CORE-Bench의 과업들은 셸(shell) 접근을 필요로 하며 에이전트가 샌드박스를 자유롭게 변경할 수 있도록 허용합니다. 주피터 노트북 접근은 비교적 통제된 환경을 제공하는 반면, 셸 접근은 에이전트가 시스템 수준에서 더 넓은 범위의 조작을 수행할 수 있게 하여, 실제 연구 환경의 복잡성을 더 잘 반영합니다. 향후 AI 에이전트 벤치마크는 더욱 복잡한 다단계 과학 워크플로우를 통합하고, 실시간 상호작용 및 불확실성 처리 능력을 평가하는 방향으로 발전해야 할 것입니다. 인공지능 연구에서 엄격한 평가를 지속하는 것은 AI의 책임감 있고 효과적인 배포를 보장하기 위해 무엇보다 중요합니다.