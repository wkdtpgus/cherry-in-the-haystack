OpenAI의 최신 모델 출시와 함께, 인공지능(AI) 기술의 실제 적용 가능성에 대한 논의가 활발합니다. 이에 대한 일반적인 반응은 AI 기술이 가져올 변혁적 잠재력에 대한 기대감입니다. AI 시스템의 속성이나 영향에 대한 이해는 기술 발전의 방향을 제시합니다. 그러나 이 기술이 사회에 미치는 실질적인 파급 효과는 여전히 복합적인 문제입니다. 어떤 정의에 기반하든, AI 기술의 윤리적 사용은 중요한 과제입니다. 이는 기업, 개발자, 정책 입안자의 역할에 새로운 요구를 부과합니다. 구체적으로 말하자면, 첨단 AI 시스템이 어떤 합의된 능력 임계값(capability threshold)에 도달하더라도, AI가 산업 전반에 확산되어 생산적인 영향을 실현하려면 많은 보완적인 혁신이 필요할 것입니다. 기술 확산은 단순히 기술 개발 속도를 넘어 인간(및 사회)의 시간 척도(timescales)에 따라 발생합니다. AI 기술과 잠재적 위험에 대한 우려는 종종 능력(capabilities)과 책임(responsibility)을 혼동합니다. 이 둘을 구별하고 나면, AI 개발에 있어 인류가 통제력을 유지하기 불가능해지는 임계점(critical point)이라는 개념을 재고할 수 있습니다. AI 기술 정의의 확산은 기술의 다면성을 보여주는 증상입니다. AI는 예상되는 영향 때문에 중요하지만, AI 시스템 자체의 속성을 기반으로 정의되어야 합니다. 그러나 시스템 속성과 영향 사이의 연결 고리는 미약하며, AI 시스템이 작동하는 환경을 어떻게 설계하느냐에 크게 좌우됩니다. 따라서 특정 AI 시스템이 변혁적인 영향을 미칠지 여부는 출시 후에도 지속적인 평가가 필요합니다. 그러므로 AI 시스템의 진정한 가치는 오직 실제 적용 후 회고적으로(retrospectively)만 의미 있게 파악될 수 있습니다.

**AI 기술 발전에 대한 현실적 관점**
AI 기술 달성은 여러 기업의 핵심 목표입니다. 이러한 기술 개발 목표는 때때로 중요한 이정표로 취급됩니다. 그러나 AI 기술의 발전은 단일한 폭발적 사건이라기보다는 지속적인 진화 과정으로 이해되어야 합니다. 과거의 기술 혁신 사례를 보면, 기술 사용은 때때로 사회적 변화에 기여했습니다. 예를 들어, 인터넷의 등장은 정보 접근성을 혁신했지만, 그 영향이 완전히 실현되기까지는 수십 년이 걸렸습니다. 새로운 AI 모델은 강력하고 다양한 기능을 갖추고 있습니다. 그러나 이러한 능력이 즉각적으로 모든 사회적, 경제적 문제를 해결할 것이라는 기대는 비현실적일 수 있습니다. 이 글에서는 AI 기술의 실제 적용 방식에 대해 논의합니다. 즉, 특별한 의미를 지닌 명확한 능력 임계값(capability threshold)이 없기 때문에 관측 불가능하며, 세계에 즉각적인 영향을 미치지 않을 것이고, 심지어 경제의 장기적인 변혁조차 불확실하다는 점을 이해해야 합니다. AI 기술은 그 자체로 목적이 아니라, 인간의 삶을 개선하고 사회적 가치를 창출하기 위한 도구여야 합니다.

**첨단 AI 모델의 잠재력과 한계**
최신 AI 모델의 핵심 혁신은 웹 검색 및 도구 활용 능력에 있습니다. <sup>1</sup> 이러한 방식으로, AI는 복잡한 인지 작업(cognitive tasks)을 수행하며, 사람과 유사한 방식으로 상호작용할 수 있습니다. 예를 들어, 다단계 추론을 통해 정보를 종합하고, 코드를 생성하며, 다양한 데이터 소스를 활용하는 능력은 인상적입니다. 최신 모델들은 다양한 종류의 작업을 수행하는 범용 에이전트(generalist agent)로서의 잠재력을 보입니다. 그러나 이러한 진보에도 불구하고, AI 시스템은 여전히 내재적인 한계를 가지고 있습니다. 이 중 어느 것도 단일 과학적 돌파구를 필요로 하지 않으며, 지속적인 공학적 개선과 훈련이 중요합니다. 동시에, 근본적인 개선 없이는 기존 아키텍처가 심각한 한계를 부과합니다. 예를 들어, 현재의 AI 시스템은 실시간으로 새로운 기술을 경험으로부터 습득하기보다는, 대규모 데이터셋을 통해 사전 훈련된 지식에 의존하는 경향이 있습니다. 즉석에서 학습하고 적응하는 능력은 여전히 미해결 연구 과제(open research problem)입니다. 많은 AGI 정의들이 공통적으로 가지고 있는 것은 다양한 작업에서 인간을 능가하는 능력에 대한 기대가 커지고 있습니다. 하지만 AI는 특정 영역에서는 초인적인 성능을 보이지만, 상식 추론이나 비정형적인 문제 해결과 같은 영역에서는 어려움을 겪으며, 많은 실제 작업에서는 여전히 심하게 실패할 것입니다. 이러한 간극은 AI의 실제 적용에 있어 중요한 고려 사항입니다. AI 기업의 리더들은 기술 발전에 대한 큰 예측과 약속을 제시합니다. 그들이 가까운 미래의 어떤 시스템을 혁신적이라고 선언할 엄청난 유인이 있으며, 그렇게 하지 않을 경우 잠재적으로 막대한 비용이 발생할 수 있습니다. AI 개발의 리더로 인식되는 것은 시장 점유율과 수익을 개선하고, 인재 접근성을 높이는 데 도움이 될 수 있습니다. 이는 AI 기술의 발전 방향이 기술적 능력뿐만 아니라 시장의 기대와 상업적 유인에 의해서도 크게 영향을 받는다는 것을 시사합니다.

**AI 확산과 경제적 영향의 시간 척도**
AI 기술을 이정표로 취급하고 그 선언을 진지하게 받아들이는 주장은 급격한 경제적 영향을 초래할 수 있다는 것입니다. 그러나 기술 발전은 이러한 변화를 실현하는 데 필요하지만 충분하지 않습니다. 근본적인 기술 발전이 사회 전반에 확산되는 데 수십 년이 걸렸습니다. AI 확산에는 여전히 많은 병목 현상(bottlenecks)이 존재합니다. 유용한 제품 및 애플리케이션 개발, 이러한 제품을 활용할 인력 훈련, AI 사용을 가능하게 하는 조직 변화 구현, 기업의 AI 채택을 촉진하는 법률 및 규범 확립 등이 그것입니다. 과거의 범용 기술과 마찬가지로, 우리는 AI의 경제적 영향이 이러한 확산 과정이 전개됨에 따라 수십 년에 걸쳐 실현될 것으로 예상합니다. 능력의 급격한 증가는 항상 급격한 경제적 영향으로 이어지는 것은 아니며, 미래에도 이러한 경향은 지속될 수 있습니다. AI의 발전은 대부분의 경제적으로 가치 있는 작업에서 인간을 보완하는 시스템으로 정의될 수 있습니다. 만약 AI가 이러한 의미에서 실현된다면, 대규모의 갑작스러운 일자리 대체보다는 인간과 AI의 협업을 통한 생산성 향상으로 이어질 수 있습니다. 인간은 변화하는 기술 환경에 적응하며, 자동화된 작업의 생산 비용이 감소함에 따라 새로운 가치 창출 영역으로 이동할 것입니다. 기술 발전, 제품 개발 및 확산 과정은 계속될 것입니다. 중요한 것은 기술 그 자체가 아니라, 기술이 사회 및 경제 시스템에 어떻게 통합되고 활용되는가입니다.

**AI 기술 경쟁과 세계 질서의 변화**
강대국들은 종종 AI 기술 경쟁(AI arms race)을 벌이고 있으며, 각국이 첨단 AI를 개발하기 위해 노력하고 있다고 묘사됩니다. 특정 국가가 AI 기술을 먼저 구축하는 국가가 결정적인 전략적 우위(strategic advantage)를 가지게 되어, 예측 가능한 미래에 세계 질서에서 지배력을 확보할 것이라는 가설이 있습니다. 이러한 관점은 현실적이지 않을 수 있습니다. AI 모델을 만드는 데 필요한 지식과 모델 능력 자체는 국가 간에 빠르게 확산되는 경향이 있기 때문입니다. 수십만 명의 AI 기술자(technologists)가 있으며, 그들은 정부 연구소보다는 민간 부문에서 일하므로, 그러한 규모에서 비밀을 유지하는 것은 실현 불가능합니다. 기술 발명, 특히 AI 모델 개발은 경쟁 우위(competitive advantage)의 유일한 원천으로 과대평가될 수 있습니다. 우리는 기술 발전이 국가 간에 대략적으로 유사하게 진행될 것으로 예상해야 합니다. 비록 특정 기업이나 국가가 현재 선두에 있지만, 우리는 지속적인 우위를 기대해서는 안 됩니다. 많은 사람들은 기술 능력의 확산 용이성을 제대로 인식하지 못했으며, 종종 이에 놀라움을 금치 못했습니다. 이것이 최근 "AI 민주화(democratization)" 현상으로 이어진 이유입니다. 분석가들은 AI 능력이 얼마나 빨리 확산될 수 있는지 깨닫지 못했고, 그 결과 신생 기업들(특히 오픈 소스 커뮤니티)이 그렇게 빨리 따라잡을 것이라고 예상하지 못했습니다. 몇 달의 기술적 우위는 중요할 수 있지만, 장기적인 관점에서는 확산의 효율성이 더 중요합니다. 강대국 경쟁의 맥락에서 중요한 질문은 어느 나라가 첨단 AI를 먼저 개발하느냐가 아니라, 어느 나라가 기술의 생산적 확산을 더 잘 가능하게 하느냐입니다. 따라서 정책 입안자들은 기술의 건전한 확산을 가능하게 하는 데 집중해야 합니다. 이는 국내외 AI 발명과 혁신을 실제로 활용하여 생산성을 향상시키는 기업과 정부의 효율성을 높이는 것을 의미합니다. 디지털화(Digitization), 클라우드 컴퓨팅(cloud computing) 채택, 인력 훈련 등은 AI 발전의 생산적인 확산을 가능하게 하는 데 필수적입니다. 이것이 진정한 경쟁 우위의 원천입니다.

**AI의 장기적인 경제적 영향과 보완적 혁신**
즉각적인 경제적 영향이 없더라도, AI 기술이 장기적으로 큰 성과를 낼 수 있는 GDP 성장을 가능하게 할 수 있을까요? 아마도 그럴 수 있습니다. 그러나 이것이 왜, 어떻게 일어날지는 전혀 명확하지 않습니다. 역사적으로 이러한 종류의 급격한 성장은 매우 드물게 발생했습니다. 문제는 지속 가능한 성장을 가속화하려면 여러 병목 현상(bottlenecks)을 제거해야 한다는 것입니다. 이는 대부분의 AI 지지자들이 가정하는 것보다 어렵습니다. AI는 부문별로 불균등한 영향을 미칠 가능성이 높으며, 장기적인 성장은 가장 약한 부문에 의해 병목 현상이 발생할 것입니다. 극적인 효과를 주장하는 사람들은 종종 병목 현상이 실제로 무엇인지에 대한 잘못된 정신 모델(mental model)을 가지고 있습니다. 예를 들어, 저렴한 과학 혁신이 진보를 가능하게 할 것이라고 믿고 싶겠지만, 새로운 발견의 생산은 실제로는 과학의 병목 현상이 아닙니다. 더 넓게 보면, 진보는 기술뿐만 아니라 올바른 전제 조건, 즉 보완적인 혁신(complementary innovations)과 문화적, 경제적, 정치적 요인에 달려 있습니다. 우리의 현재 법률, 규범, 제도 및 정치는 기술적 잠재력이 훨씬 적었던 시기에 발전했습니다. 그것들은 이미 더 많은 공공 인프라(public infrastructure)를 구축하는 것과 같은 직접적인 유형의 성장을 위한 기회를 막고 있습니다. 광범위한 인지 자동화(cognitive automation)가 잠재적으로 가져올 수 있는 경제적 이점을 얻으려면, 발생해야 할 구조적 변화의 정도는 헤아릴 수 없을 정도로 더 큽니다. 결론적으로, AI 기술로 인한 장기적인 영향의 범위와 성격은 아직 지켜봐야 하며, 우리의 보완적인 조치(complementary actions)에 달려 있습니다. 장기적인 영향은 AI 시스템 자체의 속성이 아니라, 우리가 사회적으로 어떻게 대응하느냐에 따라 달라집니다.

**AI의 책임감 있는 개발: 권력과 능력의 균형**
AI의 사회적 위험에 대한 논의는 권력(power) — 환경을 수정할 수 있는 능력 — 과 능력(capability) — 지정된 작업을 올바르게 해결할 수 있는 역량 — 을 혼동하는 경우가 많습니다. 능력은 AI 시스템의 본질적인 속성이지만, 권력은 시스템이 작동하는 환경을 우리가 어떻게 설계하느냐의 문제입니다. 인간은 이러한 설계 과정에 대한 주체성(agency)을 가지고 있습니다. 이러한 구별은 종종 간과됩니다. 예를 들어, 강력한 AI의 능력에 대한 설명은 미해결 수학 정리 증명, 훌륭한 소설 작성, 어려운 코드베이스(codebases)를 처음부터 작성하는 것과 같은 기술적 역량에 초점을 맞춥니다. 그러나 AI 시스템이 작동하도록 허용하는 환경의 속성, 즉 인터넷에서 행동하기, 인간에게 지시를 내리거나 받기, 재료 주문하기, 실험 지시하기 등은 AI 시스템에 부여된 권력의 한 예입니다. 이는 AI 시스템이 작동하는 환경에 따라 달라지며, AI 능력이 권력으로 어떻게 전환되는지를 결정합니다. 우리는 AI 능력이 지속적으로 증가할 것으로 예상합니다. 그러나 능력 수준과 관계없이, 우리는 AI가 도구로 남아 인간의 감독 없이 작동할 권력과 자율성(autonomy)을 부여받지 않도록 선택할 수 있습니다. 적절한 감독 없이 AI를 배포하는 것에 반대하는 강력한 비즈니스 유인(incentives)이 있을 것이며, 이러한 유인들은 필요할 때 규제에 의해 뒷받침될 수 있고 또 뒷받침되어야 한다고 주장합니다. 이는 자율주행차(self-driving cars)부터 AI 비서(AI assistants)에 이르는 분야에서 역사적으로 그래왔습니다. 우리는 AI 능력이 특정 "티핑 포인트(tipping point)"에 도달했다고 해서 이 추세가 갑자기 뒤바뀔 것이라고 예상하지 않습니다. AI 윤리와 안전은 기술 발전과 함께 지속적으로 논의되고 구현되어야 할 핵심 가치입니다.

**AI와 초지능: 신화와 현실**
AI 기술을 이정표로 간주하는 또 다른 이유는 시스템이 재귀적으로 자체 개선(recursively self-improve)될 수 있다는 견해입니다. 즉, AI 모델이 훨씬 더 유능해지는 미래 버전의 모델을 훈련하여 "지능 폭발(intelligence explosion)"로 이어질 수 있다는 것입니다. 그 직후, 우리는 초지능 AI(superintelligent AI, 상상할 수 있는 모든 작업에서 인간의 능력을 훨씬 뛰어넘는 AI 시스템)를 얻게 될 것이며, 이는 초지능 AI가 인간의 이익과 얼마나 잘 "정렬(aligned)"되는지에 따라 유토피아(utopia) 또는 디스토피아(dystopia)로 이어질 것입니다. 기술 발전의 관점에서는 이러한 예측을 의심할 만한 몇 가지 이유가 있습니다. 첫째는 AI 방법론에서 임의의 속도 향상이 가능하더라도, 우리는 혁신과 확산은 인간의 속도로 일어날 것이라고 생각한다는 점입니다. 다른 범용 기술과 마찬가지로, AI의 영향은 방법론과 능력이 향상될 때가 아니라, 그러한 개선이 애플리케이션으로 전환되고 경제의 생산적인 부문을 통해 확산될 때 구체화됩니다. 둘째, AI가 연구 수행을 돕는다는 사실이 이 과정이 무한히 가속화될 수 있다는 것을 의미하지는 않습니다. AI는 오늘날 이미 여러 연구 분야의 상당 부분을 자동화하는 데 사용되고 있습니다. 그러나 AI 방법론의 발전에는 여전히 많은 병목 현상이 존재합니다. 예를 들어, 특정 능력을 달성하는 데 필요할 수 있는 데이터 수집 및 실제 상호작용의 사회적 특성, 계산 및 비용 한계, 또는 진정한 돌파구를 가능하게 하는 아이디어는 무시하고 인기 있거나 직관적인 아이디어에만 몰두하는 경향 등이 있습니다. 물론, 재귀적 자체 개선(recursive self-improvement)이 가능하여 AI 방법론의 진보에 무한한 속도 향상으로 이어질 수도 있습니다. 이러한 이유로, 재귀적 자체 개선에 대한 조기 경보 시스템(early warning systems)을 갖추는 것이 중요합니다. 그러나 이는 초지능의 임박한 도래를 의미하지는 않습니다. 우리는 재귀적 자체 개선과는 거리가 멀면서도 강력한 AI 시스템을 가질 수 있으며, 그 반대도 마찬가지입니다.

**AI 정의의 복잡성과 실용적 접근**
AI와 관련 개념에 대한 수많은 정의가 존재합니다. 재스민 선(Jasmine Sun)은 20개 이상의 정의를 유용하게 정리해 놓았는데, 이들은 크게 세 가지 범주로 나뉩니다. 즉, 시스템의 세계에 대한 영향, 내부(internals), 또는 통제된 환경에서의 행동에 기반할 수 있습니다. 우리는 각 정의 방식이 실제 적용에서 결함(fatal flaw)을 가질 수 있음을 보여줄 것입니다. 이는 우리가 이상적으로 원하는 것에 비해 너무 엄격하거나 너무 약한 기준(criteria)으로 이어집니다. OpenAI의 AI 정의는 "대부분의 경제적으로 가치 있는 작업에서 인간을 능가하는 고도로 자율적인 시스템"으로 제시되기도 합니다. 만약 AI가 대부분의 경제적으로 가치 있는 작업에서 [모든] 인간을 능가한다면, 그것은 의심할 여지 없이 영향력이 클 것입니다. 이는 우리가 만드는 보완적인 혁신과 우리가 AI를 우리의 조직과 기관에 통합하기로 선택하는 정도와 적어도 같은 정도로 관련이 있습니다. 요컨대, 영향 기반 정의는 실제 확산 과정의 최종 결과를 예측할 방법을 제공하지 않기 때문에 실용적인 목적에 유용하지 않습니다. 튜링 테스트(Turing test)는 우리가 중요하게 생각하는 인간과 같은 속성을 행동의 대리 지표로 사용하려는 많은 시도 중 가장 잘 알려진 것이지만, 필연적으로 우리는 기대했던 인간과 같은 내부를 가지지 않고도 그러한 테스트를 통과하는 AI 시스템을 구축할 수 있다는 것이 밝혀졌습니다. AI는 여러 면에서 초인적이지만, 다른 면에서는 유아의 세상 이해력이 부족한 "들쭉날쭉함(jaggedness)"을 보입니다. 이러한 AI의 변혁적인 효과는 모든 면에서 완전히 인간과 같아지기(또는 초인적이 되기) 훨씬 전에 느껴질 가능성이 높습니다. 요컨대, 우리는 내부 자체에 관심이 없으므로 이러한 종류의 정의는 제쳐둡니다. 이는 우리에게 세 번째 종류의 정의를 남기는데, 이는 단연코 가장 일반적인 것으로, 행동에 기반하며 벤치마크 성능(benchmark performance)으로 운영화됩니다. 이러한 종류의 정의의 문제는 잘 알려져 있으며, 우리는 이를 반복적으로 논의했습니다. 그것들은 단순히 실제 세계에서 반드시 유용하지 않더라도 벤치마크를 이길 수 있는 AI 시스템을 구축하는 의미에서 언덕 오르기(hill climbing)를 장려할 뿐입니다.

**AI 기술 정의의 실용적 활용과 미래 방향**
기술 정의의 난제에 대한 한 가지 반응은 그것을 경험하면 알게 될 것이라고 주장하는 것입니다. 최근의 AI 모델 출시는 그 반대가 사실임을 보여줍니다. 일부 사람들에게는 능력의 발전이 혁신적인 변화를 나타낸다는 것이 분명합니다. 다른 사람들에게는 개선이 기껏해야 미미하며, 실제 세계에 영향을 미칠 가능성이 낮다고 평가됩니다. 사람들의 다른 직관은 무엇으로 설명될까요? 우리의 추측은 다음과 같습니다. AI 능력은 일반적일 수 있지만, AI를 실제 세계에서 유용하게 만드는 것은 대체로 도메인별(domain-specific) 방식으로 이루어져야 할 것입니다. (최신 모델의 범용 에이전트(generalist agent) 측면은 오해의 소지가 있습니다. 오류 비용이 낮은 생성 작업(generative tasks)만 처리할 수 있으며, 실제 세계에서 독립적으로 작동해야 할 때는 그렇지 않습니다. 예를 들어, 인간에게는 사소해 보이는 작업임에도 불구하고 유용한 여행 예약 AI 에이전트는 아직 출시되지 않았습니다.) 따라서 사람들이 특정 시스템이 "진정한 AI"인지 생각할 때, 그들은 직관적으로 다른 도메인에 대해 생각하고 있으며, 일반적인 능력과 유용한 실제 세계 능력 사이의 간극은 도메인마다 크게 다릅니다. 대부분의 작업을 자동화할 수 있는 유용한 제품을 갖추는 임계값(threshold)을 넘어서는 것은 다른 부문이나 직업에서 매우 다른 시기에 발생할 수 있습니다. AI 기술의 진정한 가치는 다양한 산업 분야에서의 실질적인 문제 해결 능력에 있습니다.

**기업과 정책 입안자들은 장기적인 관점으로 접근해야 합니다.**
AI 기술의 발전은 단일 이정표가 아닙니다. 어떤 회사가 특정 AI 기술을 달성했거나 달성할 예정이라고 선언하는 것은 기업이 어떻게 계획해야 하는지, 어떤 안전 개입(safety interventions)이 필요한지, 또는 정책 입안자들이 어떻게 반응해야 하는지에 대해 직접적인 영향을 미치지는 않습니다. 그렇다면 기업과 정책 입안자들은 어떤 전략을 취해야 할까요? 기업들은 미완성된 AI 제품을 성급하게 채택하는 것을 경계해야 합니다. AI 방법론과 능력의 빠른 발전이 자동으로 더 나은 제품으로 이어지는 것은 아닙니다. 본질적으로 확률적(stochastic)인 모델 위에 제품을 구축하는 것은 어렵습니다. 기업들은 핵심 비즈니스 프로세스(business processes)를 자동화하기 위해 AI를 사용하는 영향을 판단하기 위해 신중한 실험을 수행하면서 AI 제품을 조심스럽게 채택해야 합니다. 특히, 우리는 AI 에이전트가 인간 노동자의 "즉시 대체품(drop-in replacements)"이 되어 워크플로우(workflows)에 자동화를 신중하게 평가하고 통합할 필요성을 어떻게든 우회할 것이라는 생각에 대해 극도로 회의적입니다. AI 제품을 개발하는 기업들은 채택의 장애물(hurdles)을 식별하고 AI를 채택하는 기업들이 원하는 것을 구축하기 위해 해당 도메인에 대한 깊은 이해가 필요합니다. 예를 들어, Cursor와 Windsurf와 같은 AI 기반 코드 편집기(code editors)의 한 가지 핵심 혁신은 프로그래머가 AI가 생성한 텍스트를 다양한 추상화 수준(levels of abstraction)에서 검증할 수 있도록 하는 사용자 인터페이스(user interface)입니다. 다른 산업들은 제품이 해결해야 할 AI 채택에 대한 다른 장애물을 가질 것입니다. 정책 입안자들도 장기적인 관점으로 접근해야 합니다. AI 기술은 단일 이정표가 아니므로, 목표 달성 시점이나 필요한 투자 규모를 명확히 알기 어렵습니다. 그리고 AI 능력을 가속화하는 것은 경제적 이점을 실현하는 데 있어 실제 병목 현상을 해결하는 데 아무런 도움이 되지 않습니다. 국가들은 AI 개발을 늦추기 위해 하드웨어에 대한 수출 통제를 적용했습니다. 수출 통제 지지자들은 이것이 국가 간의 격차를 몇 달 이상 벌리지 않을 것이라고 인정합니다(우리도 동의합니다). 그러나 이것은 첨단 AI 개발의 영향이 급격한 세계에서만 중요합니다. 만약 첨단 AI의 영향이 확산을 통해 실현되고, 확산 과정이 수십 년이 걸린다면, 수십 년의 게임에서 몇 달 앞서는 것은 거의 중요하지 않습니다. 따라서 정책 입안자들은 기술의 건전한 확산을 가능하게 하는 데 집중해야 합니다. AI가 세계에 미치는 영향은 마법의 총알 기술(magic-bullet technology)을 향한 단거리 경주를 통해서가 아니라, 수백만 가지의 지루하고 작은 비즈니스 프로세스(business process) 적응과 정책 조정(policy tweaks)을 통해 실현될 것입니다. 이 에세이 초안에 대한 피드백을 주신 스티브 뉴먼(Steve Newman)과 재스민 선(Jasmine Sun)에게 감사드립니다.

**추가 자료 읽기**
재스민 선(Jasmine Sun)의 최근 에세이는 정신과 내용 면에서 우리의 에세이와 유사합니다. 그녀는 많은 인기 있는 AI 정의를 대조하고, AI가 구체적인 기술적 이정표(technical milestone)라기보다는 기술 커뮤니티의 열망(aspiration)으로 보는 것이 더 낫다고 결론 내립니다. 그녀는 또한 AI 및 기타 관련 개념에 대한 인기 있는 정의들을 정리했습니다. 보르한 빌리-하멜린(Borhane Blili-Hamelin)과 다른 이들은 우리가 AI 연구의 북극성(North star)으로 특정 목표에 집착하는 것을 멈춰야 한다고 주장합니다. 에게 에르딜(Ege Erdil)은 변혁적인 AI 능력에 도달하는 데 수십 년의 시간표(timelines)가 필요하다는 주장을 펼칩니다. 에릭 살바지오(Eryk Salvaggio)는 정책 입안자들이 AI의 임박한 위험에 과도하게 반응하는 것이 위험한 많은 이유를 제시합니다. "AI as Normal Technology"에서 우리는 AI의 미래에 대한 우리의 견해에 대한 지적 기반(intellectual foundation)을 마련했습니다. 이 에세이는 그 안에 담긴 아이디어의 함의를 탐구하는 많은 후속작 중 첫 번째입니다.

---

<sup>1</sup> LLM은 텍스트만 출력할 수 있지만, 최신 모델들은 텍스트 출력을 사용하여 도구와 상호작용하도록 훈련됩니다. 예를 들어, 특정 키워드(예: "use-search")를 출력하여 주어진 쿼리(query)를 온라인에서 검색할 수 있습니다. 분명히 말하자면, 이전 LLM도 도구와 상호작용할 수 있었습니다. 예를 들어, OpenAI의 ChatGPT 플러그인(plugins)은 2년 전 GPT-4와 같은 모델이 도구를 사용하도록 허용했습니다. 최신 모델의 핵심 차이점은 도구를 효과적으로 사용하도록 훈련되었다는 것입니다. 이전 모델은 이 작업을 위해 명시적으로 훈련되지 않은 상태에서 프롬프트(prompts)를 기반으로 도구를 사용했거나, 기껏해야 도구 사용 구문(syntax)을 배웠습니다. 최신 모델들은 검색, 코드 실행 능력, 파일 접근, 이미지 생성 및 추론을 포함하여 ChatGPT 인터페이스의 많은 도구에 접근할 수 있습니다. 전반적으로 최신 모델들은 챗봇(chatbot)이라기보다는 "에이전트(agent)"에 훨씬 더 가깝습니다.

<sup>2</sup> 예를 들어, 이 시스템이 훈련을 마친 후에야 출시된 소프트웨어 라이브러리(software library)를 사용하여 새로운 유형의 코딩 작업을 수행하는 데 사용된다고 가정해 봅시다. 충분한 문서와 지침이 주어진다면, 결국 작업을 올바르게 수행할 수 있을 것입니다. 그러나 재훈련을 통한 모델의 명시적인 업데이트가 없는 한, 이 "경험"은 모델의 가중치(weights)를 변경하지 않을 것이므로, 동일한 작업을 수행해야 하는 다른 사용자는 첫 번째 사용자가 제공했던 것과 동일한 도움을 주어야 할 것입니다.

<sup>3</sup> 우리는 이 글에서 군사 AI(military AI)를 분석하지 않습니다. 이는 중요한 주제이며, 향후 에세이에서 다시 다룰 것입니다.

<sup>4</sup> 새로운 기술의 발명(invention)과 그 기술이 사회 전반에 확산되도록 돕는 혁신(innovations)을 구별하는 것이 중요합니다. 이 단락에서의 논의는 전자에 관한 것입니다. 발명은 새로운 모델의 개발, 아마도 새로운 능력의 동반을 의미합니다. 혁신은 이러한 능력이 생산적으로 사용될 수 있도록 합니다. 더 좋고 유능한 모델은 발명의 예이며, 이러한 모델을 사용하는 제품의 개발은 혁신의 예입니다. 우리는 국가들이 발명에서 길고 지속적인 우위를 유지할 가능성이 높다고 생각하지 않습니다. 그러나 이 섹션에서 나중에 논의하듯이, 발명의 생산적인 사용을 가능하게 하는 조건은 국가마다 크게 다를 수 있습니다.

<sup>5</sup> 아모데이(Amodei)는 AGI를 피하고 자신의 예측에 대해 더 정확하게 표현하기 위해 "강력한 AI(powerful AI)"라는 용어를 사용합니다.