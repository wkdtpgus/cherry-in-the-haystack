OpenAI의 새로운 모델 'o3'의 등장과 함께, 인공지능 분야에서 범용 인공지능(Artificial General Intelligence, AGI)의 도달 여부에 대한 논의가 다시금 뜨겁게 달아오르고 있습니다. 이러한 물음에 대해 대다수 회의적인 시각을 가진 이들은 AGI의 명확한 정의가 부재하다는 점을 지적합니다. 물론 그 지적은 타당하나, 본질적인 쟁점과는 거리가 있습니다. 만약 AGI가 인류에게 그토록 중대한 전환점이라면, 그것이 현실화되었을 때 누구나 명확히 인지할 수 있어야 하는 아닐까요? 본 글에서는 AGI가 특정 시점의 이정표가 아니라는 견해를 제시합니다. AGI는 인공지능 시스템의 특성이나 사회적 파급력 면에서 급격한 변화를 가져오지 않을 것입니다. 어떤 기준으로 보든, 어떤 기업이 AGI를 개발했다고 공표하더라도, 이는 실질적인 사건으로 볼 수 없습니다. 즉, 기업이나 개발자, 정책 결정자, 또는 안전 문제에 있어서 어떠한 즉각적인 변화도 유발하지 않을 것입니다. 좀 더 구체적으로 설명하자면, 아무리 전천후 AI 시스템이 특정 역량 기준치(capability threshold)에 도달한다 하더라도, 인공지능이 사회 전반에 퍼져나가 생산적인 효과를 내기 위해서는 수많은 보완적 혁신이 뒤따라야 합니다. 이러한 기술의 확산은 기술 발전의 속도가 아닌, 인간 사회의 시간 흐름(timescales)에 맞춰 진행됩니다. AGI와 그로 인한 파멸적 위험에 대한 우려는 흔히 시스템의 수행 능력(capabilities)과 실제 영향력(power)을 혼동하는 경향이 있습니다. 이 두 개념을 명확히 구분하고 나면, 인공지능 개발 과정에서 인류가 통제력을 상실하게 될 것이라는 결정적 변곡점(critical point)이라는 생각에서 벗어날 수 있습니다. AGI 정의의 난립은 병이 아니라 그저 현상에 불과합니다. AGI는 기대되는 결과 때문에 중요하지만, 그 정의는 인공지능 시스템 자체의 내재적 특성을 기반으로 해야 합니다. 그러나 시스템의 특성과 실제 파급 효과 사이의 연관성은 미약하며, 인공지능 시스템이 작동하는 환경을 어떻게 설계하는지에 크게 좌우됩니다. 따라서 특정 인공지능 시스템이 혁명적인 변화를 가져올지 여부는 그 시스템이 처음 공개되는 시점에는 아직 미정인 상태입니다. 그렇기에 어떤 AI 시스템이 AGI에 해당한다고 판단하는 것은 오직 과거를 돌아보았을 때(retrospectively)에만 의미 있는 결론이 될 수 있습니다.

인류는 오랫동안 지능의 정점 또는 기술 발전의 궁극적인 목표를 상정하고 이를 향해 나아가는 것을 선호해왔습니다. 이러한 경향은 과학 기술의 복잡한 진보를 단순한 서사로 엮어내려는 인간 본연의 욕구에서 비롯됩니다. AGI에 대한 열띤 논쟁 역시 이러한 심리가 투영된 결과라고 볼 수 있습니다. 즉, AGI는 단순한 기술적 개념을 넘어, 인류의 미래에 대한 희망과 두려움이 뒤섞인 문화적 상징으로 기능하고 있습니다. 언론의 자극적인 헤드라인과 일부 연구자들의 과장된 예측은 이러한 기대를 더욱 부풀리지만, 현실은 언제나 복잡성과 점진적인 변화의 연속입니다. 따라서 우리는 AGI를 둘러싼 과도한 환상이나 맹목적인 공포에서 벗어나, 현재의 AI 기술이 사회에 미치는 실질적인 영향과 그 발전을 위한 현실적인 접근 방식을 모색해야 할 때입니다.

**AGI에 대한 반대 비유로서의 핵무기**
범용 인공지능의 달성은 OpenAI를 비롯한 여러 기술 기업들과 인공지능 연구 커뮤니티의 상당 부분이 추구하는 명시적인 목표입니다. 이는 마치 맨해튼 프로젝트(Manhattan Project)가 핵무기 개발 및 실전 배치를 핵심 과제로 삼았던 것처럼, 중요한 목표로 간주됩니다. 핵무기 개발은 다음 두 가지 측면에서 명확한 이정표였습니다. 첫째, 그 결과는 **관측 가능성(observability)**이 확실했습니다. 핵폭탄이 완성되었는지 여부는 폭발이라는 시각적이고 파괴적인 현상을 통해 의심할 여지 없이 확인되었기 때문입니다. 둘째, **즉각적인 영향(immediate impact)**이 엄청났습니다. 핵무기의 사용은 제2차 세계 대전을 신속하게 종결시키는 데 기여했으며, 동시에 새로운 국제 질서, 즉 지정학적 지형의 장기적인 변동을 초래했습니다. 많은 이들은 AGI 또한 이와 유사한 성격을 띠리라 직관적으로 여깁니다. 즉, AGI는 너무나 강력하고 인간과 유사하여, 그것이 만들어졌을 때 누구든 분명히 알 수 있을 것이며, 즉시 막대한 이점과 위험을 동반할 것이라고 생각하는 것입니다. 예를 들어, 경제의 상당 부분을 자동화하고, 인공지능 연구 자체를 포함한 혁신을 크게 가속화하며, 통제 불가능한 초지능(superintelligence)으로 인해 인류에게 잠재적으로 치명적인 결과를 초래할 수 있다는 주장입니다. 그러나 본 글에서 우리는 AGI가 이와는 정반대의 특성을 가질 것이라고 주장합니다. 즉, 특정 능력이 명확한 의미를 지니는 임계점(capability threshold)이 존재하지 않으므로 **관측하기 어렵고**, 전 세계에 **즉각적인 파급 효과를 미치지 않을 것이며**, 심지어 **경제의 장기적 변혁조차도 불확실**하다는 것입니다. 과거 글에서 우리는 AGI를 핵무기에 비유하는 주장이 일부 사람들이 제안하는 재앙적인 정책 개입에 반대하는 논거로 사용될 수 있다고 역설했습니다. 이러한 비유가 잘못된 예측과 오히려 해로운 정책 권고로 이어지는 것을 보며 우리는 놀라움을 금치 못했습니다.

핵무기 개발과 같은 물리적 성취와 달리, 지능의 본질은 훨씬 추상적이고 다면적입니다. 비행기의 첫 비행이나 달 착륙처럼 명확한 시연을 통해 성공 여부를 판단할 수 있는 기술적 성과와는 달리, 인공지능이 '일반 지능'을 획득했는지 여부를 판단하는 데는 객관적인 기준이 부족합니다. 이는 지능 자체가 인간 사회와 문화적 맥락에 깊이 뿌리내린 개념이기 때문입니다. 즉, 어떤 시스템이 특정 인지 과제에서 인간을 능가한다고 해서 그것이 곧 '일반 지능'을 가졌다고 선언하기는 어렵습니다. 오히려 이는 특정 도메인에서의 높은 숙련도를 의미할 뿐, 다양한 상황에 대한 유연한 적응력이나 추상적 사고 능력과 같은 진정한 일반 지능의 특성을 포괄하지 못합니다. 따라서 AGI가 '구축되었다'는 선언은 단순히 기술적 사실을 넘어, 철학적, 사회적 합의가 필요한 복잡한 문제로 귀결됩니다. 이러한 복잡성으로 인해 AGI의 달성 여부는 결코 폭발처럼 명확하게 관찰될 수 없는 것입니다.

**o3가 AGI라고 생각하는 것이 터무니없는 것은 아니지만, 이는 o3보다 AGI에 대해 더 많은 것을 말해줍니다.**
많은 저명한 인공지능 분석가들은 o3를 일종의 범용 인공지능(AGI)으로 평가했습니다. 타일러 코웬(Tyler Cowen)은 AGI를 보면 즉시 알아볼 수 있다면 자신은 그것을 보았다고 언급했으며, 이든 몰릭(Ethan Mollick)은 o3를 '들쭉날쭉한 AGI'(jagged AGI)라고 표현했습니다. o3가 이러한 열광을 불러일으킨 핵심 요인은 무엇일까요? o3의 근본적인 혁신은 강화 학습(reinforcement learning)을 활용하여 웹을 탐색하고, 추론 과정의 일부로서 다양한 도구들을 활용하는 방식을 학습한다는 점입니다.<sup>1</sup> 이러한 접근 방식을 통해 o3는 대규모 언어 모델(LLM)이 단독으로 처리할 수 있는 것보다 훨씬 더 복잡한 인지 작업(cognitive tasks)을 수행하며, 그 방식 또한 인간과 유사하게 이루어집니다. 예를 들어, 여러 제품을 비교하여 구매하는 사람을 떠올려 보세요. 그들은 몇 가지 제품을 검토한 후, 해당 제품들의 평가를 참고하여 어떤 기능이 중요한지 파악하고, 이 지식을 바탕으로 고려 대상 제품군을 반복적으로 확장하거나 축소할 수 있습니다. o3는 이러한 유형의 작업을 상당히 능숙하게 처리하는 **다재다능한 에이전트(generalist agent)**입니다. 이것이 AGI에 대해 어떤 의미를 가지는지 심사숙고해 봅시다. o3의 구체적인 기술적 한계에 얽매이지 않고, o3와 동일한 아키텍처(architecture)를 가지면서도 훨씬 더 뛰어난 능력을 지닌 미래 시스템을 상상해 볼 수 있습니다. 예를 들어, 이 시스템은 온라인 상태인 한, 아무리 찾기 어려운 정보라도 항상 작업에 적합한 웹페이지와 지식을 찾아낼 수 있습니다. 필요하다면 인터넷에서 코드를 직접 내려받아 실행하여 문제를 해결할 수도 있습니다. 이러한 능력들은 과학적 돌파구를 필요로 하지 않으며, 단지 공학적 개선과 추가적인 훈련만으로도 구현 가능합니다. 하지만 동시에, 과학적 개선 없이는 아키텍처 자체가 심각한 제약을 부과합니다. 예를 들어, 이 미래 시스템은 훈련을 통한 명시적인 업데이트를 통해서만 새로운 기술을 경험으로부터 습득할 수 있습니다. 즉석에서(on the fly) 학습할 수 있는 인공지능 시스템을 구축하는 것은 여전히 **미해결 연구 과제(open research problem)**로 남아 있습니다.<sup>2</sup> 우리의 가상 시스템은 AGI일까요? 논쟁의 여지는 있지만, 많은 AGI 정의들이 다양한 작업에서 인간을 능가하는 능력을 공통적으로 요구한다는 점을 고려하면, 그럴 가능성이 높습니다. 작업의 범위가 얼마나 좁게 정의되고, 각 작업에 대한 비교 대상 인간 집단이 얼마나 넓게 정의되느냐에 따라, 이러한 미래의 o3 유사 모델/에이전트가 특정 AGI 정의를 충족할 확률은 상당히 높습니다. 예를 들어, 대규모 언어 모델 자체는 체스에 기껏해야 보통 수준일지라도, 이 시스템은 체스에서 인간을 초월하는 능력을 발휘할 것입니다. 모델이 도구를 활용하고, 인터넷을 탐색하며, 코드를 내려받아 실행할 수 있다는 점을 기억하십시오. 만약 작업이 체스를 두는 것이라면, 체스 엔진을 내려받아 실행할 것입니다. 이처럼 많은 작업에서 인간 수준 또는 그 이상의 성능을 보이며 일부 AGI 정의를 충족할 수 있음에도 불구하고, 실제 세계의 수많은 복잡한 작업에서는 아마도 심각하게 실패할 것입니다. 그 이유에 대해서는 추후 다시 논의하겠습니다. 이 모든 것이 중요할까요? 매우 중요합니다. 인공지능 기업의 리더들은 수년 내에 AGI를 선보이겠다는 매우 과감한 예측과 약속을 해왔습니다. 그들에게는 가까운 미래의 어떤 시스템을 AGI라고 선언할 엄청난 동기가 있으며, 그렇게 하지 않을 경우 잠재적으로 막대한 비용이 발생할 수 있습니다. 아마도 인공지능 기업의 가치 평가 중 일부는 이러한 약속에 기반하고 있을 것이므로, AGI 선언이 없다면 거품이 터질 수도 있습니다. 인공지능 개발의 선두 주자로 인식되는 것은 시장 점유율과 수익을 증진시키고, 우수 인재 확보에도 도움이 될 수 있습니다. 그렇다면, 기업들이 AGI를 구축했다고 주장할 경우 어떤 결과가 따를까요? 이 에세이의 나머지 부분에서 이를 분석할 것입니다. AI Snake Oil은 AI 과대광고를 폭로하고 새로운 개발에 대한 증거 기반 분석을 게시합니다. 구독하기

여기서 '다재다능한 에이전트'와 '범용 지능' 사이의 미묘하지만 결정적인 차이를 이해하는 것이 중요합니다. o3와 같은 시스템은 다양한 도구를 활용하여 광범위한 특정 과제를 해결하는 데 탁월한 능력을 보일 수 있습니다. 이는 마치 수많은 전문 도구를 능숙하게 다루는 숙련된 장인과 같습니다. 그러나 진정한 의미의 범용 지능은 단순히 도구를 활용하는 것을 넘어, 완전히 새로운 문제 상황에 직면했을 때 기존 지식과 경험을 바탕으로 창의적인 해결책을 찾아내고, 명시적인 재훈련 없이도 새로운 환경에 적응하며 학습하는 능력을 포함합니다. o3의 '들쭉날쭉함'은 바로 이러한 지점, 즉 특정 과제에서는 초인적인 성능을 보이지만, 인간에게는 너무나 당연한 상식적 추론이나 맥락 이해 능력에서는 현저한 한계를 드러내는 데서 기인합니다. 이러한 한계에도 불구하고, AI 시스템이 마치 인간처럼 광범위한 능력을 가진 것처럼 보이게 하는 '성능 연극(performance theater)'은 투자 유치와 대중의 기대를 높이는 데 효과적일 수 있습니다. 그러나 이는 실제 기술의 본질적인 발전과는 별개의 문제입니다. 우리는 겉으로 드러나는 '능숙함'에 현혹되기보다, AI 시스템이 어떻게 지식을 습득하고, 새로운 상황에 대처하며, 궁극적으로 인류에게 어떤 실질적인 가치를 제공할 수 있는지에 대한 심층적인 이해를 추구해야 합니다.

**AGI는 확산에 수십 년이 걸리므로 경제에 충격을 주지 않을 것입니다.**
AGI를 중대한 이정표로 여기고 그 선언을 진지하게 받아들이는 한 가지 주장은, AGI가 '희소성 없는 세상', '돈이라는 개념의 소멸', 또는 '급작스러운 대량 실업'과 같은 긍정적 및 부정적 측면 모두에서 급격한 경제적 파급 효과를 가져올 수 있다는 것입니다. 그러나 인공지능이 경제에 미치는 영향은 해당 기술이 경제 전반에 걸쳐 폭넓게 채택되고 활용될 때에만 현실화됩니다. 기술의 발전은 이러한 영향을 실현하는 데 필수적이지만, 그것만으로는 충분하지 않습니다. 전기, 컴퓨팅, 인터넷과 같은 과거의 범용 기술(general-purpose technologies)의 사례를 보면, 근본적인 기술적 진보가 사회 전반에 확산되어 일상에 스며드는 데는 수십 년의 시간이 소요되었습니다. 산업 혁명(Industrial Revolution)의 놀라운 성과는 높은 연평균 성장률(3% 미만)보다는, 수십 년간 지속된 꾸준한 성장 기간에서 비롯된 것이었습니다. 인공지능의 확산에는 여러 가지 **병목 현상(bottlenecks)**이 존재합니다. 여기에는 유용한 제품 및 애플리케이션 개발, 이러한 제품을 활용할 인력 양성, 인공지능 사용을 가능하게 하는 조직 문화 및 프로세스 변화 구현, 그리고 기업의 인공지능 채택을 촉진하는 법률 및 규범 확립 등이 포함됩니다. 과거의 범용 기술과 마찬가지로, 우리는 인공지능의 경제적 파급 효과가 이러한 확산 과정이 전개됨에 따라 수십 년에 걸쳐 점진적으로 나타날 것으로 예상합니다. "AI as Normal Technology"라는 논문에서 우리는 왜 이러한 상황이 발생할 것이라고 생각하는지에 대한 상세한 논거를 제시했습니다. 능력의 급격한 증대가 급속한 경제적 영향으로 이어진다는 생각은 인공지능의 과거와 현재의 흐름과 완전히 일치하지 않으며, 미래에 이러한 상황이 바뀔 것이라고 예상할 근거도 없습니다. AGI의 한 가지 정의는 '대부분의 경제적으로 가치 있는 작업에서 인간을 능가하는 인공지능 시스템'입니다. 만약 AGI가 이러한 의미에서 실현된다면, 대규모의 갑작스러운 일자리 대체로 이어질 수 있다고 우려할 수 있습니다. 그러나 인간은 끊임없이 변화하는 목표물(moving target)입니다. 확산 과정이 전개되고 자동화된 작업의 생산 비용(따라서 가치)이 감소함에 따라, 인간은 적응하여 아직 자동화되지 않은 작업으로 이동할 것입니다. 기술 발전, 제품 개발 및 확산 과정은 계속될 것입니다.

인간 노동력은 정체된 존재가 아니라 환경 변화에 따라 끊임없이 진화하는 유기체와 같습니다. 역사적으로 새로운 기술이 등장할 때마다 특정 직업군이 사라지기도 했지만, 동시에 전혀 예상치 못했던 새로운 형태의 직업과 산업이 탄생했습니다. 예를 들어, 인터넷의 등장은 여행사 직원이나 비디오 대여점 직원의 역할을 축소시켰지만, 웹 개발자, 디지털 마케터, 소셜 미디어 전문가와 같은 수백만 개의 새로운 일자리를 창출했습니다. 이러한 변화는 단지 기존 업무의 자동화를 넘어, 인간의 창의성, 공감 능력, 비판적 사고, 그리고 복잡한 사회적 상호작용이 필요한 영역으로 노동의 초점이 이동함을 의미합니다. AGI가 일부 인지적 작업을 자동화할 수 있겠지만, 이는 인간이 더 고차원적인 문제 해결, 혁신, 그리고 타인과의 협력에 집중할 수 있는 기회를 제공할 수 있습니다. 따라서 우리는 자동화가 가져올 변화에 대한 막연한 두려움보다는, 인간 고유의 역량을 강화하고 새로운 가치를 창출할 수 있는 방향으로 교육 시스템과 사회 구조를 재편하는 데 집중해야 합니다. 이는 단순히 기술적 능력을 키우는 것을 넘어, 유연한 사고와 학습 능력을 함양하는 것을 포함합니다.

**AGI는 세계 질서의 급격한 변화로 이어지지 않을 것입니다.**
미국과 중국은 종종 인공지능 군비 경쟁(AI arms race)을 벌이고 있으며, 각국이 범용 인공지능(AGI)을 구축하기 위해 치열하게 경쟁하고 있다고 묘사됩니다. 이러한 서사에는 AGI를 먼저 개발하는 국가가 결정적인 전략적 우위(strategic advantage)를 확보하여, 예측 가능한 미래에 세계 질서에서 지배적인 위치를 차지할 것이라는 가정이 깔려 있습니다.<sup>3</sup> 그러나 이러한 주장은 설득력이 떨어집니다. 인공지능 모델을 만드는 데 필요한 지식과 모델 자체의 역량은 국가 간에 매우 빠르게 확산되는 경향이 있기 때문입니다. 수십만 명에 달하는 인공지능 기술자들(technologists)이 있으며, 이들은 대부분 정부 연구소보다는 민간 부문에서 활동하므로, 그러한 규모에서 기술 비밀을 유지하는 것은 현실적으로 불가능합니다. 발명, 즉 이 경우 인공지능 모델의 개발은 경쟁 우위(competitive advantage)의 원천으로서 과대평가되어 있습니다. 우리는 기술 발전이 국가 간에 대략적으로 보조를 맞출 것으로 예상해야 합니다. 비록 미국 기업들이 현재 선두에 있지만, 우리는 이러한 우위가 영구적으로 지속될 것이라고 기대해서는 안 됩니다.<sup>4</sup> 많은 사람들은 기술 능력의 확산 용이성을 제대로 인식하지 못했으며(아마도 핵무기 정신 모델(mental model) 때문일 것입니다), 이에 놀라움을 금치 못했습니다. 이것이 올해 초 "딥시크 모멘트(DeepSeek moment)"로 이어진 이유입니다. 분석가들은 인공지능 능력이 얼마나 빨리 확산될 수 있는지 깨닫지 못했고, 그 결과 신생 기업들(특히 중국 기업들)이 그렇게 빨리 따라잡을 것이라고 예상하지 못했습니다. 일부 사람들은 몇 달의 우위조차 중요할 것이라고 주장합니다. 우리는 이에 동의하지 않습니다. 강대국 경쟁의 맥락에서 중요한 질문은 어느 나라가 AGI를 먼저 구축하느냐가 아니라, **어느 나라가 기술 확산을 더 잘 촉진하느냐**입니다. 제프리 딩(Jeffrey Ding)이 지적했듯이, 국내외 인공지능 발명과 혁신을 실제로 활용하여 생산성을 향상시키는 기업과 정부의 효율성은 범용 기술의 경제적 영향을 결정하는 데 훨씬 더 중요합니다. 중국 인공지능 기업들은 모델과 능력 면에서 선도적인 미국 기업들보다 기껏해야 6-12개월 뒤처져 있지만, 중국은 확산을 가능하게 할 수 있는 몇 가지 핵심 지표, 즉 디지털화(Digitization), 클라우드 컴퓨팅(cloud computing) 채택, 인력 훈련 면에서 미국에 크게 뒤떨어져 있습니다. 이 모든 것은 산업 전반에 걸쳐 인공지능 발전의 생산적인 확산을 가능하게 하는 데 필수적입니다. 이것이 미국의 진정한 경쟁 우위의 원천입니다. 물론, 이러한 상황은 향후 몇 년 안에 바뀔 수 있습니다. 그러나 그렇게 된다면, 그것은 AGI 개발보다는 확산을 촉진하기 위한 정책 변화의 결과일 것입니다. 그리고 정책을 얼마나 빨리 바꾸든, 국가들이 하룻밤 사이에 이룰 수 있는 일이 아닙니다. 확산은 일반적으로 수십 년에 걸쳐 전개됩니다. 이 모든 것이 정책 입안자들이 안주해야 한다는 의미는 아닙니다. 그러나 이는 AGI에 집착하기보다는 기존 인공지능을 포함하여 생산적이고 안전한 확산을 가능하게 하는 데 집중해야 한다는 것을 의미합니다.

인공지능 시대를 맞아 세계 질서의 핵심은 더 이상 단순한 기술적 선점 경쟁에 있지 않습니다. 진정한 리더십은 기술적 우위뿐만 아니라, 인공지능의 윤리적이고 책임감 있는 개발 및 활용을 위한 국제적 거버넌스(governance)와 협력 체계를 구축하는 능력에서 나옵니다. 인공지능 기술이 국경을 넘어 빠르게 전파되는 현실 속에서, 특정 국가가 AGI를 독점하려는 시도는 무의미할 뿐만 아니라, 오히려 전 세계적인 불안정과 불신을 야기할 수 있습니다. 대신, 각국은 인공지능의 잠재력을 최대한 발휘하면서도 오용과 남용을 방지하기 위한 공유된 표준과 규범을 마련하는 데 집중해야 합니다. 이는 기술 발전의 속도 조절보다는, 기술이 사회에 미치는 영향을 관리하고 긍정적인 방향으로 유도하는 '소프트 파워(soft power)'의 중요성을 부각시킵니다. 예를 들어, 데이터 프라이버시, 알고리즘 편향성, 인공지능의 투명성에 대한 국제적 합의를 이끌어내는 국가가 장기적으로 인공지능 시대의 리더십을 확보할 것입니다. 이러한 접근 방식은 개별 국가의 'AGI 쟁취'라는 단기적 목표를 넘어, 인류 전체의 번영과 안정을 위한 지속 가능한 인공지능 생태계를 조성하는 데 기여할 것입니다.

**AGI의 장기적인 경제적 영향은 불확실합니다.**
즉각적인 경제적 파급 효과가 없다고 하더라도, 범용 인공지능(AGI)이 예를 들어 수십 년에 걸쳐 연간 10%의 GDP 성장률을 가능하게 할 수 있을까요? 아마도 그럴 수는 있을 것입니다. 그러나 이것이 왜, 그리고 어떻게 일어날지는 전혀 명확하지 않습니다. 역사적으로 이러한 종류의 급격한 성장 가속화는 매우 드물게 발생했습니다. 산업 혁명(industrial revolution)은 이러한 효과를 가져왔지만, GDP에 거의 영향을 미치지 않은 인터넷은 그렇지 않았습니다. GDP가 측정하기에 적절한 것이 아니라고 생각하더라도, GDP 성장률의 질적 변화는 여러분이 중요하게 생각하는 경제의 근본적인 변화에 대한 좋은 대리 지표(proxy)입니다. 문제는 성장을 가속화하려면 진보를 가로막는 **병목 현상(bottlenecks)**을 해소해야 한다는 것입니다. 이는 대다수 인공지능 지지자들이 가정하는 것보다 훨씬 어려운 일입니다. 인공지능은 부문별로 불균등한 영향을 미칠 가능성이 높으며, 장기적인 성장은 가장 취약한 부문에 의해 제약을 받을 것입니다. 극적인 효과를 주장하는 사람들은 종종 병목 현상이 실제로 무엇인지에 대한 잘못된 심적 모델(mental model)을 가지고 있습니다. 예를 들어, 저렴한 과학 혁신이 진보를 가능하게 할 것이라고 믿고 싶겠지만, 새로운 발견의 생산은 실제로는 과학의 병목 현상이 아닙니다. 더 넓게 보면, 진보는 기술뿐만 아니라 올바른 전제 조건, 즉 보완적인 혁신(complementary innovations)과 문화적, 경제적, 정치적 요인에 달려 있습니다. 산업 혁명을 일으키는 데 필요한 것이 증기 기관(steam power)의 발명뿐이었다면, 로마 제국(Roman Empire)이 그것을 해냈을 것입니다. 우리의 현재 법률, 규범, 제도 및 정치는 기술적 잠재력이 훨씬 적었던 시기에 발전했습니다. 그것들은 이미 더 많은 공공 인프라(public infrastructure)를 구축하는 것과 같은 직접적인 유형의 성장을 위한 기회를 막고 있습니다. 광범위한 인지 자동화(cognitive automation)가 잠재적으로 가져올 수 있는 경제적 이점을 얻으려면, 발생해야 할 구조적 변화의 정도는 헤아릴 수 없을 정도로 더 큽니다. 결론적으로, AGI로 인한 장기적인 영향의 범위와 성격은 아직 지켜봐야 하며, 우리가 어떤 보완적인 조치(complementary actions)를 취하느냐에 달려 있습니다. 장기적인 영향은 AGI 자체의 내재적 속성이 아닙니다.

인공지능이 광범위한 작업을 자동화함에 따라, 우리는 '가치 역설(value paradox)'에 직면할 수도 있습니다. 즉, 인공지능이 너무나 효율적으로 수행하는 작업들은 그 생산 비용이 거의 제로에 가까워지면서, 역설적으로 시장에서의 가치 또한 급격히 하락할 수 있다는 것입니다. 반면, 인간만이 제공할 수 있는 고유한 가치, 예를 들어 공감과 정서적 교류가 필요한 돌봄 서비스, 예술적 창작, 복잡한 윤리적 딜레마 해결, 또는 인간 간의 신뢰를 기반으로 하는 협업 등은 상대적으로 그 가치가 더욱 상승할 것입니다. 이러한 변화는 단순히 생산성 증대를 넘어, 사회 전체의 가치 평가 체계와 경제 구조를 근본적으로 재편할 수 있습니다. 예를 들어, 인공지능이 수많은 법률 문서를 분석하고 초안을 작성할 수 있게 되더라도, 고도로 복잡한 소송에서 인간 변호사의 전략적 판단과 설득력 있는 변론은 여전히 대체 불가능한 가치를 지닐 것입니다. 따라서 AGI의 장기적인 경제적 영향은 단순히 자동화의 범위를 넘어, 인간이 어떤 역할을 재정의하고, 어떤 종류의 활동에 가치를 부여하며, 사회적 자본을 어떻게 재분배할지에 따라 결정될 것입니다. 이는 기술 자체의 성능만큼이나, 사회적 합의와 정책적 선택이 중요함을 시사합니다.

**AGI의 정렬 불량(misalignment) 위험은 권력과 능력을 혼동합니다.**
다른 한편으로, 범용 인공지능(AGI)은 인공지능의 사회적 위험에 대한 전환점이 될 수 있다는 주장이 있습니다. AGI가 통제 불능 상태를 초래하고, 막대한 사회적 해악, 심지어 인류 멸종으로 이어질 수 있을까요? AGI 위험에 대한 논의는 **권력(power)** — 즉, 환경을 수정하고 영향을 미칠 수 있는 능력 — 과 **능력(capability)** — 즉, 지정된 작업을 올바르게 해결할 수 있는 역량 — 을 혼동하는 경향이 있습니다. 능력은 인공지능 시스템의 본질적인 속성이지만, 권력은 인공지능 시스템이 작동하는 환경을 우리가 어떻게 설계하느냐의 문제입니다. 그리고 인간은 이러한 설계 과정에서 주체성(agency)을 가지고 있습니다. 이러한 구별은 종종 간과됩니다. 다리오 아모데이(Dario Amodei)의 "강력한 AI(powerful AI)" 정의를 생각해 봅시다.<sup>5</sup> 그는 "...미해결 수학 정리 증명, 매우 훌륭한 소설 작성, 어려운 코드베이스(codebases)를 처음부터 작성"하는 것과 같은 강력한 AI의 능력에 대한 설명으로 시작합니다. 이 기준은 인공지능 능력의 예시이며, 우리는 이를 인공지능 시스템 수준에서 논의할 수 있습니다. 그러나 그는 이어서 인공지능 시스템이 작동하도록 허용하는 환경의 속성을 설명하는데, 여기에는 "...인터넷에서 행동하기, 인간에게 지시를 내리거나 받기, 재료 주문하기, 실험 지시하기, 비디오 시청하기, 비디오 만들기 등"이 포함됩니다. 이것은 인공지능 시스템에 부여된 **권력**의 예시입니다. 이는 인공지능 시스템이 작동하는 환경에 따라 달라지며, 인공지능 능력이 권력으로 어떻게 전환되는지를 결정합니다. 우리는 인공지능 능력이 계속 증가할 것으로 예상합니다. 그러나 능력 수준과 관계없이, 우리는 인공지능이 도구로 남아 인간의 감독 없이 작동할 권력과 자율성(autonomy)을 부여받지 않도록 선택할 수 있습니다. "AI as Normal Technology" 에세이에서 우리는 기업 간의 군비 경쟁, 권력 추구, 초인적인 설득, 기만적인 정렬(deceptive alignment) 등 이에 대한 모든 일반적인 반론을 다루었습니다. 우리는 이 논문에서 적절한 감독 없이 인공지능을 배포하는 것에 반대하는 강력한 사업적 유인(incentives)이 있을 것이며, 이러한 유인들은 필요할 때 규제에 의해 뒷받침될 수 있고 또 뒷받침되어야 한다고 주장합니다. 이는 자율주행차(self-driving cars)부터 인공지능 비서(AI assistants)에 이르는 분야에서 역사적으로 그래왔습니다. 우리는 인공지능 능력이 우리가 임의로 AGI로 지정하는 추정된 티핑 포인트(tipping point)에 도달했다고 해서 이 추세가 갑자기 뒤바뀔 것이라고 예상하지 않습니다.

인공지능 시스템에 대한 통제는 단일 지점에서 이루어지는 것이 아니라, 다층적인 제어 메커니즘을 통해 구현됩니다. 현재 개발되고 있는 대부분의 고급 AI 시스템은 인간의 감독과 개입을 필수 요소로 포함하는 '인간-개입(human-in-the-loop)' 설계를 지향합니다. 이는 AI가 최종 결정을 내리기 전에 인간의 승인을 받거나, 특정 임계값을 초과하는 상황에서 인간에게 통제권을 이양하는 방식 등을 포함합니다. '자율성(autonomy)'이라는 개념 또한 절대적인 자유를 의미하는 것이 아니라, 명확히 정의된 경계와 감독 하에서 작동하는 것을 의미합니다. 예를 들어, 자율주행차는 운전자의 개입 없이 주행하지만, 긴급 상황 시 운전자가 즉시 제어권을 회수할 수 있도록 설계됩니다. 이는 '점진적 자율성(graduated autonomy)'의 원칙이 인공지능 시스템에도 적용될 수 있음을 보여줍니다. 즉, AI의 능력이 향상됨에 따라 더 많은 자율성을 부여할 수 있지만, 항상 인간의 궁극적인 책임과 감독 하에 있어야 한다는 것입니다. 이러한 설계 원칙은 인공지능이 아무리 강력해지더라도, 그 영향력이 우리의 통제 범위를 벗어나지 않도록 하는 핵심적인 안전 장치 역할을 합니다. 따라서 정렬 불량의 위험은 기술 자체의 본질적 결함보다는, 인간이 AI 시스템을 어떻게 설계하고, 배포하며, 감독할 것인지에 대한 선택의 문제로 귀결됩니다.

**AGI는 임박한 초지능을 의미하지 않습니다.**
AGI를 이정표로 간주하는 또 다른 이유는, AGI가 구축된 직후 인공지능 시스템이 재귀적으로 자체 개선(recursively self-improve)될 수 있다는 견해 때문입니다. 즉, AGI가 훨씬 더 유능해지는 미래 버전의 모델을 스스로 훈련하여 "지능 폭발(intelligence explosion)"로 이어질 수 있다는 것입니다. 그 직후, 우리는 초지능 인공지능(superintelligent AI, 상상할 수 있는 모든 작업에서 인간의 능력을 훨씬 뛰어넘는 인공지능 시스템)을 얻게 될 것이며, 이는 초지능 인공지능이 인간의 이익과 얼마나 잘 "정렬(aligned)"되는지에 따라 유토피아(utopia) 또는 디스토피아(dystopia)로 이어질 것이라는 시나리오입니다. 일반적인 기술 관점에서는 이러한 서사에 의문을 제기할 두 가지 큰 이유가 있습니다. 첫째는 인공지능 방법론에서 임의의 속도 향상이 가능하다고 하더라도, 우리는 혁신과 확산은 인간의 속도로 일어날 것이라고 생각한다는 점입니다. 다른 범용 기술과 마찬가지로, 인공지능의 영향은 방법론과 능력이 향상될 때가 아니라, 그러한 개선이 애플리케이션으로 전환되고 경제의 생산적인 부문을 통해 확산될 때 구체화됩니다. 둘째, 인공지능이 인공지능 연구 수행을 돕는다는 사실이 이 과정이 임의로 가속화될 수 있다는 것을 의미하지는 않습니다. 인공지능은 오늘날 이미 인공지능 연구의 상당 부분을 자동화하는 데 사용되고 있습니다. 그러나 인공지능 방법론의 발전에는 많은 **병목 현상**이 있습니다. 예를 들어, 특정 능력을 달성하는 데 필요할 수 있는 데이터 수집 및 실제 상호작용의 사회적 특성, 계산 및 비용 한계, 또는 진정한 돌파구를 가능하게 하는 아이디어는 무시하고 인기 있거나 직관적인 아이디어에만 몰두하는 경향 등이 있습니다. 우리는 이것에 대해 틀릴 수도 있으며, 재귀적 자체 개선(recursive self-improvement)이 가능하여 인공지능 방법론의 진보에 무한한 속도 향상으로 이어질 수도 있습니다. 그리고 이는 광범위한 확산이 더 느리더라도, 영향에 있어 일부 불연속성을 포함하여 몇 가지 흥미로운 함의를 가질 수 있습니다. 이러한 이유로, 재귀적 자체 개선에 대한 조기 경보 시스템(early warning systems)을 갖추는 것이 중요합니다. 그러나 이것은 AGI 정의에 포착되지 않습니다. 우리는 재귀적 자체 개선과는 거리가 멀면서도 AGI를 가질 수 있으며, 그 반대도 마찬가지입니다.

지능의 발전은 단순히 연산 속도의 향상만으로 이루어지지 않습니다. 오히려 개념적 돌파구(conceptual breakthrough), 즉 기존의 틀을 깨는 새로운 아이디어와 통찰력이 결정적인 역할을 합니다. 인공지능은 방대한 데이터를 처리하고 기존 알고리즘을 최적화하는 데 탁월한 능력을 발휘할 수 있지만, 이러한 최적화는 현재의 개념적 한계 내에서 이루어집니다. 진정한 지능 폭발(intelligence explosion)은 단순한 계산 능력의 증대가 아니라, 인류가 아직 상상하지 못한 새로운 패러다임을 스스로 창출해내는 능력을 요구합니다. 이는 마치 자동차가 아무리 빠르게 달릴 수 있어도, 스스로 비행기라는 개념을 발명할 수 없는 것과 유사합니다. 현재의 인공지능 아키텍처는 인간이 부여한 프레임워크 내에서 작동하며, 이러한 프레임워크 자체를 근본적으로 재구성하는 것은 여전히 인간의 창의성과 직관이 필요한 영역입니다. 또한, '지능'이라는 것이 유한한 자원 내에서 무한히 증폭될 수 있는 것인지에 대한 근본적인 의문도 존재합니다. 생물학적 지능이 진화 과정에서 수많은 제약과 트레이드오프(trade-off)를 겪었듯이, 인공지능 또한 무한한 자기 개선 과정에서 예상치 못한 한계에 부딪힐 수 있습니다. 따라서 '초지능'으로의 급격한 전환은 단순한 기술적 예측이라기보다는, 지능의 본질과 그 한계에 대한 더 깊은 철학적 질문을 내포합니다.

**우리는 AGI가 언제 구축되었는지 알 수 없을 것입니다.**
범용 인공지능(AGI) 및 관련 개념에 대한 수많은 정의가 존재합니다. 재스민 선(Jasmine Sun)은 20개 이상의 정의를 유용하게 분류했는데, 이들은 크게 세 가지 범주, 즉 시스템의 **세계에 대한 영향**, **내부 구조(internals)**, 또는 **통제된 환경에서의 행동**에 기반하고 있습니다. 우리는 각 정의 방식이 치명적인 결함(fatal flaw)을 가지고 있음을 입증할 것입니다. 이는 우리가 이상적으로 바라는 바에 비해 너무 엄격하거나 너무 느슨한 기준(criteria)으로 귀결됩니다. 이러한 간극을 이해하는 것은 사람들이 AGI가 어떤 모습일지에 대해 왜 서로 다른 직관을 가지는지, 그리고 "보면 알게 될 것"이라는 기준이 왜 실패했고 앞으로도 계속 실패할 것인지를 보여줍니다. OpenAI의 2018년 AGI 정의는 "대부분의 경제적으로 가치 있는 작업에서 인간을 능가하는 고도로 자율적인 시스템"이었습니다. 우리의 관점, 즉 인공지능의 사회적 파급 효과에 대한 우리의 관심사에서 볼 때, 이 정의는 잠재적으로 매우 유용합니다. 만약 인공지능이 대부분의 경제적으로 가치 있는 작업에서 [모든] 인간을 능가한다면, 그것은 의심할 여지 없이 큰 영향력을 가질 것입니다. 그러나 분명히 말하자면, 이것은 인공지능 시스템 자체의 속성이 아닙니다. 이것은 **세상의 상태(state of the world)**의 속성입니다. 이는 우리가 만들어내는 보완적인 혁신과 우리가 인공지능을 우리의 조직과 기관에 통합하기로 선택하는 정도와 적어도 같은 정도로 관련이 있습니다. 실험실에서 인공지능 시스템을 고립시켜 테스트하고 그것이 사람들의 직무에서 사람들을 능가하는지 묻는 것은 터무니없는 일일 것입니다. 그것은 **범주 오류(category error)**입니다. 예를 들어, 인공지능이 (자율적으로) 의료 연구원을 능가할 수 있는지 여부는 우리가 집단적으로 인공지능 시스템이 사람들에게 대규모 의료 실험을 수행하도록 허용할지 여부에 부분적으로 달려 있습니다. 우리는 그렇게 해서는 안 되며 그렇게 하지 않을 것입니다. 이는 시스템의 능력과 관계없이 의료 연구원의 기능을 수행할 수 없다는 것을 의미합니다. 이것은 극단적인 예일 수 있지만, 거의 모든 직업에서 유사한 병목 현상이 발생합니다. 더 나쁜 것은, 인공지능을 모든 곳에 확산시키지 않는 한, 우리는 그 시스템이 이론적으로 실제 세계에서 작업을 자동화할 수 있는지조차 알지 못할 것이라는 점입니다. 우리는 세상의 복잡하고 혼란스러운 모습을 충분히 설득력 있게 모의 실험(simulacra)할 수 없을 것입니다. 요컨대, 영향 기반 정의는 고통스러울 정도로 느린 확산 과정의 최종 결과를 예측할 방법을 제공하지 않기 때문에 실용적인 목적에 유용하지 않습니다. 영향에 관심이 있는 우리와 같은 연구자들과는 대조적으로, 많은 연구자들은 **내부 구조(internals)**의 의미에서 인간과 같은 인공지능에 관심이 있습니다. 즉, 시스템이 세상을 인과적으로(causally) 진정으로 이해하는지, 우리처럼 추론하고, 계획하고, 새로운 기술을 습득할 수 있는지 등입니다. 이러한 AGI의 의미는 인공지능 내부를 관찰하고 특성화하는 어려움 때문에 운영화(operationalize)하기가 매우 어려웠습니다. 튜링 테스트(Turing test)는 우리가 중요하게 생각하는 인간과 같은 속성을 행동의 대리 지표로 사용하려는 많은 시도 중 가장 잘 알려진 것이지만, 필연적으로 우리는 기대했던 인간과 같은 내부를 가지지 않고도 그러한 테스트를 통과하는 인공지능 시스템을 구축할 수 있다는 것이 밝혀졌습니다. 더욱이, 인공지능의 들쭉날쭉함(jaggedness) 때문에 — 여러 면에서 초인적이지만, 다른 면에서는 유아의 세상 이해력이 부족한 — 인공지능의 변혁적인 효과는 모든 면에서 완전히 인간과 같아지기(또는 초인적이 되기) 훨씬 전에 느껴질 가능성이 높습니다. 요컨대, 우리는 내부 자체에 관심이 없으므로 이러한 종류의 정의는 제쳐둡니다. 이는 우리에게 세 번째 종류의 정의를 남기는데, 이는 단연코 가장 일반적인 것으로, **행동에 기반하며 벤치마크 성능(benchmark performance)으로 운영화**됩니다. 예를 들어, "인간-기계 지능 동등성(human-machine intelligence parity)"에 대한 메타큘러스(Metaculus) 질문은 수학, 물리학, 컴퓨터 과학 시험 문제의 성능으로 정의됩니다. 이러한 종류의 정의의 문제는 잘 알려져 있으며, 우리는 이를 반복적으로 논의했습니다. 그것들은 단순히 실제 세계에서 반드시 유용하지 않더라도 벤치마크를 이길 수 있는 인공지능 시스템을 구축하는 의미에서 언덕 오르기(hill climbing)를 장려할 뿐입니다.

AGI에 대한 정의는 마치 '움직이는 골대(moving goalpost)'와 같습니다. 인공지능이 특정 인간 수준의 능력을 달성할 때마다, '진정한 지능' 또는 'AGI'의 기준은 더욱 까다로운 영역으로 이동하는 경향이 있습니다. 예를 들어, 체스나 바둑에서 인간 챔피언을 이겼을 때, 사람들은 "그것은 단지 계산일 뿐, 진정한 지능은 아니다"라고 말합니다. 언어 모델이 인간처럼 대화할 수 있게 되자, "그것은 단지 패턴 인식일 뿐, 이해는 아니다"라고 주장합니다. 이러한 현상은 AGI가 순전히 기술적인 이정표라기보다는, 인간이 기술 발전과 관련하여 자신들의 지적 우월성을 유지하려는 심리적 방어 기제와 사회적 합의의 산물임을 시사합니다. 또한, 우리는 개별 인공지능 시스템의 지능을 평가하는 데 집중하지만, 미래의 AGI는 단일하고 통합된 시스템이라기보다, 수많은 특화된 인공지능(narrow AI)들이 복잡하게 상호작용하며 발현되는 '시스템적 지능(systemic intelligence)'의 형태로 나타날 수도 있습니다. 이는 개별 구성 요소의 성능만으로는 전체 시스템의 지능을 예측하기 어렵게 만들며, AGI의 존재를 더욱 모호하게 합니다. 따라서 AGI를 선언하는 것은 기술적 성취의 문제라기보다, 사회적, 문화적, 심지어 정치적 선언에 가까울 수 있습니다.

**세 가지 AGI 정의 방식의 장단점**
정의의 난제에 대한 한 가지 반응은 "AGI를 보면 알게 될 것"이라고 주장하는 것입니다. o3의 출시는 그 반대가 사실임을 보여줍니다. 일부 사람들에게는 능력의 발전이 AGI라고 부를 만한 단계적 변화(step change)를 나타낸다는 것이 분명합니다. 다른 사람들에게는 개선이 기껏해야 미미하며, 실제 세계에 영향을 미칠 가능성이 낮습니다. 사람들의 다른 직관은 무엇으로 설명될까요? 우리의 추측은 다음과 같습니다. 인공지능 능력은 일반적일 수 있지만, 인공지능을 실제 세계에서 유용하게 만드는 것은 대체로 **도메인별(domain-specific)** 방식으로 이루어져야 할 것입니다. (o3의 범용 에이전트(generalist agent) 측면은 오해의 소지가 있습니다. 오류 비용이 낮은 생성 작업(generative tasks)만 처리할 수 있으며, 실제 세계에서 독립적으로 작동해야 할 때는 그렇지 않습니다. 예를 들어, 인간에게는 사소해 보이는 작업임에도 불구하고 유용한 여행 예약 인공지능 에이전트는 아직 출시되지 않았습니다.) 따라서 사람들이 o3 또는 다른 어떤 시스템이 AGI(에 가깝)인지 생각할 때, 그들은 직관적으로 다른 도메인에 대해 생각하고 있으며, 일반적인 능력과 유용한 실제 세계 능력 사이의 간극은 도메인마다 크게 다릅니다. 대부분의 작업을 자동화할 수 있는 유용한 제품을 갖추는 임계값(threshold)을 넘어서는 것은 다른 부문이나 직업에서 매우 다른 시기에 발생할 수 있습니다.

인공지능 시스템이 실제 세계에서 효과적으로 작동하려면, 단순한 정보 처리 능력 외에도 **상식(common sense)**과 **체화된 지능(embodied intelligence)**이 필수적입니다. 현재의 인공지능 모델들은 방대한 텍스트 데이터로부터 통계적 패턴을 학습하지만, 인간이 일상생활에서 당연하게 여기는 물리적 세계의 작동 원리나 사회적 상호작용의 미묘한 규칙에 대한 깊이 있는 이해는 부족합니다. 예를 들어, '컵이 탁자 위에 있다'는 문장을 이해하는 것은 쉬워도, 그 컵을 넘어뜨리지 않고 잡거나, 컵에 담긴 액체의 온도를 추측하는 것과 같은 상식적인 행동은 인공지능에게 여전히 어려운 문제입니다. 이러한 맥락적 이해와 물리적 세계와의 상호작용 능력의 부재는, 아무리 강력한 인공지능이라 할지라도 실제 환경에서 독립적인 '범용 에이전트'로 기능하는 데 결정적인 한계로 작용합니다. 따라서 진정한 AGI는 단순히 다양한 도메인에서 높은 성능을 보이는 것을 넘어, 인간처럼 물리적, 사회적 환경 속에서 상식적인 추론을 하고 유연하게 행동할 수 있는 능력을 포함해야 할 것입니다. 이러한 관점에서 볼 때, 현재의 '범용 에이전트'는 아직 진정한 AGI로 가는 길의 초기 단계에 불과하며, 단순히 도구 사용 능력을 확장하는 것만으로는 이 간극을 메우기 어렵습니다.

**기업과 정책 입안자들은 장기적인 관점을 가져야 합니다.**
범용 인공지능(AGI)은 실현 가능한 이정표가 아니므로, 특정 기업이 AGI를 달성했거나 달성할 예정이라고 선언하는 것은 기업이 어떻게 계획해야 하는지, 어떤 안전 개입(safety interventions)이 필요한지, 또는 정책 입안자들이 어떻게 반응해야 하는지에 대해 아무런 영향을 미치지 않습니다. 그렇다면 기업과 정책 입안자들은 대신 무엇을 해야 할까요? 기업들은 미완성된 인공지능 제품을 성급하게 도입해서는 안 됩니다. 인공지능 방법론과 능력의 빠른 발전이 자동으로 더 나은 제품으로 이어지는 것은 아닙니다. 본질적으로 확률적(stochastic)인 모델 위에 제품을 구축하는 것은 어렵습니다. 기업들은 핵심 비즈니스 프로세스(business processes)를 자동화하기 위해 인공지능을 사용하는 영향을 판단하기 위해 신중한 실험을 수행하면서 인공지능 제품을 조심스럽게 채택해야 합니다. 특히, 우리는 인공지능 에이전트가 인간 노동자의 "즉시 대체품(drop-in replacements)"이 되어 워크플로우(workflows)에 자동화를 신중하게 평가하고 통합할 필요성을 어떻게든 우회할 것이라는 생각에 대해 극도로 회의적입니다. 인공지능 제품을 개발하는 기업들은 채택의 장애물(hurdles)을 식별하고 인공지능을 채택하는 기업들이 원하는 것을 구축하기 위해 해당 도메인에 대한 깊은 이해가 필요합니다. 예를 들어, Cursor와 Windsurf와 같은 인공지능 기반 코드 편집기(code editors)의 한 가지 핵심 혁신은 프로그래머가 인공지능이 생성한 텍스트를 다양한 추상화 수준(levels of abstraction)에서 검증할 수 있도록 하는 사용자 인터페이스(user interface)입니다. 정책 입안자들도 장기적인 관점을 가져야 합니다. "AGI를 위한 맨해튼 프로젝트"는 여러 면에서 잘못된 생각입니다. AGI는 이정표가 아니므로, 목표가 언제 달성되었는지 또는 얼마나 더 투자해야 하는지 알 방법이 없습니다. 그리고 인공지능 능력을 가속화하는 것은 경제적 이점을 실현하는 데 있어 실제 병목 현상을 해결하는 데 아무런 도움이 되지 않습니다. 이러한 관점은 수출 통제(export controls)에도 영향을 미칩니다. 미국은 중국의 인공지능 개발을 늦추기 위해 인공지능 개발에 필요한 하드웨어에 대한 수출 통제를 적용했습니다. 수출 통제 지지자들은 이것이 미국과 중국 간의 격차를 몇 달 이상 벌리지 않을 것이라고 인정합니다(우리도 동의합니다). 그러나 이것은 첨단 인공지능 개발의 영향이 급격한 세계에서만 중요합니다. 만약 첨단 인공지능의 영향이 확산을 통해 실현되고, 확산 과정이 수십 년이 걸린다면, 수십 년의 게임에서 몇 달 앞서는 것은 거의 중요하지 않습니다. 따라서 정책 입안자들은 확산을 가능하게 하는 데 집중해야 합니다. 우리는 최근 에세이에서 그렇게 하는 방법에 대한 몇 가지 아이디어를 제시했습니다. AGI를 변혁적인 인공지능 개발의 이정표로 취급하는 것은 매력적이지만 잘못된 생각입니다. 이는 인공지능 발전과 위험, 경제적 영향, 지정학에 대한 잘못된 심적 모델을 부추깁니다. 인공지능이 세계에 미치는 영향은 마법의 총알 기술(magic-bullet technology)을 향한 단거리 경주를 통해서가 아니라, 수백만 가지의 지루하고 작은 비즈니스 프로세스(business process) 적응과 정책 조정(policy tweaks)을 통해 실현될 것입니다. 이 에세이 초안에 대한 피드백을 주신 스티브 뉴먼(Steve Newman)과 재스민 선(Jasmine Sun)에게 감사드립니다.

기업과 정책 입안자들은 불확실한 AGI의 도래에 막연히 기대하거나 두려워하기보다, 현재의 인공지능 기술이 사회에 미칠 수 있는 실질적인 영향을 극대화하고 위험을 최소화하는 데 집중해야 합니다. 이를 위해 기업은 인공지능 솔루션 도입 시 '민첩한 거버넌스(agile governance)' 원칙을 적용하여, 새로운 기술의 효과를 소규모로 테스트하고, 피드백을 통해 빠르게 개선하는 반복적인 접근 방식을 취해야 합니다. 또한, 인공지능 개발사들은 최종 사용자 기업들과의 긴밀한 협력을 통해 각 산업의 특성과 요구 사항을 깊이 이해하고, 실제 운영 환경에 최적화된 맞춤형 솔루션을 제공하는 데 주력해야 합니다. 정책 입안자들은 '규제 샌드박스(regulatory sandboxes)'와 같은 혁신적인 정책 도구를 활용하여, 새로운 인공지능 기술이 안전하게 실험되고 시장에 진입할 수 있는 환경을 조성해야 합니다. 이는 기술 발전의 속도를 저해하지 않으면서도 잠재적 위험을 관리할 수 있는 유연한 규제 프레임워크를 의미합니다. 더 나아가, 인공지능 시대에 필요한 인력 양성을 위해 교육 기관, 기업, 정부 간의 공공-민간 파트너십(public-private partnerships)을 강화해야 합니다. 대중의 인공지능 리터러시(literacy)를 높여 합리적인 기대치를 형성하고, 기술에 대한 이해를 바탕으로 책임감 있는 활용을 유도하는 것도 중요합니다. 궁극적으로, 인공지능의 혜택은 특정 기술적 이정표를 향한 경쟁이 아니라, 기술이 사회의 다양한 영역에 스며들어 생산적인 변화를 이끌어낼 수 있도록 하는 지속적인 노력과 협력을 통해 실현될 것입니다. 이는 단순한 기술 발전이 아닌, 사회 시스템 전반의 지혜로운 적응과 진화를 요구하는 과정입니다.

**더 읽어볼 자료**
재스민 선(Jasmine Sun)의 최근 저술은 내용과 관점에서 본 에세이와 유사합니다. 그녀는 널리 퍼져 있는 다양한 AGI 정의들을 비교 분석하며, AGI를 구체적인 기술적 성과(technical milestone)보다는 인공지능 연구 공동체의 열망(aspiration)으로 해석하는 것이 더 적절하다고 결론짓습니다. 그녀는 또한 AGI 및 여타 연관 개념들에 대한 주요 정의들을 체계적으로 정리했습니다. 보르한 빌리-하멜린(Borhane Blili-Hamelin)과 다른 연구자들은 우리가 AGI를 인공지능 연구의 궁극적인 목표(North star)로 간주하는 것을 지양해야 한다고 주장합니다. 에게 에르딜(Ege Erdil)은 인공지능의 혁신적인 역량이 현실화되기까지는 수십 년의 기간(timelines)이 필요하다는 견해를 제시합니다. 에릭 살바지오(Eryk Salvaggio)는 정책 결정자들이 AGI가 임박한 것처럼 행동하는 것이 위험한 여러 가지 이유를 설명합니다. "AI as Normal Technology"라는 저작에서 우리는 인공지능의 미래에 대한 우리의 시각을 뒷받침하는 지적 토대(intellectual foundation)를 구축했습니다. 본 에세이는 그 저작에 담긴 사상들의 함의를 탐구하는 여러 후속 글 중 첫 번째입니다.

---

<sup>1</sup> 대규모 언어 모델(LLM)은 기본적으로 텍스트 생성에 국한되지만, 'o3'와 같은 시스템은 텍스트 출력을 활용하여 외부 도구와 연동하도록 특별히 학습됩니다. 예를 들어, o3는 특정 지시어(예: "탐색-활용")를 생성하여 주어진 질의(query)를 웹에서 찾아볼 수 있습니다. 물론, 이전 LLM들도 도구 연동 기능을 가지고 있었습니다. 예컨대, OpenAI의 ChatGPT 플러그인(plugins)은 약 2년 전 GPT-4 모델이 외부 기능을 사용하도록 허용했습니다. 하지만 o3와 같은 모델들의 결정적 차이는 도구들을 효과적으로 다루기 위해 **명시적으로 훈련되었다**는 점입니다. 이전 모델들은 이러한 목적을 위해 특별히 훈련되지 않은 상태에서 프롬프트(prompts)에 의존하여 도구를 사용했거나, 기껏해야 도구 사용법의 문법(syntax)만을 익혔습니다. o3는 웹 검색, 코드 실행, 파일 접근, 이미지 생성 및 복잡한 추론을 포함하여 ChatGPT 인터페이스 내의 다양한 도구들을 활용할 수 있습니다. 전반적으로 o3는 단순한 대화형 챗봇(chatbot)을 넘어, 훨씬 더 '자율적인 행위자(agent)'에 가깝습니다.

<sup>2</sup> 예를 들어, 어떤 AI 시스템이 학습 완료 이후에 공개된 새로운 소프트웨어 라이브러리(software library)를 사용하여 특정 코딩 과제를 해결하는 데 활용된다고 가정해 봅시다. 해당 라이브러리에 대한 충분한 설명과 지침이 있다면, 이 시스템은 결국 해당 과제를 성공적으로 수행할 수 있을 것입니다. 하지만 모델의 명시적인 재훈련(retraining)을 통한 업데이트가 이루어지지 않는 한, 이러한 '경험'은 시스템의 내부 가중치(weights)를 변경하지 않습니다. 따라서 동일한 과제를 수행해야 하는 다른 사용자는 첫 번째 사용자가 제공했던 것과 같은 수준의 외부 지원을 여전히 필요로 할 것입니다.

<sup>3</sup> 본 글에서는 군사적 인공지능(military AI)에 대한 심층적인 분석은 다루지 않습니다. 이는 매우 중요한 사안이므로, 추후 별도의 논문에서 상세히 논의할 예정입니다.

<sup>4</sup> 새로운 기술의 **발명(invention)**과 그 기술이 사회 전반에 퍼져나가도록 돕는 **혁신(innovations)**을 명확히 구분하는 것이 중요합니다. 이 단락의 논의는 주로 전자에 초점을 맞춥니다. 발명은 새로운 인공지능 모델의 창조, 그리고 그에 수반되는 새로운 능력의 출현을 의미합니다. 반면 혁신은 이러한 능력이 실제 환경에서 생산적으로 활용될 수 있도록 하는 과정을 말합니다. 예를 들어, 더욱 우수하고 유능한 모델은 발명의 범주에 속하며, 이러한 모델을 기반으로 한 제품 개발은 혁신의 예시입니다. 우리는 국가들이 발명 분야에서 장기적이고 지속적인 우위를 점할 가능성은 낮다고 판단합니다. 그러나 본 섹션에서 후술하듯이, 발명된 기술의 생산적 활용을 가능하게 하는 사회적, 제도적 조건은 국가별로 상당한 차이를 보일 수 있습니다.

<sup>5</sup> 다리오 아모데이(Dario Amodei)는 범용 인공지능(AGI)이라는 용어를 피하고 자신의 예측을 보다 정교하게 표현하기 위해 "강력한 인공지능(powerful AI)"이라는 표현을 사용합니다.