AIE 행사에 참여해주신 모든 분들께 깊은 감사를 전합니다. 행사 첫째 날과 둘째 날의 모든 세션 영상과 더불어, 여섯 가지 독립적인 실시간 방송 채널이 준비되어 있습니다. 주말 동안 편안하게 모든 콘텐츠를 시청하실 수 있습니다! 충분한 휴식 후에 더욱 심층적인 요약 내용을 게시할 예정입니다.

인공지능, 특히 대규모 언어 모델(LLM)이 사회 전반에 미치는 영향이 커짐에 따라, 이 복잡한 시스템의 내부 작동 방식을 이해하는 것은 단순한 학문적 호기심을 넘어 필수적인 과제가 되었습니다. 이러한 맥락에서, 앤스로픽이 지난 3월 공개한 LLM의 심층 분석(MechInterp) 관련 두 편의 중요한 학술 연구 중 하나인 '회로 탐색: 언어 모델 내 계산 경로 가시화(Circuit Tracing: Revealing Computational Graphs in Language Models)'의 핵심 저자는 에마뉘엘 아미장입니다. (이 연구는 'LLM의 생물학적 메커니즘 이해(On the Biology of LLMs)'와 함께 발표되었습니다.)

이번 인터뷰는 한 달 전에 미리 녹음되었으나, 해당 연구에서 제시된 계산 그래프 생성(graph generation)을 위한 개방형 소프트웨어 도구(open-source tooling)가 지난주 Neuronpedia와의 협력을 통해 대중에 공개될 때까지 발표 시점을 조율했습니다. 이는 연구 결과의 투명성을 높이고, 더 많은 연구자들이 LLM의 '블랙박스'를 해체하는 과정에 참여할 수 있도록 독려하기 위함입니다.

본 에피소드는 두 부분으로 나뉘어 진행됩니다. 첫 번째는 개방형 도구 공개에 대한 서론이며, 이어서 공동 진행자 비부 사프라(Vibhu Sapra)와 심층 해석(MechInterp)의 마스코트인 폼스키 모찌(Mochi)와 함께 논문 내용을 더욱 심층적으로 탐구합니다. 이번 에피소드 제작에 크게 기여해주신 비부 님께 진심으로 감사드립니다! 기존 블로그 글에는 훌륭한 안내용 시각화 자료들이 포함되어 있었지만(이는 팟캐스트 말미에 상세히 다룹니다!), 이번 주에 공개된 노트북과 Neuronpedia의 시각화 도구를 통해, 이제 시청자 여러분은 저희가 팟캐스트 영상에서 보여드린 것처럼 Neuronpedia를 직접 활용하여 탐색할 수 있습니다. 유튜브에서 전체 영상을 시청하시고 '좋아요'와 '구독'을 부탁드립니다!

**주요 논의 지점**
*   00:00 서론 및 주요 연사 소개
*   01:00 앤스로픽의 회로 탐색(Circuit Tracing) 연구 공개
*   06:11 회로 탐색 도구 및 시연 분석
*   13:01 인공지능 모델의 동작 양상 및 사용자 주도 실험
*   17:02 연구 과정 비화: 팀워크와 공동체
*   24:19 본 에피소드 개시: 심층 해석(Mech Interp)의 배경
*   25:56 심층 해석 분야 진입 경로
*   31:52 심층 해석의 연혁과 근간 이론
*   37:05 핵심 원리: 중첩 현상(Superposition) 및 내재된 특성(Features)
*   39:54 모델에서의 적용 및 개입 기법(Interventions)
*   45:59 해석 가능성의 난제와 미해결 과제
*   57:15 모델 작동 원리 파악: 회로(Circuits) 및 추론 방식(Reasoning)
*   01:04:24 모델의 계획 능력, 추론 과정 및 기여도 네트워크(Attribution Graphs)
*   01:30:52 신뢰성(Faithfulness), 기만적 행위(Deception) 및 병렬 회로(Parallel Circuits)
*   01:40:16 연구 결과 발표의 위험성, 개방형 연구 및 시각화 기법
*   01:49:33 분야 진입 장벽, 미래 비전 및 참여 독려

**대본**

swyx [00:00:03]: 안녕하세요, 저희 스튜디오에 특별한 손님 여러분을 다시 모시게 되었습니다. 한 분은 여러 차례 게스트 공동 진행자로 활약해주신 비부 님이며, 또 다른 한 분은 증류된 허스키 모찌(Mochi the Distilled Husky)로, 긴급한 질문을 품고 스튜디오에 찾아왔습니다. 그리고 에마뉘엘 님, 성함을 정확히 발음하지 못했는데, 아미장(Amiesen)이 맞으신가요? 네. 네덜란드 출신이신가요? 사실은 독일계 성입니다. 독일이요? 네. 최근 앤스로픽에서 발표된 주요 심층 해석(MechInterp) 연구들의 핵심 집필자이시죠. 저는 이 연구를 계속해서 트랜스포머 회로(Transformer Circuits)라고 불러왔는데, 그게 출판물의 총칭이라서 그렇습니다.

Emmanuel [00:00:35]: 네. 정확히 말씀드리자면, 트랜스포머 회로(Transformer Circuits)는 해당 분야의 광범위한 출판물을 지칭하는 용어이며, 저는 최근 발표된 논문 중 하나인 '회로 탐색(Circuit Tracing)'의 저자입니다. 네.

swyx [00:00:42]: 많은 분들이 이 연구에 대해 큰 관심을 보이고 있습니다. 다른 명칭으로는 'LLM의 사고 과정 추적(Tracing the Thoughts of LLMs)'과 같은 표현도 사용되고 있습니다. 이 연구는 사실상 세 가지 다른 이름으로 불리고 있는 셈이지만, 본질적으로 모두 심층 해석(MechInterp)에 속합니다.

Emmanuel [00:00:49]: 맞습니다, 모두 심층 해석(MechInterp)의 범주에 포함됩니다. 두 편의 논문이 있습니다. 하나는 방법론을 다루는 '회로 탐색(Circuit Tracing)'이고, 다른 하나는 모델에서 우리가 발견한 현상들을 '생물학적 관점(biology)'에서 설명하는 내용입니다. 그리고 '사고 과정 추적(Tracing the Thoughts)'은 혼동을 줄 수 있지만, 단순히 블로그 게시물의 제목일 뿐입니다. 네.

swyx [00:01:01]: 이는 다른 독자층을 겨냥한 것이었군요. 네. 네. 그리고 여러분이 제작하신 2분짜리 세련된 홍보 영상을 보면,

Emmanuel [00:01:07]: 그 영상은 매우 광범위한 대중을 위한 것입니다. 아시다시피, 여러 단계의 세부적인 수준으로 탐구할 수 있습니다. 특히 심층 해석(MechInterp)은 다소 복잡한 분야이므로, 가장 높은 수준에서부터 매우 미세한 부분까지 하향식으로 접근하는 것이 효과적입니다. 네.

swyx [00:01:24]: 좋습니다. 이제 대화를 시작해 볼까요. 크게 두 가지 방향으로 진행할 수 있습니다. 하나는 심층 해석(MechInterp) 분야에 대한 개인적인 경험담을 나누는 것이고, 다른 하나는 이 분야의 간략한 역사를 개괄하는 것입니다. 어쩌면 이 두 가지 주제는 자연스럽게 겹칠 수도 있겠네요.

Emmanuel [00:01:36]: 제 개인적인 여정은 비교적 간결하게 설명할 수 있으니, 먼저 그 부분을 말씀드리고 두 번째 주제로 넘어가는 것이 좋겠습니다. 저는 앤스로픽에서 상당 기간 재직했습니다. 저 역시 많은 동료들처럼, 심층 해석(MechInterp)을 흥미로우면서도 종종 아름다운 연구 결과들이 나오는 분야로 꾸준히 주시해왔습니다. 당시 저는 미세 조정(fine-tuning) 업무를 담당하고 있었는데, 이는 앤스로픽의 실제 제품 모델들을 직접 조정하는 작업이었습니다. 점차 이 분야에 대한 매력이 커지면서, 결국 저는 이 연구에 전념하기로 결심했습니다. 또한, 저희 모델들의 성능이 향상될수록, 그 작동 원리를 깊이 이해하는 것에 대한 관심이 더욱 증폭되었습니다. 이것이 저의 간략한 전환 과정입니다. 저는 기계 학습(ML) 배경을 가지고 있으며, 이전에는 응용 기계 학습 프로젝트를 많이 수행했습니다. 현재는 보다 이론적이고 탐구적인 연구에 집중하고 있습니다. 네.

swyx [00:02:20]: 오라일리(O'Reilly)에서 책도 출판하셨고, 인사이트 데이터 사이언스(Insight Data Science)에서는 인공지능 부문 책임자(Head of AI)를 역임하셨군요. 추가로 홍보하고 싶은 내용이 있으신가요?

Emmanuel [00:02:25]: 네. 사실, 지금은 논문을 알리고 싶고 책에 대한 홍보는 잠시 미루고 싶습니다. 책도 물론 훌륭합니다. 그 안에 담긴 조언들은 시간이 지나도 유효하며, 주로 "AI 제품을 개발할 때 무엇에 집중해야 하는가?"와 같은 실용적인 주제를 다룹니다. 오늘 저희가 논의할 내용과는 상당히 다르다고 할 수 있습니다. 오늘은 연구에 초점을 맞추고 있으며, 모델이 어떻게 기능하는지에 대한 가장 심오하고 때로는 기이한 측면들을 탐구할 것입니다. 반면, 제 책은 사기 탐지를 위해 랜덤 포레스트(random forest) 모델을 배포하고자 할 때, "피해야 할 상위 5가지 실수"와 같은 내용을 담고 있습니다. 네.

swyx [00:02:55]: 기계 학습의 황금기였죠. 그때는 모든 것이 훨씬 단순했습니다. 당신도 연구 분야로 직업을 바꾸셨군요. 그리고 당신의 경우와 마찬가지로, 사람들은 연구직으로 전환하려면 박사 학위가 필수적이라는 큰 오해를 가지고 있는 것 같습니다. 사람들이 연구 분야에 어떻게 진입하는지, 그리고 당신은 어떻게 그 길을 걷게 되었는지에 대한 견해를 공유해주실 수 있을까요? 아마 청중들에게 비부 님의 배경에 대해서도 통찰을 줄 수 있을 것 같습니다.

Vibhu [00:03:16]: 네. 저의 학문적 배경은 경제학과 데이터 과학이었습니다. 저는 LLM이 상당히 매력적이라고 생각했습니다. 기본적인 기계 학습(ML)부터 시작했고, LLM이 급부상하는 것을 지켜보았죠. 그래서 저는 그냥 뛰어들어 직접 해봤습니다. AI 엔지니어링도 마찬가지입니다. 그렇죠? 그냥 무언가를 구축하고, 흥미로운 프로젝트에 몰두하다 보면, 지금은 그 어느