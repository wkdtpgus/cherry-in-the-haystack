## AI의 급진적 발전: 과장인가, 현실인가, 그리고 우리는 준비되었는가?

최근 인공지능 분야에서는 초지능 시스템, 즉 흔히 '지능의 홍수'로 비유되는 거대한 변화가 목전에 와 있음을 역설하는 목소리가 높아지고 있습니다. 이러한 논의의 중심에는 AGI(인공 일반 지능)가 있습니다. AGI는 인간이 수행하는 거의 모든 지적 과업에서 전문가 수준을 뛰어넘는 역량을 가진 기계를 지칭하지만, 그 정의는 여전히 모호한 측면이 많습니다. 이들은 필요한 지능을 자유자재로 활용할 수 있는 능력이 사회 전반을 심대하게 변화시킬 것이며, 그 변화가 머지않아 도래할 것이라고 강력히 주장합니다. 다음은 근시일 내에 초지능 AI가 등장할 것이라고 예측하는 AI 연구소 내 저명한 연구자들의 최근 발언 중 일부입니다.

AI 개발자들의 주장에 대해 회의적인 시각도 존재합니다. 이들의 과감한 예측 뒤에는 투자 유치, 기업 가치 상승, 혹은 기술 역사 속에서 자신들의 위치를 공고히 하려는 동기가 작용할 수 있다는 비판도 제기됩니다. 기술자들은 예언자가 아니며, 과거 기술 예측의 역사는 수십 년 후에서야 실현된 자신감 넘치는 선언들로 가득합니다. 이러한 인간적 편향을 차치하고라도, 근본적인 기술 자체는 우리에게 의구심을 품을 충분한 이유를 제공합니다. 현재 대규모 언어 모델(LLM)들은 놀라운 성능을 보여주지만, 본질적으로 예측 불가능한 특성을 내포하고 있습니다. 특정 고난이도 작업에서는 탁월한 능력을 발휘하는 반면, 상대적으로 단순해 보이는 과제에서는 난항을 겪기도 합니다. 이러한 '불균일한 능력 경계(jagged frontier)'는 현세대 AI 시스템의 고유한 특징이며, 단기간에 해소되기 어려운 문제로 지적됩니다. 게다가, 연구자들이 1~2년 내에 AGI에 도달할 것이라는 주장이 옳다고 가정하더라도, 그들은 인간이 새로운 기술을 채택하고 적응하는 속도를 과대평가하고 있을 가능성이 높습니다. 조직의 변화는 오랜 시간이 소요되며, 업무, 삶, 교육 시스템의 근본적인 변화는 훨씬 더 더디게 진행됩니다. 기술은 세상 속에서 의미 있는 쓰임새를 찾아야 하는데, 이 또한 느린 과정입니다. 우리는 지금 당장 AGI를 가질 수도 있지만 대부분의 사람들은 그 중요성을 미처 깨닫지 못할 수도 있습니다(실제로 일부 전문가들은 클로드 3.5(Claude 3.5)와 같은 최신 AI 모델이 사실상 AGI에 근접했다고 주장하며 이미 이러한 현상이 시작되었음을 시사합니다 1).

그럼에도 불구하고, 이 모든 예측을 단순한 과장으로 치부하는 것은 경솔할 수 있습니다. AI 연구소 내부의 과학자와 엔지니어들은 그들의 동기가 무엇이든 간에, 전례 없는 기술적 진보를 목격하고 있다는 진심 어린 확신을 표명하고 있습니다. 물론 그들의 확신 그 자체만으로는 충분한 근거가 되지 못하지만, 최근 공개되는 다양한 벤치마크(benchmark) 결과와 시연들은 AI 역량의 근본적인 전환점에 우리가 도달하고 있다는 그들의 믿음에 힘을 실어주고 있습니다. 비유하자면, 물이 예상보다 빠르게 차오르는 듯한 상황입니다.

### 인공지능 능력의 지각변동

가장 많은 관심을 끌었던 사건은 작년 12월 말 OpenAI가 o3라는 새로운 모델을 공개한 것이었습니다. OpenAI 외부에서는 아직 아무도 이 시스템을 직접 사용해 보지 못했지만, o3는 이미 매우 인상적인 o1의 후속 모델입니다 2. o3 모델은 새로운 세대의 '추론기(reasoner)' 중 하나입니다. 이 AI 모델은 질문에 답하기 전에 '생각'하는 데 추가 시간을 할애하여 어려운 문제 해결 능력을 크게 향상시킵니다. OpenAI는 o3에 대한 여러 놀라운 벤치마크(benchmark)를 제공했는데, 이는 o1에 비해, 그리고 우리가 생각했던 AI 분야의 최첨단(state-of-the-art)에 비해 큰 발전을 시사합니다. 특히 세 가지 벤치마크(benchmark)에 주목할 필요가 있습니다.

첫 번째는 대학원 수준의 구글-프루프 Q&A 테스트(Graduate-Level Google-Proof Q&A test, GPQA)라고 불리며, 구글조차도 도움을 줄 수 없는 일련의 객관식 문제로 고수준 지식을 테스트하도록 되어 있습니다. 인터넷에 접속할 수 있는 박사 학위 소지자들은 이 테스트에서 자신의 전문 분야 외 문제의 34%를 맞혔고, 전문 분야 내 문제의 81%를 맞혔습니다. o3는 테스트에서 87%를 달성하여 처음으로 인간 전문가를 능가했습니다.

두 번째는 프론티어 수학(Frontier Math)으로, 수학자들이 풀기 매우 어렵게 만든 비공개 수학 문제 세트입니다. 실제로 o3 이전에는 어떤 AI도 2% 이상 득점한 적이 없었지만, o3는 25%를 맞혔습니다.

마지막 벤치마크(benchmark)는 ARC-AGI입니다. 이는 인간에게는 비교적 쉽지만 AI에게는 어려운 것으로 설계된 유동 지능(fluid intelligence)에 대한 꽤 유명한 테스트입니다. 다시 한번, o3는 87.5%를 기록하며 이전의 모든 AI와 기준 인간 수준을 능가했습니다.

이 모든 테스트에는 중요한 주의사항(caveat)이 따르지만 3, 이는 우리가 이전에 AI 성능에 대한 통과 불가능한 장벽이라고 생각했던 것들이 실제로는 상당히 빠르게 극복될 수 있음을 시사합니다. 이러한 벤치마크 결과는 단순한 점수 향상을 넘어, AI가 추상적 사고, 복잡한 문제 해결, 그리고 인간의 직관에 가까운 유동 지능 영역에서 예상보다 빠르게 발전하고 있음을 보여줍니다. 이는 과거 패턴 인식에 머물렀던 AI의 한계를 뛰어넘어, 더욱 고차원적인 인지 능력을 획득하고 있다는 강력한 증거로 해석될 수 있습니다.

### 에이전트(Agent)의 부상과 자율성의 확장

에이전트(Agent)는 AI 분야에서 또 다른 다의적인 용어입니다. 일반적으로는 특정 목표를 달성하기 위해 자율적으로 계획을 수립하고 행동을 실행할 수 있는 인공지능 시스템을 지칭합니다. 저는 이전 게시물에서 초기 에이전트 시스템 중 일부를 시연했지만, 지난 몇 주 동안은 좁지만 경제적으로 중요한 분야에서 실용적인 에이전트가 이제 실현 가능하다는 것을 보여주었습니다. 좋은 예시로는 구글의 제미니(Gemini) 딥 리서치(Deep Research)(제미니(Gemini) 구독자라면 누구나 이용 가능)가 있는데, 이는 실제로 전문화된 연구 에이전트입니다. 저는 "고성장 벤처를 위한 스타트업 자금 조달 방식 비교를 창업자 관점에서 연구하라"와 같은 주제를 주었고, 에이전트 시스템은 계획을 세우고, 173개(!) 웹사이트를 읽고, 몇 분 후에 저를 위한 보고서를 작성했습니다. 그 결과는 118개의 참고 문헌이 있는 17페이지 분량의 보고서였습니다!

하지만 과연 좋은가요? 저는 10년 넘게 와튼 스쿨에서 창업 입문 수업을 가르쳤고, 해당 주제에 대해 출판했으며, 직접 회사를 창업했고, 심지어 창업에 관한 책도 썼습니다. 그리고 저는 이것이 꽤 탄탄하다고 생각합니다. 명백한 오류는 발견하지 못했지만, 원하시면 여기서 직접 읽어보실 수 있습니다. 가장 큰 문제는 정확성이 아니라, 에이전트가 공개된 비유료 웹사이트로 제한되며 학술지나 프리미엄 출판물은 아니라는 점입니다. 또한 다소 피상적이며 상충되는 증거에 직면했을 때 강력한 주장을 펼치지 못합니다. 따라서 최고의 인간만큼 좋지는 않지만, 제가 보는 많은 보고서보다는 낫습니다. 그럼에도 불구하고, 이것은 진정한 가치를 지닌 에이전트의 혁신적인 사례입니다. 연구 및 보고서 작성은 많은 직업의 주요 업무입니다. 딥 리서치(Deep Research)가 3분 만에 달성한 것은 인간에게는 여러 시간이 걸렸을 것이며, 비록 인간이 더 미묘한 분석을 추가했을 수도 있지만 말입니다. 이를 고려할 때, 연구 보고서를 작성하는 사람이라면 누구나 딥 리서치(Deep Research)를 시도하여 시작점으로 어떻게 작동하는지 확인해야 할 것입니다. 비록 좋은 최종 보고서는 여전히 인간의 손길을 필요로 하겠지만 말입니다. 저는 딥 리서치(Deep Research) 프로젝트 책임자와 이야기할 기회가 있었는데, 그로부터 이것이 소규모 팀의 파일럿 프로젝트일 뿐이라는 것을 알게 되었습니다. 따라서 좁지만 효과적인 에이전트를 만드는 데 높은 동기를 부여받은 다른 그룹과 회사들도 그렇게 할 수 있을 것이라고 생각합니다. 좁은 범위의 에이전트(Narrow agent)는 이제 미래의 가능성이 아니라 실제 제품입니다. 이미 많은 코딩 에이전트가 있으며, 과학 및 금융 연구를 수행하는 실험적인 오픈소스(open-source) 에이전트를 사용할 수 있습니다. 좁은 범위의 에이전트(Narrow agent)는 특정 작업에 특화되어 있어 다소 제한적입니다. 이는 우리가 곧 AI에게 무엇이든 물어보면 컴퓨터와 인터넷을 사용하여 수행하는 범용 에이전트(generalist agent)를 보게 될 것인지에 대한 의문을 제기합니다. 샘 알트만(Sam Altman)이 주장한 바와 달리 사이먼 윌리슨(Simon Willison)은 그렇게 생각하지 않습니다. 올해가 지나면서 더 많은 것을 알게 되겠지만, 범용 에이전트 시스템이 안정적이고 안전하게 작동한다면, 스마트 AI가 세상에서 행동을 취할 수 있도록 허용하므로 정말로 많은 것을 변화시킬 것입니다.

에이전트 시스템의 발전은 AI가 단순한 도구를 넘어 자율적인 '행위자'로 진화하고 있음을 의미합니다. 이러한 자율성은 AI가 복잡한 다단계 작업을 스스로 계획하고 실행하며, 외부 환경과 상호작용하는 능력을 부여합니다. 이는 코딩, 디자인, 금융 분석 등 다양한 전문 분야에서 인간의 업무를 보조하거나 대체하는 것을 넘어, 완전히 새로운 형태의 협업과 자동화를 가능하게 할 잠재력을 가집니다. 물론, 에이전트의 자율성이 증대될수록 윤리적 책임, 안전성 확보, 그리고 통제 가능성에 대한 논의는 더욱 중요해질 것입니다.

### 멀티모달 AI의 경계 확장과 창의적 잠재력

에이전트와 매우 똑똑한 모델은 혁신적인 AI에 필요한 핵심 요소이지만, 빠르게 발전하고 있는 다른 많은 부분들도 있습니다. 여기에는 AI가 기억할 수 있는 양(컨텍스트 윈도우(context window))의 발전과 보고 말할 수 있게 해주는 멀티모달(multimodal) 기능이 포함됩니다. 진행 상황을 파악하기 위해 과거를 조금 돌아보는 것이 도움이 될 수 있습니다. 예를 들어, 저는 ChatGPT가 나오기 전부터 이미지 및 비디오 모델에 대해 "와이파이를 사용하는 비행기 위의 수달(otter on a plane using wifi)"이라는 프롬프트(prompt)를 테스트해 왔습니다. 2023년 10월에는 이 프롬프트(prompt)가 이 끔찍한 괴물을 만들어냈습니다.

"와이파이를 사용하는 비행기 위의 수달" 2023년 10월

18개월도 채 지나지 않아, 여러 이미지 생성 도구가 이 프롬프트(prompt)를 완벽하게 구현합니다. 그 결과, 저는 더 어려운 것을 찾아야 했습니다(이는 오래된 벤치마크(benchmark)가 AI에 의해 능가되는 벤치마크 포화(benchmark saturation)의 예시입니다). 저는 몇 분 시간을 내어 구글의 비오(Veo) 비디오 모델로 수달의 여정을 담은 영화를 얼마나 만들 수 있는지 확인해 보기로 했습니다. 아래 비디오를 만드는 데는 15분 미만의 실제 작업이 필요했지만, 비디오가 생성될 때까지 잠시 기다려야 했습니다. 그림자와 빛의 품질을 살펴보세요. 특히 수달이 마지막에 컴퓨터를 여는 방식이 마음에 듭니다. 그리고 한 단계 더 나아가, 저는 수달의 이야기를 우주에 있는 수달과 시대에 맞는 주제가를 특징으로 하는 1980년대 스타일의 공상 과학 애니메이션으로 바꾸기로 결정했습니다(수노(Suno) 덕분입니다). 다시 한번, (인간의) 작업은 거의 필요하지 않았습니다.

멀티모달 AI의 발전은 텍스트, 이미지, 오디오, 비디오 등 다양한 형태의 데이터를 통합적으로 이해하고 생성하는 AI의 능력을 의미합니다. 이는 단순한 콘텐츠 생성을 넘어, 의료 영상 진단, 복잡한 설계 시뮬레이션, 실시간 언어 번역 등 광범위한 분야에서 혁신을 이끌고 있습니다. AI가 여러 감각 정보를 동시에 처리하고 추론할 수 있게 되면서, 인간과 기계 간의 상호작용은 더욱 자연스럽고 직관적으로 변화하고 있습니다. 이러한 진보는 AI가 단순히 정보를 처리하는 것을 넘어, 더욱 창의적이고 공감각적인 방식으로 세상과 소통할 수 있는 길을 열어주고 있습니다.

### 지능의 홍수: 어떻게 대비하고 적응할 것인가?

이 모든 발전상을 종합해 볼 때, AI 연구소에서 주장하는 '지능의 홍수'가 과연 얼마나 현실적인 위협 또는 기회로 다가올지 진지하게 고민할 필요가 있습니다. 이미 목격한 o3 모델의 획기적인 벤치마크 성과, 복잡한 연구를 수행하는 특화된 에이전트(agent) 시스템, 그리고 놀랍도록 정교한 콘텐츠를 생성하는 멀티모달(multimodal) AI의 능력만으로도, 우리는 수많은 지식 노동의 패러다임을 변화시킬 잠재력을 충분히 인지할 수 있습니다. 그럼에도 불구하고 연구소들은 이것이 단지 시작일 뿐이며, 훨씬 더 유능한 시스템과 범용 에이전트(general agent)가 임박했다고 주장합니다.

저를 가장 우려하게 하는 것은 연구소들이 이 타임라인(timeline)에 대해 맞는지 여부가 아닙니다. 그것은 그들이 옳을 가능성은 말할 것도 없고, 현재 AI 수준이 할 수 있는 일에 대해서도 우리가 충분히 대비하지 못하고 있다는 점입니다. AI 연구자들은 정렬(alignment)에 집중하여 AI 시스템이 윤리적이고 책임감 있게 행동하도록 보장하고 있지만, 인공지능으로 가득 찬 세상이 실제로 어떤 모습일지 상상하고 명확히 표현하려는 목소리는 훨씬 적습니다. 이것은 단지 기술 자체에 관한 것만이 아닙니다. 그것은 우리가 그것을 어떻게 형성하고 배치할지 선택하는 방법에 관한 것입니다. 이러한 중대한 질문들은 단지 AI 개발자들만의 전유물이 아닙니다. 이 거대한 전환기를 헤쳐나가야 할 기업의 리더들, 업무 환경의 변화를 맞이할 근로자들, 그리고 미래가 이 기술의 방향에 달려 있는 모든 이해관계자들이 함께 고민하고 참여해야 할 의제입니다.

다가올 수 있는 지능의 홍수는 그 자체로 좋거나 나쁘지 않습니다. 그 영향은 전적으로 우리가 어떻게 준비하고, 어떻게 적응하며, 가장 중요하게는 이 강력한 도구를 어떻게 활용할지에 달려 있습니다. 이러한 변화에 대한 사회적 논의는 더 이상 기술 전문가만의 영역이 아닙니다. 정책 입안자들은 AI의 윤리적 사용, 데이터 프라이버시, 그리고 책임 소재에 대한 명확한 가이드라인을 수립해야 합니다. 교육 시스템은 미래 세대가 AI와 협력하며 새로운 가치를 창출할 수 있도록 재편되어야 하며, 기업들은 AI를 전략적으로 통합하고 새로운 비즈니스 기회를 모색해야 합니다. 이러한 대화를 시작할 시기는 물이 차오르기 시작한 후가 아니라 바로 지금입니다. 우리는 AI가 가져올 변화의 물결을 수동적으로 기다리기보다, 능동적으로 그 방향을 설정하고 긍정적인 미래를 만들어갈 책임이 있습니다.

구독 공유

1 저는 클로드(Claude)에게 완성된 문서를 읽고 피드백을 달라고 요청했고, 클로드는 다음과 같이 썼습니다: "클로드 3.5(Claude 3.5)에 대한 괄호 안의 언급은 잠재적인 AGI의 예시로 언급되었으므로 업데이트 또는 수정의 이점을 얻을 수 있습니다. 클로드 3.5 소네트(Claude 3.5 Sonnet)로서, 저는 AGI와 관련하여 제 능력에 대한 특정 주장을 확인할 수 없다는 점을 말씀드립니다."
2 그들은 o2라는 이름을 건너뛰었는데, 이는 영국에 있는 전화 회사의 이름이기 때문입니다. AI 명명은 여전히 매우 좋지 않습니다.
3 GPQA에 대한 주의사항(caveat)은 데이터가 공개적으로 이용 가능하며, 모델이 우연히든 의도적으로든 해당 데이터로 훈련되었을 가능성이 있다는 것입니다. 비록 그렇게 했다는 징후는 없지만 말입니다. 프론티어 수학(Frontier Math) 테스트의 주의사항(caveat)은 문제의 난이도가 다르다는 것입니다. 1단계(Tier 1)는 어려운 수학 올림피아드 문제이고, 2단계(Tier 2)는 대학원 수준 문제이며, 3단계(Tier 3)는 진정한 연구 수준 문제입니다. o3의 정답에 대해 책임 있는 수학자의 말에 따르면: "40%는 1단계, 50%는 2단계, 10%는 3단계였습니다. 그러나 대부분의 3단계 '해결책'과 많은 2단계 해결책은 진정한 수학적 이해보다는 발견적 지름길(heuristic shortcut)에서 비롯되었습니다." ARC-AGI에 대한 주의사항(caveat)은 o3가 높은 점수를 달성하기 위해 충분히 오래 실행하는 데 매우 비싼 컴퓨터 시간이 많이 필요했다는 것입니다.