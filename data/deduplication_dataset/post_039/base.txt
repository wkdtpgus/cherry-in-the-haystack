# **대홍수의 예언**

Author: Ethan Mollick
URL: https://www.oneusefulthing.org/p/prophecies-of-the-flood

============================================================

최근 AI 산업에 변화가 생겼습니다. 연구자들은 초지능 AI 시스템, 즉 지능의 홍수가 멀지 않은 미래가 아닌 임박한 시기에 도래할 것이라고 긴급하게 이야기하기 시작했습니다. 그들은 종종 AGI(인공 일반 지능)를 언급하는데, 이는 대부분의 지적 작업에서 전문 인간을 능가할 수 있는 기계로 정의되지만 다소 불명확합니다. 그들은 필요에 따라 지능을 활용할 수 있는 능력이 사회를 깊이 변화시킬 것이며, 그 변화가 곧 일어날 것이라고 주장합니다. 다음은 근시일 내에 초지능 AI가 등장할 것이라고 예측하는 AI 연구소 내 저명한 연구자들의 최근 발언 중 일부입니다. 내부자들의 말을 믿지 않을 이유는 많습니다. 그들은 대담한 예측을 할 분명한 동기를 가지고 있기 때문입니다. 자본을 조달하고, 주식 가치를 높이며, 어쩌면 자신들의 역사적 중요성을 스스로에게 확신시키고 있을지도 모릅니다. 그들은 기술자이지 예언자가 아니며, 기술 예측의 실적은 수십 년 앞서 나간 것으로 판명된 자신감 넘치는 선언들로 가득합니다. 이러한 인간적 편향을 제쳐두더라도, 근본적인 기술 자체는 우리에게 의심할 이유를 제공합니다. 오늘날의 대규모 언어 모델(Large Language Models)은 인상적인 능력에도 불구하고, 근본적으로 일관성 없는 도구로 남아 있습니다. 어떤 작업에서는 뛰어나지만 겉보기에 더 간단한 작업에서는 어려움을 겪습니다. 이러한 "들쭉날쭉한 경계(jagged frontier)"는 현재 AI 시스템의 핵심 특성이며, 쉽게 해결되지 않을 것입니다. 게다가, 연구자들이 1~2년 내에 AGI에 도달할 것이라는 주장이 옳다고 가정하더라도, 그들은 인간이 기술을 채택하고 적응하는 속도를 과대평가하고 있을 가능성이 높습니다. 조직의 변화는 오랜 시간이 걸립니다. 업무, 삶, 교육 시스템의 변화는 훨씬 더 느립니다. 그리고 기술은 세상에서 중요한 특정 용도를 찾아야 하는데, 이 또한 느린 과정입니다. 우리는 지금 당장 AGI를 가질 수도 있지만 대부분의 사람들은 알아차리지 못할 것입니다(실제로 일부 관찰자들은 클로드 3.5(Claude 3.5)와 같은 최신 AI 모델이 사실상 AGI라고 주장하며 이미 일어났다고 시사했습니다 1). 그러나 이러한 예측을 단순한 과장으로 일축하는 것은 도움이 되지 않을 수 있습니다. 그들의 동기가 무엇이든, AI 연구소 내부의 연구자와 엔지니어들은 전례 없는 무언가의 출현을 목격하고 있다고 진정으로 확신하는 듯합니다. 그들의 확신만으로는 중요하지 않을 것입니다. 다만, 점점 더 공개되는 벤치마크(benchmark)와 시연이 우리가 AI 역량의 근본적인 변화에 접근하고 있다고 그들이 믿는 이유를 암시하기 시작했다는 점은 예외입니다. 말하자면, 물이 예상보다 빠르게 차오르는 것 같습니다.

### 물이 차오르는 곳

가장 많은 추측을 불러일으킨 사건은 12월 말 OpenAI가 o3라는 새로운 모델을 공개한 것이었습니다. OpenAI 외부에서는 아직 아무도 이 시스템을 실제로 사용해 보지 못했지만, o3는 이미 매우 인상적인 o1의 후속 모델입니다 2. o3 모델은 새로운 세대의 '추론기(reasoner)' 중 하나입니다. 이 AI 모델은 질문에 답하기 전에 '생각'하는 데 추가 시간을 할애하여 어려운 문제 해결 능력을 크게 향상시킵니다. OpenAI는 o3에 대한 여러 놀라운 벤치마크(benchmark)를 제공했는데, 이는 o1에 비해, 그리고 우리가 생각했던 AI 분야의 최첨단(state-of-the-art)에 비해 큰 발전을 시사합니다. 특히 세 가지 벤치마크(benchmark)에 주목할 필요가 있습니다.

첫 번째는 대학원 수준의 구글-프루프 Q&A 테스트(Graduate-Level Google-Proof Q&A test, GPQA)라고 불리며, 구글조차도 도움을 줄 수 없는 일련의 객관식 문제로 고수준 지식을 테스트하도록 되어 있습니다. 인터넷에 접속할 수 있는 박사 학위 소지자들은 이 테스트에서 자신의 전문 분야 외 문제의 34%를 맞혔고, 전문 분야 내 문제의 81%를 맞혔습니다. o3는 테스트에서 87%를 달성하여 처음으로 인간 전문가를 능가했습니다.

두 번째는 프론티어 수학(Frontier Math)으로, 수학자들이 풀기 매우 어렵게 만든 비공개 수학 문제 세트입니다. 실제로 o3 이전에는 어떤 AI도 2% 이상 득점한 적이 없었지만, o3는 25%를 맞혔습니다.

마지막 벤치마크(benchmark)는 ARC-AGI입니다. 이는 인간에게는 비교적 쉽지만 AI에게는 어려운 것으로 설계된 유동 지능(fluid intelligence)에 대한 꽤 유명한 테스트입니다. 다시 한번, o3는 87.5%를 기록하며 이전의 모든 AI와 기준 인간 수준을 능가했습니다.

이 모든 테스트에는 중요한 주의사항(caveat)이 따르지만 3, 이는 우리가 이전에 AI 성능에 대한 통과 불가능한 장벽이라고 생각했던 것들이 실제로는 상당히 빠르게 극복될 수 있음을 시사합니다.

### 에이전트(Agent)

AI가 더 똑똑해짐에 따라, 그들은 더 효과적인 에이전트(agent)가 됩니다. 에이전트(agent)는 또 다른 모호하게 정의된 용어(패턴이 보이시나요?)로, 일반적으로 일련의 목표를 달성하기 위해 자율적으로 행동할 수 있는 능력을 부여받은 AI를 의미합니다. 저는 이전 게시물에서 초기 에이전트 시스템 중 일부를 시연했지만, 지난 몇 주 동안은 좁지만 경제적으로 중요한 분야에서 실용적인 에이전트가 이제 실현 가능하다는 것을 보여주었습니다. 좋은 예시로는 구글의 제미니(Gemini) 딥 리서치(Deep Research)(제미니(Gemini) 구독자라면 누구나 이용 가능)가 있는데, 이는 실제로 전문화된 연구 에이전트입니다. 저는 "고성장 벤처를 위한 스타트업 자금 조달 방식 비교를 창업자 관점에서 연구하라"와 같은 주제를 주었고, 에이전트 시스템은 계획을 세우고, 173개(!) 웹사이트를 읽고, 몇 분 후에 저를 위한 보고서를 작성했습니다. 그 결과는 118개의 참고 문헌이 있는 17페이지 분량의 보고서였습니다!

하지만 과연 좋은가요? 저는 10년 넘게 와튼 스쿨에서 창업 입문 수업을 가르쳤고, 해당 주제에 대해 출판했으며, 직접 회사를 창업했고, 심지어 창업에 관한 책도 썼습니다. 그리고 저는 이것이 꽤 탄탄하다고 생각합니다. 명백한 오류는 발견하지 못했지만, 원하시면 여기서 직접 읽어보실 수 있습니다. 가장 큰 문제는 정확성이 아니라, 에이전트가 공개된 비유료 웹사이트로 제한되며 학술지나 프리미엄 출판물은 아니라는 점입니다. 또한 다소 피상적이며 상충되는 증거에 직면했을 때 강력한 주장을 펼치지 못합니다. 따라서 최고의 인간만큼 좋지는 않지만, 제가 보는 많은 보고서보다는 낫습니다. 그럼에도 불구하고, 이것은 진정한 가치를 지닌 에이전트의 혁신적인 사례입니다. 연구 및 보고서 작성은 많은 직업의 주요 업무입니다. 딥 리서치(Deep Research)가 3분 만에 달성한 것은 인간에게는 여러 시간이 걸렸을 것이며, 비록 인간이 더 미묘한 분석을 추가했을 수도 있지만 말입니다. 이를 고려할 때, 연구 보고서를 작성하는 사람이라면 누구나 딥 리서치(Deep Research)를 시도하여 시작점으로 어떻게 작동하는지 확인해야 할 것입니다. 비록 좋은 최종 보고서는 여전히 인간의 손길을 필요로 하겠지만 말입니다. 저는 딥 리서치(Deep Research) 프로젝트 책임자와 이야기할 기회가 있었는데, 그로부터 이것이 소규모 팀의 파일럿 프로젝트일 뿐이라는 것을 알게 되었습니다. 따라서 좁지만 효과적인 에이전트를 만드는 데 높은 동기를 부여받은 다른 그룹과 회사들도 그렇게 할 수 있을 것이라고 생각합니다. 좁은 범위의 에이전트(Narrow agent)는 이제 미래의 가능성이 아니라 실제 제품입니다. 이미 많은 코딩 에이전트가 있으며, 과학 및 금융 연구를 수행하는 실험적인 오픈소스(open-source) 에이전트를 사용할 수 있습니다. 좁은 범위의 에이전트(Narrow agent)는 특정 작업에 특화되어 있어 다소 제한적입니다. 이는 우리가 곧 AI에게 무엇이든 물어보면 컴퓨터와 인터넷을 사용하여 수행하는 범용 에이전트(generalist agent)를 보게 될 것인지에 대한 의문을 제기합니다. 샘 알트만(Sam Altman)이 주장한 바와 달리 사이먼 윌리슨(Simon Willison)은 그렇게 생각하지 않습니다. 올해가 지나면서 더 많은 것을 알게 되겠지만, 범용 에이전트 시스템이 안정적이고 안전하게 작동한다면, 스마트 AI가 세상에서 행동을 취할 수 있도록 허용하므로 정말로 많은 것을 변화시킬 것입니다.

### 많은 작은 발전이 일어나고 있다

에이전트와 매우 똑똑한 모델은 혁신적인 AI에 필요한 핵심 요소이지만, 빠르게 발전하고 있는 다른 많은 부분들도 있습니다. 여기에는 AI가 기억할 수 있는 양(컨텍스트 윈도우(context window))의 발전과 보고 말할 수 있게 해주는 멀티모달(multimodal) 기능이 포함됩니다. 진행 상황을 파악하기 위해 과거를 조금 돌아보는 것이 도움이 될 수 있습니다. 예를 들어, 저는 ChatGPT가 나오기 전부터 이미지 및 비디오 모델에 대해 "와이파이를 사용하는 비행기 위의 수달(otter on a plane using wifi)"이라는 프롬프트(prompt)를 테스트해 왔습니다. 2023년 10월에는 이 프롬프트(prompt)가 이 끔찍한 괴물을 만들어냈습니다.

"와이파이를 사용하는 비행기 위의 수달" 2023년 10월

18개월도 채 지나지 않아, 여러 이미지 생성 도구가 이 프롬프트(prompt)를 완벽하게 구현합니다. 그 결과, 저는 더 어려운 것을 찾아야 했습니다(이는 오래된 벤치마크(benchmark)가 AI에 의해 능가되는 벤치마크 포화(benchmark saturation)의 예시입니다). 저는 몇 분 시간을 내어 구글의 비오(Veo) 비디오 모델로 수달의 여정을 담은 영화를 얼마나 만들 수 있는지 확인해 보기로 했습니다. 아래 비디오를 만드는 데는 15분 미만의 실제 작업이 필요했지만, 비디오가 생성될 때까지 잠시 기다려야 했습니다. 그림자와 빛의 품질을 살펴보세요. 특히 수달이 마지막에 컴퓨터를 여는 방식이 마음에 듭니다. 그리고 한 단계 더 나아가, 저는 수달의 이야기를 우주에 있는 수달과 시대에 맞는 주제가를 특징으로 하는 1980년대 스타일의 공상 과학 애니메이션으로 바꾸기로 결정했습니다(수노(Suno) 덕분입니다). 다시 한번, (인간의) 작업은 거의 필요하지 않았습니다.

### 홍수는 어떠한가?

이 모든 것을 고려할 때, AI 연구소의 '지능의 홍수'가 오고 있다는 주장을 얼마나 진지하게 받아들여야 할까요? 우리가 이미 본 것들, 즉 이전 장벽을 허무는 o3 벤치마크(benchmark), 복잡한 연구를 수행하는 좁은 범위의 에이전트(narrow agent), 그리고 점점 더 정교한 콘텐츠를 생성하는 멀티모달(multimodal) 시스템만을 고려하더라도, 우리는 많은 지식 기반 작업을 변화시킬 수 있는 능력을 보고 있습니다. 그럼에도 불구하고 연구소들은 이것이 단지 시작일 뿐이며, 훨씬 더 유능한 시스템과 범용 에이전트(general agent)가 임박했다고 주장합니다.

저를 가장 우려하게 하는 것은 연구소들이 이 타임라인(timeline)에 대해 맞는지 여부가 아닙니다. 그것은 그들이 옳을 가능성은 말할 것도 없고, 현재 AI 수준이 할 수 있는 일에 대해서도 우리가 충분히 대비하지 못하고 있다는 점입니다. AI 연구자들은 정렬(alignment)에 집중하여 AI 시스템이 윤리적이고 책임감 있게 행동하도록 보장하고 있지만, 인공지능으로 가득 찬 세상이 실제로 어떤 모습일지 상상하고 명확히 표현하려는 목소리는 훨씬 적습니다. 이것은 단지 기술 자체에 관한 것만이 아닙니다. 그것은 우리가 그것을 어떻게 형성하고 배치할지 선택하는 방법에 관한 것입니다. 이러한 질문들은 AI 개발자만이 답할 수 있거나 답해야 하는 질문이 아닙니다. 이 전환을 헤쳐나가야 할 조직 리더들, 업무 생활이 변화할 수 있는 직원들, 그리고 미래가 이러한 결정에 달려 있을 수 있는 이해관계자들의 관심을 요구하는 질문들입니다. 다가올 수 있는 지능의 홍수는 본질적으로 좋거나 나쁘지 않습니다. 그러나 우리가 그것을 어떻게 준비하고, 어떻게 적응하며, 가장 중요하게는 어떻게 사용할지 선택하는 것이 그것이 진보의 힘이 될지 아니면 혼란의 힘이 될지 결정할 것입니다. 이러한 대화를 시작할 시기는 물이 차오르기 시작한 후가 아니라 바로 지금입니다.

구독 공유

1 저는 클로드(Claude)에게 완성된 문서를 읽고 피드백을 달라고 요청했고, 클로드는 다음과 같이 썼습니다: "클로드 3.5(Claude 3.5)에 대한 괄호 안의 언급은 잠재적인 AGI의 예시로 언급되었으므로 업데이트 또는 수정의 이점을 얻을 수 있습니다. 클로드 3.5 소네트(Claude 3.5 Sonnet)로서, 저는 AGI와 관련하여 제 능력에 대한 특정 주장을 확인할 수 없다는 점을 말씀드립니다."
2 그들은 o2라는 이름을 건너뛰었는데, 이는 영국에 있는 전화 회사의 이름이기 때문입니다. AI 명명은 여전히 매우 좋지 않습니다.
3 GPQA에 대한 주의사항(caveat)은 데이터가 공개적으로 이용 가능하며, 모델이 우연히든 의도적으로든 해당 데이터로 훈련되었을 가능성이 있다는 것입니다. 비록 그렇게 했다는 징후는 없지만 말입니다. 프론티어 수학(Frontier Math) 테스트의 주의사항(caveat)은 문제의 난이도가 다르다는 것입니다. 1단계(Tier 1)는 어려운 수학 올림피아드 문제이고, 2단계(Tier 2)는 대학원 수준 문제이며, 3단계(Tier 3)는 진정한 연구 수준 문제입니다. o3의 정답에 대해 책임 있는 수학자의 말에 따르면: "40%는 1단계, 50%는 2단계, 10%는 3단계였습니다. 그러나 대부분의 3단계 '해결책'과 많은 2단계 해결책은 진정한 수학적 이해보다는 발견적 지름길(heuristic shortcut)에서 비롯되었습니다." ARC-AGI에 대한 주의사항(caveat)은 o3가 높은 점수를 달성하기 위해 충분히 오래 실행하는 데 매우 비싼 컴퓨터 시간이 많이 필요했다는 것입니다.