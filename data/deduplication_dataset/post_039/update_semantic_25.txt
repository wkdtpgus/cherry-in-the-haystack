인공지능 분야는 최근 상당한 전환점을 맞이했습니다. 일부 학자들은 고도로 지능적인 인공지능 체계, 즉 지성체의 범람이 머지않은 미래가 아닌 코앞에 닥쳤다고 강조하고 있습니다. 이들은 흔히 범용 인공지능(AGI)을 거론하는데, 이는 인간 전문가의 지적 능력을 대부분의 영역에서 뛰어넘는 기계로 설명되지만, 그 개념 자체는 여전히 모호한 측면이 있습니다. 이들은 지능을 적재적소에 활용하는 능력이 사회 전반에 걸쳐 심대한 변화를 가져올 것이며, 그러한 변혁이 머지않아 현실이 될 것이라고 역설합니다. 아래에는 가까운 시일 내에 고성능 AI의 출현을 예견하는 AI 연구 기관 내부의 주요 인사들이 최근 밝힌 견해 중 일부가 제시됩니다.

업계 관계자들의 주장을 전적으로 신뢰하기 어려운 여러 근거가 존재합니다. 그들에게는 과감한 전망을 내놓을 명확한 유인이 있기 때문입니다. 이는 투자 유치, 기업 가치 증대, 또는 자신들의 역사적 역할을 스스로에게 각인시키려는 시도일 수 있습니다. 이들은 예언자가 아닌 기술 전문가이며, 과거 기술 예측의 역사는 실제 구현보다 수십 년 앞선 낙관적인 선언들로 채워져 있습니다. 이러한 인간적인 경향을 배제하더라도, 핵심 기술 자체에서 우리는 회의적인 시각을 가질 근거를 찾을 수 있습니다.

현존하는 거대 언어 모델(Large Language Models, LLM)들은 놀라운 역량을 보여주지만, 본질적으로 불균일한 성능을 보이는 도구로 남아 있습니다. 특정 과제에서는 탁월한 반면, 겉보기에 더 단순해 보이는 임무에서는 난항을 겪기도 합니다. 이러한 '불규칙한 최전선(jagged frontier)'은 현행 인공지능 시스템의 근본적인 속성이며, 단기간 내에 해소되기 어려울 것입니다.

더 나아가, 설령 연구진의 주장대로 1~2년 내에 범용 인공지능(AGI)이 현실화된다 할지라도, 그들은 인류가 새로운 기술을 수용하고 적응하는 속도를 과대평가하고 있을 공산이 큽니다. 조직 체계의 변혁은 상당한 시간을 요구합니다. 직무, 생활 방식, 교육 체계의 변화는 훨씬 더 더디게 진행됩니다. 또한, 기술이 사회 내에서 의미 있는 특정 활용처를 찾는 과정 역시 느리게 전개됩니다. 설령 지금 당장 범용 인공지능이 존재한다 해도, 대다수의 사람들은 이를 인지하지 못할 가능성이 높습니다(일부 분석가들은 클로드 3.5(Claude 3.5)와 같은 최신 AI 모델이 사실상 AGI에 해당한다고 주장하며, 이미 이러한 현상이 발생했음을 시사하기도 했습니다 1).

그렇다고 해서 이러한 전망을 단순히 과장된 주장으로 치부하는 것 또한 현명하지 않을 수 있습니다. 그들의 동기가 무엇이든 간에, AI 연구 기관 내의 과학자들과 기술자들은 이전에 없던 무언가가 나타나고 있음을 진심으로 확신하는 듯 보입니다. 단순히 그들의 확신만으로는 큰 의미를 부여하기 어렵습니다. 다만, 점차 공개되는 성능 평가(benchmark)와 시연 자료들이 그들이 인공지능 역량의 근본적인 전환점에 다다랐다고 믿는 이유를 시사하기 시작했다는 점은 주목할 만합니다. 요컨대, 변화의 물결이 예상보다 빠르게 밀려오고 있는 상황으로 보입니다.

**변화의 물결이 시작되는 곳**

가장 큰 관심을 모았던 소식은 작년 12월 말 OpenAI가 'o3'라는 새로운 인공지능 모델을 선보였다는 점입니다. OpenAI 외부에서는 아직 이 체계를 직접 경험한 이는 없지만, o3는 이미 상당한 성능을 보였던 'o1'의 계보를 잇는 후속 모델입니다 2. 'o3' 모델은 차세대 '추론 엔진(reasoner)'의 선두 주자 중 하나로 평가됩니다. 이 인공지능은 질문에 즉시 응답하기보다 '사고' 과정을 위해 추가적인 시간을 투입함으로써, 복잡한 난제를 해결하는 능력을 현저히 증진시켰습니다. OpenAI는 'o3'의 여러 인상적인 성능 평가(benchmark) 결과를 공개했는데, 이는 'o1'은 물론이고 기존 인공지능 분야의 최고 기술 수준(state-of-the-art)을 뛰어넘는 비약적인 발전을 보여줍니다. 특히 다음 세 가지 주요 평가 항목에 주목할 필요가 있습니다.

첫 번째는 '대학원 수준 구글-프루프 Q&A 테스트(Graduate-Level Google-Proof Q&A test, GPQA)'로 명명된 시험입니다. 이는 구글 검색으로도 해결하기 어려운 고도의 객관식 문항들로 구성되어, 심층적인 지식 수준을 측정하도록 고안되었습니다. 인터넷 접근이 가능한 박사 학위 소지자들은 이 시험에서 자신의 전공 외 분야 문제에 대해 34%, 전공 분야 문제에 대해서는 81%의 정답률을 기록했습니다. 반면 'o3'는 87%의 정답률을 달성하며 최초로 인간 전문가의 성과를 넘어섰습니다.

두 번째는 '프론티어 수학(Frontier Math)'이라는 비공개 수학 문제 묶음으로, 이는 전문 수학자들이 해결하기 극히 어렵도록 설계되었습니다. 실제로 'o3' 이전에는 그 어떤 인공지능도 2% 이상의 점수를 기록한 적이 없었으나, 'o3'는 25%의 정답률을 보였습니다.

마지막 성능 평가(benchmark)는 'ARC-AGI'입니다. 이 시험은 인간에게는 상대적으로 용이하지만 인공지능에게는 난해하게 고안된 유동성 지능(fluid intelligence) 측정의 저명한 도구입니다. 이번에도 'o3'는 87.5%라는 기록적인 수치를 달성하며, 기존의 모든 인공지능과 기준이 되는 인간의 능력을 초월했습니다.

이 모든 시험 결과에는 중요한 단서(caveat)가 수반되지만 3, 이는 우리가 과거에 인공지능 성능의 넘을 수 없는 한계라고 여겼던 것들이 실제로는 놀랍도록 빠르게 돌파될 수 있음을 보여줍니다. 이러한 '추론 엔진'의 등장은 단순한 패턴 인식에서 벗어나, AI가 문제의 본질을 이해하고 전략적으로 해결책을 모색하는 새로운 시대를 예고합니다. 기존 벤치마크의 한계와 데이터 오염 가능성에도 불구하고, 이러한 결과는 AI의 '창발적 능력(emergent abilities)'이 더 이상 이론적인 개념이 아님을 시사합니다. 이는 AI가 과학적 발견, 신약 개발과 같은 복잡한 영역에서도 예상치 못한 통찰력을 제공하며 인류의 지평을 넓힐 잠재력을 가지고 있음을 의미합니다.

**대행자(Agent)의 부상**

인공지능의 지능 수준이 향상되면서, 이들은 더욱 능률적인 '대행자(agent)'의 역할을 수행하게 됩니다. '대행자'는 여전히 정의가 불분명한 개념(이러한 경향이 반복되는 것을 느끼시나요?) 중 하나로, 통상적으로는 일련의 목표를 완수하기 위해 스스로 판단하고 행동할 수 있는 역량을 갖춘 인공지능을 지칭합니다. 이전 글에서 저는 초창기 대행자 시스템의 일부를 선보였지만, 최근 몇 주간의 진보는 특정 영역에 한정되지만 경제적으로 중요한 분야에서 실용적인 대행자 구현이 이제 가능하다는 것을 입증했습니다.

대표적인 사례는 구글의 '제미니(Gemini) 딥 리서치(Deep Research)'(제미니 구독자라면 누구나 접근 가능)로, 이는 사실상 전문화된 연구 보조 대행자입니다. 제가 '고성장 벤처를 위한 창업자의 관점에서 스타트업 자금 조달 방식 비교 연구'와 같은 주제를 제시하자, 이 대행자 시스템은 자체적으로 계획을 수립하고, 173개(놀랍게도!)의 웹사이트를 분석한 후, 단 몇 분 만에 저를 위한 보고서를 완성했습니다. 그 결과물은 118개의 참고 자료를 포함한 17페이지 분량의 상세 보고서였습니다!

그렇다면 그 품질은 어떠했을까요? 저는 10년 이상 와튼 스쿨에서 창업 기초 과정을 강의했고, 관련 주제로 논문을 발표했으며, 직접 회사를 설립하고 창업 관련 서적까지 집필한 경험이 있습니다. 이러한 배경에서 볼 때, 저는 이 보고서가 상당히 견고하다고 판단합니다. 명백한 오류는 발견되지 않았으며, 관심 있으신 분은 여기서 직접 확인하실 수 있습니다. 가장 큰 한계점은 정확성 자체보다는, 대행자가 접근할 수 있는 정보원이 대중에게 공개된 무료 웹사이트로 한정되어 있어 학술 저널이나 유료 구독 출판물에는 접근할 수 없다는 점입니다. 더불어, 내용은 다소 피상적이며 상반되는 증거가 있을 때 확고한 논지를 제시하는 데 어려움을 보입니다. 결과적으로 최고 수준의 인간 분석가만큼 뛰어나지는 않지만, 제가 접하는 수많은 일반적인 보고서보다는 우수했습니다. 그럼에도 불구하고, 이는 실질적인 가치를 지닌 대행자의 혁신적인 구현 사례로 평가됩니다.

조사 및 보고서 작성은 수많은 직업에서 핵심적인 업무에 해당합니다. '딥 리서치'가 3분 만에 이뤄낸 성과는 인간에게는 수시간이 소요될 일이었을 것이며, 물론 인간은 더 심층적인 분석을 덧붙일 수 있었을 것입니다. 이러한 점을 감안할 때, 연구 보고서 작성 업무에 종사하는 사람이라면 누구나 '딥 리서치'를 시도하여 초기 작업의 효율성을 확인해 볼 필요가 있습니다. 물론, 완성도 높은 최종 보고서를 위해서는 여전히 인간의 개입이 필수적이겠지만 말입니다. 저는 '딥 리서치' 프로젝트의 담당자와 대화할 기회가 있었고, 이 시스템이 단지 소규모 팀에서 진행하는 시범 프로젝트에 불과하다는 사실을 알게 되었습니다. 따라서 제한적이지만 효과적인 대행자를 구축하려는 강한 동기를 가진 다른 조직이나 기업들도 유사한 성과를 낼 수 있을 것이라고 예상합니다.

특정 분야에 특화된 '협소 에이전트(Narrow agent)'는 이제 미래의 잠재력이 아닌 현실의 제품으로 자리매김하고 있습니다. 이미 수많은 코딩 대행자가 활용되고 있으며, 과학 및 금융 연구를 수행하는 실험적인 오픈소스(open-source) 대행자들도 이용 가능합니다. 협소 에이전트는 특정 업무에 특화되어 있다는 점에서 다소 제약이 따릅니다. 이는 우리가 조만간 인공지능에게 어떠한 질문이든 던지면 컴퓨터와 인터넷을 활용하여 스스로 해결하는 '범용 대행자(generalist agent)'를 목격하게 될 것인지에 대한 의문을 제기합니다. 샘 알트만(Sam Altman)의 주장과는 달리, 사이먼 윌리슨(Simon Willison)은 이에 대해 회의적인 시각을 가지고 있습니다. 올해가 지나면서 더 많은 정보가 밝혀지겠지만, 만약 범용 대행자 시스템이 안정적이고 안전하게 운영될 수 있다면, 이는 지능형 인공지능이 현실 세계에서 직접적인 행동을 취할 수 있게 함으로써 실로 엄청난 변화를 가져올 것입니다.

협소 에이전트의 등장은 특정 직무 영역에 큰 파급효과를 가져올 것입니다. 예를 들어, 맞춤형 학습 대행자(personalized learning agents)는 개인의 학습 속도와 스타일에 맞춰 교육 콘텐츠를 제공하고, 의료 진단 보조 대행자(medical diagnostic assistants)는 방대한 의학 정보를 분석하여 의사의 진단을 돕는 역할을 할 수 있습니다. 자율 거래 봇(autonomous trading bots)은 금융 시장에서 복잡한 전략을 실행하며 효율성을 극대화할 것입니다. 그러나 이러한 대행자 시스템의 현실 세계 배포에는 안전성, 정렬(alignment), 그리고 예상치 못한 환경에 대한 견고성 확보라는 중대한 과제가 남아있습니다. ReAct, Reflexion, AutoGen과 같은 다양한 에이전트 아키텍처(architecture) 연구는 이러한 문제 해결을 위한 진보를 보여주지만, 윤리적 책임과 규제의 틀 속에서 자율적인 AI가 어떻게 작동해야 하는지에 대한 철학적 질문은 여전히 유효합니다.

**수많은 미세한 진전들**

대행자와 고성능 모델은 인공지능 혁신의 핵심 동력이지만, 이와 더불어 급속도로 발전하고 있는 수많은 다른 요소들도 존재합니다. 여기에는 인공지능이 기억할 수 있는 정보의 범위(컨텍스트 윈도우(context window)) 확장과 시각 및 청각 정보를 처리하여 소통할 수 있게 하는 다중 모드(multimodal) 기능의 발전이 포함됩니다. 현재의 진척 상황을 이해하기 위해 과거를 잠시 되돌아보는 것이 유용할 수 있습니다. 가령, 저는 챗GPT(ChatGPT)가 등장하기 이전부터 이미지 및 비디오 생성 모델에 '와이파이를 사용하는 비행기 위의 수달(otter on a plane using wifi)'이라는 지시어(prompt)를 사용하여 테스트해 왔습니다. 2023년 10월 당시에는 이 지시어가 다소 기괴한 결과물을 생성했습니다.

불과 18개월도 채 되지 않아, 다수의 이미지 생성 도구들이 이 지시어를 완벽하게 구현해냈습니다. 그 결과, 저는 더 도전적인 과제를 찾아야만 했습니다(이는 기존의 성능 평가(benchmark)가 인공지능에 의해 초월되는 '벤치마크 포화(benchmark saturation)' 현상의 한 예시입니다). 저는 잠시 시간을 할애하여 구글의 '비오(Veo)' 비디오 모델을 이용해 수달의 여정을 담은 영상을 얼마나 잘 만들 수 있는지 실험해 보기로 했습니다. 아래 영상 제작에는 15분 미만의 실제 작업 시간이 소요되었지만, 영상이 완성되기까지는 일정 대기 시간이 필요했습니다. 영상 속 그림자와 빛의 표현 품질을 주목해 주십시오. 특히 수달이 마지막에 컴퓨터를 조작하는 모습이 인상 깊었습니다. 나아가, 저는 이 수달 이야기를 1980년대 스타일의 공상 과학 애니메이션으로 각색하기로 결심했습니다. 우주를 유영하는 수달과 그 시대에 어울리는 주제곡(수노(Suno)의 도움으로)이 특징입니다. 이 작업 역시 (인간의) 개입은 거의 요구되지 않았습니다.

이러한 발전은 컨텍스트 윈도우의 비약적인 확장, 효율성 개선(예: 더 작은 모델, 빠른 추론 속도), 그리고 Mixtrue-of-Experts(MoE)와 같은 새로운 아키텍처의 도입 덕분입니다. 더불어, 데이터 큐레이션(data curation) 기술의 향상과 로봇 공학과의 통합 노력 또한 AI의 역량을 한층 끌어올리고 있습니다. 다중 모드 AI는 예술과 엔터테인먼트 분야에서 전에 없던 창의적 가능성을 열고 있습니다. AI가 생성하는 음악 비디오, 대화형 스토리텔링, 가상 세계는 인간의 상상력을 보완하며 새로운 형태의 미디어를 창조하고 있습니다. 그러나 이러한 기술 발전은 딥페이크(deepfake)와 잘못된 정보(misinformation) 확산이라는 심각한 도전 과제도 안고 있습니다. 인공지능이 생성한 콘텐츠의 진위 여부를 판별하고, 그 윤리적 사용을 보장하는 것은 기술 발전만큼이나 중요한 사회적 책임으로 부상하고 있습니다.

**지성의 홍수, 어떻게 대응할 것인가?**

이 모든 상황을 종합적으로 고려할 때, 인공지능 연구 기관들이 제기하는 '지성의 범람' 주장을 우리는 어느 정도로 심각하게 받아들여야 할까요? 우리가 이미 목격한 사실들, 즉 기존의 한계를 뛰어넘는 'o3'의 성능 평가(benchmark), 복잡한 조사를 수행하는 특정 영역의 대행자(narrow agent), 그리고 점차 정교한 콘텐츠를 만들어내는 다중 모드(multimodal) 시스템만 보더라도, 우리는 수많은 지식 기반 업무를 혁신할 잠재력을 인지하고 있습니다. 그럼에도 불구하고, 연구 기관들은 이러한 현상이 단지 서막에 불과하며, 훨씬 더 뛰어난 성능의 시스템과 범용 대행자(general agent)의 출현이 임박했다고 역설합니다.

제가 가장 크게 우려하는 점은 연구 기관들이 제시하는 시간 계획(timeline)이 정확한지 여부가 아닙니다. 그들의 주장이 옳을 가능성은 차치하고라도, 현재 인공지능의 역량 수준에 대해서조차 우리가 충분히 준비되어 있지 않다는 사실입니다. 인공지능 연구자들은 시스템이 윤리적이고 책임감 있게 작동하도록 보장하는 '정렬(alignment)' 문제에 집중하고 있지만, 인공지능이 충만한 미래 세계가 실제로 어떤 양상일지 상상하고 구체적으로 그려내려는 노력은 상대적으로 미흡합니다. 이는 단순히 기술 그 자체만의 문제가 아닙니다. 우리가 이 기술을 어떻게 형성하고 어디에 배치할지를 선택하는 방식에 대한 문제입니다. 이러한 질문들은 오직 인공지능 개발자들만이 답할 수 있거나 답해야 하는 영역이 아닙니다. 이러한 전환기를 헤쳐나가야 할 조직의 리더들, 업무 환경에 변화를 겪을 수 있는 임직원들, 그리고 미래가 이 결정에 좌우될 수 있는 모든 이해관계자들의 적극적인 관심을 요구하는 사안들입니다.

다가올 수 있는 지성체의 범람은 본질적으로 선하거나 악한 것이 아닙니다. 그러나 우리가 이를 어떻게 준비하고, 어떻게 적응하며, 가장 중요하게는 어떻게 활용할지를 선택하는 방식이 그것이 발전의 원동력이 될지 아니면 혼돈의 근원이 될지를 좌우할 것입니다. 이러한 논의를 시작해야 할 시점은 변화의 물결이 이미 닥친 후가 아니라, 바로 지금입니다.

인공지능 거버넌스(AI governance)의 확립은 이러한 변화를 책임감 있게 관리하기 위한 필수적인 요소입니다. 인공지능의 라이선싱(licensing), 규제 샌드박스(regulatory sandboxes) 도입, 그리고 국제적인 협력 체계 구축과 같은 다양한 정책적 제안들이 논의되고 있습니다. 대중 교육과 미디어 리터러시(media literacy)의 강화 또한 인공지능 시대에 대비하는 중요한 축입니다. 인공지능 기술의 작동 원리, 잠재적 위험, 그리고 사회적 영향에 대한 이해를 높이는 것은 시민들이 정보에 입각한 판단을 내리고 기술 발전에 적극적으로 참여할 수 있도록 돕습니다. 또한, 일자리 대체에 대한 우려를 완화하고 생산성을 향상시키기 위해 '인간-AI 협업(human-AI collaboration)' 모델을 적극적으로 탐색해야 합니다. 이는 AI가 인간의 능력을 보완하고 확장하는 도구로 기능하도록 설계하는 것을 의미합니다. 이러한 복합적인 과제들은 단순히 기술 전문가만의 영역이 아니라, 사회학자, 철학자, 정책 입안자, 교육자 등 다양한 분야의 전문가들이 함께 머리를 맞대고 해결해야 할 문제입니다. 인공지능의 미래는 기술적 진보만큼이나 사회적 합의와 현명한 선택에 달려 있습니다.

구독 공유

1 저는 클로드(Claude)에게 완성된 문서를 읽고 피드백을 달라고 요청했고, 클로드는 다음과 같이 썼습니다: "클로드 3.5(Claude 3.5)에 대한 괄호 안의 언급은 잠재적인 AGI의 예시로 언급되었으므로 업데이트 또는 수정의 이점을 얻을 수 있습니다. 클로드 3.5 소네트(Claude 3.5 Sonnet)로서, 저는 AGI와 관련하여 제 능력에 대한 특정 주장을 확인할 수 없다는 점을 말씀드립니다."
2 그들은 o2라는 이름을 건너뛰었는데, 이는 영국에 있는 전화 회사의 이름이기 때문입니다. AI 명명은 여전히 매우 좋지 않습니다.
3 GPQA에 대한 단서(caveat)는 데이터가 공개적으로 이용 가능하며, 모델이 우연히든 의도적으로든 해당 데이터로 훈련되었을 가능성이 있다는 것입니다. 비록 그렇게 했다는 징후는 없지만 말입니다. 프론티어 수학(Frontier Math) 테스트의 단서(caveat)는 문제의 난이도가 다르다는 것입니다. 1단계(Tier 1)는 어려운 수학 올림피아드 문제이고, 2단계(Tier 2)는 대학원 수준 문제이며, 3단계(Tier 3)는 진정한 연구 수준 문제입니다. o3의 정답에 대해 책임 있는 수학자의 말에 따르면: "40%는 1단계, 50%는 2단계, 10%는 3단계였습니다. 그러나 대부분의 3단계 '해결책'과 많은 2단계 해결책은 진정한 수학적 이해보다는 발견적 지름길(heuristic shortcut)에서 비롯되었습니다." ARC-AGI에 대한 단서(caveat)는 o3가 높은 점수를 달성하기 위해 충분히 오래 실행하는 데 매우 비싼 컴퓨터 시간(compute time)이 많이 필요했다는 것입니다.