**LangSmith로 AI 에이전트의 블랙박스를 해제하다: 심층 트레이싱 가이드**

AI 에이전트(agent)를 구축하면서 내부에서 실제로 무슨 일이 일어나는지 궁금했던 적이 있으신가요? 에이전트가 실패하거나 예상치 못한 결과를 생성할 때, 디버깅(debugging)은 마치 블랙박스(black box)를 조사하는 것처럼 느껴질 수 있습니다. 바로 이때 LangSmith 트레이싱(tracing)이 매우 중요해집니다. 이 튜토리얼에서는 웹에서 레시피(recipe) 정보를 검색하고 개인화된 요리 가이드를 생성하는 레시피 검색 에이전트(Recipe Discovery Agent)를 구축할 것입니다. 더 중요하게는, LangSmith 트레이싱을 사용하여 에이전트 실행의 모든 단계를 관찰하고, 그 블랙박스를 투명하고 디버깅 가능한 시스템으로 전환할 것입니다.

최근 LLM 기반 애플리케이션의 복잡성이 증가하면서, 단순히 코드를 작성하는 것을 넘어 시스템의 동작을 깊이 이해하는 것이 필수적이 되었습니다. 에이전트가 예상치 못한 결과를 도출하거나, 성능 저하를 겪을 때, 문제가 발생하는 정확한 지점을 식별하는 것은 매우 어려운 일입니다. 이때 LangSmith의 심층적인 관측 가능성(observability) 기능이 빛을 발합니다. 이는 개발자가 에이전트의 내부 로직을 시각화하고, 각 구성 요소의 상호작용을 분석하며, 궁극적으로 더 안정적이고 효율적인 AI 애플리케이션을 구축할 수 있도록 돕습니다.

**목차:**
*   에이전트 아키텍처(Agent Architecture) 심층 분석
*   LangSmith 트레이싱 설정 및 프로젝트 관리
*   LLM 클라이언트(Client) 래핑(Wrapping)의 중요성
*   추적 가능한 함수(Traceable Functions) 구축 및 활용
*   심화 트레이싱 기법 및 활용
*   LangSmith를 통한 지속적인 개선

대규모 언어 모델(LLM) 위에 애플리케이션(application)을 구축해 본 경험이 있다면, 그 어려움을 잘 아실 것입니다. 문제가 발생했을 때, 단순한 버그(bug)인 경우는 거의 없습니다. 대신, 복잡한 실행 트리(run tree)를 통해 단일 사용자 상호작용을 추적하거나, 모델이 왜 올바르게 추론하지 못했는지 이해하기 위해 수많은 비정형 대화 속에서 의미를 찾으려 노력하게 됩니다. 그 논리를 디버깅하고 성능을 지속적으로 개선하는 방법을 알아내는 것은 종종 반복 가능한 과학이라기보다는 예측 불가능한 예술처럼 느껴질 수 있습니다. 바로 이 지점에서 LangSmith가 등장합니다. LangSmith는 전체 LLM 개발 수명 주기(lifecycle)를 위해 설계되었으며, 일반적인 가정을 뒤엎는 몇 가지 근본적인 원칙을 제시합니다.

LangSmith는 관측 가능성(observability)과 같은 필수 기능을 제공하며, 여기에는 자동화된 트레이싱(tracing) 및 디버깅(debugging)을 위한 실행 트리(run tree) 보기, 비용이 많이 드는 단계 식별, 지연 시간 병목 현상(latency bottlenecks) 분석과 같은 기능이 포함됩니다. 또한, 이 플랫폼은 평가(evaluation) 및 실험(experimentation)을 지원하여 사용자가 사용자 지정 평가자(custom evaluators)를 정의하고, 선별된 데이터셋(datasets)으로 체계적인 테스트(testing)를 수행하며, 아키텍처(architectural) 변경의 장단점(trade-offs)을 평가하기 위해 실험 결과를 나란히 비교할 수 있도록 합니다.

이 시리즈는 다음 주제를 다룰 것입니다:
*   LangSmith란 무엇인가? (게시됨!)
*   LangSmith로 트레이싱하기 (현재 보고 계신 글)
*   LangSmith의 플레이그라운드(Playground) 및 프롬프트(Prompts)
*   LangSmith의 데이터셋(Datasets) 및 평가(Evaluations)
*   LangSmith의 주석 큐(Annotation Queues)
*   LangSmith의 자동화(Automations) 및 온라인 평가(Online Evaluation)
*   LangSmith의 대시보드(Dashboards)

**1. 에이전트 아키텍처(Agent Architecture) 심층 분석**

저희 레시피 에이전트는 간단한 두 단계의 파이프라인(pipeline)을 따릅니다. 먼저, DuckDuckGo를 사용하여 웹에서 레시피 정보를 수집합니다. 그런 다음, 이 정보를 언어 모델(language model)에 전달하여 모든 것을 유용한 요리 가이드로 형식화합니다. 개념은 간단하지만, 이 파이프라인을 통해 데이터(data)가 어떻게 흐르는지 관찰하면 성능, 비용 및 잠재적인 개선 사항에 대한 중요한 통찰력을 얻을 수 있습니다.

이러한 모듈식 아키텍처는 LLM 기반 애플리케이션에서 흔히 볼 수 있는 패턴입니다. 정보 검색(Information Retrieval), 응답 생성(Response Generation), 그리고 경우에 따라서는 사용자 피드백 처리(User Feedback Processing)와 같은 명확한 단계를 분리함으로써, 각 단계의 책임이 명확해지고 디버깅 및 최적화가 용이해집니다. 예를 들어, 검색 결과가 부적절하다면 정보 검색 단계의 문제임을, 검색된 정보는 좋지만 최종 가이드가 부실하다면 응답 생성 단계의 문제임을 쉽게 파악할 수 있습니다. LangSmith는 이러한 각 단계를 독립적인 '스팬(span)'으로 시각화하여, 데이터 흐름과 병목 현상을 한눈에 파악할 수 있도록 돕습니다.

**2. LangSmith 트레이싱 설정 및 프로젝트 관리**

에이전트 코드(code)에 들어가기 전에 LangSmith를 올바르게 구성해야 합니다. 여기서 작업 순서는 매우 중요합니다. LangChain 라이브러리(libraries)를 임포트(import)하기 전에 환경 변수(environment variables)를 설정해야 합니다. 그렇지 않으면 트레이싱이 제대로 초기화되지 않습니다.

```python
import os
from google.colab import userdata

# Set environment variables FIRST
os.environ[”LANGSMITH_TRACING”] = “true”
os.environ[”LANGSMITH_ENDPOINT”] = “https://api.smith.langchain.com”
os.environ[”LANGSMITH_PROJECT”] = “recipe-discovery-agent”
os.environ[”LANGSMITH_API_KEY”] = userdata.get(”LANGSMITH_API_KEY”)
OPENROUTER_API_KEY = userdata.get(’OPENROUTER_API_KEY’)
```

`LANGSMITH_TRACING`을 "true"로 설정함으로써, LangSmith에게 에이전트로부터 실행 데이터(execution data)를 자동으로 수집하도록 지시하는 것입니다. `LANGSMITH_PROJECT` 이름은 이러한 트레이스(traces)가 대시보드(dashboard)에 어디에 나타날지 결정하여, 다양한 실험(experiments)이나 애플리케이션(applications)을 더 쉽게 정리할 수 있도록 합니다. 예를 들어, 개발 단계, 프로덕션 단계, 또는 특정 기능별로 프로젝트를 분리하여 관리할 수 있습니다. 이는 복잡한 시스템에서 트레이스를 체계적으로 분류하고 분석하는 데 매우 유용합니다.

이 에이전트의 경우, 저는 더 전문화된 API(API) 대신 DuckDuckGo 검색을 선택했습니다. 그 이유는 실용적입니다. DuckDuckGo는 API 키(key)가 필요 없으므로 튜토리얼(tutorials) 및 실험에 완벽합니다. 이는 우리의 필요에 잘 맞는 구조화된 검색 결과(structured search results)를 반환합니다.

```python
from langchain_community.tools import DuckDuckGoSearchResults
search_tool = DuckDuckGoSearchResults(max_results=3)
```

DuckDuckGo가 이 데모(demo)에 훌륭하지만, 실제 운영 환경(production) 애플리케이션은 Tavily Search(AI에 최적화된 결과 제공) 또는 Wikipedia(더 백과사전적인 정보 제공)와 같은 대안으로부터 이점을 얻을 수 있습니다. LangChain의 도구 추상화(tool abstraction)의 장점은 나중에 이들을 교체할 때 최소한의 코드 변경만 필요하다는 것입니다. 또한, `LANGSMITH_API_KEY`는 보안상 중요한 정보이므로, `userdata.get()`과 같은 안전한 방식으로 관리하는 것이 좋습니다.

**3. LLM 클라이언트(Client) 래핑(Wrapping)의 중요성**

이제 흥미로운 부분이 시작됩니다. 단순히 LLM을 호출하는 것만으로는 LangSmith에서 상세한 트레이스(traces)를 얻을 수 없습니다. LangSmith의 `wrap_openai` 함수(function)로 클라이언트(client)를 래핑(wrap)해야 합니다. 이 래퍼(wrapper)는 모든 API 호출을 가로채고 전체 프롬프트(prompt), 응답(response), 토큰(token) 개수, 타이밍(timing) 정보를 포함한 완전한 상호작용을 기록합니다.

```python
from langsmith.wrappers import wrap_openai
from openai import OpenAI

openrouter_client = wrap_openai(
    OpenAI(
        base_url=”https://openrouter.ai/api/v1”,
        api_key=OPENROUTER_API_KEY,
    )
)
```

이 래퍼가 없으면, 트레이스에는 함수가 LLM을 호출했다는 것만 표시되고 실제로 무엇이 전송되거나 수신되었는지는 볼 수 없을 것입니다. 이러한 가시성(visibility)은 프롬프트 문제(prompt issues)를 디버깅하거나 토큰 사용량(token usage)을 최적화할 때 매우 중요해집니다. `wrap_openai`는 OpenAI API뿐만 아니라 OpenAI 호환 API(OpenRouter와 같이)에도 적용될 수 있습니다. LangChain은 또한 Anthropic, Google Gemini 등 다른 주요 LLM 제공업체를 위한 유사한 래퍼를 제공하여, 어떤 모델을 사용하든 일관된 트레이싱 경험을 제공합니다. 이 래핑 프로세스는 LLM 호출의 컨텍스트(context)를 LangSmith로 전파하여, 실행 트리의 특정 지점에서 어떤 LLM이 어떤 인풋으로 호출되었는지 정확히 파악할 수 있게 합니다.

**4. 추적 가능한 함수(Traceable Functions) 구축 및 활용**

LangSmith의 마법은 `@traceable` 데코레이터(decorator)를 통해 일어납니다. `@traceable`로 장식된 모든 함수는 입력(inputs), 출력(outputs), 실행 시간(execution time) 및 호출 계층(call hierarchy) 내에서의 위치를 자동으로 기록합니다. 에이전트의 각 함수를 살펴보겠습니다.

`@traceable` 데코레이터는 복잡한 에이전트의 내부 동작을 시각적으로 이해하는 데 핵심적인 역할을 합니다. 이는 단순히 함수 호출을 기록하는 것을 넘어, 각 호출을 독립적인 '스팬(span)'으로 간주하고, 이 스팬들을 부모-자식 관계를 가진 '실행 트리(run tree)'로 구성합니다. 이를 통해 어떤 함수가 어떤 함수를 호출했고, 각 단계에서 어떤 데이터가 전달되었으며, 얼마나 많은 시간이 소요되었는지를 직관적으로 파악할 수 있습니다.

**레시피 검색 함수 예시**

예를 들어, 우리의 레시피 에이전트에서 검색 도구를 사용하는 함수를 `@traceable`로 장식할 수 있습니다.

```python
from langsmith import traceable

@traceable
def search_for_recipes(query: str, num_results: int = 3) -> str:
    """사용자 쿼리를 기반으로 레시피를 검색하고 결과를 반환합니다."""
    print(f"레시피 검색 중: {query}")
    results = search_tool.run(query)
    print(f"검색 결과: {len(results)}개")
    return results

@traceable
def generate_cooking_guide(recipe_info: str, user_preference: str) -> str:
    """검색된 레시피 정보와 사용자 선호도를 바탕으로 요리 가이드를 생성합니다."""
    print("요리 가이드 생성 중...")
    prompt = f"""다음 레시피 정보를 바탕으로 사용자의 선호도('{user_preference}')에 맞춰 상세한 요리 가이드를 작성해주세요:
    {recipe_info}
    """
    response = openrouter_client.chat.completions.create(
        model="google/gemini-pro",
        messages=[{"role": "user", "content": prompt}]
    )
    guide = response.choices[0].message.content
    print("요리 가이드 생성 완료.")
    return guide

@traceable
def recipe_discovery_agent(user_query: str, user_preference: str) -> str:
    """레시피 검색 및 요리 가이드 생성을 통합하는 에이전트 메인 함수."""
    search_results = search_for_recipes(user_query)
    final_guide = generate_cooking_guide(search_results, user_preference)
    return final_guide

# 에이전트 실행 예시
# final_output = recipe_discovery_agent("쉬운 저녁 식사", "건강하고 빠르게 만들 수 있는")
# print(final_output)
```

위 예시에서 `recipe_discovery_agent`, `search_for_recipes`, `generate_cooking_guide` 함수 모두 `@traceable`로 장식되어 있습니다. 이 에이전트를 실행하면 LangSmith 대시보드에 `recipe_discovery_agent`가 루트(root) 스팬으로 표시되고, 그 아래에 `search_for_recipes`와 `generate_cooking_guide`가 자식 스팬으로 계층적으로 나타나게 됩니다. 각 스팬을 클릭하면 해당 함수의 입력, 출력, 실행 시간, LLM 호출 정보(프롬프트, 응답, 토큰 사용량) 등 상세한 정보를 확인할 수 있습니다.

**5. 심화 트레이싱 기법 및 활용**

`@traceable` 데코레이터는 강력하지만, 더 풍부한 트레이스 정보를 위해 추가적인 기능을 활용할 수 있습니다.

*   **커스텀 스팬(Custom Spans) 및 태그(Tags):** 특정 코드 블록을 명시적으로 스팬으로 만들거나, 스팬에 메타데이터(metadata)를 추가하여 필터링 및 분석을 용이하게 할 수 있습니다. 예를 들어, `@traceable(name="데이터 전처리", tags=["preprocessing", "단계1"])`와 같이 정의하여 스팬의 목적을 명확히 하고, 관련 태그로 그룹화할 수 있습니다.
*   **에러 핸들링 및 디버깅:** 트레이스 내에서 에러가 발생하면 LangSmith는 이를 명확히 표시하고, 관련 스택 트레이스(stack trace)를 기록합니다. 이를 통해 문제가 발생한 정확한 위치와 원인을 빠르게 파악할 수 있습니다. 특히 LLM 호출 실패, 도구 실행 오류 등 복합적인 에이전트 에러를 디버깅할 때 매우 효과적입니다.
*   **성능 최적화와 비용 분석:** 각 스팬의 실행 시간과 LLM 호출의 토큰 사용량 정보는 성능 병목 현상과 비용이 많이 드는 단계를 식별하는 데 중요합니다. LangSmith 대시보드에서 이러한 지표를 시각적으로 확인하고, 특정 단계의 지연 시간이 길거나 토큰 사용량이 과도한 경우 해당 부분을 최적화하는 데 집중할 수 있습니다.

**6. LangSmith를 통한 지속적인 개선**

LangSmith는 단순히 디버깅 도구를 넘어, LLM 애플리케이션의 지속적인 개선을 위한 플랫폼입니다.

*   **평가(Evaluation)와의 연동:** 트레이싱된 실행 데이터는 LangSmith의 평가 모듈로 직접 연결될 수 있습니다. 개발자는 실제 사용자 상호작용 또는 테스트 데이터셋에 대한 에이전트의 실행 트레이스를 수집하고, 이를 바탕으로 자동화된 평가자(evaluator)나 수동 주석(annotation)을 통해 에이전트의 성능을 정량적으로 측정할 수 있습니다. 예를 들어, 검색된 레시피의 관련성이나 생성된 가이드의 유용성 등을 평가하여 에이전트의 약점을 파악하고 개선 방향을 설정할 수 있습니다.
*   **운영 환경(Production) 모니터링:** 에이전트가 운영 환경에 배포된 후에도 LangSmith 트레이싱은 지속적인 모니터링 기능을 제공합니다. 실시간으로 에이전트의 성능 지표(지연 시간, 에러율, 토큰 사용량)를 추적하고, 예상치 못한 동작이나 성능 저하가 발생했을 때 즉시 알림을 받을 수 있습니다. 이를 통해 문제 발생 시 빠르게 대응하고, 사용자 경험에 미치는 영향을 최소화할 수 있습니다.

결론적으로, LangSmith 트레이싱은 LLM 기반 에이전트 개발의 필수적인 부분입니다. 이는 단순한 디버깅을 넘어, 에이전트의 복잡한 내부 동작을 투명하게 공개하고, 성능을 최적화하며, 지속적인 개선을 위한 데이터 기반의 통찰력을 제공합니다. LangSmith를 활용하여 여러분의 AI 에이전트를 더욱 견고하고 효율적으로 만들어 보세요.