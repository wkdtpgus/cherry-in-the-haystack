**AI 에이전트 내부를 들여다보기: LangSmith 트레이싱으로 블랙박스 해소하기**

인공지능 에이전트를 개발하다 보면, 그 내부 작동 방식에 대해 호기심을 느낄 때가 많습니다. 특히 에이전트가 오작동하거나 예상과 다른 출력을 낼 때, 문제 해결 과정은 마치 미지의 상자를 들여다보는 것처럼 막막하게 느껴질 수 있습니다. 이러한 상황에서 LangSmith의 트레이싱 기능은 개발자에게 필수적인 도구가 됩니다. 본 튜토리얼에서는 웹에서 레시피 정보를 찾아 개인화된 요리 가이드를 만드는 '레시피 발견 에이전트(Recipe Discovery Agent)'를 구축할 예정입니다. 더 나아가, LangSmith 트레이싱을 활용하여 에이전트 실행의 모든 단계를 면밀히 관찰하고, 그 불투명했던 시스템을 투명하고 디버깅 가능한 구조로 전환하는 방법을 보여드릴 것입니다.

**목차:**
*   에이전트 아키텍처(Agent Architecture)
*   LangSmith 트레이싱 설정
*   LLM 클라이언트(Client) 래핑(Wrapping)
*   추적 가능한 함수(Traceable Functions) 구축
*   트레이싱 결과 관찰 및 이해
*   결론

거대 언어 모델 기반의 애플리케이션을 개발해 본 이들이라면, 그 과정의 난해함을 익히 알고 있을 것입니다. 오류가 발생하더라도 이는 흔히 단순한 결함이 아닙니다. 오히려 하나의 사용자 요청에 대한 복잡한 실행 흐름을 쫓거나, 모델이 왜 정확한 추론을 하지 못했는지 파악하기 위해 방대한 비정형 상호작용 기록에서 실마리를 찾아야 하는 경우가 허다합니다. 이러한 논리적 오류를 해결하고 성능을 지속적으로 향상시키는 작업은 종종 예측 불가능한 예술처럼 느껴지곤 합니다. 바로 이 시점에서 LangSmith가 강력한 해결책으로 등장합니다. LangSmith는 전체 LLM 개발 수명 주기(lifecycle)를 염두에 두고 설계되었으며, 기존의 개발 방식에 대한 몇 가지 근본적인 변화를 제안합니다.

LangSmith는 개발 과정에서 필수적인 관측 가능성(observability)을 제공합니다. 여기에는 자동화된 추적(tracing) 및 디버깅(debugging)을 위한 상세한 실행 트리(run tree) 시각화가 포함되어, 시스템 내에서 비용이 많이 드는 구성 요소를 식별하고, 잠재적인 지연 시간 병목 현상(latency bottlenecks)을 정밀하게 분석할 수 있도록 돕습니다. 또한, 이 플랫폼은 모델의 성능을 체계적으로 평가하고 다양한 실험을 수행할 수 있는 환경을 지원합니다. 사용자는 자신만의 맞춤형 평가 기준(custom evaluators)을 정의하고, 엄선된 데이터셋(datasets)으로 반복적인 테스트(testing)를 진행하며, 아키텍처(architectural) 변경이 가져올 장단점(trade-offs)을 명확히 파악하기 위해 여러 실험 결과를 나란히 비교 분석할 수 있습니다.

이 시리즈는 다음 주제를 다룰 것입니다:
*   LangSmith란 무엇인가? (게시됨!)
*   LangSmith로 트레이싱하기 (현재 보고 계신 글)
*   LangSmith의 플레이그라운드(Playground) 및 프롬프트(Prompts)
*   LangSmith의 데이터셋(Datasets) 및 평가(Evaluations)
*   LangSmith의 주석 큐(Annotation Queues)
*   LangSmith의 자동화(Automations) 및 온라인 평가(Online Evaluation)
*   LangSmith의 대시보드(Dashboards)

유세프 호스니 · 6월 17일

**1. 에이전트 아키텍처(Agent Architecture)**

본 레시피 에이전트의 구조는 두 가지 주요 단계로 구성된 간결한 흐름을 따릅니다. 초기 단계에서는 DuckDuckGo를 활용하여 웹상에서 필요한 레시피 데이터를 탐색하고 수집합니다. 이후, 이렇게 얻은 정보는 언어 모델로 전달되어 사용자가 활용하기 편리한 요리 안내서 형태로 정리됩니다. 이처럼 개념적으로는 단순한 파이프라인이지만, 데이터(data)가 각 단계를 거치며 어떻게 변환되고 흐르는지 면밀히 관찰하는 것은 에이전트의 성능, 운영 비용, 그리고 잠재적인 개선 영역에 대한 깊이 있는 통찰력을 제공합니다. 모듈화된 아키텍처는 각 구성 요소의 역할을 명확히 하고, 문제 발생 시 원인 분석을 용이하게 합니다.

**2. LangSmith 트레이싱 설정**

에이전트의 실제 구현에 앞서, LangSmith를 정확하게 설정하는 과정이 필수적입니다. 이 과정에서 설정 순서는 매우 결정적인 역할을 합니다. 특히 LangChain 관련 모듈을 불러오기 전에 반드시 관련 환경 변수들을 먼저 지정해야 합니다. 이 순서를 지키지 않으면 추적 기능이 올바르게 활성화되지 않을 수 있습니다. `LANGSMITH_PROJECT` 변수를 통해 프로젝트 이름을 명확히 지정하는 것은 다양한 실험이나 애플리케이션의 추적 데이터를 대시보드에서 효율적으로 분류하고 관리하는 데 도움을 줍니다.

```python
import os
from google.colab import userdata

# Set environment variables FIRST
os.environ["LANGSMITH_TRACING"] = "true"
os.environ["LANGSMITH_ENDPOINT"] = "https://api.smith.langchain.com"
os.environ["LANGSMITH_PROJECT"] = "recipe-discovery-agent"
os.environ["LANGSMITH_API_KEY"] = userdata.get("LANGSMITH_API_KEY")
OPENROUTER_API_KEY = userdata.get('OPENROUTER_API_KEY')
```

`LANGSMITH_TRACING`을 "true"로 설정함으로써, LangSmith에게 에이전트의 실행 데이터를 자동으로 수집하도록 명시적으로 지시하는 것입니다. 이 예제에서는 DuckDuckGo 검색을 사용했는데, 이는 특정 API 키(key)가 필요 없어 튜토리얼이나 초기 실험에 매우 적합하기 때문입니다. DuckDuckGo는 우리의 요구사항에 맞는 구조화된 검색 결과(structured search results)를 제공합니다.

```python
from langchain_community.tools import DuckDuckGoSearchResults
search_tool = DuckDuckGoSearchResults(max_results=3)
```

DuckDuckGo가 이 데모(demo)에 훌륭한 선택이지만, 실제 운영 환경(production) 애플리케이션에서는 Tavily Search(AI에 최적화된 결과 제공) 또는 Wikipedia(더 백과사전적인 정보 제공)와 같은 다른 대안을 고려할 수 있습니다. LangChain의 도구 추상화(tool abstraction)는 이러한 도구들을 나중에 교체하더라도 최소한의 코드 변경만으로 가능하게 하여 유연성을 극대화합니다. 특정 사용 사례에 따라 가장 적합한 도구를 선택하는 것이 중요하며, LangSmith는 각 도구의 성능을 비교 분석하는 데 도움을 줄 수 있습니다.

**3. LLM 클라이언트(Client) 래핑(Wrapping)**

단순히 대규모 언어 모델을 호출하는 방식만으로는 LangSmith에서 정교한 추적 기록을 확보하기 어렵습니다. 따라서 LangSmith가 제공하는 `wrap_openai` 함수를 활용하여 LLM 클라이언트를 감싸는 과정이 필요합니다. 이 래퍼는 모든 API 통신을 중간에서 포착하여, 전송된 프롬프트, 수신된 응답, 사용된 토큰의 양, 그리고 각 단계별 소요 시간 등 상호작용의 모든 세부 정보를 빠짐없이 기록합니다. 이러한 래핑(wrapping)은 프롬프트 엔지니어링이나 모델 변경 시 각 버전의 성능을 비교하는 A/B 테스트(A/B testing)를 수행할 때 특히 유용합니다.

```python
from langsmith.wrappers import wrap_openai
from openai import OpenAI

openrouter_client = wrap_openai(
    OpenAI(
        base_url="https://openrouter.ai/api/v1",
        api_key=OPENROUTER_API_KEY,
    )
)
```

이러한 래퍼가 없다면, 추적 기록에는 단지 함수가 LLM을 호출했다는 사실만 표시될 뿐, 실제로 어떤 내용이 전송되고 수신되었는지에 대한 상세한 가시성(visibility)은 얻을 수 없을 것입니다. 이러한 가시성은 프롬프트 문제(prompt issues)를 신속하게 디버깅하거나, 토큰 사용량(token usage)을 최적화하여 비용을 절감하는 데 결정적인 역할을 합니다.

**4. 추적 가능한 함수(Traceable Functions) 구축**

LangSmith의 핵심적인 기능은 `@traceable` 데코레이터를 통해 구현됩니다. 이 데코레이터가 적용된 모든 함수는 해당 함수의 인풋, 아웃풋, 소요된 실행 시간, 그리고 전체 호출 구조 내에서의 위치 정보를 자동으로 추적하고 기록합니다. 이제 에이전트의 핵심 함수들을 `@traceable`로 만들어 LangSmith가 어떻게 작동하는지 살펴보겠습니다.

**레시피 검색 및 가이드 생성**

먼저, 웹에서 레시피 정보를 검색하는 함수를 정의합니다. 이 함수는 `search_tool`을 사용하여 DuckDuckGo에서 관련 내용을 가져옵니다.

```python
from langsmith import traceable

@traceable
def fetch_recipe_data(query: str) -> str:
    """주어진 쿼리에 대해 웹에서 레시피 정보를 검색합니다."""
    search_results = search_tool.run(f"레시피 {query}")
    return search_results

@traceable
def format_recipe_guide(recipe_info: str, user_preference: str) -> str:
    """검색된 레시피 정보와 사용자 선호도를 바탕으로 요리 가이드를 생성합니다."""
    prompt = f"""
    다음 레시피 정보를 바탕으로 사용자의 선호도('{user_preference}')를 고려한 요리 가이드를 작성해주세요.
    레시피 정보: {recipe_info}

    가이드는 다음을 포함해야 합니다:
    1. 요리 이름
    2. 필요한 재료
    3. 간단한 조리법
    4. 팁 (선택 사항)
    """
    messages = [{"role": "user", "content": prompt}]
    
    response = openrouter_client.chat.completions.create(
        model="mistralai/mistral-7b-instruct",
        messages=messages,
        temperature=0.7,
    )
    return response.choices[0].message.content

@traceable
def run_recipe_agent(query: str, preference: str) -> str:
    """레시피 검색 에이전트의 전체 실행 흐름을 담당합니다."""
    raw_data = fetch_recipe_data(query)
    final_guide = format_recipe_guide(raw_data, preference)
    return final_guide

# 에이전트 실행 예시
# result = run_recipe_agent("김치찌개", "간단하고 빠르게 만들 수 있도록")
# print(result)
```

`@traceable` 데코레이터 덕분에 `fetch_recipe_data`, `format_recipe_guide`, 그리고 `run_recipe_agent` 함수가 호출될 때마다 LangSmith는 자동으로 실행 정보를 기록합니다. 이는 각 함수의 입력과 출력, 소요 시간, 그리고 전체 에이전트 실행 내에서의 호출 관계를 파악하는 데 결정적인 역할을 합니다.

**5. 트레이싱 결과 관찰 및 이해**

LangSmith 대시보드에 접속하면 `recipe-discovery-agent` 프로젝트 아래에 방금 실행된 트레이스(trace)가 나타날 것입니다. 각 트레이스를 클릭하면 상세한 실행 트리(run tree)를 볼 수 있습니다. 이 트리는 다음과 같은 정보를 포함합니다:

*   **스팬(Spans)**: `@traceable` 함수 호출, LLM 호출, 도구 사용 등 각 작업 단위를 나타냅니다.
*   **입력 및 출력(Inputs & Outputs)**: 각 스팬에 전달된 입력과 반환된 출력을 확인할 수 있습니다. 이를 통해 데이터가 각 단계를 거치면서 어떻게 변형되는지 추적할 수 있습니다.
*   **지연 시간(Latency)**: 각 스팬이 실행되는 데 걸린 시간을 시각적으로 보여주어, 성능 병목 현상을 쉽게 식별할 수 있습니다.
*   **토큰 사용량(Token Usage)**: LLM 호출의 경우, 사용된 프롬프트 및 응답 토큰 수를 확인할 수 있어 비용 분석에 도움이 됩니다.
*   **오류(Errors)**: 특정 단계에서 오류가 발생하면, 해당 스팬에 오류 정보가 기록되어 신속한 문제 해결을 돕습니다.

이러한 시각화된 정보를 통해 개발자는 에이전트의 복잡한 실행 흐름을 한눈에 파악하고, 특정 단계에서 왜 예상과 다른 결과가 나왔는지, 또는 왜 성능이 저하되었는지를 정확하게 진단할 수 있습니다. 예를 들어, `fetch_recipe_data`에서 검색 결과가 불충분하거나, `format_recipe_guide`에서 프롬프트가 모호하여 LLM이 잘못된 가이드를 생성하는 경우 등을 명확히 찾아낼 수 있습니다.

**결론**

이 튜토리얼을 통해 우리는 LangSmith 트레이싱이 AI 에이전트 개발 과정에서 얼마나 강력한 도구인지 살펴보았습니다. 블랙박스처럼 느껴졌던 에이전트의 내부를 투명하게 만들고, 각 구성 요소의 작동 방식을 명확하게 이해함으로써, 우리는 더 효율적으로 디버깅하고, 성능을 최적화하며, 궁극적으로 더욱 견고하고 신뢰할 수 있는 LLM 기반 애플리케이션을 구축할 수 있게 됩니다. LangSmith는 단순한 관측 도구를 넘어, LLM 개발의 복잡성을 관리하고 반복적인 개선을 가능하게 하는 핵심 플랫폼으로서 그 가치를 증명합니다. 앞으로 LangSmith의 다른 기능들을 활용하여 에이전트의 평가 및 실험을 자동화하는 방법도 다룰 예정입니다.