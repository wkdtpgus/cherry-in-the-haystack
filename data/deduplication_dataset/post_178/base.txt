# **금주의 AI 에이전트: 알아두어야 할 논문들**

Author: Pascal Biese
URL: https://www.llmwatch.com/p/ai-agents-of-the-week-papers-you-116

============================================================

**요약**

**도구를 활용한 병렬 계획**
새로운 프레임워크(framework)는 대규모 언어 모델(LLM) 에이전트(agent)가 작업을 의존성 그래프(dependency graph) 형태로 계획하도록 하여, 엄격하게 순차적인 ReAct 방식의 실행 대신 병렬적인 도구 사용을 허용합니다. 이는 복잡한 다단계 질의(query)에 대한 효율성과 정확성을 향상시킵니다.

**스스로 개선하는 에이전트(agent)**
연구자들은 LLM 기반 에이전트가 스스로와 대결함으로써 학습할 수 있음을 입증했습니다. 세 가지 역할(role)의 조합(질문 제안자, 해결사, 심판)이 강화 학습(reinforcement learning)을 통해 함께 진화하며 최소한의 인간 감독으로 일반적인 추론 능력에서 측정 가능한 향상을 가져왔습니다.

**다중 에이전트(multi-agent) 협업 및 토론**
새로운 벤치마크(benchmark)와 방법론은 다중 에이전트 상호작용을 다루었습니다. DEBATE 데이터셋(dataset)은 수천 개의 실제 인간 토론 메시지를 담고 있으며, LLM 에이전트가 실제 그룹 역학(group dynamics)을 얼마나 잘 시뮬레이션(simulate)하는지 평가하기 위해 사용됩니다. 결과는 역할극을 하는 에이전트들이 미세 조정(fine-tuning) 후에도 인간의 행동과 달라진다는 것을 보여줍니다. 또 다른 연구에서는 에이전트들에게 서로의 행동을 소통하고 검증할 수 있는 방법을 제공하는 것(또는 환경으로부터의 피드백(feedback))이 협력적인 문제 해결 능력과 신뢰성을 극적으로 향상시켰다는 것을 발견했습니다.

**장기 기억(long-term memory) 및 구조화된 추론**
혁신적인 에이전트 아키텍처(architecture)는 계층적 계획(hierarchical planning)을 기억과 통합하고 있습니다. 하나의 새로운 프레임워크는 에이전트들을 트리 구조(tree structure)로 조직했으며, 부모-자식 간의 업무 분담과 장기 기억 저장소를 갖추고 있습니다. 이는 코드 생성(code generation)과 같은 복잡한 작업에서 성능을 향상시키기 위해 더 유연한 추론, 효율적인 오류 수정, 그리고 과거 지식의 재사용을 가져왔습니다.

**알려진 한계점 해결**
연구자들은 또한 현재 에이전트들의 사각지대(blind spot)를 식별하고 있습니다. 예를 들어, LLM 기반 에이전트는 기본적으로 시간적 인식(temporal awareness)이 부족합니다. 이는 '시간적 맹점(temporal blindness)'의 한 형태로, 도구 사용 시점의 오류를 유발합니다. 전용 평가(evaluation)는 모델(model)들이 명시적인 시간 신호(time cue) 없이 도구를 언제 다시 호출해야 할지 종종 잘못 판단한다는 것을 보여줍니다. 또 다른 비교 연구는 최고 수준의 LLM조차도 인간에게는 사소한 특정 논리적 추론(logical reasoning) 작업에서 여전히 어려움을 겪는다는 것을 확인했으며, 이는 에이전트 추론(reasoning) 및 정렬(alignment) 분야의 지속적인 발전 필요성을 강조합니다.