# **신은 맥락에 굶주려 있다: o3 pro에 대한 첫 생각**

Author: Latent Space
URL: https://www.latent.space/p/o3-pro

============================================================

**“유출된” 바와 같이**, OpenAI는 오늘 o3 가격을 80% 인하했습니다 (mtok당 $10/$40에서 $2/$8로 - GPT 4.1 가격과 일치합니다!!) 이는 o3-pro($20/$80) 출시를 위한 발판을 마련하기 위함이며, (-pro 변형 모델들이 그들의 논문과 저희 Chai 에피소드에서 언급된 바와 같이 다수결 투표를 통해 기본 모델 호출의 10배에 해당한다는 검증되지 않은 커뮤니티 이론을 뒷받침합니다). o3-pro는 인간 테스터들을 대상으로 o3 대비 64%의 승률을 기록했으며, 4/4 신뢰성 벤치마크(reliability benchmarks)에서 약간 더 나은 성능을 보였습니다. 하지만 sama가 지적했듯이, 다르게 테스트할 때 실제 경험은 확장됩니다… 저희를 다뤄준 Hacker News와 theo에게 감사드립니다. 저는 지난주부터 o3 pro를 미리 사용해 볼 수 있었습니다. 아래는 저의 (초기) 생각입니다: 신은 맥락(context)에 굶주려 있습니다. 우리는 작업별 모델(task-specific models)의 시대에 살고 있습니다. 한쪽에는 3.5 Sonnet과 4o와 같은 “일반적인” 모델들이 있습니다. 이들은 친구처럼 대화하며 글쓰기를 돕고 일상적인 질문에 답해줍니다. 다른 한쪽에는 심층 분석(비판에 탁월함), 복잡한 문제의 원샷 해결(one-shotting), 순수 지능의 한계를 뛰어넘기 위해 사용하는 거대하고 느리며 비싸고 지능을 극대화하는 추론 모델(reasoning models)들이 있습니다.

만약 트위터(Twitter)에서 저를 팔로우하신다면, 제가 o-추론 모델(o-reasoning models)들과 함께한 여정을 아실 겁니다. o1/o1-pro에 대한 저의 첫인상은 상당히 부정적이었습니다. 하지만 다른 사람들의 열광적인 평가에 힘입어 처음 몇 주를 이를 악물고 사용하면서, 사실 제가 잘못 사용하고 있었다는 것을 깨달았습니다. 저는 제 모든 생각을 정리했고, @sama에게 비율(ratio)을 당했으며, @gdb에게 인용 트윗(quote-tweet)되었습니다.

o1은 채팅 모델이 아닙니다 (그리고 그것이 핵심입니다)
Ben Hylak and Latent.Space · 1월 12일
전체 스토리 읽기

제가 발견한 핵심은 그것과 채팅하지 않는 것이었습니다. 대신, 보고서 생성기(report generator) 1 처럼 다루는 것이었습니다. 맥락(context)을 주고, 목표를 주고, 마음껏 작동하게 하는 것입니다. 그리고 이것이 바로 제가 오늘날 o3를 사용하는 방식입니다. 하지만 여기에 o3 pro를 평가하는 데 문제가 있습니다. 그것은 더 똑똑합니다. 훨씬 더 똑똑합니다. 하지만 그것을 확인하려면 훨씬 더 많은 맥락(context)을 제공해야 합니다. 그리고 저는 맥락이 부족합니다. 저를 놀라게 할 만한 간단한 테스트나 질문은 없었습니다. 하지만 저는 다른 접근 방식을 취했습니다. 저의 공동 창업자 알렉시스(Alexis)와 저는 시간을 들여 Raindrop에서의 모든 과거 기획 회의 기록, 모든 목표, 심지어 음성 메모까지 모았습니다. 그리고 o3-pro에게 계획을 세워달라고 요청했습니다. 저희는 깜짝 놀랐습니다. 그것은 제가 항상 LLM이 만들어주기를 바랐던 바로 그 종류의 구체적인 계획과 분석을 내놓았습니다 — 목표 지표(target metrics), 타임라인(timelines), 우선순위, 그리고 무엇을 반드시 제외해야 하는지에 대한 엄격한 지침까지 완벽하게 갖춘 것이었습니다. o3가 제공한 계획은 그럴듯하고 합리적이었습니다. 하지만 o3 Pro가 제공한 계획은 매우 구체적이고 충분히 근거가 있어서 실제로 저희가 미래에 대해 생각하는 방식을 바꾸어 놓았습니다.

이것은 평가(eval)에서 포착하기 어렵습니다.

**현실 세계와의 통합(Integrating with the Real World)**
o3 Pro를 사용해보면서 저는 오늘날 모델들이 개별적으로는 너무 뛰어나서, 간단한 테스트가 부족하다는 것을 깨달았습니다. 진정한 도전은 모델들을 사회에 통합하는 것입니다. 이는 마치 IQ가 매우 높은 12살 아이가 대학에 가는 것과 같습니다. 그들은 똑똑할지 모르지만, 통합되지 못하면 유용한 직원이 될 수 없습니다. 오늘날 이러한 통합은 주로 도구 호출(tool calls)로 귀결됩니다: 모델이 인간, 외부 데이터, 그리고 다른 AI와 얼마나 잘 협력하는지 말입니다. 그것은 훌륭한 사상가이지만, 훌륭한 실행가로 성장해야 합니다. o3 Pro는 이 부분에서 진정한 도약을 이룹니다. 그것은 자신의 환경이 무엇인지 식별하는 데 현저히 더 뛰어나며, 어떤 도구에 접근할 수 있는지 정확하게 전달하고, 외부 세계에 대해 언제 질문해야 하는지(정보/접근 권한이 있는 척하는 대신), 그리고 작업에 적합한 도구를 선택하는 데 능숙합니다.

o3 pro (왼쪽) vs o3 (오른쪽): o3 pro (왼쪽)가 자신의 환경의 한계를 훨씬 더 명확하게 이해하고 있습니다.

**단점(Shortcomings)**
초기 접근(early access)을 통해 제가 알아차린 한 가지는: 충분한 맥락(context)을 주지 않으면, 과도하게 생각하는 경향이 있다는 것입니다. 분석에는 엄청나게 뛰어나고, 도구를 사용하여 작업을 수행하는 데는 놀랍지만, 직접적으로 작업을 수행하는 데는 그리 좋지 않습니다. 저는 그것이 환상적인 오케스트레이터(orchestrator)가 될 것이라고 생각합니다. 하지만 예를 들어, o3가 더 잘 처리했던 ClickHouse SQL 질문들이 있었습니다. YMMV! (Your Mileage May Vary - 개인차가 있을 수 있습니다!)

**예를 들어:**
다른 모델들과 비교했을 때, o3 Pro는 Opus와 Gemini 2.5 Pro와는 매우, 매우 다르게 느껴집니다. Claude Opus는 거대하게 느껴지지만 그 “거대함”의 명확한 징후를 저에게 보여준 적이 없는 반면, o3 Pro의 결과물은 그저… 더 좋습니다. 완전히 다른 경기장처럼 느껴집니다. OpenAI는 이 수직적인 강화 학습(RL) 경로(Deep Research, Codex)를 정말로 추진하고 있습니다 — 모델에게 도구 사용법뿐만 아니라 언제 도구를 사용해야 할지에 대해 추론하는 방법까지 가르치고 있습니다.

**마무리 생각(Closing Thoughts)**
추론 모델(reasoning models)에 프롬프트(prompt)를 제공하는 가장 좋은 방법은 변하지 않았습니다. o1에 프롬프트를 제공하는 방법에 대한 저의 가이드는 여전히 유효합니다. 맥락(context)이 전부입니다. 마치 쿠키 몬스터에게 쿠키를 먹이는 것과 같습니다. 이는 LLM 메모리(memory)를 부트스트랩(bootstrapping)하는 방법이지만, 실제로 잘 작동하도록 목표가 설정되어 있습니다. 그리고 시스템 프롬프트(system prompt)가 정말 중요합니다. 모델들은 실제로 매우 유연해져서, 모델에게 환경과 목표를 가르치는 LLM “하네스(harnesses)”가 엄청난 영향을 미칩니다. 모델, 도구, 메모리(memory) 및 기타 방법들의 조합인 이 “하네스(harnesses)”가 AI 제품을 실제로 좋게 만듭니다 (Cursor와 같은 것들이 대부분 잘 작동하게 하는 요인입니다).

기타 여러 작업: 시스템 프롬프트(system prompt)는 모델의 행동을 엄청나게 형성했습니다 (좋은 방향으로!). 심지어 o3보다 훨씬 더 두드러지게 느껴졌습니다. Anthropic과 Gemini와는 비교할 수 없을 정도로 달랐습니다. Claude Opus는 거대하게 느껴지지만 (실제로 그 “거대함”의 진정한 징후를 저에게 보여준 적이 없는 반면), 이러한 결과물은 그저… 더 좋습니다. 완전히 다른 경기장처럼 느껴집니다. OAI는 이 수직적인 강화 학습(RL) 경로(Deep Research, Codex)를 정말로 추진하고 있습니다. 예를 들어, 모델에게 도구 사용법뿐만 아니라 언제 도구를 사용해야 할지에 대해 추론하는 방법까지 가르치고 있습니다.

1 많은 사람들이 이렇게 말합니다 - “보고서 생성(report generation)”은 기본적으로 저희가 AINews에서 하는 일이며, Deep Research와 Brightwave에서도 마찬가지입니다.