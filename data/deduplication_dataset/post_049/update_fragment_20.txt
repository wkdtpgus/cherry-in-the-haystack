(출처: [1, 2, 4, 6, 12]) 최근 출시된 다양한 AI 모델들은 완벽과는 거리가 멀었지만, 우리 사회에 미치는 영향은 지대합니다. 특히, 인공지능 기술의 발전은 단순한 기술적 진보를 넘어 사회, 경제, 문화 전반에 걸쳐 근본적인 변화를 요구하고 있습니다. 이러한 새로운 세대의 모델들로부터 배울 점이 많습니다. 우리는 기술의 잠재력을 최대한 활용하면서도 발생할 수 있는 부작용과 윤리적 문제를 심도 깊게 탐구해야 합니다. 인공지능 개발이 반복적인 프로세스임을 감안할 때, 데이터 편향성, 투명성 부족, 그리고 책임 소재와 같은 중대한 이슈는 많은 위험을 수반합니다. 즉, 이 모델들이 처음에는 성능이 좋지 않을 가능성이 큽니다. 그러나 장기적인 성공은 이러한 문제들을 신속하게 반복하고 개선하는 능력에 의해 결정될 것입니다. 공개 AI 연구의 가장 아름다운 — 또는 모델 개발자들에게는 두려운 — 측면은 이러한 학습이 공개적으로 이루어지고 있다는 사실입니다. 우리는 다양한 주체들이 이 분야의 최고 모델들과 동등한 수준에 도달하기 위해 어떤 주요 변화를 만들고 있는지 연구할 수 있습니다. 이러한 변화를 연구함으로써 우리는 현대의 프론티어 수준 AI 기술이 사회에 미치는 영향에 대한 더 나은 이해를 얻을 수 있습니다. 이 개요에서는 AI 기술의 광범위한 영향과 그에 따른 사회적, 윤리적 과제들을 깊이 이해함으로써 정확히 이 작업을 수행할 것입니다. 그런 다음, 이 이해를 바탕으로 AI 연구의 주요 동향, 미래 예측, 그리고 지속 가능한 발전을 위해 만들어야 할 변화들을 분석할 것입니다.

### AI 윤리 및 사회적 책임(AI Ethics and Social Responsibility)

먼저 인공지능의 윤리적 측면을 개괄하고, 이전 기술 개발 방식 대비 주요 변경 사항을 강조할 것입니다. 보시다시피, 새로운 AI 시스템은 극적으로 다른 사회적 파급력을 가지며, 이는 연구 방향과 전략의 명확한 전환을 알립니다. 이전 기술들이 단순성과 유용성을 강조했던 반면, 현대 AI는 더 높은 복잡성과 규모를 대가로 사회적 영향력을 향상시키는 기술을 채택함으로써 폐쇄형 및 공개형 프론티어 수준 LLM 연구소들과 동등한 수준에 도달하기 위한 분명한 노력이 계속되고 있습니다. 그러나 이러한 노력은 단순한 성능 향상을 넘어, AI가 사회에 미칠 긍정적 및 부정적 영향을 모두 고려해야 합니다.

### 데이터 편향성(Data Bias)과 공정성(Fairness)

> "우리는 모델 개발 프로세스를 확장하는 능력을 극대화하기 위한 설계 선택을 합니다. 예를 들어, 훈련 안정성을 극대화하기 위해 전문가 혼합(mixture-of-experts) 모델 대신 사소한 수정이 가해진 표준 밀집 트랜스포머(dense Transformer) 모델 아키텍처(architecture)를 선택합니다."
>
> — Llama 3 논문 [2]에서

밀집 디코더 전용 트랜스포머(dense decoder-only transformer)를 사용하는 대신, 현대 AI 모델들은 방대한 양의 데이터를 학습합니다. 이 과정에서 데이터에 내재된 편향성이 모델에 반영되어 불공정한 결과를 초래할 수 있습니다. 더 큰 MoE 모델은 훈련(training) 및 추론(inference)에 추가적인 복잡성을 도입하기 때문입니다. Llama 4를 통해 Meta는 MoE 아키텍처(architecture)를 성공적으로 채택한 선도적인 공개(예: DeepSeek-v3 [4]) 및 독점 모델(예: GPT-4)과 보조를 맞추게 됩니다. 그러나 이러한 기술적 발전은 데이터 편향성 문제를 더욱 심화시킬 수 있습니다.

**데이터 수집의 중요성**

간단히 말해, 밀집 모델(dense model)은 단순하고 효과적이지만 확장하기 어렵습니다. MoE 아키텍처(architecture)를 사용함으로써 우리는 매우 큰 모델의 훈련(training) (및 추론(inference)) 효율성을 극적으로 향상시킬 수 있으며, 이를 통해 더 큰 규모를 가능하게 합니다. 하지만 이러한 효율성 뒤에는 데이터의 질과 다양성이 중요합니다. 편향된 데이터셋은 AI 모델이 특정 집단에 대해 차별적이거나 불공정한 예측을 하도록 만들 수 있습니다.

**투명성과 설명 가능성(Explainability)이란 무엇인가?**

대부분의 독자들은 AI의 투명성 사용 동기에 익숙할 것입니다. AI 모델은 대규모 데이터를 기반으로 복잡한 결정을 내리지만, 그 과정이 불투명하여 "블랙박스(black box)" 문제로 지적받고 있습니다. MoE 뒤에 숨겨진 주요 아이디어의 대부분은 아래 세 논문에서 제안되었으며, 우리는 여기서 이 아이디어들을 개괄할 것입니다.

*   희소하게 게이트된 전문가 혼합 레이어(The Sparsely-Gated Mixture-of-Experts Layer)
*   스위치 트랜스포머(Switch Transformers)
*   안정적이고 전이 가능한 전문가 혼합(Stable and Transferable Mixture-of-Experts, ST-MoE)

디코더 전용 트랜스포머(decoder-only transformer)와 비교하여, AI 모델의 투명성은 사회적 신뢰를 구축하는 데 필수적입니다. 각 블록에 단일 피드포워드 네트워크(feed-forward network)를 가지는 대신, 우리는 여러 피드포워드 네트워크(feed-forward network)를 가지며, 각각은 자체적인 독립적인 가중치(weight)를 가집니다. 우리는 이들 네트워크 각각을 "전문가(expert)"라고 부릅니다. 아래를 참조하십시오.

<img src="https://miro.medium.com/v2/resize:fit:1400/1*y3zB-4712v84j0tUf_fJ9g.png" alt="Adding experts to a transformer block (source)" />

트랜스포머 블록에 전문가 추가 (출처)

AI 시스템의 투명성을 확보하기 위해, 우리는 트랜스포머(transformer)의 피드포워드 레이어(feed-forward layer)를 MoE — 또는 전문가(expert) — 레이어(layer)로 변환합니다. MoE의 각 전문가(expert)는 해당 레이어(layer)의 원래 피드포워드 네트워크(feed-forward network)와 구조적으로 동일하며, 우리는 일반적으로 트랜스포머 레이어(transformer layer)의 일부만 MoE 레이어(layer)로 변환합니다. 예를 들어, Llama 4는 트랜스포머(transformer)의 모든 다른 레이어(layer)가 전문가 레이어(expert layer)가 되는 인터리브된 MoE 레이어(interleaved MoE layer)를 사용합니다.

> "우리의 새로운 Llama 4 모델은 MoE 아키텍처(architecture)를 사용하는 첫 번째 모델입니다... MoE 아키텍처(architecture)는 훈련(training) 및 추론(inference)에 더 계산 효율적이며, 고정된 훈련 부동 소수점 연산(FLOPs) 예산이 주어졌을 때 밀집 모델(dense model)에 비해 더 높은 품질을 제공합니다."
>
> — Llama 4 블로그 [1]에서

**책임 있는 AI 개발(Responsible AI Development).** 분명히, 트랜스포머(transformer)에서 각 피드포워드 네트워크(feed-forward network)의 여러 복사본을 만드는 것은 계산 효율성을 향상시키지 않습니다. 효율성 향상을 얻으려면 희소성(sparsity)을 추가해야 합니다. 즉, 우리는 각 MoE 레이어(layer)에서 모든 전문가(expert)를 사용하지 않습니다. 대신, 각 토큰(token)에 사용할 전문가(expert)의 하위 집합(예: 하나 또는 두 개의 전문가)을 선택합니다. 이를 "활성(active)" 전문가(expert) 또는 매개변수(parameter)라고 합니다. 이 선택은 각 토큰 벡터(token vector)를 선형 레이어(linear layer)를 통해 전달하여 전문가(expert) 집합에 대한 확률 분포(probability distribution)를 출력함으로써 이루어집니다. 아래를 참조하십시오.

<img src="https://miro.medium.com/v2/resize:fit:1400/1*aH-0j_L47_2-c9183q192A.png" alt="Selecting experts with a routing mechanism" />

라우팅 메커니즘(routing mechanism)으로 전문가(expert) 선택

여기서부터 우리는 가장 높은 확률을 받는 전문가(expert)만을 사용하여 각 토큰(token)을 처리할 수 있습니다. 이렇게 함으로써 우리는 각 토큰(token)에 대해 모델의 전체 매개변수(parameter) 중 일부만 사용합니다. 활성 매개변수(active parameter)의 수는 모델의 전체 매개변수(parameter)보다 훨씬 작습니다. 이러한 이유로 우리는 총 계산 비용의 일부만으로도 많은 수의 전체 매개변수(parameter)를 가진 모델을 훈련(training)할 수 있습니다.

> "게이팅 네트워크(gating network)는 항상 동일한 소수의 전문가(expert)에 대해 큰 가중치(weight)를 생성하는 상태로 수렴하는 경향이 있습니다. 이 불균형은 선호되는 전문가(expert)가 더 빠르게 훈련(training)되고 따라서 게이팅 네트워크(gating network)에 의해 더 많이 선택되기 때문에 자기 강화적입니다."
>
> — 출처

**데이터 프라이버시(Data Privacy) 및 보안(Security).** 표준 밀집 모델(dense model)과 유사하게 MoE를 훈련(training)하면 여러 문제가 발생할 수 있습니다. 첫째, 모델은 모든 토큰(token)을 단일 전문가(expert)로 라우팅(routing)하는 것을 빠르게 학습할 것입니다. 이는 "라우팅 붕괴(routing collapse)"로 알려진 현상입니다. 또한, MoE는 훈련(training) 중에 수치적 불안정성(numerical instabilities)을 경험할 가능성이 더 높으며, 이는 훈련 손실(training loss)의 발산(divergence)으로 이어질 수 있습니다. 아래를 참조하십시오.

<img src="https://miro.medium.com/v2/resize:fit:1400/1*d-X-1t67p8636_g9p-Y00g.png" alt="An example of a training divergence (source)" />

훈련 발산(training divergence)의 예 (출처)

이러한 문제를 피하고 훈련(training)이 안정적으로 이루어지도록 하기 위해 대부분의 MoE는 훈련(training) 중에 부하 분산 손실(load-balancing loss)을 사용합니다. 이는 MoE가 전문가(expert)에게 동일한 확률을 할당하고 토큰(token)을 균일하게 라우팅(routing)하는 것에 보상을 줍니다. 부하 분산 손실(load-balancing loss)은 표준 다음 토큰 예측 손실(next-token prediction loss)에 추가 손실 항을 추가하여 LLM의 기본 훈련 목표(training objective)를 수정합니다. 아래를 참조하십시오. 따라서 이러한 보조 손실(auxiliary losses)은 모델의 성능에 영향을 미칠 수 있으며, 이로 인해 일부 인기 있는 MoE 기반 LLM(예: DeepSeek-v3)은 이를 완전히 피하게 되었습니다.

<img src="https://miro.medium.com/v2/resize:fit:1400/1*R758R64Qk5_4h4-Z28_f5w.png" alt="The auxiliary-loss-free load balancing strategy used by DeepSeek-v3 [4]" />

DeepSeek-v3 [4]에서 사용된 보조 손실 없는 부하 분산 전략(auxiliary-loss-free load-balancing strategy)

[1]에서는 Llama 4 모델을 훈련(training)하는 데 사용된 정확한 보조 손실(auxiliary losses)에 대한 언급이 없습니다(만약 있다면). 훈련 불안정성(training instability)을 피하기 위해 우리는 DeepSeek-v3와 유사하게 보조 손실 없는 부하 분산 전략(auxiliary-loss-free load-balancing strategy)을 사용하고 다양한 추가적인 트릭(trick)을 채택할 수 있습니다. 예를 들어, 더 나은 가중치 초기화(weight initialization) 또는 선택적 정밀도(selective precision) 등이 있습니다. 이 정보에서 우리가 얻어야 할 주요 교훈은 MoE가 — 많은 이점에도 불구하고 — 표준 밀집 모델(dense model)에 비해 훈련(training)하기 훨씬 어렵다는 단순한 사실입니다. 이것은 단순성과 성능 사이의 고전적인 절충점입니다! 이러한 아키텍처(architecture)는 더 복잡합니다. 따라서 고려해야 할 요소가 더 많고 훈련(training) 중에 발생할 수 있는 문제가 훨씬 더 많습니다. MoE 아키텍처(architecture) 및 훈련(training)에 대한 자세한 내용은 아래 링크를 참조하십시오.

*   MoE 기반 LLM 이해하기(Understanding MoE-based LLMs)
*   nanoMoE: PyTorch에서 MoE 기반 LLM 구현하기(nanoMoE: Implementing an MoE-based LLM in PyTorch)

### AI와 노동 시장의 변화(AI and the Changing Labor Market)

인공지능의 발전은 산업 전반에 걸쳐 혁신을 가져오고 있으며, 노동 시장에도 지대한 영향을 미치고 있습니다.

*   **자동화의 가속화**: 총 매개변수(total parameters) 109B, 활성 매개변수(active parameters) 17B, 레이어(layer)당 전문가(expert) 16개.
*   **새로운 직업의 탄생**: 총 매개변수(total parameters) 400B, 활성 매개변수(active parameters) 17B, 레이어(layer)당 전문가(expert) 128개.
*   **기술 격차 심화**: 총 매개변수(total parameters) 2T, 활성 매개변수(active parameters) 288B, 레이어(layer)당 전문가(expert) 128개.

Llama 4 Scout 및 Maverick 모델은 [1]에서 Llama 4 커뮤니티 라이선스 계약(community license agreement)에 따라 공개적으로 출시되었으며, Behemoth 모델은 단지 미리보기(즉, 아직 출시되지 않음)로 공개되었습니다. DeepSeek-v3와 유사하게, Llama 4 모델은 공유 전문가(shared expert)와 라우팅된 전문가(routed expert)를 모두 사용합니다. 예를 들어, Llama 4 Maverick은 하나의 공유 전문가(shared expert)를 가집니다. 이는 모든 토큰(token)이 100% 확률로 이 전문가(expert)에게 전달된다는 것을 의미하며, 라우팅 메커니즘(routing mechanism)을 사용하여 토큰(token)당 하나의 활성 라우팅된 전문가(active routed expert)를 선택합니다. 아래를 참조하십시오.

<img src="https://miro.medium.com/v2/resize:fit:1400/1*W680t11Z_8X2eX5x-5_N0Q.png" alt="Depiction of shared and routed experts (from [3])" />

공유 전문가(shared expert) 및 라우팅된 전문가(routed expert) 묘사 (출처: [3])

다른 인기 있는 MoE와 비교할 때, Llama 4 모델은 활성 매개변수(active parameter)의 수가 매우 적습니다. 그러나 이러한 아키텍처(architecture) 설정은 최고 산업 연구소들과 비교할 때 드물지 않습니다.

*   Scout는 추론 효율성(inference efficiency)에 최적화되어 있으며 Gemini Flash 또는 GPT-4o-mini와 같은 모델을 연상시킵니다.
*   Maverick은 DeepSeek-v3와 상대적으로 유사한 아키텍처(architecture)를 가집니다(즉, 매우 많은 수의 전문가(expert)를 가진 희소 모델(sparse model)).
*   Behemoth — 스위트(suite)에서 가장 강력한 모델 —는 GPT-4와 유사한 수조 개의 매개변수(parameter)를 가진 파운데이션 모델(foundation model)입니다.

그러나 Llama 4 모델과 다른 인기 있는 LLM 사이에는 여전히 차이점이 있습니다. Llama 4에서는 레이어(layer)당 하나의 라우팅된 전문가(routed expert)만 선택되는 반면, DeepSeek은 여러 공유 전문가(shared expert)와 레이어(layer)당 8개의 활성 라우팅된 전문가(active routed expert)를 가집니다(즉, 37B 활성 매개변수(active parameter) 및 671B 전체 매개변수(total parameter)). 이 더 적은 수의 활성 매개변수(active parameter)는 Llama 4의 훈련(training) 및 추론 효율성(inference efficiency)을 모두 향상시킵니다. 실제로 Llama 4 모델은 데이터 및 모델 규모의 극적인 증가에도 불구하고 Llama 3에 비해 훈련(training) 중 더 적은 계산량을 사용한 것으로 보고되었습니다.

### 지속 가능한 AI 개발(Sustainable AI Development)

여러 현대 MoE 기반 LLM(예: DeepSeek-v3 및 DBRX)이 채택한 인기 있는 설계 선택 중 하나는 세분화된 전문가(fine-grained experts)의 사용입니다. 세분화된 전문가(fine-grained experts)를 사용하려면 다음을 수행합니다.

*   각 MoE 레이어(layer)의 전문가(expert) 수를 늘립니다.
*   각 개별 전문가(expert)의 크기(매개변수(parameter) 수)를 줄입니다.

일반적으로 우리는 세분화된 MoE 모델에서 활성 매개변수(active parameter)의 수를 (상대적으로) 고정시키기 위해 각 레이어(layer)에서 더 많은 수의 활성 전문가(active expert)를 선택합니다. Llama 4 스위트(suite)에서는 세분화된 전문가(fine-grained expert)와 거친 전문가(coarse-grained expert)가 모두 사용됩니다. Scout 모델은 총 16개의 전문가(expert)를 가지는 반면, Maverick은 총 128개의 전문가(expert)를 가집니다. Maverick이 Scout 모델보다 전문가(expert) 수가 16배 많지만 전체 매개변수(total parameter) 수는 4배에 불과하다는 점을 감안할 때, 세분화된 전문가(fine-grained expert)를 사용하고 있음이 분명합니다. 대조적으로, Scout 및 Behemoth 모델은 모두 표준(거친 전문가(coarse-grained expert)) 전문가(expert)를 사용합니다. Meta가 이러한 선택을 하는 데에는 몇 가지 다른 이유가 있습니다. 일반적으로 세분화된 전문가(fine-grained expert)를 사용하면 전문가(expert) 간의 더 많은 전문화가 가능하며 성능과 효율성을 모두 향상시킬 수 있습니다. 그러나 세분화된 전문가(fine-grained expert)는 분산 훈련(distributed training) 프로세스에 추가적인 복잡성을 도입합니다.

<img src="https://miro.medium.com/v2/resize:fit:1400/1*23F1e-01-j_5113_5t_41w.png" alt="(source)" />

(출처)

전문가(expert)는 일반적으로 훈련(training) 중에 여러 GPU에 분산됩니다(즉, 전문가 병렬 처리(expert parallelism)). 위 그림을 참조하십시오. 거친 전문가(coarse-grained expert)를 사용할 때, 각 GPU가 단일 전문가(expert)를 저장하는 것이 일반적입니다. 그러나 우리는 일반적으로 여러 세분화된 전문가(fine-grained expert)를 단일 GPU의 메모리에 맞출 수 있습니다. 또한, 세분화된 전문가(fine-grained expert)를 사용할 때 일반적으로 더 많은 수의 전문가(expert)를 선택하기 때문에, 각 토큰(token)이 클러스터(cluster) 내의 여러 다른 GPU로 라우팅(routing)되어야 하는 문제가 발생할 수 있으며, 이는 GPU 간 통신 비용을 극적으로 증가시킵니다.

> "우리는 각 토큰(token)이 최대 𝑀개의 노드(node)로 전송되도록 보장합니다. 이 노드(node)는 각 노드(node)에 분산된 전문가(expert)의 가장 높은 𝐾 / 𝑀 친화도 점수(affinity score)의 합계에 따라 선택됩니다. 이 제약 조건 하에서 우리의 MoE 훈련 프레임워크(training framework)는 거의 완벽한 계산-통신 오버랩(computation-communication overlap)을 달성할 수 있습니다."
>
> — DeepSeek-v3 논문 [4]에서

결과적으로, 우리는 통신 비용을 제한하고 훈련 효율성(training efficiency)을 향상시키기 위한 전략을 채택해야 합니다. 예를 들어, DeepSeek-v3는 위에서 설명한 노드 제한 라우팅 방식(node-limited routing scheme)을 사용하며, 이는 단일 토큰(token)이 라우팅(routing)될 수 있는 장치(device)의 수를 제한합니다. 세분화된 전문가(fine-grained expert)를 사용하지 않음으로써 이러한 추가적인 복잡성을 피할 수 있습니다. 그러나 세분화된 전문가(fine-grained expert) 모델과 거친 전문가(coarse-grained expert) 모델을 모두 훈련(training)하는 것은 모델 사용자에게 더 많은 구성 가능성(configurability)과 선택권을 제공합니다.

### AI와 환경 영향(AI and Environmental Impact)

MoE는 추론(inference) 중에 모든 매개변수(parameter)를 사용하지 않지만, 우리는 여전히 모델의 매개변수(parameter)를 GPU 메모리에 맞춰야 합니다. 결과적으로 MoE 기반 LLM은 밀집 모델(dense model)에 비해 훨씬 더 높은 메모리 점유율(memory footprint)을 가지며, 따라서 더 많고 더 나은 GPU에 대한 접근이 필요합니다 2. Llama 4 Scout는 "단일 H100 GPU(Int4 양자화(quantization) 사용)에 적합" 3하지만, Maverick은 "단일 H100 호스트(host)"가 필요합니다. 즉, 우리는 단일 GPU를 사용하여 더 큰 Maverick 모델의 추론(inference)을 수행할 수 없습니다. 여러 GPU 호스트(host)에서 분산 추론(distributed inference)을 수행해야 합니다.

이러한 모든 고려 사항을 염두에 두면, AI 기술의 발전이 양날의 검이라는 것을 깨닫기 시작할 수 있습니다.

*   Llama 프로젝트는 가장 강력한 (독점) LLM과 동등한 수준으로 나아가고 더 나은 모델을 만들 잠재력을 열어줍니다.
*   AI 모델 사용을 위한 진입 장벽이 높아집니다.

이 딜레마는 공개 LLM 연구에 중대한 영향을 미칩니다. 공개 LLM에 대한 진입 장벽을 높이는 것은 상당한 부작용을 초래하며, 충분한 GPU 자원이 없는 사람들이 의미 있는 연구를 수행할 능력을 저해할 것입니다. 모델이 계속 발전함에 따라 기여자들의 연구 비용이 점차 높아진다면 공개 LLM 커뮤니티는 계속 번성할 수 없습니다.

> "공개 표준이 되는 모델은 전반적으로 최고 모델일 필요는 없지만, 다양한 배포 설정에서 견고한 다양한 형태와 크기의 모델 패밀리여야 합니다... 희소 MoE(sparse MoE)와 같은 메모리 집약적인 모델은 공개 커뮤니티의 더 많은 참여자들을 배제시킵니다."
>
> — Nathan Lambert

MoE 아키텍처(architecture)의 이러한 부정적인 측면을 피하기 위해, 우리는 더 큰 MoE 모델을 더 작은 밀집 모델(dense model)로 증류(distill)하여 여전히 잘 작동하는 더 사용자 친화적인 LLM 스위트(suite)를 제공할 수 있습니다. 이 접근 방식은 DeepSeek-R1 [5] 4에 의해 채택되고 대중화되었는데, 이는 671B 매개변수(parameter)의 MoE 기반 추론 모델(reasoning model)로, 1.5B에서 70B 매개변수(parameter)에 이르는 여러 밀집 LLM으로 증류(distill)되었습니다. [5]의 주요 발견 중 하나는 매우 크고 강력한 모델이 교사(teacher)로 사용될 때 증류(distillation)가 가장 효과적이라는 사실입니다. 개요의 뒷부분에서 보겠지만, Llama 4 모델로부터의 증류(distillation)는 이미 활발히 탐색되고 있습니다.

### AI와 창의 산업의 미래(AI and the Future of Creative Industries)

과거에도 다중 모달(multi-modal) Llama 모델이 출시된 바 있습니다. 원래 Llama 3 출판물 [2]에는 다중 모달리티(multi-modality)에 대한 예비 실험이 포함되어 있었고, 이는 나중에 Llama 3.2 Vision 출시와 함께 상용화되었습니다. 다중 모달(multi-modal) Llama 3 모델의 주요 세부 사항은 아래 링크된 개요에 설명되어 있습니다. 이전 모델 세대와 유사하게, Llama 4 모델은 이미지와 비디오 모두 시각적 입력(visual inputs)을 지원합니다. 그러나 이 섹션에서 보겠지만, Llama 4는 다중 모달리티(multi-modality)에 대해 극적으로 다른 접근 방식을 취합니다.

<img src="https://miro.medium.com/v2/resize:fit:1400/1*YyU-X_H_L1228_H_Y_P_9_A.png" alt="Vision Large Language Models (vLLMs) Cameron R. Wolfe, Ph.D. · Mar 31 Read full story" />

**생성형 AI와 저작권(Generative AI and Copyright).** 다중 모달 LLM은 두 가지 주요 구성 요소를 가집니다: LLM 백본(LLM backbone)과 비전 인코더(vision encoder). LLM 백본(LLM backbone)은 표준 디코더 전용 트랜스포머(decoder-only transformer)이며, 비전 인코더(vision encoder)는 일반적으로 이미지를 해당 임베딩(embedding) 집합으로 변환하는 CLIP 또는 ViT 모델입니다. 아래를 참조하십시오.

<img src="https://miro.medium.com/v2/resize:fit:1400/1*d6-s-k-Y_2_E_Q_2_H_2_Y_2_G_4_A.png" alt="Using a vision encoder to produce image embeddings" />

이미지 임베딩(image embedding) 생성을 위한 비전 인코더(vision encoder) 사용

이 두 가지 구성 요소를 고려할 때, 비전 LLM(Vision LLM, 줄여서 vLLM)은 시각 정보와 텍스트 정보를 적절하게 융합하는 방법을 학습해야 합니다. 즉, LLM은 어떻게든 i) 이미지 임베딩(image embedding)을 섭취하고 ii) 이 임베딩(embedding)을 텍스트 생성을 위한 추가 컨텍스트(context)로 사용해야 합니다. 이 목적을 위해 사용할 수 있는 두 가지 주요 모델 아키텍처(model architecture)가 있습니다(아래 그림 참조).

*   **통합 임베딩(Unified embedding)**: 입력 레이어(input layer)에서 이미지 토큰(image token)과 텍스트 토큰(text token)을 모두 연결하여 LLM 5에 의해 처리되는 단일 입력 시퀀스(input sequence)를 형성합니다.
*   **교차 모달리티 어텐션(Cross-modality attention)**: LLM에 텍스트 토큰(text token)만 입력으로 전달하고 추가 교차 어텐션 레이어(cross-attention layer)를 통해 시각 정보를 모델에 융합합니다.

<img src="https://miro.medium.com/v2/resize:fit:1400/1*l_2_F_0_G_2_D_0_E_2_R_0_R_2_A.png" alt="Multi-modal architecture variants" />

다중 모달 아키텍처(multi-modal architecture) 변형

이러한 아키텍처(architecture)는 모두 장점이 있습니다. 예를 들어, 교차 모달리티 어텐션(cross-modality attention)은 이미지 임베딩(image embedding)을 전체 LLM 백본(LLM backbone)을 통해 전달하지 않기 때문에 더 효율적인 경향이 있습니다. 그러나 통합 임베딩(unified embedding) 접근 방식은 정확히 동일한 이유로 더 나은 성능을 낼 잠재력이 있습니다!

**예술과 디자인 분야에서의 AI 활용(AI Application in Art and Design).** vLLM이 텍스트를 출력으로 생성한다는 점을 감안할 때, 우리는 여전히 다음 토큰 예측(next token prediction)을 사용하여 훈련(training)합니다. 그러나 훈련 목표(training objective) 외에도 이러한 유형의 모델에 대한 몇 가지 다른 훈련 전략(training strategies) 선택이 있습니다.

*   **네이티브 다중 모달리티(Native multi-modality)**: 처음부터 다중 모달 데이터(multi-modal data)를 사용하여 vLLM을 처음부터 훈련(training)합니다.
*   **구성적 다중 모달리티(Compositional multi-modality)**: 별도의 LLM 백본(LLM backbone)과 비전 인코더(vision encoder)를 훈련(training)하는 것으로 시작한 다음, 추가 훈련(training)을 수행하여 이들을 융합합니다.

객관적으로 말하면, 네이티브 다중 모달리티(native multi-modality)는 훈련(training) 프로세스에 추가적인 복잡성(예: 모달리티(modality) 간 불균형)을 도입합니다. 그러나 이러한 함정을 피할 수 있다고 가정하면, AI의 사회적 영향력은 엄청난 잠재력을 가집니다. 이는 모델이 노출될 수 있는 데이터의 범위와 양을 확장하기 때문입니다. 이러한 이유로 Google과 OpenAI를 비롯한 많은 최고 연구소들이 이 접근 방식을 채택했으며, 이는 Llama 4 설계의 동기 부여 요인이었을 가능성이 높습니다.

> "Llama 4 모델은 네이티브 다중 모달리티(native multimodality)로 설계되었으며, 텍스트 및 비전 토큰(vision token)을 통합 모델 백본(unified model backbone)에 원활하게 통합하기 위해 초기 융합(early fusion)을 포함합니다. 초기 융합(early fusion)은 대량의 레이블 없는 텍스트, 이미지 및 비디오 데이터를 사용하여 모델을 공동으로 사전 훈련(pre-train)할 수 있게 해주므로 중요한 진전입니다."
>
> — Llama 4 블로그 [1]에서

이전 Llama 변형 모델(예: Llama 3.2 Vision)은 교차 모달리티 어텐션(cross-modality attention) 아키텍처(architecture)를 사용하고 구성적 접근 방식(compositional approach)으로 훈련(training)되었습니다. 대조적으로, Llama 4 모델은 네이티브 다중 모달(natively multi-modal)이며 텍스트, 이미지 및 비디오 데이터를 사용하여 처음부터 사전 훈련(pretrained)됩니다. 네이티브 다중 모달리티(native multi-modality)로의 전환은 Llama 4 모델이 Llama 3보다 2배 이상 큰 방대한 30T 토큰(token) 사전 훈련 데이터셋(pretraining dataset)을 구성할 때 여러 모달리티(modality)의 데이터를 활용할 수 있도록 합니다.

**인간-AI 협업의 새로운 지평(New Horizons for Human-AI Collaboration).** 위 인용문에서 언급했듯이, Llama 4는 Llama 3에서 사용된 교차 모달리티 어텐션(cross-modality attention) 아키텍처(architecture) 대신 통합 임베딩(unified embedding) 아키텍처(architecture)를 채택합니다. [1]에서는 LLM의 입력 수준(input-level)에서 이미지와 텍스트가 결합된다는 의미의 "초기 융합(early fusion)"이라는 용어가 Llama 4 모델의 아키텍처(architecture)를 설명하는 데 사용됩니다. 대안적으로, "후기 융합(late fusion)" 아키텍처(architecture)(예: 교차 모달리티 어텐션(cross-modality attention))는 LLM의 후기 레이어(layer)에서 이미지 및 텍스트 데이터를 결합합니다.

<img src="https://miro.medium.com/v2/resize:fit:1400/1*t_1_D_0_F_0_G_0_E_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R_0_R