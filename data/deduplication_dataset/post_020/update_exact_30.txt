지난달에는 많은 일들이 있었습니다. 애플은 온디바이스 LLM(on-device LLM) 통합을 발표했고, 엔비디아는 대규모 네모트론(Nemotron) 모델을 공개했으며, FlashAttention-3가 발표되었고, 구글의 Gemma 2가 출시되는 등 다양한 소식이 있었습니다. 아마 여러분은 이미 여러 뉴스 매체를 통해 이 모든 소식을 접하셨을 것입니다. 따라서 이 글에서는 LLM 훈련을 위한 근본적인 기술인 인스트럭션 파인튜닝(instruction finetuning)에 초점을 맞춘 최근 연구에 대해 다루고자 합니다.

이 글에서 다룰 내용은 다음과 같습니다:
*   인스트럭션 데이터 생성 방법의 진화와 실용적 적용
*   효과적인 인스트럭션 파인튜닝(instruction finetuning) 전략 심층 분석
*   사전 훈련(pretraining) 단계에서 인스트럭션 데이터(instruction data) 활용의 최신 동향
*   Gemma 2 모델의 기술적 혁신과 시장 영향
*   최근 LLM 연구의 주요 하이라이트 및 실용적 함의

즐거운 독서 되시길 바랍니다!

## 1. 처음부터 정렬 데이터(Alignment Data) 생성하기

"The Magpie: Alignment Data Synthesis from Scratch by Prompting Aligned LLMs with Nothing" 논문은 LLM 인스트럭션 파인튜닝(instruction finetuning)을 위한 고품질 데이터셋을 생성하는 흥미로운 해킹(hack) 방법을 공유합니다. 이 방법이 특별히 최신 연구 통찰력을 제공하는 것은 아니지만, 매우 유용해 보이는 흥미롭고 실용적인 활용 사례 중 하나입니다.

### 1.1 아무것도 없는 상태에서 인스트럭션 데이터셋(Instruction Dataset) 생성하기

이 인스트럭션 데이터 생성(instruction-data-generating) 방법이 다른 방법들과 구별되는 점은 완전히 자동화될 수 있으며, 초기 질문이나 인스트럭션이 필요 없다는 것입니다. 논문 제목이 시사하듯이, 이 방법은 "아무것도 없는(Nothing)" 상태에서 인스트럭션 데이터셋(instruction dataset)을 생성할 수 있게 합니다. 필요한 유일한 것은 로컬에서 실행되는 Llama 3 8B 모델입니다.

아래 그림은 이 방법이 어떻게 작동하는지 요약합니다.

인스트럭션 파인튜닝(instruction finetuning)을 위한 합성 데이터셋을 생성하는 Magpie 방법론의 주석이 달린 그림.
이 그림은 Magpie 논문의 그림을 기반으로 합니다: https://arxiv.org/abs/2406.08464

기본적으로, 위 그림에서 볼 수 있듯이, 우리는 Llama 3 8B Instruct 모델에 사전 쿼리 템플릿(pre-query template)으로 프롬프트(prompt)를 주기만 하면, 모델이 우리를 위한 인스트럭션(instruction)을 생성할 것입니다. 그런 다음, 그 인스트럭션(instruction)을 다시 LLM에 입력하면, 모델이 응답을 생성합니다. 이 절차를 수천 번 반복하면, 인스트럭션 파인튜닝(instruction finetuning)을 위한 데이터셋을 얻을 수 있습니다. (선택적으로, LLM을 사용하여 인스트럭션-응답 쌍(instruction-response pairs)의 품질을 필터링할 수 있습니다.)

### 1.2 데이터셋 품질

흥미로운 점은, 생성된 인스트럭션 데이터셋을 사용하여 저자들이 인스트럭션 파인튜닝(instruction finetuning)만으로 Llama 3 8B 기본 모델을 파인튜닝(finetuning)하는 것이 (RLHF 및 DPO를 통한 선호도 파인튜닝(preference finetuning) 없이) Meta AI의 오리지널 Llama 2 8B Instruct 모델을 능가한다는 것을 발견했다는 것입니다. 이는 아래 그림에 나와 있습니다.

Magpie가 생성한 인스트럭션 데이터셋으로 파인튜닝(finetuned)된 Llama 3 8B 기본 모델이 오리지널 Llama 3 8B Instruct 모델을 능가합니다.
Magpie 논문의 주석이 달린 그림을 기반으로 합니다: https://arxiv.org/abs/2406.08464

위 그림에 나타난 Magpie 결과는 단 30만 개의 샘플(samples)로 달성되었습니다. 이에 비해, 오리지널 Llama 3 Instruct 모델은 1억 개의 샘플(samples)로 파인튜닝(finetuned)되고 정렬(aligned)되었습니다!

### 1.3 데이터셋 생성 로컬에서 실행하기

Magpie 방법론의 가장 큰 장점 중 하나는 고성능 컴퓨팅 자원에 대한 의존도를 낮추면서 고품질 인스트럭션 데이터를 로컬에서 생성할 수 있다는 점입니다. 이는 소규모 연구팀이나 개인 개발자에게 LLM 훈련을 위한 데이터 접근성을 크게 향상시킵니다. Ollama와 같은 도구를 활용하면 MacBook Air와 같은 개인 장치에서도 이러한 데이터 생성 파이프라인(pipeline)을 구축하고 실행하는 것이 가능해집니다. 물론, 대규모 데이터셋을 생성하는 데는 여전히 상당한 시간이 소요될 수 있지만, 클라우드 기반 LLM API(Application Programming Interface) 사용 시 발생하는 비용 부담을 획기적으로 줄일 수 있다는 점에서 매우 매력적입니다. 그러나 로컬에서 생성된 데이터는 원본 LLM의 편향(bias)을 그대로 물려받을 수 있으므로, 데이터 품질 검증과 잠재적 편향 완화에 대한 추가적인 노력이 필요할 수 있습니다.

### 1.4 추가 세부 정보

Magpie 연구자들은 "Pro" 및 "Air" 버전의 데이터셋을 생성하여, 소스 LLM의 크기가 최종 데이터셋의 품질에 미치는 영향을 탐구했습니다. Magpie-Pro는 Llama 3 70B Instruct 모델을, Magpie-Air는 Llama 3 8B Instruct 모델을 활용했습니다. 이들 데이터셋은 인스트럭션 파인튜닝(instruction finetuning)을 통해 Llama 3 8B 기본 모델의 성능을 향상시키는 데 사용되었는데, Pro 버전이 약간 더 강력한 모델을 생성하는 경향을 보였습니다. 이는 데이터 생성에 사용되는 LLM의 역량이 최종 데이터 품질에 직접적인 영향을 미친다는 것을 시사합니다.

또한, Magpie 데이터셋은 Alpaca, Evol Instruct, UltraChat와 같은 기존의 인스트럭션 파인튜닝 데이터셋보다 훨씬 넓은 범위와 다양성(diversity)을 가지고 있다는 분석이 제시되었습니다. 이러한 다양성은 다양한 유형의 작업을 포괄하며, 모델이 더 일반화된 인스트럭션 팔로잉(instruction-following) 능력을 습득하는 데 기여합니다. 이는 단순한 양적 증가를 넘어 질적인 개선을 의미하며, 합성 데이터 생성 방법론의 발전 가능성을 보여줍니다.

### 1.5 결론

전반적으로, Magpie는 한편으로는 그 효과성에서 매혹적이고, 다른 한편으로는 많은 실용적인 유용성을 가진 흥미로운 활용 사례라고 생각합니다. 저는 앞으로 범용 인스트럭션 데이터셋(general-purpose instruction datasets)을 구축하는 데 있어 흥미롭고, 간단하며, 비용 효율적인 후보로 확실히 고려할 것입니다.

## 2. 처음부터 인스트럭션 파인튜닝(Instruction Finetuning)

LLM을 특정 작업이나 사용자의 의도에 맞게 정렬(align)하는 데 필수적인 인스트럭션 파인튜닝(instruction finetuning)은 단순히 모델을 학습시키는 것을 넘어, 모델의 행동을 형성하는 핵심 단계입니다. 처음부터 인스트럭션 파인튜닝 파이프라인(pipeline)을 구축하는 것은 LLM의 작동 원리를 깊이 이해하고, 특정 요구사항에 최적화된 모델을 개발하는 데 매우 중요합니다.

이 과정은 일반적으로 다음 단계를 포함합니다:
1.  **데이터 수집 및 큐레이션(Data Collection and Curation)**: 고품질의 인스트럭션-응답 쌍(instruction-response pairs)을 확보하는 것이 가장 중요합니다. 이는 수동 생성, 기존 데이터셋 활용, 또는 Magpie와 같은 합성 데이터 생성 방법을 통해 이루어질 수 있습니다. 데이터의 다양성과 품질은 최종 모델의 성능에 결정적인 영향을 미칩니다.
2.  **모델 선택 및 준비**: 파인튜닝할 기본 LLM을 선택하고, 토크나이저(tokenizer)를 설정하며, 모델이 훈련 데이터를 처리할 수 있도록 입력 형식(input formatting)을 지정합니다. 여기에는 패딩 토큰(padding tokens) 마스킹(masking)과 같은 세부적인 처리도 포함됩니다.
3.  **훈련 루프(Training Loop) 구현**: 선택한 옵티마이저(optimizer), 학습률(learning rate), 배치 크기(batch size) 등을 사용하여 모델을 훈련합니다. LoRA(Low-Rank Adaptation)와 같은 효율적인 파인튜닝 기법을 적용하여 훈련 비용을 절감하고, 과적합(overfitting)을 방지할 수 있습니다.
4.  **평가 및 검증**: 훈련된 모델의 성능을 평가하기 위해 사용자 정의 테스트 세트(custom test set)를 사용하여 인스트럭션 팔로잉(instruction-following) 능력, 응답 품질, 안전성 등을 측정합니다. 이는 모델이 의도한 대로 작동하는지 확인하고 필요한 경우 추가 개선을 위한 피드백을 제공합니다.

이러한 과정을 통해 개발자는 모델이 복잡한 지시를 이해하고, 일관되고 유용한 응답을 생성하며, 특정 도메인(domain)의 지식을 효과적으로 활용하도록 만들 수 있습니다. 인스트럭션 파인튜닝은 LLM을 단순한 텍스트 생성기에서 강력한 문제 해결 도구로 변모시키는 핵심 기술이라 할 수 있습니다.

## 3. 인스트럭션 사전 훈련(Instruction Pretraining) LLM

"Instruction Pre-Training: Language Models are Supervised Multitask Learners" (https://arxiv.org/abs/2406.14491) 논문에서 연구자들은 원본 텍스트(raw text) 대신 합성 인스트럭션-응답 쌍(synthetic instruction-response pairs)을 포함함으로써 LLM 사전 훈련(pretraining)을 더 효율적으로 만들 수 있는지 조사합니다. (여기서 "원본 텍스트(raw text)"는 특정 형식으로 재처리되지 않은 책, 웹사이트, 논문 등의 텍스트를 의미합니다.)

일반 사전 훈련(regular pretraining)(상단)과 제안된 인스트럭션 사전 훈련(instruction pretraining) 접근 방식(하단)의 비교 (https://arxiv.org/abs/2406.14491의 주석이 달린 그림을 통해)

### 3.1 인스트럭션 합성기(Instruction Synthesizer)

인스트럭션 사전 훈련(instruction pretraining)의 핵심 구성 요소는 바로 인스트럭션 합성기(instruction synthesizer)입니다. 이 논문에서는 Mistral 7B v0.1 LLM을 기반으로, HotpotQA와 같은 데이터셋을 사용하여 원본 텍스트에서 인스트럭션-응답 쌍을 생성하도록 파인튜닝된 모델을 사용합니다. 인스트럭션 합성기는 단순한 텍스트 변환을 넘어, 상식 추론(commonsense reasoning), 감성 분석(sentiment analysis), 수학 문제 해결 등 다양한 유형의 작업을 포괄하는 인스트럭션을 생성할 수 있어야 합니다. 이를 위해서는 합성기가 원본 텍스트의 의미를 깊이 이해하고, 그로부터 다양한 질문과 그에 대한 정확한 답변을 도출할 수 있는 능력을 갖추어야 합니다. 합성기의 품질은 최종적으로 사전 훈련되는 LLM의 성능에 직접적인 영향을 미치므로, 합성기 자체의 훈련 데이터셋 구성과 파인튜닝 전략이 매우 중요합니다.

### 3.2 인스트럭션 데이터(Instruction Data)를 사용한 사전 훈련(Pretraining)

연구 결과에 따르면, 인스트럭션 사전 훈련(Instruct PT) 접근 방식은 전통적인 사전 훈련(Vanilla PT)이나 원본 텍스트와 인스트럭션 데이터를 혼합한 훈련(Mix PT) 방식보다 대부분의 벤치마크(benchmark) 작업에서 우수한 성능을 보였습니다. 이는 LLM이 처음부터 다양한 작업 지향적(task-oriented) 데이터를 통해 학습할 때, 단순히 다음 토큰을 예측하는 것을 넘어 다중 작업 학습자(multitask learner)로서의 역량을 더욱 효과적으로 개발할 수 있음을 시사합니다. 모델은 초기 단계부터 인스트럭션 팔로잉(instruction following) 능력을 내재화하여, 이후 파인튜닝(finetuning) 단계에서 훨씬 더 효율적으로 정렬(alignment)될 수 있습니다. 이러한 접근 방식은 LLM이 단순히 언어 패턴을 학습하는 것을 넘어, 언어 뒤에 숨겨진 의도와 맥락을 이해하는 데 필요한 "지식"을 더욱 체계적으로 습득하도록 돕습니다.

### 3.3 인스트럭션 데이터(Instruction Data)를 사용한 연속 사전 훈련(Continual Pretraining)

인스트럭션 사전 훈련의 개념은 처음부터 모델을 훈련하는 것뿐만 아니라, 이미 사전 훈련된 모델을 특정 도메인(domain)에 맞게 조정하는 연속 사전 훈련(continual pretraining)에도 강력한 이점을 제공합니다. Llama 3 8B와 같은 범용 모델을 생의학, 금융, 법률 등 전문 분야에 특화시키고자 할 때, 해당 분야의 원본 텍스트와 함께 합성된 인스트럭션 데이터를 활용하면 모델이 해당 도메인의 복잡한 질문에 더 정확하고 유연하게 응답할 수 있게 됩니다. 이는 특정 도메인 LLM을 구축하는 데 드는 시간과 자원을 크게 절약하면서도, 최신 정보와 해당 도메인의 특성을 반영하는 모델을 만들 수 있는 효율적인 방법입니다. 합성 인스트럭션 데이터는 도메인 특화된 작업에 대한 모델의 이해도를 높여, 도메인 적응(domain adaptation) 과정에서 발생할 수 있는 치명적 망각(catastrophic forgetting) 문제를 완화하는 데도 기여할 수 있습니다.

### 3.4 결론

LLM 사전 훈련(pretraining)의 전통적인 방식이 주로 대규모 원본 텍스트 코퍼스(corpus)에 의존했던 것에 비해, 인스트럭션 사전 훈련은 새로운 패러다임(paradigm)을 제시합니다. 이는 LLM이 단순히 통계적 패턴을 학습하는 것을 넘어, 처음부터 "무엇을 해야 하는지"를 배우는 지도 다중 작업 학습자(supervised multitask learner)로 진화할 수 있음을 보여줍니다. 물론, 대규모 합성 인스트럭션 데이터를 생성하는 데 여전히 비용이 많이 들 수 있지만, 한 번 생성된 고품질 데이터는 여러 프로젝트에서 재활용될 수 있으며, 장기적으로는 LLM 개발의 효율성을 크게 향상시킬 것입니다. 이 연구는 미래의 LLM이 더욱 강력하고, 다재다능하며, 특정 작업에 최적화될 수 있는 기반을 마련했다고 평가할 수 있습니다.

## 4. Gemma 2

구글의 새로운 Gemma 2 모델을 언급하지 않고는 이 글을 쓸 수 없습니다. 이 모델은 지난달 가장 큰 모델 출시작이라고 할 수 있습니다. 그러나 순수한 크기 면에서는 엔비디아의 Nemotron-4 340B가 최고를 차지합니다 (https://arxiv.org/abs/2406.11704).

Gemma 2 모델은 2.6B, 9B, 27B 매개변수(parameter) 버전으로 제공됩니다. 이 글이 이미 상당히 길고, 여러분은 다른 출처를 통해 Gemma 2에 대해 이미 잘 알고 계실 것이므로, 바로 본론으로 들어가겠습니다. 구글이 새로 출시한 Gemma 2 LLM의 주요 특징과 주목할 만한 업데이트는 무엇일까요?

주요 주제는 훈련 데이터셋(training datasets)의 크기를 반드시 늘리지 않고, 오히려 비교적 작고 효율적인 LLM을 개발하는 데 초점을 맞춘 기술을 탐색하는 것입니다. 구체적으로, 그들은 2.6B 및 9B 매개변수(parameter) 모델을 만들기 위해 세 가지 주요 아키텍처(architectural) 및 훈련 선택을 혼합합니다: 슬라이딩 윈도우 어텐션(sliding window attention), 그룹 쿼리 어텐션(grouped-query attention), 그리고 지식 증류(knowledge distillation)입니다.

### 4.1 슬라이딩 윈도우 어텐션(Sliding window attention)

슬라이딩 윈도우 어텐션(Sliding window attention)은 Mistral과 같은 모델에서 인기를 얻은 기술로, LLM이 긴 컨텍스트(long context)를 효율적으로 처리할 수 있도록 돕습니다. 기존 어텐션 메커니즘(attention mechanism)이 모든 이전 토큰(token)에 어텐션하는 것과 달리, 슬라이딩 윈도우 어텐션은 고정된 크기의 윈도우(window) 내에서만 어텐션을 수행합니다. Gemma 2에서는 일반 어텐션 레이어(regular attention layer)와 슬라이딩 윈도우 어텐션 레이어(sliding window attention layer)를 번갈아 사용하여 효율성과 성능의 균형을 맞췄습니다. 이 방식은 컨텍스트 길이(context length)가 길어질수록 기하급수적으로 증가하는 계산 비용을 선형적으로 줄여, 메모리 사용량과 추론(inference) 속도를 크게 개선합니다. 이는 제한된 하드웨어 자원을 가진 환경에서도 LLM을 활용할 수 있게 하는 중요한 발전입니다.

### 4.2 그룹 쿼리 어텐션(Group-query attention)

그룹 쿼리 어텐션(Group-query attention, GQA)은 LLM의 추론 효율성을 높이는 또 다른 핵심 기술입니다. 이는 Llama 2 및 Llama 3와 같은 최신 모델에서도 채택되었습니다. GQA는 여러 쿼리 헤드(query heads)가 동일한 키(keys) 및 값(values) 헤드(heads) 세트를 공유하도록 하여, 다중 쿼리 어텐션(Multi-Query Attention, MQA)의 개념을 일반화한 것입니다. 이를 통해 모델의 훈련 가능한 매개변수(trainable parameters) 수를 줄이고, 특히 추론 시 KV 캐시(cache)의 메모리 사용량을 대폭 절감할 수 있습니다. 결과적으로, GQA는 모델의 계산 요구 사항을 낮추면서도 거의 동등한 성능을 유지하여, 더 큰 모델을 효율적으로 배포하고 서비스할 수 있게 합니다.

### 4.3 지식 증류(Knowledge distillation)

지식 증류(Knowledge distillation)는 더 크고 복잡한 교사 모델(teacher model)의 지식을 더 작고 효율적인 학생 모델(student model)로 전달하는 기술입니다. Gemma 2의 경우, 27B 교사 모델을 먼저 훈련한 다음, 이 교사 모델의 출력(logits)을 사용하여 2.6B 및 9B 학생 모델을 훈련했습니다. 이 방법은 단순히 더 작은 모델을 처음부터 훈련하는 것보다, 교사 모델의 풍부한 지식을 활용하여 학생 모델의 성능을 크게 향상시킬 수 있습니다. 특히, 지식 증류는 모델의 크기를 줄이면서도 추론 속도를 높이고, 에너지 소비를 줄여 모바일 장치나 엣지 디바이스(edge device)와 같은 자원 제약이 있는 환경에 LLM을 배포하는 데 매우 효과적인 전략입니다.

### 4.4 기타 흥미로운 아키텍처(architecture) 세부 정보

Gemma 2는 앞서 언급한 주요 기술 외에도 여러 흥미로운 아키텍처적(architectural) 특징을 가지고 있습니다. 256,000 토큰(token)에 달하는 큰 어휘 크기(vocabulary size)는 이 모델의 주목할 만한 특징 중 하나입니다. 이는 Llama 3(128,000)나 Phi-3(32,000)와 비교했을 때 훨씬 넓은 범위의 단어와 개념을 포괄하며, 다국어 처리 능력과 토큰화 아티팩트(tokenization artifacts) 감소에 기여합니다. 또한, "로짓 캐핑(logit capping)"이라는 기술은 훈련 중 로짓 값(logit values)을 특정 범위 내로 유지하여 모델의 안정성을 높이고 기울기 흐름(gradient flow)을 개선하는 데 사용되었습니다. 이는 `logits ← soft_cap * tanh(logits/soft_cap)`와 같은 방식으로 구현되며, 모델이 예측을 할 때 너무 극단적인 값을 가지는 것을 방지합니다. 이 외에도, Gemma 2는 다양한 하이퍼파라미터(hyperparameters)로 훈련된 여러 모델을 결합하는 모델 병합 기술(model merging techniques)을 활용하여 최종 성능을 최적화했습니다. 이는 WARP(Weight Averaged Rewarded Policies)와 같은 접근 방식을 통해 이루어졌습니다.

### 4.5 결론

Gemma 2는 작고 효율적인 모델을 통해 대형 모델에 필적하는 성능을 달성하려는 구글의 노력을 잘 보여줍니다. 슬라이딩 윈도우 어텐션, 그룹 쿼리 어텐션, 지식 증류와 같은 기술의 조합은 Gemma 2를 단일 GPU 사용 사례(single-GPU use cases)에서 가장 유능한 모델 중 하나로 만듭니다. 특히, 구글이 이 모델에 대해 비교적 상세한 기술 보고서를 공개했다는 점은 학계와 개발 커뮤니티에 귀중한 통찰력을 제공하며, LLM 연구의 투명성과 협력을 촉진하는 긍정적인 신호입니다. Gemma 2의 출시는 오픈 소스 LLM 생태계에 큰 활력을 불어넣고 있으며, 더 작고 효율적인 모델 개발의 중요성을 다시 한번 강조합니다.

## Ahead of AI 지원하기

Ahead of AI는 직접적인 보상을 제공하지 않는 개인적인 열정 프로젝트입니다. 그러나 저를 지원하고 싶으신 분들은 제 책을 구매해 주시면 감사하겠습니다. 이 책들이 통찰력 있고 유익하다고 생각하시면, 친구와 동료들에게 자유롭게 추천해 주십시오. 잠시 시간을 내어 Amazon에 Machine Learning Q and AI 또는 Machine Learning with PyTorch and Scikit-Learn에 대한 리뷰를 남겨주시면 큰 도움이 될 것입니다! 여러분의 지원은 저에게 큰 의미이며, 이 여정을 계속하는 데 엄청난 도움이 됩니다. 감사합니다!

## 5. 최근 LLM 연구 논문 하이라이트

아래는 최근 제가 주목했던 흥미로운 LLM 연구 논문들입니다. 이 목록은 LLM 기술의 최신 동향과 실용적인 적용 가능성에 초점을 맞추고 있습니다.

*   **Scaling Synthetic Data Creation with 1,000,000,000 Personas** by Chan, Wang, Yu, et al. (6월 28일), https://arxiv.org/abs/2406.20094
    이 연구는 LLM을 활용하여 방대한 페르소나(persona) 컬렉션인 페르소나 허브(Persona Hub)를 구축하고, 이를 기반으로 다양한 합성 데이터(synthetic data)를 생성하는 방법론을 제안합니다. 이는 데이터 다양성 확보와 모델의 일반화 능력 향상에 기여할 수 있습니다.

*   **LLM Critics Help Catch LLM Bugs** by McAleese, Pokorny, Ceron Uribe, et al. (6월 28일), https://arxiv.org/abs/2407.00215
    RLHF를 통해 훈련된 "비평가(critic)" 모델이 LLM이 생성한 코드(code)의 오류를 평가하고 자연어 피드백을 제공하여, 코드 품질 검증 및 디버깅(debugging) 프로세스를 효율화하는 방법을 제시합니다.

*   **Direct Preference Knowledge Distillation for Large Language Models** by Li, Gu, Dong, et al. (6월 28일), https://arxiv.org/abs/2406.19774
    이 논문은 LLM을 위한 지식 증류(Knowledge Distillation)를 두 단계로 재구성하는 DPKD 방법을 소개합니다. 암묵적 보상(implicit reward)과 역 KL 발산(reverse KL divergence)을 최적화하고, 교사 모델(teacher model) 출력에 대한 선호도 확률을 높여 학생 모델(student model)의 성능을 향상시킵니다.

*   **Changing Answer Order Can Decrease MMLU Accuracy** by Gupta, Pantoja, Ross, et al. (6월 27일), https://arxiv.org/abs/2406.19470
    MMLU 벤치마크(benchmark)에서 답변 순서가 모델의 정확도에 미치는 영향을 분석한 연구로, 답변 레이블(label)의 내용을 섞는 것만으로도 모델 전반에 걸쳐 정확도가 감소할 수 있음을 보여줍니다.

*   **Dataset Size Recovery from LoRA Weights** by Salama, Kahana, Horwitz, and Hoshen (6월 27일), https://arxiv.org/abs/2406.19395
    LoRA 행렬의 노름(norm)과 스펙트럼(spectrum) 분석을 통해 LoRA 파인튜닝(finetuning)에 사용된 원본 이미지(image) 수를 복구하는 방법을 제시하며, 이는 데이터셋 프라이버시(privacy) 및 모델 투명성(transparency)에 대한 새로운 시사점을 제공합니다.

*   **Step-DPO: Step-wise Preference Optimization for Long-chain Reasoning of LLMs** by Azerbayev, Shao, Lin, et al. (6월 26일), https://arxiv.org/abs/2406.18629
    LLM의 수학 문제 해결 능력 향상을 위해 개별 추론 단계(reasoning steps)를 최적화하는 Step-DPO 방법을 소개하며, 맞춤형 단계별 선호도 데이터셋(step-wise preference dataset)을 활용합니다.

*   **\* A Closer Look into Mixture-of-Experts in Large Language Models** by Zhang, Liu, Patel, et al. (6월 26일), https://arxiv.org/abs/2406.18219
    Mixture-of-Experts (MoE) LLM의 내부 작동 방식에 대한 심층 분석을 제공하며, 뉴런(neuron) 동작, 전문가 선택 기준(expert selection criteria) 및 전문가 다양성(expert diversity)에 대한 통찰력을 공유하여 MoE 설계에 대한 실용적인 제안을 제시합니다.

*   **\* Following Length Constraints in Instructions** by Yuan, Kulikov, Yu, et al. (6월 25일), https://arxiv.org/abs/2406.17744
    추론(inference) 시 사용자가 지정한 길이 제약(length constraints)을 따를 수 있는 LLM을 훈련하는 방법을 소개하며, 길이 제어 작업(length-controlled tasks)에서 기존 모델보다 뛰어난 성능을 보입니다.

*   **\* The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale** by He, Wang, Shen, et al. (6월 25일), https://arxiv.org/abs/2406.17557
    Common Crawl에서 파생된 15조 토큰(token) 데이터셋(dataset)인 FineWeb과 1.3조 토큰(token) 교육 서브셋(educational subset)인 FineWeb-Edu를 소개하며, LLM 훈련을 위한 고품질 데이터셋의 중요성을 강조합니다.

*   **\* A Tale of Trust and Accuracy: Base vs. Instruct LLMs in RAG Systems** by Cuconasu, Trappolini, Tonellotto, et al. (6월 21일), https://arxiv.org/abs/2406.14972
    이 연구는 검색 증강 생성(Retrieval Augmented Generation, RAG) 시스템에서 기본 LLM이 인스트럭션 튜닝(instruction-tuned) 모델보다 우수한 성능을 보일 수 있음을 입증하며, 기존의 통념에 도전합니다.

*   **\* Can Long-Context Language Models Subsume Retrieval, RAG, SQL, and More?** by Wu, Zhang, Johnson, et al. (6월 19일), https://arxiv.org/abs/2406.13121
    수백만 개의 토큰(token)을 요구하는 작업에서 긴 컨텍스트(long-context) LLM의 성능을 평가하는 벤치마크(benchmark)를 소개하며, 이들이 인컨텍스트 검색(in-context retrieval) 및 추론 작업(reasoning tasks)에서 전문화된 RAG 시스템과 경쟁할 수 있음을 보여줍니다.

*   **\* DeepSeek-Coder-V2: Breaking the Barrier of Closed-Source Models in Code Intelligence** by Zhu, Wang, Lee, et al. (6월 17일), https://arxiv.org/abs/2406.11931
    DeepSeek-Coder-V2는 추가 6조 토큰(token)에 대한 연속 사전 훈련(continued pretraining)을 통해 코딩 작업(coding tasks)에서 GPT4-Turbo 수준의 성능을 달성하는 오픈 소스(open-source) Mixture-of-Experts 코드 LLM입니다.

*   **\* Nemotron-4 340B Technical Report** by Unknown Authors at NVIDIA (6월 17일), https://arxiv.org/abs/2406.11704
    엔비디아의 Nemotron-4 340B 모델 제품군(model family)에 대한 기술 보고서로, 다양한 벤치마크(benchmark)에서 경쟁력 있는 성능을 보이며 합성 데이터 생성(synthetic data generation)에 탁월한 능력을 보여줍니다.

*   **\* How Do Large Language Models Acquire Factual Knowledge During Pretraining?** by Chang, Park, Ye, et al. (6월 17일), https://arxiv.org/abs/2406.11813
    LLM이 사전 훈련(pretraining) 과정에서 사실적 지식(factual knowledge)을 어떻게 습득하는지에 대한 메커니즘(mechanism)을 분석한 연구입니다.

*   **\* Samba: Simple Hybrid State Space Models for Efficient Unlimited Context Language Modeling** (6월 11일), https://arxiv.org/abs/2406.07522
    Samba는 선택적 상태 공간 모델(selective state space models)(Mamba)과 슬라이딩 윈도우 어텐션(sliding window attention)을 결합한 하이브리드 모델(hybrid model)로, 3.8B 매개변수(parameters)까지 효율적으로 확장되는 언어 모델링(language modeling) 방법을 제안합니다.

*   **\* Never Miss A Beat: An Efficient Recipe for Context Window Extension of Large Language Models with Consistent "Middle" Enhancement** (6월 11일) by Wu, Zhao, and Zheng, https://arxiv.org/abs/2406.07138
    CREAM은 위치 인코딩(positional encodings)을 보간하고 가우시안(Gaussian)을 사용하여 중간 컨텍스트 정보(middle-context information)를 우선시함으로써 LLM의 컨텍스트 길이(context length)를 효율적으로 확장하는 훈련 기법입니다.

*   **\* Self-Tuning: Instructing LLMs to Effectively Acquire New Knowledge through Self-Teaching** by Zhang, Peng, Zhou, et al. , (6월 10일), https://arxiv.org/abs/2406.06326
    셀프 튜닝(Self-Tuning) 프레임워크(framework)는 기억(memorization), 이해(comprehension) 및 자기 성찰(self-reflection)에 초점을 맞춘 자기 학습 작업(self-teaching tasks)을 통해 원본 문서(raw documents)로부터 LLM의 지식 습득(knowledge acquisition)을 향상시킵니다.

*   **\* Scalable MatMul-free Language Modeling** by Zhu, Zhang, Sifferman, et al. (6월 4일), https://arxiv.org/abs/2406.02528
    행렬 곱셈(matrix multiplications) 없이 요소별 곱셈(element-wise products)과 삼진 가중치(ternary weights)를 사용한 누적(accumulations)으로 대체하는 확장 가능한 MatMul-free 언어 모델 아키텍처(language model architecture)를 제시하며, 이는 수십억 매개변수(billion-parameter) 규모에서도 잘 작동합니다.

*   **\* Large Language Models Must Be Taught to Know What They Don't Know** by Kapoor, Gruver, Roberts, et al. (6월 12일), https://arxiv.org/abs/2406.08391
    등급이 매겨진 예제(graded examples)의 작은 데이터셋(dataset)으로 LLM을 파인튜닝(finetuning)하는 것이 프롬프트(prompting)만 사용하는 것보다 더 신뢰할 수 있는 불확실성 추정치(uncertainty estimates)를 생성할 수 있음을 보여줍니다.

*   **\* An Empirical Study of Mamba-based Language Models** by Waleffe, Byeon, Riach, et al. (6월 12일), https://arxiv.org/abs/2406.07887
    Mamba와 같은 상태 공간 모델(state-space models)과 트랜스포머 모델(Transformer models)을 비교하며, 순수 상태 공간 모델이 많은 작업에서 트랜스포머와 동등하거나 그 이상이지만, 특정 복잡한 작업에서는 뒤처질 수 있음을 밝혀냅니다.

*   **\* Are We Done with MMLU?** by Gema, Leang, Hong, et al. (6월 6일), https://arxiv.org/abs/2406.04127
    널리 사용되는 MMLU 벤치마크(benchmark)에서 수많은 오류를 식별하고, 재주석된 서브셋(re-annotated subset)인 MMLU-Redux를 통해 보고된 모델 성능(model performance)의 불일치를 드러냅니다.

*   **\* Transformers Need Glasses! Information Over-Squashing in Language Tasks** by Barbero, Banino, Kapturowski, et al. (6월 6일), https://arxiv.org/abs/2406.04267
    LLM의 정보 전파(information propagation)를 분석하여, 표현 붕괴 현상(representational collapse phenomenon)이 발생할 수 있음을 밝혀내고, 이는 특정 작업에서 오류를 유발하고 입력 토큰(input tokens)에 대한 민감도(sensitivity)를 상실하게 한다고 주장합니다.

*   **The Prompt Report: A Systematic Survey of Prompting Techniques** by Schulhoff, Ilie, Balepur, et al. (6월 6일), https://arxiv.org/abs/2406.06608
    이 포괄적인 논문은 프롬프트(prompts) 및 프롬프트 기술(prompting techniques)을 이해하기 위한 명확하고 체계적인 프레임워크(framework)를 제공하는 것을 목표로 합니다.

## Ahead of AI 지원하기

이 매거진은 직접적인 보상을 제공하지 않는 개인적인 열정 프로젝트입니다. 그러나 저를 지원하고 싶으신 분들은 제 책 중 한 권을 구매해 주시면 감사하겠습니다. 이 책들이 통찰력 있고 유익하다고 생각하시면, 친구와 동료들에게 자유롭게 추천해 주십시오. (Amazon에 책 리뷰를 통해 다른 사람들과 피드백을 공유하는 것도 큰 도움이 됩니다!)

Build A Large Language Model (From Scratch), Machine Learning Q And AI, and Machine Learning with PyTorch and Scikit-Learn

여러분의 지원은 저에게 큰 의미입니다! 감사합니다!