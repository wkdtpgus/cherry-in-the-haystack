AI 선도자들은 AI가 암 치료, 인간 수명 두 배 연장, 우주 식민지화, 그리고 다음 10년 안에 1세기 분량의 발전을 이루는 등 극적인 과학적 진보를 가능하게 할 것이라고 예측했습니다. 미국에서 과학 분야 연방 기금 삭감이 이루어지는 상황에서, AI가 대규모 과학 인력의 필요성을 대체할 수 있으므로 시기는 완벽해 보입니다. 적어도 기술자들 사이에서는 AI가 과학 파이프라인의 모든 부분, 즉 기존 문헌 요약, 새로운 아이디어 생성, 데이터 분석 및 실험 수행, 연구 결과 작성, "동료" 검토 수행 등에 도입되면서 과학을 크게 가속화할 것이라는 상식적인 견해가 있습니다. 그러나 새로운 기술이 기존 제도에 미치는 영향에 대한 많은 초기 상식적인 예측들은 심각하게 틀렸음이 입증되었습니다. 이 에세이의 분석은 AI가 이러한 격차를 악화시킬 가능성이 높다고 시사합니다.

"AI as Normal Technology" 프레임워크에 기반한 분석 및 논평

**목차**
1.  과학의 진보와 생산-진보 역설
2.  진보 둔화의 다면적 원인과 AI의 역할
3.  과학 연구의 소프트웨어 및 AI 통합 과제
4.  예측에서 이해로: AI 모델링의 한계와 가능성
5.  인간의 이해, 여전히 과학의 핵심
6.  AI 시대, 과학의 미래를 위한 제언
7.  마지막 생각

### 1. 과학의 진보와 생산-진보 역설

총 출판 논문 수는 기하급수적으로 증가하여 12년마다 두 배로 늘어나고 있습니다. 연구 논문을 저술한 연구자의 총수는 훨씬 더 빠르게 증가하고 있습니다. 그리고 2000년에서 2021년 사이에 상위 7개 자금 지원국(미국, 중국, 일본, 독일, 한국, 영국, 프랑스) 전반에 걸쳐 연구 개발 투자는 4배 증가했습니다. 하지만 이것이 더 빠른 진보를 의미할까요? 반드시 그렇지는 않습니다. 일부 논문은 과학의 궤적을 바꾸는 근본적인 돌파구로 이어지는 반면, 다른 논문들은 알려진 결과에 사소한 개선을 더합니다. 진정한 진보는 우리의 이해에 대한 돌파구에서 비롯됩니다. 예를 들어, 우리는 지난 세기 중반에 대륙이 움직인다는 판 구조론(plate tectonics)을 이해했습니다. 그 전에는 지질학자들은 올바른 질문조차 할 수 없었습니다. 그들은 지구가 식는 효과를 알아내려고 노력했는데, 그것이 산과 같은 지질학적 특징을 초래했다고 믿었기 때문입니다. 오래된 지질학 패러다임(paradigm)에서의 어떤 연구 결과나 논문도 판 구조론이 이룬 것과 같은 진보를 가져오지 못했을 것입니다. 따라서 논문 수는 기하급수적으로 증가하지만 진보는 같은 속도로 증가하지 않거나 심지어 둔화될 가능성이 있습니다.

이러한 "생산-진보 역설(production-progress paradox)"은 현대 과학의 가장 중요한 도전 과제 중 하나입니다. 메타과학 연구는 이 현상에 대한 다양한 증거를 제시하고 있습니다. 예를 들어, 최근 연구들은 논문의 파괴성(disruptiveness)이 점차 감소하고 있으며, 새로운 아이디어를 도입하는 연구가 줄어들고 있음을 보여줍니다. 또한, 노벨상 수상 연구와 같은 중요한 발견이 이루어지는 시점과 그것이 인정받는 시점 사이의 간격이 길어지고 있다는 분석도 있습니다. 이는 단순히 생산량의 증가가 진정한 의미의 과학적 돌파구로 이어지지 않음을 시사합니다. 과학의 목표가 무엇인지, 그리고 진보를 어떻게 측정할 것인지에 대한 근본적인 질문 없이는, 우리는 양적인 성장에만 매몰되어 질적인 쇠퇴를 간과할 위험이 있습니다. 특히 AI 기술의 급격한 발전은 이러한 역설을 심화시킬 수 있는 잠재력을 가지고 있습니다. AI가 연구 생산성을 높이는 데 기여할 수는 있지만, 그것이 진정한 진보로 이어질지는 미지수입니다. 우리는 AI가 과학의 생산성을 가속화하는 동시에, 오히려 진보의 속도를 늦추는 역효과를 낼 수 있는 메커니즘을 면밀히 검토해야 합니다.

### 2. 진보 둔화의 다면적 원인과 AI의 역할

진보 둔화에 대한 가장 흔한 설명 중 하나는 "낮은 곳에 열린 과일 가설(low-hanging fruit hypothesis)"입니다. 이 가설은 쉬운 발견은 이미 이루어졌고, 남아있는 문제들은 점점 더 어려워진다는 주장입니다. 그러나 이 가설은 종종 반박됩니다. 과학 도구의 발전과 새로운 분야의 등장은 항상 새로운 "낮은 곳에 열린 과일"을 만들어내기 때문입니다. 오히려, 진보 둔화의 더 설득력 있는 원인들은 과학 시스템 자체의 비효율성과 인센티브 구조에 있습니다.

그 중 하나는 과학 연구의 "과잉 생산(overproduction)" 문제입니다. 매년 쏟아져 나오는 방대한 양의 논문은 개별 연구자의 주의력(attention)을 분산시키고, 진정으로 혁신적인 아이디어가 주목받기 어렵게 만듭니다. 이러한 "주의력 불평등(inequality of attention)"은 기존의 잘 인용된 논문들을 더욱 공고히 하고, 새로운 패러다임을 제시하는 연구가 정설로 자리 잡는 것을 방해합니다. AI는 이러한 과잉 생산을 더욱 심화시킬 수 있습니다. AI 기반 도구들은 논문 작성 및 데이터 분석을 가속화하여, 연구자들이 더 많은 논문을 더 빠르게 생산할 수 있게 합니다. 이는 단기적인 생산성 향상으로 보일 수 있지만, 장기적으로는 "소음"을 증폭시켜 진정한 돌파구를 식별하기 더 어렵게 만들 수 있습니다.

또 다른 핵심 원인은 "출판 아니면 소멸(publish-or-perish)"이라는 학계의 인센티브 구조입니다. 대학과 연구 기관은 연구자들을 논문 수, 인용 횟수, 연구비 수주액 등 양적인 지표로 평가하는 경향이 있습니다. 이러한 인센티브는 연구자들이 위험 회피적인(risk-averse) 연구를 선택하고, 단기적인 성과를 낼 수 있는 증분적(incremental) 연구에 집중하게 만듭니다. 피터 힉스(Peter Higgs)와 같은 노벨상 수상자조차 현대 학계에서는 자신의 연구 방식으로는 일자리를 얻기 어려웠을 것이라고 언급했을 정도입니다. AI는 이러한 경향을 더욱 부추길 수 있습니다. AI를 활용하여 기존 연구를 약간 개선하거나, 새로운 데이터를 빠르게 분석하여 논문을 양산하는 것은 개별 연구자에게는 유리할 수 있습니다. 그러나 이는 진정한 돌파구를 위한 오랜 시간과 높은 위험을 수반하는 연구를 저해하고, 결국 집단적인 진보의 속도를 늦출 것입니다. 또한, 연구 분야의 지나친 전문화와 복잡성 증가, 규제 부담의 증가, 그리고 연구에 필요한 지식의 양(burden of knowledge)이 기하급수적으로 늘어나는 것 또한 진보 둔화의 원인으로 지목됩니다. AI는 이러한 문제들을 해결할 잠재력도 있지만, 동시에 새로운 복잡성을 야기하거나 기존의 병목 현상을 가속화할 수도 있습니다.

### 3. 과학 연구의 소프트웨어 및 AI 통합 과제

과학은 수십 년 동안 소프트웨어 사용에 있어 업계 표준에 뒤처져 왔습니다. 자동화된 테스트, 버전 관리, 프로그래밍 설계 지침 준수와 같은 모범 사례는 연구 커뮤니티에서 여전히 드물게 적용됩니다. 이러한 소프트웨어 공학의 부재는 연구 결과의 재현성(reproducibility)과 신뢰성을 저해하는 주요 원인입니다. AI, 특히 생성형 AI(generative AI)의 도입은 이러한 문제를 더욱 복잡하게 만듭니다. AI는 연구자들이 코드를 작성하고 데이터를 분석하는 과정을 가속화할 수 있지만, AI가 생성한 코드나 분석 결과의 품질과 정확성을 검증하는 것은 새로운 도전 과제로 떠오르고 있습니다.

최근 보고서에 따르면, AI 모델을 사용하여 생성된 코드에는 미묘한 오류나 비효율성이 포함될 수 있으며, 이를 식별하고 수정하는 데 상당한 전문 지식이 필요합니다. 또한, AI 모델 자체의 "블랙박스(black box)" 특성은 과학적 과정의 투명성을 저해하고, 결과에 대한 신뢰를 떨어뜨릴 수 있습니다. 예를 들어, 의료 진단이나 신약 개발과 같은 민감한 분야에서 AI 모델이 내린 결정의 근거를 설명하기 어렵다면, 그 활용은 제한될 수밖에 없습니다. 과학 커뮤니티는 AI를 연구 프로세스에 통합하기 전에, 소프트웨어 공학의 모범 사례를 시급히 도입하고, AI 모델의 검증 및 해석 가능성(interpretability)에 대한 새로운 표준을 마련해야 합니다. 이는 단순히 기술적인 문제를 넘어, 과학적 무결성(integrity)과 신뢰성을 유지하기 위한 근본적인 변화를 요구합니다. AI의 잠재력을 최대한 활용하면서도 그 위험을 최소화하기 위해서는, 연구자들이 AI 도구에 대한 깊은 이해와 비판적 사고를 갖추는 것이 필수적입니다. AI는 강력한 도구이지만, 그 사용에 대한 책임은 여전히 인간 연구자에게 있습니다.

### 4. 예측에서 이해로: AI 모델링의 한계와 가능성

최근 Nature 저널의 논평에서 우리는 천문학의 지구 중심 모델(geocentric model)에 대한 비유를 통해 이를 설명했습니다. 지구 중심 모델—지구를 중심으로 하는 우주 모델—은 행성의 움직임을 예측하는 데 매우 정확했습니다. "주전원(epicycles)"과 같은 우회적인 방법들은 이러한 예측을 정확하게 만들었습니다. ... 지구 중심 모델은 어떻게 태양 중심 모델—행성들이 태양 주위를 도는 모델—에 찬성하여 전복되었을까요? 두 모델의 정확도가 비슷했기 때문에, 두 모델의 정확도를 비교하는 것으로는 해결될 수 없었습니다. 오히려, 태양 중심 모델이 행성 운동에 대해 훨씬 더 간단한 설명을 제공했기 때문입니다. 다시 말해, 지구 중심설에서 태양 중심설로 나아가기 위해서는 단순히 더 정확한 모델에 의존하는 것이 아니라 이론적 진보(theoretical advance)가 필요했습니다.

이 비유는 AI 기반 모델링의 핵심적인 한계를 보여줍니다. AI는 방대한 데이터를 기반으로 놀라운 예측 정확도(predictive accuracy)를 달성할 수 있지만, 종종 그 현상에 대한 근본적인 이해를 제공하지는 못합니다. 예를 들어, 약물 개발 분야에서 AI는 특정 화합물이 질병에 효과적일지 예측하는 데 사용될 수 있습니다. 그러나 AI가 왜 그런 예측을 하는지, 즉 어떤 생물학적 메커니즘이 작용하는지에 대한 통찰을 제공하지 못한다면, 이는 새로운 약물 표적을 발견하거나 질병의 본질을 이해하는 데 도움이 되지 않을 수 있습니다. AI가 단순히 "주전원"을 추가하여 예측을 개선하는 데 탁월하다면, 우리는 결함 있는 이론에 대한 의존을 연장시키고 진정한 이론적 진보를 방해할 위험이 있습니다.

이러한 문제에 대응하기 위해 "설명 가능한 AI(Explainable AI, XAI)"와 같은 분야가 부상하고 있습니다. XAI는 AI 모델의 내부 작동 방식과 예측 근거를 인간이 이해할 수 있는 형태로 설명하려는 시도입니다. 그러나 현재 XAI 기술은 아직 초기 단계이며, 복잡한 AI 모델의 모든 측면을 완벽하게 설명하기는 어렵습니다. 과학에서 AI 모델링의 진정한 가치는 단순히 예측을 넘어, 새로운 가설을 생성하고, 복잡한 현상의 숨겨진 패턴을 드러내며, 인간의 직관을 보완하는 데 있습니다. 이를 위해서는 AI 모델이 제공하는 예측과 함께, 그 예측이 도출된 방식에 대한 심층적인 분석과 인간의 해석이 필수적입니다. AI가 과학적 발견의 도구로 효과적으로 사용되려면, 예측 정확도와 함께 이론적 이해와 설명 가능성을 동시에 추구하는 방향으로 발전해야 합니다.

### 5. 인간의 이해, 여전히 과학의 핵심

…[수학자들이] 하는 일은 사람들이 수학을 이해하고 생각하는 방법을 찾는 것입니다. 컴퓨터와 사람이 매우 다르기 때문에 컴퓨터의 빠른 발전은 이 점을 극적으로 보여주었습니다. 예를 들어, Appel과 Haken이 대규모 자동 계산을 사용하여 4색 지도 정리(4-color map theorem)의 증명을 완성했을 때, 많은 논란을 불러일으켰습니다. 저는 그 논란이 정리의 진실성이나 증명의 정확성에 대한 사람들의 의심과는 거의 관련이 없다고 해석합니다. 오히려, 그것은 정리가 참이라는 지식 외에 증명에 대한 인간적 이해를 지속적으로 갈망하는 것을 반영했습니다. ... 그들은 이러한 경험을 통해 자신이 정말로 원하는 것은 보통 "답"의 모음이 아니라 이해라는 것을 깨닫습니다. [원문 강조]

윌리엄 서스턴(William Thurston)의 통찰은 과학적 진보의 본질이 단순히 문제를 해결하거나 정리를 증명하는 것을 넘어, 인간의 이해를 심화하는 데 있음을 강조합니다. AI는 복잡한 계산을 수행하고 패턴을 식별하며, 심지어 새로운 가설을 생성하는 데 탁월할 수 있습니다. 그러나 이러한 과정이 인간의 깊은 이해로 이어지지 않는다면, 그것은 진정한 과학적 진보라고 보기 어렵습니다. AI가 미해결 연구 문제(open research problems)에 대한 "해답"을 제공하더라도, 그 해답이 도출된 과정을 인간이 이해하고 내재화하지 못한다면, 그 지식은 단절된 채로 남아 새로운 질문을 생성하거나 다른 분야로 확장될 수 없습니다.

AI가 인간의 이해 과정을 단축시키거나 우회하게 만든다면, 우리는 과학적 직관, 창의성, 그리고 우연한 발견(serendipity)의 기회를 잃을 수 있습니다. 과학적 발견은 종종 예상치 못한 관찰, 여러 분야의 지식 통합, 그리고 수많은 시행착오 끝에 얻어지는 통찰에서 비롯됩니다. AI가 이러한 과정을 자동화하려 할 때, 인간이 스스로 지식을 탐구하고 개념적 연결을 구축하는 경험을 박탈할 위험이 있습니다. 이는 새로운 과학자를 훈련시키고, 혁신적인 이론을 개발하며, 궁극적으로 인류의 지식 지평을 확장하는 능력에 부정적인 영향을 미칠 수 있습니다. 따라서 AI를 과학 연구에 활용할 때, 우리는 AI가 인간의 이해를 보완하고 확장하는 도구로서 기능하도록 설계해야 합니다. AI가 단순히 정답을 제시하는 "신탁(oracle)"이 아니라, 인간 연구자가 더 깊이 이해하고 탐구할 수 있도록 돕는 "조력자"가 되어야 합니다. 이를 위해서는 AI의 활용 방식에 대한 신중한 고려와 함께, 인간의 이해와 통찰을 가치 있게 여기는 새로운 과학적 문화가 필요합니다.

### 6. AI 시대, 과학의 미래를 위한 제언

지난 10년 동안 과학자들은 AI를 채택하기 위해 맹렬히 달려왔습니다. 이러한 속도는 품질 관리를 유지하고 과학의 본질적으로 인간적인 것을 식별하고 보존하기 위해 느리게 움직이는 과학 기관의 규범(institutional norms)을 조정할 수 있는 능력을 희생시켰습니다. 결과적으로, 이러한 추세는 생산-진보 역설(production-progress paradox)을 악화시켜 논문 출판을 가속화할 것이지만, 진정한 과학적 진보에 관해서는 우리를 더 깊은 수렁으로 빠뜨릴 가능성이 높습니다. AI를 사용하는 논문의 수는 2012년에서 2022년 사이에 20개 분야에 걸쳐 4배 증가했습니다. 이는 대규모 언어 모델(large language models)이 채택되기 전의 일입니다.

Duede et al. 의 그림.

그렇다면 과학계는 무엇을 다르게 해야 할까요? 개별 연구자, 자금 지원 기관, 출판사 및 기타 문지기(gatekeepers), 그리고 AI 기업의 역할에 대해 이야기해 봅시다.

**과학적 관행 변경 및 새로운 교육 모델 도입**
개별 연구자들은 AI를 단순히 생산성 도구로 여기는 것을 넘어, 그 한계와 잠재적 위험을 이해해야 합니다. 소프트웨어 공학의 기본 원칙을 숙지하고, AI 기반 분석의 재현성과 투명성을 보장하는 데 적극적으로 참여해야 합니다. 예를 들어, AI 모델의 학습 데이터, 코드, 그리고 모델 자체를 공개하고 공유하는 오픈 사이언스(Open Science) 관행을 채택하는 것이 중요합니다. 또한, AI 윤리 및 책임 있는 AI(Responsible AI)에 대한 교육을 강화하여, 연구자들이 AI의 편향성(bias), 환각(hallucination) 등의 문제를 인식하고 완화할 수 있도록 해야 합니다. AI를 "목발(crutch)"처럼 사용하여 전문 지식(expertise)을 잃지 않도록, AI는 인간의 비판적 사고와 창의성을 증진시키는 보조 도구로 활용되어야 합니다.

**메타과학(metascience)에 대한 전략적 투자 확대**
메타과학은 과학 시스템 자체를 연구하여 진보를 가속화하는 방법을 찾는 데 필수적입니다. 현재 메타과학에 대한 투자는 전체 과학 연구 자금의 극히 일부에 불과합니다. 우리는 이 투자를 대폭 확대하여, 진보의 측정 기준을 개발하고, AI가 과학적 무결성(integrity)과 재현성에 미치는 영향을 심층적으로 분석해야 합니다. 특히, AI가 연구 과정에서 발생하는 오류를 어떻게 감지하고 예방할 수 있는지, 그리고 AI가 과학적 편향을 어떻게 줄일 수 있는지에 대한 연구가 시급합니다. 메타과학은 또한 과학 커뮤니티의 인센티브 구조가 진정한 진보를 장려하는지 여부를 평가하고, AI 시대에 적합한 새로운 모델을 제안하는 역할을 해야 합니다.

**인센티브 개혁: 양에서 질로, 단기에서 장기로**
현재의 "출판 아니면 소멸" 문화는 AI의 도입으로 더욱 심화될 위험이 있습니다. 우리는 논문의 양적 지표에 대한 의존을 줄이고, 연구의 질, 혁신성, 사회적 영향력, 그리고 새로운 이론적 통찰을 가치 있게 여기는 방향으로 인센티브 구조를 개혁해야 합니다. 예를 들어, 연구자 평가 시 논문 수 대신 "내러티브 CV(Narrative CV)"나 "영향력 진술서(Impact Statement)"를 활용하여 연구의 깊이와 장기적인 기여를 평가할 수 있습니다. 또한, 데이터 세트, 소프트웨어 코드, 오픈 소스 기여, 멘토링 활동 등 비전통적인 연구 성과에 대한 인정을 확대해야 합니다. 자금 지원 기관은 단기적인 성과보다는 위험을 감수하는 장기적인 탐색적 연구에 대한 지원을 늘리고, 실패를 학습 과정의 일부로 받아들이는 문화를 조성해야 합니다.

**과학을 위한 AI 도구 재고 및 신중한 개발**
AI 연구소와 기업들은 단순히 "AI가 X를 발견했다!"는 헤드라인을 쫓기보다, 과학 커뮤니티의 실제 병목 현상과 필요에 귀 기울여야 합니다. AI 도구는 오류 감지, 데이터 품질 향상, 재현성 보장, 그리고 복잡한 개념을 시각화하고 이해를 돕는 방향으로 개발되어야 합니다. 예를 들어, 수학자들이 정리 증명 자동화보다 인간의 이해를 돕는 도구에 더 관심을 가지는 것처럼, AI는 인간의 인지적 한계를 보완하고 새로운 통찰을 얻도록 돕는 역할을 해야 합니다. AI 도구의 평가는 단순한 생산성 향상을 넘어, 연구자의 이해 증진, 과학적 무결성 강화, 그리고 커뮤니티 전반에 미치는 집단적 영향까지 포함해야 합니다. AI가 기존의 유명 논문에 대한 주의를 더욱 집중시키는 것이 아니라, 숨겨진 지식을 발굴하고 새로운 연결을 만드는 데 기여해야 합니다.

### 7. 마지막 생각

우리 자신도 과학적 워크플로우(scientific workflows)에서 AI를 열정적으로 사용하는 사람들입니다. 일상적으로는 모든 것이 매우 흥미롭게 느껴집니다. 그렇기 때문에 AI가 개별 과학자가 아닌 기관으로서의 과학에 미치는 영향은 다른 종류의 분석을 요구하는 다른 질문이라는 것을 쉽게 잊을 수 있습니다. 이 에세이를 쓰는 것은 여러 경우에 우리의 직관과 싸워야 했습니다. 만약 당신이 이 도구들을 사용하는 것에 대해 비슷하게 흥분하는 과학자라면, 이 차이점을 명심하시기를 촉구합니다.

여기서 우리의 회의론은 우리가 "AI as Normal Technology"에서 제시한 느린 타임라인(slow timelines)에 대한 우리의 이유와 유사점과 차이점을 가집니다. 그 논문에서 우리는 시장 메커니즘(market mechanisms)이 어느 정도의 품질 관리(quality control)를 행사하며, 많은 조잡한 AI 배포(deployments)가 심각하게 실패하여, 명성을 중요하게 생각하는 기업들이 AI를 배포할 때, 특히 중요한 작업에 대해, 개발 속도가 아무리 빠르더라도 신중하게 접근하도록 강요했다고 설명했습니다. 그러나 과학에서는 채택(adoption)과 품질 관리 프로세스(quality control processes)가 분리되어 있으며, 전자가 훨씬 빠릅니다. 우리는 과학적 규범과 프로세스가 장기적으로 따라잡을 것이라고 낙관합니다. 그러나 지금으로서는 험난한 여정이 될 것입니다.

이 에세이 초안에 대한 피드백을 제공해 준 Eamon Duede에게 감사드립니다.

**추가 읽을거리**
최근 발표된 "과학적 발견의 미래: AI 시대의 도전과 기회" 보고서는 AI가 과학 연구의 모든 단계에 걸쳐 가져올 수 있는 변화와 함께, 윤리적 고려사항, 데이터 거버넌스, 그리고 인력 양성 문제에 대한 심층적인 분석을 제공합니다. 이 보고서는 특히 AI가 혁신적인 아이디어의 생성과 학제 간 협력을 어떻게 촉진할 수 있는지에 주목하면서도, 동시에 발생할 수 있는 지적 침체와 불평등 문제에 대한 해결책을 모색합니다.

또한, "오픈 사이언스와 AI: 투명성, 재현성, 그리고 신뢰성 증진 전략"이라는 학술 논문은 AI 기반 연구의 투명성을 높이고 재현성을 보장하기 위한 구체적인 방법론과 정책 권고를 제시합니다. 이 논문은 AI 모델과 데이터 공유의 중요성을 강조하며, 연구자 커뮤니티가 새로운 기술적 도전에 어떻게 대응해야 하는지에 대한 실질적인 지침을 제공합니다.

우리는 이 뉴스레터의 많은 이전 에세이에서 과학을 위한 AI 사용에 대해 썼습니다.
*   AI가 계산 재현성(computational reproducibility)을 자동화할 수 있을까?
*   과학자들은 AI를 신탁(oracle)이 아닌 도구로 사용해야 한다
*   ML은 많은 것에 유용하지만, 과학적 재현성(scientific replicability)을 예측하는 데는 그렇지 않다
*   ML 기반 과학에서 오류를 감지하고 예방하기 위한 REFORMS 체크리스트

Lisa Messeri와 Molly Crockett은 과학에서 AI 사용에 대한 분류법(taxonomy)을 제시합니다. 그들은 과학에서 AI를 채택할 때의 많은 함정들을 논의하며, 이해는 줄어들면서 더 많이 생산하게 될 수 있다고 주장합니다.

Matt Clancy는 과학과 혁신의 둔화에 대한 증거를 검토하고, 진정한 진보를 장려하기 위한 개입(interventions)을 논의했습니다.

Institute for Progress는 메타과학(meta-science)에 대한 팟캐스트 시리즈를 발표했습니다. 이 시리즈는 둔화에 대한 우려와 과학 자금 지원 및 조직을 위한 대안 모델 등을 논의합니다.