인공지능(AI) 분야의 선구자들은 AI가 암 정복, 인류 수명 획기적 연장, 심지어 우주 개척과 같은 중대한 과학적 도약을 실현하며, 향후 10년 내에 지난 한 세기 이상의 발전을 압축적으로 이뤄낼 것이라고 내다봤습니다. 미국에서 과학 분야에 대한 연방 재정 지원이 축소되는 상황에서, AI가 대규모 연구 인력의 필요성을 대체할 수 있다는 점에서 이러한 시기는 매우 적절해 보입니다. 적어도 기술 개발자들 사이에서는 AI가 과학 연구의 모든 단계, 즉 기존 문헌 정리, 새로운 아이디어 발상, 데이터 분석 및 실험 수행, 연구 결과 작성, 그리고 동료 심사 과정에 이르기까지 폭넓게 도입되어 과학 발전을 크게 가속화할 것이라는 일반적인 믿음이 형성되어 있습니다.

그러나 새로운 기술이 기존 사회 시스템에 미치는 영향에 대한 과거의 많은 낙관적인 예측들은 심각하게 빗나갔다는 점을 우리는 기억해야 합니다. 예를 들어, 인쇄술 초기 가톨릭 교회는 성경 출판을 통해 자신들의 권위를 더욱 확고히 할 수 있을 것이라 환영했습니다. 소셜 미디어의 등장 초기에는 아랍의 봄 이후 전 세계적으로 민주주의가 확산될 것이라는 기대감이 지배적이었습니다. 이와 마찬가지로, 과학 분야에서 AI가 가져올 변화 또한 우리의 직관과는 다른 방향으로 전개될 수 있습니다. 개별 연구자들이 AI 활용을 통해 이득을 얻는다고 해서, 과학 공동체 전체가 반드시 혜택을 받는 것은 아닙니다. 거시적인 관점에서 이 시스템을 바라볼 때, 우리는 창발적 특성을 지닌 복잡계와 마주하고 있습니다. 이 시스템은 시장과는 다른 방식으로 기능하며, 진실을 보상하는 일부 측면에서는 시장보다 우월하지만, 기술적 충격에 대응하는 방식에서는 오히려 취약할 수 있습니다. 지금까지 전반적으로 볼 때, AI는 과학에 부정적인 영향을 미쳤으며, 많은 과학적 절차를 한계점까지 밀어붙였습니다.

AI가 과학에 미치는 영향을 진지하게 평가하려는 모든 시도는 '생산-진보 역설(production-progress paradox)'이라는 난관에 봉착할 수밖에 없습니다. 과학 논문의 출판량은 기하급수적으로 늘어나, 1900년부터 2015년 사이에 무려 500배나 증가했습니다. 하지만 실질적인 진보는 어떤 기준으로 측정하더라도 정체되거나 오히려 둔화되는 추세를 보입니다. 따라서 우리는 AI가 이러한 불균형을 야기한 요인들에 어떻게 영향을 미치고 있으며, 앞으로 어떤 방식으로 영향을 미칠 것인지 심층적으로 질문해야 합니다. 본 분석은 AI가 이러한 격차를 더욱 심화시킬 가능성이 크다는 점을 시사합니다. 물론 모든 과학 분야에 해당되는 것은 아니며, 결코 확정적인 미래는 아닙니다. 아래에서 제시하는 것과 같은 조치들을 신중하고 시급하게 실행한다면, 우리는 이러한 흐름을 바꿀 수도 있습니다. 안타깝게도 AI 기업, 과학 연구 기금 기관, 정책 입안자들은 과학 발전의 진정한 병목 현상이 무엇인지 제대로 인식하지 못하는 듯합니다. 그들은 단순히 연구 생산량만 늘리려고 하는데, 이는 마치 교통 체증의 원인이 톨게이트인데도 고속도로에 차선만 추가하는 것과 같습니다. 이러한 접근 방식은 상황을 오히려 악화시킬 것이 분명합니다.

**목차**
1.  과학은 둔화되고 있다 — 생산-진보 역설
2.  진보가 둔화되는 이유는 무엇인가? AI가 도움이 될 수 있을까?
3.  과학은 AI는 고사하고 소프트웨어조차 준비되지 않았다
4.  AI는 결함 있는 이론에 대한 의존을 연장시킬 수 있다
5.  인간의 이해는 여전히 필수적이다
6.  과학의 미래에 대한 함의
7.  마지막 생각

"AI as Normal Technology" 프레임워크에 기반한 분석 및 논평

**1. 과학은 둔화되고 있다 — 생산-진보 역설(production-progress paradox)**

발표되는 전체 논문 수는 기하급수적인 증가세를 보여, 대략 12년마다 두 배로 늘어나고 있습니다. 연구 논문을 작성하는 연구자의 총수는 이보다 훨씬 더 빠른 속도로 증가하고 있습니다. 더욱이, 2000년부터 2021년 사이 주요 7개 연구 투자국(미국, 중국, 일본, 독일, 한국, 영국, 프랑스)의 연구 개발(R&D) 지출은 네 배 가까이 확대되었습니다. 1 하지만 이러한 양적 성장이 더 빠른 과학적 진보로 이어질까요? 반드시 그렇지는 않습니다. 어떤 논문은 과학의 방향을 근본적으로 바꾸는 획기적인 발견으로 이어지는 반면, 다른 논문들은 이미 알려진 결과에 미미한 개선을 더하는 데 그칩니다. 진정한 진보는 우리의 지식 체계에 대한 근본적인 돌파구에서 비롯됩니다. 예를 들어, 우리는 지난 세기 중반에 대륙이 이동한다는 판 구조론을 이해하게 되었습니다. 그 이전에는 지질학자들이 올바른 질문조차 던질 수 없었습니다. 그들은 지구가 식는 과정이 산과 같은 지질학적 특징을 형성한다고 믿으며 그 효과를 규명하려고 노력했습니다. 과거의 지질학적 패러다임 내에서는 어떤 연구 결과나 논문도 판 구조론이 가져온 것과 같은 수준의 진보를 이끌어낼 수 없었을 것입니다. 따라서 논문 수가 기하급수적으로 늘어나더라도, 실질적인 진보는 동일한 속도로 증가하지 않거나 오히려 둔화될 가능성이 있습니다. 과연 이것이 사실일까요? 이 질문에 답하는 데 있어 한 가지 어려움은, 연구 생산량과는 달리 진보에는 명확하고 객관적인 측정 지표가 없다는 점입니다. 다행히도, "과학의 과학(science of science)" 또는 메타과학(metascience)이라는 학문 분야 전체가 이 질문에 대한 답을 찾기 위해 노력하고 있습니다. 메타과학은 과학 연구 자체를 연구하기 위해 과학적 방법론을 적용합니다. 이 분야는 다음과 같은 질문들을 탐구합니다: 연구 결과가 얼마나 자주 재현될 수 있는가? 연구자의 작업 품질에 영향을 미치는 요인은 무엇인가? 학계의 인센티브 구조가 과학적 결과에 어떻게 작용하는가? 다양한 과학 기금 지원 모델이 진보에 어떤 영향을 미치는가? 그리고 궁극적으로 진보는 얼마나 빠른 속도로 일어나고 있는가?

왼쪽: 연구 논문의 저자 수와 저술된 논문 수는 기하급수적으로 증가해왔다 (Dong et al. 에서 발췌, 웹 플롯 디지타이저(web plot digitizer)를 사용하여 선형 스케일로 재구성). 오른쪽: 논문의 파괴성(disruptiveness)은 시간이 지남에 따라 감소하고 있다 (Park et al. 에서 발췌).

놀랍게도, 메타과학 연구의 상당수는 연구 자금, 출판된 논문 수, 그리고 과학 논문을 쓰는 연구자의 수가 극적으로 증가했음에도 불구하고 진보가 둔화되고 있음을 가리킵니다. 아래에서 몇 가지 증거를 정리했습니다. 맷 클랜시(Matt Clancy)는 이러한 연구 결과들을 훨씬 더 심층적으로 분석합니다.

1) 박 등(Park et al.)의 연구는 전체 과학적 산출물에서 '파괴적인(disruptive)' 연구가 차지하는 비중이 점차 줄어들고 있음을 보여줍니다. 출판 논문과 특허 수가 기하급수적으로 증가했음에도 불구하고, 진정한 돌파구의 수는 거의 일정한 수준을 유지하고 있습니다.
2) 새로운 개념을 제시하는 연구는 새로운 용어를 만들어낼 가능성이 높습니다. 밀로예비치(Milojevic)는 과학의 '인지적 범위(cognitive extent)'를 측정하기 위해 시간이 지남에 따라 과학 논문 제목에 사용된 고유한 구문(unique phrases) 수를 집계했습니다. 이 지표는 2000년대 초반까지 증가하다가, 그 이후로는 연구 논문 제목에 사용되는 고유한 구문 수가 감소하는 정체 상태에 들어섰음을 발견했습니다.
3) 패트릭 콜리슨(Patrick Collison)과 마이클 닐슨(Michael Nielsen)은 노벨상을 수상한 분야에서 가장 중요한 돌파구에 대한 인식이 시간이 지남에 따라 어떻게 변하는지 여러 분야의 연구자들을 대상으로 설문조사했습니다. 그들은 과학자들에게 1910년대부터 1980년대까지의 노벨상 수상 연구를 비교해달라고 요청했습니다. 그 결과, 과학자들은 의학, 물리학, 화학 전반에 걸쳐 초기 수십 년간의 발전이 최근 수십 년간의 발전만큼 중요하다고 평가한다는 것을 발견했습니다. 자금, 출판된 논문, 저자의 엄청난 증가에도 불구하고, 오늘날의 가장 중요한 돌파구는 과거 수십 년의 돌파구만큼이나 인상적인 수준에 머무르고 있습니다.
4) 맷 클랜시(Matt Clancy)는 특정 연도에 노벨상을 수상한 발견 중 이전 20년 이내에 출판된 논문의 비율을 분석하여 이를 보완했습니다. 그는 이 수치가 1970년 90%에서 2015년 50%로 하락했음을 밝혀냈는데, 이는 변혁적인 발견이 더 느린 속도로 일어나고 있거나, 발견이 변혁적인 것으로 인정받는 데 더 오랜 시간이 걸린다는 것을 시사합니다.

매년 노벨상 수상작을 설명하는 논문 중 이전 20년 동안 출판된 논문의 비율. 10년 이동 평균(10-year moving average). 출처: Clancy, Li et al. 의 데이터 기반.

5) 블룸 등(Bloom et al.)은 경제학적 관점에서 연구 산출물(research output)을 분석합니다. 경제 성장이 궁극적으로 새로운 아이디어에서 비롯된다고 가정할 때, 일정하거나 감소하는 성장률은 연구자 수의 기하급수적인 증가가 연구자당 생산량(output per researcher)의 상응하는 감소로 상쇄되고 있음을 의미합니다. 그들은 이러한 패턴이 반도체, 농업, 의학을 포함한 특정 분야에서 심층적으로 검토했을 때도 유효하다는 것을 발견했습니다 (여기서 진보 측정치는 각각 무어의 법칙(Moore’s law), 작물 수확량 증가, 기대 수명입니다).

연구 생산성(research productivity)의 감소. 경제학자들은 "생산(production)"을 논문 및 특허 수, 성장 및 기타 측정 기준을 포함하는 포괄적인 용어로 사용한다는 점에 유의하십시오. 우리는 생산과 진보를 근본적으로 다른 개념으로 보므로, "생산"이라는 용어를 더 좁은 의미로 사용합니다. 그림에서 "생산성(productivity)"은 논문 생산에 기반한 것이 아니라 진보 측정치로 더 잘 간주되는 측정치에 기반한다는 점을 명심하십시오. 출처: Bloom et al.

물론, 위에 언급된 각 지표들에는 한계점이 존재합니다. 이는 예상할 수 있는 일입니다. 진보에는 객관적인 측정 기준이 없으므로, 우리는 그것을 측정하기 위한 대리 지표(proxies)에 의존해야 하며, 이러한 대리 지표는 필연적으로 몇 가지 결함을 가질 수밖에 없습니다. 예를 들어, 박 등(Park et al.)은 인용 패턴(citation patterns)을 활용하여 논문을 '파괴적(disruptive)'으로 분류했습니다. 특정 논문에 대한 후속 인용이 이 논문이 참고한 선행 연구를 인용하지 않는 경향이 강할수록, 해당 논문은 파괴적인 것으로 간주될 가능성이 높습니다. 이 측정 방식에 대한 한 가지 비판은, 이것이 논문의 진정한 파괴성 결과라기보다는, 단순히 시간이 흐름에 따라 인용 관행이 변화한 결과일 수 있다는 것입니다. 또한 이 지표는 일부 획기적인 발견들을 비파괴적인 것으로 분류하기도 합니다. 예를 들어, AlphaFold는 이 기준에 의해 파괴적인 논문으로 간주되지 않습니다. 2 그러나 이러한 연구 결과들을 종합해 볼 때, 적어도 논문, 연구자, 자원의 양적 증가와 비교했을 때 과학적 진보가 둔화되고 있음을 시사합니다. 그럼에도 불구하고, 이는 추가 연구가 필요한 분야입니다. 투입 대비 진보 속도의 감소는 매우 명확해 보이지만, 총체적인 수준에서 정확히 어떤 현상이 벌어지고 있는지는 아직 불분명합니다. 더욱이, 과학의 목표가 무엇인지, 진보가 무엇을 의미하는지에 대한 다양한 개념들이 존재하며, 현재 사용 가능한 진보 측정 지표들을 이러한 상위 수준의 정의와 어떻게 연관시켜야 할지는 명확하지 않습니다.

**과학적 진보 둔화에 대한 몇 가지 주요 증거 요약**

**2. 진보가 둔화되는 이유는 무엇인가? AI가 도움이 될 수 있을까?**

진보가 둔화되는 원인에 대해서는 여러 가설이 제기됩니다. 한 가지 가설은 둔화가 과학적 진보의 본질적인 특성이며, 우리가 자연스럽게 받아들여야 할 현상이라는 주장입니다. 예를 들어, '낮은 곳에 열린 과일 가설(low-hanging fruit hypothesis)'이 있습니다. 이는 쉬운 과학적 문제들은 이미 해결되었고, 따라서 남아있는 발견들은 점점 더 어려워지고 있다는 생각입니다. 이 아이디어는 직관적으로 설득력이 있습니다. 그러나 우리는 이 가설이 전적으로 타당하다고 보지 않습니다. 애덤 마스트로이아니(Adam Mastroianni)는 이 주장을 반박하는 여러 강력한 근거를 제시합니다. 그는 우리가 이 문제에 대해 계속해서 오판해왔으며, 1890년대 물리학과 같이 과학 분야가 혁명적 변화를 앞두고 있을 때조차 포화 상태에 도달했다고 잘못 판단했던 사례들을 코믹하게 나열합니다. 낮은 곳에 열린 과일이 먼저 따이는 것은 사실이지만, 이를 상쇄하는 요인들도 있습니다. 시간이 지남에 따라 우리의 과학 도구는 더욱 정교해지고, 우리는 과거 지식의 토대 위에 서서 더 높은 곳에 도달하기 용이해집니다. 종종 개선된 도구와 이해의 이점은 너무나 변혁적이어서 완전히 새로운 분야와 하위 분야를 창출합니다. 지난 50~100년 동안 새롭게 등장한 분야로는 컴퓨터 과학, 기후 과학, 인지 신경과학, 네트워크 과학, 유전학, 분자 생물학 등이 있습니다. 효과적으로 우리는 새로운 나무에서 과일을 따고 있는 셈이므로, 언제나 낮은 곳에 열린 과일은 존재합니다. 우리의 관점으로는, 낮은 곳에 열린 과일 가설은 기껏해야 특정 분야 내의 둔화를 부분적으로 설명할 수 있을 뿐입니다. 따라서 다른 아이디어들을 고찰해 볼 가치가 있습니다.

두 번째 가설들은 덜 숙명론적입니다. 이 가설들은 우리가 과학을 수행하는 방식에 최적화되지 않은 부분이 있으며, 그 결과 과학적 투입이 진보로 전환되는 효율성이 저하되고 있다고 지적합니다. 특히, 한 가지 하위 가설은 연구 생산율 자체의 증가를 원인으로 지목합니다. 과학이 너무 빠르게 나아가려 하기 때문에 오히려 둔화되고 있다는 것입니다. 어떻게 이런 일이 가능할까요? 핵심은 개별 과학자의 주의력(attention)이 유한하여 매년 제한된 수의 논문에만 집중할 수 있다는 점입니다. 따라서 논문 저자들이 기존 학설(canon)에서 벗어나는 것은 매우 위험한 일이 됩니다. 그러한 잠재적인 돌파구 논문들은 수많은 다른 논문들 속에 묻혀 학자들의 임계 질량(critical mass)으로부터 주목을 받지 못할 수 있습니다. 생산율이 높을수록 '소음'이 많아지고, 따라서 진정으로 새로운 논문들이 받을 관심은 줄어들 것이며, 정설로 자리 잡을 가능성 또한 낮아질 것입니다. 추(Chu)와 에반스(Evans)는 다음과 같이 설명합니다. 매년 출판되는 논문의 수가 매우 많아지면, 새로운 논문들의 빠른 흐름은 학자들의 주의를 이미 잘 인용된 논문들로 향하게 하고, 덜 확립된 논문들—심지어 새롭고 유용하며 잠재적으로 변혁적인 아이디어를 담고 있는 논문들까지도—에 대한 주의를 제한할 수 있습니다. 새로운 출판물들의 홍수는 분야 패러다임(field paradigms)의 더 빠른 전환을 유도하기보다는, 최다 인용 논문들을 더욱 공고히 하여 새로운 연구가 해당 분야의 가장 많이 인용되고 일반적으로 알려진 학설로 부상하는 것을 저해합니다. 우리의 실증 분석(empirical analysis)에 의해 뒷받침되는 이러한 주장들은 과학계가 양적 생산에 초점을 맞추는 것이 근본적인 진보를 방해할 수 있음을 시사합니다. 이러한 해로운 효과는 각 분야의 연간 출판물 양이 계속 증가함에 따라 더욱 심화될 것입니다.

또 다른 인과 메커니즘은 과학자들의 '출판 아니면 소멸(publish-or-perish)'이라는 인센티브와 깊이 관련되어 있습니다. 생산량은 측정하기 쉽지만, 진보는 측정하기 어렵습니다. 따라서 대학 및 기타 과학 기관들은 연구자들을 그들이 발표하는 논문의 수나 확보한 연구비 규모와 같은 양적으로 측정 가능한 기준으로 평가하는 경향이 있습니다. 과학자들이 고용되거나 종신 재직권(tenure)을 얻기 위해 특정 수의 동료 심사(peer-reviewed) 논문을 출판해야 하는 것은 암묵적인 규범(implicit norms)이나 명시적인 요구 사항(explicit requirements) 때문에 흔한 일입니다. 이러한 생산 측정 기준에 대한 강조는 시간이 지남에 따라 더욱 심화되는 것으로 보입니다. 물리학 노벨상 수상자인 피터 힉스(Peter Higgs)는 자신이 충분히 생산적이라고 여겨지지 않을 것이기 때문에 현대 학계에서는 일자리조차 얻지 못했을 것이라고 유명하게 언급했습니다. 따라서 개별 연구자들의 경력은 위험을 회피하는 방향으로 나아갈 때 더 유리할 수 있지만, 이는 집단적인 진보 속도를 저하시킬 수 있습니다. 르제츠키 등(Rzhetsky et al.)은 생물의학 분야에서 이러한 현상의 증거를 발견했습니다. 이 분야에서는 진정한 돌파구로 이어질 수 있는 위험도 높은 실험보다는, 이미 중요하다고 인식되는 잘 알려진 분자들을 실험하는 데 지나치게 집중하는 경향이 있습니다 (이는 논문 출판으로 이어질 가능성이 더 높기 때문입니다). 우려스러운 점은, 그들이 이 현상이 시간이 지남에 따라 더욱 심화되고 있음을 발견했다는 것입니다. 이는 피드백 루프(feedback loop)를 완성합니다. 경력 인센티브는 연구자들이 더 많은 논문을 출판하게 하고, 진정한 돌파구를 가져오는 새로운 연구(하지만 수년간의 작업 끝에 단 하나의 논문만 나올 수도 있는)를 저해합니다.

만약 더딘 진보가 실제로 더 빠른 생산에 의해 야기된다면, AI는 그것에 어떻게 영향을 미칠까요? 가장 분명하게는, 과학 연구 과정의 일부를 자동화하는 것은 과학자들이 무의미한 생산성 측정 기준을 추구하는 것을 훨씬 더 쉽게 만들 것입니다. AI는 개별 연구자들을 더 창의적으로 만들 수 있지만, '균질화 효과(homogenizing effect)' 때문에 집단 전체의 창의성을 감소시킬 수도 있습니다. 또한 AI는 주의력의 불평등(inequality of attention)을 심화시키고 새로운 아이디어가 주목받아 돌파구를 찾기 더욱 어렵게 만들 수 있습니다. 구글 스칼라(Google Scholar)와 같은 기존의 검색 기술도 정확히 이러한 효과를 내는 것으로 보입니다. 요약하자면, 지금까지 우리는 과학의 둔화가 과잉 생산(overproduction)에 의해 발생한다면 AI가 이를 더욱 악화시킬 것이라고 주장했습니다. 다음 몇 섹션에서는 AI가 무엇이 원인이든 상관없이 둔화를 더욱 심화시킬 수 있는 이유를 논의할 것입니다.

**3. 과학은 AI는 고사하고 소프트웨어조차 준비되지 않았다**

연구자들은 AI를 다양한 방식으로 활용합니다. 정교한 패턴 매칭 알고리즘을 사용하여 데이터 내의 추세를 밝혀내는 AI 기반 모델링(AI-based modeling)부터, 전문가 지식에 기반하여 수동으로 작성된 기계 학습 모델(hand-written machine learning models), 심지어 연구자들이 이전에 작성했던 코드와 유사한 코드를 생성하는 생성형 AI(generative AI)에 이르기까지 폭넓게 사용됩니다. 문헌 검토를 위한 AI 사용과 같은 일부 응용 분야는 코드 작성과 직접적인 관련이 없지만, 과학 분야에서 AI를 적용하는 대부분의 경우 본질적으로 소프트웨어 개발(software development)의 영역에 속합니다. 불행히도, 과학자들은 형편없는 소프트웨어 엔지니어(software engineers)로 악명이 높습니다. 자동화된 테스트(automated testing), 버전 관리(version control), 프로그래밍 설계 지침(programming design guidelines) 준수와 같이 산업계에서는 표준으로 자리 잡은 관행들이 연구 커뮤니티에서는 대부분 부재하거나 무작위적으로 채택됩니다. 이러한 관행들은 지난 60년간의 소프트웨어 공학(software engineering) 발전 과정에서 버그를 예방하고 소프트웨어가 예상대로 작동하도록 보장하기 위해 개발되고 표준화되었습니다. 더욱 심각한 문제는, 과학 연구에 사용되는 소프트웨어에 대한 검토가 거의 이루어지지 않는다는 것입니다. 동료 심사(peer review)는 과학 논문을 출판하는 길고 힘든 과정이지만, 계산 연구(computational research)의 대부분의 '과학'이 논문에 수반되는 코드와 데이터에서 수행되고 논문 자체에는 요약만 되어 있음에도 불구하고, 논문에 수반되는 코드 검토는 포함하지 않습니다. 실제로, 논문들은 종종 결과를 생성하는 데 사용된 코드와 데이터를 공유하지 않으므로, 다른 연구자들이 코드를 검토할 의향이 있더라도 그럴 수단이 없습니다. 가벨리카 등(Gabelica et al.)은 데이터와 코드를 공유하겠다고 약속한 1,800개의 생물의학 논문 중 93%가 이러한 아티팩트(artifacts)를 결국 공유하지 않았다는 것을 발견했습니다. 이는 가장 저명한 과학 저널의 결과에도 영향을 미칩니다. 스토든 등(Stodden et al.)은 최고 과학 저널 중 하나인 사이언스(Science)에 출판된 204개 논문의 저자들에게 연락하여 연구에 사용된 코드와 데이터를 요청했습니다. 단 44%만이 응답했습니다.

연구자들이 사용한 코드와 데이터를 공유하는 경우에도, 그것은 종종 치명적인 오류를 포함하고 있습니다. 엑셀(Excel)과 같은 간단한 도구조차도 다양한 분야에서 광범위한 오류를 초래한 것으로 악명이 높습니다. 2016년 연구에 따르면, 유전자 이름(예: Septin 2)이 자동으로 날짜(9월 2일)로 변환되는 등의 문제로 인해 유전학 논문 5개 중 1개가 엑셀 관련 오류를 겪고 있는 것으로 나타났습니다. 마찬가지로, 대부분의 과학 커뮤니티가 간단한 통계를 책임감 있게 사용하는 방법을 익히는 데 수십 년이 걸렸습니다. AI는 완전히 새로운 차원의 문제들을 야기합니다. AI 커뮤니티는 미묘한 오류를 감지하는 것이 얼마나 어려운지 충분히 인식하지 못한 채 AI를 만능 해결책(silver bullet)으로 과장 광고하는 경우가 많습니다. 불행히도, AI 도구를 깊이 이해하고 오류를 식별하는 방법을 배우는 것보다 AI 도구를 단순히 사용하는 데는 훨씬 적은 역량(competence)이 요구됩니다. 다른 소프트웨어 기반 연구와 마찬가지로, AI 기반 과학의 오류는 밝혀내는 데 오랜 시간이 걸릴 수 있습니다. AI의 광범위한 채택이 연구자들이 잘못된 연구를 수행하거나 그러한 연구를 기반으로 더 많은 시간과 노력을 들이게 한다면, 연구자의 귀중한 시간과 노력이 비생산적인 연구 방향으로 낭비되므로 진보를 늦출 수 있습니다. 안타깝게도, 우리는 AI가 이미 광범위한 오류를 초래했음을 목격했습니다. 생성형 AI(generative AI) 이전에도 전통적인 기계 학습(machine learning)은 30개 과학 분야에 걸쳐 600개 이상의 논문에서 오류를 유발했습니다. 많은 경우, 영향을 받은 논문들은 조사된 논문의 대다수를 차지했으며, 이는 많은 분야에서 AI 기반 연구의 상당수가 결함이 있을 가능성을 제기합니다. 다른 연구자들은 AI 도구가 종종 부적절한 기준 비교(baseline comparisons)와 함께 사용되어, 이전 방법보다 성능이 우수한 것처럼 잘못 보이게 만든다는 것을 발견했습니다. 이러한 오류는 단지 이론적인 문제가 아닙니다. 이는 AI의 잠재적인 실제 배포에도 심각한 영향을 미칩니다. 예를 들어, 로버츠 등(Roberts et al.)은 COVID-19 진단을 위해 AI를 사용한 400개 이상의 논문 중 방법론적 결함(methodological flaws)으로 인해 임상적으로 유용한 도구를 생산한 논문은 없다는 것을 발견했습니다. 생성형 AI의 응용 프로그램은 새로운 유형의 오류를 초래할 수 있습니다. 예를 들어, AI가 프로그래밍을 돕는 동안에도 AI를 사용하여 생성된 코드에는 종종 오류가 있습니다. AI 채택이 증가함에 따라, 우리는 과학을 위한 AI의 더 많은 응용 분야를 접하게 될 것입니다. 그리고 우리는 이러한 응용 분야 중 상당수에서 광범위한 오류를 발견할 것으로 예상합니다.

과학 커뮤니티는 왜 소프트웨어 공학의 모범 사례(best practices)에 그렇게 뒤처져 있을까요? 공학 응용 분야에서는 버그가 테스트를 통해 쉽게 드러나거나, 최악의 경우 고객에게 배포될 때 나타납니다. 기업들은 애플리케이션의 품질을 유지하기 위해 오류를 수정할 강력한 인센티브를 가지고 있습니다. 그렇지 않으면 시장 점유율을 잃을 것이기 때문입니다. 결과적으로, 좋은 소프트웨어를 작성하는 데 (그리고 이제는 AI를 잘 활용하는 데) 깊은 전문 지식을 가진 소프트웨어 엔지니어에 대한 강력한 수요가 있습니다. 이것이 산업계의 소프트웨어 공학 관행이 연구 분야보다 수십 년 앞서 있는 이유입니다. 대조적으로, 결함 있는 과학적 결과를 수정할 인센티브는 거의 없으며, 오류는 종종 수년 동안 지속됩니다. 그렇다고 과학이 규범 기반(norms-based) 모델에서 시장 기반(market-based) 모델로 전환해야 한다는 의미는 아닙니다. 그러나 시장이 해결했지만 과학이 해결하지 못한 많은 문제들—예를 들어 소프트웨어 엔지니어를 위한 훈련 파이프라인(training pipelines) 개발과 같은—이 있다는 것은 놀라운 일이 아닙니다. 과학과 산업 사이에 이러한 격차가 발생하는 지점에서는 과학 기관들이 과학의 특별함을 잃지 않으면서도 혁신을 계속하도록 보장하기 위해 의도적으로 산업 모범 사례를 채택해야 합니다. 요컨대, 과학은 반세기 동안의 소프트웨어 공학 발전에 빠르게 발맞춰야 합니다. 그렇지 않으면 AI의 수용은 엄청난 오류를 초래하고 진보의 순풍(tailwinds)이 아닌 역풍(headwinds)을 만들 것입니다.

AI도 이러한 문제 해결에 기여할 수 있습니다. 오류를 찾아내는 데 특화된 다양한 AI 응용 프로그램들이 존재합니다. 예를 들어, Black Spatula 프로젝트와 YesNoError 프로젝트는 AI를 활용하여 연구 논문의 결함을 밝혀냅니다. 우리 자신의 연구에서는 논문을 자동으로 재현하는 AI 에이전트(AI agents) 개발을 촉진하기 위한 벤치마크(benchmarks)를 개발했습니다. 코드 작성에 대한 생성형 AI의 유용성을 고려할 때, AI 자체는 피드백 제공, 제안, 모범 사례 제시, 대규모 코드 검토(code reviews) 등을 통해 연구자들의 소프트웨어 공학 관행을 개선하는 데 활용될 수 있습니다. 이러한 도구들이 신뢰성을 확보하고 널리 채택된다면, AI는 잘못된 작업에 기반한 시간과 노력의 낭비를 피하도록 도움으로써 문제 해결의 일부가 될 수 있습니다. 그러나 이러한 모든 가능성은 단순히 생산량만을 강조하기보다는 훈련, 통합(synthesis), 오류 감지(error detection)를 장려하기 위한 저널, 기관, 그리고 자금 지원 기관의 적극적인 개입을 필요로 합니다. 특히, AI가 생성하는 코드의 품질과 투명성을 보장하기 위한 새로운 표준과 검증 절차가 필수적입니다. 단순히 코드를 생성하는 것을 넘어, 그 코드가 과학적 엄격성과 재현성을 충족하는지 평가하는 AI 기반 도구의 개발도 중요합니다.

**4. AI는 결함 있는 이론에 대한 의존을 연장시킬 수 있다**

과학 분야에서 AI의 핵심적인 활용처 중 하나는 모델링(modeling)입니다. 전통적인 모델링 기법은 세상이 어떻게 작동하는지에 대한 가설(hypothesis)을 설정한 다음, 통계 모델(statistical models)을 사용하여 이 가설에 대한 추론(inferences)을 도출하는 과정을 필요로 했습니다. 이와 대조적으로, AI 기반 모델링은 이 과정을 블랙박스(black box)처럼 다룹니다. 세상에 대한 가설을 세우고 모델 결과에 기반하여 우리의 이해를 증진시키는 대신, 단순히 과거 데이터에 근거하여 어떤 결과가 발생할지 예측하는 능력을 개선하는 데 집중합니다. 레오 브레이먼(Leo Breiman)은 그의 기념비적인 논문 "통계 모델링: 두 가지 문화(Statistical Modeling: The Two Cultures)"에서 이 두 가지 모델링 접근 방식의 차이를 상세히 설명했습니다. 그는 주로 산업 현장에서의 경험을 바탕으로 AI 기반 모델링의 강력한 지지자였습니다. 예측 정확도(predictive accuracy)에 대한 이러한 초점은 산업 분야에서는 의심할 여지 없이 유용합니다. 그러나 근본적인 이해가 중요한 과학 분야에서는 오히려 진보를 저해할 수 있습니다. 왜 그럴까요?

최근 네이처(Nature) 저널에 실린 우리의 논평에서 우리는 천문학의 지구 중심 모델(geocentric model)에 대한 비유를 통해 이를 설명했습니다. 지구 중심 모델—지구를 우주의 중심으로 보는 모델—은 행성들의 움직임을 예측하는 데 매우 높은 정확도를 보였습니다. '주전원(epicycles)'과 같은 보조적인 개념들은 이러한 예측을 더욱 정교하게 만들었습니다. (주전원은 지구 주위를 도는 행성의 궤도에 추가된 작은 원들이었습니다.) 모델의 예측과 실제 관측 사이에 불일치가 발생할 때마다, 천문학자들은 모델의 정확도를 높이기 위해 주전원을 추가했습니다. 지구 중심 모델은 행성의 움직임을 예측하는 데 너무나 정확했기 때문에, 많은 현대 천문관에서는 여전히 이를 사용하여 행성의 궤적을 계산합니다.

왼쪽: 지구 중심 모델은 결국 수많은 주전원 때문에 극도로 복잡해졌다. 오른쪽: 태양 중심 모델(heliocentric model)은 훨씬 더 간단했다.

그렇다면 지구 중심 모델은 어떻게 태양 중심 모델—행성들이 태양 주위를 돈다는 모델—에게 자리를 내주게 되었을까요? 두 모델의 예측 정확도가 유사했기 때문에, 단순히 정확도를 비교하는 방식으로는 해결될 수 없었습니다. 오히려, 태양 중심 모델이 행성 운동에 대해 훨씬 더 간결하고 우아한 설명을 제공했기 때문입니다. 다시 말해, 지구 중심설에서 태양 중심설로 나아가기 위해서는 단순히 더 정확한 모델에 의존하는 것을 넘어선 이론적 진보(theoretical advance)가 필수적이었습니다. 이 사례는 과학적 진보가 이론의 발전에 깊이 의존함을 보여줍니다. 행성이 움직이는 방식에 대한 이론적 관점을 업데이트하지 않고서는, 아무리 예측 정확도를 개선하더라도 태양 중심 모델이라는 새로운 이해에 도달할 수 없었을 것입니다.

과학 분야의 AI로 다시 돌아와 봅시다. AI 기반 모델링은 예측 정확도를 향상시키는 데 분명히 기여합니다. 그러나 그것이 현상에 대한 개선된 이해로 직결되지는 않습니다. AI는 다양한 분야에서 '주전원'에 해당하는 복잡한 보정 메커니즘을 생산하는 데 탁월할 수 있으며, 이는 '예측-설명 오류(prediction-explanation fallacy)'로 이어질 수 있습니다. 다시 말해, AI가 부정확한 이론에 기반해서도 더 나은 예측을 할 수 있게 한다면, 이는 연구자들이 결함 있는 이론을 더 오랫동안 사용하게 되는 결과를 초래하여 과학적 진보를 둔화시킬 수 있습니다. 극단적인 경우, 기존 패러다임(paradigms) 내에서 예측 정확도를 개선하는 데 아무리 탁월하더라도, 해당 분야는 지적 침체(intellectual rut)에 빠질 수 있습니다. AI의 발전이 이러한 한계를 극복하는 데 도움이 될 수 있을까요? 아마도 그렇겠지만, 이는 모델링 접근 방식과 기술에 대한 근본적인 변화 없이는 불가능하며, AI 산업이 이 분야에서 혁신할 인센티브는 거의 없습니다. 지금까지 예측 정확도의 개선은 근본적인 현상을 정확하게 모델링하는 능력의 개선을 훨씬 능가했습니다.

이해 없는 예측(Prediction without understanding): 바파 등(Vafa et al.)은 1천만 개의 행성 궤도에 대해 훈련된 트랜스포머 모델(transformer model)이 해당 궤도를 생성하는 근본적인 중력 법칙을 파악하지 않고도 궤도를 예측하는 데 탁월하다는 것을 보여줍니다.

**5. 인간의 이해는 여전히 필수적이다**

과학적 문제 해결 과정에서 과학자들은 자신이 연구하는 현상에 대한 깊은 이해를 쌓아갑니다. 이러한 이해 구축 과정은 단순히 문제 해결에 도달하는 수단처럼 보일 수도 있습니다. 따라서 문제에서 해결책으로 가는 과정을 자동화할 수 있다면 중간 단계는 불필요해 보일 수 있습니다. 그러나 현실은 그 반대에 가깝습니다. 문제를 해결하고 그에 대한 논문을 작성하는 행위는 인간의 이해라는 진정한 보상으로 이어지는 하나의 '의식(ritual)'으로 볼 수 있으며, 이러한 이해 없이는 과학적 진보는 불가능합니다. 필즈 메달(Fields Medal) 수상 수학자 윌리엄 서스턴(William Thurston)은 이를 훌륭하게 설명하는 에세이를 썼습니다. 그는 서두에서 수학의 본질은 단순히 수학적 사실의 진리값(truth value)을 알아내는 것이 아니라, 그 과정에서 수반되는 인간의 이해라고 강조합니다.

…[수학자들이] 하는 일은 사람들이 수학을 이해하고 생각하는 방법을 찾는 것입니다. 컴퓨터와 사람이 매우 다르기 때문에 컴퓨터의 빠른 발전은 이 점을 극적으로 보여주었습니다. 예를 들어, 아펠(Appel)과 하켄(Haken)이 대규모 자동 계산을 사용하여 4색 지도 정리(4-color map theorem)의 증명을 완성했을 때, 많은 논란을 불러일으켰습니다. 저는 그 논란이 정리의 진실성이나 증명의 정확성에 대한 사람들의 의심과는 거의 관련이 없다고 해석합니다. 오히려, 그것은 정리가 참이라는 지식 외에 증명에 대한 인간적 이해를 지속적으로 갈망하는 것을 반영했습니다.

더 일상적인 수준에서, 컴퓨터를 처음 다루기 시작하는 사람들이 손으로 더 작은 규모로 했을 수도 있는 것들을 대규모로 계산하는 것은 흔한 일입니다. 그들은 첫 10,000개의 소수(primes) 표를 인쇄할 수도 있지만, 결국 그 인쇄물이 자신이 정말로 원했던 것이 아니라는 것을 발견합니다. 그들은 이러한 경험을 통해 자신이 정말로 원하는 것은 보통 "답"의 모음이 아니라 이해라는 것을 깨닫습니다. [원문 강조]

그는 이어서 많은 수학자들의 관심의 중심이었던 엽층 이론(theory of foliations)을 연구하던 대학원생 시절의 경험을 설명합니다. 그가 해당 분야의 가장 중요한 정리들에 대한 여러 논문을 증명한 후, 역설적이게도 사람들이 그 분야를 떠나기 시작했습니다.

저는 여러 수학자들로부터 엽층 이론에 뛰어들지 말라는 조언을 주고받았다는 이야기를 들었습니다. 그들은 서스턴이 그 분야를 정리하고 있다고 말했습니다. 사람들은 저에게 (불평이 아니라 칭찬으로) 제가 그 분야를 죽이고 있다고 말했습니다. 대학원생들은 엽층 이론 연구를 중단했고, 얼마 지나지 않아 저도 다른 관심사로 눈을 돌렸습니다. 저는 그 분야가 지적으로 고갈되었기 때문에 사람들이 떠났다고 생각하지 않습니다. 여전히 남아있고 아마도 접근 가능한 흥미로운 질문들이 많았습니다(그리고 지금도 있습니다). 그 이후로, 그 분야에 남아있거나 새로 진입한 소수의 사람들에 의해 흥미로운 발전이 이루어졌고, 인접 분야에서도 중요한 발전이 있었습니다. 저는 수학자들이 엽층 이론을 계속해서 활발하게 추구했다면 훨씬 더 가속화되었을 것이라고 생각합니다. 오늘날, 그 당시 엽층 이론의 최첨단(state of the art)에 가까운 것을 이해하는 수학자는 거의 없다고 생각하지만, 그 이후의 발전을 포함하여 엽층 이론의 일부는 여전히 번성하고 있습니다.

이러한 이탈에는 두 가지 원인이 있었습니다. 첫째, 그가 기록한 결과물들이 이해하기 어려운 방식으로 작성되었습니다. 이는 신규 진입자들이 해당 분야에 들어오는 것을 막았습니다. 둘째, 수학의 요점이 인간의 이해를 쌓는 것임에도 불구하고, 수학자들이 자신의 작업에 대해 일반적으로 인정받는 방식은 정리를 증명하는 것입니다. 한 분야에서 가장 두드러진 결과들이 이미 증명되었다면, 다른 사람들이 그 분야의 기여를 이해할 인센티브는 거의 남지 않습니다. 왜냐하면 그들은 더 이상의 결과(궁극적으로 인정을 받게 될)를 증명할 수 없기 때문입니다. 다시 말해, 연구자들은 정리를 증명하도록 인센티브를 받습니다. 더 일반적으로, 모든 분야의 연구자들은 과학적 문제에 대한 해결책을 찾도록 인센티브를 받습니다. 그러나 이러한 인센티브는 정리 증명 또는 문제 해결 과정이 인간의 이해를 쌓는 것으로 이어지기 때문에 진보를 가져올 뿐입니다. 엽층 이론 연구의 이탈이 보여주듯이, 문제 해결과 인간의 이해 구축 사이에 불일치가 있을 때, 이는 더딘 진보로 이어질 수 있습니다. 이것이 바로 AI가 가질 수 있는 효과입니다. AI는 수반되는 이해 없이 미해결 연구 문제(open research problems)를 해결함으로써, 이해를 구축할 인센티브를 감소시켜 이러한 유용한 부산물(byproducts)을 침식할 수 있습니다. 우리가 AI를 사용하여 이러한 이해 과정을 단축시킨다면, 그것은 체육관에서 지게차를 사용하는 것과 같습니다. 물론 더 무거운 무게를 들어 올릴 수 있지만, 그것이 체육관에 가는 이유가 아닙니다.

AI는 과학적 진보에 필수적인 인간 이해 구축 과정을 단축시킬 수 있다.

물론, 수학은 극단적인 경우일 수 있습니다. 왜냐하면 인간의 이해는 (순수) 수학의 궁극적인 목표이지, 단순히 수학적 진술의 진리값을 아는 것이 아니기 때문입니다. 이는 과학의 많은 응용 분야에서는 해당되지 않을 수 있습니다. 예를 들어 일기 예보나 재료 합성(materials synthesis)과 같이 인간의 이해보다는 실제 결과에 대한 진보를 목표로 하는 경우입니다. 대부분의 분야는 이 두 극단 사이에 있습니다. 만약 우리가 AI를 사용하여 인간의 이해를 우회하거나, 더 나쁘게는 이해의 환상(illusions of understanding)만을 유지한다면, 우리는 새로운 과학자를 훈련시키고, 새로운 이론과 패러다임을 개발하고, 결과를 통합하고 수정하고, 과학을 넘어 지식을 적용하거나, 심지어 새롭고 흥미로운 문제를 생성하는 능력을 잃을 수도 있습니다. 과학 분야 전반의 경험적 증거는 이러한 효과 중 일부에 대한 증거를 발견했습니다. 예를 들어, 하오 등(Hao et al.)은 6개 분야의 데이터를 수집하여 AI를 채택한 논문들이 새로운 문제를 생성하기보다는 알려진 문제에 대한 해결책을 제공하고 기존 패러다임 내에서 작업하는 데 더 집중하는 경향이 있음을 발견했습니다. 물론, AI는 사람들이 수학적 증명이나 다른 과학적 지식을 이해하도록 돕는 것과 같이 암묵적 지식(tacit knowledge)을 구축하는 데도 사용될 수 있습니다. 그러나 이것은 과학이 조직되는 방식에 근본적인 변화를 필요로 합니다. 오늘날의 경력 인센티브와 사회적 규범은 인간의 이해보다는 과학적 문제에 대한 해결책을 중요하게 여깁니다. AI 채택이 가속됨에 따라, 우리는 인간의 이해가 우선시되도록 인센티브를 변경해야 합니다.

**6. 과학의 미래에 대한 함의**

지난 10년간 과학자들은 AI를 적극적으로 도입하기 위해 맹렬히 달려왔습니다. 이러한 빠른 속도는 품질 관리를 유지하고 과학의 본질적으로 인간적인 가치를 식별하고 보존하기 위해 느리게 움직이는 과학 기관의 규범(institutional norms)을 조정할 수 있는 역량을 희생시켰습니다. 결과적으로, 이러한 추세는 '생산-진보 역설(production-progress paradox)'을 더욱 심화시켜 논문 출판을 가속화할 것이지만, 진정한 과학적 진보에 있어서는 우리를 더 깊은 수렁으로 빠뜨릴 가능성이 높습니다. AI를 활용한 논문의 수는 2012년부터 2022년 사이에 20개 분야에 걸쳐 4배나 증가했습니다. 이는 대규모 언어 모델(large language models)이 광범위하게 채택되기 이전의 수치입니다.

듀드 등(Duede et al.)의 그림.

그렇다면 과학계는 어떤 방향으로 변화해야 할까요? 개별 연구자, 연구 자금 지원 기관, 출판사 및 기타 문지기(gatekeepers), 그리고 AI 기업의 역할에 대해 논의해 봅시다.

**과학적 관행 변경**
개별 연구자들은 AI를 도입할 때 더욱 신중해야 합니다. 그들은 소프트웨어 공학 기술을 숙달하고, AI 기반 모델링에서 발생하는 길고 복잡한 함정 목록을 피하는 방법을 익히며, AI를 단순히 목발(crutch)이나 신탁(oracle)처럼 사용하여 자신의 전문 지식(expertise)을 잃지 않도록 노력해야 합니다. AI의 부주의한 사용은 단기적으로는 효율성을 높이는 것처럼 보일 수 있지만, 장기적으로는 의미 있는 과학적 성과를 저해할 것입니다. 이 모든 것을 고려할 때, 우리는 대부분의 개별 연구자들이 합리적으로 자신의 인센티브(생산성 측정 기준)를 따르고 있다는 점을 인정합니다. 그들에게 단순히 주의를 촉구하는 것만으로는 큰 도움이 되지 않을 것입니다. 왜냐하면 우리가 직면한 것은 집단 행동 문제(collective action problems)이기 때문입니다. 변화를 이끌어낼 진정한 힘을 가진 주체는 저널, 대학의 채용 및 승진 위원회, 자금 지원 기관, 그리고 정책 입안자 등입니다. 다음으로 이들을 살펴보겠습니다.

**메타과학(meta-science)에 투자**
메타과학 연구는 생산-진보 역설(production-progress paradox)을 밝혀내는 데 매우 귀중한 역할을 해왔습니다. 그러나 지금까지 그 발견들은 분석적 정밀도(analytical precision)가 높지 않습니다. 과학이 투자 대비 효과(bang for its buck)가 줄어들고 있다는 막연한 아이디어만 있을 뿐입니다. 이 발견은 일반적으로 과학자들의 직감과 일치하며, 진정한 진보를 간접적으로 측정하려는 여러 가지 다른 측정 기준에 의해 뒷받침됩니다. 그러나 우리는 '진보'라는 구성 개념(construct)이 무엇인지에 대한 명확한 이해가 부족하며, 둔화의 원인에 대한 합의된 설명과는 거리가 멉니다. 분명히 말하자면, 우리는 결코 하나의 완벽한 진보 측정 기준(One True Progress Metric)을 가질 수 없을 것입니다. 만약 우리가 그렇게 한다면, 굿하트/캠벨의 법칙(Goodhardt/Campbell’s law)이 발동할 것입니다. "측정 기준이 목표가 되면, 그것은 좋은 측정 기준이기를 멈춘다." 과학자들은 우리가 출판 및 인용 횟수로 해왔던 것처럼 그것을 맹렬히 최적화하기 시작할 것이고, 그러한 조작(gaming)은 진보를 추적하는 방법으로서 그것을 쓸모없게 만들 것입니다. 그렇긴 하지만, 메타과학이 진보와 둔화에 대한 우리의 양적 이해와 (더 중요하게는) 질적/인과적 이해를 개선하는 데 갈 길이 멀다는 것은 분명합니다. 메타과학은 또한 해결책의 효능(efficacy of solutions)을 이해하기 위해 노력해야 합니다. 최근의 성장에도 불구하고, 메타과학에 대한 자금은 전체 과학 자금의 1% 미만입니다 (그리고 둔화에 대한 연구는 그 파이의 극히 일부에 불과합니다). 만약 과학 자금 전체가 과거보다 훨씬 적은 투자 대비 효과를 얻고 있다는 것이 사실이라면, 메타과학 투자는 한탄스러울 정도로 적어 보입니다.

**인센티브 개혁**
과학자들은 서로에게 '출판 아니면 소멸(publish-or-perish)'의 쳇바퀴에 대해 끊임없이 불평하며, 생산 중심의 보상 구조가 과학적 진보를 장려하는 데 좋지 않다는 것을 잘 알고 있습니다. 그러나 이를 바꾸려는 노력은 지속적으로 실패했습니다. 한 가지 이유는 단순한 관성(inertia)입니다. 그리고 앞서 언급한 굿하트(Goodhart)의 법칙이 있습니다. 어떤 새로운 측정 기준이 도입되더라도 빠르게 조작될 것입니다. 마지막 어려움은 진정한 진보는 고용 및 승진 결정에 적합하지 않은 시간 척도에서만 회고적으로(retrospectively) 식별될 수 있다는 것입니다. 한 가지 희망적인 점은 AI로 인해 논문 출판 비용이 더욱 낮아지면서, 생산 측정 기준에 의존하는 것을 중단하도록 강요할 수 있다는 것입니다. AI 분야 자체에서는 논문을 작성하는 데 필요한 노력이 너무 낮아서 우리는 특이점(singularity)을 향해 가고 있으며, 일부 연구자들은 연간 거의 100편의 논문을 (공동) 저술할 수 있습니다. (그러나 다시 말하지만, 실제 진보의 인지된 속도는 대부분 평평해 보입니다.) 다른 분야도 같은 길을 갈 수 있습니다. 따라서 개별 연구 결과의 출판에 보상하는 것은 더 이상 오래 지속될 수 있는 선택지가 아닐 수 있습니다. 대신, 경력 발전에 기여하는 논문의 종류는 새로운 이론이나 과학 연구 패러다임과 같이 자동화하기 어려운 것들로 제한되어야 할 것입니다. 그리고 이러한 인센티브 구조의 개혁은 자금 지원의 변화와 함께 이루어져야 합니다. 우리가 더 이상 필요로 하지 않는 한 가지는 AI 채택에 대한 더 많은 인센티브입니다. 위에서 설명했듯이, 이는 이미 엄청난 속도로 진행되고 있으며 병목 현상(bottleneck)이 아닙니다.

**과학을 위한 AI 도구 재고**
과학을 위한 AI 연구소와 대형 AI 기업의 과학 도구에 관해서는, 그들이 잘못된 동기로 이 분야에 뛰어들었다는 것이 명백한 문제입니다. 그들은 "AI가 X를 발견했다!"는 화려한 헤드라인을 원하며, 이를 통해 AI가 인류의 문제를 해결할 것이라는 이야기를 유지하고, 이는 그들에게 유리한 정책적 대우를 가져다줍니다. 우리는 이것이 변할 것이라고 기대하지 않습니다. 우리는 과학을 위한 AI 뉴스 헤드라인에 회의적이어야 합니다. 그들 중 많은 부분이 크게 과장되어 있습니다. 결과가 재현되지 않거나, AI가 실제로는 여러 도구 중 하나였음에도 불구하고 주연으로 묘사될 수 있습니다. 만약 실제로 도움을 주고 싶어 하는 과학을 위한 AI 도구 개발자들이 있다면, 우리의 조언은 다음과 같습니다.

또 다른 문헌 검토 도구를 만드는 대신 실제 병목 현상을 목표로 삼으십시오. 과학 코드의 오류를 찾거나 다른 형태의 품질 관리를 위한 도구는 어떻습니까? 사용자들의 의견을 경청하십시오. 예를 들어, 수학자들은 인간의 이해를 개선하는 도구가 정리 증명(theorem-proving)을 자동화하려는 시도보다 훨씬 더 흥미롭다고 반복해서 말해왔습니다. 그들은 정리 증명 자동화가 핵심을 놓치고 있다고 봅니다.

과학을 위한 AI 도구를 평가하는 방식도 바뀌어야 합니다. 문헌 검토 도구를 생각해 봅시다. 물어볼 수 있는 질문은 세 가지 종류가 있습니다.
*   연구자의 시간을 절약하고 기존 도구와 비슷한 품질의 결과를 생성하는가?
*   이 도구의 사용이 전통적인 검색과 비교하여 문헌에 대한 연구자의 이해에 어떤 영향을 미치는가?
*   이 도구가 널리 채택된다면 커뮤니티에 어떤 집단적 영향(collective impacts)을 미칠 것인가? 예를 들어, 이미 유명한 논문에 대한 커뮤니티의 주의를 더욱 집중시킬 것인가?

이 세 가지 질문은 각각 생산, 이해, 진보를 다룹니다. 현재는 첫 번째 질문만이 평가의 의미의 일부로 간주됩니다. 나머지 두 가지는 범위 밖이며, 그러한 측정을 위한 확립된 방법이나 측정 기준조차 없습니다. 이는 과학을 위한 AI 평가가 이러한 도구의 유용성에 대한 매우 불완전하고 편향된 그림을 제공하고 잠재적 해악을 최소화하도록 보장한다는 것을 의미합니다.

**7. 마지막 생각**

우리 자신도 과학적 워크플로우(scientific workflows)에서 AI를 열정적으로 사용하는 사람들입니다. 일상적으로는 모든 것이 매우 흥미롭게 느껴집니다. 그렇기 때문에 AI가 개별 과학자가 아닌 기관으로서의 과학에 미치는 영향은 다른 종류의 분석을 요구하는 다른 질문이라는 것을 쉽게 잊을 수 있습니다. 이 에세이를 쓰는 것은 여러 경우에 우리의 직관과 싸워야 했습니다. 만약 당신이 이 도구들을 사용하는 것에 대해 비슷하게 흥분하는 과학자라면, 이 차이점을 명심하시기를 촉구합니다.

여기서 우리의 회의론은 우리가 "AI as Normal Technology"에서 제시한 느린 타임라인(slow timelines)에 대한 우리의 이유와 유사점과 차이점을 가집니다. 그 논문에서 우리는 시장 메커니즘(market mechanisms)이 어느 정도의 품질 관리(quality control)를 행사하며, 많은 조잡한 AI 배포(deployments)가 심각하게 실패하여, 명성을 중요하게 생각하는 기업들이 AI를 배포할 때, 특히 중요한 작업에 대해, 개발 속도가 아무리 빠르더라도 신중하게 접근하도록 강요했다고 설명했습니다. 그러나 과학에서는 채택(adoption)과 품질 관리 프로세스(quality control processes)가 분리되어 있으며, 전자가 훨씬 빠릅니다. 우리는 과학적 규범과 프로세스가 장기적으로 따라잡을 것이라고 낙관합니다. 그러나 지금으로서는 험난한 여정이 될 것입니다.

이 에세이 초안에 대한 피드백을 제공해 준 이몬 듀드(Eamon Duede)에게 감사드립니다.

**추가 읽을거리**
미국 과학 가속화 프로젝트(American Science Acceleration Project, ASAP)는 2030년까지 미국 과학을 "10배 더 빠르게" 만드는 것을 목표로 하는 국가 이니셔티브(national initiative)입니다. 하인리히(Heinrich) 상원의원과 라운즈(Rounds) 상원의원 사무실은 최근 이를 달성하는 방법에 대한 피드백을 요청했습니다. 우리의 답변에서 우리는 생산-진보 역설(production-progress paradox)을 강조하고, AI가 과학적 진보를 가속화하기보다는 늦출 수 있는 이유를 논의했으며, 도움이 될 수 있는 정책 개입(policy interventions)을 권고했습니다. 우리의 동료 알론드라 넬슨(Alondra Nelson) 또한 ASAP 이니셔티브에 대한 답변을 작성하여, 더 빠른 과학이 자동으로 더 나은 것은 아니며, 생산 속도 증가에도 불구하고 남아있는 많은 과제들을 강조했습니다.

최근 네이처(Nature) 저널의 논평에서 우리는 AI 기반 모델링(AI-driven modeling)의 확산이 과학에 왜 해로울 수 있는지 논의했습니다.

우리는 이 뉴스레터의 많은 이전 에세이에서 과학을 위한 AI 사용에 대해 썼습니다.
*   AI가 계산 재현성(computational reproducibility)을 자동화할 수 있을까?
*   과학자들은 AI를 신탁(oracle)이 아닌 도구로 사용해야 한다
*   ML은 많은 것에 유용하지만, 과학적 재현성(scientific replicability)을 예측하는 데는 그렇지 않다
*   ML 기반 과학에서 오류를 감지하고 예방하기 위한 REFORMS 체크리스트

리사 메세리(Lisa Messeri)와 몰리 크로켓(Molly Crockett)은 과학에서 AI 사용에 대한 분류법(taxonomy)을 제시합니다. 그들은 과학에서 AI를 채택할 때의 많은 함정들을 논의하며, 이해는 줄어들면서 더 많이 생산하게 될 수 있다고 주장합니다.

맷 클랜시(Matt Clancy)는 과학과 혁신의 둔화에 대한 증거를 검토하고, 진정한 진보를 장려하기 위한 개입(interventions)을 논의했습니다.

진보 연구소(Institute for Progress)는 메타과학(meta-science)에 대한 팟캐스트 시리즈를 발표했습니다. 이 시리즈는 둔화에 대한 우려와 과학 자금 지원 및 조직을 위한 대안 모델 등을 논의합니다.

업데이트 (2025년 7월 17일): 명확성을 위한 사소한 문구 수정.
1 인플레이션을 감안하더라도 이는 여전히 2.5배 증가입니다.
2 이 네이처 뉴스(Nature News) 기사는 원본 연구가 출판된 지 2년 후에 출판되었으며, 해당 논문의 결과와 저자들의 반응을 둘러싼 논란을 기록하고 있습니다.