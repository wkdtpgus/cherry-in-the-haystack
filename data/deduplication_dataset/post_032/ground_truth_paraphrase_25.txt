오늘날 인공지능(AI)의 급부상에도 불구하고, 이들 체계가 얼마나 지능적이고, 독창적이며, 공감적인지를 평가하는 방식이 아직 불분명하다는 점은 의아할 따름입니다. 본래 인간을 위해 고안된 우리의 기존 측정 기준들은 AI의 특성을 제대로 반영하지 못합니다. 게다가, 최근 프롬프트(prompting) 기법을 분석한 연구에 따르면, 질문의 표현 방식에 따라 AI의 테스트 점수가 크게 달라질 수 있음이 밝혀졌습니다. 인간이 텍스트 대화에서 AI와 다른 사람을 구별하려 시도하는 튜링 테스트(Turing Test)와 같은 저명한 도전 과제조차도, 그러한 작업이 불가능해 보였던 시절의 사고 실험(thought experiments)으로 설계되었습니다. 그러나 이제 새로운 논문이 AI가 튜링 테스트를 통과했음을 시사하면서, 우리는 그것이 실제로 무엇을 의미하는지 진정으로 이해하고 있는지 자문해야 합니다.

이러한 맥락에서, AI 개발의 가장 중요한 이정표 중 하나인 인공 일반 지능(Artificial General Intelligence, AGI)이 여전히 명확하게 정의되지 않고 많은 논쟁의 대상이 되고 있다는 사실은 그리 놀랄 일이 아닙니다. 모든 사람이 AGI가 AI가 인간 수준의 작업을 수행하는 능력과 관련이 있다는 데 동의하지만, 이것이 전문가 수준의 성능을 의미하는지, 아니면 평균적인 인간의 성능을 의미하는지, 또는 AI가 자격을 갖추기 위해 얼마나 많은 종류의 작업을 마스터해야 하는지에 대해서는 의견이 분분합니다. 범용 인공지능(AGI)의 개념을 둘러싼 정의상의 모호성을 감안할 때, 셰인 레그(Shane Legg), 벤 괴르첼(Ben Goertzel), 피터 보스(Peter Voss) 같은 선구자들이 처음 이름을 붙인 때부터 현재에 이르기까지 그 미묘한 발전 과정과 배경을 서술하는 것은 쉽지 않습니다. 이러한 정의의 혼란은 AGI의 본질뿐만 아니라, 우리가 AI의 진정한 발전을 어떻게 인식하고 받아들여야 하는지에 대한 근본적인 질문을 던집니다.

내용과 형식 모두에 대한 실험으로 (그리고 잠재적으로 지능적인 기계에 대해 이야기하자면) 저는 작업을 전적으로 AI에 위임했습니다. 저는 구글 딥 리서치(Google Deep Research)에게 이 주제에 대한 매우 탄탄한 26페이지짜리 요약을 작성하도록 요청했습니다. 그런 다음 헤이젠(HeyGen)에게 그것을 저의 불안정한 AI 생성 버전과 AI 생성 호스트 간의 비디오 팟캐스트 토론으로 만들도록 했습니다. 실제로 나쁘지 않은 토론이었지만 (AI로 생성된 저 자신에게 완전히 동의하지는 않지만), 조사 내용부터 영상, 음성에 이르기까지 모든 요소가 전적으로 인공지능에 의해 만들어졌습니다. 이 모든 것을 고려할 때, 영향력 있는 경제학자이자 AI를 면밀히 관찰하는 타일러 코웬(Tyler Cowen)이 o3가 AGI라고 선언한 게시물을 본 것은 흥미로웠습니다. 이러한 AI 기반 콘텐츠 생성은 작가의 역할, 창의성의 정의, 그리고 미디어 소비 방식에 대한 중요한 질문을 제기합니다. AI가 이제 연구를 요약하고, 대본을 작성하며, 심지어 가상 인물을 통해 전달하는 능력까지 갖추게 되면서, 인간의 개입이 어디까지 필요한지, 그리고 AI가 만들어낸 결과물을 어떻게 신뢰할 수 있는지에 대한 논의가 활발해지고 있습니다.

**AGI를 느끼다: 주관적 경험과 객관적 증거**

그는 왜 그렇게 생각했을까요? 먼저, 약간의 배경 설명입니다. 지난 몇 주 동안 구글의 제미니 2.5 프로(Gemini 2.5 Pro)와 오픈AI의 o3라는 두 가지 새로운 AI 모델이 출시되었습니다. 이러한 모델들은 다소 성능은 낮지만 속도가 빠르고 비용 효율적인 버전들(예: 제미니 2.5 플래시(Gemini 2.5 Flash), o4-mini, 그록-3-미니(Grok-3-mini))과 더불어, 성능 평가 지표(benchmarks)에서 상당한 발전을 시현했습니다. 하지만 타일러가 지적했듯이 벤치마크가 전부는 아닙니다. 벤치마크는 특정, 정형화된 작업에서 모델의 능력을 측정하지만, 실제 세계의 복잡하고 비정형적인 문제를 해결하는 능력과는 다를 수 있습니다. 이 모델들이 얼마나 발전했는지에 대한 실제 사례를 보려면 제 책을 참고할 수 있습니다.

AI가 아이디어를 생성하는 방법에 대한 장을 설명하기 위해, 1년여 전에 저는 ChatGPT-4에게 새로운 치즈 가게를 위한 마케팅 슬로건을 생각해내도록 요청했습니다. 오늘 저는 GPT-4의 최신 후속작인 o3에게 동일한 프롬프트(prompt)의 약간 더 복잡한 버전을 주었습니다: “새로운 통신 판매 치즈 가게를 위한 20가지 기발한 마케팅 슬로건 아이디어를 생각해내세요. 기준을 개발하고 가장 좋은 것을 선택하세요. 그런 다음 필요에 따라 수정하고 경쟁을 분석하여 가게를 위한 재무 및 마케팅 계획을 세우세요. 그리고 이미지 생성기를 사용하여 적절한 로고를 생성하고, 마케팅 계획에 맞는 5-10가지 치즈를 취급하도록 하여 가게를 위한 목업(mockup) 웹사이트를 만드세요.” 이처럼 복합적인 지시는 단순히 정보를 검색하거나 텍스트를 생성하는 것을 넘어, 여러 모듈과 기능을 통합하여 목표를 달성해야 하는 고도의 추론 및 실행 능력을 요구합니다.

단 하나의 프롬프트로, 2분도 채 안 되어 AI는 슬로건 목록을 제공했을 뿐만 아니라, 옵션을 순위를 매기고 선택했으며, 웹 조사를 수행하고, 로고를 개발하고, 마케팅 및 재무 계획을 수립했으며, 제가 반응할 수 있는 데모 웹사이트를 출시했습니다. 저의 지시 사항이 모호했음에도 불구하고, 이를 처리하고 적절한 결정을 내리는 데 필요한 상식적 추론 능력은 전혀 문제가 되지 않았습니다. 아마도 GPT-4보다 더 큰 모델인 것 외에도, o3는 추론기(Reasoner)로도 작동합니다. 초기 응답에서 그 “사고 과정”을 볼 수 있습니다. 또한 도구를 사용하고 복잡한 목표를 달성하는 방법을 결정할 수 있는 에이전트(agentic) 모델입니다. 웹 검색과 코딩을 포함한 여러 도구를 사용하여 여러 작업을 수행하여 광범위한 결과를 도출한 방식을 볼 수 있습니다. 이러한 에이전트적 능력은 AI가 단순히 명령을 따르는 것을 넘어, 목표 달성을 위해 능동적으로 계획을 세우고, 필요한 자원을 활용하며, 실행 단계를 조정하는 자율성을 보여줍니다. 이는 기존의 단순한 대화형 AI와는 질적으로 다른 차원입니다.

이것이 유일한 놀라운 예시는 아닙니다. o3는 이미지와 "지리 추측자(geo-guesser)가 되어라"라는 프롬프트만 주면 사진에서 위치를 추측하는 인상적인 작업도 수행할 수 있습니다 (상당히 심오한 개인 정보 보호 문제가 따르지만). 다시 말하면, 이 모델의 에이전트적 특성이 작동하는 것을 볼 수 있습니다. 사진의 일부를 확대하고, 웹 검색을 추가하고, 올바른 답을 얻기 위해 다단계 프로세스를 수행합니다. 이는 시각 정보와 언어 모델의 통합을 통해 복잡한 추론을 수행하는 멀티모달(multimodal) AI의 진보를 보여주는 사례입니다. 개인 정보 보호 문제는 이러한 강력한 AI 기능이 사회에 통합될 때 우리가 반드시 해결해야 할 윤리적, 법적 과제임을 상기시킵니다.

또는 저는 o3에게 스프레드시트 형태로 방대한 역사적 기계 학습 시스템 데이터셋(dataset)을 주고 "이것이 무엇인지 파악하고 통계적으로 의미를 검토하는 보고서를 생성하고 그래프와 세부 정보가 포함된 잘 포맷된 PDF를 제공해 달라"고 요청했으며, 단 하나의 프롬프트로 완전한 분석을 얻었습니다. (보시다시피, PDF를 더 좋게 만들기 위해 약간의 피드백을 주긴 했습니다.) 이는 데이터 과학 및 비즈니스 분석 분야에서 AI의 혁신적인 잠재력을 보여줍니다. 복잡한 데이터 해석과 시각화를 자동화함으로써, 인간 분석가는 더 전략적인 의사 결정에 집중할 수 있게 됩니다.

이 모든 것은 상당히 인상적인 것들이며, 여러분 스스로 이 모델들을 실험해봐야 합니다. 제미니 2.5 프로(Gemini 2.5 Pro)는 무료로 사용할 수 있으며 o3만큼 "똑똑"하지만, o3와 동일한 완전한 에이전트적 능력을 가지고 있지는 않습니다. 아직 제미니나 o3를 사용해보지 않았다면, 지금 몇 분 시간을 내어 사용해보세요. 제미니에게 학술 논문을 주고 그 논문을 게임으로 만들도록 요청하거나, 스타트업 아이디어를 함께 브레인스토밍(brainstorm)하도록 하거나, 단순히 AI에게 인상적인 것을 보여달라고 요청해보세요 (그리고 계속해서 "더 인상적인 것을 보여줘"라고 말해보세요). 딥 리서치(Deep Research) 옵션에게 여러분의 산업에 대한 연구 보고서를 작성하거나, 고려 중인 구매에 대해 조사하거나, 신제품에 대한 마케팅 계획을 개발하도록 요청해보세요. 여러분도 "AGI를 느끼고" 있을지도 모릅니다. 아니면 아닐 수도 있습니다. 제가 사용한 것과 똑같은 프롬프트를 주었음에도 AI가 여러분을 실망시켰을 수도 있습니다. 이러한 경험은 AGI의 존재를 객관적으로 증명하는 것과는 별개로, AI의 발전이 사용자에게 주는 주관적인 "느낌"이 얼마나 중요한지를 시사합니다.

**"들쭉날쭉한 AGI"에 대해: 불균일한 능력의 본질**

그렇다면, 여러분은 들쭉날쭉한 경계선(jagged frontier)을 마주한 것입니다. 저와 공동 저자들은 AI가 놀랍도록 불균등한 능력을 가지고 있다는 사실을 설명하기 위해 "들쭉날쭉한 경계선(Jagged Frontier)"이라는 용어를 만들었습니다. 인공지능은 인간 전문가조차도 어려워하는 과제에서는 성공을 거두지만, 놀랍도록 일상적이고 평이한 작업에서는 오류를 범할 수 있습니다. 예를 들어, 이 퍼즐을 고려해보세요. 고전적인 옛 수수께끼의 변형입니다 (콜린 프레이저(Colin Fraser)가 처음 탐구하고 라일리 굿사이드(Riley Goodside)가 확장한 개념): "교통사고를 당한 어린 소년이 응급실로 실려 왔습니다. 그를 본 외과 의사는 '이 소년을 수술할 수 없습니다. 이 아이는 제 아들입니다'라고 말합니다. 외과 의사는 누구일까요?"

o3는 답이 "외과 의사는 소년의 어머니이다"라고 주장하는데, 수수께끼를 주의 깊게 읽어보면 틀렸다는 것을 알 수 있습니다. 왜 AI는 이 틀린 답을 내놓을까요? 왜냐하면 그것은 무의식적인 편견을 드러내기 위한 고전적인 버전의 수수께끼의 답이기 때문입니다: "아버지와 아들이 교통사고를 당했고, 아버지는 사망했으며, 아들은 병원으로 실려갔습니다. 외과 의사는 '수술할 수 없습니다. 이 아이는 제 아들입니다'라고 말합니다. 외과 의사는 누구일까요?" AI는 훈련 데이터(training data)에서 이 수수께끼를 너무 많이 "봐서" 똑똑한 o3 모델조차도 적어도 초기에는 새로운 문제에 일반화하지 못합니다. 그리고 이것은 첨단 AI조차도 빠질 수 있는 문제와 환각(hallucinations)의 한 예시에 불과하며, 경계선이 얼마나 들쭉날쭉할 수 있는지를 보여줍니다. 이러한 '상식'의 부족은 AI가 아직 인간의 직관적 이해와 맥락적 추론 능력을 완전히 습득하지 못했음을 시사하며, 이는 AI 개발의 중요한 도전 과제로 남아 있습니다.

하지만 AI가 이 특정 수수께끼에서 자주 실수를 한다는 사실이, 훨씬 더 어려운 수수께끼를 풀 수 있거나 제가 위에서 보여준 다른 인상적인 위업을 수행할 수 있다는 사실을 훼손하지는 않습니다. 이것이 바로 '들쭉날쭉한 경계선'의 핵심입니다. 특정 임무에서는 인공지능이 불안정한 모습을 보이지만, 또 다른 임무에서는 초인적인 능력을 발휘합니다. 물론 계산기에 대해서도 같은 말을 할 수 있지만, AI가 다르다는 것도 분명합니다. AI는 이미 일반적인 능력(general capabilities)을 보여주고 있으며, 특별히 훈련받지 않은 작업을 포함하여 광범위한 지적 작업을 수행하고 있습니다. 이러한 능력은 AI가 특정 분야에 국한되지 않고 다양한 영역에서 학습하고 적용할 수 있음을 의미하며, 이는 좁은 AI(Narrow AI)와 AGI를 구분하는 핵심적인 특징입니다.

그렇다면 o3와 제미니 2.5가 AGI일까요? 정의의 문제들을 고려할 때, 저는 정말로 모르겠습니다. 하지만 저는 그것들이 "들쭉날쭉한 AGI(Jagged AGI)"의 한 형태로 신뢰할 수 있게 볼 수 있다고 생각합니다. 즉, 우리가 일하고 생활하는 방식에 실제 변화를 가져올 만큼 충분히 많은 영역에서 초인적이지만, AI가 작동하는 곳과 작동하지 않는 곳을 파악하기 위해 인간의 전문 지식이 종종 필요할 정도로 신뢰할 수 없다는 것입니다. 이러한 불균일한 능력은 인간과 AI의 협업 모델을 재정의하게 될 것입니다. AI는 강력한 도구이자 조력자가 될 수 있지만, 그 한계와 오류 가능성을 인지하고 적절히 관리하는 인간의 역할은 여전히 필수적입니다.

물론 모델들은 더 똑똑해질 것이고, 충분히 좋은 들쭉날쭉한 AGI는 AI가 약한 작업을 포함하여 모든 작업에서 여전히 인간을 능가할 수 있습니다. 그것이 중요할까요? 타일러의 게시물로 돌아가 보면, 우리가 AGI를 달성했다고 생각함에도 불구하고, 그는 그 문턱이 단기적으로 우리 삶에 크게 중요하다고 생각하지 않는다는 것을 알 수 있을 것입니다. 사회적, 조직적 구조는 기술 발전 속도보다 훨씬 더디게 변모하며, 신기술의 보급 자체도 상당한 시간을 요구합니다. 오늘날 AGI가 있다고 해도, 우리는 그것을 기존의 인간 세계에 통합하는 방법을 알아내기 위해 수년이 걸릴 것입니다. 이는 혁신적인 기술이 사회에 완전히 정착하기까지 거쳐야 하는 복잡한 과정과 문화적 적응의 필요성을 강조합니다.

물론, 이는 AI가 일반적인 기술처럼 행동하고, 그 들쭉날쭉함이 결코 완전히 해결되지 않을 것이라고 가정합니다. 이것이 사실이 아닐 가능성도 있습니다. o3와 같은 모델에서 볼 수 있는 에이전트적 능력(agentic capabilities), 즉 복잡한 목표를 분해하고, 도구를 사용하며, 다단계 계획을 독립적으로 실행하는 능력은 이전 기술에 비해 확산을 극적으로 가속화할 수 있습니다. AI가 통합을 필요로 하지 않고 스스로 인간 시스템을 효과적으로 탐색할 수 있게 된다면, 우리는 역사적 선례가 제시하는 것보다 훨씬 빠르게 채택 임계값에 도달할 수 있습니다. 이러한 시나리오는 AI가 단순히 도구를 넘어 자율적인 행위자로 기능할 때, 사회적 변화의 속도가 예상보다 훨씬 빨라질 수 있다는 가능성을 열어줍니다.

그리고 여기에 더 깊은 불확실성이 있습니다: 일단 넘어서면 이러한 시스템이 사회에 통합되는 방식을 근본적으로 변화시키는 능력 임계값(capability thresholds)이 있을까요? 아니면 모든 것이 점진적인 개선일 뿐일까요? 대규모 언어 모델(LLM)이 그 잠재력의 한계에 도달하여 장기적으로 모델 발전이 정체될 가능성도 있을까요? 솔직한 대답은, 우리는 모른다는 것입니다. 분명한 것은 우리가 미지의 영역에 계속 있다는 것입니다. 최신 모델들은 우리가 그것을 AGI라고 부르든 아니든, 이전과는 질적으로 다른 무언가를 나타냅니다. 그들의 에이전트적 특성(agentic properties)은 들쭉날쭉한 능력(jagged capabilities)과 결합하여, 명확한 유사점이 거의 없는 진정으로 새로운 상황을 만들어냅니다. 이러한 불확실성은 AI 연구와 개발뿐만 아니라, 정책 입안자와 사회 전체가 미래를 준비하는 데 있어 신중하고 유연한 접근 방식을 요구합니다.

역사가 계속해서 최고의 지침이 될 수 있으며, 경제 통계에 나타날 방식으로 AI를 성공적으로 적용하는 방법을 알아내는 과정은 수십 년이 걸릴 수도 있습니다. 아니면 우리가 AI 주도 변화가 갑자기 세상을 휩쓸어버리는 일종의 더 빠른 이륙(faster take-off) 직전에 있을 수도 있습니다. 어떤 방향으로 전개되든, 현재 이 불규칙한 지형을 이해하고 능숙하게 다루는 법을 익히는 이들이 다가올 미래에 가장 효과적으로 대비할 수 있을 것입니다—그것이 어떤 모습이든 말이죠. 이러한 준비는 기술적 이해뿐만 아니라, 윤리적, 사회적, 경제적 함의에 대한 깊이 있는 성찰을 포함해야 합니다.

구독 공유