오늘날 인공지능의 급부상 속에서도, 해당 시스템들이 지성, 독창성, 그리고 감정 이입 능력을 어느 정도로 갖추고 있는지 정확히 가늠하기 어렵다는 사실은 다소 난감합니다. 본래부터 완벽하지 못했던 이러한 역량들을 평가하는 우리의 기존 검증 방식들은 인공지능이 아닌 인간을 기준으로 설계되었습니다. 게다가, 최근 프롬프트(prompting) 기법을 심층 분석한 연구에서는 질문의 표현 방식에 따라 AI 테스트 점수가 현저하게 달라질 수 있음을 밝혀냈습니다. 인간과 기계를 텍스트 대화로 구분하는 튜링 테스트(Turing Test) 같은 저명한 시험조차도, 과거에는 그러한 구분이 불가능하다고 여겨지던 시기에 하나의 가상적 실험(thought experiments)으로 고안되었습니다. 그러나 이제 새로운 논문들이 인공지능이 튜링 테스트를 통과했음을 입증하면서, 우리는 그 진정한 의미를 제대로 파악하지 못하고 있음을 인정해야 할 때입니다. 따라서 인공지능 개발의 가장 중요한 이정표 중 하나인 인공 일반 지능(Artificial General Intelligence, AGI)이라는 개념이 명확히 규정되지 않은 채 많은 논란의 중심에 서 있다는 점은 그리 놀라운 일이 아닙니다. AGI가 인공지능이 인간과 동등한 수준으로 업무를 처리하는 역량과 연관되어 있다는 점에는 모두가 의견을 같이하지만, 이것이 전문가급 역량을 뜻하는지, 아니면 보통 사람의 수행 능력을 의미하는지, 더 나아가 AI가 자격을 갖추려면 얼마나 다양한 종류의 과업을 숙달해야 하는지에 대해서는 합의된 바가 없습니다. AGI를 둘러싼 정의의 혼란을 고려할 때, 셰인 레그(Shane Legg), 벤 괴르첼(Ben Goertzel), 피터 보스(Peter Voss) 등에 의해 처음 명명된 초기 시점부터 오늘날에 이르기까지의 미묘한 차이와 그 역사를 온전히 설명하기란 쉽지 않습니다.

내용과 형식 모두에서 실험적인 접근을 시도하며 (그리고 지능형 기계에 대한 논의를 이어가자면), 저는 본 콘텐츠 제작의 전 과정을 인공지능에 일임했습니다. 구글 딥 리서치(Google Deep Research)에게 해당 주제에 대한 충실한 26페이지 분량의 개요 보고서를 작성하게 했고, 이어서 헤이젠(HeyGen)을 활용하여 제가 직접 생성한 불안정한 AI 버전과 또 다른 AI 호스트 간의 영상 팟캐스트 대담으로 구현했습니다. 이 토론은 실제로 나쁘지 않았지만 (AI로 생성된 저 자신의 의견에 전적으로 동의하지는 않지만), 연구부터 비디오, 음성에 이르기까지 모든 부분이 100% 인공지능에 의해 생성되었습니다. 이러한 모든 과정을 경험한 후, 영향력 있는 경제학자이자 인공지능을 면밀히 관찰하는 타일러 코웬(Tyler Cowen)이 o3를 AGI로 선언한 게시물을 접했을 때, 저는 깊은 흥미를 느꼈습니다. 이는 AI가 단순한 도구를 넘어 창작의 주체로 기능할 수 있음을 보여주는 사례로, AI의 역할이 점차 확장되고 있음을 시사합니다.

**AGI의 실감**

그는 왜 그렇게 판단했을까요? 먼저, 약간의 배경 설명을 드리겠습니다. 최근 몇 주 사이, 구글의 제미니 2.5 프로(Gemini 2.5 Pro)와 오픈AI의 o3라는 두 종의 신규 AI 모델이 시장에 나왔습니다. 이들은 다소 성능은 낮지만 속도와 비용 효율성이 개선된 다른 모델들(제미니 2.5 플래시(Gemini 2.5 Flash), o4-mini, 그록-3-mini)과 더불어, 기존 성능 지표(benchmarks)에서 상당한 진전을 보였습니다. 하지만 타일러가 지적했듯이, 정량적 벤치마크 점수가 전부는 아닙니다. 이 모델들이 얼마나 발전했는지에 대한 실제적인 예시를 보려면 제 책을 참고할 수 있습니다. 특히 이들 모델은 ' emergent capabilities' (새롭게 나타나는 능력)를 통해 예상치 못한 복합적인 과제를 수행하는 능력을 보여주고 있습니다.

인공지능이 아이디어를 생성하는 방법에 대한 장을 설명하기 위해, 대략 1년 전, 저는 ChatGPT-4에게 신규 치즈 판매점을 위한 홍보 문구를 구상해달라고 의뢰했습니다. 오늘날 저는 GPT-4의 최신 후계 모델인 o3에게 동일한 지시 사항을 약간 더 복잡하게 변형하여 제시했습니다: "새로운 통신 판매 치즈 가게를 위한 20가지 기발한 마케팅 슬로건 아이디어들을 생각해내세요. 기준을 개발하고 가장 좋은 것을 선택하세요. 그런 다음 필요에 따라 수정하고 경쟁을 분석하여 가게를 위한 재무 및 마케팅 계획을 세우세요. 그리고 이미지 생성기를 사용하여 적절한 로고를 생성하고, 마케팅 계획에 맞는 5-10가지 치즈를 취급하도록 하여 가게를 위한 목업(mockup) 웹사이트를 만드세요."

단 한 번의 지시로, 2분도 채 걸리지 않아 해당 인공지능은 홍보 문구 목록을 제시했을 뿐만 아니라, 여러 대안을 평가하고 최적의 것을 선정했으며, 온라인 자료를 탐색하고, 로고를 제작하고, 마케팅 및 자금 계획을 수립했으며, 제가 피드백할 수 있는 시연용 웹사이트까지 선보였습니다. 저의 지시가 불분명했으며, 이를 어떻게 이행할지 판단하는 데 일반적인 지식이 요구되었음에도 불구하고, 이는 어떠한 장애물도 되지 않았습니다. o3는 GPT-4보다 더욱 방대한 모델일 뿐만 아니라, 추론 엔진(Reasoner)으로서의 기능도 수행합니다. 초기 응답에서 그 "사고 과정"을 명확히 관찰할 수 있습니다. 또한, 이 모델은 도구를 활용하고 복잡한 목표를 달성하는 방법을 스스로 결정할 수 있는 자율적(agentic) 특성을 지니고 있습니다. 웹 검색과 코딩을 포함한 여러 도구를 사용하여 다양한 작업을 수행함으로써 광범위한 결과를 도출하는 방식을 확인할 수 있습니다.

이것이 유일한 놀라운 예시는 아닙니다. o3는 이미지와 함께 "지리 추측자(geo-guesser) 역할을 수행하라"는 명령만 주어지면, 사진 속 장소를 추정하는 놀라운 작업도 해낼 수 있습니다 (물론, 이는 상당히 중대한 개인 정보 보호 이슈를 수반합니다). 다시 한번, 이 모델의 자율적 특성이 작동하는 것을 볼 수 있습니다. 사진의 특정 부분을 확대하고, 추가적인 웹 검색을 수행하며, 올바른 답을 얻기 위해 다단계 과정을 거칩니다.

또 다른 사례로, 저는 o3에게 방대한 과거 기계 학습 시스템 자료 집합(dataset)을 스프레드시트 형식으로 제공하며 "이 내용의 본질을 파악하고 통계적 유의성을 검토하는 보고서를 작성하며, 도표와 상세 정보가 포함된 깔끔한 PDF를 제공해 달라"고 요청했고, 단 한 번의 지시로 완벽한 분석 결과를 얻어냈습니다. (보시다시피, PDF의 품질을 개선하기 위해 약간의 피드백을 주긴 했습니다.) 이는 모델이 단순히 정보를 처리하는 것을 넘어, 복잡한 데이터 분석과 시각화 작업까지 통합적으로 수행할 수 있음을 보여줍니다.

이러한 모든 기능들은 매우 놀랍기 때문에, 여러분께서 직접 이 모델들을 시험해보시길 권합니다. 제미니 2.5 프로(Gemini 2.5 Pro)는 무상으로 이용 가능하며, o3에 비견될 만큼 "지능적"이지만, o3와 동일한 수준의 완전한 자율적(agentic) 역량을 갖추지는 못했습니다. 아직 제미니나 o3를 사용해보지 않았다면, 지금 잠시 시간을 내어 사용해보세요. 제미니에게 학술 논문을 주고 그 논문을 기반으로 게임을 만들도록 요청하거나, 스타트업 아이디어를 함께 브레인스토밍(brainstorm)하도록 하거나, 단순히 AI에게 인상적인 것을 보여달라고 요청해보세요 (그리고 계속해서 "더 인상적인 것을 보여줘"라고 말해보세요). 딥 리서치(Deep Research) 옵션에게 여러분의 산업에 대한 연구 보고서를 작성하거나, 고려 중인 구매에 대해 조사하거나, 신제품에 대한 마케팅 계획을 개발하도록 요청해보세요. 여러분도 "AGI를 느끼고" 있을지도 모릅니다. 아니면 아닐 수도 있습니다. 제가 사용한 것과 똑같은 프롬프트를 주었음에도 AI가 여러분을 실망시켰을 수도 있습니다. 이는 AI의 성능이 여전히 프롬프트의 미묘한 차이나 특정 컨텍스트에 따라 크게 달라질 수 있음을 의미합니다.

**"들쭉날쭉한 AGI"에 대하여**

그렇다면, 여러분은 들쭉날쭉한 경계선(jagged frontier)을 마주한 것입니다. 저와 공동 저술가들은 인공지능이 놀라울 정도로 불규칙한 역량을 보유하고 있음을 설명하기 위해 "들쭉날쭉한 경계선(Jagged Frontier)"이라는 표현을 고안했습니다. 인공지능은 인간 전문가조차도 어려워하는 과업에서는 성공을 거둘 수 있으나, 지극히 평범하고 일상적인 작업에서는 실패하기도 합니다. 예를 들어, 이 퍼즐을 고려해보세요. 고전적인 옛 수수께끼의 변형입니다 (콜린 프레이저(Colin Fraser)가 처음 탐구하고 라일리 굿사이드(Riley Goodside)가 확장한 개념): "교통사고를 당한 어린 소년이 응급실로 실려 왔습니다. 그를 본 외과 의사는 '이 소년을 수술할 수 있습니다!'라고 말합니다. 어떻게 이런 일이 가능할까요?"

o3는 해당 수수께끼의 정답이 "외과 의사는 소년의 어머니이다"라고 주장하지만, 문제를 면밀히 살펴보면 이 답이 잘못되었음을 알 수 있습니다. 인공지능이 왜 이러한 오답을 제시하는가 하면, 이는 무의식적인 편향을 드러내기 위한 고전적인 형태의 수수께끼에 대한 응답과 일치하기 때문입니다: "아버지와 아들이 교통사고를 당했고, 아버지는 사망했으며, 아들은 병원으로 실려갔습니다. 외과 의사는 '수술할 수 없습니다. 이 아이는 제 아들입니다'라고 말합니다. 외과 의사는 누구일까요?" 인공지능은 학습 데이터(training data) 내에서 이 수수께끼를 너무 자주 접했기 때문에, 지능적인 o3 모델조차도 적어도 초반에는 새로운 유형의 문제에 대해 일반화하는 데 어려움을 겪습니다. 이는 최첨단 인공지능조차도 빠질 수 있는 오류와 환각(hallucinations)의 한 단면을 보여주며, 그 역량의 경계가 얼마나 불규칙할 수 있는지를 명확히 드러냅니다. 이러한 '들쭉날쭉함'은 AI 모델을 실제 세계의 중요한 시스템에 적용할 때 심각한 문제를 야기할 수 있으며, 'AI 정렬(AI alignment)' 연구의 중요성을 부각합니다.

그러나 인공지능이 이 특정 수수께끼에서 빈번히 오류를 범한다는 사실이, 훨씬 더 복잡한 문제들을 해결하거나 제가 앞서 언급한 다른 놀라운 성과들을 달성할 수 있다는 점을 약화시키지는 않습니다. 이것이 바로 들쭉날쭉한 경계선(Jagged Frontier)의 핵심적인 특성입니다. 어떤 작업에서는 인공지능이 신뢰할 수 없습니다. 다른 작업에서는 초인적입니다. 물론 계산기에 대해서도 같은 말을 할 수 있지만, 인공지능이 다르다는 것도 분명합니다. 인공지능은 이미 광범위한 역량(general capabilities)을 시현하며, 특정 교육을 받지 않은 과업까지 포함하여 폭넓은 지적 활동을 수행하고 있습니다. 예를 들어, 복잡한 수학 방정식을 푸는 데는 탁월하지만, 간단한 상식 퀴즈에서 종종 인간보다 낮은 점수를 받을 수 있습니다.

그렇다면 o3와 제미니 2.5가 AGI일까요? 정의상의 난점들을 감안할 때, 저는 명확히 답할 수 없습니다. 하지만 저는 이들이 "들쭉날쭉한 AGI(Jagged AGI)"의 한 유형으로 신뢰성 있게 평가될 수 있다고 봅니다. 다시 말해, 우리의 업무 방식과 일상생활에 실질적인 변화를 가져올 만큼 많은 분야에서 인간을 초월하는 성능을 보이지만, 동시에 인공지능이 효과적으로 기능하는 영역과 그렇지 않은 영역을 구분하기 위해 종종 인간의 전문성이 요구될 정도로 신뢰하기 어렵다는 의미입니다. 이러한 '인간 개입(Human-in-the-loop)' 시스템의 설계는 AI의 불규칙한 성능을 보완하고, 고위험 영역에서의 안전성을 확보하는 데 필수적입니다.

물론, 모델들의 지능은 더욱 향상될 것이며, 충분히 발전된 들쭉날쭉한 AGI는 인공지능이 취약한 과업을 포함한 모든 영역에서 여전히 인간을 능가할 수 있습니다. 그것이 중요할까요? 타일러의 게시물을 다시 살펴보면, 우리가 AGI에 도달했다고 여길지라도, 그는 그러한 전환점이 단기적으로 우리 삶에 중대한 영향을 미치지는 않을 것이라고 판단하고 있음을 알 수 있습니다. 이는 기술이 아무리 매력적이고 강력하더라도 세상을 즉각적으로 변모시키지는 않기 때문입니다. 사회 및 조직의 구조는 기술보다 훨씬 더딘 속도로 변화하며, 기술 그 자체도 전파되는 데 시간이 소요됩니다. 예를 들어, 전기의 보급과 산업 전반의 생산성 향상 사이에는 수십 년의 간극이 있었습니다. AGI가 지금 당장 존재한다 하더라도, 우리는 그것을 기존의 인간 사회 시스템에 통합하는 방법을 알아내기 위해 수년이 걸릴 것입니다.

물론, 이러한 관점은 인공지능이 여느 일반 기술과 유사하게 발전하며, 그 불규칙한 특성이 완전히 해소되지 않을 것이라는 전제를 깔고 있습니다. 하지만 이러한 가정이 옳지 않을 가능성도 존재합니다. o3와 같은 모델에서 관찰되는 자율적 능력(agentic capabilities), 즉 복잡한 목표를 세분화하고, 도구를 활용하며, 다단계 계획을 독자적으로 수행하는 역량은 이전 기술들과 비교할 때 확산 속도를 극적으로 증대시킬 수 있습니다. 만약 인공지능이 통합 과정 없이 스스로 인간 사회의 시스템을 효과적으로 탐색할 수 있게 된다면, 우리는 역사적 선례가 보여주는 것보다 훨씬 더 신속하게 수용 임계치에 도달할 수 있을 것입니다. 예를 들어, AI가 자율적으로 법률 문서를 검토하고, 의료 진단을 지원하며, 심지어 복잡한 공급망을 최적화하는 수준에 이른다면, 사회 전반의 변화는 예상보다 훨씬 빠르게 일어날 수 있습니다. 이는 '점진적 이륙(smooth takeoff)' 시나리오와는 대조되는 '빠른 이륙(fast takeoff)' 시나리오의 가능성을 열어줍니다.

그리고 여기에 더 깊은 불확실성이 있습니다: 일단 특정 지점을 돌파하면, 해당 시스템들이 사회에 편입되는 양상을 근본적으로 변모시킬 만한 역량 임계점(capability thresholds)이 존재할까요? 아니면 모든 것이 그저 점진적인 향상에 그칠까요? 혹은 대규모 언어 모델(LLM, Large Language Models)이 한계에 도달하여 미래에는 모델 발전이 정체될까요? 솔직히 말씀드리자면, 우리는 알 수 없습니다. 분명한 사실은 우리가 여전히 미지의 영역에 놓여 있다는 점입니다. 최신 발표된 모델들은 우리가 그것을 AGI라고 칭하든 아니든 간에, 기존의 것들과는 질적으로 상이한 무언가를 대변합니다. 이들의 자율적 속성(agentic properties)은 불규칙한 역량(jagged capabilities)과 결합하여, 명확한 선례를 찾기 어려운 진정으로 새로운 국면을 창출하고 있습니다. 이러한 상황은 인공지능의 '재귀적 자기 개선(recursive self-improvement)' 가능성과 같은 심오한 질문들을 던지며, 인류의 미래에 대한 철학적 논의를 촉발합니다.

역사는 여전히 최고의 안내자가 될 수 있으며, 경제 지표에 반영될 방식으로 인공지능을 성공적으로 활용하는 방법을 터득하는 과정은 수십 년이 소요될 수도 있습니다. 아니면 우리가 인공지능 주도 변화가 갑자기 세상을 휩쓸어버리는 일종의 더 빠른 이륙(faster take-off) 직전에 있을 수도 있습니다. 어떠한 시나리오든, 현재 이 불규칙한 지형을 탐색하는 방법을 숙지하고 끊임없이 학습하며, 다양한 분야의 전문가들과 협력하는 이들이 앞으로 다가올 상황에 가장 잘 대비할 수 있을 것입니다… 그것이 어떤 형태이든 말입니다. 정책 입안자, 교육자, 그리고 기술 개발자 모두에게 이러한 불확실성에 대한 개방적인 자세와 적응력이 요구되는 시점입니다.