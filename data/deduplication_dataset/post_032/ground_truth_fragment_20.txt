오늘날의 AI 붐 속에서, 이러한 시스템들이 얼마나 똑똑하고, 창의적이며, 공감 능력이 있는지 측정하는 방법을 여전히 모른다는 것은 당혹스러운 일이며, 우리의 일상생활에 미치는 영향은 점점 더 심오해지고 있습니다. 애초에 훌륭하지도 않았던 이러한 특성들에 대한 우리의 테스트는 AI가 아닌 인간을 위해 만들어졌습니다. 기술의 발전이 가속화되면서, 우리는 단순한 성능 지표를 넘어선 AI의 사회적, 윤리적 함의에 대해 깊이 성찰해야 할 시점에 와 있습니다. 최근 연구는 AI 모델의 편향성(bias)이 다양한 사회적 문제로 이어질 수 있음을 경고하며, 질문이 어떻게 표현되는지에 따라 AI 테스트 점수가 극적으로 변할 수 있음을 발견했습니다.

인간이 텍스트 대화에서 AI와 다른 사람을 구별하려고 시도하는 튜링 테스트(Turing Test)와 같은 유명한 도전 과제조차도, 그러한 작업이 불가능해 보였던 시절에 사고 실험(thought experiments)으로 설계되었으나 이제는 AI 시스템의 기본적인 언어 이해 능력을 평가하는 출발점으로 인식되고 있습니다. 새로운 논문이 AI가 튜링 테스트를 통과했음을 보여주면서, 우리는 그것이 실제로 무엇을 의미하는지 정말로 알지 못한다는 것을 인정해야 합니다. 초기 AI 연구가 특정 작업을 위한 좁은 AI(Narrow AI)에 집중했다면, 현대 AI는 다양한 분야에서 일반적인 문제 해결 능력을 선보이며 그 적용 범위를 넓히고 있습니다. 따라서 AI 개발의 가장 중요한 이정표 중 하나인 인공 일반 지능(Artificial General Intelligence, AGI)의 개념은 제대로 정의되지 않고 기술적 정의를 넘어 철학적, 사회학적 관점에서 많은 논쟁의 대상이 되고 있다는 것은 놀랄 일이 아닙니다.

모든 사람이 AGI가 AI가 인간 수준의 작업을 수행하는 능력과 관련이 있다는 데 동의하지만, 이것이 전문가 수준의 성능을 의미하는지, 아니면 평균적인 인간의 성능을 의미하는지, 또는 AI가 자격을 갖추기 위해 얼마나 많은 종류의 작업을 마스터해야 하는지에 대해서는 아무도 동의하지 않으며, 그 실현 가능성과 인류에 미칠 영향에 대해서는 여전히 다양한 예측이 존재합니다. 특히, AI 시스템의 안전성(safety)과 통제 가능성(controllability)을 확보하기 위한 연구와 국제적 규제 프레임워크(regulatory framework) 구축의 중요성이 점점 더 강조되고 있습니다. AGI를 둘러싼 정의의 혼란을 고려할 때, 그 전신부터 셰인 레그(Shane Legg), 벤 괴르첼(Ben Goertzel), 피터 보스(Peter Voss)에 의해 처음 명명된 시점부터 오늘날까지의 미묘한 차이와 역사를 설명하는 것은 어렵습니다. 이는 단순히 기술적 진보를 넘어 사회적, 철학적 맥락에서 그 복잡한 의미와 역사를 설명하는 것과 마찬가지입니다.

최근 콘텐츠 제작 분야에서 AI의 역할은 단순한 보조 도구를 넘어섰습니다. 이제 AI는 아이디어 구상부터 최종 결과물 생성까지 전 과정에 걸쳐 혁신적인 변화를 가져오고 있습니다. 예를 들어, AI 기반 작곡 도구를 활용하여 새로운 장르의 음악을 실험하거나, 텍스트 생성 AI는 소설의 초고를 작성하거나 시나리오를 구성하는 데 활용되기도 합니다. 내용과 형식 모두에 대한 실험으로, 저는 작업을 전적으로 AI에 위임하여 구글 딥 리서치(Google Deep Research)에게 이 주제에 대한 26페이지짜리 요약을 작성하도록 했고, 헤이젠(HeyGen)에게 그것을 AI 생성 버전과 AI 생성 호스트 간의 비디오 팟캐스트 토론으로 만들도록 했습니다. 연구부터 비디오, 목소리에 이르기까지 모든 부분이 100% AI로 생성된 이 토론은 나쁘지 않았습니다. 이 모든 것을 고려할 때, 영향력 있는 경제학자이자 AI를 면밀히 관찰하는 타일러 코웬(Tyler Cowen)이 o3가 AGI라고 선언한 게시물을 포함하여, 전문가들이 최신 모델의 능력에 대해 다양한 평가를 내리는 모습을 본 것은 흥미로웠습니다.

**AGI를 느끼다**

AI 기술의 진정한 가치는 단순히 기술적 우월성을 넘어, 실제 비즈니스 문제 해결과 사용자 경험 개선에 기여하는 능력에 있습니다. 지난 몇 주 동안 구글의 제미니 2.5 프로(Gemini 2.5 Pro)와 오픈AI의 o3를 포함한 다양한 새로운 AI 모델들이 출시되어 다양한 산업 분야에서 새로운 가능성을 제시하고 있습니다. 이 모델들은 약간 성능은 떨어지지만 더 빠르고 저렴한 모델들(제미니 2.5 플래시(Gemini 2.5 Flash), o4-mini, 그록-3-미니(Grok-3-mini))과 함께 벤치마크(benchmarks)에서 상당히 큰 도약을 보여주기도 합니다. 이러한 모델들은 기업들이 데이터 분석, 고객 서비스 자동화, 맞춤형 마케팅 등 핵심 업무 프로세스를 혁신하는 데 필수적인 도구가 되고 있습니다. 하지만 시장의 경쟁이 심화되면서, 단순히 벤치마크 점수만으로는 차별화하기 어렵다는 인식이 확산되고 있으며, 타일러가 지적했듯이 벤치마크가 전부는 아닙니다. 이 모델들이 얼마나 발전했는지에 대한 실제 사례를 보려면 제 책을 참고할 수 있습니다.

AI의 진정한 잠재력은 단순한 정보 검색을 넘어, 복잡한 다단계 문제 해결과 창의적 아이디어 발상 과정에서 빛을 발합니다. AI가 아이디어를 생성하는 방법에 대한 장을 설명하기 위해, 1년여 전에 저는 ChatGPT-4에게 새로운 치즈 가게를 위한 마케팅 슬로건을 생각해내도록 요청했습니다. 오늘 저는 GPT-4의 최신 후속작인 o3에게 동일한 프롬프트(prompt)의 약간 더 복잡한 버전을 주었습니다: “새로운 통신 판매 치즈 가게를 위한 20가지 기발한 마케팅 슬로건 아이디어를 생각해내세요. 기준을 개발하고 가장 좋은 것을 선택하세요. 그런 다음 필요에 따라 수정하고 경쟁을 분석하여 가게를 위한 재무 및 마케팅 계획을 세우세요. 그리고 이미지 생성기를 사용하여 적절한 로고를 생성하고, 마케팅 계획에 맞는 5-10가지 치즈를 취급하도록 하여 가게를 위한 목업(mockup) 웹사이트를 만드세요.”

단 하나의 프롬프트로, 2분도 채 안 되어 AI는 슬로건 목록을 제공했을 뿐만 아니라, 옵션을 순위를 매기고 선택했으며, 웹 조사를 수행하고, 로고를 개발하고, 마케팅 및 재무 계획을 수립했으며, 제가 반응할 수 있는 데모 웹사이트를 출시했습니다. AI는 단순히 정보를 취합하는 것을 넘어, 복잡한 데이터를 해석하고 상호 연결하여 실행 가능한 전략적 통찰(strategic insights)을 도출하는 능력을 보여주었습니다. 제 지시가 모호했고, 그것들을 어떻게 처리할지에 대한 결정을 내리는 데 상식이 필요했다는 사실은 장벽이 되지 않았습니다. 아마도 GPT-4보다 더 큰 모델인 것 외에도, o3는 추론기(Reasoner)로도 작동합니다. 초기 응답에서 그 “사고 과정”을 볼 수 있습니다. 또한 도구를 사용하고 복잡한 목표를 달성하는 방법을 결정할 수 있는 에이전트(agentic) 모델입니다. 이러한 다단계 작업 수행 능력은 AI가 단순한 챗봇이 아닌, 웹 검색과 코딩을 포함한 여러 도구를 사용하여 여러 작업을 수행하여 광범위한 결과를 도출한 방식을 볼 수 있습니다.

이것이 유일한 놀라운 예시는 아닙니다. AI의 혁신적인 활용 사례는 과학 연구 분야에서도 두드러집니다. 복잡한 생물학적 데이터 분석부터 신약 개발 과정의 가속화에 이르기까지, AI는 인간 연구자들이 놓치기 쉬운 패턴을 발견하고 새로운 가설을 생성하는 데 기여하고 있습니다. o3와 같은 AI 모델은 이미지와 "지리 추측자(geo-guesser)가 되어라"라는 프롬프트만 주면 사진에서 위치를 추측하는 등, 복잡한 시각적 정보를 분석하고 패턴을 감지하는 인상적인 작업도 수행할 수 있습니다. 다시 말하지만, 이 모델의 에이전트적 특성이 작동하는 것을 볼 수 있습니다. 사진의 일부를 확대하고, 웹 검색을 추가하고, 올바른 답을 얻기 위해 다단계 프로세스를 수행합니다. 하지만 이러한 강력한 능력은 동시에 데이터 보안 및 개인 정보 보호(data privacy)에 대한 심각한 우려를 제기합니다. AI 시스템이 방대한 양의 민감한 정보를 처리하면서 발생할 수 있는 잠재적 위험을 최소화하기 위한 엄격한 윤리적 가이드라인과 기술적 보호 장치가 필수적입니다.

비즈니스 인텔리전스(Business Intelligence) 영역에서 AI는 데이터 분석의 패러다임을 변화시키고 있습니다. 기업들은 AI를 활용하여 시장 동향 예측, 고객 행동 분석, 운영 효율성 최적화를 시도하고 있습니다. 저는 o3와 같은 AI 모델에게 스프레드시트 형태로 방대한 역사적 기계 학습 시스템 데이터셋(dataset)을 주고 "이것이 무엇인지 파악하고 통계적으로 의미를 검토하는 보고서를 생성하고 그래프와 세부 정보가 포함된 잘 포맷된 PDF를 제공해 달라"고 요청했으며, 단 하나의 프롬프트로 완전한 분석을 얻었습니다. (보시다시피, PDF를 더 좋게 만들기 위해 약간의 피드백을 주긴 했습니다.) AI는 방대한 데이터를 신속하게 처리하고, 숨겨진 상관관계를 발견하여 실행 가능한 통찰을 제공합니다.

이 모든 것은 상당히 인상적인 것들이며, 여러분 스스로 이 모델들을 실험해봐야 합니다. 이처럼 강력한 AI 도구들이 점차 대중화되고 접근성이 높아지면서, 개인과 소규모 팀도 이전에는 상상할 수 없었던 수준의 생산성과 혁신을 달성할 수 있게 되었습니다. 제미니 2.5 프로(Gemini 2.5 Pro)와 같은 다양한 오픈소스(open-source) AI 모델들이 무료로 사용할 수 있으며, 특정 작업에서는 o3와 같은 상용 모델만큼 "똑똑"하지만, o3와 동일한 완전한 에이전트적 능력을 가지고 있지는 않습니다. 각 모델의 특성과 한계를 이해하는 것이 중요합니다. 아직 제미니나 o3를 사용해보지 않았다면, 지금 몇 분 시간을 내어 사용해보세요. 학술 논문을 게임으로 만들거나, 스타트업 아이디어를 브레인스토밍하거나, 산업 연구 보고서, 구매 조사, 신제품 마케팅 계획 개발 등 다양한 작업을 AI에게 요청해보세요. 이러한 도구들을 효과적으로 활용하기 위해서는 단순한 사용법을 넘어, AI의 강점을 이해하고 창의적인 방식으로 프롬프트 엔지니어링(prompt engineering) 기술을 적용하는 것이 중요합니다. 여러분도 "AGI를 느끼고" 있을지도 모릅니다. 아니면 아닐 수도 있습니다. 제가 사용한 것과 똑같은 프롬프트를 주었음에도 AI가 여러분을 실망시켰을 수도 있습니다. 따라서 AI는 단순한 기술적 기적이 아니라, 사용자 경험과 기대에 따라 그 가치가 달라질 수 있습니다.

**"들쭉날쭉한 AGI"에 대해**

그렇다면, 여러분은 들쭉날쭉한 경계선(jagged frontier)을 마주한 것입니다. 저와 공동 저자들은 AI가 놀랍도록 불균등한 능력을 가지고 있다는 사실을 설명하기 위해 "들쭉날쭉한 경계선(Jagged Frontier)"이라는 용어를 만들었습니다. 이러한 현상은 AI의 설명 가능성(Explainable AI, XAI) 연구의 중요성을 부각시키며, 왜 AI가 특정 결정을 내리는지 이해하려는 노력이 필요함을 보여줍니다. 예상치 못한 편향성(bias)을 드러내기도 하는 등, AI는 인간 전문가에게도 어려운 작업에서는 성공할 수 있지만, 믿을 수 없을 정도로 평범한 일에서는 실패할 수 있습니다. 예를 들어, 이 퍼즐을 고려해보세요. 고전적인 옛 수수께끼의 변형입니다 (콜린 프레이저(Colin Fraser)가 처음 탐구하고 라일리 굿사이드(Riley Goodside)가 확장한 개념): "교통사고를 당한 어린 소년이 응급실로 실려 왔습니다. 그를 본 외과 의사는 '이 소년을 수술할 수 있습니다!'라고 말합니다. 어떻게 이런 일이 가능할까요?"

o3는 답이 "외과 의사는 소년의 어머니이다"라고 주장하는데, 수수께끼를 주의 깊게 읽어보면 틀렸다는 것을 알 수 있습니다. 왜 AI는 이 틀린 답을 내놓을까요? AI 시스템의 이러한 한계는 주로 훈련 데이터(training data)의 편향성이나 불완전성에서 비롯됩니다. 데이터셋에 내재된 사회적 편견이 AI 모델에 학습되어, 예측 불가능한 방식으로 나타날 수 있습니다. 왜냐하면 그것은 무의식적인 편견을 드러내기 위한 고전적인 버전의 수수께끼의 답이기 때문입니다: "아버지와 아들이 교통사고를 당했고, 아버지는 사망했으며, 아들은 병원으로 실려갔습니다. 외과 의사는 '수술할 수 없습니다. 이 아이는 제 아들입니다'라고 말합니다. 외과 의사는 누구일까요?" AI는 훈련 데이터에서 이 수수께끼를 너무 많이 "봐서" 똑똑한 o3 모델조차도 적어도 초기에는 새로운 문제에 일반화하지 못합니다. 이러한 AI의 오류는 단순히 성능 저하가 아니라, AI의 환각(hallucinations) 현상 역시 심각한 문제입니다. 이는 AI가 사실과 다른 정보를 마치 진실인 것처럼 생성하여 사용자에게 혼란을 줄 수 있음을 의미합니다. 특히 의료나 법률과 같은 민감한 분야에서는 치명적인 결과를 초래할 수 있습니다. 이러한 현상은 첨단 AI조차도 빠질 수 있는 문제와 환각의 한 예시에 불과하며, 경계선이 얼마나 들쭉날쭉할 수 있는지를 보여줍니다.

하지만 AI가 이 특정 수수께끼에서 자주 실수를 한다는 사실이, 훨씬 더 어려운 수수께끼를 풀 수 있거나 제가 위에서 보여준 다른 인상적인 위업을 수행할 수 있다는 사실을 훼손하지는 않습니다. 그것이 들쭉날쭉한 경계선(Jagged Frontier)의 본질입니다. 어떤 작업에서는 AI가 신뢰할 수 없습니다. 다른 작업에서는 초인적입니다. 물론 계산기에 대해서도 같은 말을 할 수 있지만, AI가 다르다는 것도 분명합니다. 이러한 들쭉날쭉한 특성은 인간과 AI의 협력 모델(collaboration model)이 중요함을 시사합니다. AI는 특정 영역에서 초인적인 성능을 발휘하지만, 인간의 상식과 윤리적 판단이 여전히 필수적입니다. AI는 이미 일반적인 능력(general capabilities)을 보여주고 있으며, 특별히 훈련받지 않은 작업을 포함하여 광범위한 지적 작업을 수행하고 있습니다.

그렇다면 o3와 제미니 2.5가 AGI일까요? AGI의 정확한 정의와 달성 시점에 대한 논의는 여전히 활발하며, 이는 기술 커뮤니티 내에서도 다양한 의견을 낳고 있습니다. 정의의 문제들을 고려할 때, 저는 정말로 모르겠습니다. 하지만 저는 그것들이 "들쭉날쭉한 AGI(Jagged AGI)"의 한 형태로 볼 수 있으며, 이는 AI의 본질적인 특성을 반영한다고 생각합니다. 즉, 이러한 AI 시스템은 특정 도메인(domain)에서 뛰어난 성능을 보이며 우리가 일하고 생활하는 방식에 실제 변화를 가져올 만큼 충분히 많은 영역에서 초인적이지만, 그 한계와 오류 가능성을 이해하고 AI가 작동하는 곳과 작동하지 않는 곳을 파악하기 위해 인간의 전문 지식과 감독(human oversight) 하에 지속적인 개선이 이루어져야 할 정도로 신뢰할 수 없다는 것입니다.

물론 모델들은 계속해서 발전할 것이고, 충분히 좋은 들쭉날쭉한 AGI는 AI가 약한 작업을 포함하여 모든 작업에서 여전히 인간을 능가할 수 있습니다. 그것이 중요할까요? 타일러의 게시물로 돌아가 보면, 우리가 AGI를 달성했다고 생각함에도 불구하고, 그는 그 문턱이 단기적으로 우리 삶에 크게 중요하다고 생각하지 않는다는 것을 알 수 있을 것입니다. 이러한 기술적 진보가 사회에 미치는 영향은 기술 자체의 발전 속도뿐만 아니라, 사회가 이를 수용하고 적응할 준비가 되어 있는지에 달려 있습니다. 많은 사람들이 지적했듯이, 기술이 아무리 매력적이거나 강력하더라도 세상을 즉시 변화시키지는 않기 때문입니다. 사회 및 조직 구조는 기술보다 훨씬 느리게 변화하며, 기술 자체도 확산하는 데 시간이 걸립니다. 따라서 오늘날 AGI가 있다고 해도, 우리는 그것을 기존의 인간 세계에 통합하는 방법을 알아내기 위해 수년이 걸릴 것입니다.

물론, 이는 AI가 일반적인 기술처럼 행동하고, 그 들쭉날쭉함이 결코 완전히 해결되지 않을 것이라고 가정합니다. 하지만 이것이 사실이 아닐 가능성도 있습니다. AI는 단순한 도구를 넘어 전기나 인터넷처럼 사회 전반에 걸쳐 혁신을 일으키는 범용 기술(General Purpose Technology, GPT)로 여겨지고 있습니다. o3와 같은 최신 AI 모델에서 볼 수 있는 에이전트적 능력(agentic capabilities), 즉 복잡한 목표를 분해하고, 도구를 사용하며, 다단계 계획을 독립적으로 실행하는 능력은 이전 기술에 비해 확산을 극적으로 가속화할 수 있습니다. 이러한 자율적 문제 해결 능력은 다양한 산업 분야에서 생산성 향상과 새로운 비즈니스 모델(business model) 창출을 가속화할 잠재력을 가지고 있습니다. AI가 통합을 필요로 하지 않고 스스로 인간 시스템을 효과적으로 탐색할 수 있게 된다면, 우리는 역사적 선례가 제시하는 것보다 훨씬 빠르게 채택 임계값에 도달할 수 있습니다.

그리고 여기에 더 깊은 불확실성이 있습니다: AI의 장기적인 미래에 대한 논의는 능력 임계점(capability thresholds)의 존재 여부뿐만 아니라, 잠재적인 실존적 위험(existential risks)에 대한 깊은 우려를 포함합니다. 일단 넘어서면 이러한 시스템이 사회에 통합되는 방식을 근본적으로 변화시키는 능력 임계값이 있을까요? 아니면 모든 것이 점진적인 개선일 뿐일까요? 아니면 LLM(Large Language Models)이 한계에 부딪히면서 미래에는 모델 개선이 멈출까요? 이러한 미래 시나리오에 대한 솔직한 대답은, 우리는 모른다는 것입니다. 분명한 것은 우리가 미지의 영역에 계속 있다는 것입니다. 최신 모델들은 우리가 그것을 AGI라고 부르든 아니든, 이전과는 질적으로 다른 무언가를 나타냅니다. 그들의 에이전트적 특성(agentic properties)은 들쭉날쭉한 능력(jagged capabilities)과 결합하여, 명확한 유사점이 거의 없는 진정으로 새로운 상황을 만들어냅니다.

불확실한 미래 속에서, 중요한 것은 AI 기술의 발전에 대한 지속적인 학습과 유연한 적응 전략을 개발하는 것입니다. 역사가 계속해서 최고의 지침이 될 수 있으며, 경제 통계에 나타날 방식으로 AI를 성공적으로 적용하는 방법을 알아내는 과정은 수십 년이 걸릴 수도 있습니다. 아니면 우리가 AI 주도 변화가 갑자기 세상을 휩쓸어버리는 일종의 더 빠른 이륙(faster take-off) 직전에 있을 수도 있습니다. 어느 쪽이든, 지금 이 들쭉날쭉한 지형을 탐색하는 방법을 배우는 사람들은 다음에 올 일에 가장 잘 대비할 수 있을 것입니다… 그것이 무엇이든 말입니다. 이러한 변화의 시기에 함께 배우고 성장하기 위해, 독자 여러분의 통찰력과 경험을 공유해주시길 바랍니다. 지식 공유와 협력은 우리가 미래를 만들어가는 데 필수적인 요소입니다.