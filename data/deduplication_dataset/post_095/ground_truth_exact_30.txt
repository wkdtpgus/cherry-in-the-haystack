**업데이트**: 전체 강연은 지금 YouTube에서 시청하실 수 있습니다! 슬라이드는 여기에서 확인하세요: https://docs.google.com/presentation/d/1sZqMAoIJDxz79cbC5ap5v9jknYH4Aa9cFFaWL8Rids4/edit?usp=sharing 많은 사람들이 오늘 YC AI 스타트업 스쿨(YC AI Startup School)에서 있었던 Andrej의 강연에 흥분했습니다. 안타깝게도 저는 초대받지 못했습니다. 강연은 "앞으로 몇 주 안에" 공개될 예정인데, 그때쯤이면 강연 내용이 구식이 될 수도 있습니다. 아무도 팬캠(fancam)을 녹화한 것 같지 않습니다. 하지만… 아직 끝이 아닙니다. 그냥 직접 해볼 수 있습니다! 피프리서치(PeepResearch)™를 사용하여 강연에 대한 모든 트윗을 취합하고, 훌륭한 필기자(마지막 슬라이드에 출처 표기)들의 힌트를 활용하여 순서를 매겼습니다. **업데이트**: 이제 전체 스크립트(transcript)가 나왔습니다! 여기에서 가장 중요한 핵심 내용들을 살펴보고, 구독자들은 하단에서 전체 슬라이드를 얻을 수 있습니다. 몇 주 안에 전체 강연 영상이 올라오면 이 글을 업데이트하여 주석을 달 예정입니다. **업데이트**: 슬라이드가 이제 전체 스크립트(transcript)와 동기화(synced)되었습니다. 읽어보시려면 아래로 스크롤하여 슬라이드를 확인하세요.

이전 게시물에서 우리는 Andrej Karpathy의 강연을 재구성하기 위해 노력했습니다. 이제 시간이 흘러, 그의 통찰력이 어떻게 발전했으며, AI 생태계에 어떤 영향을 미쳤는지 심층적으로 살펴볼 때입니다. 특히 최근 AI 에이전트(Agent) 기술의 급부상과 함께 그의 초기 비전이 현실화되는 양상에 주목합니다.

**Part 0: 소프트웨어 3.0(Software 3.0) - 프롬프트(Prompt)가 이제 프로그램(Program)이다**

우리는 "AI 엔지니어(AI Engineer)의 부상(Rise of The AI Engineer)"에서 소프트웨어 3.0(Software 3.0)에 대해 처음 논의했지만, 이는 소프트웨어 2.0(Software 2.0) 에세이와 "가장 뜨거운 새로운 프로그래밍 언어(programming language)는 영어다"라는 말의 명백한 결과입니다. 그는 원래 테슬라(Tesla)에서 소프트웨어 1.0(Software 1.0)을 잠식하고 있는 것을 관찰하며 소프트웨어 2.0(Software 2.0) 에세이를 썼습니다. 그리고 이제 소프트웨어 3.0(Software 3.0)에 맞춰 이를 업데이트하기 위해 돌아왔습니다.
Andrej는 소프트웨어 1.0, 2.0, 3.0의 공존과 상호작용을 보여주는 새로운 다이어그램을 선보이며, 3.0이 기존 패러다임을 잠식하고 소프트웨어가 재작성될 것이라고 예측했습니다. 그는 여전히 프로그램(program)을 위한 프롬프트(prompt)에 초점을 맞추고 있으며, 우리는 2023년에 약간 의견이 달랐고 지금도 그렇습니다. 소프트웨어 3.0(Software 3.0)의 "1+2=3" 변형은 지난 몇 년간 AI 엔지니어(AI Engineer)가 프롬프트 엔지니어(Prompt Engineer)를 훨씬 능가했으며 앞으로도 그럴 것이라는 전체적인 이유입니다. 이는 프롬프트 엔지니어링을 넘어, LLM이 전통 코드(1.0)와 학습 모델(2.0)을 결합한 에이전트(Agent) 기반 시스템을 구축하는 패러다임을 의미하며, 프로그램 정의는 '시스템 설계'로 확장됩니다.

**Part 1: LLM(Large Language Model)은 새로운 컴퓨터(Computer)다**

LLM(Large Language Model)은 유틸리티(Utility)와 같다: API를 통해 쉽게 접근 가능한 기본 인프라 서비스로, 클라우드 기반 LLM이 고성능 AI 기능을 제공합니다.
LLM(Large Language Model)은 팹(Fab)과 같다: 물리적 칩 생산처럼, LLM은 '지식'과 '추론 능력'을 생성하며, 미세 조정(fine-tuning)은 맞춤형 '지식 칩'과 유사합니다.
LLM(Large Language Model)은 OS(Operating System)와 같다: LLM은 도구 상호작용, 작업 흐름 조정, 사용자 명령 해석 등 '운영체제' 역할을 수행합니다. 에이전트 프레임워크 내에서 시스템의 두뇌 역할을 합니다.
LLM(Large Language Model)은 시분할 메인프레임(Timeshare Mainframe)과 같다… 비록 그가 "파워 투 더 피플(Power to the People)"에서 주장하듯이, LLM(Large Language Model)은 또한 값비싼 최첨단 기술(frontier tech)의 일반적인 흐름과는 다른 특이한 역전 현상을 보이기도 합니다. 우리가 클라우드(cloud)를 떠나 개인/프라이빗 AI(Personal/Private AI)로 향함에 따라, 엑소랩스(Exolabs) + 애플 MLX(Apple MLX) 작업에서 개인 컴퓨팅 v2(Personal Computing v2)의 몇 가지 징후가 나타나고 있습니다. 최근 온디바이스(on-device) LLM 발전으로 구글 젬마(Gemma), 메타 라마(Llama) 같은 경량 모델이 개인 기기에서 직접 실행 가능해져, 클라우드 의존도를 줄이고 사용자 통제권을 부여하는 새로운 개인 컴퓨팅 시대를 예고합니다.

Part 1 요약: 이러한 비유들은 LLM이 단순한 모델을 넘어, 현대 컴퓨팅 인프라의 근본적인 변화를 이끌고 있음을 보여줍니다.

**Part 2: LLM 심리학(LLM Psychology)**

LLM(Large Language Model)은 "사람의 영혼"과 같습니다. 즉, 일종의 창발적 "심리학"을 가진 사람들의 확률적 시뮬레이션(stochastic simulation)입니다. Andrej는 현재 LLM(Large Language Model)이 사람을 시뮬레이션(simulate)하는 방식에 대한 두 가지 문제를 강조합니다.

**들쭉날쭉한 지능(Jagged Intelligence)** (https://x.com/karpathy/status/1816531576228053133): 제가 생각해낸 이 단어는 최첨단 LLM(state-of-the-art LLM)이 매우 인상적인 작업(예: 복잡한 수학 문제 해결)을 수행할 수 있으면서도 동시에 매우 어리석은 문제로 고군분투하는 (이상하고 직관적이지 않은) 사실을 설명합니다. 예를 들어, 이틀 전의 예시입니다. 9.11과 9.9 중 어떤 숫자가 더 큰가요? 틀렸습니다. … 어떤 것들은 (인간의 기준으로) 매우 잘 작동하는 반면, 어떤 것들은 (다시 인간의 기준으로) 치명적으로 실패하며, 어느 것이 어느 것인지 항상 명확하지는 않지만 시간이 지남에 따라 약간의 직관을 개발할 수 있습니다. 많은 지식과 문제 해결 능력이 모두 고도로 상관관계가 있고 태어날 때부터 성인기까지 함께 선형적으로(linearly) 향상되는 인간과는 다릅니다. 개인적으로 저는 이것들이 근본적인 문제라고 생각하지 않습니다. 이것들은 스케일링(scaling)뿐만 아니라 스택(stack) 전반에 걸쳐 더 많은 작업을 요구합니다. 제가 생각하는 가장 큰 문제는 현재 "인지적 자기 지식(cognitive self-knowledge)"이 부족하다는 것입니다. '자기 성찰(self-reflection)'이나 '사고의 사슬(Chain-of-Thought)' 기법, 특정 영역 전문 모델(Specialist Models) 조합을 통한 앙상블(ensemble) 방식이 주목받고 있습니다. 이는 순진하게 "인간 라벨러(human labeler)를 모방하고 크게 만드는" 해결책 대신 모델 후처리 학습(model post-training)에서 더 정교한 접근 방식을 필요로 합니다. 우리가 지금까지 주로 사용해 온 방식입니다. 제가 말하는 것의 예시를 보려면, 라마 3.1(Llama 3.1) 논문의 환각(hallucination) 완화 섹션을 참조하세요: https://x.com/karpathy/status/1816171241809797335 현재로서는 특히 프로덕션 환경(production setting)에서 이것을 인지해야 합니다. LLM(Large Language Model)을 잘하는 작업에 사용하되, 들쭉날쭉한 부분에 주의하고 휴먼 인 더 루프(human in the loop)를 유지하세요.

**전향성 기억상실증(Anterograde Amnesia)** (https://x.com/karpathy/status/1930003172246073412): 저는 LLM(Large Language Model)이 전향성 기억상실증(Anterograde Amnesia)을 가진 동료와 같다고 설명하고 싶습니다. 즉, 학습이 끝나면 장기적인 지식이나 전문성을 통합하거나 구축하지 못하고, 그들이 가진 것은 단기 기억(short-term memory)(컨텍스트 윈도우(context window))뿐입니다. 이러한 상태에서는 관계를 구축하거나(참조: 첫 키스만 50번째) 작업을 수행하기 어렵습니다(참조: 메멘토). 제가 본 이러한 결함의 첫 번째 완화는 ChatGPT의 메모리(Memory) 기능인데, 이는 앞으로 가능할 것의 원시적이고 조악한 구현처럼 느껴지며, 이것이 제가 여기서 새로운 학습 패러다임(learning paradigm)으로 제안하게 된 계기입니다: https://x.com/karpathy/status/1921368644069765486 우리는 LLM(Large Language Model) 학습을 위한 (적어도 하나의) 주요 패러다임(paradigm)을 놓치고 있습니다. 무엇이라고 불러야 할지 확실하지 않지만, 아마 이름이 있을 수도 있습니다. 시스템 프롬프트 학습(system prompt learning)일까요? 사전 학습(Pretraining)은 지식을 위한 것입니다. 미세 조정(Finetuning)(지도 학습(SL)/강화 학습(RL))은 습관적인 행동을 위한 것입니다. 이 둘 모두 파라미터(parameter)의 변화를 포함하지만, 많은 인간 학습은 시스템 프롬프트(system prompt)의 변화처럼 느껴집니다. 문제를 만나고, 무언가를 알아낸 다음, 다음번을 위해 상당히 명시적인 용어로 무언가를 "기억"합니다. 예를 들어, "이런 종류의 문제를 만났을 때는 이런 종류의 접근 방식/해결책을 시도해야 할 것 같다"와 같습니다. 이는 사용자별 무작위 사실을 저장하는 것이 아니라 일반/전역 문제 해결 지식과 전략을 저장하는 "메모리(Memory)" 기능과 같은, 자신을 위한 메모를 하는 것과 더 비슷하게 느껴집니다. LLM(Large Language Model)은 말 그대로 메멘토(Memento)의 남자와 같지만, 우리는 아직 그들에게 스크래치패드(scratchpad)를 주지 않았습니다. 이 패러다임(paradigm)은 지식 기반 "검토" 단계가 보상 스케일러(reward scaler)보다 훨씬 더 고차원 피드백 채널(feedback channel)이기 때문에 훨씬 더 강력하고 데이터 효율적이라는 점에 주목하세요. … 제 생각에는 이것이 강화 학습(Reinforcement Learning)을 통해 가중치(weight)에 내재화되어야 하는 종류의 문제 해결 지식이 아니며, 적어도 즉시/독점적으로는 아닙니다. 그리고 인간 엔지니어(engineer)가 시스템 프롬프트(system prompt)를 수동으로 작성하는 것에서 나와서도 안 됩니다. 이는 시스템 프롬프트 학습(System Prompt learning)에서 나와야 하며, 이는 학습 알고리즘(learning algorithm)(수정 vs 경사 하강법(gradient descent))을 제외하고는 설정에서 강화 학습(Reinforcement Learning)과 유사합니다. LLM(Large Language Model) 시스템 프롬프트(system prompt)의 상당 부분은 시스템 프롬프트 학습(system prompt learning)을 통해 작성될 수 있으며, 이는 LLM(Large Language Model)이 문제 해결 방법에 대한 책을 스스로 쓰는 것과 비슷하게 보일 것입니다. 이것이 작동한다면 새롭고 강력한 학습 패러다임(learning paradigm)이 될 것입니다. 아직 해결해야 할 많은 세부 사항이 남아 있습니다(수정은 어떻게 작동하는가? 수정 시스템을 학습할 수/해야 하는가? 인간이 하는 것처럼 명시적인 시스템 텍스트에서 습관적 가중치로 지식을 점진적으로 어떻게 이동시키는가? 등). 이를 극복하기 위해 '검색 증강 생성(Retrieval Augmented Generation, RAG)' 기법이 널리 활용됩니다. RAG는 외부 지식 검색으로 LLM이 최신 정보를 기반으로 정확하고 일관된 응답을 하도록 돕습니다. 이는 '스크래치패드(scratchpad)' 제공과 유사하며, 지속적인 미세 조정(continuous fine-tuning) 및 적응형 학습 연구도 진행 중입니다.

Part 2 요약: LLM의 '심리학'은 인간과 다르며, 이러한 특성을 이해하고 보완하는 것이 효과적인 AI 시스템 설계의 핵심입니다.

**Part 3: 부분 자율성(Partial Autonomy)**

우리는 아이언맨 슈트(Iron Man Suit) 비유를 좋아합니다. 이 슈트는 두 가지 유용한 방식으로 우리를 확장합니다.

*   **증강(Augmentation)**: 사용자에게 힘, 도구, 센서(sensor) 및 정보를 제공
*   **자율성(Autonomy)**: 슈트는 종종 자체적인 의지를 가지고 프롬프트(prompt) 없이 행동을 취함

이러한 패턴(pattern)을 따르는 AI 제품을 어떻게 설계할 수 있을까요?

**Part 3a: 자율성 슬라이더(Autonomy Slider)**는 컨텍스트(context)에 대한 자율성(autonomy) 수준을 선택할 수 있게 해주는 중요한 개념입니다. 예:

*   커서(Cursor): Tab -> cmd+K -> Cmd+L -> Cmd+I (에이전트 모드(agent mode))
*   퍼플렉시티(Perplexity): 검색 -> 연구 -> 심층 연구
*   테슬라 오토파일럿(Tesla Autopilot): 레벨 1에서 레벨 4

최신 IDE(통합 개발 환경)는 코드 자동 완성(Code Autocompletion)부터 함수 생성, 디버깅 제안까지 다양한 AI 지원을 제공하여 사용자가 개입 수준을 조절할 수 있게 합니다.

**Part 3b: 인간-AI 생성-검증 루프(Human-AI Generation-Verification Loop)**는 AI가 초안 생성, 인간이 검토/수정, AI에 피드백을 주는 방식입니다. 루프가 빠를수록 좋습니다. '검증 개선'은 쉬운 오류 표시와 수정 제안, '생성 개선'은 피드백 기반 모델 최적화를 포함합니다.

**Part 3c: 데모-제품 간극(Demo-Product Gap)**

우리가 **부분** 자율성(partial autonomy)을 필요로 하는 이유는 작동하는 데모(demo)와 신뢰할 수 있는 제품 사이에 여전히 상당한 간극이 있기 때문입니다. 그는 2014년에 웨이모(Waymo) 프로토타입(prototype)을 아무런 개입 없이 탔던 경험을 회상하며 자율 주행(self-driving)이 "도래했다"고 생각했지만, 여전히 해결해야 할 많은 문제가 남아 있었다고 말합니다.

"데모(demo)는 works.any()이고, 제품은 works.all()이다."

**Part 4: 바이브 코딩(Vibe Coding)**

수많은 스타트업(startup)을 탄생시킨 트윗은 이제 자체 위키백과(Wikipedia) 페이지를 가지고 있습니다! 그러나 여전히 많은 문제가 남아 있습니다. 메뉴젠(MenuGen)을 바이브 코딩(Vibe coding)하는 동안, 그는 로컬 코드(local code)를 실행한 직후 AI 가속이 사라지는 것을 발견했습니다. 이는 AI 생성 코드를 실제 환경에 통합할 때 발생하는 '컨텍스트 불일치(context mismatch)' 문제입니다. 2025년 웹 앱(web app) 구축의 현실은 웹 개발 전문가(webdev expert)들이 일자리를 유지하도록 설계되었고 AI에는 접근할 수 없는, 분리된 서비스들의 혼란입니다. 불쌍한 클럭(Clerk)은 부정적인 언급을 받았고, 버셀(Vercel)의 @leerob은 긍정적인 언급을 받았습니다. 이는 그들의 문서 접근 방식이 각각 인간 대 에이전트(agent)에 맞춰 어떻게 조정될 것인지를 보여줍니다. 복잡한 현대 웹 개발 도구 체인(toolchain)은 AI가 전체 시스템을 이해하고 일관된 코드를 생성하기 어렵게 만듭니다. 미래 AI 코딩 도구는 단순히 코드를 생성하는 것을 넘어, 전체 개발 스택(stack)을 이해하고, 동기화 및 배포까지 지원하는 '전체 스택 인식(full-stack aware)' 에이전트(agent)로 발전해야 합니다.

**Part 5: 에이전트(Agent)를 위해 구축하라**

결론은 도구 제작자(toolmaker)들이 "디지털 정보의 새로운 소비자/조작자 범주"가 있다는 것을 깨달아야 한다는 것입니다.

1.  인간(GUI(Graphical User Interface))
2.  컴퓨터(API(Application Programming Interface))
3.  **새로운 것**: 에이전트(Agent) <- 컴퓨터… 하지만 인간과 유사함

구체적으로: llms.txt가 작동하는 이유는 HTML이 LLM(Large Language Model)에게는 파싱(parsing)하기 쉽지 않기 때문입니다. 웹 페이지의 복잡한 시각적 구조로 인해 LLM은 의미론적 정보 추출에 전처리(pre-processing)가 필요합니다. 따라서 에이전트 친화적인 구조화된 JSON, YAML 등 스키마(schema) 데이터 형식이 중요해질 것입니다. "컨텍스트 빌더(Context builder)"는 LLM이 작업에 필요한 관련 정보를 동적으로 수집, 정리하여 제공함으로써, 에이전트의 '기억상실증(amnesia)'을 완화하고 추론 능력을 향상시킵니다.

**마무리 / 요약**

이것은 에이전트(Agent)의 10년입니다. AGI(Artificial General Intelligence) 2027과 작동하지 않는 화려한 데모(demo)는 줄어들 것입니다. 대신 부분 자율성(partial autonomy), 맞춤형 GUI(custom GUI) 및 자율성 슬라이더(autonomy slider)가 더 많아질 것입니다. 소프트웨어 3.0(Software 3.0)이 소프트웨어 1/2(Software 1/2)을 잠식하고 있다는 것, 그들의 유틸리티(Utility)/팹(Fab)/OS(Operating System) 특성이 그들의 운명을 결정할 것이라는 것, 생성기-검증기 루프(generator-verifier loop)를 개선하고, **에이전트(Agent)를 위해 구축하라 🤖**는 것을 기억하세요. 궁극적으로, AI 에이전트는 인간의 지능을 대체하기보다 보완하고 확장할 것입니다. 우리는 AI가 인간과 협력하여 더 복잡한 문제를 해결하도록, 견고하고 신뢰할 수 있는 에이전트 시스템 구축에 집중해야 합니다. LS 구독자를 위한 전체 슬라이드는 여기 :) 아래 링크