# **Andrej Karpathy의 소프트웨어 3.0(Software 3.0): 인공지능(AI) 시대의 소프트웨어 (전체 대본으로 업데이트됨)**

Author: Latent Space
URL: https://www.latent.space/p/s3

============================================================

**업데이트**: 전체 강연은 지금 YouTube에서 시청하실 수 있습니다! 슬라이드는 여기에서 확인하세요: https://docs.google.com/presentation/d/1sZqMAoIJDxz79cbC5ap5v9jknYH4Aa9cFFaWL8Rids4/edit?usp=sharing 많은 사람들이 오늘 YC AI 스타트업 스쿨(YC AI Startup School)에서 있었던 Andrej의 강연에 흥분했습니다. 안타깝게도 저는 초대받지 못했습니다. 강연은 "앞으로 몇 주 안에" 공개될 예정인데, 그때쯤이면 강연 내용이 구식이 될 수도 있습니다. 아무도 팬캠(fancam)을 녹화한 것 같지 않습니다. 하지만… 아직 끝이 아닙니다. 그냥 직접 해볼 수 있습니다! 피프리서치(PeepResearch)™를 사용하여 강연에 대한 모든 트윗을 취합하고, 훌륭한 필기자(마지막 슬라이드에 출처 표기)들의 힌트를 활용하여 순서를 매겼습니다. **업데이트**: 이제 전체 스크립트(transcript)가 나왔습니다! 여기에서 가장 중요한 핵심 내용들을 살펴보고, 구독자들은 하단에서 전체 슬라이드를 얻을 수 있습니다. 몇 주 안에 전체 강연 영상이 올라오면 이 글을 업데이트하여 주석을 달 예정입니다. **업데이트**: 슬라이드가 이제 전체 스크립트(transcript)와 동기화(synced)되었습니다. 읽어보시려면 아래로 스크롤하여 슬라이드를 확인하세요.

**Part 0: 소프트웨어 3.0(Software 3.0) - 프롬프트(Prompt)가 이제 프로그램(Program)이다**

우리는 "AI 엔지니어(AI Engineer)의 부상(Rise of The AI Engineer)"에서 소프트웨어 3.0(Software 3.0)에 대해 처음 논의했지만, 이는 소프트웨어 2.0(Software 2.0) 에세이와 "가장 뜨거운 새로운 프로그래밍 언어(programming language)는 영어다"라는 말의 명백한 결과입니다. 그는 원래 테슬라(Tesla)에서 소프트웨어 1.0(Software 1.0)을 잠식하고 있는 것을 관찰하며 소프트웨어 2.0(Software 2.0) 에세이를 썼습니다. 그리고 이제 소프트웨어 3.0(Software 3.0)에 맞춰 이를 업데이트하기 위해 돌아왔습니다.

제가 했던 것처럼 소프트웨어 2.0(Software 2.0) 차트를 수정하는 대신, Andrej는 소프트웨어 1.0/2.0/3.0의 혼합/공존을 보여주는 새로운 다이어그램을 선보이며 "소프트웨어 3.0(Software 3.0)이 1.0/2.0을 잠식하고 있다" 그리고 "엄청난 양의 소프트웨어(software)가 다시 작성될 것"이라고 언급했습니다.

Andrej는 여전히 프로그램(program)을 위한 프롬프트(prompt)에 초점을 맞추고 있으며, 우리는 2023년에 약간 의견이 달랐고 지금도 그렇습니다. 소프트웨어 3.0(Software 3.0)의 "1+2=3" 변형은 지난 몇 년간 AI 엔지니어(AI Engineer)가 프롬프트 엔지니어(Prompt Engineer)를 훨씬 능가했으며 앞으로도 그럴 것이라는 전체적인 이유입니다.

**Part 1: LLM(Large Language Model)은 새로운 컴퓨터(Computer)다**

LLM(Large Language Model)은 유틸리티(Utility)와 같다
LLM(Large Language Model)은 팹(Fab)과 같다
LLM(Large Language Model)은 OS(Operating System)와 같다
LLM(Large Language Model)은 시분할 메인프레임(Timeshare Mainframe)과 같다… 비록 그가 "파워 투 더 피플(Power to the People)"에서 주장하듯이, LLM(Large Language Model)은 또한 값비싼 최첨단 기술(frontier tech)의 일반적인 흐름과는 다른 특이한 역전 현상을 보이기도 합니다.

우리가 클라우드(cloud)를 떠나 개인/프라이빗 AI(Personal/Private AI)로 향함에 따라, 엑소랩스(Exolabs) + 애플 MLX(Apple MLX) 작업에서 개인 컴퓨팅 v2(Personal Computing v2)의 몇 가지 징후가 나타나고 있습니다.

Part 1 요약:

**Part 2: LLM 심리학(LLM Psychology)**

LLM(Large Language Model)은 "사람의 영혼"과 같습니다. 즉, 일종의 창발적 "심리학"을 가진 사람들의 확률적 시뮬레이션(stochastic simulation)입니다.

Andrej는 현재 LLM(Large Language Model)이 사람을 시뮬레이션(simulate)하는 방식에 대한 두 가지 문제를 강조합니다.

**들쭉날쭉한 지능(Jagged Intelligence)** (https://x.com/karpathy/status/1816531576228053133): 제가 생각해낸 이 단어는 최첨단 LLM(state-of-the-art LLM)이 매우 인상적인 작업(예: 복잡한 수학 문제 해결)을 수행할 수 있으면서도 동시에 매우 어리석은 문제로 고군분투하는 (이상하고 직관적이지 않은) 사실을 설명합니다. 예를 들어, 이틀 전의 예시입니다. 9.11과 9.9 중 어떤 숫자가 더 큰가요? 틀렸습니다. … 어떤 것들은 (인간의 기준으로) 매우 잘 작동하는 반면, 어떤 것들은 (다시 인간의 기준으로) 치명적으로 실패하며, 어느 것이 어느 것인지 항상 명확하지는 않지만 시간이 지남에 따라 약간의 직관을 개발할 수 있습니다. 많은 지식과 문제 해결 능력이 모두 고도로 상관관계가 있고 태어날 때부터 성인기까지 함께 선형적으로(linearly) 향상되는 인간과는 다릅니다. 개인적으로 저는 이것들이 근본적인 문제라고 생각하지 않습니다. 이것들은 스케일링(scaling)뿐만 아니라 스택(stack) 전반에 걸쳐 더 많은 작업을 요구합니다. 제가 생각하는 가장 큰 문제는 현재 "인지적 자기 지식(cognitive self-knowledge)"이 부족하다는 것입니다. 이는 순진하게 "인간 라벨러(human labeler)를 모방하고 크게 만드는" 해결책 대신 모델 후처리 학습(model post-training)에서 더 정교한 접근 방식을 필요로 합니다. 우리가 지금까지 주로 사용해 온 방식입니다. 제가 말하는 것의 예시를 보려면, 라마 3.1(Llama 3.1) 논문의 환각(hallucination) 완화 섹션을 참조하세요: https://x.com/karpathy/status/1816171241809797335 현재로서는 특히 프로덕션 환경(production setting)에서 이것을 인지해야 합니다. LLM(Large Language Model)을 잘하는 작업에 사용하되, 들쭉날쭉한 부분에 주의하고 휴먼 인 더 루프(human in the loop)를 유지하세요.

**전향성 기억상실증(Anterograde Amnesia)** (https://x.com/karpathy/status/1930003172246073412): 저는 LLM(Large Language Model)이 전향성 기억상실증(Anterograde Amnesia)을 가진 동료와 같다고 설명하고 싶습니다. 즉, 학습이 끝나면 장기적인 지식이나 전문성을 통합하거나 구축하지 못하고, 그들이 가진 것은 단기 기억(short-term memory)(컨텍스트 윈도우(context window))뿐입니다. 이러한 상태에서는 관계를 구축하거나(참조: 첫 키스만 50번째) 작업을 수행하기 어렵습니다(참조: 메멘토). 제가 본 이러한 결함의 첫 번째 완화는 ChatGPT의 메모리(Memory) 기능인데, 이는 앞으로 가능할 것의 원시적이고 조악한 구현처럼 느껴지며, 이것이 제가 여기서 새로운 학습 패러다임(learning paradigm)으로 제안하게 된 계기입니다: https://x.com/karpathy/status/1921368644069765486 우리는 LLM(Large Language Model) 학습을 위한 (적어도 하나의) 주요 패러다임(paradigm)을 놓치고 있습니다. 무엇이라고 불러야 할지 확실하지 않지만, 아마 이름이 있을 수도 있습니다. 시스템 프롬프트 학습(system prompt learning)일까요? 사전 학습(Pretraining)은 지식을 위한 것입니다. 미세 조정(Finetuning)(지도 학습(SL)/강화 학습(RL))은 습관적인 행동을 위한 것입니다. 이 둘 모두 파라미터(parameter)의 변화를 포함하지만, 많은 인간 학습은 시스템 프롬프트(system prompt)의 변화처럼 느껴집니다. 문제를 만나고, 무언가를 알아낸 다음, 다음번을 위해 상당히 명시적인 용어로 무언가를 "기억"합니다. 예를 들어, "이런 종류의 문제를 만났을 때는 이런 종류의 접근 방식/해결책을 시도해야 할 것 같다"와 같습니다. 이는 사용자별 무작위 사실을 저장하는 것이 아니라 일반/전역 문제 해결 지식과 전략을 저장하는 "메모리(Memory)" 기능과 같은, 자신을 위한 메모를 하는 것과 더 비슷하게 느껴집니다. LLM(Large Language Model)은 말 그대로 메멘토(Memento)의 남자와 같지만, 우리는 아직 그들에게 스크래치패드(scratchpad)를 주지 않았습니다. 이 패러다임(paradigm)은 지식 기반 "검토" 단계가 보상 스케일러(reward scaler)보다 훨씬 더 고차원 피드백 채널(feedback channel)이기 때문에 훨씬 더 강력하고 데이터 효율적이라는 점에 주목하세요. … 제 생각에는 이것이 강화 학습(Reinforcement Learning)을 통해 가중치(weight)에 내재화되어야 하는 종류의 문제 해결 지식이 아니며, 적어도 즉시/독점적으로는 아닙니다. 그리고 인간 엔지니어(engineer)가 시스템 프롬프트(system prompt)를 수동으로 작성하는 것에서 나와서도 안 됩니다. 이는 시스템 프롬프트 학습(System Prompt learning)에서 나와야 하며, 이는 학습 알고리즘(learning algorithm)(수정 vs 경사 하강법(gradient descent))을 제외하고는 설정에서 강화 학습(Reinforcement Learning)과 유사합니다. LLM(Large Language Model) 시스템 프롬프트(system prompt)의 상당 부분은 시스템 프롬프트 학습(system prompt learning)을 통해 작성될 수 있으며, 이는 LLM(Large Language Model)이 문제 해결 방법에 대한 책을 스스로 쓰는 것과 비슷하게 보일 것입니다. 이것이 작동한다면 새롭고 강력한 학습 패러다임(learning paradigm)이 될 것입니다. 아직 해결해야 할 많은 세부 사항이 남아 있습니다(수정은 어떻게 작동하는가? 수정 시스템을 학습할 수/해야 하는가? 인간이 하는 것처럼 명시적인 시스템 텍스트에서 습관적 가중치로 지식을 점진적으로 어떻게 이동시키는가? 등).

Part 2 요약:

**Part 3: 부분 자율성(Partial Autonomy)**

우리는 아이언맨 슈트(Iron Man Suit) 비유를 좋아합니다. 이 슈트는 두 가지 유용한 방식으로 우리를 확장합니다.

*   **증강(Augmentation)**: 사용자에게 힘, 도구, 센서(sensor) 및 정보를 제공
*   **자율성(Autonomy)**: 슈트는 종종 자체적인 의지를 가지고 프롬프트(prompt) 없이 행동을 취함

이러한 패턴(pattern)을 따르는 AI 제품을 어떻게 설계할 수 있을까요?

**Part 3a: 자율성 슬라이더(Autonomy Slider)**

자율성 슬라이더(Autonomy Slider)는 컨텍스트(context)에 대한 자율성(autonomy) 수준을 선택할 수 있게 해주는 중요한 개념입니다. 예:

*   커서(Cursor): Tab -> cmd+K -> Cmd+L -> Cmd+I (에이전트 모드(agent mode))
*   퍼플렉시티(Perplexity): 검색 -> 연구 -> 심층 연구
*   테슬라 오토파일럿(Tesla Autopilot): 레벨 1에서 레벨 4

**Part 3b: 인간-AI 생성-검증 루프(Human-AI Generation-Verification Loop)**

생성 <-> 검증 주기에서 우리는 부분 자율성(partial autonomy)의 완전한 워크플로우(workflow)가 필요합니다. 루프(loop)가 빠를수록 좋습니다.

*   **검증 개선**: 쉽고 빠르게 승리하게 만드세요.
*   **생성 개선**: AI의 고삐를 바싹 죄세요.

**Part 3c: 데모-제품 간극(Demo-Product Gap)**

우리가 **부분** 자율성(partial autonomy)을 필요로 하는 이유는 작동하는 데모(demo)와 신뢰할 수 있는 제품 사이에 여전히 상당한 간극이 있기 때문입니다. 그는 2014년에 웨이모(Waymo) 프로토타입(prototype)을 아무런 개입 없이 탔던 경험을 회상하며 자율 주행(self-driving)이 "도래했다"고 생각했지만, 여전히 해결해야 할 많은 문제가 남아 있었다고 말합니다.

"데모(demo)는 works.any()이고, 제품은 works.all()이다."

**Part 4: 바이브 코딩(Vibe Coding)**

수많은 스타트업(startup)을 탄생시킨 트윗은 이제 자체 위키백과(Wikipedia) 페이지를 가지고 있습니다!

그러나 여전히 많은 문제가 남아 있습니다. 메뉴젠(MenuGen)을 바이브 코딩(Vibe coding)하는 동안, 그는 로컬 코드(local code)를 실행한 직후 AI 가속이 사라지는 것을 발견했습니다.

2025년 웹 앱(web app) 구축의 현실은 웹 개발 전문가(webdev expert)들이 일자리를 유지하도록 설계되었고 AI에는 접근할 수 없는, 분리된 서비스들의 혼란입니다. 불쌍한 클럭(Clerk)은 부정적인 언급을 받았고, 버셀(Vercel)의 @leerob은 긍정적인 언급을 받았습니다. 이는 그들의 문서 접근 방식이 각각 인간 대 에이전트(agent)에 맞춰 어떻게 조정될 것인지를 보여줍니다.

**Part 5: 에이전트(Agent)를 위해 구축하라**

결론은 도구 제작자(toolmaker)들이 "디지털 정보의 새로운 소비자/조작자 범주"가 있다는 것을 깨달아야 한다는 것입니다.

1.  인간(GUI(Graphical User Interface))
2.  컴퓨터(API(Application Programming Interface))
3.  **새로운 것**: 에이전트(Agent) <- 컴퓨터… 하지만 인간과 유사함

구체적으로: llms.txt가 작동하는 이유는 HTML이 LLM(Large Language Model)에게는 파싱(parsing)하기 쉽지 않기 때문입니다. 그는 또한 우리가 라이트닝 팟(lightning pod)에서 다루었던 기트인제스트(Gitingest)와 코그니션(Cognition)의 딥위키(DeepWiki)와 같은 "컨텍스트 빌더(Context builder)"를 언급했습니다.

**마무리 / 요약**

이것은 에이전트(Agent)의 10년입니다. AGI(Artificial General Intelligence) 2027과 작동하지 않는 화려한 데모(demo)는 줄어들 것입니다. 대신 부분 자율성(partial autonomy), 맞춤형 GUI(custom GUI) 및 자율성 슬라이더(autonomy slider)가 더 많아질 것입니다. 소프트웨어 3.0(Software 3.0)이 소프트웨어 1/2(Software 1/2)을 잠식하고 있다는 것, 그들의 유틸리티(Utility)/팹(Fab)/OS(Operating System) 특성이 그들의 운명을 결정할 것이라는 것, 생성기-검증기 루프(generator-verifier loop)를 개선하고, **에이전트(Agent)를 위해 구축하라 🤖**는 것을 기억하세요.

LS 구독자를 위한 전체 슬라이드는 여기 :) 아래 링크