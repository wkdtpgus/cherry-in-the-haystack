**업데이트**: 전체 강연 영상은 현재 유튜브(YouTube) 채널에서 시청 가능합니다! 관련 슬라이드는 다음 링크에서 확인하실 수 있습니다: https://docs.google.com/presentation/d/1sZqMAoIJDxz79cbC5ap5v9jknYH4Aa9cFFaWL8Rids4/edit?usp=sharing 안드레이 카파시(Andrej Karpathy)의 YC AI 스타트업 스쿨(YC AI Startup School) 발표는 많은 이들의 큰 관심을 끌었습니다. 필자는 해당 행사에 직접 참석하지 못해 아쉬웠습니다. 강연 내용이 공식적으로 공개되기까지 "몇 주"가 소요될 예정이었기에, 그 시점에는 정보가 다소 구식이 될 수도 있었습니다. 현장 라이브 영상이 따로 촬영된 것 같지도 않았습니다. 하지만… 아직 희망은 있었습니다. 직접 내용을 구성해볼 수 있었으니까요! 피프리서치(PeepResearch)™ 기술을 활용해 발표 관련 트윗들을 수집하고, 우수한 필기 기록(출처는 최종 슬라이드에 명시)들을 참고하여 내용을 정리했습니다. **업데이트**: 이제 전체 강연 스크립트(transcript)가 공개되었습니다! 본 글에서는 핵심 요약들을 다루며, 구독자분들은 글 하단에서 전체 슬라이드를 열람하실 수 있습니다. 몇 주 후 전체 강연 영상이 게시되면, 이 글에 추가적인 주석을 달아 내용을 보강할 예정입니다. **업데이트**: 슬라이드 자료가 이제 전체 스크립트(transcript)와 완벽하게 연동되었습니다. 상세 내용을 확인하시려면 아래로 스크롤하여 슬라이드를 살펴보세요.

최근 인공지능(AI) 분야의 발전 속도는 경이로울 정도이며, 안드레이 카파시와 같은 선구자들의 통찰은 미래 기술의 방향을 가늠하는 중요한 지표가 됩니다. 그의 강연은 단순한 정보 전달을 넘어, AI 시대의 새로운 사고방식과 개발 패러다임을 제시하며 개발자 커뮤니티에 깊은 영감을 주었습니다. 본 글은 그의 발표 내용을 심층 분석하고, 그 핵심 메시지를 재구성하여 AI 엔지니어링의 미래를 조망하고자 합니다.

**Part 0: 소프트웨어 3.0(Software 3.0) - 이제 지시어가 곧 실행 코드이다**

저희는 'AI 엔지니어(AI Engineer)의 부상' 글에서 소프트웨어 3.0(Software 3.0) 개념을 처음 다루었으나, 이는 소프트웨어 2.0(Software 2.0) 논문과 '가장 주목받는 새로운 코딩 언어는 영어이다'라는 견해의 자연스러운 연장선상에 있습니다. 그는 본래 테슬라(Tesla)에서 소프트웨어 1.0(Software 1.0)의 영역을 침범하는 소프트웨어 2.0(Software 2.0)의 모습을 관찰하며 소프트웨어 2.0(Software 2.0)에 대한 글을 작성했습니다. 그리고 이제 그는 소프트웨어 3.0(Software 3.0)의 등장에 맞춰 기존 관점을 갱신하기 위해 다시 돌아왔습니다.

제가 소프트웨어 2.0(Software 2.0) 도표를 수정했던 것과는 다르게, 안드레이는 소프트웨어 1.0/2.0/3.0의 혼합 및 공존을 보여주는 새로운 다이어그램을 제시하며 "소프트웨어 3.0(Software 3.0)이 1.0/2.0의 영역을 잠식하고 있다" 그리고 "막대한 양의 소프트웨어(software)가 새롭게 재편될 것"이라고 언급했습니다.

안드레이는 여전히 프로그램(program) 대신 프롬프트(prompt)를 사용하는 것에 집중하고 있으며, 저희는 2023년에 이 부분에서 의견이 달랐고 지금도 그렇습니다. 소프트웨어 3.0(Software 3.0)이 '1+2=3' 형태를 띠는 것은 지난 몇 년간 AI 엔지니어(AI Engineer)가 프롬프트 엔지니어(Prompt Engineer)보다 훨씬 더 중요한 역할을 했고 앞으로도 그럴 것이라는 주된 이유입니다.

소프트웨어 개발의 역사는 크게 세 가지 시대로 나눌 수 있습니다. 소프트웨어 1.0(Software 1.0)은 인간이 직접 모든 논리를 코드로 작성하는 전통적인 방식입니다. 반면 소프트웨어 2.0(Software 2.0)은 방대한 데이터를 통해 신경망 모델이 스스로 패턴을 학습하고 예측하는, 데이터 중심의 패러다임입니다. 그리고 이제 소프트웨어 3.0(Software 3.0)은 대규모 언어 모델(LLM)을 활용하여 자연어 형태의 지시어(prompt)만으로 원하는 기능을 구현하는 시대를 의미합니다. 이는 단순한 도구의 변화를 넘어, 소프트웨어 설계와 구현 방식 전반에 걸쳐 근본적인 전환을 예고합니다. 기존의 `if-else` 조건문이나 복잡한 알고리즘이 자연어 명령어로 대체될 수 있다는 상상은 개발 방식의 혁명을 의미하며, '의도 기반 개발(intent-driven development)'이라는 새로운 개념을 제시합니다. 즉, 개발자는 더 이상 세부 구현 로직에 얽매이지 않고, 원하는 결과에 대한 의도를 명확히 전달하는 데 집중하게 될 것입니다.

**Part 1: LLM(Large Language Model)은 새로운 연산 장치다**

대규모 언어 모델(LLM)은 마치 공공 서비스(Utility)와 같습니다.
대규모 언어 모델(LLM)은 반도체 제조 공장(Fab)과 같습니다.
대규모 언어 모델(LLM)은 운영 체제(OS)와 같습니다.
대규모 언어 모델(LLM)은 시분할 방식의 대형 컴퓨터(Timeshare Mainframe)와 유사합니다… 비록 그가 "파워 투 더 피플(Power to the People)"에서 주장하듯이, 대규모 언어 모델(LLM)은 또한 값비싼 최첨단 기술(frontier tech)의 일반적인 흐름과는 다른 특이한 역전 현상을 보이기도 합니다.

우리가 클라우드(cloud) 기반 시스템에서 벗어나 개인/독립형 AI(Personal/Private AI)로 나아가면서, 엑소랩스(Exolabs)와 애플 MLX(Apple MLX)의 연구에서 개인 컴퓨팅 v2(Personal Computing v2)의 몇 가지 조짐이 나타나고 있습니다.

대규모 언어 모델(LLM)이 새로운 컴퓨팅 패러다임의 핵심으로 부상하면서, 다양한 비유를 통해 그 본질을 이해하려는 시도가 이어지고 있습니다.

*   **공공 서비스(Utility)**: LLM은 수도나 전기처럼 필요할 때 언제든 접근하여 사용할 수 있는 온디맨드(on-demand) 컴퓨팅 자원과 같습니다. 표준화된 인터페이스를 통해 복잡한 내부 동작을 알 필요 없이 원하는 결과를 얻을 수 있습니다.
*   **반도체 제조 공장(Fab)**: LLM은 고수준의 설계도(프롬프트)만으로 복잡한 결과물(코드, 이미지, 텍스트)을 생성해내는 능력을 지녔습니다. 마치 반도체 공장이 설계도를 받아 실제 칩을 생산하듯이, LLM은 추상적인 아이디어를 구체적인 형태로 구현합니다.
*   **운영 체제(OS)**: LLM은 여러 기능을 통합하고 자원을 관리하며, 다양한 애플리케이션의 기반이 되는 운영 체제와 유사합니다. 다른 AI 모델이나 도구들을 조율하고 상호작용하는 중심 허브 역할을 수행할 수 있습니다.
*   **시분할 메인프레임(Timeshare Mainframe)**: 초기 컴퓨팅 시대의 메인프레임처럼, LLM은 강력한 중앙 집중식 자원으로 여러 사용자가 공유하여 고성능 작업을 수행할 수 있습니다.

이러한 중앙 집중식 모델과 더불어, 개인 기기에서 직접 구동되는 로컬(local) AI 모델의 발전은 또 다른 중요한 흐름입니다. 이는 클라우드 의존도를 줄이고, 프라이버시를 강화하며, 지연 시간을 단축하는 등 분산형 컴퓨팅의 이점을 제공합니다. `llama.cpp`나 애플 MLX(Apple MLX)와 같은 프로젝트들은 이러한 '개인 컴퓨팅 v2' 시대를 앞당기는 핵심 동력이 되고 있으며, 사용자 기기에서 직접 실행되는 AI의 가능성을 열고 있습니다.

Part 1 요약: LLM은 새로운 컴퓨팅 기반으로, 유틸리티, 팹, OS, 메인프레임과 유사한 특성을 보이며, 동시에 개인 기기에서의 로컬 AI 발전이라는 역설적 흐름을 동반하고 있습니다.

**Part 2: LLM의 인지 특성(LLM Psychology)**

대규모 언어 모델(LLM)은 마치 '인간의 정신'과 흡사합니다. 다시 말해, 독특한 발현적 '심리'를 지닌 인간 존재의 확률적 모의실험이라고 볼 수 있습니다.

안드레이는 현재 대규모 언어 모델(LLM)이 인간을 모방하는 방식에서 나타나는 두 가지 주요한 문제점을 강조합니다.

**들쭉날쭉한 지능(Jagged Intelligence)** (https://x.com/karpathy/status/1816531576228053133): 제가 고안한 이 용어는 최신 대규모 언어 모델(state-of-the-art LLM)이 매우 복잡한 과제(예: 난해한 수학 문제 해결)를 훌륭하게 처리하면서도, 동시에 아주 단순한 문제에서 헤매는 (기이하고 비직관적인) 현상을 설명합니다. 예를 들어, 며칠 전의 사례입니다. 9.11과 9.9 중 어느 숫자가 더 큰가요? 틀렸습니다. … 어떤 능력은 (인간의 관점에서) 매우 뛰어나지만, 어떤 능력은 (다시 인간의 관점에서) 치명적으로 실패하며, 어느 부분이 그렇고 아닌지는 항상 명확하지 않습니다. 다만 시간이 지나면서 약간의 감을 익힐 수 있습니다. 이는 지식과 문제 해결 능력이 고도로 연관되어 태어날 때부터 성인기까지 선형적으로(linearly) 향상되는 인간과는 다릅니다. 개인적으로 저는 이것들이 근본적인 문제라고 생각하지 않습니다. 이러한 현상들은 스케일링(scaling)뿐만 아니라 스택(stack) 전반에 걸쳐 더 많은 노력을 필요로 합니다. 제가 생각하는 가장 큰 문제는 현재 '인지적 자기 지식(cognitive self-knowledge)'이 부족하다는 점입니다. 이는 단순히 '인간 라벨러(human labeler)를 모방하고 확장하는' 해결책 대신, 모델 훈련 후 처리(model post-training) 단계에서 더욱 정교한 접근법을 요구합니다. 현재까지 우리가 주로 사용해 온 방식입니다. 제가 말하는 것의 예시를 보려면, 라마 3.1(Llama 3.1) 논문의 환각(hallucination) 완화 섹션을 참조하세요: https://x.com/karpathy/status/1816171241809797335 현재로서는 특히 실제 운영 환경(production setting)에서 이 점을 인지해야 합니다. 대규모 언어 모델(LLM)을 잘하는 작업에 활용하되, 불균일한 부분에 주의하고 인간 개입(human in the loop)을 유지하세요.

**전향성 기억상실증(Anterograde Amnesia)** (https://x.com/karpathy/status/1930003172246073412): 저는 대규모 언어 모델(LLM)이 전향성 기억상실증(Anterograde Amnesia)을 겪는 동료와 같다고 설명하고 싶습니다. 즉, 훈련이 완료되면 장기적인 지식이나 전문성을 통합하거나 축적하지 못하고, 그들이 보유한 것은 단기 기억(short-term memory)인 컨텍스트 윈도우(context window)뿐입니다. 이러한 상태에서는 관계를 형성하거나(참고: 첫 키스만 50번째) 작업을 수행하기 어렵습니다(참고: 메멘토). 제가 목격한 이러한 결함에 대한 첫 번째 해결책은 챗GPT(ChatGPT)의 메모리(Memory) 기능인데, 이는 앞으로 가능할 것들의 원시적이고 불완전한 구현처럼 느껴집니다. 이것이 제가 여기서 새로운 학습 패러다임(learning paradigm)으로 제안하게 된 계기입니다: https://x.com/karpathy/status/1921368644069765486 우리는 대규모 언어 모델(LLM) 학습을 위한 (적어도 하나의) 핵심 패러다임(paradigm)을 놓치고 있습니다. 무엇이라고 불러야 할지 확실하지 않지만, 아마 명칭이 있을 수도 있습니다. 시스템 프롬프트 학습(system prompt learning)일까요? 사전 학습(Pretraining)은 지식 습득을 위한 것입니다. 미세 조정(Finetuning)(지도 학습(SL)/강화 학습(RL))은 습관적인 행동 패턴을 위한 것입니다. 이 두 가지 모두 매개변수(parameter)의 변화를 수반하지만, 많은 인간 학습은 시스템 프롬프트(system prompt)의 변화처럼 느껴집니다. 문제를 마주하고, 무언가를 파악한 다음, 다음번을 위해 상당히 명시적인 용어로 무언가를 '기억'합니다. 예를 들어, '이런 종류의 문제를 접했을 때는 이런 접근 방식/해결책을 시도해야 할 것 같다'와 같습니다. 이는 사용자별 무작위 사실을 저장하는 것이 아니라 일반/전역 문제 해결 지식과 전략을 저장하는 '메모리(Memory)' 기능과 같이, 스스로에게 메모를 하는 것과 더 비슷하게 느껴집니다. 대규모 언어 모델(LLM)은 말 그대로 영화 메멘토(Memento)의 주인공과 같지만, 우리는 아직 그들에게 스크래치패드(scratchpad)를 제공하지 않았습니다. 이 패러다임(paradigm)은 지식 기반 '검토' 단계가 보상 스케일러(reward scaler)보다 훨씬 더 고차원적인 피드백 채널(feedback channel)이기 때문에 훨씬 더 강력하고 데이터 효율적이라는 점에 주목하세요. … 제 생각에는 이것이 강화 학습(Reinforcement Learning)을 통해 가중치(weight)에 내재화되어야 하는 종류의 문제 해결 지식이 아니며, 적어도 즉시/독점적으로는 아닙니다. 그리고 인간 엔지니어(engineer)가 시스템 프롬프트(system prompt)를 수동으로 작성하는 것에서 나와서도 안 됩니다. 이는 시스템 프롬프트 학습(System Prompt learning)에서 나와야 하며, 이는 학습 알고리즘(learning algorithm)(수정 vs 경사 하강법(gradient descent))을 제외하고는 설정에서 강화 학습(Reinforcement Learning)과 유사합니다. 대규모 언어 모델(LLM) 시스템 프롬프트(system prompt)의 상당 부분은 시스템 프롬프트 학습(system prompt learning)을 통해 작성될 수 있으며, 이는 대규모 언어 모델(LLM)이 문제 해결 방법에 대한 책을 스스로 쓰는 것과 비슷하게 보일 것입니다. 이것이 작동한다면 새롭고 강력한 학습 패러다임(learning paradigm)이 될 것입니다. 아직 해결해야 할 많은 세부 사항이 남아 있습니다(수정은 어떻게 작동하는가? 수정 시스템을 학습할 수/해야 하는가? 인간이 하는 것처럼 명시적인 시스템 텍스트에서 습관적 가중치로 지식을 점진적으로 어떻게 이동시키는가? 등).

대규모 언어 모델(LLM)은 놀라운 능력을 보여주지만, 인간의 인지 과정과는 다른 독특한 특성을 지닙니다. 이러한 특성을 이해하는 것은 LLM을 효과적으로 활용하고 발전시키는 데 필수적입니다.

*   **들쭉날쭉한 지능(Jagged Intelligence)**: 이는 최신 LLM이 복잡한 추론이나 창의적인 글쓰기와 같은 고난도 과제를 능숙하게 처리하면서도, 동시에 단순한 산수 문제나 상식적인 질문에서 어이없는 오류를 범하는 현상을 말합니다. 예를 들어, 미적분 문제를 푸는 LLM이 "사과 한 개와 바나나 한 개를 합치면 무엇이 되나요?"라는 질문에 엉뚱한 답을 내놓는 경우가 있습니다. 이러한 불균일한 성능은 LLM의 내부 작동 방식과 학습 데이터의 특성에서 기인합니다. 인간의 지능은 다양한 영역에서 상호 연결되어 전반적으로 향상되는 경향이 있지만, LLM은 특정 패턴 학습에 특화되어 있어 예상치 못한 약점을 보일 수 있습니다. 이 문제를 해결하기 위해서는 단순히 모델 크기를 늘리는 것을 넘어, LLM의 '인지적 아키텍처(cognitive architecture)'를 개선하고, 자기 성찰(self-reflection) 및 오류 수정 메커니즘을 강화하는 방향으로 연구가 진행되어야 합니다.
*   **전향성 기억상실증(Anterograde Amnesia)**: LLM은 훈련이 완료되면 새로운 정보를 장기적으로 기억하고 통합하는 데 어려움을 겪습니다. 현재 모델들은 주로 '컨텍스트 윈도우(context window)'라는 단기 기억 공간에 의존하며, 이 공간을 벗어나는 정보는 사실상 잊어버립니다. 이는 마치 영화 '메멘토'의 주인공처럼, 매번 새로운 상호작용에서 초기화되는 듯한 인상을 줍니다. 챗GPT(ChatGPT)의 '메모리(Memory)' 기능은 이러한 한계를 극복하려는 첫 시도입니다. 하지만 이는 단순히 특정 사실을 저장하는 것을 넘어, LLM이 새로운 문제 해결 전략이나 일반적인 학습 원칙을 스스로 터득하고 내면화하는 '시스템 프롬프트 학습(system prompt learning)'으로 발전해야 합니다. 이는 사전 학습(pre-training)이 지식 습득을, 미세 조정(fine-tuning)이 특정 행동 패턴을 학습하는 것과 달리, LLM이 마치 스스로 학습 노트를 작성하듯 메타 인지(meta-cognition) 능력을 개발하는 방향을 제시합니다. 이러한 새로운 패러다임은 기존의 강화 학습(Reinforcement Learning) 방식보다 훨씬 더 효율적이고 강력한 학습 메커니즘을 제공할 잠재력을 가지고 있습니다.

Part 2 요약: LLM은 '들쭉날쭉한 지능'과 '전향성 기억상실증'이라는 고유한 인지적 한계를 가지고 있으며, 이를 극복하기 위해 '인지적 자기 지식'과 '시스템 프롬프트 학습'과 같은 새로운 접근 방식이 요구됩니다.

**Part 3: 부분적 자율성(Partial Autonomy)**

우리는 아이언맨 슈트(Iron Man Suit) 비유를 선호합니다. 이 슈트는 두 가지 유용한 방식으로 우리의 능력을 확장합니다.

*   **증강(Augmentation)**: 사용자에게 힘, 도구, 센서(sensor) 및 정보를 제공
*   **자율성(Autonomy)**: 슈트는 종종 자체적인 의지를 가지고 프롬프트(prompt) 없이 행동을 취함

이러한 패턴(pattern)을 따르는 AI 제품을 어떻게 설계할 수 있을까요?

아이언맨 슈트 비유는 인간과 AI의 협업 모델을 이해하는 데 매우 적합합니다. AI는 인간의 능력을 보완하고 확장하는 '증강' 도구로서, 복잡한 데이터 분석, 정보 검색, 창의적인 아이디어 생성 등을 지원합니다. 동시에 AI는 특정 상황에서 인간의 지시 없이 스스로 판단하고 행동하는 '자율성'을 발휘합니다. 이러한 두 가지 측면을 균형 있게 통합하는 것이 차세대 AI 제품 설계의 핵심 과제입니다. 예를 들어, 의료 진단 AI는 의사에게 정확한 정보를 제공하여 진단을 '증강'하면서도, 특정 응급 상황에서는 자율적으로 조치를 제안할 수 있습니다.

**Part 3a: 자율성 조절기(Autonomy Slider)**

자율성 조절기(Autonomy Slider)는 상황에 따라 자율성(autonomy) 수준을 선택할 수 있게 해주는 중요한 개념입니다. 예:

*   커서(Cursor): Tab -> cmd+K -> Cmd+L -> Cmd+I (에이전트 모드(agent mode))
*   퍼플렉시티(Perplexity): 검색 -> 연구 -> 심층 연구
*   테슬라 오토파일럿(Tesla Autopilot): 레벨 1에서 레벨 4

자율성 조절기(Autonomy Slider)는 사용자가 AI의 개입 수준을 직접 제어할 수 있도록 하는 인터페이스를 의미합니다. 이는 사용자 신뢰도를 높이고, AI의 오작동 위험을 관리하며, 다양한 사용 시나리오에 유연하게 대응하기 위해 필수적입니다. 자율주행 차량의 레벨 1(운전자 보조)부터 레벨 4(고도 자율주행)까지의 단계적 자율성처럼, 콘텐츠 생성 도구에서는 단순한 문장 완성에서부터 전체 초안 작성까지, 금융 거래 시스템에서는 투자 정보 제공에서부터 자동 거래 실행까지 그 수준을 조절할 수 있습니다. 이 조절기는 사용자 경험(UX) 설계의 핵심 요소가 될 것이며, AI 시스템이 사용자의 의도와 상황에 맞춰 최적의 협업 모드를 제공하도록 돕습니다. '적응형 자율성(adaptive autonomy)' 개념을 도입하여, AI가 사용자의 숙련도나 작업의 중요도에 따라 자율성 수준을 스스로 제안하거나 조절하는 방식도 고려해볼 수 있습니다.

**Part 3b: 인간-AI 생성-검증 순환(Human-AI Generation-Verification Loop)**

생성 <-> 검증 주기에서 우리는 부분적 자율성(partial autonomy)의 완전한 워크플로우(workflow)가 필요합니다. 순환(loop)이 빠를수록 좋습니다.

*   **검증 개선**: 쉽고 빠르게 성공을 경험하게 만드세요.
*   **생성 개선**: AI의 고삐를 단단히 잡으세요.

인간-AI 생성-검증 순환(Human-AI Generation-Verification Loop)은 AI가 생성한 결과물을 인간이 검토하고, 그 피드백을 통해 AI의 생성 능력을 지속적으로 향상시키는 과정을 말합니다. 이 순환의 속도와 효율성이 AI 시스템의 신뢰성과 유용성을 결정합니다. 검증 과정을 개선하기 위해서는 AI가 생성한 결과물에 대한 명확한 신뢰도 점수(confidence score)를 제공하고, 오류 발생 시 쉽게 수정할 수 있는 직관적인 인터페이스를 설계해야 합니다. 또한, AI의 생성 능력을 향상시키기 위해서는 적절한 '가드레일(guardrails)'을 설정하여 원치 않는 결과물을 방지하고, 소량의 데이터(few-shot prompting)만으로도 AI가 원하는 방향으로 학습할 수 있도록 유도해야 합니다. 궁극적으로 이 루프는 AI가 단순히 결과물을 내놓는 것을 넘어, 인간과의 상호작용을 통해 지속적으로 학습하고 발전하는 '지능형 조수(intelligent assistant)'로 진화하는 기반이 됩니다.

**Part 3c: 시연-제품 간극(Demo-Product Gap)**

우리가 **부분적** 자율성(partial autonomy)을 필요로 하는 이유는 작동하는 시연(demo)과 신뢰할 수 있는 제품 사이에 여전히 상당한 간극이 존재하기 때문입니다. 그는 2014년에 웨이모(Waymo) 프로토타입(prototype)을 아무런 개입 없이 탔던 경험을 회상하며 자율 주행(self-driving)이 "도래했다"고 생각했지만, 여전히 해결해야 할 많은 문제가 남아 있었다고 말합니다.

"시연(demo)은 works.any()이고, 제품은 works.all()이다."

시연-제품 간극(Demo-Product Gap)은 AI 기술이 실제로 활용되는 과정에서 흔히 마주하는 현실적인 문제입니다. 화려한 시연은 특정 조건에서 AI의 놀라운 능력을 보여주지만, 실제 제품은 모든 예외 상황과 복잡한 변수를 처리하며 100% 신뢰할 수 있어야 합니다. 예를 들어, AI 기반의 법률 문서 검토 시스템이 특정 유형의 계약서에서는 완벽한 성능을 보였지만, 복잡한 다국어 문서나 예상치 못한 법률 조항이 포함된 경우 치명적인 오류를 발생시킬 수 있습니다. 이러한 간극은 기술적인 문제뿐만 아니라 윤리적, 법적 문제로도 이어질 수 있습니다. 따라서 AI 제품을 개발할 때는 '작동하는 것(works.any())'을 넘어 '모든 상황에서 작동하는 것(works.all())'을 목표로 해야 하며, 이를 위해 강력한 오류 처리, 인간 개입을 위한 명확한 폴백(fallback) 메커니즘, 그리고 지속적인 검증 및 개선 프로세스가 필수적입니다.

**Part 4: 바이브 코딩(Vibe Coding)**

수많은 스타트업(startup)을 탄생시킨 그 트윗은 이제 자체 위키백과(Wikipedia) 페이지를 보유하고 있습니다!

그러나 여전히 많은 문제가 남아 있습니다. 메뉴젠(MenuGen)을 바이브 코딩(Vibe coding)하는 동안, 그는 로컬 코드(local code)를 실행한 직후 AI 가속이 사라지는 것을 발견했습니다.

2025년 웹 앱(web app) 구축의 현실은 웹 개발 전문가(webdev expert)들이 일자리를 유지하도록 설계되었고 AI에는 접근할 수 없는, 분리된 서비스들의 혼란입니다. 불쌍한 클럭(Clerk)은 부정적인 언급을 받았고, 버셀(Vercel)의 @leerob은 긍정적인 언급을 받았습니다. 이는 그들의 문서 접근 방식이 각각 인간 대 에이전트(agent)에 맞춰 어떻게 조정될 것인지를 보여줍니다.

'바이브 코딩(Vibe Coding)'은 개발자가 명확한 설계나 상세한 계획 없이, 직감과 흐름에 따라 코드를 작성하는 방식을 의미합니다. 이는 대규모 언어 모델(LLM)을 활용하여 빠르게 아이디어를 구현하고 프로토타입을 만드는 과정에서 흔히 나타나는 현상입니다. 하지만 카파시가 언급했듯이, 이렇게 AI의 도움을 받아 빠르게 생성된 코드가 실제 로컬 환경에서 실행될 때 AI의 '가속 효과'가 사라지는 경험은 많은 개발자에게 현실적인 한계로 다가옵니다. 이는 AI 모델이 생성한 코드가 실제 시스템 환경의 복잡성(예: 라이브러리 의존성, 환경 설정, API 연동)을 완전히 이해하지 못하거나, AI가 접근할 수 없는 로컬 리소스와의 상호작용에서 문제가 발생하기 때문입니다.

현재의 웹 애플리케이션 개발 환경은 수많은 분리된 서비스와 API로 구성되어 있으며, 이는 인간 개발자에게는 익숙하지만 AI 에이전트에게는 접근하기 어렵고 파싱(parsing)하기 복잡한 '혼돈'으로 다가옵니다. 이러한 환경은 마치 인간 전문가가 아니면 다루기 힘든 복잡한 기계와 같아서, AI가 개발 프로세스에 깊이 개입하기 어렵게 만듭니다. 클럭(Clerk)과 버셀(Vercel)의 사례는 이러한 문제점을 극명하게 보여줍니다. 클럭의 문서는 인간 개발자에게는 유용하지만, AI 에이전트가 이해하고 활용하기에는 비효율적일 수 있습니다. 반면 버셀의 접근 방식은 AI 에이전트가 정보를 더 쉽게 파악하고 활용할 수 있도록 설계되었음을 암시합니다. 미래에는 AI가 개발 과정에 더욱 깊이 통합될 수 있도록, 'AI-네이티브 개발 환경(AI-native development environments)'과 에이전트 친화적인 문서화 및 API 설계가 필수적일 것입니다.

**Part 5: 에이전트(Agent)를 위한 설계**

결론적으로, 도구 제작자(toolmaker)들은 "디지털 정보의 새로운 소비자/조작자 범주"가 있다는 것을 인식해야 합니다.

1.  인간(GUI(Graphical User Interface))
2.  컴퓨터(API(Application Programming Interface))
3.  **새로운 존재**: 에이전트(Agent) <- 컴퓨터… 그러나 인간과 유사함

구체적으로: llms.txt가 작동하는 이유는 HTML이 대규모 언어 모델(LLM)에게는 구문 분석(parsing)하기 쉽지 않기 때문입니다. 그는 또한 우리가 라이트닝 팟(lightning pod)에서 다루었던 기트인제스트(Gitingest)와 코그니션(Cognition)의 딥위키(DeepWiki)와 같은 "컨텍스트 빌더(Context builder)"를 언급했습니다.

AI 시대의 도구와 플랫폼을 설계할 때, 우리는 더 이상 인간과 전통적인 컴퓨터 프로그램만을 사용자로 상정해서는 안 됩니다. '에이전트(Agent)'라는 새로운 유형의 사용자가 등장했음을 인지하고, 이들을 위한 맞춤형 설계가 필요합니다. 에이전트는 단순히 API를 통해 데이터를 주고받는 컴퓨터 프로그램과는 다릅니다. 이들은 인간과 유사한 방식으로 정보를 이해하고, 의도를 파악하며, 복잡한 작업을 자율적으로 수행하려 합니다.

이러한 에이전트들을 위해 시스템을 구축한다는 것은 다음과 같은 의미를 내포합니다:
*   **에이전트 친화적인 인터페이스**: HTML과 같은 시각적 정보는 LLM에게 복잡한 파싱(parsing) 과정을 요구합니다. 따라서 llms.txt와 같이, 에이전트가 정보를 더 쉽게 추출하고 이해할 수 있는 구조화된 데이터 포맷이나 '시맨틱 API(semantic API)'가 필요합니다. 이는 단순히 데이터 필드를 나열하는 것을 넘어, 데이터의 의미와 관계를 명시적으로 표현하여 에이전트가 맥락을 파악하도록 돕습니다.
*   **강력한 컨텍스트 구축 도구**: 기트인제스트(Gitingest)나 코그니션(Cognition)의 딥위키(DeepWiki)와 같은 '컨텍스트 빌더(Context builder)'는 에이전트가 특정 작업에 필요한 방대한 지식과 정보를 효과적으로 수집하고 정리하는 데 필수적입니다. 이는 에이전트가 '기억상실증'을 극복하고, 장기적인 전문성을 구축하며, 더 복잡한 추론을 수행할 수 있는 기반을 마련합니다. 미래에는 에이전트를 위한 '지식 그래프(knowledge graph)'나 '자율 학습 데이터 파이프라인(autonomous learning data pipeline)'과 같은 개념이 더욱 중요해질 것입니다.
*   **에이전트 우선 설계 철학**: API 디자인부터 데이터 구조화, 그리고 플랫폼 개발에 이르기까지 모든 단계에서 에이전트의 관점을 고려해야 합니다. 이는 에이전트가 시스템과 자연스럽게 상호작용하고, 인간의 개입 없이도 목표를 달성할 수 있도록 돕는 '에이전트 네이티브 프로토콜(agent-native protocols)'의 개발로 이어질 수 있습니다.

**마무리 / 요약**

이것은 에이전트(Agent)의 시대입니다. 인공 일반 지능(AGI) 2027과 제대로 작동하지 않는 화려한 시연(demo)은 줄어들 것입니다. 그 대신 부분적 자율성(partial autonomy), 맞춤형 그래픽 사용자 인터페이스(custom GUI) 및 자율성 조절기(autonomy slider)가 더욱 보편화될 것입니다. 소프트웨어 3.0(Software 3.0)이 소프트웨어 1/2(Software 1/2)을 대체하고 있다는 점, 그들의 유틸리티(Utility)/반도체 제조 공장(Fab)/운영 체제(OS) 특성이 그들의 운명을 결정할 것이라는 점, 생성기-검증기 순환(generator-verifier loop)을 개선하고, **에이전트(Agent)를 위해 구축하라 🤖**는 점을 기억하세요.

우리는 지금 인공지능이 단순한 도구를 넘어 자율적인 '에이전트'로 진화하는 변곡점에 서 있습니다. 이는 기술적 혁신을 넘어 사회 전반에 걸쳐 광범위한 변화를 가져올 것입니다. 개발자와 제품 관리자는 이러한 패러다임 전환을 인지하고, 에이전트 중심의 사고방식으로 접근해야 합니다. 불확실성 속에서도 명확한 목표는 에이전트가 인간의 삶을 실질적으로 개선하고, 복잡한 문제를 해결하며, 새로운 가치를 창출할 수 있도록 지원하는 견고하고 신뢰할 수 있는 시스템을 구축하는 것입니다. 이 에이전트의 시대는 우리에게 전례 없는 기회와 도전을 동시에 제시하며, 끊임없는 혁신과 책임감 있는 개발을 요구하고 있습니다.

LS 구독자를 위한 전체 슬라이드는 여기 :) 아래 링크