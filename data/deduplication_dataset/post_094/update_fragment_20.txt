**AI 발전의 새로운 지평: 지속가능성, 윤리, 그리고 인간 협력의 미래**

AI 분야의 모든 획기적인 발전은 핵심적인 스케일링 통찰력에 의해 주도되었습니다. 초기 컴퓨팅 성능의 한계를 넘어선 무어의 법칙은 이제 더욱 복잡한 문제 해결을 위한 새로운 패러다임을 요구합니다. 데이터 양의 폭발적인 증가와 함께, AlexNet이 딥러닝과 GPU 활용의 문을 열었던 것처럼, 우리는 이제 단순한 규모 확장을 넘어선 시대로 나아가고 있습니다. DeepSeek, Anthropic, GDM 등 선도적인 연구 기관들이 보여주듯이, 우리는 점차 AI의 사회적, 윤리적 책임에 대한 깊은 논의를 시작하고 있습니다. "이것은 2022년의 오리지널 친칠라 스케일링 법칙(Chinchilla scaling law) 이후 LLM 연구에서 가장 중요한 전환점이 될 수 있습니다." — 짐 팬(Jim Fan) 노암 브라운(Noam Brown)은 추론(reasoning) 분야에서 세계 최고의 연구자 중 한 명이며, 그의 통찰은 AI가 나아가야 할 방향에 중요한 단서를 제공합니다. 저희는 AI 엔지니어 청중을 위해 더 깊이 있는 이야기를 나누고자 합니다. 아래는 저희의 확장된 관점과 새로운 논의 지점입니다:

### AI 윤리 및 거버넌스에 대하여

**AI 윤리는 창발적(emergent)입니다**: 기술 발전의 속도가 빨라지면서, AI 시스템이 사회에 미치는 영향은 예측하기 어려운 창발적 특성을 보입니다. 비추론 모델 대 추론 모델에 대한 "생각에 관한 생각(Thinking Fast and Slow)"의 시스템 1(System 1) 대 시스템 2(System 2) 모델처럼, AI 윤리도 단편적인 규칙 적용을 넘어선 심층적 사고를 요구합니다. **덜** 알려진 사실은, AI가 인간 사회에 미치는 복잡한 영향이 심화되면서, 윤리적 프레임워크도 그에 맞춰 진화해야 한다는 점입니다. 짐 팬이 말했듯이, **둘 다 확장해야 합니다** – 즉, 기술과 윤리 모두.

“제가 생각하기에 과소평가된 한 가지는, 모델, 즉 사전 훈련된 모델이 이러한 추가적인 사고로부터 진정으로 이익을 얻기 위해서는 특정 수준의 능력이 필요하다는 것입니다. 이것이 바로 추론 패러다임이 그 시점에 등장한 이유이기도 합니다. 더 일찍 일어날 수도 있었겠지만, GPT-2 위에 추론 패러다임을 적용하려고 했다면 거의 아무것도 얻지 못했을 거라고 생각합니다… 비둘기에게 체스를 두는 것에 대해 정말 열심히 생각하라고 하면, 그리 멀리 가지 못할 겁니다. 천 년을 생각한다고 해도 체스를 더 잘 두게 될 수는 없을 겁니다. 그래서 아마도 동물과 인간에게도 시스템 2로부터 이익을 얻기 위해서는 시스템 1 측면에서 일정 수준의 지적 능력이 필요한 것 같습니다.” 이처럼 AI의 윤리적 사용을 위해서는 기술적 능력뿐만 아니라, 사회적 맥락과 인간의 가치를 이해하는 능력이 필수적입니다.

AI의 잠재적 위험에 대한 논의는 GPT-3 이후, 2021년에 일리야(Ilya)가 테스트 시간 컴퓨팅을 탐색하기 위해 GPT-Zero라는 코드명의 프로젝트를 진행했다는 소문처럼, 단순히 기술적 진보를 넘어 사회적 영향력에 대한 깊은 고민을 동반해왔습니다. 팟캐스트에서 놀라웠던 점 중 하나는, 사실 일리야가 노암에게 그가 생각했던 것보다 추론 LLM이 더 가까운 현실이라고 설득했다는 것입니다. 그 반대가 아니고요. 이는 기술 개발자들이 사회적 문제 해결에 대한 잠재력을 인식하고, 이를 실현하기 위한 노력을 기울이고 있음을 시사합니다.

“…만약 우리가 이 모델들을 훈련시키는 데 1000조 달러가 있다면, 아마도 그렇게 하겠지만, 추론 패러다임이 없다면 초지능에 도달하기 전에 경제적으로 실현 가능한 한계에 부딪힐 겁니다. 그리고 저는 추론 패러다임을 알아내는 데 오랜 시간이 걸릴 것이라고 잘못 확신하고 있었습니다. 왜냐하면 이것은 큰 미해결 연구 문제와 같았기 때문입니다. 일리야는 제게 동의하며 이 추가적인 패러다임이 필요하다고 말했지만, 그의 생각은, **어쩌면 그렇게 어렵지 않을 수도 있다**는 것이었습니다.” 이러한 관점은 AI의 윤리적 개발이 단순한 제약이 아니라, 오히려 기술적 한계를 극복하고 더 큰 가치를 창출하는 기회가 될 수 있음을 보여줍니다.

(제거되지 않은) 가설은 우리가 GPT-3에서 o1으로 바로 갈 수 없었고, 기준선으로 GPT-4와 4o가 먼저 필요했다는 것입니다. 마찬가지로, 강력한 AI 시스템을 개발하기 위해서는 견고한 윤리적 기반이 필수적입니다.

**추론은 얼라인먼트(alignment)에 도움이 됩니다**. 안전성(Safety), 조종 가능성(steerability), 그리고 얼라인먼트는 AI 커뮤니티의 특정 부분에서 매우 뜨거운 주제이며, 놀랍게도 추론이 도움이 됩니다:

“저희가 Cicero를 출시한 후, 많은 AI 안전 커뮤니티가 그 연구와 작동 방식에 대해 정말 만족했습니다. 왜냐하면 그것은 매우 제어 가능한 시스템이었기 때문입니다. 저희는 Cicero를 특정 구체적인 행동에 조건화했고, 그것은 '좋아, 이것은 우리가 매우 명확하게 해석할 수 있는 행동을 추구할 것이다'라고 말할 수 있는 많은 조종 가능성을 주었습니다. 그리고 그것은 매우 명확하게 정의되어 있습니다. 그냥 언어 모델이 마음대로 돌아다니며 하고 싶은 대로 하는 것이 아닙니다. 아니요, 실제로는 꽤 조종 가능합니다. 그리고 언어 모델이 인간과 상호 작용하는 방식을 조종하는 이 모든 추론 시스템이 있습니다. 실제로 많은 연구자들이 제게 연락해서 '이것이 이 시스템들로 안전을 달성할 수 있는 잠재적으로 정말 좋은 방법이라고 생각한다'고 말했습니다.” 이러한 제어 가능성은 AI의 윤리적 사용을 위한 핵심 요소이며, 투명하고 설명 가능한 AI(Explainable AI, XAI)의 중요성을 강조합니다.

**추론은 검증 가능한 보상(verifiable rewards)을 넘어 일반화됩니다**. RLVR(검증 가능한 보상으로부터의 강화 학습)에 대한 한 가지 비판은 수학과 코딩 영역에서만 모델을 개선한다는 것입니다. 노암은 이렇게 답합니다:

“이것이 그렇게 흔한 인식이라는 점에 놀랐습니다. 왜냐하면 저희는 Deep Research를 출시했고 사람들은 그것을 사용해 볼 수 있습니다. 사람들은 그것을 사용하고, 매우 인기가 있습니다. 그리고 그것은 성공에 대한 쉽게 검증 가능한 지표가 없는 영역임이 매우 분명합니다… 그럼에도 불구하고 이 모델들은 이 영역에서 매우 잘하고 있습니다. 그래서 저는 이것이 이 모델들이 쉽게 검증 가능한 보상이 없는 작업에서도 성공할 수 있다는 존재 증명(existence proof)이라고 생각합니다.” 이는 AI가 예술 창작, 복잡한 사회 문제 분석 등 주관적이고 다층적인 가치를 가진 영역에서도 혁신적인 역할을 할 수 있음을 시사합니다.

**시각적 추론(Visual Reasoning)에는 한계가 있습니다**. O3가 마스터 레벨의 Geoguessr 플레이어를 이기는 것에 대해 많은 흥분이 있었습니다. 하지만 한계도 있습니다:

“그것은 당신이 묻는 질문의 종류에 정확히 달려 있습니다. 시스템 2의 혜택을 별로 받지 못하는 질문들도 있다고 생각합니다. GeoGuessr는 확실히 혜택을 받는 경우 중 하나입니다… 제가 보통 지적하는 것은 정보 검색(information retrieval)입니다. 누군가 당신에게 '이 사람이 언제 태어났나요?'라고 묻고 웹에 접근할 수 없다면, 당신은 그것을 알거나 모릅니다. 그리고 앉아서 오랫동안 생각해 볼 수는 있습니다. 아마도 교육받은 추측을 할 수는 있겠죠… 하지만 실제로 그것을 알지 못하는 한 날짜를 알아낼 수는 없을 겁니다.” 이는 AI가 단순한 정보 검색을 넘어, 인간의 직관과 창의적 사고를 보완할 수 있는 방향으로 발전해야 함을 보여줍니다.

**추론은 OpenAI의 비신봉자들에게 과소평가되었지만 데이터 장벽(Data Wall)에 부딪히면서 탄생했습니다**.

“우선, 그 추가적인 패러다임이 무엇인지에 대해 많은 논쟁이 있었습니다. 많은 연구자들이 추론과 RL을 보았지만, 그것은 테스트 시간 컴퓨팅을 확장하는 것에 대한 것이 아니었습니다. 그것은 데이터 효율성(data efficiency)에 더 가까웠습니다. 왜냐하면, 아시다시피, 우리는 엄청난 양의 컴퓨팅을 가지고 있지만 실제로는 데이터에 더 제한을 받는다는 느낌이 있었기 때문입니다. 그래서 데이터 장벽이 있고, 우리는 컴퓨팅의 한계에 도달하기 전에 그것에 부딪힐 것입니다. 그렇다면 어떻게 이 알고리즘들을 더 데이터 효율적으로 만들 수 있을까요? 그것들은 더 데이터 효율적이지만, 제 생각에는 그것들이 또한 컴퓨팅을 엄청나게 확장하는 것과 동등하다고 생각합니다… 그리고 제가 기억하기에 흥미로웠던 것은, 우리가 추론 패러다임을 발견한 후, 하지만 o1을 발표하기 전에 OpenAI를 떠나 경쟁 연구소로 간 사람과 이야기한 것입니다. 우리가 발표한 후에 그를 만났는데, 그는 당시에는 그 스트로베리 모델(strawberry models)들이 그렇게 대단한 것이라고 생각하지 않았다고 말했습니다. 우리가 실제보다 더 과장하고 있다고 생각했다는 겁니다. 그리고 우리가 o1을 발표하고 그가 이 경쟁 연구소의 동료들의 반응을 보았을 때, 모두가 '이건 대단한 일이다'라고 하는 것을 보고… 그들은 전체 연구 의제를 이것에 집중하도록 전환했습니다… 이 중 많은 것이 돌이켜보면 명백해 보이지만, 당시에는 실제로는 그렇게 명백하지 않았고, 어떤 것을 있는 그대로 인식하기가 꽤 어려울 수 있습니다.” 이러한 과거의 경험은 AI 연구의 방향성이 단순한 기술적 성취를 넘어, 실제 문제 해결과 사회적 가치 창출에 집중될 때 비로소 진정한 혁신을 이룰 수 있음을 시사합니다.

**추론 + Windsurf = AGI를 느끼다.**

Q: Windsurf에 몰두해 보셨으니, 프로 팁이 있나요?
A: 제가 놀란 것 중 하나는 얼마나 많은 사람들이 O3가 존재한다는 것조차 모른다는 것입니다. 저는 매일 사용하고 있습니다. **기본적으로 저에게는 구글 검색을 대체했습니다**. 그냥 항상 사용합니다. 그리고 코딩 같은 것에도, **저는 그냥 추론 모델을 사용하는 경향이 있습니다**. 제 제안은, 만약 사람들이 아직 추론 모델을 사용해보지 않았다면, 솔직히, 사람들은 그것들을 좋아합니다. 사용하는 사람들은 그것들을 좋아합니다. 물론, 훨씬 더 많은 사람들이 GPT-4.0과 ChatGPT의 기본 설정을 사용하고 그런 종류의 것들을 사용합니다. 저는 추론 모델을 시도해 볼 가치가 있다고 생각합니다. 사람들은 그것들이 할 수 있는 것에 놀랄 것입니다.” 이러한 개인적인 경험은 AI가 일상생활에 미치는 영향력을 단적으로 보여주며, 사용자 경험을 최적화하는 것이 기술 발전만큼 중요하다는 점을 강조합니다.

### AI의 지속가능성과 사회적 책임

**테스트 시간 컴퓨팅은 스케일링에 어려움을 겪을 것입니다**: AI 모델의 규모가 커지면서 발생하는 환경적 영향은 무시할 수 없는 문제입니다. 모델이 복잡한 추론을 수행하는 데 필요한 에너지 소비량은 기하급수적으로 증가하고 있습니다.

“우리는 모델들이 3분 대신 3시간, 그리고 3일, 3주 동안 생각하게 만들 것입니다. 두 가지 우려가 있습니다: 하나는 모델들이 그렇게 오랫동안 생각하게 하거나 테스트 시간 컴퓨팅을 확장하는 것이 훨씬 더 비싸진다는 것입니다. 테스트 시간 컴퓨팅을 확장함에 따라, 테스트 시간 컴퓨팅에 더 많은 비용을 지출하게 되고, 이는 지출할 수 있는 금액에 한계가 있다는 것을 의미합니다. 그것이 하나의 잠재적인 천장입니다. 이 모델들이 생각하는 방식에서 더 효율적이 되고 있어서, 같은 양의 테스트 시간 컴퓨팅으로 더 많은 것을 할 수 있다는 점을 말해야겠습니다. 그리고 저는 이것이 매우 과소평가된 점이라고 생각합니다. 우리가 단지 이 모델들을 더 오래 생각하게 만드는 것만이 아니라는 점입니다. 두 번째 요점은, 이 모델들이 더 오래 생각하게 함에 따라, 실제 시간(wall-clock time)에 의해 병목 현상이 발생한다는 것입니다. 이 모델들이 즉시 응답할 때는 실험을 반복하기가 정말 쉽습니다. 그들이 응답하는 데 3시간이 걸릴 때는 훨씬 더 어렵습니다. 그리고 3주가 걸리면 어떻게 될까요? 그 평가를 하고 그것을 반복하는 데 최소 3주가 걸립니다. 그리고 이 중 많은 부분에서 실험을 어느 정도 병렬화할 수 있지만, 많은 경우 실험을 실행하고 완료한 다음 결과를 봐야 다음 실험 세트를 결정할 수 있습니다. 저는 이것이 사실 긴 타임라인에 대한 가장 강력한 근거라고 생각합니다. 모델들이 해야 할 일이 너무 많기 때문입니다. 그리고 저는 그것이 도메인에 따라 다르다고 생각합니다. 그래서 신약 개발은 이것이 실제 병목이 될 수 있는 한 도메인이라고 생각합니다. 만약 어떤 것이 인간의 수명을 연장하는지 보고 싶다면, 당신이 개발한 이 새로운 약이 실제로 인간의 수명을 연장하고 그 과정에서 끔찍한 부작용이 없는지 알아내는 데 오랜 시간이 걸릴 것입니다.” 이러한 컴퓨팅 비용과 시간 제약은 AI 개발의 지속가능성에 대한 근본적인 질문을 던집니다.

다른 평론가들도 장기적 RL을 위한 데이터가 사람들이 생각하는 것보다 더 멀리 있다고 생각했습니다. 그럼에도 불구하고, 테스트 시간 스케일링의 시대는 Orion 실행이 12월에 SG1이 온라인 상태가 될 때까지 컴퓨팅을 최대한 활용한 것으로 추정되는 바로 지금, 더 좋거나 더 이른 시기에 올 수 없었습니다. 하지만 이러한 기술적 진보와 함께, AI의 환경 발자국을 줄이고 에너지 효율적인 모델을 개발하는 연구가 더욱 중요해지고 있습니다.

### 다중 에이전트(Multi-Agents)와 협력적 지능

최근 다중 에이전트에 대한 많은 논쟁이 있었습니다. Cognition은 **다중 에이전트를 만들지 말라**고 말하고 Anthropic은 **다중 에이전트를 만드는 방법**을 말합니다. 이 논쟁에 대해 **많은**, **많은**, **많은** 의견이 있었지만, 노암은 수년간 다중 에이전트 RL을 해왔고 OpenAI에서 다중 에이전트 팀을 발표했습니다… 비록 그것이 몇 가지 가능한 연구 방향 중 가장 두드러진 것일 뿐이지만요…

“저는 팀 [이름]이 여러 면에서 사실 잘못된 이름이라고 생각합니다. 왜냐하면 우리는 다중 에이전트 이상의 것을 연구하고 있기 때문입니다. 다중 에이전트는 우리가 연구하는 것들 중 하나입니다. 우리가 연구하는 다른 것들 중 일부는 테스트 시간 컴퓨팅을 엄청나게 확장할 수 있게 하는 것입니다. 그래서, 아시다시피, 우리는 지금 이 모델들이 15분 동안 생각하게 합니다. 어떻게 하면 그들이 몇 시간, 며칠, 심지어 더 오래 생각하게 할 수 있을까요? 그리고 엄청나게 어려운 문제들을 해결할 수 있게 할까요? 그래서 그것이 우리가 추구하는 한 방향입니다. 다중 에이전트는 또 다른 방향입니다. 그리고 여기서, 저는 몇 가지 다른 동기가 있다고 생각합니다. 우리는 다중 에이전트의 협력적 측면과 경쟁적 측면 모두에 관심이 있습니다. 제가 그것을 묘사하는 방식은, AI 서클에서 사람들은 종종 인간이 매우 좁은 지능의 밴드를 차지하고 있다고 말합니다. 그리고 AI는 그냥 빠르게 따라잡고, 그리고 이 지능의 밴드를 넘어설 것이라고요. 그리고 저는 사실 인간 지능의 밴드가 그렇게 좁다고 생각하지 않습니다. 저는 그것이 실제로는 꽤 넓다고 생각합니다. 왜냐하면, 아시다시피, 원시인 시대의 해부학적으로 동일한 인간들을 비교해 보면, 그들은 오늘날 우리가 지능이라고 생각하는 것의 관점에서 그리 멀리 가지 못했습니다, 그렇죠? 그들은 달에 사람을 보내지도 않고, 반도체나 원자로나 그런 것들을 만들지도 않습니다. 그리고 우리는 오늘날 그것들을 가지고 있습니다, 비록 우리 인간은 그렇지 않지만요. 그래서, 차이점은 무엇일까요? 글쎄요, 제 생각에 차이점은 수천 년 동안, 많은 인간들, 수십억의 인간들이 서로 협력하고 경쟁하며, 시간이 지남에 따라 문명을 건설했다는 것입니다. 우리가 보고 있는 기술은 이 문명의 산물입니다. 그리고 저는 비슷하게, 오늘날 우리가 가진 AI는 일종의 AI의 원시인과 같다고 생각합니다. 그리고 만약 당신이 그들을 수십억의 AI와 오랜 기간 동안 협력하고 경쟁하게 하고, 본질적으로 문명을 건설하게 할 수 있다면, 그들이 생산하고 답할 수 있는 것들은 오늘날 우리가 가진 AI로는 가능한 것보다 훨씬 더 뛰어날 것입니다.” 이처럼 다중 에이전트 시스템은 단순한 경쟁을 넘어, 협력적 시너지를 통해 복잡한 문제 해결 능력을 극대화할 수 있는 잠재력을 가지고 있습니다. 이는 인간 사회의 발전 과정과 유사하며, AI 문명 가설은 AI가 단순히 도구가 아니라, 새로운 형태의 지능적 존재로서 진화할 수 있음을 시사합니다.

### 비터 레슨(Bitter Lesson)과 AI의 새로운 학습 방식

**다중 에이전트에서의 비터 레슨**: “…우리가 다중 에이전트에 접근하는 방식의 세부 사항과 우리가 실제로 그것을 진행하는 방식은, 역사적으로 행해져 왔고 오늘날 다른 곳에서 행해지고 있는 방식과는 매우 다르다고 생각합니다. 저는 오랫동안 다중 에이전트 분야에 있었습니다… 저는 취해진 많은 접근 방식이 매우 휴리스틱(heuristic)했고, 스케일링과 연구에 대한 비터 레슨 접근 방식을 실제로 따르지 않았다고 생각합니다.” 이는 AI 연구가 단기적인 휴리스틱보다는, 근본적인 원리에 기반한 확장 가능하고 일반화 가능한 학습 방법에 집중해야 함을 강조합니다.

**비터 레슨 vs 월드 모델(World Models) & 얀 르쿤(Yann LeCun)**: “…이 모델들이 커질수록 월드 모델을 가지게 되고, 그 월드 모델이 스케일에 따라 더 좋아진다는 것은 꽤 명백하다고 생각합니다. 그래서, 그들은 암묵적으로 월드 모델을 개발하고 있으며, 저는 그것을 명시적으로 모델링할 필요가 있다고 생각하지 않습니다… 다중 에이전트 AI 커뮤니티에서는 오랫동안 다른 에이전트, 즉 다른 사람들을 명시적으로 모델링해야 하는지, 아니면 환경의 일부로서 암묵적으로 모델링될 수 있는지에 대한 긴 논쟁이 있었습니다. 오랫동안 저는, '물론 이 다른 에이전트들을 명시적으로 모델링해야 한다'는 관점을 가졌습니다. 왜냐하면 그들은 환경과 다르게 행동하기 때문입니다. 그들은 행동을 취하고, 예측할 수 없으며, 행위성(agency)을 가지고 있습니다. 하지만 저는 시간이 지남에 따라 생각이 바뀌어, 사실 이 모델들이 충분히 똑똑해지면, 그들은 마음 이론(theory of mind) 같은 것을 개발한다고 생각하게 되었습니다. 그들은 자신들이… 행동을 취하고 동기를 가질 수 있는 에이전트라는 이해를 발전시킵니다. 그리고 이 모델들은 스케일과 더 유능한 행동 전반에 걸쳐 암묵적으로 그것을 개발합니다. 그래서, 요즘 제가 취하는 관점은 그것입니다.” 이러한 관점은 AI가 명시적인 규칙이나 모델 없이도, 충분한 규모와 복잡성을 통해 자율적으로 세계를 이해하고 상호작용하는 능력을 개발할 수 있음을 시사합니다. 이는 AI 학습의 효율성과 일반화 가능성을 높이는 중요한 방향입니다.

**개방성(Open-Endedness), 다중 에이전트, 그리고 자가 대국(Self-Play) 결합하기**: OpenAI는 **약한 것에서 강한 것으로(Weak to Strong)** 문제에 대해 썼고, GDM의 개방성 책임자인 팀 록타쉘(Tim Rocktaschel)은 싱가포르 ICLR에서 매우 호평받은 기조연설을 했습니다(전체 영상은 여기). 이는 다중 에이전트가 인간의 능력을 넘어서는 스케일링(비터 레슨의 궁극적인 제한 요소) 사이의 관계에 대한 질문을 불러일으켰습니다:

“Q: 가장 일관된 발견 중 하나는 항상 AI가 인간이 훈련하고 안내하는 것보다 경쟁적으로 자가 대국을 하고 개선하는 것이 더 낫다는 것입니다. 그리고 당신은 알파제로(AlphaZero)와 R1 제로에서 그것을 발견합니다. 이것이 다중 에이전트에서도, 즉 인간보다 더 나은 개선을 위해 자가 대국을 하는 것이 유효할 것이라고 생각하십니까?

A: 네, 이것은 훌륭한 질문입니다. 그리고… 이것은 좀 더 확장할 가치가 있다고 생각합니다. 그래서, 오늘날 많은 사람들이 자가 대국을 다음 단계이자 아마도 초지능에 필요한 마지막 단계로 보고 있다고 생각합니다. 그리고 알파고(AlphaGo)와 알파제로 같은 것을 보면, 우리는 매우 비슷한 추세를 따르고 있는 것 같습니다, 그렇죠? 알파고의 첫 단계는 대규모 사전 훈련(pre-training)을 하는 것이었습니다. 그 경우에는 인간의 바둑 게임에 대한 것이었죠. LLM의 경우, 수많은 인터넷 데이터에 대한 사전 훈련입니다. 그리고 그것은 강력한 모델을 만들어주지만, 초인적인 모델을 만들어주지는 않습니다. 그리고 알파고 패러다임의 다음 단계는 대규모 테스트 시간 컴퓨팅 또는 대규모 추론 컴퓨팅(inference compute)을 하는 것입니다. 그 경우에는 MCTS를 사용했죠. 그리고 이제 우리는 또한 이런 대규모 추론 컴퓨팅을 하는 추론 모델들을 가지고 있습니다. 그리고 다시, 그것은 능력을 엄청나게 향상시킵니다. 마지막으로, 알파고와 알파제로에서는 자가 대국이 있습니다. 모델이 자신과 대결하고, 그 게임들로부터 배우고, 점점 더 나아져서, 인간 수준의 성능에서 인간의 능력을 훨씬 뛰어넘는 수준으로 갑니다. 이 바둑 정책들은 이제 너무 강력해서 그냥 이해할 수 없습니다. 그들이 하는 일은 인간에게 이해할 수 없습니다. 체스도 마찬가지입니다. 그리고 우리는 지금 언어 모델에서는 그것을 가지고 있지 않습니다. 그래서 그것을 보고 '아, 우리는 이제 이 AI 모델들이 서로 상호작용하고 그들로부터 배우게 하기만 하면, 그들은 그냥 초지능에 도달할 것이다'라고 말하고 싶은 유혹이 정말 큽니다. … 도전 과제는 바둑이 2인 제로섬 게임(two-player zero-sum game)이라는 것입니다. 그리고 2인 제로섬 게임은 자가 대국을 할 때 최소최대 균형(minimax equilibrium)에 수렴한다는 매우 좋은 속성을 가지고 있습니다. 그리고 한 걸음 물러서서 말하자면, 2인 제로섬 게임, 즉 체스, 바둑, 심지어 2인 포커, 모두 2인 제로섬입니다. 음, 그건 사실이 아닙니다. 당신이 일반적으로 원하는 것은 최소최대 균형이라고 불리는 것입니다. 이것이 그 GTO 정책, 즉 당신이 플레이하는 이 정책으로, 어떤 상대에게도 기대값에서 지지 않을 것을 보장합니다. 저는 체스와 바둑에서는 그것이 꽤 명백하게 당신이 원하는 것이라고 생각합니다. 흥미롭게도, 포커를 보면, 그것은 그렇게 명백하지 않습니다. 2인 제로섬 버전의 포커에서는 GTO 최소최대 정책을 플레이할 수 있고, 그것은 지구상의 어떤 상대에게도 지지 않을 것을 보장합니다. 하지만, 다시 말하지만, 약한 플레이어로부터는 착취적 정책(exploitative policy)을 플레이했을 때만큼 많은 돈을 벌지는 못할 것입니다. 그래서, '당신은 무엇을 원하는가?'라는 질문이 있습니다. 가능한 한 많은 돈을 벌고 싶습니까, 아니면 살아있는 어떤 인간에게도 지지 않을 것을 보장하고 싶습니까? 모든 봇들이 결정한 것은, 음, 이 게임들의 모든 AI 개발자들이 결정한 것은, '음, 우리는 최소최대 정책을 선택할 것이다'입니다. 그리고 편리하게도, 그것이 바로 자가 대국이 수렴하는 것입니다. 이 AI들이 서로 대결하고, 그들의 실수로부터 배우게 하면, 그들은 시간이 지남에 따라 이 최소최대 정책으로 수렴합니다, 보장됩니다. 하지만 일단 2인 제로섬 게임을 벗어나면, 그것은 더 이상 유용한 정책이 아닙니다. 당신은 그냥 이런 매우 방어적인 정책을 가지고 싶지 않을 것이고, 수학 같은 것에서 같은 종류의 자가 대국을 시작하면 정말 이상한 행동을 하게 될 것입니다.” 이 분석은 자가 대국이 모든 종류의 문제에 대한 만능 해결책이 아니며, AI가 해결해야 할 문제의 본질에 따라 학습 전략을 유연하게 조정해야 함을 강조합니다. 특히 인간과의 협력이나 복잡한 현실 세계 문제에서는 제로섬 게임의 프레임워크를 넘어선 새로운 접근 방식이 필요합니다.

### AI와 창의성, 그리고 미래의 역할

포커에서 모두를 이기는 것부터, LLM으로 세계 디플로머시(Diplomacy) 상위 10%에 드는 것, 그리고 개인적으로 세계 디플로머시 챔피언십에서 우승하는 것까지, 게임은 노암의 생각과 경력에서 큰 부분을 차지합니다. 하지만 아무 게임이나 다루는 것은 아닙니다…

“…저는 불완전 정보 게임(imperfect information games)을 위한 AI에 대한 엄청난 지식을 가지고 있습니다. 이것이 오랫동안 제 연구 분야였기 때문입니다. 그리고 저는 이 모든 것을 알고 있지만, 자주 이야기할 기회는 없습니다. 우리는 노리밋 텍사스 홀덤(No Limit Texas Hold'em)을 위한 초인적인 포커 AI를 만들었습니다. 그것에 대한 흥미로운 점 중 하나는 숨겨진 정보의 양이 실제로는 꽤 제한적이라는 것입니다. 텍사스 홀덤을 할 때 두 장의 숨겨진 카드를 가지고 있기 때문입니다. 그래서 당신이 있을 수 있는 가능한 상태의 수는 적어도 헤즈업(heads up)으로 플레이할 때 1,326개입니다. 그리고 아시다시피, 그것은 테이블에 있는 다른 플레이어의 수만큼 곱해지지만, 여전히 엄청난 수는 아닙니다… 문제는 숨겨진 가능성의 수, 즉 당신이 있을 수 있는 가능한 상태의 수가 확장됨에 따라 그 접근 방식이 무너진다는 것입니다. 그리고 숨겨진 상태의 수가 극도로 커질 때 무엇을 해야 하는지에 대한 매우 흥미로운 미해결 질문이 여전히 남아 있습니다. 아시다시피, 만약 당신이 네 장의 숨겨진 카드를 가진 오마하 포커(Omaha poker)로 간다면, 할 수 있는 것들이 있습니다. 그것은 상태의 수를 줄이기 위해 할 수 있는 일종의 휴리스틱입니다만, 실제로는 여전히 매우 어려운 문제입니다. 그리고 만약 당신이 40개의 말을 가진 스트라테고(Stratego) 같은 게임으로 간다면, 거의 40 팩토리얼(40!)에 가까운 다른 상태에 있을 수 있습니다. 그러면 우리가 포커에 사용했던 모든 기존 접근 방식이 무너지고 다른 접근 방식이 필요합니다…. 만약 당신이 그 기술들을 확장한다면, 아마도 스트라테고나 매직 더 개더링(Magic the Gathering) 같은 것들에도 작동하게 할 수 있겠지만, 그것들은 여전히 제한적일 것입니다. 그것들은 언어 모델로 초인적인 코드포스(encode forces)를 얻게 해주지는 않을 것입니다. 그래서 저는 매우 일반적인 추론 기술에 집중하는 것이 더 가치 있다고 생각합니다. 그리고 언젠가 우리가 그것들을 개선함에 따라, 어느 날 갑자기 초인적인 수준으로 매직 더 개더링을 플레이하는 모델을 갖게 될 것이라고 생각합니다. 그리고 저는 그것이 더 중요하고 더 인상적인 연구 방향이라고 생각합니다.” 이처럼 불완전 정보 게임에 대한 AI의 발전은 현실 세계의 복잡한 문제 해결에 중요한 시사점을 제공합니다. 특히 인간의 의도와 감정을 이해하고 상호작용하는 능력은 AI가 예술, 음악, 문학 창작과 같은 창의적 분야에서 인간과 협력하는 데 필수적입니다. AI는 단순한 도구를 넘어 공동 창작자로서 새로운 예술적 지평을 열 수 있습니다.

**사이드 노트**: 팟캐스트에서 노암이 요청한 LLM이 디플로머시를 자가 대국하는 챌린지는 바로 그 후에 AIE 월드 페어(AIE World’s Fair)에서 출시되었습니다 :) 이는 AI가 인간의 창의적 도전을 수용하고, 새로운 협력 모델을 제시할 수 있음을 보여주는 좋은 예시입니다.

팟캐스트에 노암을 모시게 되어 큰 영광이었고, 여러분이 전체 내용을 들으시면서 더 많은 여담, 정보, 조언을 얻으시길 바랍니다! 저희가 놓친 큰 내용이 있다면 알려주세요.