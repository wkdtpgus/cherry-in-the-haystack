인공지능 분야의 눈부신 진보는 언제나 핵심적인 확장 원리(scaling principle)의 발견과 함께해 왔습니다. 과거 무어의 법칙(Moore's Law)이 반도체 기술의 발전을 이끌었다면, 이후 황의 법칙(Huang's Law)은 실리콘 기반 컴퓨팅 성능의 비약적인 향상을 주도했습니다. 데이터 처리의 중요성을 강조한 Kaplan 등의 연구는 Hoffman 등의 후속 연구(데이터 1)로 발전했으며, AlexNet은 딥러닝과 GPU를 활용한 머신러닝 혁명(사전 훈련)의 서막을 열었습니다. 최근 o1의 발표와 함께 DeepSeek, Anthropic, GDM 등 유수의 AI 기업들이 뒤따르면서, 우리는 이제 '테스트 시간 컴퓨팅(test time compute)'의 규모를 확장하는 시대로 확고히 접어들었음을 목격하고 있습니다.

이러한 흐름 속에서, 짐 팬(Jim Fan)은 "이는 2022년의 친칠라 스케일링 법칙(Chinchilla scaling law) 이후 LLM 연구에서 가장 중요한 전환점이 될 수 있다"고 언급하며 그 중요성을 강조했습니다. 오늘 우리는 추론(reasoning) 분야의 세계적인 권위자인 노암 브라운(Noam Brown) 박사를 모시고, 이 새로운 시대의 핵심인 추론의 본질과 미래 방향에 대해 심층적인 대화를 나눴습니다. TED 강연, OpenAI 영상, 그리고 수많은 AI 팟캐스트를 통해 그의 통찰력을 접해본 분들이 많으실 텐데요, AI 엔지니어 청중을 위해 더욱 깊이 있는 논의를 펼쳐준 노암 박사에게 진심으로 감사드립니다. 그의 깊은 식견을 바탕으로 한 오늘의 팟캐스트 주요 내용을 아래에 요약했습니다.

### 추론에 대하여

**추론 능력은 특정 임계점을 넘어서야 발현됩니다**: 카네만(Kahneman)의 저서 "생각에 관한 생각(Thinking, Fast and Slow)"에서 제시된 시스템 1(System 1, 직관적이고 빠른 사고)과 시스템 2(System 2, 숙고적이고 느린 사고) 모델은 비추론적 인공지능과 추론적 인공지능의 차이를 설명하는 데 자주 인용됩니다. 특히 1단위의 테스트 시간 컴퓨팅이 1,000배에서 10,000배에 달하는 모델 규모의 효과를 낼 수 있다는 비대칭성 또한 널리 인식되고 있습니다. 그러나 이러한 심오한 추론 능력이 GPT-4 이후에야 비로소 실현 가능해졌다는 사실은 상대적으로 덜 부각됩니다. 짐 팬의 언급처럼, 모델의 규모(pre-training)와 추론 역량(test-time compute)은 상호 보완적으로 확장되어야 합니다.

노암 박사는 이 점을 강조하며, "사전 훈련된 모델이 충분한 기반 역량을 갖추지 못하면, 아무리 추가적인 사고를 부여하려 해도 그 효과는 미미할 것"이라고 설명했습니다. 이는 마치 어린아이가 기본적인 언어 능력을 습득하기 전에는 복잡한 추론 문제를 해결할 수 없는 것과 유사합니다. GPT-2와 같은 초기 모델에 연쇄적 사고(chain-of-thought) 기법을 적용했을 때 유의미한 결과가 나오지 않았던 이유도 여기에 있습니다. 모델의 '지능 지수'가 일정 수준에 도달해야만 시스템 2의 심층적인 사고 과정이 효과를 발휘할 수 있다는 의미입니다.

흥미롭게도, GPT-3 개발 이후 2021년, 일리야(Ilya Sutskever)는 테스트 시간 컴퓨팅 탐색을 위한 'GPT-Zero'라는 코드명의 프로젝트를 진행했습니다(이는 공식적으로 확인된 바는 아니나 업계에 널리 알려진 이야기입니다). 당시 노암 박사는 범용 추론 패러다임 구현에 상당한 시간이 걸릴 것이라 예상했지만, 일리야는 "어쩌면 그렇게 어렵지 않을 수도 있다"는 의견으로 노암 박사를 설득했다고 합니다. 이는 선구적인 연구자들이 당시의 통념을 넘어 새로운 가능성을 탐색하고 있었음을 보여주는 대목입니다. OpenAI 내부에서는 데이터 효율성 문제로 인해 추론 연구의 필요성이 제기되었고, 초기에는 그 중요성에 대한 의견 차이도 있었지만, 결국 추론 모델의 잠재력을 조기에 인식하고 대규모 투자를 단행한 것이 o1과 같은 혁신으로 이어졌습니다.

**추론은 AI 정렬(alignment)에 중요한 역할을 합니다**. 인공지능의 안전성(Safety), 제어 가능성(steerability) 및 인간 가치와의 정렬은 AI 연구 커뮤니티에서 매우 중요한 화두입니다. 놀랍게도, 추론 능력은 이러한 목표 달성에 크게 기여합니다. 노암 박사는 OpenAI의 Cicero 프로젝트를 예로 들며 다음과 같이 설명했습니다: “Cicero 출시 이후, 많은 AI 안전 전문가들이 저희 연구 결과와 시스템 작동 방식에 깊은 만족감을 표했습니다. 그 이유는 Cicero가 매우 명확하게 제어 가능한 시스템이었기 때문입니다. 저희는 Cicero가 특정 행동 양식을 따르도록 명확히 조건화했고, 이를 통해 모델의 행동을 명확하게 예측하고 해석할 수 있는 높은 수준의 조종 가능성을 확보했습니다. 이는 마치 통제 불능의 언어 모델이 아니라, 인간과의 상호작용을 정교하게 유도하는 추론 시스템을 갖춘 에이전트와 같았습니다. 실제로 많은 연구자들은 이러한 접근 방식이 AI 시스템의 안전성을 확보하는 데 매우 유망한 방법이라고 평가했습니다.”

**추론의 범용성은 명확한 보상 체계를 넘어섭니다**. 강화 학습(Reinforcement Learning) 분야에서 주로 논의되는 검증 가능한 보상(verifiable rewards) 기반 학습 방식에 대한 비판 중 하나는, 이러한 방식이 수학이나 코딩과 같이 명확한 정답과 보상 체계가 존재하는 영역에서만 효과적이라는 것입니다. 이에 대해 노암 박사는 다음과 같이 반박했습니다: “이러한 인식이 널리 퍼져 있다는 점이 놀랍습니다. 저희가 출시한 Deep Research는 이미 많은 사용자들이 활용하고 있으며 높은 인기를 얻고 있습니다. Deep Research는 '최고의 연구 보고서란 무엇인가?'와 같이 성공을 쉽게 측정할 수 없는 영역에 속합니다. 그럼에도 불구하고, 이 모델들은 해당 분야에서 탁월한 성과를 보여주고 있습니다. 이는 명확히 검증 가능한 보상이 부재한 작업에서도 인공지능 모델이 성공할 수 있음을 입증하는 강력한 증거입니다.” 이는 법률 문서 검토나 복잡한 전략 기획과 같이, 결과물의 품질이 주관적이거나 다면적인 평가를 요구하는 영역에서도 추론 모델의 잠재력이 크다는 것을 시사합니다. 모델은 단일한 '정답'을 찾는 대신, 다양한 요소를 종합적으로 고려하여 최적의 경로를 추론하고, 그 과정에서 인간 전문가와 유사하거나 그 이상의 통찰력을 제공할 수 있습니다.

**시각적 추론의 적용 범위는 질문의 성격에 따라 달라집니다**. O3 모델이 최고 수준의 GeoGuessr 플레이어들을 능가하는 성과를 보이면서 시각적 추론에 대한 큰 기대가 모였습니다. 하지만 노암 박사는 이러한 능력에도 명확한 한계가 있음을 지적합니다: "이는 질문의 유형에 따라 크게 달라집니다. 시스템 2의 심층적 사고 과정이 큰 이점을 제공하지 않는 질문들도 존재합니다. GeoGuessr는 분명 시스템 2가 유용한 영역이지만, 정보 검색(information retrieval)과 같은 경우에는 다릅니다. 예를 들어, 누군가에게 '이 인물은 언제 태어났습니까?'라고 묻고 인터넷에 접속할 수 없다면, 당신은 그 사실을 알거나 모르는 둘 중 하나입니다. 아무리 오랫동안 숙고하고 교육받은 추측을 한다고 해도, 실제 지식이 없다면 정확한 날짜를 알아낼 수는 없습니다." 이러한 관점은 AI 모델이 단순히 '생각하는' 능력만으로는 해결할 수 없는 문제들이 있음을 강조합니다. 즉, 추론 능력과 더불어 방대한 지식 기반(knowledge base)에 대한 접근성, 혹은 외부 도구 활용 능력(tool use)이 결합될 때 비로소 인공지능의 진정한 잠재력이 발휘될 수 있음을 시사합니다.

**데이터 장벽에 직면하며 추론의 가치가 재조명되었습니다**. 초기 OpenAI 내부에서는 추론의 중요성에 대한 다양한 의견이 존재했습니다. 많은 연구자들은 추론과 강화 학습(RL)을 데이터 효율성을 높이는 방법으로 보았지, 테스트 시간 컴퓨팅의 확장과 직접적으로 연결시키지는 않았습니다. 노암 박사는 당시의 분위기를 다음과 같이 회고했습니다: “우리는 엄청난 양의 컴퓨팅 자원을 가지고 있었지만, 실제로는 데이터의 양에 더 큰 제약을 받고 있다는 인식이 지배적이었습니다. 컴퓨팅 한계에 도달하기 전에 '데이터 장벽(Data Wall)'에 부딪힐 것이라는 예측이 많았죠. 따라서 알고리즘을 어떻게 더 데이터 효율적으로 만들 것인가가 주요 관심사였습니다. 추론 모델은 데이터 효율성을 높이는 동시에, 컴퓨팅 자원을 대규모로 확장하는 것과 유사한 효과를 가져왔습니다.” 그는 또한 추론 패러다임 발견 후 o1 발표 전에 OpenAI를 떠나 경쟁사로 이직했던 한 연구자의 사례를 언급하며, 당시에는 이 '스트로베리 모델(strawberry models)'이라 불리던 추론 모델의 중요성을 간과했던 이들이 o1 발표 후 경쟁사 동료들의 폭발적인 반응을 보고서야 연구 방향을 급선회하는 상황을 목격했다고 전했습니다. 이는 돌이켜보면 명백해 보이는 진보가 당시에는 얼마나 인식하기 어려웠는지를 보여주는 단적인 예시입니다. 이러한 일화는 인공지능 연구의 역동적인 특성을 잘 보여줍니다. 특정 시점에는 특정 기술의 한계가 명확해 보이지만, 새로운 관점과 접근 방식이 도입되면 그 한계가 돌파될 수 있다는 것을 의미합니다. 특히, 추론은 단순히 단일 모델의 성능을 향상시키는 것을 넘어, 기존의 개별적인 AI 기능들을 통합하고 시너지를 창출하는 핵심적인 요소로 부상하고 있습니다.

**추론 모델, 일상과 업무의 혁신 도구**: Windsurf와 같은 플랫폼에서 추론 모델을 적극적으로 활용하고 있는 노암 박사는 사용자들에게 다음과 같은 '프로 팁'을 전했습니다: “놀랍게도, O3와 같은 추론 모델의 존재 자체를 모르는 사람들이 아직도 많습니다. 저 자신은 O3를 매일 사용하고 있으며, 이제는 제게 구글 검색을 사실상 대체했습니다. 코딩 작업을 할 때도 저는 주로 추론 모델을 활용합니다. 아직 추론 모델을 경험해보지 못한 분들께 강력히 권해드립니다. 솔직히, 한번 사용해 본 사람들은 모두 그 매력에 빠져듭니다. 물론 GPT-4.0과 ChatGPT의 기본 설정을 사용하는 사람들이 훨씬 많지만, 추론 모델을 시도해 본다면 그 능력에 분명 놀라실 겁니다.” 이러한 언급은 최신 추론 모델이 단순한 기술적 진보를 넘어, 사용자 경험과 생산성에 실질적인 변화를 가져오고 있음을 보여줍니다. 노암 박사는 코덱스(CodeX)와 같은 AI 코딩 도구를 사용하며 "AGI를 여러 번 느꼈다"고 표현했는데, 이는 인공지능이 인간의 기대치를 뛰어넘는 순간들을 의미합니다. 그는 소라(Sora)의 초기 발표 당시 사람들이 느꼈던 경이로움이 시간이 지나면서 익숙함으로 바뀌고, 결국 더 높은 기준을 요구하게 되는 현상을 언급하며, 인공지능 기술의 발전 속도와 인간의 적응력이 얼마나 빠른지를 설명했습니다. "몇 달마다 새로운 기술이 등장하여 AGI를 느끼게 하고, 우리는 또다시 빠르게 익숙해진다"는 그의 말은 인공지능 분야의 끊임없는 혁신과 사용자 경험의 진화를 압축적으로 보여줍니다.

### 테스트 시간 컴퓨팅 확장성의 이중적 난관

인공지능 모델이 더 깊이 사고하도록, 예를 들어 3분에서 3시간, 나아가 며칠 또는 몇 주 동안 추론하게 만드는 것은 분명 강력한 잠재력을 지닙니다. 그러나 노암 박사는 이러한 테스트 시간 컴퓨팅의 확장에는 두 가지 핵심적인 제약이 따른다고 지적했습니다:
첫째, **비용 증가의 문제**입니다. 모델의 사고 시간을 늘리거나 테스트 시간 컴퓨팅의 규모를 키울수록 운영 비용이 기하급수적으로 증가합니다. 이는 결국 경제적으로 감당 가능한 지출의 한계에 부딪힐 수 있음을 의미합니다. 물론 모델 자체의 사고 효율성이 지속적으로 개선되어 동일한 컴퓨팅 자원으로 더 많은 작업을 수행할 수 있게 되는 점은 고무적입니다. 하지만 이러한 효율성 증가는 모델을 단순히 '더 오래 생각하게 만드는 것' 이상의 의미를 가지며, 그 중요성이 종종 과소평가되곤 합니다.
둘째, **실제 시간(wall-clock time) 병목 현상**입니다. 모델이 즉각적으로 응답할 때는 실험을 빠르게 반복하고 결과를 평가하기 용이합니다. 하지만 모델이 응답하는 데 3시간이 걸리거나 심지어 3주가 소요된다면, 연구 개발의 반복 주기와 평가에 필요한 시간이 대폭 늘어나게 됩니다. 비록 일부 실험은 병렬화가 가능하지만, 많은 경우 하나의 실험이 완전히 종료되어야만 다음 단계의 결정을 내릴 수 있습니다. 이러한 시간 제약은 특히 신약 개발과 같이 장기적인 검증이 필요한 분야에서 심각한 병목 현상을 초래할 수 있으며, 이는 인공지능 발전의 전반적인 타임라인에 큰 영향을 미칠 수 있습니다.

이러한 난관을 극복하기 위한 연구는 활발히 진행 중입니다. 효율적인 알고리즘 개발을 통해 모델의 사고 과정을 최적화하고, 분산 컴퓨팅(distributed computing) 기술을 활용하여 대규모 테스트 시간 컴퓨팅을 효율적으로 분배하는 방안이 모색되고 있습니다. 또한, 특정 연산에 최적화된 특수 하드웨어(ASIC)의 발전은 이러한 병목 현상을 완화하는 데 중요한 역할을 할 것으로 기대됩니다. 궁극적으로는 컴퓨팅 비용을 절감하고 연구 주기를 단축할 수 있는 혁신적인 접근 방식이 요구됩니다.

### 다중 에이전트에 대하여

최근 Cognition이 "다중 에이전트를 만들지 말라"고 주장하고 Anthropic이 "다중 에이전트를 만드는 방법"을 제시하는 등, 다중 에이전트(Multi-Agents)에 대한 논의가 뜨겁습니다. 이러한 논쟁 속에서 노암 브라운 박사는 OpenAI의 다중 에이전트 팀을 이끌고 있으며, 그의 팀은 단순한 다중 에이전트 연구를 넘어선 광범위한 목표를 추구하고 있음을 밝혔습니다: “저희 팀의 이름은 사실 오해의 소지가 있습니다. 저희는 다중 에이전트 연구 외에도 훨씬 더 많은 것을 다루고 있기 때문입니다. 핵심 목표 중 하나는 테스트 시간 컴퓨팅(test time compute)의 규모를 엄청나게 확장하는 것입니다. 현재 모델들이 15분 정도 사고할 수 있다면, 이를 몇 시간, 며칠, 나아가 그 이상으로 늘려 극도로 복잡한 문제들을 해결할 수 있도록 하는 것이죠. 다중 에이전트 연구는 또 다른 중요한 방향이며, 우리는 협력적 측면과 경쟁적 측면 모두에 주목하고 있습니다.” 노암 박사는 인간 지능의 범주가 일반적으로 인식하는 것보다 훨씬 넓다고 주장합니다. 원시 시대의 인간과 현대 인류가 해부학적으로 동일하더라도 문명의 발전 수준에서 엄청난 차이를 보이는 것은, 수천 년에 걸쳐 수십억의 인간이 서로 협력하고 경쟁하며 지식을 축적하고 문명을 건설한 결과라는 것입니다. 그는 이러한 관점을 AI에 적용하여, "오늘날의 AI는 AI 문명의 초기 단계에 있는 '원시인'과 같다"고 비유했습니다. 만약 수십억의 AI 에이전트가 오랜 시간 동안 협력하고 경쟁하며 'AI 문명'을 구축할 수 있다면, 현재 AI로는 상상조차 할 수 없는 수준의 결과물과 해결책을 창출할 수 있을 것이라는 비전을 제시했습니다. 이러한 'AI 문명' 가설은 다중 에이전트 시스템이 단순히 게임 환경을 넘어 과학적 발견, 복잡한 엔지니어링 문제 해결, 심지어는 사회 시스템 최적화와 같은 광범위한 영역에서 혁신을 가져올 수 있음을 시사합니다. 각 에이전트가 특정 전문성을 가지고 상호작용하며 문제를 분해하고 해결하는 과정은, 마치 인간 사회의 전문가 집단이 협력하는 방식과 유사하게 작동할 수 있습니다. 이는 AI의 능력을 개별 모델의 한계를 넘어선 집단 지능의 형태로 확장하려는 시도입니다.

### 비터 레슨에 대하여

**다중 에이전트 연구의 '비터 레슨'**: 노암 박사는 다중 에이전트 분야에서의 접근 방식에 대해 다음과 같이 설명했습니다: “저희가 다중 에이전트 연구에 접근하는 방식과 실제 진행 과정은 역사적으로나 현재 다른 연구소에서 진행되는 방식과는 상당히 다릅니다. 저는 이 분야에 오랫동안 몸담아 왔는데, 그동안 많은 접근 방식들이 지나치게 휴리스틱(heuristic)에 의존했으며, '비터 레슨(Bitter Lesson)'이 강조하는 스케일링 중심의 연구 방향을 제대로 따르지 못했다고 생각합니다.”

**'비터 레슨'과 암묵적 월드 모델**: 얀 르쿤(Yann LeCun)과 같은 학자들이 강조하는 '월드 모델(World Models)'의 필요성에 대해, 노암 박사는 스케일링의 관점에서 다른 견해를 제시합니다: “모델의 규모가 커질수록, 그들은 암묵적으로 월드 모델을 형성하며 그 모델의 완성도 또한 높아집니다. 저는 이러한 월드 모델을 명시적으로 구축할 필요가 없다고 생각합니다.” 그는 오랫동안 다중 에이전트 AI 커뮤니티에서 논의되어 온 '다른 에이전트를 명시적으로 모델링해야 하는가, 아니면 환경의 일부로 암묵적으로 다룰 수 있는가'라는 질문에 대해, 과거에는 명시적 모델링이 필수적이라고 생각했지만, 지금은 생각이 바뀌었다고 말했습니다. 충분히 지능적인 모델은 스케일 확장과 함께 '마음 이론(theory of mind)'과 같이 다른 에이전트의 행동과 동기를 이해하는 능력을 암묵적으로 개발한다는 것입니다. 이는 복잡한 외부 세계나 다른 주체에 대한 이해가 모델의 본질적인 능력 향상과 함께 자연스럽게 발현된다는 '비터 레슨'의 철학을 반영합니다.

### 개방성, 다중 에이전트, 그리고 자가 대국 결합하기

**2인 제로섬 게임을 넘어서는 자가 대국(Self-Play)의 도전**: OpenAI의 '약한 것에서 강한 것으로(Weak to Strong)' 문제와 GDM의 팀 록타쉘(Tim Rocktaschel)이 ICLR에서 제시한 개방성(Open-Endedness)에 대한 논의는 다중 에이전트 시스템이 인간의 능력을 뛰어넘어 스케일링하는 방식에 대한 중요한 질문을 던집니다. 특히, AI가 인간의 훈련이나 지시보다 자가 대국을 통해 경쟁적으로 발전하는 것이 더 효과적이라는 일관된 연구 결과는 알파제로(AlphaZero)와 같은 성공 사례를 통해 입증되었습니다. 노암 박사는 이러한 자가 대국 패러다임이 초지능 달성의 최종 단계로 여겨지는 경향이 있음을 인정하면서도, 그 적용 범위에는 중요한 한계가 있음을 강조했습니다. 알파고의 성공 경로가 대규모 사전 훈련, 대규모 테스트 시간 컴퓨팅(추론 모델), 그리고 최종적으로 자가 대국으로 이어졌고, 이를 통해 인간의 이해를 뛰어넘는 바둑 및 체스 실력을 갖추게 되었지만, 언어 모델에서는 아직 이러한 자가 대국 단계가 명확히 구현되지 않았다는 것입니다. 그는 많은 이들이 언어 모델도 상호작용과 학습을 통해 초지능에 도달할 것이라 기대하지만, **핵심적인 도전 과제는 바둑이나 체스가 2인 제로섬 게임(two-player zero-sum game)이라는 점**에 있다고 지적했습니다. 이러한 게임에서는 자가 대국을 통해 최소최대 균형(minimax equilibrium)에 수렴하는 특성이 있어, 기대값에서 상대에게 지지 않는 최적의 전략(GTO 정책)을 보장합니다. 그러나 포커와 같이 약한 상대를 착취하는 전략(exploitative policy)이 더 큰 이득을 가져올 수 있는 게임이나 수학 문제 해결과 같은 2인 제로섬이 아닌 복잡한 환경에서는 이러한 방어적인 최소최대 정책이 항상 유용하지 않으며, 오히려 이상한 행동으로 이어질 수 있습니다. 즉, 알파고의 성공 모델이 모든 AI 분야에 그대로 적용될 수는 없으며, 비제로섬 환경에서의 자가 대국은 훨씬 더 복잡하고 미묘한 문제라는 것이 노암 박사의 설명입니다. 이러한 자가 대국 패러다임의 한계는 언어 모델과 같은 비제로섬 환경에서 새로운 형태의 학습 메커니즘이 필요함을 시사합니다. 단순한 경쟁적 대결을 넘어, 모델 스스로 자신의 사고 과정을 성찰하고(self-reflection), 내부적으로 다양한 에이전트가 협력하며 문제를 해결하는 협력적 자가 대국(cooperative self-play), 또는 인간의 피드백을 지속적으로 반영하는 Human-in-the-loop 방식 등이 대안으로 모색될 수 있습니다. 이는 AI가 복잡하고 개방적인 실제 세계 문제를 해결하기 위해 필수적인 단계가 될 것입니다.

### 게임에 대하여

포커에서 모두를 이기는 것부터, LLM으로 세계 디플로머시(Diplomacy) 상위 10%에 드는 것, 그리고 개인적으로 세계 디플로머시 챔피언십에서 우승하는 것까지, 게임은 노암 박사의 생각과 경력에서 큰 부분을 차지합니다. 특히 그는 **불완전 정보 게임(imperfect information games)** 분야의 선구적인 연구자입니다. 그는 자신의 연구 경험을 바탕으로 다음과 같이 설명했습니다: “저는 불완전 정보 게임 AI에 대한 방대한 지식을 가지고 있습니다. 이 분야는 오랫동안 제 주요 연구 영역이었고, 저는 많은 것을 알고 있지만 자주 논할 기회는 없었습니다. 저희는 노리밋 텍사스 홀덤(No Limit Texas Hold'em)을 위한 초인적인 포커 AI를 개발했습니다. 흥미로운 점은 텍사스 홀덤의 경우 숨겨진 정보의 양이 비교적 제한적이라는 것입니다. 헤즈업(heads-up) 플레이 기준으로 가능한 카드 조합 상태는 1,326가지이며, 이는 다른 플레이어 수에 따라 곱해지지만 여전히 관리 가능한 수준입니다.” 그러나 그는 숨겨진 가능성, 즉 '상태 공간(state space)'이 기하급수적으로 커질 때 기존 접근 방식이 한계에 부딪힌다고 지적했습니다. 예를 들어, 4장의 숨겨진 카드를 사용하는 오마하 포커(Omaha poker)나 40개의 말을 사용하는 스트라테고(Stratego)와 같이 상태 공간이 40 팩토리얼(40!)에 육박하는 게임에서는 포커에 사용했던 탐색(search) 기반의 접근 방식이 더 이상 유효하지 않습니다. 노암 박사는 이러한 복잡성 앞에서 게임별 휴리스틱(heuristic)을 확장하려는 시도보다는 **매우 일반적인 추론 기술에 집중하는 것이 훨씬 더 가치 있다**고 강조했습니다. 그는 이러한 범용 추론 기술이 발전하면, 언젠가 매직 더 개더링(Magic the Gathering)과 같은 극도로 복잡한 게임도 별도의 학습 없이 초인적인 수준으로 플레이할 수 있는 모델이 탄생할 것이라고 전망하며, 이것이 더 중요하고 인상적인 연구 방향이라고 역설했습니다. 이러한 관점은 '일반 게임 플레이(General Game Playing)'라는 AI 연구 분야의 궁극적인 목표와도 맞닿아 있습니다. 특정 게임에만 특화된 AI가 아니라, 규칙이 주어지면 어떤 새로운 게임이든 스스로 이해하고 마스터할 수 있는 범용 AI를 지향하는 것입니다. 현재 LLM의 발전은 이러한 목표에 새로운 가능성을 열어주고 있습니다. 언어 이해와 추론 능력을 바탕으로 게임의 규칙과 역학을 해석하고, 이를 통해 효과적인 전략을 스스로 학습하고 생성하는 AI가 등장할 수 있기 때문입니다. 이는 게임이라는 제한된 환경을 넘어, 실제 세계의 복잡한 문제 해결 능력으로 확장될 수 있는 중요한 발판이 될 것입니다.

### AI 개발의 미래와 과제

**AGI 경험과 빠르게 변화하는 기대치**: 노암 박사는 CodeX와 같은 도구를 사용하며 "AGI를 여러 번 느꼈다"고 표현했는데, 이는 인공지능이 인간의 기대치를 뛰어넘는 순간들을 의미합니다. 그는 Sora의 초기 발표 당시 사람들이 느꼈던 경이로움이 시간이 지나면서 익숙함으로 바뀌고, 결국 더 높은 기준을 요구하게 되는 현상을 언급하며, 인공지능 기술의 발전 속도와 인간의 적응력이 얼마나 빠른지를 설명했습니다. "몇 달마다 새로운 기술이 등장하여 AGI를 느끼게 하고, 우리는 또다시 빠르게 익숙해진다"는 그의 말은 인공지능 분야의 끊임없는 혁신과 사용자 경험의 진화를 압축적으로 보여줍니다.

**AI 훈련 파이프라인의 진화: '중간 훈련(Mid-Training)'의 부상**: AI 모델의 개발 과정은 크게 사전 훈련(Pre-training), 중간 훈련(Mid-training), 그리고 사후 훈련(Post-training)으로 나눌 수 있습니다. 노암 박사는 OpenAI 모델의 경우 사용자가 직접 상호작용하는 모델은 항상 중간 훈련과 사후 훈련 단계를 거친 최종 제품이라고 설명합니다. 특히 '중간 훈련'은 사전 훈련된 모델의 광범위한 지식과 능력을 특정 목적에 맞게 더욱 정교하게 다듬는 과정으로, 모델의 유용성과 효율성을 극대화하는 데 필수적입니다. 이 단계는 단순히 모델을 특정 작업에 미세 조정하는 것을 넘어, 모델의 전반적인 행동 양식과 추론 능력을 개선하는 데 중요한 역할을 합니다.

**인간과 AI의 데이터 효율성 격차**: 인공지능 모델이 방대한 데이터로 훈련되는 반면, 인간은 훨씬 적은 샘플로도 빠르게 학습하는 '데이터 효율성(data efficiency)'의 차이는 여전히 중요한 연구 과제입니다. 노암 박사는 이 점을 "가장 중요한 미해결 연구 질문 중 하나"로 꼽으며, 인간이 인터넷 데이터뿐만 아니라 다양한 감각 경험과 상호작용을 통해 학습한다는 점을 지적했습니다. AI의 데이터 효율성을 높이는 것은 단순히 더 많은 데이터를 수집하는 것을 넘어, 새로운 알고리즘 개선과 학습 방식의 혁신을 통해 이루어져야 할 것입니다. 이는 AI가 실제 세계에서 더욱 유연하고 빠르게 적응하는 데 필수적인 요소입니다.

**AI의 미래: 소프트웨어 엔지니어링을 넘어선 원격 작업**: 노암 박사는 AI의 영향력이 소프트웨어 엔지니어링에만 국한되지 않을 것이라고 예측합니다. 그는 AI가 광범위한 '원격 작업(remote work)' 영역의 업무를 수행할 수 있게 될 것이며, 이는 프리랜서 업무나 가상 비서(virtual assistant)와 같은 역할까지 확장될 수 있다고 보았습니다. 특히 가상 비서의 경우, AI가 인간 대리인과 달리 '주인-대리인 문제(principal-agent problem)'에서 자유로울 수 있어, 사용자의 선호도에 완벽하게 정렬된 형태로 업무를 수행할 수 있다는 장점을 강조했습니다. 이는 AI가 단순히 도구를 넘어, 인간의 목표와 가치에 부합하는 '동반자'로서 기능할 수 있는 미래를 시사합니다.

**AI 개발자들을 위한 조언**: 노암 박사는 빠르게 진화하는 AI 분야에서 개발자들이 직면하는 어려움에 대해서도 언급했습니다. 그는 현재 많은 '하네스(harnesses)'나 '라우터(routers)' 같은 솔루션들이 단기적으로 유용하지만, 스케일링을 통해 모델 역량이 급증하면서 결국 대체될 수 있음을 경고했습니다. "6개월 후에 사라질 수도 있는 것을 만드는 데 6개월을 쓰지 말라"는 그의 조언은, AI 개발자들이 단기적인 해결책에 매몰되기보다, 모델 자체의 근본적인 능력 향상과 범용적인 접근 방식에 초점을 맞춰야 함을 강조합니다. 또한, 연구 현황을 파악하기 위해 학술 논문과 업계 동향을 꾸준히 살피고, 흥미로운 아이디어를 내부적으로 재현해보는 노력이 중요하다고 덧붙였습니다.