AI 발전의 매 순간은 핵심적인 확장 개념에 의해 주도되어 왔습니다. 무어의 법칙이 황의 법칙(반도체 기술)으로 대체되고, 캐플런(Kaplan) 등의 연구가 호프만(Hoffman) 등의 연구(데이터 활용)로 진화했으며, 알렉스넷(AlexNet)은 딥러닝과 머신러닝을 위한 그래픽 처리 장치(GPU) 혁명(사전 학습)의 기폭제가 되었습니다. o1 공개를 통해 명확히 드러났듯이, 그리고 뒤이어 딥시크(DeepSeek), 앤스로픽(Anthropic), GDM이 연이어 발표되면서, 현재는 추론에 필요한 연산 자원을 극대화하는 시대로 접어들었습니다. “이는 2022년의 초기 친칠라 스케일링 법칙(Chinchilla scaling law) 이후 대규모 언어 모델(LLM) 연구에서 가장 중요한 지표일 수 있습니다.” — 짐 팬(Jim Fan) 노암 브라운(Noam Brown)은 사고(reasoning) 분야에서 세계 최고 수준의 연구자 중 한 명으로(o1 출시 영상과 o1 시스템 카드에 공동으로 기여했습니다), TED 강연, OpenAI 영상, 그리고 세계 유수의 AI 팟캐스트에서 그의 목소리를 들으셨을 것입니다. 그가 AI 엔지니어 청중을 위해 깊이 있는 이야기를 나누고자 시간을 내어 저희 팟캐스트에 참여해 주신 것을 영광으로 생각합니다. 이제 그의 업적에 대한 찬사는 잠시 멈추고, 오늘 팟캐스트의 주요 내용을 바로 살펴보겠습니다. 다음은 저희가 정리한 내용입니다.

### 사고 역량에 대하여

**사고 역량은 점진적으로 나타나는 특성을 지닙니다(emergent)**: 비사고 모델과 사고 모델을 구분하는 "빠르게 생각하기, 느리게 생각하기(Thinking Fast and Slow)"라는 저서에서 다루는 시스템 1(System 1)과 시스템 2(System 2) 방식의 인지 처리 모델, 그리고 적은 양의 추론 계산(test time compute)이 수천 배에서 수만 배에 달하는 거대한 모델 크기(model size)와 맞먹는다는 불균형적 특성은 이제 널리 알려져 있습니다. 그러나 **덜** 부각되는 사실은, 이러한 현상이 GPT-4 버전에 와서야 비로소 구현될 수 있었다는 점입니다. 짐 팬이 언급했듯이, **두 가지 측면 모두에서 확장이 이루어져야 합니다**.

“제가 생각하기에 과소평가된 한 가지는, 모델, 즉 사전 훈련된 모델이 이러한 심층적 사고 과정으로부터 실질적인 이점을 얻기 위해서는 특정 수준의 기본 능력을 갖추어야 한다는 것입니다. 바로 이러한 이유 때문에 추론 패러다임이 그 시점에 이르러서야 나타나게 된 것입니다. 물론 더 일찍 발현될 수도 있었겠지만, 만약 GPT-2 수준의 모델에 추론 패러다임을 적용하려고 시도했다면, 아마도 거의 아무런 성과도 얻지 못했을 것이라고 생각합니다… 비둘기에게 체스 두는 법을 아무리 열심히 생각하라고 해도, 큰 진전을 보이지 못할 것입니다. 천 년을 생각한다 한들 체스를 더 잘 두게 되지는 않을 겁니다. 따라서 동물이나 인간의 경우에도, 시스템 2의 이점을 충분히 활용하기 위해서는 시스템 1 차원에서 특정 수준의 지적 기반이 필수적이라고 할 수 있습니다.”

GPT-3 이후, 2021년에 일리야(Ilya)가 추론 계산 능력을 탐구하기 위해 GPT-Zero라는 가칭의 프로젝트를 진행했다는 소문은 널리 알려져 있지 않으며(또한 공식적으로 확인되지도 않습니다). 팟캐스트에서 놀라웠던 점 중 하나는, 사실 일리야가 노암에게 자신이 생각했던 것보다 추론형 대규모 언어 모델(LLM)이 훨씬 더 현실에 가깝다고 설득했다는 것입니다. 노암의 생각이 바뀐 것이죠.

“…만약 우리가 이 모델들을 훈련하는 데 천조 달러의 자금이 있었다면, 아마 그렇게 했을 겁니다. 하지만 추론 패러다임이 없다면, 초지능에 도달하기 전에 경제적으로 실현 가능한 한계에 부딪히게 될 것입니다. 그리고 저는 추론 패러다임을 개발하는 데 오랜 시간이 걸릴 것이라고 잘못 확신하고 있었습니다. 왜냐하면 그것은 거대한 미해결 연구 과제였기 때문입니다. 일리야는 저의 의견에 동의하며 이 추가적인 패러다임이 필요하다고 말했지만, 그의 견해는 **어쩌면 생각보다 어렵지 않을 수도 있다**는 것이었습니다.”

(아직 검증되지 않은) 가설은 GPT-3에서 o1으로 직접 도약하는 것은 불가능했으며, GPT-4와 4o가 먼저 기준점으로서 필요했다는 것입니다.

**합리적 사고는 시스템 정렬(alignment)에 기여합니다**. 안전성(Safety), 조종 가능성(steerability), 그리고 시스템 정렬은 AI 커뮤니티의 특정 분야에서 매우 중요한 의제이며, 놀랍게도 사고 역량(reasoning)이 여기에 도움이 됩니다.

“저희가 Cicero를 공개했을 때, 많은 AI 안전 커뮤니티가 그 연구와 그 작동 방식에 크게 만족했습니다. 이는 매우 제어 가능한 시스템이었기 때문입니다. 저희는 Cicero가 특정 구체적인 행동에 조건화되도록 설계했고, 이를 통해 '이 시스템은 우리가 명확하게 해석할 수 있는 행동을 추구할 것이다'라고 말할 수 있는 높은 수준의 조종 가능성(steerability)을 확보했습니다. 즉, 이것은 단순히 언어 모델이 제멋대로 작동하는 것이 아니라, 실제로는 상당히 조종 가능하며, 언어 모델이 인간과 상호 작용하는 방식을 통제하는 전체 사고 시스템이 존재한다는 것을 명확히 정의했습니다. 실제로 많은 연구자들이 제게 연락하여 '이것이 이러한 시스템의 안전성을 확보하는 데 잠재적으로 매우 효과적인 방법이라고 생각한다'고 말했습니다.”

**사고 역량은 확인 가능한 보상 체계(verifiable rewards)를 넘어선 영역까지 적용됩니다**. 강화 학습(RL) 기반 시스템에 대한 비판 중 하나는 수학 및 코딩 분야에서만 모델 성능을 향상시킨다는 것입니다. 이에 대해 노암은 다음과 같이 답변합니다.

“저희가 Deep Research를 출시했고 많은 사람들이 직접 사용하며 매우 인기를 얻고 있다는 점에서, 이것이 그렇게 일반적인 인식이라는 사실에 놀랐습니다. Deep Research는 성공 여부를 쉽게 검증할 수 있는 명확한 지표가 없는 영역임이 분명합니다… 그럼에도 불구하고 이 모델들은 해당 영역에서 놀라운 성과를 보여주고 있습니다. 따라서 저는 이것이 모델들이 쉽게 검증 가능한 보상이 없는 작업에서도 성공할 수 있음을 입증하는 강력한 증거(existence proof)라고 생각합니다.”

**시각 정보를 활용한 추론 능력에도 제한이 존재합니다**. O3가 마스터 수준의 GeoGuessr 플레이어를 능가한다는 소식에 많은 기대가 있었지만, 여기에도 한계는 있습니다.

“이는 당신이 어떤 종류의 질문을 하는지에 따라 정확히 달라집니다. 시스템 2의 이점을 크게 얻지 못하는 질문들도 있다고 생각합니다. GeoGuessr는 확실히 이점을 얻는 경우 중 하나입니다… 제가 주로 언급하는 것은 정보 검색(information retrieval)입니다. 만약 누군가 당신에게 '이 사람이 언제 태어났나요?'라고 묻고 웹에 접근할 수 없다면, 당신은 그 정보를 알거나 모르는 둘 중 하나입니다. 앉아서 오랫동안 고민해 볼 수는 있겠죠. 아마도 교육받은 추측을 할 수도 있을 겁니다… 하지만 실제로 그 정보를 알지 못하는 한 정확한 날짜를 알아낼 수는 없을 것입니다.”

**사고 역량은 OpenAI 내부의 회의론자들에게 저평가되었지만, 데이터 포화 상태(Data Wall)에 직면하면서 자연스레 부각되었습니다**.

“무엇보다 그 추가적인 패러다임이 무엇인지에 대한 많은 논의가 있었습니다. 많은 연구자들이 사고 역량과 강화 학습(RL)을 주목했지만, 그것은 추론 계산(test time compute)의 확장에 관한 것이 아니었습니다. 오히려 데이터 효율성(data efficiency)에 더 초점을 맞추고 있었습니다. 왜냐하면, 아시다시피, 우리는 엄청난 양의 컴퓨팅 자원을 보유하고 있지만, 실제로는 데이터에 의해 더 크게 제약받고 있다는 인식이 있었기 때문입니다. 따라서 데이터 포화 상태가 존재하며, 우리는 컴퓨팅의 한계에 도달하기 전에 이 데이터 장벽에 부딪힐 것이라는 생각이었습니다. 그렇다면 어떻게 이러한 알고리즘들을 더 데이터 효율적으로 만들 수 있을까요? 물론 그들은 더 데이터 효율적이지만, 제 생각에는 그것들이 또한 컴퓨팅 자원을 엄청나게 확장하는 것과 동등한 효과를 낸다고 봅니다… 그리고 제가 기억하기에 흥미로웠던 것은, 우리가 사고 패러다임을 발견한 후, 하지만 o1을 발표하기 전에 OpenAI를 떠나 경쟁 연구소로 이직한 사람과 대화한 것입니다. 발표 후에 그를 만났을 때, 그는 당시에는 그 스트로베리 모델(strawberry models)들이 그렇게 대단한 것이라고 생각하지 않았다고 말했습니다. 그는 우리가 실제보다 더 과장하고 있다고 생각했다는 겁니다. 그러다가 우리가 o1을 발표하고, 그가 경쟁 연구소의 동료들이 '이것은 대단한 일이다'라고 반응하는 것을 보았을 때… 그들은 전체 연구 의제를 이것에 집중하도록 전환했습니다… 이 모든 것이 돌이켜보면 명백해 보이지만, 당시에는 실제로는 그렇게 명백하지 않았고, 어떤 것을 있는 그대로 인식하기가 상당히 어려울 수 있습니다.”

**사고 역량 + 윈드서프(Windsurf) = 인공 일반 지능(AGI)을 체감하다.**

Q: 윈드서프에 깊이 몰두해 보셨으니, 전문가 팁이 있나요?
A: 제가 놀란 것 중 하나는 얼마나 많은 사람들이 O3의 존재조차 모른다는 것입니다. 저는 매일 사용하고 있습니다. **일상적으로 구글 검색 엔진의 역할을 대체했습니다**. 그냥 항상 사용합니다. 그리고 코딩 같은 작업에도 **저는 주로 사고 모델을 활용하는 경향이 있습니다**. 제 제안은, 아직 사고 모델을 사용해보지 않은 분들이 있다면, 솔직히, 사람들은 그것들을 정말 좋아합니다. 사용하는 사람들은 그것들에 매료됩니다. 물론, 훨씬 더 많은 사람들이 GPT-4.0과 ChatGPT의 기본 설정을 사용합니다. 하지만 저는 사고 모델을 시도해 볼 가치가 있다고 생각합니다. 사람들은 그것들이 할 수 있는 능력에 놀랄 것입니다.”

### 추론 계산(Test Time Compute)의 스케일링 과제 2

“우리는 모델들이 3분 대신 3시간, 그리고 3일, 3주 동안 사고하도록 만들 것입니다. 여기에는 두 가지 우려가 있습니다. 첫째, 모델들이 그렇게 오랜 시간 사고하거나 추론 계산을 확장하는 데 드는 비용이 훨씬 더 증가한다는 점입니다. 추론 계산을 확장할수록, 더 많은 비용을 지출하게 되며, 이는 지출할 수 있는 금액에 한계가 있다는 것을 의미합니다. 이는 하나의 잠재적 상한선으로 작용합니다. 물론, 이 모델들은 사고 과정에서 점점 더 효율적이 되고 있어서, 동일한 양의 추론 계산으로도 더 많은 성과를 낼 수 있게 되었다는 점은 강조할 필요가 있습니다. 그리고 저는 이것이 매우 과소평가된 부분이라고 생각합니다. 우리가 단지 이 모델들을 더 오래 사고하도록 만드는 것만이 아니라는 점이죠. 두 번째 요점은, 이 모델들이 더 오랫동안 사고하게 할수록, 실제 경과 시간(wall-clock time)에 의해 제약이 발생한다는 점입니다. 모델들이 즉시 응답할 때는 실험을 반복하기가 정말 쉽습니다. 그들이 응답하는 데 3시간이 걸릴 때는 훨씬 더 어렵습니다. 그리고 3주가 걸리면 어떻게 될까요? 그 평가를 수행하고 그 결과를 바탕으로 반복하는 데 최소 3주가 걸립니다. 이 중 많은 부분에서 실험을 어느 정도 병렬화할 수 있지만, 상당 부분은 실험을 실행하고 완료한 다음 결과를 확인해야만 다음 실험 세트를 결정할 수 있습니다. 저는 이것이 사실 장기적인 타임라인(long timelines)에 대한 가장 강력한 근거라고 생각합니다. 모델들이 처리해야 할 일이 너무 많기 때문입니다. 그리고 저는 그것이 도메인에 따라 다르다고 생각합니다. 신약 개발은 이러한 제약이 현실적인 병목 현상이 될 수 있는 한 분야라고 생각합니다. 예를 들어, 어떤 물질이 인간의 수명을 연장하는지 확인하려면, 당신이 개발한 새로운 약이 실제로 인간의 수명을 연장하고 그 과정에서 끔찍한 부작용이 없는지 알아내는 데 오랜 시간이 걸릴 것입니다.”

다른 전문가들도 장기 강화 학습(long horizon RL)을 위한 데이터 확보가 사람들이 생각하는 것보다 더 요원하다고 보았습니다. 그럼에도 불구하고, 추론 계산 확장 시대는 오리온(Orion)이 12월 SG1이 가동될 때까지 컴퓨팅 자원을 최대한 활용한 것으로 추정되는 바로 지금, 그 어느 때보다 적절한(혹은 일찍) 도래했습니다.

### 다수 에이전트(Multi-Agents)에 대하여

최근 다수 에이전트(Multi-Agents)에 대한 논의가 활발합니다. 코그니션(Cognition)은 **다수 에이전트를 구축하지 말라**고 주장하고 앤스로픽(Anthropic)은 **다수 에이전트 구축 방법**을 제시합니다. 이 논쟁에 대해 **수많은**, **다양한** 의견이 오갔지만, 노암은 수년간 다수 에이전트 강화 학습(RL)을 연구해 왔으며 OpenAI에서 다수 에이전트 연구 조직을 출범시켰습니다… 비록 그것이 여러 가능한 연구 방향 중 가장 널리 알려진 것일 뿐이지만요…

“저는 팀 이름이 여러 면에서 사실은 오해의 소지가 있다고 생각합니다. 왜냐하면 우리는 다수 에이전트 외에도 더 많은 것을 연구하고 있기 때문입니다. 다수 에이전트는 우리가 다루는 주제 중 하나일 뿐입니다. 우리가 집중하는 다른 영역 중 일부는 추론 계산(test time compute)을 엄청나게 확장하는 것입니다. 예를 들어, 현재 모델들이 15분 동안 사고하도록 만들고 있는데, 어떻게 하면 몇 시간, 며칠, 심지어 그 이상 사고하게 할 수 있을까요? 그리고 이를 통해 믿을 수 없을 정도로 어려운 문제들을 해결할 수 있게 할까요? 이것이 우리가 추구하는 한 방향입니다. 다수 에이전트는 또 다른 방향입니다. 그리고 여기에는 몇 가지 다른 동기가 있다고 생각합니다. 우리는 다수 에이전트의 협력적 측면과 경쟁적 측면 모두에 관심을 가지고 있습니다. 제가 설명하는 방식은 이렇습니다. AI 분야에서 사람들은 종종 인간이 매우 좁은 지능의 범위를 차지하고 있으며, AI는 빠르게 따라잡아 이 지능의 범위를 넘어설 것이라고 말합니다. 하지만 저는 사실 인간 지능의 범위가 그렇게 좁다고 생각하지 않습니다. 오히려 상당히 넓다고 봅니다. 예를 들어, 해부학적으로 동일한 원시 시대의 인간들을 수많은, 수십억 명의 인간들이 서로 협력하고 경쟁하며 시간이 흐름에 따라 문명을 구축한 결과와 비교해 보십시오. 오늘날 우리가 보는 기술은 바로 이 문명의 산물입니다. 그리고 저는 비슷하게, 오늘날 우리가 가진 AI는 일종의 AI 초기 단계에 불과하다고 생각합니다. 만약 수십억 개의 AI가 오랜 시간 동안 서로 협력하고 경쟁하며 본질적으로 문명을 구축할 수 있다면, 그들이 생산하고 답할 수 있는 것들은 오늘날 우리가 가진 AI로는 상상할 수 없는 수준을 훨씬 뛰어넘을 것입니다.”

### 비터 레슨(Bitter Lesson)에 대하여

**다수 에이전트 분야에서의 비터 레슨**: “…우리가 다수 에이전트에 접근하는 방식과 세부적인 실행 방식은, 역사적으로 이루어져 왔고 오늘날 다른 곳에서 이루어지고 있는 방식과는 매우 다르다고 생각합니다. 저는 오랫동안 다수 에이전트 분야에 몸담았습니다… 제 생각에는 그동안 채택된 많은 접근 방식이 경험적 규칙(heuristic)에 기반한 것이 주를 이루었으며, 확장 및 연구 방법론에 대한 '비터 레슨' 원칙을 제대로 준수하지 못했다고 봅니다.”

**비터 레슨 vs 월드 모델(World Models) & 얀 르쿤(Yann LeCun)**: “…모델들이 커질수록 암묵적인 월드 모델을 형성하고, 그 월드 모델은 규모가 커질수록 더욱 정교해진다는 것은 꽤 명백하다고 생각합니다. 따라서 모델들은 내재적으로 월드 모델을 개발하며, 저는 그것을 구체적으로 모형화할 필요가 없다고 판단합니다… 다수 에이전트 AI 커뮤니티에서는 오랫동안, 그리고 여전히 진행 중인 긴 논쟁이 있었습니다. 다른 에이전트, 즉 다른 사람들을 명시적으로 모델링해야 하는지, 아니면 환경의 일부로서 암묵적으로 모델링될 수 있는지에 대한 것이죠. 오랫동안 저는 '물론 이 다른 에이전트들을 명시적으로 모델링해야 한다'는 관점을 가졌습니다. 왜냐하면 그들은 환경과 다르게 행동하고, 행동을 취하며, 예측 불가능하고, 행위성(agency)을 가지고 있기 때문입니다. 하지만 저는 시간이 지남에 따라 생각이 바뀌어, 사실 이 모델들이 충분히 똑똑해지면, 그들은 인지 이론 중 하나인 '마음 이론(theory of mind)'과 유사한 능력을 발달시킨다고 생각하게 되었습니다. 그들은 자신들이… 행동을 취하고 동기를 가질 수 있는 에이전트라는 이해를 발전시킵니다. 그리고 이러한 모델들은 규모와 더 강력한 행동을 통해 암묵적으로 그러한 능력을 개발합니다. 따라서, 이것이 제가 요즘 취하는 관점입니다.”

**개방성(Open-Endedness), 다수 에이전트, 그리고 자가 대국(Self-Play)의 결합**: OpenAI는 **약한 것에서 강한 것으로(Weak to Strong)** 문제에 대해 논의했으며, GDM의 개방성 책임자인 팀 록타쉘(Tim Rocktaschel)은 싱가포르 ICLR에서 매우 호평받은 기조연설을 했습니다(전체 영상은 여기). 이는 다수 에이전트가 인간의 능력을 넘어서는 확장(비터 레슨의 궁극적인 한계점) 사이의 관계에 대한 질문으로 이어졌습니다.

“Q: 가장 일관된 발견 중 하나는 항상 AI가 인간의 훈련과 지시를 받는 것보다 경쟁적으로 자가 대국(self-play)을 통해 스스로 개선하는 것이 더 효과적이라는 것입니다. 알파제로(AlphaZero)와 R1 제로에서 이를 확인할 수 있습니다. 이것이 다수 에이전트 시스템에서도 유효할 것이라고 생각하십니까? 즉, 인간보다 더 나은 개선을 위해 자가 대국이 가능할까요?

A: 네, 이것은 훌륭한 질문입니다. 그리고… 이 질문에 대해 좀 더 자세히 설명할 가치가 있다고 생각합니다. 오늘날 많은 사람들이 자가 대국을 초지능을 향한 다음 단계이자 아마도 마지막 단계로 보고 있다고 생각합니다. 알파고(AlphaGo)와 알파제로 같은 사례를 보면, 우리는 매우 유사한 추세를 따르고 있는 것 같습니다, 그렇죠? 알파고의 첫 단계는 대규모 사전 훈련(pre-training)이었습니다. 그 당시에는 인간의 바둑 기보를 사용했죠. 대규모 언어 모델(LLM)의 경우, 방대한 인터넷 데이터로 사전 훈련을 합니다. 그리고 그것은 강력한 모델을 만들어주지만… 초인적인 모델은 아닙니다. 그리고 알파고 패러다임의 다음 단계는 대규모 추론 계산(inference compute) 또는 대규모 테스트 시간 컴퓨팅을 수행하는 것입니다. 그 경우에는 몬테카를로 트리 탐색(MCTS)을 사용했습니다. 그리고 이제 우리는 이러한 대규모 추론 계산을 수행하는 사고 모델들을 가지고 있습니다. 그리고 다시, 그것은 능력을 엄청나게 향상시킵니다. 마지막으로, 알파고와 알파제로에는 자가 대국이 있습니다. 모델이 자신과 대결하고, 그 게임들로부터 배우고, 점점 더 나아져서, 인간 수준의 성능에서 인간의 능력을 훨씬 뛰어넘는 수준으로 발전합니다. 이 바둑 정책들은 이제 너무 강력해서 인간으로서는 이해하기조차 어렵습니다. 그들이 하는 일은 인간에게는 이해할 수 없습니다. 체스도 마찬가지입니다. 그리고 우리는 지금 언어 모델에서는 그것을 가지고 있지 않습니다. 그래서 그것을 보고 '아, 우리는 이제 이 AI 모델들이 서로 상호작용하고 그들로부터 배우게 하기만 하면, 그들은 그냥 초지능에 도달할 것이다'라고 말하고 싶은 유혹이 정말 큽니다. … 도전 과제는, 그리고 제가 디플로머시에 대해 이야기할 때 약간 언급했듯이, 바둑이 2인 제로섬 게임(two-player zero-sum game)이라는 것입니다. 그리고 2인 제로섬 게임은 자가 대국을 할 때 최소최대 균형(minimax equilibrium)에 수렴한다는 매우 좋은 속성을 가지고 있습니다. 그리고 한 걸음 물러서서 말하자면, 2인 제로섬 게임, 즉 체스, 바둑, 심지어 2인 포커, 모두 2인 제로섬입니다. 음, 그건 사실이 아닙니다. 당신이 일반적으로 원하는 것은 최소최대 균형이라고 불리는 것입니다. 이것이 그 GTO 정책, 즉 당신이 플레이하는 이 정책으로, 어떤 상대에게도 기대값에서 지지 않을 것을 보장합니다. 저는 체스와 바둑에서는 그것이 꽤 명백하게 당신이 원하는 것이라고 생각합니다. 흥미롭게도, 포커를 보면, 그것은 그렇게 명백하지 않습니다. 2인 제로섬 버전의 포커에서는 GTO 최소최대 정책을 플레이할 수 있고, 그것은 지구상의 어떤 상대에게도 지지 않을 것을 보장합니다. 하지만, 다시 말하지만, 약한 플레이어로부터는 착취적 정책(exploitative policy)을 플레이했을 때만큼 많은 돈을 벌지는 못할 것입니다. 그래서, '당신은 무엇을 원하는가?'라는 질문이 있습니다. 가능한 한 많은 돈을 벌고 싶습니까, 아니면 살아있는 어떤 인간에게도 지지 않을 것을 보장하고 싶습니까? 모든 봇들이 결정한 것은, 음, 이 게임들의 모든 AI 개발자들이 결정한 것은, '음, 우리는 최소최대 정책을 선택할 것이다'입니다. 그리고 편리하게도, 그것이 바로 자가 대국이 수렴하는 것입니다. 이 AI들이 서로 대결하고, 그들의 실수로부터 배우게 하면, 그들은 시간이 지남에 따라 이 최소최대 정책으로 수렴합니다, 보장됩니다. 하지만 일단 2인 제로섬 게임을 벗어나면, 그것은 더 이상 유용한 정책이 아닙니다. 당신은 그냥 이런 매우 방어적인 정책을 가지고 싶지 않을 것이고, 수학 같은 것에서 같은 종류의 자가 대국을 시작하면 정말 이상한 행동을 하게 될 것입니다.”

### 게임 및 전략적 사고에 대하여

포커에서 모든 상대를 이기는 것부터, 대규모 언어 모델(LLM)을 활용하여 세계 디플로머시(Diplomacy) 게임에서 상위 10%에 진입하고, 나아가 개인적으로 세계 디플로머시 챔피언십에서 우승하는 것까지, 게임은 노암의 사고 방식과 경력에서 중요한 위치를 차지합니다. 하지만 그가 다루는 게임은 단순히 오락적인 차원에 머무르지 않습니다.

“…저는 불완전 정보 게임(imperfect information games)을 위한 인공지능(AI)에 대한 방대한 지식을 축적해 왔습니다. 이 분야가 오랫동안 저의 주요 연구 영역이었기 때문입니다. 이 모든 것을 알고 있지만, 자주 이야기할 기회는 많지 않습니다. 저희는 노리밋 텍사스 홀덤(No Limit Texas Hold'em)을 위한 초인적인 포커 AI를 개발했습니다. 이 게임의 흥미로운 점 중 하나는 숨겨진 정보의 양이 실제로는 상당히 제한적이라는 것입니다. 텍사스 홀덤에서는 두 장의 숨겨진 카드를 가지고 플레이하기 때문입니다. 따라서 적어도 헤즈업(heads up) 플레이 시 가능한 상태의 수는 1,326가지입니다. 물론 테이블에 있는 다른 플레이어 수만큼 곱해지지만, 여전히 엄청나게 큰 숫자는 아닙니다… 문제는 숨겨진 가능성의 수, 즉 당신이 처할 수 있는 가능한 상태의 수가 기하급수적으로 늘어남에 따라 기존의 접근 방식이 한계에 부딪힌다는 것입니다. 숨겨진 상태의 수가 극도로 커질 때 무엇을 해야 하는지에 대한 매우 흥미롭고 미해결된 질문이 여전히 남아 있습니다. 예를 들어, 네 장의 숨겨진 카드를 가진 오마하 포커(Omaha poker)로 넘어가면, 상태의 수를 줄이기 위해 할 수 있는 일종의 경험적 규칙(heuristic)이 있지만, 실제로는 여전히 매우 어려운 문제입니다. 그리고 40개의 말을 가진 스트라테고(Stratego)와 같은 게임으로 가면, 거의 40 팩토리얼(40!)에 가까운 다양한 상태가 존재할 수 있습니다. 그러면 우리가 포커에 사용했던 모든 기존 접근 방식이 무너지고 새로운 접근 방식이 필요합니다…. 만약 그러한 기술들을 확장한다면, 스트라테고나 매직 더 개더링(Magic the Gathering) 같은 게임에도 적용될 수 있겠지만, 여전히 한계가 있을 것입니다. 그것들이 언어 모델로 초인적인 코드포스(encode forces) 능력을 제공하지는 않을 것입니다. 따라서 저는 매우 일반적인 추론 기술에 집중하는 것이 더 가치 있다고 생각합니다. 그리고 언젠가 우리가 그러한 기술들을 개선함에 따라, 어느 날 갑자기 초인적인 수준으로 매직 더 개더링을 플레이하는 모델을 갖게 될 것이라고 생각합니다. 그리고 저는 그것이 더 중요하고 더 인상적인 연구 방향이라고 생각합니다.”

**사이드 노트**: 팟캐스트에서 노암이 제안한 대규모 언어 모델(LLM)이 디플로머시 게임을 자가 대국(self-play)하는 챌린지는 바로 그 후에 AIE 월드 페어(AIE World’s Fair)에서 실제로 구현되었습니다 :)

팟캐스트에 노암을 모시게 되어 큰 영광이었고, 여러분이 전체 내용을 들으시면서 더 많은 여담, 정보, 조언을 얻으시길 바랍니다! 저희가 놓친 중요한 내용이 있다면 알려주세요.

### 타임스탬프

00:00 소개 – 디플로머시, Cicero & 세계 챔피언십
02:00 리버스 켄타우로스: AI가 노암의 인간 플레이를 어떻게 향상시켰나
05:00 채팅에서의 튜링 테스트 실패: 환각 & 조종 가능성
07:30 추론 모델 & 빠른 사고 vs. 느린 사고 패러다임
11:00 시각적 과제에서의 시스템 1 vs. 시스템 2 (GeoGuessr, 틱택토)
14:00 검증 불가능한 도메인에 대한 Deep Research의 존재 증명
17:30 AI 에이전트의 하네스, 도구 사용, 그리고 취약성
21:00 스캐폴드와 라우터에 대한 과도한 의존에 반대하는 논거
24:00 강화 미세 조정과 장기적 모델 적응성
28:00 일리야의 추론에 대한 베팅과 O-시리즈의 돌파구
34:00 노암의 개발 스택: Codex, Windsurf & AGI의 순간들
38:00 더 나은 AI 개발자 만들기: 메모리, 재사용, 그리고 PR 리뷰
41:00 다중 에이전트 지능과 "AI 문명" 가설
44:30 스케일링을 통한 암묵적 월드 모델과 마음 이론
48:00 바둑과 체스를 넘어서면 자가 대국이 무너지는 이유
54:00 모호한 과제를 위한 더 나은 벤치마크 설계
57:30 테스트 시간 컴퓨팅의 실제 한계: 비용 vs. 시간
1:00:30 인간과 LLM 간의 데이터 효율성 격차
1:03:00 훈련 파이프라인: 사전 훈련, 중간 훈련, 사후 훈련
1:05:00 연구 시험장으로서의 게임: 포커, MTG, 스트라테고
1:10:00 맺음말 – 5년 후의 전망과 열린 연구 방향

### 녹취록

**Alessio [00:00:04]**: 안녕하세요 여러분, Latent Space 팟캐스트에 오신 것을 환영합니다. 저는 Decibel의 파트너이자 최고 기술 책임자(CTO)인 알레시오(Alessio)입니다. 그리고 SmolAI의 창립자인 제 공동 진행자 스윅스(Swyx)와 함께합니다.

**swyx [00:00:12]**: 안녕하세요, 안녕하세요. 오늘은 휴일인 월요일에 OpenAI의 노암 브라운과 함께 녹음하고 있습니다. 환영합니다. 감사합니다. 드디어 함께하게 되어 정말 기쁩니다. 많은 분들이 당신에 대해 들어보셨을 겁니다. 렉스 프리드먼(Lex Friedman) 팟캐스트에서 시간을 꽤 관대하게 내주셨고, 최근에는 사고 패러다임에 대해 이야기하는 TED 강연도 하셨죠. 하지만 아마도 가장 흥미로운 최근 성과는 세계 디플로머시 챔피언십에서 우승한 것일 겁니다. 네. 2022년에 당신은 인간 플레이어 상위 10%에 드는 Cicero를 만들었죠. 제 첫 질문은, Cicero 작업을 한 이후 그리고 지금 개인적으로 플레이하면서 당신의 디플로머시 플레이는 어떻게 변했나요?

**Noam [00:00:52]**: 이런 게임을 개발할 때는, 봇을 디버깅할 수 있을 만큼 게임을 깊이 이해해야 합니다. 봇이 정말 파격적이고 일반적으로 하지 않을 행동을 했을 때, 그것이 실수인지, 아니면 시스템의 버그인지, 혹은 봇의 탁월한 전략인지 판단하기 어렵기 때문입니다. 디플로머시 작업을 하면서, 저는 게임을 더 잘 이해하기 위해 몰두했습니다. 토너먼트에 참가했고, 게임에 대한 수많은 튜토리얼과 해설 영상을 시청했습니다. 그 과정을 통해 제 실력이 향상되었습니다. 봇이 게임에서 행동하는 방식을 보면서도 많은 것을 배웠습니다. 때로는 인간이 보통 하지 않을 행동을 하기도 했는데, 그것 또한 게임에 대한 저의 이해를 넓혀주었습니다. 2022년 말 Cicero를 출시하고 발표한 후에도, 저는 이 게임이 여전히 매우 매력적이라고 느껴 계속 플레이했습니다. 그 결과 2025년 세계 챔피언십에서 우승할 수 있었습니다.

**swyx [00:01:45]**: 그럼 불과 몇 달 전이네요. 인간과 기계가 협력하는 켄타우로스 시스템(centaur systems) 같은 질문이 항상 있죠. 바둑에서 일어났던 것처럼 당신의 플레이 스타일을 업데이트하는 것과 같은 일이 있었나요?

**Noam [00:01:55]**: 만약 제가 토너먼트에서 Cicero를 사용했는지 묻는 것이라면, 대답은 '아니오'입니다. 봇이 플레이하는 방식을 관찰하고 거기서 영감을 얻은 것이 토너먼트에서 저에게 도움이 되었다고 생각합니다. 네. 네.

**swyx [00:02:06]**: 이제 사람들은 디플로머시를 할 때마다 튜링 질문을 하나요? 상대방이 봇인지 사람인지 알아내려고요. 네. 그게 당신이 시작할 때 걱정했던 한 가지잖아요.

**Noam [00:02:19]**: Cicero를 개발할 때 정말 흥미로웠습니다. 당시에는 최고의 언어 모델을 가지고 있지 않았고, 언어 모델의 품질이 심각한 병목 현상(bottleneck)이었습니다. 봇이 때때로 이상한 말을 하곤 했습니다. 99%는 괜찮았지만, 가끔씩 정말 기이한 말을 했습니다. 예를 들어, 무언가에 대해 환각(hallucinate)을 일으키는 거죠. 누군가 봇과의 대화에서 이전에 말했던 것을 언급하면 봇은 '무슨 말인지 전혀 모르겠어요. 그런 말 한 적 없어요.'라고 말합니다. 그러면 그 사람은 '보세요, 채팅을 위로 스크롤하면 바로 거기에 있잖아요.'라고 말하고, 봇은 '아니요, 당신은 거짓말하고 있어요.'라고 합니다. 아, 컨텍스트 윈도우. 그리고 이런 종류의 일을 할 때, 사람들은 그냥 '아, 저 사람이 피곤하거나 술에 취했나 보다' 또는 '그냥 나를 놀리는 거겠지'라고 생각하며 대수롭지 않게 넘겼습니다. 하지만 제 생각에 그건 사람들이 봇을 찾고 있지 않았기 때문입니다. 그들은 게임에 봇이 있을 거라고 예상하지 않았습니다. 우리는 사실 정말 무서웠습니다. 왜냐하면 사람들이 어느 순간 이 게임에 봇이 있다는 것을 알아챌까 봐 두려웠고, 그러면 그들은 항상 그것을 경계할 것이기 때문입니다. 그리고 그들은 항상 그럴 것입니다. 그리고 만약 당신이 그것을 찾고 있다면, 당신은 그것을 발견할 수 있습니다. 그게 문제입니다. 그래서 지금은 발표되었고 사람들이 그것을 찾을 줄 알기 때문에, 그들은 그것을 발견하기 더 쉬울 것이라고 생각합니다. 그렇긴 하지만, 언어 모델도 2022년 이후로 훨씬 더 좋아졌습니다. 적대적이죠. 네. 그래서 이 시점에서, 진실은, GPD 4.0과 0.3 같은 모델들은 튜링 테스트(Turing test)를 통과하고 있습니다. 그래서 그들이 실제로 차이를 만들 수 있는 튜링 완전 질문을 많이 할 수 있다고 생각하지 않습니다.

**Alessio [00:03:39]**: 그리고 T-Zero는 2.7B로 매우 작았죠, 그렇죠?

**Noam [00:03:42]**: 매우 작은 언어 모델이었습니다. 네. 프로젝트를 진행하면서 우리가 깨달은 것 중 하나는, 아, 더 큰 언어 모델을 갖는 것만으로도 정말 많은 이점을 얻는다는 것이었습니다. 맞아요.

**Alessio [00:03:50]**: 네. 오늘날의 AI에 대한 인식과, 예를 들어, 사람들을 설득해서 게임에서 이기도록 돕는 데 정말 능숙한 봇을 만들 것이라는 안전 담론에 대해 어떻게 생각하시나요? 네. 게임이요. 그리고 오늘날 연구소들은 그런 종류의 문제에 대해 연구하지 않는다고 말하고 싶어 하는 것 같습니다. 그 둘 사이의 이분법에 대해 어떻게 생각하시나요?

**Noam [00:04:08]**: 솔직히 말해서, Cicero를 출시한 후, 많은 AI 안전 커뮤니티가 그 연구와 작동 방식에 대해 정말 만족했습니다. 왜냐하면 그것은 매우 제어 가능한 시스템이었기 때문입니다. 우리는 Cicero를 특정 구체적인 행동에 조건화했고, 그것은 '좋아, 이것은 우리가 매우 명확하게 해석할 수 있는 행동을 추구할 것이다'라고 말할 수 있는 많은 조종 가능성(steerability)을 주었습니다. 그리고 그것은 매우 명확하게 정의되어 있습니다. 그냥 '오, 이건 언어 모델이야, 마음대로 돌아다니면서 하고 싶은 대로 하는 거지'가 아닙니다. 아니요, 실제로는 꽤 조종 가능합니다. 그리고 언어 모델이 인간과 상호 작용하는 방식을 조종하는 이 모든 추론 시스템이 있습니다. 실제로 많은 연구자들이 제게 연락해서 '이것이 이 시스템들로 안전을 달성할 수 있는 잠재적으로 정말 좋은 방법이라고 생각한다'고 말했습니다.

**swyx [00:04:50]**: 아마도 마지막 디플로머시 관련 질문은, O 시리즈 모델을 디플로머시에서 업데이트하거나 테스트해 보셨나요? 그리고 더 많은 차이를 기대하시나요?

**Noam [00:05:01]**: 해보지 않았습니다. 언젠가 트위터에서 이것이 훌륭한 벤치마크가 될 것이라고 말했던 것 같습니다. 모든 주요 봇들이 서로 디플로머시 게임을 하고 누가 가장 잘하는지 보고 싶습니다. 그리고 몇몇 사람들이 그것에서 영감을 받아 실제로 이러한 벤치마크를 구축하고 모델을 평가하고 있는 것 같습니다. 제 이해로는 현재는 그다지 잘하지 못합니다. 음, 하지만 저는 이것이 정말 매력적인 벤치마크라고 생각하고, 시도해 볼 만한 정말 멋진 일이라고 생각합니다.

**swyx [00:05:25]**: 자, 이제 O 시리즈에 대해 조금 이야기해 보겠습니다. 마지막으로 홍보 활동을 많이 하셨을 때, 막 O one을 출시하고, TED 강연도 하시고 그랬죠. 전반적으로 분위기는 어떻게 변했나요? 화학 같은 분야의 도메인 전문가들로부터 O 시리즈 모델에 대한 리뷰를 배우는 것에 매우 흥분된다고 하셨는데, 작년 말 이후로 어떻게 업데이트되셨나요?

**Noam [00:05:48]**: 저는 개발 주기 초반부터 궤도가 꽤 명확했다고 생각합니다. 그리고 그 이후에 전개된 모든 것이 제가 예상했던 것과 거의 일치했습니다. 그래서 상황이 어디로 가고 있는지에 대한 제 인식이 솔직히 그렇게 많이 바뀌었다고는 말하지 않겠습니다. 음, 저는 우리가 앞으로도 계속해서 이 패러다임이 빠르게 발전하는 것을 보게 될 것이라고 말했고, 오늘날에도 그것이 사실이라고 생각합니다. 우리는 O one 프리뷰에서 O one, O three로 가는 일관된 발전을 보았습니다. 그리고 앞으로도 계속해서 그것을 보게 될 것입니다. 그리고 이 모델들이 할 수 있는 것의 범위도 넓어질 것이라고 생각합니다. 아시다시피, 우리는 에이전트적인 행동을 보기 시작할 것입니다. 음, 우리는 이미 그것을 보기 시작했습니다. 우리는 에이전트적인 행동을 보기 시작했습니다. 솔직히, 저에게 O three는 제 일상생활에서 엄청나게 많이 사용하고 있습니다. 저는 그것이 너무 유용하다고 생각합니다. 특히 이제 웹을 탐색하고 제 대신 의미 있는 연구를 할 수 있다는 사실이요. 마치 3분 안에 응답을 받을 수 있는 미니 딥 리서치와 같습니다. 그래서 네, 시간이 지남에 따라 점점 더 유용하고 강력해질 것이라고 생각합니다. 꽤 빨리요.

**Alessio [00:06:51]**: 네. 그리고 딥 리서치(Deep Research)에 대해 이야기하자면, 검증 불가능한 도메인에서 우리가 이것을 할 수 있다는 증거가 필요하다면 딥 리서치가 훌륭한 예라고 트윗하셨습니다. 사람들이 놓치고 있는 것이 있다면 말씀해 주시겠어요? 아시다시피, 코딩과 수학에서는 쉽지만 다른 도메인에서는 그렇지 않다는 말을 많이 듣는 것 같습니다.

**Noam [00:07:07]**: 저는 꽤 저명한 AI 연구자들을 포함해서 이 질문을 자주 받습니다. '좋아, 우리는 이 추론 모델들이 수학과 코딩, 그리고 이런 쉽게 검증 가능한 도메인에서 뛰어난 것을 보고 있지만, 성공이 덜 명확하게 정의된 도메인에서도 성공할 수 있을까?' 저는 이것이 그렇게 흔한 인식이라는 점에 놀랐습니다. 왜냐하면 우리는 딥 리서치를 출시했고 사람들은 그것을 사용해 볼 수 있기 때문입니다. 사람들은 그것을 사용합니다. 매우 인기가 있습니다. 그리고 그것은 성공에 대한 쉽게 검증 가능한 지표가 없는 영역임이 매우 분명합니다. '당신이 생성할 수 있는 최고의 연구 보고서는 무엇인가?'와 같은 것이죠. 그럼에도 불구하고 이 모델들은 이 영역에서 매우 잘하고 있습니다. 그래서 저는 이것이 이 모델들이 쉽게 검증 가능한 보상이 없는 작업에서도 성공할 수 있다는 존재 증명이라고 생각합니다.

**Alessio [00:07:51]**: 그것은 또한 반드시 틀린 답이 없기 때문일까요? 딥 리서치 품질에는 스펙트럼이 있잖아요? 좋아 보이는 보고서를 가질 수 있지만 정보는 그저 그렇고, 훌륭한 보고서도 있고요. 사람들이 결과를 받았을 때 그 차이를 이해하기 어려워한다고 생각하시나요?

**Noam [00:08:07]**: 제 인상은 사람들이 결과를 받았을 때 차이를 이해한다는 것입니다. 그리고 그들은 딥 리서치 결과가 얼마나 좋은지에 놀란다고 생각합니다. 물론, 100%는 아닙니다. 더 좋아질 수 있고 우리는 그것을 더 좋게 만들 것입니다. 하지만 저는 사람들이 좋은 보고서와 나쁜 보고서, 그리고 확실히 좋은 보고서와 평범한 보고서의 차이를 구별할 수 있다고 생각합니다.

**Alessio [00:08:24]**: 그리고 그것이 나중에 제품을 만들고 모델 성능을 향상시키기 위해 루프를 돌리기에 충분하다는 것이군요.

**Noam [00:08:29]**: 제 생각에, 만약 사람들이 출력물 간의 차이를 구별할 수 없는 상황에 있다면, 당신이 발전에 대해 언덕 오르기(hill climbing)를 하고 있는지 여부는 별로 중요하지 않습니다. 이 모델들은 성공의 척도가 있는 영역에서 더 나아질 것입니다. 이제, 그것이 쉽게 검증 가능해야 한다는 생각은, 저는 그것이 사실이라고 생각하지 않습니다. 저는 성공이 정의하기 매우 어려운 것일지라도, 때로는 주관적일지라도 이 모델들이 잘할 수 있다고 생각합니다.

**swyx [00:08:56]**: 사람들이 많이 의존하는 것, 당신도 그랬듯이, 바로 사고 모델에 대한 '생각에 관한 생각' 비유입니다. 그리고 저는 이제 그것이 꽤 잘 퍼졌다고 생각합니다. 이것이 다음 스케일링 패러다임이라는 생각 말이죠. 모든 비유는 불완전합니다. '생각에 관한 생각'이나 시스템 1, 시스템 2가 우리가 실제로 이것들을 확장하는 방식에 적용되지 않는 한 가지 방식은 무엇일까요?

**Noam [00:09:21]**: 제가 생각하기에 과소평가된 한 가지는, 모델, 즉 사전 훈련된 모델이 이러한 심층적 사고 과정으로부터 실질적인 이점을 얻기 위해서는 특정 수준의 능력이 필요하다는 것입니다. 바로 이러한 이유 때문에 추론 패러다임이 그 시점에 이르러서야 나타나게 된 것입니다. 물론 더 일찍 발현될 수도 있었겠지만, 만약 GPT-2 수준의 모델에 추론 패러다임을 적용하려고 시도했다면, 아마도 거의 아무런 성과도 얻지 못했을 것이라고 생각합니다. 이것이 창발(emergence)인가요? 창발이라고 단정하기는 어렵지만, 제가 그것을 명확하게 정의하기 위한 측정을 해보지는 않았습니다. 하지만 꽤 명백하다고 생각합니다. 사람들은 GPT 같은 정말 작은 모델로 연쇄적 사고(chain of thought)를 시도했고, 그것이 별 효과가 없다는 것을 보았습니다. 그리고 더 큰 모델로 가면 효과가 나타나기 시작합니다. 저는 이런 종류의 행동이 어느 정도까지 창발적인지에 대해 많은 논쟁이 있다고 생각하지만, 분명히 차이는 있습니다. 그래서 이것들이 두 개의 독립적인 패러다임인 것은 아닙니다. 제 생각에 그것들은 시스템 2로부터 이익을 얻기 위해 모델에 일정 수준의 시스템 1 능력이 필요하다는 의미에서 관련이 있습니다. 네.

**swyx [00:10:22]**: 저는 아마추어 신경과학자처럼 뇌의 진화와 비교해 보려고 한 적이 있습니다. 뇌의 다른 부분을 진화시키기 전에 먼저 피질을 진화시켜야 하는 것처럼요. 그리고 아마도 우리가 여기서 하고 있는 것이 바로 그것일 겁니다. 네.

**Noam [00:10:36]**: 그리고 사실 이것은 시스템 1, 시스템 2 패러다임과 크게 다르지 않다고 주장할 수도 있습니다. 왜냐하면, 비둘기에게 체스를 두는 것에 대해 정말 열심히 생각하라고 하면, 그리 멀리 가지 못할 겁니다. 천 년을 생각한다고 해도 체스를 더 잘 두게 될 수는 없을 겁니다. 그래서 아마도 동물과 인간에게도 시스템 2로부터 이익을 얻기 위해서는 시스템 1 측면에서 일정 수준의 지적 능력이 필요한 것 같습니다. 네.

**swyx [00:11:00]**: 잠깐 다른 이야기로, 이것이 시각적 추론에도 적용되나요? 예를 들어, 이제 우리는 4.0, 즉 네이티브 옴니 모델 같은 것을 가지고 있는데, 그것이 O3를 GeoGuessr에서 정말 잘하게 만듭니다. 이것이 다른 모달리티에도 적용되나요?

**Noam [01:11:17]**: 증거는 '그렇다'고 생각합니다. 그것은 당신이 묻는 질문의 종류에 정확히 달려 있습니다. 시스템 2의 혜택을 별로 받지 못하는 질문들도 있다고 생각합니다. GeoGuessr는 확실히 혜택을 받는 경우 중 하나입니다. 제 생각에 이미지 인식은, 만약 제가 추측해야 한다면, 시스템 2 사고로부터 혜택을 덜 받는 것들 중 하나일 것입니다. 왜냐하면 당신은 그것을 알거나 모르기 때문입니다. 네, 정확합니다. 방법이 없습니다. 네. 그리고 제가 보통 지적하는 것은 정보 검색 같은 것입니다. 누군가 당신에게 '이 사람이 언제 태어났나요?'라고 묻고 웹에 접근할 수 없다면, 당신은 그것을 알거나 모릅니다. 그리고 앉아서 오랫동안 생각해 볼 수는 있습니다. 아마도 교육받은 추측을 할 수는 있겠죠. 그래서 '음, 이 사람은 아마 이 시기쯤에 살았을 거야. 그래서 대략적인 날짜는 이 정도야'라고 말할 수 있습니다. 하지만 실제로 그것을 알지 못하는 한 날짜를 알아낼 수는 없을 겁니다.

**swyx [01:12:01]**: 하지만 공간 추론, 예를 들어 틱택토 같은 것은 더 나을 수 있겠네요. 모든 정보가 거기에 있으니까요. 네.

**Noam [01:12:06]**: 그리고 틱택토의 경우, GBD 4.5가 무너지는 것을 볼 수 있다는 것은 사실입니다. 꽤 괜찮게 플레이합니다. 무너진다고 말해서는 안 되겠네요. 보드를 합리적으로 잘 제어합니다. 합법적인 수를 둘 수 있지만, 때때로 실수를 합니다. 그리고 완벽하게 플레이하게 하려면 정말로 그 시스템 2가 필요합니다. 이제 GBD 6에 도달해서 시스템 1만 사용하면 완벽하게 플레이할 수도 있을 겁니다. 언젠가는 알게 되겠죠. 하지만 지금 당장은 잘하기 위해 시스템 2가 필요할 것이라고 생각합니다.

**Alessio [01:12:34]**: 시스템 1에 필요한 것들은 무엇이라고 생각하시나요? 예를 들어 게임 규칙에 대한 일반적인 이해는 당연하고요. 다른 게임에서 말을 어떻게 평가하는지와 같은 메타게임 같은 것도 이해해야 할까요? 시스템 1에서 어떻게 일반화해야 시스템 2에서 게임 플레이로 넘어갈 수 있을까요?

**Noam [01:12:53]**: 시스템 1에 더 많은 것이 있을수록, 이것은 인간과 같은 것입니다. 인간이 체스 같은 게임을 처음 할 때, 많은 시스템 2 사고를 적용할 수 있습니다. 그리고 만약 당신이 정말 똑똑한 사람에게 완전히 새로운 게임을 제시하고 '좋아, 당신은 이 게임을 AI나 이 게임을 마스터한 인간과 할 거야'라고 말하고, 그들에게 이 게임을 어떻게 할지 3주 동안 앉아서 생각하라고 한다면, 제 생각에 그들은 꽤 잘할 수 있을 겁니다. 하지만 확실히 그 시스템 1 사고를 쌓는 것, 즉 게임에 대한 직관을 쌓는 것이 도움이 됩니다. 왜냐하면 그것이 당신을 훨씬 더, 네, 훨씬 더 빠르게 만들어 줄 것이기 때문입니다.

**Alessio [01:13:35]**: 포켓몬 예시가 좋은 것 같아요. 시스템 1이 게임에 대한 모든 정보를 가지고 있는 것 같지만, 게임에 투입되면 여전히 많은 하네스(harnesses)가 필요합니다. 저는 하네스에서 얼마나 많은 것을 가져와 시스템 1에 넣을 수 있는지, 그래서 시스템 2가 가능한 한 하네스로부터 자유로워질 수 있는지 알아내려고 합니다.

**Noam [01:13:53]**: 하지만 그것은 게임과 AI를 일반화하는 문제와 같다고 생각합니다. 네, 저는 그것을 다른 질문으로 봅니다. 제 생각에 하네스에 대한 질문은, 이상적인 하네스는 하네스가 없는 것이라는 점입니다. 맞습니다. 저는 하네스가 결국 우리가 넘어설 수 있는 목발과 같다고 생각합니다. 그래서 두 번의 호출만 합니다. 그리고 O3에게 물어볼 수도 있습니다. 사실, 흥미로운 것은 이 포켓몬 플레이가 일종의 벤치마크로 떠올랐을 때, 저는 사실 우리 OpenAI 모델로 이것을 평가하는 것에 꽤 반대했습니다. 왜냐하면 제 생각은 '좋아, 이 평가를 할 거면, 그냥 O3로 하자'는 것이었기 때문입니다. O3가 아무런 하네스 없이 얼마나 멀리 갈 수 있을까? 포켓몬을 플레이하면서 얼마나 멀리 갈 수 있을까? 그리고 대답은 '그리 멀리 가지 못한다'입니다. 그리고 그건 괜찮습니다. 모델이 끔찍하게 못하는 평가가 있는 것도 괜찮다고 생각합니다. 그리고 그것에 대한 답이 '음, 이제 이 평가에서 잘할 수 있도록 정말 좋은 하네스를 만들자'가 되어서는 안 된다고 생각합니다. 제 생각에 답은 '좋아, 그냥 우리 모델의 능력을 향상시켜서 모든 것을 잘하게 만들자. 그러면 이 평가에서도 진전을 이루게 될 것이다'입니다.

**Alessio [01:14:56]**: 유효한 수를 확인하는 것 같은 것을 하네스로 간주하시나요, 아니면 모델 안에 있는 것인가요? 예를 들어 체스는 모델이 시스템 1에서 어떤 수가 유효하고 무엇을 할 수 있고 할 수 없는지 배우게 하거나, 시스템 2에서 알아내게 할 수 있습니다.

**Noam [01:15:11]**: 제 생각에, 이것의 많은 부분은 디자인 문제입니다. 저에게는, 모델에게 수가 합법적인지 확인할 수 있는 능력을 주어야 한다고 생각합니다. 원한다면, 그것은 환경의 옵션이 될 수 있습니다. '좋아, 여기 수가 합법적인지 보기 위해 만들 수 있는 도구 호출(tool call) 같은 액션이 있어.' 만약 그것을 사용하고 싶다면, 할 수 있습니다. 그리고 '모델이 불법적인 수를 두면 어떻게 할 것인가?'와 같은 디자인 문제가 있습니다. 그리고 저는 '음, 만약 그들이 불법적인 수를 두면, 게임에서 진다'고 말하는 것이 전적으로 합리적이라고 생각합니다. 체스 게임에서 인간이 불법적인 수를 두면 어떻게 되는지 모르겠습니다. 사실 잘 모릅니다. 저는 체스를 그렇게 많이 두지 않았습니다. 네, 저도요. 그냥 허용되지 않나요? 네. 그냥 게임에서 지는 건가요? 모르겠네요.

**swyx [01:15:44]**: 만약 그렇다면, AI 모델에 대해서도 그것이 기준이 되는 평가를 하는 것이 전적으로 합리적이라고 생각합니다. 네. 하지만 제 생각에, 연구자 용어로 그것을 해석하는 한 가지 방법은, 탐색(search)을 할 수 있느냐는 것입니다. 그리고 DeepSeek의 유명한 발견 중 하나는 MCTS가 그들에게 그다지 유용하지 않았다는 것입니다. 하지만 많은 엔지니어들이 탐색을 시도하고 있고 많은 토큰을 사용하고 있는데, 아마도 그럴 가치가 없을 수도 있습니다.

**Noam [01:16:08]**: 음, 저는 여기서 수가 합법적인지 불법적인지 확인하기 위한 도구 호출과 실제로 그 수를 두고 그것이 합법적인지 불법적인지 보는 것 사이의 구분을 하고 있습니다. 만약 그 도구 호출이 가능하다면, 그 도구 호출을 해서 수가 합법적인지 불법적인지 확인하는 것은 전적으로 괜찮다고 생각합니다. 모델이 '오, 나 이 수 둘래'라고 말하는 것은 다르다고 생각합니다. 네. 그리고 나서 '오, 불법적인 수를 뒀네'라는 피드백을 받고, 그래서 '오, 농담이야. 다른 거 할게'라고 하는 것은 다릅니다. 그래서, 그것이 제가 긋는 구분입니다.

**swyx [01:16:40]**: 어떤 사람들은 두 번째 유형의 플레이를 테스트 시간 컴퓨팅으로 분류하려고 했습니다. 당신은 그것을 테스트 시간 컴퓨팅으로 분류하지 않으시겠군요.

**Noam [01:16:48]**: 그 패러다임에 의존하고 싶지 않은 많은 이유가 있습니다. 로봇이 있다고 상상해 보세요. 당신의 로봇이 세상에서 어떤 행동을 하고 무언가를 부쉈는데, 당신은 그냥 '오, 농담이야. 그럴 의도는 아니었어. 그 행동을 취소할게'라고 말할 수 없습니다. 그 물건은 부서졌습니다. 그래서 만약 당신이 로봇을 이런 식으로 움직이면 무슨 일이 일어날지 시뮬레이션하고, 그 시뮬레이션에서 이 물건이 부서지는 것을 보고 그 행동을 하지 않기로 결정한다면, 그것은 전적으로 괜찮습니다. 하지만 당신이 세상에서 취한 행동을 그냥 되돌릴 수는 없습니다.

**swyx [01:17:14]**: 이 대략적인 영역에서 다루고 싶었던 몇 가지가 더 있습니다. 저는 사실 '생각에 관한 생각' 측면에 대한 답이 있었는데, 아마도 당신이 어떻게 생각하는지 궁금합니다. 많은 사람들이 효과적으로 모델 라우터 레이어를 넣으려고 합니다. 예를 들어 빠른 응답 모델과 오래 생각하는 모델 사이에요. Anthropic은 명시적으로 그렇게 하고 있습니다. 그리고 항상 라우팅을 위해 똑똑한 심판이 필요한지, 아니면 빠르기 때문에 멍청한 심판이 필요한지에 대한 질문이 있다고 생각합니다. 그래서 모델 라우터가 있을 때, 예를 들어 시스템 1 측과 시스템 2 측 사이에 요청을 전달할 때, 라우터가 똑똑한 모델만큼 똑똑해야 할까요, 아니면.

**Noam [01:17:51]**: 멍청한 모델이 문제가 정말 어렵고 해결할 수 없다는 것을 인식하고 더 유능한 모델로 라우팅하는 것이 가능하다고 생각합니다.

**swyx [01:18:01]**: 하지만 멍청한 모델이 속거나 과신할 수도 있습니다.

**Noam [01:18:05]**: 모르겠습니다. 거기에는 진짜 트레이드오프가 있다고 생각합니다. 하지만 저는 이렇게 말하고 싶습니다. 지금 사람들이 만들고 있는 많은 것들이 결국 스케일에 의해 씻겨 나갈 것이라고 생각합니다. 그래서 저는 하네스가 좋은 예라고 생각합니다. 결국 모델들이 그렇게 될 것이라고 생각합니다. 그리고 저는 이것이 실제로 추론 모델에서 일어났다고 생각합니다. 추론 모델이 등장하기 전에는, GPT-4-0이나 이런 비추론 모델에 많은 호출을 하는 에이전트 시스템을 엔지니어링하는 데 모든 노력이 들어갔습니다. 그리고 나서 알고 보니, '오, 우리는 그냥 추론 모델을 만들었고, 이런 복잡한 행동이 필요 없다'는 것이 밝혀졌습니다. 사실, 여러 면에서 그것은 상황을 더 악화시킵니다. 그냥 추론 모델에게 아무런 스캐폴딩(scaffolding) 없이 같은 질문을 주면 그냥 해냅니다. 아니요. 여전히 할 수 있습니다. 그래서 사람들은 지금 추론 모델 위에 스캐폴딩을 만들고 있습니다. 하지만 여러 면에서, 그 스캐폴드들도 그냥 추론 모델과 모델 전반이 더 유능해지면서 대체될 것이라고 생각합니다. 그리고 비슷하게, 모델 같은 것들, 이런 라우터들, 아시다시피, 우리는 단일 통합 모델이 있는 세상으로 나아가고 싶다고 꽤 공개적으로 말해왔습니다. 그리고 그 세상에서는 모델 위에 라우터가 필요하지 않아야 합니다. 그래서 저는 라우터 문제도 결국 해결될 것이라고 생각합니다.

**swyx [01:19:18]**: 라우터를 모델 자체의 가중치에 내장하는 것처럼요.

**Noam [01:19:22]**: 저는 이익이 있을 것이라고 생각하지 않습니다. 제가 틀릴 수도 있기 때문에 그렇게 말해서는 안 되겠지만요. 예를 들어, 다른 모델 제공업체로 라우팅할 이유가 있을 수도 있습니다. 하지만 저는 라우터가 결국 사라질 것이라고 생각합니다. 그리고 단기적으로는 그것을 하는 것이 가치가 있다는 것을 이해할 수 있습니다. 왜냐하면 사실, 지금은 유익하기 때문입니다. 그리고 만약 당신이 제품을 만들고 있고 그것으로부터 이익을 얻고 있다면, 지금 당장 하는 것이 가치가 있습니다. 제가 상상하기에 많은 개발자들이 직면하고 있는 까다로운 것 중 하나는, 6개월, 12개월 후에 이 모델들이 어디에 있을지 계획해야 한다는 것입니다. 그리고 그것은 매우 어렵습니다. 왜냐하면 상황이 매우 빠르게 진행되고 있기 때문입니다. 6개월 동안 무언가를 만들고 나서 그것이 스케일에 의해 완전히 씻겨 나가는 것을 원하지 않을 것입니다. 하지만 저는 개발자들에게, 이런 종류의 것들, 즉 스캐폴드와 라우터를 만들 때, 이 분야가 매우 빠르게 진화하고 있다는 것을 명심하라고 격려하고 싶습니다. 3개월, 6개월은 말할 것도 없고, 상황이 변할 것입니다. 그리고 그것은 이러한 것들을 근본적으로 바꾸거나 완전히 버려야 할 수도 있습니다. 그러니 6개월 후에 버려질 수도 있는 것을 만드는 데 6개월을 쓰지 마세요.

**swyx [01:20:29]**: 하지만 그건 너무 어렵습니다. 모두가 이렇게 말하지만, 구체적인 제안을 하는 사람은 아무도 없습니다.

**Alessio [01:20:36]**: 강화 미세 조정(reinforcement fine-tuning)은 어떻습니까? 한 달 전에 UrbanEye에서 출시하셨는데, 지금 사람들이 시간을 투자해야 할까요, 아니면 다음 도약을 기다려야 할까요?

**Noam [01:20:46]**: 저는 강화 미세 조정이 꽤 멋지다고 생각합니다. 그리고 살펴볼 가치가 있다고 생각합니다. 이것은 당신이 가진 데이터에 모델을 특화시키는 것에 관한 것이기 때문에 살펴볼 가치가 있는 것이라고 생각합니다. 그리고 제 생각에, 개발자들에게는 살펴볼 가치가 있는 것입니다. 우리는 갑자기 그 데이터를 원시 모델에 많이 구워 넣지는 않을 것입니다. 그래서 저는 그것이 별개의 문제라고 생각합니다. 네.

**Alessio [01:21:11]**: 그럼 환경과 보상 모델을 만드는 것이 지금 사람들이 할 수 있는 최선이군요. 사람들이 가지는 질문은 '모델을 RFT를 사용해서 서둘러 미세 조정해야 할까? 아니면 모델이 더 좋아지면 RFT할 수 있도록 하네스를 만들어야 할까?'인 것 같습니다.

**Noam [01:21:25]**: 제 생각에 차이점은 강화 미세 조정을 위해 당신은 모델이 개선됨에 따라 유용할 데이터를 수집하고 있다는 것입니다. 그래서 만약 우리가 훨씬 더 유능한 미래 모델을 내놓는다면, 당신은 여전히 당신의 데이터에 그것들을 미세 조정할 수 있습니다. 그것은, 제 생각에 실제로 당신이 모델 스케일링을 보완하고 더 유능해지는 것을 돕는 무언가를 만들고 있는 좋은 예입니다. 반드시 스케일에 의해 씻겨 나가는 것이 아니고요.

**swyx [01:21:50]**: 일리야에 대한 마지막 질문 하나, 사라 앤 엘라드(Sarah and Elad) 팟캐스트에서 언급하셨는데, 몇 년 전 일리야와 더 많은 RL과 추론, 그리고 언어 모델에 대해 대화를 나누셨다고요. 그가 시도했을 때 왜 그의 시도가 실패했는지, 혹은 타이밍이 맞지 않았는지, 그리고 왜 지금이 적기인지에 대한 추측이나 생각이 있으신가요?

**Noam [01:22:14]**: 저는 그것을 그의 시도가 실패했다고 표현하지는 않겠습니다. 여러 면에서 성공했습니다. 일리야, 저에게는, 제가 작업했던 모든 도메인, 포커, 하나비, 디플로머시에서 모델이 행동하기 전에 생각하게 하는 것이 성능에 엄청난 차이를 만들었습니다. 수십만 배의 차이요. 1만 배. 네. 천 배에서 십만 배 정도요. 마치 천 배에서 십만 배 더 큰 모델과 동등한 것입니다. 그리고 언어 모델에서는 그런 것을 정말 볼 수 없었습니다. 모델들이 그냥 즉시 응답했죠. LLM 분야의 일부 사람들은 '좋아, 우리는 그냥 사전 훈련을 계속 확장하면 초지능에 도달할 거야'라고 확신했습니다. 그리고 저는 2021년 말에 그 관점에 대해 다소 회의적이었습니다. 일리야와 식사를 하고 있었는데, 그가 제게 AGI 타임라인이 어떻게 되냐고 물었습니다. 아주 표준적인 SF 질문이죠. 그리고 저는 그에게 '보세요, 저는 사실 꽤 멀었다고 생각합니다. 왜냐하면 우리는 이 추론 패러다임을 매우 일반적인 방식으로 알아내야 할 것이기 때문입니다. 그리고 LLM 같은 것들은, LLM은 매우 일반적이지만, 매우 일반적인 추론 패러다임을 가지고 있지 않습니다. 그리고 그들이 그렇게 하기 전까지는, 그들이 할 수 있는 것에 한계가 있을 것입니다. 우리는 말할 겁니다. 물론, 우리는 이것들을 몇 자릿수 더 확장할 것입니다. 그들은 더 유능해지겠지만, 그것만으로는 초지능을 볼 수 없을 것입니다. 그리고 만약 우리가 이 모델들을 훈련시키는 데 1000조 달러가 있다면, 아마도 그렇게 하겠지만, 추론 패러다임이 없다면 초지능에 도달하기 전에 경제적으로 실현 가능한 한계에 부딪힐 겁니다. 그리고 저는 추론 패러다임을 알아내는 데 오랜 시간이 걸릴 것이라고 잘못 확신하고 있었습니다. 왜냐하면 이것은 큰 미해결 연구 문제와 같았기 때문입니다. 그리고, 아시다시피, 일리야는 제게 동의하며 '네, 알아요, 제 생각에 우리는 이 추가적인 패러다임이 필요하다'고 말했지만, 그의 생각은 '어쩌면 그렇게 어렵지 않을 수도 있다'는 것이었습니다. 저는 그 당시에는 몰랐지만, 그와 OpenAI의 다른 사람들도 이것에 대해 생각하고 있었습니다. 그들도 RL에 대해 생각하고 있었고, 그것에 대해 작업하고 있었고, 어느 정도 성공을 거뒀다고 생각합니다. 하지만 대부분의 연구와 마찬가지로, 반복해야 하고, 다른 아이디어를 시도해야 하고, 네, 다른 것들을 시도해야 합니다. 그리고 모델이 더 유능해지고, 더 빨라지면서, 실험을 반복하기가 더 쉬워집니다. 그리고 저는 그들이 한 작업이, 비록 추론 패러다임으로 이어지지는 않았지만, 모든 것이 이전 작업 위에 구축된다고 생각합니다. 맞습니다. 그래서 그들은 시간이 지남에 따라 이 추론 패러다임으로 이어진 많은 것들을 만들었습니다.

**swyx [01:24:31]**: 청취자들을 위해, 아무도 이것에 대해 이야기할 수 없지만, 소문에 따르면 그 프로젝트의 코드명은 GPT 제로(GPT zero)였습니다. 만약 그 연구 라인을 검색하고 싶다면요. 제 생각에 기본적으로 RL이 암흑기를 겪었던 시기가 있었습니다. 모두가 그것에 올인했다가 아무 일도 일어나지 않자 포기했죠. 그리고 지금은 다시 황금기인 것 같습니다. 그래서 저는 그것을 식별하려고 합니다. 왜, 무엇일까요? 그리고 그것은 단지 우리가 더 똑똑한 기본 모델과 더 나은 데이터를 가지고 있기 때문일 수도 있습니다.

**Noam [01:24:57]**: 저는 단지 우리가 더 똑똑한 기본 모델을 가지고 있기 때문이라고 생각하지 않습니다. 제 생각에는 그렇습니다. 네. 그래서 우리는 결국 추론에서 큰 성공을 거두었습니다. 하지만 저는 그것이 여러 면에서 점진적인 것이었다고 생각합니다. 어느 정도는 점진적이었습니다. 생명의 징후들이 있었습니다. 그리고 우리는 반복하고 몇 가지를 더 시도했습니다. 우리는 더 나은 생명의 징후를 얻었습니다. 제 생각에 2023년 11월이나 10월쯤이었던 것 같습니다. 2023년 11월이나 10월쯤이었던 것 같습니다. 그때 저는 우리가 '오, 이것이, 이것이 패러다임이 될 것이고, 큰일이 될 것이다'라는 매우 결정적인 생명의 징후를 가지고 있다고 확신했습니다. 그것은 여러 면에서 점진적인 것이었습니다. 제 생각에 OpenAI가 잘한 것은 우리가 그 생명의 징후를 얻었을 때, 그것을 있는 그대로 인식하고 그것을 확장하는 데 막대하게 투자했다는 것입니다. 그리고 저는 그것이 궁극적으로 추론 모델이 그 시점에 도착하게 된 이유라고 생각합니다.

**Alessio [01:25:45]**: 내부적으로 의견 불일치가 있었나요? 특히 OpenAI가 끊임없이...

**Noam [01:25:50]**: 제 생각에 그것 또한 OpenAI의 공로라고 생각합니다. '좋아, 그래, 그들은 필요한 패러다임을 알아냈고, 그래서 그들은 이 모든 연구 노력을 이 RL 같은 것에 투자하고 있었다'고요. 그리고 제 생각에 그것 또한 OpenAI의 공로라고 생각합니다. '좋아, 그래, 그들은 패러다임을 알아냈다'고요. 그리고 그들은 그것을 확장하는 데 매우 집중했습니다. 사실, 자원의 대부분이 그것을 확장하는 데 집중되었습니다. 하지만 그들은 또한 다른 무언가가 필요할 것이라는 가치를 인식했습니다. 그리고 그 추가적인 패러다임이 무엇인지 알아내기 위해 다른 방향으로 연구 노력을 기울일 가치가 있었습니다. 우선, 그 추가적인 패러다임이 무엇인지에 대한 많은 논쟁이 있었습니다. 그래서 많은 연구자들이 추론과 RL을 보았지만, 그것은 테스트 시간 컴퓨팅을 확장하는 것에 대한 것이 아니었습니다. 그것은 데이터 효율성에 더 가까웠습니다. 왜냐하면, 아시다시피, '음, 우리는 엄청난 양의 컴퓨팅을 가지고 있지만 실제로는 데이터에 더 제한을 받는다'는 느낌이 있었기 때문입니다. 그래서 데이터 장벽이 있고, 우리는 컴퓨팅의 한계에 도달하기 전에 그것에 부딪힐 것입니다. 그렇다면 어떻게 이 알고리즘들을 더 데이터 효율적으로 만들 수 있을까요? 그것들은 더 데이터 효율적이지만, 제 생각에는 그것들이 또한 컴퓨팅을 엄청나게 확장하는 것과 동등하다고 생각합니다. 그것은 흥미로웠습니다. '좋아, 음, 우리가 여기서 정확히 무엇을 하고 있는 거지?'와 같은 많은 논쟁이 있었습니다. 그리고 제 생각에 또한, 우리가 생명의 징후를 얻었을 때조차도, 그것의 중요성에 대해 많은 논쟁이 있었다고 생각합니다. '좋아. 이 패러다임을 확장하는 데 얼마나 투자해야 할까?' 제 생각에, 특히 당신이 작은 회사에 있을 때, 2023년의 OpenAI는 오늘날만큼 크지 않았습니다. 그리고 컴퓨팅은 오늘날보다 더 제한적이었습니다. 그리고 만약 당신이 어떤 방향으로 자원을 투자한다면, 그것은 다른 무언가를 희생하는 것입니다. 그래서 만약 당신이 추론에 대한 이 생명의 징후를 보고 '좋아, 음, 이것은 유망해 보인다. 우리는 이것을 엄청나게 확장하고 훨씬 더 많은 자원을 투자할 것이다'라고 말한다면, 그 자원들은 어디에서 오는 걸까요? 당신은 그 자원들을 어디에서 끌어올지에 대한 어려운 결정을 내려야 합니다. 그리고 그것은 매우 논란이 많고, 매우 어려운 결정이며, 어떤 사람들을 불행하게 만듭니다. 그리고 저는 우리가 이 패러다임에 너무 많이 집중하고 있는지, 그것이 정말로 큰일인지, 우리가 그것이 일반화되고 다양한 일을 하는 것을 볼 수 있을지에 대한 논쟁이 있었다고 생각합니다. 그리고 제가 기억하기에 흥미로웠던 것은, 우리가 추론 패러다임을 발견한 후, 하지만 o1을 발표하기 전에 OpenAI를 떠나 경쟁 연구소로 간 사람과 이야기한 것입니다. 우리가 발표한 후에 그를 만났습니다. 그리고 그는 제게 '그 당시에는, 이 추론 같은 것, 이 O 시리즈, 스트로베리 모델들이 그렇게 대단한 것이라고 정말 생각하지 않았다'고 말했습니다. 마치, 그들은 우리가 실제보다 더 과장하고 있다고 생각했다는 겁니다. 그리고 우리가 o1을 발표하고 그가 이 경쟁 연구소의 동료들의 반응을 보았을 때, 모두가 '오 젠장, 이건 대단한 일이다'라고 하는 것을 보고, 그들은 전체 연구 의제를 이것에 집중하도록 전환했습니다. 그제서야 그들은 '오, 사실 이건 아마도 대단한 일일지도 몰라'라고 깨달았다는 겁니다. 아시다시피, 이 중 많은 것이 돌이켜보면 명백해 보이지만, 당시에는 실제로는 그렇게 명백하지 않았고, 어떤 것을 있는 그대로 인식하기가 꽤 어려울 수 있습니다.

**Alessio [01:29:00]**: 제 말은, OpenAI는 올바른 베팅을 한 훌륭한 역사를 가지고 있습니다. GPD 모델도 비슷한 것 같아요, 그렇죠? 게임, NRL로 시작했다가, '어쩌면 그냥 이 언어 모델들을 확장할 수 있을까'로 갔죠. 그리고 저는 리더십과 물론 이 통찰력을 계속해서 내놓는 연구팀에 감명받았습니다.

**Noam [01:29:19]**: 오늘날 돌이켜보면, '오, 물론, 이 모델들은 스케일에 따라 더 좋아지니까, 그냥 엄청나게 확장하면 더 좋아질 거야'라고 생각하는 것이 명백해 보일 수 있습니다. 하지만 정말로, 최고의 연구는 돌이켜보면 명백합니다. 그리고 당시에는 오늘날 보이는 것만큼 명백하지 않습니다.

**swyx [01:29:35]**: 데이터 효율성에 대한 후속 질문입니다. 이것은 제가 좋아하는 주제입니다. 우리의 현재 학습 방법은 여전히 너무 비효율적인 것 같습니다, 그렇죠? 인간이라는 존재 증명과 비교하면, 우리는 다섯 개의 샘플을 보고 무언가를 배웁니다. 기계는 200개, 아마도, 당신이 필요로 할 수 있는 데이터 포인트당 그 정도일 겁니다. 데이터 효율성에서 흥미로운 일을 하는 사람이 있나요? 아니면 기계 학습이 인간에 비해 항상 존재할 근본적인 비효율성이 있다고 생각하시나요?

**Noam [01:30:05]**: 이 모델들이 훈련받는 데이터의 양을 보고 인간이 같은 성능을 얻기 위해 관찰하는 데이터의 양과 비교하면 좋은 지적이라고 생각합니다. 사전 훈련의 경우, 사과 대 사과 비교를 하기가 좀 어렵습니다. 왜냐하면, 아기가 실제로 얼마나 많은 토큰을 흡수하는지 모르기 때문입니다. 아기가 발달할 때요. 하지만 이 모델들이 인간보다 데이터 효율성이 떨어진다는 것은 공정한 진술이라고 생각합니다. 그리고 저는 그것이 미해결 연구 문제이며 아마도 가장 중요한 미해결 연구 문제 중 하나라고 생각합니다.

**swyx [01:30:32]**: 아마도 알고리즘 개선보다 더 중요할 수 있습니다. 왜냐하면 우리는 세상과 인간의 기존 집합에서 데이터 공급을 늘릴 수 있기 때문입니다.

**Noam [01:30:42]**: 그건 좋은 지적입니다. 그것에 대해 몇 가지 생각이 있습니다. 하나는 답이 알고리즘 개선일 수 있다는 것입니다. 아마도 알고리즘 개선이 더 큰 효율성으로 이어질 수 있습니다. 그리고 두 번째는, 인간이 단지 인터넷을 읽는 것만으로 배우는 것은 아니라는 것입니다. 그래서 인터넷에 있는 데이터로부터 배우는 것이 확실히 가장 쉽다고 생각하지만, 그것이 당신이 수집할 수 있는 데이터의 한계라고는 생각하지 않습니다.

**swyx [01:31:05]**: 코딩으로 주제를 바꾸기 전 마지막 후속 질문입니다. 일리야에 대한 다른 일화나 통찰력이 있으신가요? 그와 함께 일하셨으니, 그와 함께 일한 사람들과 이야기할 수 있는 사람이 많지 않으니까요.

**Noam [01:31:17]**: 저는 그냥 매우, 매우 감명받았습니다. 특히 제가 합류했을 때 OpenAI의 내부 문서를 보고, 그가 2021년, 2022년, 심지어 그 이전부터 무엇을 생각하고 있었는지 보았을 때, 그가 이 모든 것이 어디로 가고 있고 무엇이 필요한지에 대한 명확한 비전을 가지고 있었다는 것에 매우 감명받았습니다.

**swyx [01:31:36]**: 2016년, 17년에 OpenAI를 설립할 때의 그의 이메일 일부가 공개되었습니다. 그리고 그때조차도 그는 '하나의 큰 실험이 100개의 작은 실험보다 훨씬 더 가치 있다'와 같은 말을 했습니다. 그것은 핵심적인 통찰력이었습니다. 그것은 예를 들어 그들을 브레인(Brain)과 구별하는 핵심적인 통찰력이었습니다. 그는 다른 사람들보다 훨씬 더 명확하게 사물을 보는 것 같아서 매우 통찰력 있어 보입니다. 그리고 저는 그의 생산 함수가 어떤지, 어떻게 그런 인간을 만드는지, 그리고 그것을 더 잘 모델링하기 위해 자신의 사고를 어떻게 개선하는지 궁금합니다.

**Noam [01:32:04]**: 제 말은, OpenAI의 큰 성공 중 하나가 스케일링 패러다임에 베팅한 것이 사실이라고 생각합니다. 그들이 가장 큰 연구소가 아니었고, 스케일링하기 어려웠다는 점을 고려하면 좀 이상합니다. 그 당시에는 많은 작은 실험을 하는 것이 훨씬 더 일반적이었습니다. 더 학문적인 스타일이었죠. 사람들은 이러한 다양한 알고리즘 개선을 알아내려고 노력했고 OpenAI는 꽤 일찍부터 대규모에 베팅했습니다.

**swyx [01:32:27]**: 저희는 GPT-1과 2 당시 VP Eng였던 데이비드 루안(David Luan)을 초대했었습니다. 그리고 그는 브레인과 OpenAI의 차이점이 기본적으로 구글이 확장된 모델을 내놓지 못한 원인이었다고 말했습니다. 구조적으로, 모두가 컴퓨팅을 할당받았고, 베팅을 하기 위해 자원을 모아야 했는데, 그럴 수 없었다는 겁니다.

**Noam [01:32:47]**: 그건 사실이라고 생각합니다. OpenAI는 다르게 구조화되었고 그것이 그들에게 정말 도움이 되었다고 생각합니다. OpenAI는 스타트업처럼 많이 기능하고 다른 곳들은 대학이나 전통적으로 존재했던 연구소처럼 기능하는 경향이 있었습니다. OpenAI가 AGI와 초지능을 구축한다는 사명을 가진 스타트업처럼 더 많이 운영되는 방식이 그들이 조직하고, 협력하고, 자원을 모으고, 자원을 어떻게 할당할지에 대한 어려운 선택을 하는 데 도움이 되었습니다. 그리고 저는 다른 많은 연구소들이 이제 그렇게 하고 있다고 생각합니다. 그런 패러다임, 그런 설정을 채택하려고 노력하는 것이 매우 효과적입니다.

**Alessio [01:33:22]**: 아마도 이 모델들의 킬러 유스케이스, 적어도 제 생각에는 코딩에 대해 이야기해 봅시다. 최근에 CodeX를 출시하셨는데, 노암 브라운의 코딩 스택에 대해 이야기하고 싶습니다. 어떤 모델을 사용하시고, 어떻게 상호작용하시나요? Cursor, Windsurf.

**Noam [01:33:35]**: 최근에는 Windsurf와 CodeX를 사용하고 있습니다. 사실 CodeX를 많이 사용합니다. 정말 재미있게 사용하고 있습니다. 그냥 작업을 주면 알아서 해주고 5분 후에 풀 리퀘스트(pull request)를 가지고 돌아옵니다. 그리고 핵심 연구 과제인가요?

**swyx [01:33:47]**: 아니면 보통 하지 않는 부수적인 일인가요?

**Noam [01:33:49]**: 부수적인 일이라고는 말하지 않겠습니다. 기본적으로 제가 보통 코딩하려고 하는 모든 것을 먼저 CodeX로 시도합니다.

**swyx [01:34:02]**: 음, 당신에게는 무료지만, 네, 모두에게는 지금 무료입니다.

**Noam [01:34:04]**: 그리고 저는 그것이 부분적으로는 제가 그것을 하는 가장 효과적인 방법이기 때문이라고 생각합니다. 그리고 또한, 이 기술로 작업하고 그것의 단점을 보는 경험을 하는 것이 저에게 좋습니다. 그것은 제가 이 모델들의 한계와 다음에 무엇을 추진해야 하는지를 더 잘 이해하는 데 도움이 됩니다.

**swyx [01:34:20]**: AGI를 느껴보셨나요?

**Noam [01:34:21]**: AGI를 여러 번 느껴봤습니다, 네.

**swyx [01:34:25]**: 사람들이 당신이 했던 방식으로 CodeX를 어떻게 밀어붙여야 할까요? 그리고 당신은 다른 사람들보다 먼저 그것을 보았을 거라고 생각합니다. 왜냐하면 당신이 그것에 더 가까웠기 때문이죠.

**Noam [01:34:33]**: 누구나 CodeX를 사용하고 AGI를 느낄 수 있다고 생각합니다. AGI를 느끼고 나면 아주 빨리 익숙해지는 것이 좀 웃깁니다.

**swyx [01:34:43]**: 그래서 정말... 부족한 부분에 불만족스럽습니다.

**Noam [01:34:46]**: 네, 알아요. 마법 같습니다. 저는 사실 발표되었을 때의 옛날 Sora 비디오들을 다시 보고 있었습니다. Sora가 나왔을 때, 그것은 그냥 마법 같았다는 것을 기억하시나요? 그것을 보면 '정말 여기 있구나. 이것이 AGI다'라고 생각하게 됩니다. 하지만 지금 보면, '오, 사람들이 아주 유기적으로 움직이지 않고, 어떤 면에서는 일관성이 부족하다'와 같습니다. 그리고 처음 나왔을 때는 정말 눈치채지 못했던 모든 결점들을 지금은 보게 됩니다. 그리고 네, 이 기술에 아주 빨리 익숙해집니다. 하지만 제가 생각하기에 멋진 점은, 그것이 너무 빨리 발전하고 있기 때문에, 몇 달에 한 번씩 그런 'AGI를 느끼는' 순간들을 경험하게 된다는 것입니다. 그래서 다른 무언가가 나오고, 그것이 당신에게 마법처럼 느껴집니다. 그리고 나서 아주 빨리 익숙해집니다.

**swyx [01:35:28]**: Windsurf에 몰두하셨으니, 프로 팁이 있나요?

**Noam [01:35:33]**: 제가 놀란 것 중 하나는 얼마나 적은 사람들이... 제 말은, 아마도 당신의 청중은 추론 모델에 더 익숙하고 추론 모델을 더 많이 사용할 것입니다. 하지만 저는 얼마나 많은 사람들이 O3가 존재한다는 것조차 모르는지에 놀랐습니다. 저는 매일 사용하고 있습니다. 기본적으로 저에게는 구글 검색을 대체했습니다. 그냥 항상 사용합니다. 그리고 코딩 같은 것에도, 저는 그냥 추론 모델을 사용하는 경향이 있습니다. 제 제안은, 만약 사람들이 아직 추론 모델을 사용해보지 않았다면, 솔직히, 사람들은 그것들을 좋아합니다. 사용하는 사람들은 그것들을 좋아합니다. 물론, 훨씬 더 많은 사람들이 GPT-4.0과 ChatGPT의 기본 설정을 사용하고 그런 종류의 것들을 사용합니다. 저는 추론 모델을 시도해 볼 가치가 있다고 생각합니다. 사람들은 그것들이 할 수 있는 것에 놀랄 것입니다.

**swyx [01:36:15]**: 저는 Windsurf를 매일 사용하는데, 아직도 Windsurf에서 기본값으로 활성화되지 않았습니다. 항상 O3를 입력해서 찾아야 합니다. '아, 맞다, 그게 있었지' 하고요. 이상합니다. 제 생각에, 제 어려움은 추론하는 데 너무 오래 걸려서 흐름을 깨뜨린다는 것이었습니다.

**Noam [01:36:34]**: 그건 사실이라고 생각합니다. 네. 그리고 이것이 CodeX의 장점 중 하나라고 생각합니다. 자급자족적인 작업을 주고, 그것이 알아서 일을 하고 10분 후에 돌아올 수 있습니다. 그리고 만약 당신이 이것을 페어 프로그래머(pair programmer)처럼 사용한다면, 네, GPT-4.1이나 그런 것을 사용하고 싶을 겁니다.

**Alessio [01:36:51]**: AI를 이용한 개발 주기에서 가장 망가진 부분은 무엇이라고 생각하시나요? 제 생각에는 풀 리퀘스트(pull request) 리뷰입니다. 저는 CodeX를 항상 사용하는데, 그러면 이 모든 풀 리퀘스트를 받게 되고, 그것들을 모두 검토하기가 좀 어렵습니다. 이것을 더 확장 가능하게 만들기 위해 사람들이 무엇을 더 만들었으면 좋겠나요?

**Noam [01:37:09]**: 저는 우리가 훨씬 더 많은 것을 만들어야 한다고 생각합니다. 이 모델들은 어떤 면에서는 매우 제한적입니다. 저는 그들에게 무언가를 하라고 요청하면 10분 동안 그것을 하고, 그 다음에 꽤 비슷한 것을 하라고 요청하면 또 10분 동안 그것을 하는 것이 답답하다고 생각합니다. 저는 그들을 '천재지만, 직장에서 첫날인 사람'이라고 묘사합니다. 그리고 그것은 좀 짜증납니다. 지구상에서 가장 똑똑한 사람이라도 직장에서 첫날일 때는, 당신이 원하는 만큼 유용하지 않을 것입니다. 그래서 더 많은 경험을 얻고, 실제로 직장에서 하루가 아니라 6개월 동안 일한 사람처럼 행동할 수 있게 되면, 그들이 훨씬 더 유용해질 것이라고 생각합니다. 하지만 그것은 정말 우리가 그 능력을 만들어야 할 몫입니다.

**Alessio [01:37:51]**: 그것의 많은 부분이 GPU 제약 때문이라고 생각하시나요? 예를 들어 CodeX를 생각해보면, 왜 제가 직접 환경을 설정하라고 요청하는 걸까요? 만약 제가 O3에게 리포지토리의 환경 설정 스크립트를 만들라고 요청하면, 분명히 할 수 있을 텐데요. 하지만 오늘날 제품에서는 제가 해야 합니다. 그래서 제 생각에, 만약 우리가 다시 더 많은 테스트 시간 컴퓨팅을 투입한다면 이것들이 훨씬 더 나아질 수 있을까요? 아니면 오늘날 근본적인 모델 능력의 한계가 있어서 여전히 많은 인간의 하네스가 필요하다고 생각하시나요?

**Noam [01:38:19]**: 제 생각에 우리는 지금 발전이 매우 빠르고, '분명히 우리가 모델에서 이것을 더 잘할 수 있다'와 같은 것들이 있는 어색한 상태에 있습니다. 우리는 그것에 도달할 것입니다. 단지 하루에 몇 시간이 있는지에 따라 제한될 뿐입니다. 그래서 발전은 그렇게 빨리 진행될 수밖에 없습니다. 우리는 가능한 한 빨리 모든 것에 도달하려고 노력하고 있습니다. 그리고 저는 O3가 6개월 후에 기술이 도달할 곳이 아니라고 생각합니다.

**swyx [01:38:41]**: 전반적으로 그 질문이 마음에 듭니다. 소프트웨어 개발 생명주기가 있습니다. 코드 생성뿐만 아니라, 이슈에서 PR까지가 기본적으로 그에 대한 일반적인 논평입니다. 그리고 당신의 ID 안에 있는 윈드서프 측면이 있습니다. 그 외에 또 뭐가 있을까요? 풀 리퀘스트 리뷰는 사람들이 별로... 그것을 중심으로 구축된 스타트업들이 있습니다. CodeX가 하는 일이 아니고, 할 수도 있습니다. 그래서, 당신이 반복할 수 있는 소프트웨어의 양을 제한하는 다른 것이 무엇이 있을까요? 그것은 열린 질문입니다. 답이 있는지 모르겠습니다. 그것에 대해 다른 할 말이 있나요? 네. 일반적으로, 이것이 폼 팩터나 내년 이맘때쯤 우리가 보게 될 것, 즉 모델이 오늘날 할 수 없는 것을 할 수 있게 되는 측면에서 어디로 갈 것이라고 생각하시나요?

**Noam [01:39:29]**: ASWY에 국한될 것이라고 생각하지 않습니다. 제 생각에, 소프트웨어 엔지니어링에 국한될 것이라고 생각하지 않습니다. 많은 원격 근무 종류의 작업을 할 수 있을 것이라고 생각합니다. 네.

**swyx [01:39:37]**: 프리랜서 타입의 일이요. 네.

**Noam [01:39:40]**: 아니면 반드시 소프트웨어 엔지니어링이 아닌 것들이요. 알겠습니다. 그래서 제가 생각하는 방식은, 원격 근무 종류의 일을 하는 사람은 누구나 그들의 기술에 익숙해지고, 그것이 무엇을 할 수 있고, 무엇을 할 수 없는지, 무엇을 잘하고, 무엇을 잘 못하는지에 대한 감을 잡는 것이 가치 있다고 생각합니다. 왜냐하면 그것이 할 수 있는 일의 폭이 시간이 지남에 따라 확장될 것이기 때문입니다.

**swyx [01:39:59]**: 그렇다면 가상 비서가 ASWY 다음이 될 것 같습니다. 왜냐하면 그들은 가장 쉽게... 가상 비서처럼, 필리핀에서 누군가를 고용해서 이메일을 훑어보게 하는 것과 같죠. 왜냐하면 그것은 전적으로, 모든 입력과 출력을 가로채서 그것으로 훈련할 수 있기 때문입니다. 그리고 아마도 OpenAI는 그냥 가상 비서 회사를 인수할 수도 있겠네요.

**Noam [01:40:20]**: 네. 제가 기대하는 것은 가상 비서 같은 것들에 대해, 모델들이 잘 얼라인(aligned)되어 있다면, 그런 종류의 작업에 정말 선호될 수 있다는 것입니다. 아시다시피, 누군가에게 작업을 위임할 때 항상 주인-대리인 문제(principal agent problem)가 있습니다. 그들이 정말로 당신이 원하는 대로 그것을 하는 것에 얼라인되어 있을까요?

**swyx [01:40:40]**: 그리고 가능한 한 싸고, 빠르게 말이죠. 네, 네.

**Noam [01:40:44]**: 그래서 만약 당신에게 정말로 얼라인된 AI 모델이 있다면, 그것은 인간보다 훨씬 더 나은 일을 할 수 있을 겁니다. 음, 인간보다 더 나은 일을 한다는 것이 아니라, 인간이 할 것보다 더 나은 일을 한다는 것입니다.

**swyx [01:40:56]**: 그건 그렇고, 얼라인먼트라는 단어, 제 생각에 안전 얼라인먼트와 지시 따르기 얼라인먼트 사이에 흥미로운 재정의나 동형사상이 있는 것 같습니다. 그리고 그것들이 어디서 갈라지는지 궁금합니다.

**Noam [01:41:09]**: 알겠습니다. 제 생각에 그것이 갈라지는 지점은, 모델을 무엇에 얼라인시키고 싶은가 하는 것입니다. 그것이, 제 생각에, 어려운 질문입니다. 예를 들어, 사용자에 얼라인시키고 싶다고 말할 수 있습니다. 좋습니다, 그럼 사용자가 인류의 절반을 쓸어버릴 새로운 바이러스를 만들고 싶어하면 어떻게 될까요? 그것이 안전 얼라인먼트입니다, 네. 그래서 제 생각에 얼라인먼트, 그것들은 관련이 있다고 생각합니다. 그리고 큰 질문은 '당신은 무엇을 향해 얼라인하고 있는가?'입니다.

**swyx [01:41:30]**: 네, 인류의 목표가 있고, 당신의 개인적인 목표가 있고, 그 사이의 모든 것이 있죠.

**Alessio [01:41:35]**: 그래서 그것이 개별 에이전트라고 생각합니다. 그리고 당신은 OpenAI에서 다중 에이전트 팀을 이끌고 있다고 발표했습니다. 저는 많은 것을 보지 못했습니다. 어떤 발표도요. 아마 제가 놓쳤을 수도 있지만, 당신이 작업해 온 것에 대해 흥미로운 연구 방향이나 그로부터 얻은 것이 있다면 무엇을 공유해 주실 수 있나요?

**Noam [01:41:51]**: 네, 이것에 대한 발표는 정말 없었습니다. 저희는 멋진 것들을 작업하고 있고, 언젠가는 멋진 것들을 발표할 수 있을 것이라고 생각합니다. 제 생각에 팀은 여러 면에서 사실 잘못된 이름입니다. 왜냐하면 우리는 다수 에이전트 외에도 더 많은 것을 연구하고 있기 때문입니다. 다수 에이전트는 우리가 연구하는 것들 중 하나입니다. 우리가 연구하는 다른 것들 중 일부는 추론 계산(test time compute)을 엄청나게 확장하는 것입니다. 그래서, 아시다시피, 우리는 지금 이 모델들이 15분 동안 사고하도록 만들고 있는데, 어떻게 하면 몇 시간, 며칠, 심지어 그 이상 사고하게 할 수 있을까요? 그리고 이를 통해 믿을 수 없을 정도로 어려운 문제들을 해결할 수 있게 할까요? 이것이 우리가 추구하는 한 방향입니다. 다수 에이전트는 또 다른 방향입니다. 그리고 여기에는 몇 가지 다른 동기가 있다고 생각합니다. 우리는 다수 에이전트의 협력적 측면과 경쟁적 측면 모두에 관심을 가지고 있습니다. 제가 설명하는 방식은 이렇습니다. AI 분야에서 사람들은 종종 인간이 매우 좁은 지능의 범위를 차지하고 있으며, AI는 빠르게 따라잡아 이 지능의 범위를 넘어설 것이라고 말합니다. 하지만 저는 사실 인간 지능의 범위가 그렇게 좁다고 생각하지 않습니다. 오히려 상당히 넓다고 봅니다. 예를 들어, 해부학적으로 동일한 원시 시대의 인간들을 수많은, 수십억 명의 인간들이 서로 협력하고 경쟁하며 시간이 흐름에 따라 문명을 구축한 결과와 비교해 보십시오. 오늘날 우리가 보는 기술은 바로 이 문명의 산물입니다. 그리고 저는 비슷하게, 오늘날 우리가 가진 AI는 일종의 AI 초기 단계에 불과하다고 생각합니다. 만약 수십억 개의 AI가 오랜 시간 동안 서로 협력하고 경쟁하며 본질적으로 문명을 구축할 수 있다면, 그들이 생산하고 답할 수 있는 것들은 오늘날 우리가 가진 AI로는 상상할 수 없는 수준을 훨씬 뛰어넘을 것입니다.

**Alessio [01:43:56]**: 그것이 짐 팬의 보이저(Voyager) 스킬 라이브러리 아이디어와 비슷하다고 보시나요? 이런 것들을 다시 저장하는 거요? 아니면 모델들이 이 새로운 지식으로 다시 훈련되는 것일까요? 왜냐하면 인간은 성장하면서 뇌에 많은 것을 가지고 있으니까요.

**Noam [01:44:10]**: 여기서 좀 회피적으로 말하자면... 우리는... 네, 우리는... 발표할 것이 있을 때까지는, 그리고 그리 멀지 않은 미래에 있을 것이라고 생각합니다. 저는 우리가 정확히 무엇을 하고 있는지에 대해 좀 모호하게 말할 것입니다. 하지만 우리가 다중 에이전트에 접근하는 방식의 세부 사항과 우리가 실제로 그것을 진행하는 방식은, 역사적으로 행해져 왔고 오늘날 다른 곳에서 행해지고 있는 방식과는 매우 다르다고 생각합니다. 저는 오랫동안 다중 에이전트 분야에 있었습니다. 저는 다중 에이전트 분야가... 그 분야가 취한 접근 방식과 그것이 접근된 방식에서 어떤 면에서는 좀 잘못되었다고 느꼈습니다. 그래서 우리는 다중 에이전트에 대해 매우 원칙적인 접근 방식을 취하려고 노력하고 있습니다.

**swyx [01:44:52]**: 죄송합니다, 덧붙여야겠네요. 당신이 무엇을 하고 있는지 말할 수는 없지만, 무엇이 잘못되었는지는 말할 수 있겠네요. 무엇이 잘못되었나요?

**Noam [01:44:57]**: 제 생각에 취해진 많은 접근 방식이 매우 휴리스틱했고, 스케일링과 연구에 대한 비터 레슨 접근 방식을 실제로 따르지 않았다고 생각합니다.

**Alessio [01:45:07]**: 알겠습니다. 아마 여기가 좋은 지점일 것 같습니다. 당신은 많은 놀라운 일을 하셨습니다. 포커에서 많은 놀라운 일을 하셨고, 추론 모델이 더 좋아지면서, 저는 예전에 하드코어 포커 그라인더였던 친구와 이야기하고 있었는데, 제가 당신을 인터뷰할 것이라고 말했습니다. 그리고 그들의 질문은, 테이블에서 당신은 한 사람이 어떻게 플레이하는지에 대해 작은 샘플 크기로 많은 정보를 얻을 수 있다는 것이었습니다. 하지만 오늘날 GTO는 너무 널리 퍼져 있어서 때로는 사람들이 착취적으로 플레이할 수 있다는 것을 잊어버립니다. 당신의 생각은 어떻습니까? 다중 에이전트와 경쟁에 대해 생각할 때, 항상 최적의 것을 찾으려고 노력할까요? 아니면 많은 부분이... 순간에 더 많이 생각하고, 누군가를 어떻게 착취할지 생각하는 것일까요?

**Noam [01:45:46]**: 아마도 당신의 청중은 포커 용어에 그다지 익숙하지 않을 것이므로, 이것을 좀 설명하겠습니다. 물론입니다. 많은 사람들이 포커는 그냥 운 게임이라고 생각하는데, 그건 사실이 아닙니다. 실제로는... 포커에는 많은 전략이 있습니다. 그래서, 올바른 전략을 사용하면 포커에서 꾸준히 이길 수 있습니다. 포커에는 다른 접근 방식이 있습니다. 하나는 게임 이론 최적(game theory optimal)입니다. 이것은, 당신이 기대값에서 이길 수 없는 전략을 플레이하는 것입니다. 당신은 그냥 착취당하지 않습니다. 마치 가위바위보와 같습니다. 가위바위보에서 이길 수 없게 만들 수 있습니다. 그냥 가위, 바위, 보를 같은 확률로 무작위로 선택하면 됩니다. 왜냐하면 상대방이 무엇을 하든, 당신을 착취할 수 없기 때문입니다. 당신은 이길 것입니다. 기대값에서 지지 않을 것입니다. 이제, 많은 사람들이 그것을 듣고, '음, 그것은 또한 당신이 기대값에서 이길 수 없다는 것을 의미한다. 왜냐하면 당신은 그냥 완전히 무작위로 플레이하고 있기 때문이다'라고 생각합니다. 하지만 포커에서는, 만약 당신이 균형 전략을 플레이한다면, 상대방이 당신과 비기기 위해 어떻게 해야 하는지 알아내는 것이 정말 어렵습니다. 그리고 그들은 결국 당신이 이기게 될 실수를 하게 될 것입니다. 그리고 그들은 장기적으로 당신이 이기게 될 실수를 하게 될 것입니다. 그것이 엄청난 승리는 아닐지라도, 승리가 될 것입니다. 충분히 많은 핸드를 충분히 오랜 기간 동안 플레이하면, 당신은 기대값에서 이길 것입니다. 이제, 착취적 포커(exploitative poker)도 있습니다. 여기서 아이디어는 상대방이 플레이하는 방식의 약점을 발견하려고 노력하는 것입니다. 예를 들어, 그들이 충분히 블러핑을 하지 않거나, 블러핑에 너무 쉽게 폴드하는 경우입니다. 그래서 당신은 게임 이론 최적의 균형 전략, 즉 때로는 블러핑하고 때로는 블러핑하지 않는 것에서 벗어나, '오, 나는 그냥 이 사람에게 엄청나게 블러핑을 할 거야. 왜냐하면 내가 블러핑할 때마다 항상 폴드하니까'와 같은 매우 불균형한 전략을 플레이하기 시작합니다. 이제, 핵심은 여기에 트레이드오프가 있다는 것입니다. 왜냐하면 만약 당신이 이 착취적 접근 방식을 취한다면, 당신은 또한 착취에 노출되기 때문입니다. 그래서 당신은 지지 않을 것을 보장하지만 잠재적으로 벌 수 있는 만큼의 돈을 벌지 못할 수도 있는 방어적인 게임 이론 최적 정책을 플레이하는 것과, 훨씬 더 수익성이 높을 수 있지만 상대방이 이용하고 속일 수 있는 약점을 만드는 착취적 전략을 플레이하는 것 사이에서 이 균형을 선택해야 합니다. 그리고 그 둘을 완벽하게 균형 잡을 방법은 없습니다. 마치 가위바위보와 같습니다. 만약 누군가가 5번 연속으로 보를 내는 것을 본다면, '오, 그들의 전략에 약점이 있구나. 나는 그냥 가위를 내야겠다. 그리고 그들을 이용할 거야'라고 생각할 수 있습니다. 그래서 6번째에 가위를 내지만, 사실 그때 그들은 바위를 냅니다. 그리고 당신은 결코 알 수 없습니다. 그래서 항상 이 트레이드오프가 있습니다. 매우 성공적이었던 포커 AI들, 그리고 제 배경은, 저는 대학원 시절 몇 년 동안 포커용 AI를 연구했고 최초의 초인적인 노리밋 포커 AI를 만들었습니다. 우리가 취한 접근 방식은 이 게임 이론 최적 접근 방식이었습니다. AI들이 이길 수 없는 전략을 플레이하고, 세계 최고들과 대결하여 그들을 이겼습니다. 이제, 그것은 또한 그들이 세계 최악을 이겼다는 것을 의미합니다. 그들은 그냥 누구든 이겼습니다. 하지만 만약 그들이 약한 상대와 마주했다면, 인간 전문가만큼 심하게 이기지는 못했을 수도 있습니다. 왜냐하면 인간 전문가는 게임 이론 최적 정책에서 벗어나 이 약한 플레이어들을 착취하는 방법을 알기 때문입니다. 그래서 '어떻게 착취적인 포커 AI를 만드는가?'와 같은 미해결 질문이 있습니다. 그리고 많은 사람들이 이 연구 방향을 추구했습니다. 저는 대학원 시절에 그것에 약간 손을 댔습니다. 그리고 저는 근본적으로 그것이 AI가 인간만큼 샘플 효율적이지 않다는 것으로 귀결된다고 생각합니다. 아시다시피, 우리는 이전에 논의했습니다. 인간이 포커를 할 때, 그들은 십여 핸드 내에 플레이어의 강점과 약점에 대해 정말 좋은 감을 얻을 수 있습니다. 솔직히 정말 인상적입니다. 그리고 우리가 2010년대 중반에 포커용 AI를 연구할 때, 이 AI들은 이 플레이어가 누구인지, 어떻게 플레이하는지, 약점이 어디인지에 대한 좋은 프로필을 얻기 위해 1만 핸드의 포커를 플레이해야 했습니다. 이제, 저는 더 최근의 기술로 그것이 줄어들었다고 생각합니다. 하지만 여전히, 샘플 효율성은 큰 도전 과제였습니다. 이제, 흥미로운 것은 포커 작업을 한 후, 저는 디플로머시를 작업했습니다. 우리는 이것에 대해 이전에 이야기했다고 생각합니다. 그리고 디플로머시는, 아시다시피, 7인 협상 게임입니다. 그리고 우리가 그것을 작업하기 시작했을 때, 저는 문제에 대해 매우 게임 이론적인 접근 방식을 취했습니다. 저는 '좋아, 이것은 포커와 같다. 이 게임 이론 최적 정책을 계산해야 한다. 그리고 그냥 이것을 플레이하면 된다. 기대값에서 지지 않을 것이고, 실제로는 이길 것이다'라고 느꼈습니다. 하지만 실제로는 디플로머시에서는 작동하지 않습니다. 그리고 그것이 작동하지 않는 이유는, 우리가 이 토끼굴에 얼마나 깊이 들어갈 것인가 하는 질문에 대한 것이지만, 기본적으로, 포커와 같은 제로섬 게임을 할 때는 게임 이론 최적이 정말 잘 작동합니다. 디플로머시와 같은 게임, 즉 협력하고 경쟁해야 하고 협력의 여지가 있는 게임을 할 때는 게임 이론 최적이 실제로는 그렇게 잘 작동하지 않습니다. 그리고 당신은 플레이어들을 이해하고 그들에게 훨씬 더 잘 적응해야 합니다. 그래서, 이것은 포커에서의 문제, 즉 상대방에게 어떻게 적응하는가 하는 문제와 매우 유사하게 됩니다. 포커에서는 그들의 약점에 적응하고 그것을 이용하는 것에 관한 것입니다. 디플로머시에서는 그들의 플레이 스타일에 적응하는 것에 관한 것입니다. 마치, 당신이 테이블에 있고 모두가 프랑스어를 말하고 있다면, 당신은 그냥 계속 영어로 말하고 싶지 않을 것입니다. 당신은 그들에게 적응하고 프랑스어로도 말하고 싶을 것입니다. 그것이 제가 디플로머시에서 깨달은 것입니다. 우리는 이 게임 이론 최적 패러다임에서 벗어나 다른 플레이어들을 모델링하고, 그들이 누구인지 이해하고, 그에 따라 대응하는 방향으로 전환해야 한다는 것입니다. 그래서, 여러 면에서, 우리가 디플로머시에서 개발한 기술들은 착취적입니다. 착취적이지 않습니다. 그것들은 정말로, 아시다시피, 상대방, 테이블의 다른 플레이어들에게 적응하는 것입니다. 하지만 저는 같은 기술들이 포커용 AI에서 착취적인 포커 AI를 만드는 데 사용될 수 있다고 생각합니다. 만약 제가 언어 모델로 보고 있는 놀라운 진전에 AGI-pilled되지 않고, 제 전체 연구 의제를 일반적인 추론에 집중하는 것으로 바꾸지 않았다면, 아마도 제가 다음에 작업했을 것은 이런 착취적인 포커 AI를 만드는 것이었을 겁니다. 맞습니다. 그래서, 정말 재미있는 연구 방향입니다. 저는 그것이 하고 싶은 사람 누구에게나 여전히 열려 있다고 생각합니다. 그리고 저는 핵심이 우리가 디플로머시에서 사용한 기술을 가져와 포커 같은 것에 적용하는 것이라고 생각합니다.

**Alessio [01:51:16]**: 제 생각에, 저에게 핵심은 온라인에서 플레이할 때 HUD가 있다는 것입니다. HUD는 다른 플레이어에 대한 모든 통계, 예를 들어 프리플랍 참여율 등을 알려줍니다. 그리고 제 생각에, 제 이해로는 이 모델들 중 많은 수가 테이블에 있는 다른 플레이어들의 행동을 실제로 활용하지 않고 있습니다. 그들은 그냥 보드 상태를 보고 거기서부터 작업하는 것 같습니다.

**Noam [01:51:36]**: 맞습니다. 그건 사실입니다. 그건 사실입니다. 그건 사실입니다. 특히 오늘날 포커 AI가 작동하는 방식은 그렇습니다. 그들은 그냥 미리 계산된 GTO 전략에 충실하고, 테이블의 다른 플레이어들에게 적응하지 않습니다. 그리고, 그들이 적응하게 하기 위해 다양한, 일종의 해키한 것들을 할 수 있지만, 그것들은 그다지 원칙적이지 않고, 아주 잘 작동하지 않습니다.

**swyx [01:51:55]**: 네. 알겠습니다. 듣고 있는 대학원생 있나요? 네. 만약 그것에 대해 연구하고 싶다면, 저는 그것이 매우, 매우 합리적인 연구 방향이라고 생각합니다. 적어도 당신 앞에 놓이고, 어느 정도 주목을 받을 수 있을 겁니다. 네. 제 생각에 이 대화가 저에게 떠올리게 하는 한 가지는, 네, 테스트 시간 컴퓨팅 다음 단계가 무엇인지에 대한 가설 중 하나는 월드 모델입니다. 월드 모델링이 중요하거나 가치 있는 연구 방향인가요? 얀 르쿤은 이것에 대해 끊임없이 이야기하고 있지만, 기본적으로 어떤 LLM도, 내부 월드 모델은 가지고 있지만, 명시적인 월드 모델은 가지고 있지 않습니다.

**Noam [01:52:29]**: 이 모델들이 커질수록 월드 모델을 가지게 되고, 그 월드 모델이 스케일에 따라 더 좋아진다는 것은 꽤 명백하다고 생각합니다. 그래서, 그들은 암묵적으로 월드 모델을 개발하고 있으며, 저는 그것을 명시적으로 모델링할 필요가 없다고 생각합니다. 제가 틀릴 수도 있지만요.

**swyx [01:52:48]**: 사람이나 다중 에이전트를 다룰 때는 그럴 수도 있습니다. 왜냐하면 당신은 세상이 아닌 개체들을 가지고 있고, 당신이 다룰 수 있는 많은 유형의 개체들 중 어떤 것인지에 대한 가설을 해결하고 있기 때문입니다.

**Noam [01:53:00]**: 아시다시피, 다중 에이전트 AI 커뮤니티에서는 오랫동안, 그리고 지금도 계속되고 있는 논쟁이 있었습니다. 다른 에이전트, 즉 다른 사람들을 명시적으로 모델링해야 하는지, 아니면 환경의 일부로서 암묵적으로 모델링될 수 있는지에 대한 것입니다. 오랫동안 저는, '물론 이 다른 에이전트들을 명시적으로 모델링해야 한다'는 관점을 가졌습니다. 왜냐하면 그들은 환경과 다르게 행동하고, 행동을 취하며, 예측 불가능하고, 행위성(agency)을 가지고 있기 때문입니다. 하지만 저는 시간이 지남에 따라 생각이 바뀌어, 사실 이 모델들이 충분히 똑똑해지면, 그들은 마음 이론 같은 것을 개발한다고 생각하게 되었습니다. 그들은 자신들이... 행동을 취하고 동기를 가질 수 있는 에이전트라는 이해를 발전시킵니다. 그리고 이러한 모델들은 규모와 더 강력한 행동을 통해 암묵적으로 그러한 능력을 개발합니다. 멋지네요. 그래서, 요즘 제가 취하는 관점은 그것입니다.

**swyx [01:53:47]**: 그래서, 제가 방금 말한 것은 비터 레슨으로 채워지지 않은 휴리스틱의 예이고, 당신은 그냥, 그것은 그냥 사라집니다. 네.

**Noam [01:53:53]**: 정말 모든 것이 비터 레슨으로 돌아옵니다.

**swyx [01:53:56]**: 모든 AI 팟캐스트에서 그들을 인용해야 합니다. 그래서, 흥미로운 발견 중 하나이자 가장 일관된 발견 중 하나는, 당신이 ICLR에 있었고, 거기서 히트했던 강연 중 하나가 개방성에 관한 것이었다고 생각합니다. 그리고 그 강연을 한 팀이라는 사람은 다중 에이전트 시스템에 대해서도 많은 연구를 해왔습니다. 가장 일관된 발견 중 하나는 항상 AI가 인간이 훈련하고 안내하는 것보다 경쟁적으로 자가 대국을 하고 개선하는 것이 더 낫다는 것입니다. 그리고 당신은 알파제로와 R1.0 같은 것에서 그것을 발견합니다. 이것이 다중 에이전트에서도, 즉 인간보다 더 나은 개선을 위해 자가 대국이 유효할 것이라고 생각하십니까? 네.

**Noam [01:54:33]**: 네, 알겠습니다. 이것은 훌륭한 질문입니다. 그리고... 이 질문에 대해 좀 더 자세히 설명할 가치가 있다고 생각합니다. 오늘날 많은 사람들이 자가 대국을 초지능을 향한 다음 단계이자 아마도 마지막 단계로 보고 있다고 생각합니다. 알파고와 알파제로 같은 사례를 보면, 우리는 매우 유사한 추세를 따르고 있는 것 같습니다, 그렇죠? 알파고의 첫 단계는 대규모 사전 훈련(pre-training)이었습니다. 그 당시에는 인간의 바둑 기보를 사용했죠. 대규모 언어 모델(LLM)의 경우, 방대한 인터넷 데이터로 사전 훈련을 합니다. 그리고 그것은 강력한 모델을 만들어주지만… 초인적인 모델은 아닙니다. 그리고 알파고 패러다임의 다음 단계는 대규모 추론 계산(inference compute) 또는 대규모 테스트 시간 컴퓨팅을 수행하는 것입니다. 그 경우에는 몬테카를로 트리 탐색(MCTS)을 사용했습니다. 그리고 이제 우리는 이러한 대규모 추론 계산을 수행하는 사고 모델들을 가지고 있습니다. 그리고 다시, 그것은 능력을 엄청나게 향상시킵니다. 마지막으로, 알파고와 알파제로에는 자가 대국이 있습니다. 모델이 자신과 대결하고, 그 게임들로부터 배우고, 점점 더 나아져서, 인간 수준의 성능에서 인간의 능력을 훨씬 뛰어넘는 수준으로 발전합니다. 이 바둑 정책들은 이제 너무 강력해서 인간으로서는 이해하기조차 어렵습니다. 그들이 하는 일은 인간에게는 이해할 수 없습니다. 체스도 마찬가지입니다. 그리고 우리는 지금 언어 모델에서는 그것을 가지고 있지 않습니다. 그래서 그것을 보고 '아, 우리는 이제 이 AI 모델들이 서로 상호작용하고 그들로부터 배우게 하기만 하면, 그들은 그냥 초지능에 도달할 것이다'라고 말하고 싶은 유혹이 정말 큽니다. 도전 과제는, 그리고 제가 디플로머시에 대해 이야기할 때 약간 언급했듯이, 바둑이 2인 제로섬 게임(two-player zero-sum game)이라는 것입니다. 그리고 2인 제로섬 게임은 자가 대국을 할 때 최소최대 균형(minimax equilibrium)에 수렴한다는 매우 좋은 속성을 가지고 있습니다. 그리고 한 걸음 물러서서 말하자면, 2인 제로섬 게임, 즉 체스, 바둑, 심지어 2인 포커, 모두 2인 제로섬입니다. 음, 그건 사실이 아닙니다. 당신이 일반적으로 원하는 것은 최소최대 균형이라고 불리는 것입니다. 이것이 그 GTO 정책, 즉 당신이 플레이하는 이 정책으로, 어떤 상대에게도 기대값에서 지지 않을 것을 보장합니다. 저는 체스와 바둑에서는 그것이 꽤 명백하게 당신이 원하는 것이라고 생각합니다. 흥미롭게도, 포커를 보면, 그것은 그렇게 명백하지 않습니다. 2인 제로섬 버전의 포커에서는 GTO 최소최대 정책을 플레이할 수 있고, 그것은 지구상의 어떤 상대에게도 지지 않을 것을 보장합니다. 하지만, 다시 말하지만, 약한 플레이어로부터는 착취적 정책(exploitative policy)을 플레이했을 때만큼 많은 돈을 벌지는 못할 것입니다. 그래서, '당신은 무엇을 원하는가?'라는 질문이 있습니다. 가능한 한 많은 돈을 벌고 싶습니까, 아니면 살아있는 어떤 인간에게도 지지 않을 것을 보장하고 싶습니까? 모든 봇들이 결정한 것은, 음, 이 게임들의 모든 AI 개발자들이 결정한 것은, '음, 우리는 최소최대 정책을 선택할 것이다'입니다. 그리고 편리하게도, 그것이 바로 자가 대국이 수렴하는 것입니다. 이 AI들이 서로 대결하고, 그들의 실수로부터 배우게 하면, 그들은 시간이 지남에 따라 이 최소최대 정책으로 수렴합니다, 보장됩니다. 하지만 일단 2인 제로섬 게임을 벗어나면, 그것은 더 이상 유용한 정책이 아닙니다. 당신은 그냥 이런 매우 방어적인 정책을 가지고 싶지 않을 것이고, 수학 같은 것에서 같은 종류의 자가 대국을 시작하면 정말 이상한 행동을 하게 될 것입니다.

**swyx [01:58:39]**: 그렇다면 그것의 목적 함수는 무엇인가요? 새로운 목적 함수는 무엇인가요?

**Noam [01:58:43]**: 네, 좋은 질문입니다. 그리고 제 생각에 그것은 많은 사람들이 생각하고 있는 것입니다. 네.

**swyx [01:58:50]**: 당신도 그럴 거라고 확신합니다. 당신이 했던 마지막 팟캐스트 중 하나에서, 자가 대국의 아이디어를 언급하셨습니다. Sora에 매우 감명받았다고 하셨죠. Sora에 직접적으로 작업하지는 않지만, 분명히 OpenAI의 일부입니다. 제 생각에 가장 최근의 새로운 업데이트, 또는 그 생성 미디어 공간에서는 자기회귀적(auto-regressive) 이미지 생성입니다. 그것이 당신이 언급하고 싶은 어떤 방식으로든 흥미롭거나 놀라운가요?

**Noam [01:59:10]**: 저는 이미지 생성 작업을 하지 않아서, 이것에 대해 언급할 수 있는 제 능력이 좀 제한적입니다. 하지만 저는 그것을 좋아한다고 말할 수 있습니다. 저는 그것이 매우 인상적이라고 생각합니다. 그것은, 아시다시피, 당신이 이 추론 모델들을 작업하고, '와, 우리는 고급 과학이나 에이전트 작업, 소프트웨어 엔지니어링 같은 온갖 미친 짓을 할 수 있을 거야'라고 생각하는 것과 같습니다. 그리고 나서, '오, 이제 이미지와 비디오를 만들 수 있구나, 그리고 그것은 너무 재미있다'와 같은 완전히 다른 차원의 발전이 있습니다. 그리고 솔직히, 특히 일반 대중에게서 그것이 훨씬 더 많은 관심을 받고 있습니다. 그리고 그것은 아마도 ChachBT의 구독 계획을 훨씬 더 많이 이끌고 있을 것입니다. 그것은 훌륭하지만, 제 생각에 좀 웃긴 것은, 네, 우리도, 약속하건대, 우리도 초지능을 연구하고 있다는 것입니다.

**swyx [01:59:50]**: 하지만 모든 것을 지브리(Ghibli)처럼 만들 수 있습니다. 제 생각에 저에게 델타는, 저는 사실 자기회귀적 방출 때문에 디퓨전(diffusion)이 끝났다는 이 논제를 품고 있었습니다. 작년 말에 이것에 대한 소문이 있었고, 분명히 지금은 나왔습니다. 그리고 나서 제미나이(Gemini)가 텍스트 디퓨전으로 나오고, 디퓨전은 너무 나쁩니다. 그리고 이것은 두 방향이고, 자기회귀 대 디퓨전의 추론에 매우 관련이 있습니다. 우리는 둘 다 가질 수 있나요? 하나가 이기나요?

**Noam [02:00:18]**: 연구의 아름다움은, 아시다시피, 다른 방향을 추구해야 한다는 것입니다. 그리고 무엇이 유망한 길인지 항상 명확하지는 않을 것입니다. 그리고 저는 사람들이 다른 방향을 탐구하고 다른 것들을 시도하는 것이 훌륭하다고 생각합니다. 그 탐험에는 많은 가치가 있고, 우리 모두가 무엇이 효과가 있는지 보는 것으로부터 이익을 얻는다고 생각합니다.

**swyx [02:00:38]**: 디퓨전 추론에 잠재력이 있나요? 예를 들어 당신의... 아마도 그 질문에 답할 수 없겠네요.

**Alessio [02:00:43]**: 알겠습니다. 로보틱스 석사도 하셨죠. 당신의 생각에 대해 듣고 싶습니다. 첫째, OpenAI는 펜 돌리기 트릭과 그들이 만들고 싶었던 로봇 팔로 시작했습니다. 이 휴머노이드 같은 것에 작업하는 것이 맞을까요? 그것이 AI의 잘못된 구현이라고 생각하시나요? 일반적인 '언제 로봇을 얻게 될까' 같은 질문 외에, 지금 근본적으로 탐구되지 않고 있다고 생각하는 것이 있나요?

**Noam [02:01:06]**: 사람들이 로보틱스에서 정말로 해야 할 일이요? 저는 몇 년 전에 로보틱스 석사를 했습니다. 그리고 그 경험에서 얻은 교훈은... 우선, 저는 실제로 로봇과 그렇게 많이 작업하지 않았습니다. 저는 기술적으로 로보틱스 프로그램에 있었고, 프로그램 첫 주에 레고 로봇을 좀 가지고 놀았습니다. 하지만 그 후, 솔직히, 저는 그냥 꽤 빨리 포커용 AI 작업으로 전환했습니다. 그리고 그것은 명목상으로는 로보틱스 석사 과정에 있었습니다. 하지만 모든 로봇 공학자들과 교류하고 그들의 연구를 보면서 얻은 제 교훈은 로봇 작업을 하고 싶지 않다는 것이었습니다. 왜냐하면 물리적 하드웨어를 다룰 때 연구 주기가 훨씬 더 느리고 훨씬 더 고통스럽기 때문입니다. 소프트웨어는 훨씬 더 빨리 진행됩니다. 그리고 저는 그것이 우리가 언어 모델과 모든 가상 동료 종류의 작업에서 그렇게 많은 진전을 보고 있지만 로보틱스에서는 그다지 많은 진전을 보지 못한 이유라고 생각합니다. 물리적 하드웨어는 반복하기가 훨씬 더 고통스럽습니다. 휴머노이드 문제에 대해서는, 이것은 제가 작업하는 분야가 아니기 때문에 그다지 강한 의견이 없습니다. 하지만 비휴머노이드 로보틱스에도 많은 가치가 있다고 생각합니다. 저는 드론이 완벽한 예라고 생각합니다. 거기에는 분명히 많은 가치가 있습니다. 그것이 휴머노이드인가요? 아니요. 하지만 여러 면에서, 그것은 훌륭합니다. 아시다시피, 그런 종류의 기술에는 휴머노이드가 필요하지 않습니다. 저는 매주, 그것이 비휴머노이드라고 생각합니다. 그리고 저는 그것이 휴머노이드 로봇이 많은 가치를 제공하는 방법의 훌륭한 예라고 생각합니다.

**Alessio [02:02:23]**: 저는 리처드 해밍(Richard Hemming)의 '과학과 공학을 하는 기술(The Art of Doing Science and Engineering)'을 읽고 있었는데, 그는 새로운 기술적 변화가 있을 때 사람들이 오래된 작업량을 가져와서 새로운 기술로 그냥 복제하려고 한다고 말합니다. 실제로는 그것을 하는 방식을 바꿔야 한다고요. 그리고, 아시다시피, 제가 이 비디오, 즉 집에 있는 당신의 휴머노이드 비디오를 볼 때, '음, 인간의 형태는 실제로는 개선될 수 있는 많은 한계를 가지고 있다'고 생각하게 됩니다. 하지만 제 생각에 사람들은 익숙한 것을 원합니다. 예를 들어, 팔이 10개이고 다리가 5개인 로봇을 집에 두시겠습니까? 아니면 밤에 일어나서 그 물건이 걸어 다니는 것을 보면 으스스할까요? 그래서 우리가 휴머노이드를 사용하는 것일까요? 그래서 제 생각에, 거의 '우리는 그것을 인간처럼 보이게 만들어야 한다'는 지역적 극대점(local maxim)이 있는 것 같습니다. 하지만 제 생각에, 집안에서 가장 좋은 형태는 무엇일까요?

**Noam [02:03:08]**: 저는 제품 디자인에 끔찍해서, 이 질문에 답할 사람이 아닙니다. 제 생각에, 우리에게 더 익숙하기 때문에 휴머노이드를 만드는 것이 더 나은가, 아니면 우리와 더 비슷하지만 완전히 동일하지는 않기 때문에 휴머노이드를 만드는 것이 더 나쁜가 하는 질문이 있습니다. 저는 실제로 어느 쪽이 더 소름 끼칠지 모르겠습니다.

**swyx [02:03:25]**: 네. 네. 저를 휴머노이드에 약간 빠지게 한 것은 세상의 대부분이 어차피 인간을 위해 만들어졌다는 주장이었습니다. 그래서 인간 노동을 대체하고 싶다면, 휴머노이드를 만들어야 한다는 거죠. 그게 설득력이 있는지는 모르겠습니다.

**Noam [02:03:38]**: 다시 말하지만, 저는 이 분야에서 일하지 않기 때문에 그다지 강한 의견이 없습니다. 저는 휴머노이드에 약하게 찬성하는 편이었는데, 저를 비휴머노이드에 약하게 찬성하도록 설득한 것은 피지컬 인텔리전스(physical intelligence) CEO의 말을 듣고, 그들이 왜 비휴머노이드 로보틱스를 추구하는지에 대한 그의 발표를 들었을 때였습니다. 알겠습니다. 그리고 편리하게도, 그들의 사무실은 사실 여기와 매우 가깝습니다. 그래서 만약 당신이 원한다면— 그들이 제가 운영하는 컨퍼런스에서 연설합니다. 알겠습니다, 완벽하네요. 네. 그래서 저는 그것을 기대하고 있습니다. 그래서, 아시다시피, 그의 발표를 듣고 아마도 그가 당신을 비휴머노이드가 갈 길이라고 설득할 수 있을 것이라고 말하고 싶습니다.

**swyx [02:04:08]**: 멋지네요. 제가 사람들에게 추천하고 싶은 다른 하나는 짐 팬이 최근에 세쿼이아 컨퍼런스에서 한 물리적 튜링 테스트에 대한 강연입니다. 매우, 매우 좋았습니다. 그는 사물을 설명하는 훌륭한 교육자이자 설명가입니다. 특히 그 분야에서는 매우 어렵습니다. 멋지네요. 당신이 작업하지 않는 것에 대해 묻는 것은 끝났습니다. 그래서 이것들은 당신의 경계를 탐색하고 빠른 답변을 얻기 위한 더 많은 속사포 질문들입니다. 당신이나 최고의 산업 연구소들은 어떻게 연구를 따라잡나요? 당신의 도구와 관행은 무엇인가요?

**Noam [02:04:39]**: 정말 어렵습니다. 많은 사람들이 학술 연구는 관련이 없다는 인식을 가지고 있다고 생각합니다. 그리고 그것은 사실이 아닙니다. 제 생각에 우리는 학술 연구를 봅니다. 도전 과제 중 하나는—. 네. 도전 과제 중 하나는, 많은 학술 연구가 논문에서는 유망해 보이지만, 실제로는 스케일에서 작동하지 않거나 심지어 재현되지 않는다는 것입니다. 만약 우리가 흥미로운 논문을 발견하면, 우리는 그것을 내부에서 재현해보고 그것이 여전히 유효한지, 그리고 또한 잘 확장되는지 확인하려고 할 것입니다. 하지만 그것은 우리에게 큰 영감의 원천입니다.

**swyx [02:05:09]**: 아카이브(Archive)에 올라오는 것은 무엇이든, 말 그대로, 당신도 우리와 똑같이 하나요, 아니면 특별한 과정이 있나요?

**Noam [02:05:15]**: 특히 추천을 받으면요. 우리는 내부적으로— 입소문입니다. 네. 사람들이 흥미로운 논문을 올리는 곳이 있습니다. 네. 그리고, 제 생각에 그것은 '좋아, 이 분야에 더 익숙한 이 사람이 이 논문이 흥미롭다고 생각하니까, 나도 읽어야겠다'와 같은 좋은 출처입니다. 네. 그리고 비슷하게, 저는 제 분야에서 일어나고 있는 흥미로운 일들을 계속 추적할 것입니다. 그리고 만약 제가 정말 흥미롭다고 생각하면, 아마도 공유할 것입니다.

**swyx [02:05:34]**: 저에게는, 왓츠앱과 시그널 그룹 채팅에 연구자들과 함께 있는 것이 전부입니다. 네.

**Noam [02:05:38]**: 제 생각에는, 많은 사람들이 트위터 같은 것을 보고, 우리가 소셜 미디어에서 많은 관심을 받아야 주목받는 지경에 이르렀다는 것이 정말 안타깝다고 생각합니다.

**swyx [02:05:50]**: 그것이 대학원생들이 훈련받는 것입니다—그들은 이것을 하기 위해 수업을 듣고 있습니다.

**Noam [02:05:53]**: 저는 대학원생들과 함께 일했고—지금은 덜 일합니다. 왜냐하면 우리가 그렇게 많이 출판하지 않기 때문입니다—하지만 제가 FAIR에서 논문을 출판할 때, 함께 일하는 대학원생들에게 트위터에 올려야 한다고 말했습니다. 네. 그리고 당신은—그리고 우리는 작업을 어떻게 제시할지에 대한 트위터 스레드 같은 것을 검토하고, 거기에는 진짜 기술이 있고, 그것은 중요합니다. 그리고 그것은 좀 슬픈 진실입니다. 네.

**Alessio [02:06:15]**: 네. 아시다시피, 당신이 ACPC, 즉 AI 포커 대회를 할 때, 사람들이 추론 시 CPU가 2개로 제한되어 있어서 탐색을 하지 않는다고 언급하셨습니다. 음-흠. 오늘날에도 흥미로운 연구가 이루어지는 것을 막는 비슷한 것들이 있다고 보시나요? 그것이—그렇게 인기가 없고, 최고의 컨퍼런스에 들어가지 못하게 하는, 환경적인 제한 요인이 있나요? 물론입니다.

**Noam [02:06:37]**: 그리고 저는 한 가지 예가 벤치마크라고 생각합니다. 인류의 마지막 시험(humanity's last exam) 같은 것을 보면, 엄청나게 어려운 문제들이 있지만, 여전히 매우 쉽게 채점할 수 있습니다. 그리고 저는 그것이 그 패러다임에 머무른다면 이 모델들을 평가할 수 있는 범위를 실제로 제한한다고 생각합니다. 그것은 매우 편리합니다. 왜냐하면, 아시다시피, 모델들을 채점하기가 매우 쉽기 때문입니다. 하지만 실제로, 우리가 이 모델들을 평가하고 싶은 많은 것들은 다지선다형 문제가 아닌, 좀 더 모호한 작업들입니다. 음-흠. 그리고 그런 종류의 것들을 위한 벤치마크를 만드는 것은 훨씬 더 어렵고, 아마도 평가하는 데 훨씬 더 비쌀 것입니다. 하지만 저는 그것들이 작업할 가치가 있는 정말 가치 있는 것들이라고 생각합니다.

**Alessio [02:07:13]**: 그리고 그것은 GPT-4.5를 높은 취향의 모델로 설정하는 것과 맞을 것입니다. 모델에 대해 측정할 수 없는 좋은 점들이 많이 있는데, 아마도 사람들은 그렇지 않을 것입니다.

**Noam [02:07:25]**: 음, 제 생각에 측정할 수 있는 것들이 있지만, 측정하기가 훨씬 더 어렵습니다. 그리고 저는 많은 벤치마크가 측정하기는 정말 쉽지만 정말 어려운 문제를 내는 이 패러다임에 머물러 왔다고 생각합니다. 네.

**swyx [02:07:37]**: 그럼 사전 훈련 스케일링 패러다임이 GPT 발견부터 GPT-4까지 확장하는 데 약 5년이 걸렸다고 가정합시다. 그리고 테스트 시간 컴퓨팅에도 5년을 줍시다. 만약 2030년까지 테스트 시간 컴퓨팅이 한계에 부딪힌다면, 그 원인은 무엇일까요?

**Noam [02:07:54]**: 사전 훈련의 일부에 관해서는, 사전 훈련을 훨씬 더 밀어붙일 수 있습니다. 단지 반복할 때마다 더 비싸질 뿐입니다. 저는 테스트 시간 컴퓨팅에서도 비슷한 것을 보게 될 것이라고 생각합니다. 우리는 그들이 3분 대신 3시간, 그리고 3일, 3주 동안 생각하게 만들 것입니다. 오, 인간의 수명이 다하네요. 음, 알겠습니다. 그래서 두 가지—두 가지—두 가지 우려가 있습니다. 하나는 모델들이 그렇게 오랫동안 생각하게 하거나, 테스트 시간 컴퓨팅을 확장하는 것이 훨씬 더 비싸진다는 것입니다. 테스트 시간 컴퓨팅을 확장함에 따라, 테스트 시간 컴퓨팅에 더 많은 비용을 지출하게 되고, 이는 지출할 수 있는 금액에 한계가 있다는 것을 의미합니다. 그것이 하나의 잠재적인 천장입니다. 이제, 분명히—음, 분명하지는 않지만, 저는 우리가 또한 더 효율적이 되고 있다고 말해야 합니다. 이 모델들은 생각하는 방식에서 더 효율적이 되고 있어서, 같은 양의 테스트 시간 컴퓨팅으로 더 많은 것을 할 수 있습니다. 그리고 저는 이것이 매우 과소평가된 점이라고 생각합니다. 우리가 단지 이 모델들을 더 오래 생각하게 만드는 것만이 아니라는 점입니다. 두 번째 요점은, 이 모델들이 더 오래 생각하게 함에 따라, 실제 시간(wall-clock time)에 의해 병목 현상이 발생한다는 것입니다. 이 모델들이 즉시 응답할 때는 실험을 반복하기가 정말 쉽습니다. 그들이 응답하는 데 3시간이 걸릴 때는 훨씬 더 어렵습니다. 그리고 3주가 걸리면 어떻게 될까요? 그 평가를 하고 그것을 반복하는 데 최소 3주가 걸립니다. 그리고 이 중 많은 부분에서 실험을 어느 정도 병렬화할 수 있지만, 많은 경우 실험을 실행하고 완료한 다음 결과를 봐야 다음 실험 세트를 결정할 수 있습니다. 저는 이것이 사실 긴 타임라인에 대한 가장 강력한 근거라고 생각합니다. 모델들이 해야 할 일이 너무 많기 때문입니다. 그리고 저는 그것이 도메인에 따라 다르다고 생각합니다. 그래서 신약 개발은 이것이 실제 병목이 될 수 있는 한 도메인이라고 생각합니다. 만약 어떤 것이 인간의 수명을 연장하는지 보고 싶다면, 당신이 개발한 이 새로운 약이 실제로 인간의 수명을 연장하고 그 과정에서 끔찍한 부작용이 없는지 알아내는 데 오랜 시간이 걸릴 것입니다.

**swyx [02:09:38]**: 저는 그것이 도전 과제라고 생각합니다.

**Noam [02:09:44]**: 그리고 저는 그것이 도메인에 따라 다르다고 생각합니다. 그래서 신약 개발은 이것이 실제 병목이 될 수 있는 한 도메인이라고 생각합니다. 만약 어떤 것이 인간의 수명을 연장하는지 보고 싶다면, 당신이 개발한 이 새로운 약이 실제로 인간의 수명을 연장하고 그 과정에서 끔찍한 부작용이 없는지 알아내는 데 오랜 시간이 걸릴 것입니다.

**swyx [02:10:00]**: 사이드 노트, 우리는 지금쯤 인간 화학과 생물학의 완벽한 모델을 가지고 있지 않나요?

**Noam [02:10:03]**: 음, 그래서 이것이, 제 생각에, 문제입니다. 그리고 다시, 저는 여기서 조심하고 싶습니다. 왜냐하면 저는 실제로, 아시다시피, 생물학자나 화학자가 아니기 때문입니다. 저는 이 분야들에 대해 거의 모릅니다. 제가 마지막으로 생물학 수업을 들은 것은 고등학교 10학년 때였습니다. 저는 지금 인간 생물학의 완벽한 시뮬레이터가 있다고 생각하지 않습니다. 그리고 저는 그것이 이 문제를 해결하는 데 잠재적으로 도움이 될 수 있는 것이라고 생각합니다.

**swyx [02:10:21]**: 그것이 바로 우리가 모두 노력해야 할 가장 중요한 일 중 하나입니다.

**Noam [02:10:24]**: 음, 그것은 우리가 이 최신 모델들이 도움이 되기를 바라는 것 중 하나입니다. 네.

**swyx [02:10:28]**: 오늘날 중간 훈련(mid-training)과 사후 훈련(post-training)을 어떻게 분류하시겠습니까?

**Noam [02:10:32]**: 모든 정의가 너무 모호합니다. 그래서 명확한 답변을 드리기는 어렵습니다. 네.

**swyx [02:10:38]**: 사람들이 당신의 OpenAI에 대해 궁금해하는 질문 중 하나는, 지금 중간 훈련(mid-training)을 위해 명시적으로 채용하고 있는데, 모두가 중간 훈련이 대체 무엇인지 궁금해합니다. 제 생각에 중간 훈련은 사전 훈련(pre-training)과 사후 훈련(post-training) 사이에 있는 것 같습니다.

**Noam [02:10:50]**: 그것은, 사전 훈련도 아니고 사후 훈련도 아닙니다. 사전 훈련 후에 모델에 무언가를 더 추가하는 것과 같습니다. 흥미로운 방식이죠. 네. 알겠습니다.

**swyx [02:11:01]**: 알겠습니다. 음, 저는 명확성을 얻으려고 노력하고 있었습니다.

**Alessio [02:11:06]**: 그렇다면 사전 훈련된 모델은 이제 기본적으로 다른 모델들을 생성하는 아티팩트(artifact)와 같은 것인가요? 그리고 핵심 사전 훈련 모델은 더 이상 노출되지 않는 것과 같고, 중간 훈련이 새로운 사전 훈련이며, 모델들이 분기된 후에 사후 훈련이 있는 것인가요?

**Noam [02:11:22]**: 실제 원시 사전 훈련 모델과 직접 상호 작용하는 일은 없습니다. 모델과 상호 작용하려면 중간 훈련과 사후 훈련을 거쳐야 합니다. 그래서, 음, 당신은 최종 제품을 보고 있는 것입니다.

**swyx [02:11:31]**: 음, 당신은 우리가 그렇게 하도록 허락하지 않지만, 아시다시피, 우리는 예전에는 그랬습니다.

**Noam [02:11:33]**: 음, 네. 제 말은, 아시다시피, 원시 사전 훈련 모델과 직접 상호 작용할 수 있는 오픈 소스 모델들이 있습니다. 음, 하지만 OpenAI 모델의 경우, 중간 훈련 단계를 거치고 사후 훈련 단계를 거친 다음 출시되며 훨씬 더 유용합니다. 솔직히 말해서, 만약 당신이 사전 훈련 모델과만 상호 작용한다면, 그것은 작업하기 매우 어려울 것이고 다소 멍청해 보일 것입니다.

**Alessio [02:11:51]**: 네.

**swyx [02:11:51]**: 하지만 이상한 방식으로 유용할 것입니다. 아시다시피, 채팅처럼 사후 훈련을 할 때 모드 붕괴(mode collapse)가 발생하기 때문이죠. 네.

**Noam [02:11:59]**: 그리고 어떤 면에서는 그 모드 붕괴를 원합니다. 아시다시피, 분포의 붕괴를 원합니다. 유용하기 위해서요. 네. 이해합니다. 네. 네.

**swyx [02:12:08]**: 그리고 만약 그와 많이 이야기해야 한다면, 무엇을 물어보시겠습니까?

**Noam [02:12:11]**: 그렉에게 무엇을 물어볼까요? 제 말은, 저는 항상 그렉에게 물어볼 수 있지만, 당신은 그렉에게 무엇을 물어봐야 할까요?

**swyx [02:12:15]**: 흥미로운 답변을 이끌어낼 수 있는 질문이요. 그가 충분히 듣지 못하는 질문이지만, 아시다시피, 그가 열정을 가지고 있는 것이거나 당신이 그의 생각을 듣고 싶은 것이요.

**Noam [02:12:25]**: 제 생각에 일반적으로, 이것이 어디로 향하는지 묻는 것이 가치 있습니다. 아시다시피, 5년 후의 세상은 실제로 어떻게 보일까요? 10년 후의 세상은 어떻게 보일까요? 결과의 분포는 어떻게 보일까요? 그리고 무엇을 할 수 있을까요? 네. 세상이나 개인들이 부정적인 결과 대신 좋은 결과로 나아가도록 돕기 위해 무엇을 할 수 있을까요?

**swyx [02:12:45]**: 알겠습니다, 얼라인먼트(alignment) 질문처럼요.

**Noam [02:12:48]**: 사람들은 1년이나 2년 안에 무슨 일이 일어날지에 매우 집중하는 경향이 있습니다. 그리고 5년이나 10년 안에 무슨 일이 일어날지, 그리고 그 세상이 어떻게 보일지에 대해 생각하는 데 시간을 할애하는 것도 가치 있다고 생각합니다.

**swyx [02:12:59]**: 제 말은, 그에게 수정 구슬이 있는 것은 아니지만요.

**Noam [02:13:01]**: 하지만 그는 분명히 생각이 있습니다. 네, 그래서 저는 그것이 탐구할 가치가 있다고 생각합니다.

**Alessio [02:13:08]**: 사람들에게 추천하는 게임은 무엇인가요, 특히 사회적인 게임이요?

**Noam [02:13:12]**: 사람들에게 추천하는 게임이요? 저는 요즘 '블러드 온 더 클락타워(Blood on the Clocktower)'라는 게임을 많이 하고 있습니다.

**swyx [02:13:18]**: 그게 뭔가요?

**Noam [02:13:19]**: 마피아나 늑대인간 같은 게임입니다. 샌프란시스코에서 매우 인기를 얻고 있습니다. 아, 그게 당신 집에서 했던 게임인가요? 네. 알겠습니다. 좀 웃긴데요. 제가 몇몇 사람들과 이야기했는데, 그들은 예전에는 포커가 벤처 캐피탈리스트(VC)와 기술 창업가들이 서로 교류하는 방식이었다고 말했습니다. 그리고 실제로 이제는 '블러드 온 더 클락타워' 쪽으로 바뀌고 있습니다. 베이 에어리어(Bay Area)에서 사람들이 교류하는 방식이 된 거죠. 그리고 실제로 한 스타트업이 '블러드 온 더 클락타워' 게임을 채용 행사로 열었다고 들었습니다. 와우.

**swyx [02:13:55]**: 네.

**Noam [02:13:55]**: 그래서 제 생각에 그것은 정말 인기를 얻고 있지만, 재미있는 게임입니다. 그리고 포커를 하는 것보다 돈을 덜 잃을 수 있습니다. 그래서 이런 것에 능숙하지 않은 사람들에게는 더 좋습니다. 좀 이상한 채용 행사 같지만, 분명히 재미있는 게임입니다.

**swyx [02:14:08]**: 여기서 승자를 만드는 어떤 자질이 채용에 흥미로운가요?

**Noam [02:14:13]**: 그게 문제입니다. 음, 거짓말을 잘하는 능력을 얻는다고 생각합니다. 속임수와 속임수를 간파하는 능력요. 그게 최고의 직원일까요? 음, 모르겠습니다.

**Alessio [02:14:23]**: 그래서 저의 마지막 사소한 관심사는 '매직 더 개더링(Magic the Gathering)'입니다. 체스나 바둑 같은 완전 정보 게임에 대해 이야기했습니다. 그리고 포커는 제한된 우주에서 불완전 정보를 가진 게임입니다. 52장의 카드 게임만 있죠. 그리고 불완전 정보를 가진 다른 게임들도 있습니다. 예를 들어 가능한 옵션이 엄청나게 많은 게임들이요. 그것이 얼마나 더 어려운지 아시나요? 이 문제의 난이도가 어떻게 확장될까요?

**Noam [02:14:48]**: 그 질문을 해주셔서 정말 좋습니다. 왜냐하면 저는 불완전 정보 게임(imperfect information games)을 위한 AI에 대한 방대한 지식을 가지고 있기 때문입니다. 이것이 오랫동안 저의 연구 분야였기 때문입니다. 그리고 저는 이 모든 것을 알고 있지만, 자주 이야기할 기회는 많지 않습니다. 우리는 노리밋 텍사스 홀덤(No Limit Texas Hold'em)을 위한 초인적인 포커 AI를 만들었습니다. 그것에 대한 흥미로운 점 중 하나는 숨겨진 정보의 양이 실제로는 꽤 제한적이라는 것입니다. 텍사스 홀덤을 할 때 두 장의 숨겨진 카드를 가지고 있기 때문입니다. 그래서 당신이 있을 수 있는 가능한 상태의 수는 적어도 헤즈업(heads up)으로 플레이할 때 1,326개입니다. 그리고 아시다시피, 그것은 테이블에 있는 다른 플레이어의 수만큼 곱해지지만, 여전히 엄청난 수는 아닙니다. 그래서 이 AI 모델들이 작동하는 방식은 당신이 있을 수 있는 모든 다른 상태들을 열거하는 것입니다. 그래서 만약 당신이 6인 포커를 하고 있다면, 다른 플레이어가 5명이고, 5 곱하기 1,326입니다. 그것이 당신이 있었던 상태의 수입니다. 그리고 나서 각 상태에 확률을 할당하고, 그 확률들을 신경망(neural net)에 입력하면 각 상태에 대한 행동을 얻습니다. 문제는 숨겨진 가능성의 수, 즉 당신이 있을 수 있는 가능한 상태의 수가 확장됨에 따라 그 접근 방식이 무너진다는 것입니다. 그리고 숨겨진 상태의 수가 극도로 커질 때 무엇을 해야 하는지에 대한 매우 흥미로운 미해결 질문이 여전히 남아 있습니다. 아시다시피, 만약 당신이 네 장의 숨겨진 카드를 가진 오마하 포커(Omaha poker)로 간다면, 할 수 있는 것들이 있습니다. 그것은 상태의 수를 줄이기 위해 할 수 있는 일종의 휴리스틱(heuristic)입니다만, 실제로는 여전히 매우 어려운 문제입니다. 그리고 만약 당신이 40개의 말을 가진 스트라테고(Stratego) 같은 게임으로 간다면, 거의 40 팩토리얼(40!)에 가까운 다른 상태에 있을 수 있습니다. 그러면 우리가 포커에 사용했던 모든 기존 접근 방식이 무너지고 다른 접근 방식이 필요합니다. 그리고 그것을 어떻게 처리해야 하는지에 대한 많은 활발한 연구가 진행 중입니다. 그래서 매직 더 개더링 같은 것에 대해서는, 우리가 포커에 사용했던 탐색(search) 기술들이 바로 작동하지 않을 것입니다. 그리고 그것은 여전히 흥미로운 연구 질문입니다. 아시다시피, 이제 무엇을 해야 할까요? 제가 말해야 할 것은, 당신이 포커에서 사용했던 종류의 탐색 기술을 사용할 때 이것이 문제가 된다는 것입니다. 만약 당신이 모델 프리 RL(model free RL)을 하고 있다면, 그것은 문제가 되지 않습니다. 그리고 제 생각에 누군가 노력을 기울인다면, 지금 매직 더 개더링을 위한 초인적인 봇을 만들 수 있을 것입니다. 네. 그 분야에는 여전히 몇 가지 미해결 연구 질문이 있습니다. 이제, 그것들이 가장 중요한 미해결 연구 질문일까요? 저는 아니라고 생각합니다. 제 생각에 문제는 우리가 포커에서 사용했던 종류의 탐색 기술들이 꽤 제한적이었다는 것입니다. 그리고 만약 당신이 그 기술들을 확장한다면, 아마도 스트라테고나 매직 더 개더링 같은 것들에도 작동하게 할 수 있겠지만, 그것들은 여전히 제한적일 것입니다. 그것들은 언어 모델로 초인적인 코드포스(encode forces)를 얻게 해주지는 않을 것입니다. 그래서 저는 매우 일반적인 추론 기술에 집중하는 것이 더 가치 있다고 생각합니다. 그리고 언젠가 우리가 그것들을 개선함에 따라, 어느 날 갑자기 초인적인 수준으로 매직 더 개더링을 플레이하는 모델을 갖게 될 것이라고 생각합니다. 그리고 저는 그것이 더 중요하고 더 인상적인 연구 방향이라고 생각합니다. 멋지네요. 놀랍습니다.

**Alessio [02:17:31]**: 네. 노암, 와주셔서 감사합니다. 네.

**Noam [02:17:34]**: 시간 내주셔서 감사합니다. 네. 감사합니다. 초대해주셔서 감사합니다.

**편집자 주**: 이 팟캐스트의 이전 버전에는 유감스러운 헤드라인 이미지가 포함되어 있었습니다. 죄송하며 해당 이미지를 삭제했지만, 저희의 실수를 숨기지는 않습니다. 1 그리고 라마(Llama)의 기여를 통해 추론 최적 스케일링(inference-optimal scaling)에 대한 이해가 있었습니다. 2 이전에 '테스트 시간 컴퓨팅이 한계에 부딪힐 것이다'라고 썼지만, 노암의 주장에 따라 수정되었습니다.