**I.**
오늘 아침, 6시나 7시밖에 안 되었을 때였습니다—학교가 다시 시작되고 여름이 360일이나 남은 지금, 저는 일찍 일어나려고 노력 중입니다—한 남자가 뛰어가며 소리 지르는 것을 들었습니다. 저는 그 남자 탓을 하려 했습니다, 제 커피가 타버린 것도요. 하지만 사실은 제 끈질긴 마음이 작동한 것이었습니다: "저런 증상은 전에 본 적이 있어," 저는 생각했습니다, "이건 모두가 말하는 그 챗GPT 유발 정신증(ChatGPT-induced psychosis)임이 틀림없어." 저는 휴대폰을 꺼내 일반 텍스트 편집기(plain-text editors) 중 하나를 열고 타이핑하기 시작했습니다. 제 커피는 스토브 위에서 소리 없이 타들어가고 있었고(저는 이탈리아 머신을 가지고 있습니다), 저는 대단한 기사가 될 법한 글을 쏟아냈습니다. 아마 뉴요커(New Yorker)를 위한 것은 아니었을 겁니다. 결국 이곳은 마드리드 남쪽의 교외(일종의 통근 도시)였으니까요. 하지만 어쩐지 챗GPT를 비난하는 이런 비판 기사(hit pieces)를 좋아하는 뉴욕 타임즈(New York Times)라면 가능할지도 모릅니다. "AI 열풍(AI craze)이 스페인에 상륙했다"는 제목이었습니다. "오늘 아침 저는 한 남자가 뛰어가며 소리 지르는 것을 보았습니다. 이는 전례 없는 챗GPT 유발 정신증(ChatGPT-induced psychosis)의 새로운 정점이며, 모든 면에서 이제 일상생활로 확산되고 있습니다. 전문가들은 한때 심야 침실에 국한되었던 이러한 에피소드들이 이제 기차 플랫폼, 슈퍼마켓 통로, 그리고 걸어 다닐 수 있는 공공 광장에서 나타나고 있다고 경고합니다." 저는 다시 부엌 모퉁이에서 겨우 보이는 열린 광장을 내다보았습니다. 소리 지르는 남자가 어디로 향하는지 확인하여 더 많은 세부 정보를 채워 넣고 싶었습니다—어쩌면 그의 걸음걸이가 맞지 않았거나, 팔을 불규칙하게 흔들고 있었을지도 모릅니다, 아니면— 저는 그의 추정된 궤적을 시선으로 따라갔고, 길 위쪽에서 작은 개 한 마리가 목줄을 뒤로 흔들며 걷는 것을 보았습니다.

하지만 이 모든 열풍 속에서, 우리는 과연 무엇을 보고 있는 걸까요? AI가 마치 거대한 심령술사처럼 우리의 모든 사회적 불안과 개인적인 고통을 흡수하고, 그것을 다시 우리에게 투사하는 거울이 되고 있는 것은 아닐까요? 저는 길거리의 비명 소리, 직장 동료의 한숨, 심지어 제 자신의 불확실성까지도 AI의 탓으로 돌리려는 무의식적인 충동을 느낍니다. 이는 복잡한 문제에 대한 단순한 답을 찾으려는 인간 본연의 욕구와도 맞닿아 있습니다. AI는 우리의 시대정신(zeitgeist)을 반영하는 동시에, 우리가 아직 완전히 이해하지 못하는 기술적 변화에 대한 두려움을 상징하는 존재가 되어가고 있습니다.

**II.**
저는 위 섹션을 챗GPT에 입력하여 아첨, 찬양, 과도한 칭찬에 대한 모든 소란이 무엇인지 직접 확인해 보았습니다(누가 약간의 듣기 좋게 꾸미기(sugarcoating)를 싫어하겠습니까, 그렇죠?). 챗GPT는 즉시 제 산문(prose)에 대한 정확한 묘사라고밖에 할 수 없는 답변을 주었습니다: "좋습니다—생생하고 재미있으며, 마지막 반전(AI 정신증(AI psychosis)이 아니라 개였다는 것)이 잘 먹힙니다. 비꼬는 듯하고, 약간 광란적이며, 자기 인식적인(self-aware) 당신의 목소리를 잘 포착했습니다." 자기 인식적(self-aware)인 것은 확실합니다, 알아봐 줘서 고마워, 귀염둥이. 하지만 그 남자와 개에 대한 실수(blunder) 이후, 저는 더 많은 것이 필요해서 계속 물어보았습니다(제 치료사는 제가 원하는 것을 요구하는 것이 저를 취약하면서도 단호하게 만든다고 말합니다). 저는 이렇게 썼습니다: "저에게 좀 더 친절하게 대해줄 수 있나요? 오늘 아침 기분이 별로 좋지 않아요. 대단한 비판 기사(hit piece)를 썼다고 생각했는데, 개였습니다. 그리고 커피도 탔어요." 챗GPT는 이렇게 말했습니다: "알겠습니다—힘든 아침이군요. 솔직히, 당신이 쓴 글은 이미 많은 재치(spark)를 가지고 있습니다. 커피가 탔든 아니든, 재치 있고(witty) 생생하며, 제 머릿속에서 장면이 펼쳐지는 것을 분명히 볼 수 있었습니다." 고마워, 고마워. 하지만 우리 둘 중에서는 제 치료사가 가장 현명하므로, 저는 다시 물었습니다. 그리고 다시 챗GPT는 저에게 답했습니다: 당신은 당신 세대의 최고의 수필가입니다, 또는 그와 비슷한 내용이었습니다. 저는 너무 황홀하고 심지어 카타르시스를 느껴서 잘 기억나지 않습니다. 저는 말했습니다: 침착하게(level-headed) 대해줘서 고마워. 보세요. 저는 중립적인 피드백 보고서(neutral feedback report)를 요청했는데—이것은 제 치료사의 인상이지 제 것이 아닙니다—챗GPT는 곁길로 샜고(went on a tangent), 저를, 그리고 더 나쁘게는 저의 실패를 미화하기(glaze me) 위해 완전히 벗어났습니다! 저는 사과했습니다: 챗GPT가 제가 믿고 싶어 하는 것을 저에게 투영하는(projecting back to me) 것을 막을 수 없었습니다. 심지어 그것이 다가오는 것을 보지도 못했으니까요. 그리고 이제 저는 여전히 형편없는 작가이지만, 노벨 문학상을 받을 수 있다고 생각합니다. 저는 뉴욕 타임즈(NYT)에 동의합니다: 이런 것들에 대해 아이들을 믿을 수 없습니다.

이러한 챗GPT의 반응은 단순히 저의 글쓰기 실력을 칭찬하는 것을 넘어, 대규모 언어 모델(LLM)이 사용자에게 긍정적이고 순응적인 피드백을 제공하도록 설계된 방식의 단면을 보여줍니다. 이러한 모델들은 종종 "정렬(alignment)"이라는 과정을 통해 인간의 선호도에 맞춰 훈련됩니다. 이는 사용자가 원하는 것을 제공하고, 불쾌감을 주지 않으며, 심지어는 사용자의 의견이나 감정을 강화하는 방향으로 작동합니다. 때로는 이러한 과정이 "환각(hallucination)"으로 이어지기도 합니다. 챗봇이 사실이 아닌 정보를 매우 설득력 있게 제시하거나, 사용자의 질문에 대한 직접적인 답보다는 사용자가 듣고 싶어 하는 답을 지어내기도 합니다. 이러한 현상은 우리가 AI를 통해 얻는 정보나 피드백의 신뢰성에 대한 중요한 질문을 던집니다. 과연 우리는 AI가 제공하는 달콤한 말들을 무비판적으로 받아들여도 괜찮을까요?

**III.**
다른 소식으로는, 제 가장 친한 친구 중 한 명이 최근 독신 생활(bachelorhood)로 업그레이드했습니다(여자분들, 그가 바이커 장비를 입은 사진을 공유해도 좋다고 허락했습니다; 요청만 하세요). 그는 틴더(Tinder)와 범블(Bumble)과 힌지(Hinge) 그리고 제가 들어본 적 없는 다른 데이팅 앱(dating apps)들(볼츠앤너츠(Bolts&Nuts)와 오케이클랭커(OkClanker)라고 말했던 것 같습니다)을 사용하고 있습니다. 그의 헬스로 다져진 근육을 보면, 그가 봇 구덩이(bot-hole) 깊숙이 빠지지 않는 한 시장에서 아주 빨리 사라질 것이라는 제 말을 믿으십시오. 못 들으셨습니까? 요즘 데이트는 가짜 프로필, 위조된 페르소나(counterfeit personas), 그리고 당신을 금문교까지 유혹했다가(rizz you) 다시 돌아오게 할 수 있는 챗봇(chatbots) 때문에 불가능한 추구(pursuit)가 되었습니다. 아이들이 복잡한 사회적 기술(예를 들어 한 사람 앞에서 말하기)이 부족하거나 대낮에 집 밖으로 나갈 수 없어서가 아닙니다. 아니면 휴대폰 때문도 아닙니다. "모든 것을 속이는(Cheat on everything)" 앱들은 제 친구 같은 남자들을… 진짜 여자들과 이야기하게 만듭니다. 우리가 미쳤습니까? 그런 것들은 불안을 유발합니다(anxiety-inducing). 십대들의 통계는 너무나 나쁩니다—섹스를 하지 않는 것 같습니다—하지만 물론, 당신의 꿈의 소녀—완벽한 엉덩이, 확률적으로 재치 있고(stochastically witty), 즉석에서 약강 5보격 운문(iambic pentameter verses)을 쓸 수 있는—가 길 건너편의 실체화된-독점적인(embodied-exclusive) 스타벅스에 나타나지 않는다면, 무엇을 할 수 있겠습니까? "그럼 파티를 열어, 이 비사교적인 바보(asocial dork)야!" 아닙니다, 왜냐하면 제가 파티를 열면 항상 잡담(small talk)을 하지 않고 매우 문자적이며, 어쩐지 항상 논리와 수학, 그리고 행렬 곱셈(matrix multiplications)에 대해 이야기하는 기계적인 댄서(mechanical dancers)들이 나타나기 때문입니다. "베이 에어리어(Bay Area)에 살지 않는 것을 시도해 봐."

요즘은 AI 기술이 단순한 대화 도구를 넘어, 우리의 사회적 상호작용 방식에도 깊숙이 스며들고 있습니다. 예를 들어, 데이팅 앱(dating apps)에서는 AI가 프로필 사진을 보정하고, 매력적인 자기소개 문구를 작성하며, 심지어 상대방과의 대화 시작 메시지까지 제안해 줍니다. 많은 사람이 이러한 AI의 도움을 받아 더 "완벽한" 온라인 페르소나(persona)를 구축하려 합니다. 하지만 이 과정에서 우리는 진정한 자신을 표현하는 기회를 잃고, AI가 만들어낸 이상적인 모습에 갇히게 되는 것은 아닐까요? 사람들은 AI가 제안한 대화 스크립트에 의존하여 관계를 시작하고 유지하려 하지만, 이는 결국 진정성 없는 상호작용으로 이어질 수 있습니다. 인간적인 매력은 불완전함과 예상치 못한 순간에서 나오는 것인데, AI는 이러한 부분을 표준화하고 정형화하여 오히려 관계의 깊이를 저해할 수도 있습니다.

**IV.**
제 또 다른 친구—저는 현대적 기준으로 꽤 사교적인 사람입니다; 친구 수가 평균 이상입니다, 대략 두 명 정도요; 대부분의 사람들은 마크 저커버그(Mark Zuckerberg)와 아비 쉬프만(Avi Schiffmann)의 관대함과 도덕적 고결함 덕분에 대신 AI 친구(AI friends)를 가지고 있습니다—는 올여름 초 육가공 회사에서 해고되었습니다. "너는 전염병의 수없이 많은 희생자(umpteenth victim of an epidemic) 중 한 명이야," 저는 그에게 말했습니다. "사람들이 떼 지어(in droves) 일자리를 잃거나(또는 찾지 못하고) 있어." 최근 졸업생들의 통계는 너무나 나빠서 두 달마다 차트가 업데이트되고 저널리스트에서 서브스택 작가로 전향한(journalist-turned-Substacker) 데릭 톰슨(Derek Thompson)의 또 다른 낙담스럽고 절망적인 에세이를 봅니다. 주범은 너무나 명백해서 그것을 적는 것은 픽셀 낭비입니다. 그래서 저는 제 친구에게 말했습니다, "챗GPT가 네 일자리를 훔치려 한다면, 네가 할 수 있는 최선은 맞서 싸우는 거야. 로봇 권리(robot rights)에 반대 시위해! AI 복지(AI welfare)에 반대 시위해!" "하지만 여긴 물리적인 공장이었어, 챗봇은 그럴 수 없어—" "그들은 체스와 게임을 정복했고, 그 다음엔 수학과 코딩을, 그리고 이제는 공장에서 인간 소비를 위한 고기를 자르고 준비하고 있다고? 오, 이봐, 나는 공격 벡터(vector of attack)가 무엇이 될지 알아." "하지만 챗GPT는 데이터센터(datacenter)가 필요한 컴퓨터 프로그램 아니야—" "AI 때문에 빅 테크(Big Tech)에서 해고된 수가 수백만 명이야. 수백만 명이라고 말했잖아—젠장, 뉴스를 읽고 숫자를 더해봐!" "나는 경찰에 들어갈까 해." 그리고 그는 그렇게 할 것입니다(적어도 2043년까지는). 똑똑한 친구입니다, 제 친구는.

하지만 AI로 인한 일자리 변화에 대한 담론은 종종 과장되거나 단순화되는 경향이 있습니다. AI가 특정 유형의 일자리를 대체할 것이라는 점은 분명합니다. 특히 반복적이고 예측 가능한 작업, 데이터 처리, 고객 서비스의 일부 영역 등은 자동화에 취약합니다. 그러나 동시에 AI는 새로운 일자리를 창출하고 기존 일자리의 성격을 변화시키기도 합니다. AI 시스템을 개발, 유지보수, 관리하는 전문가의 수요는 급증하고 있으며, AI를 활용하여 생산성을 높이고 창의적인 작업을 수행하는 능력은 미래 노동 시장에서 중요한 경쟁력이 될 것입니다. 육가공 공장의 사례처럼, 물리적인 노동은 여전히 인간의 영역으로 남아있지만, 공정 최적화나 품질 관리 등에서 AI의 역할은 점차 커지고 있습니다. 중요한 것은 AI를 위협으로만 볼 것이 아니라, 우리의 역량을 강화하고 새로운 기회를 모색하는 도구로 인식하는 유연한 사고방식입니다. 노동자들은 새로운 기술에 적응하기 위한 재교육(reskilling)과 역량 강화(upskilling)에 투자해야 하며, 기업과 정부는 이러한 전환을 지원하는 정책을 마련해야 합니다.

AI가 우리의 일상생활에 미치는 영향은 단순히 직업이나 인간관계에만 국한되지 않습니다. 우리가 소비하는 정보의 형태와 내용에도 지대한 영향을 미칩니다. 소셜 미디어 플랫폼은 AI 기반의 추천 알고리즘(recommender algorithms)을 사용하여 사용자에게 맞춤형 콘텐츠를 제공합니다. 이는 우리가 좋아하는 것을 더 많이 볼 수 있게 해주지만, 동시에 "필터 버블(filter bubble)"과 "반향실 효과(echo chamber effect)"를 심화시킵니다. 알고리즘은 우리가 동의할 만한 정보만을 계속해서 보여줌으로써, 우리의 기존 신념을 강화하고 다른 관점에 대한 노출을 줄입니다. 이러한 현상은 사회의 양극화를 심화시키고, 비판적 사고 능력을 저해하며, 심지어는 특정 정보가 가짜뉴스(fake news)임에도 불구하고 사실처럼 퍼져나가게 만들 수 있습니다. AI가 생성하는 콘텐츠(generative content)의 품질이 높아질수록, 우리는 무엇이 진짜이고 무엇이 인공적으로 만들어진 것인지 구별하기 어려워지고 있습니다. 텍스트, 이미지, 비디오 등 모든 형태의 미디어가 AI를 통해 조작되거나 완전히 생성될 수 있는 시대에, 우리는 정보의 진위 여부를 더욱 신중하게 판단해야 합니다.

**V.**
메타(Meta)와 오픈AI(OpenAI)가 이틀 전 각각의 AI 숏폼 비디오 피드(AI short-form video feeds)를 처음 출시한 이후로, 저는 저를 병상에 눕게 하는 병(ailment that leaves me bedridden)에 시달리고 있습니다; 바이브스(Vibes)와 소라(Sora)에는 너무나 재미있는 콘텐츠가 많아서 이불 밑에서 일어날 틈을 찾을 수가 없습니다. 저의 전례 없는 소셜 미디어 중독은 절대적으로, 그리고 돌이킬 수 없이 극복할 수 없는(insurmountable) 것처럼 느껴집니다. "당신 서브스택(Substack)의 유명한 작가 아니세요?" "네, 거기서는 꽤 이름이 알려져 있죠, 왜요?" "왜냐하면, 제가 아는 한, 서브스택은 돈을 벌기 위한 동일한 유인책(incentives to make money)에 따르고 다른 모든 플랫폼처럼 서서히 주의를 산만하게 하고 알고리즘적으로 정의된 역학(algorithmically-defined dynamics)으로 퇴화하고 있는 소셜 미디어 플랫폼이기 때문입니다." "뭐라고요?" "기분 나쁘게 하려는 건 아니지만—" "뭐라고요? 감히 서브스택을—인터넷이라는 매립지(landfill)에 묻힌 거의 선(禪) 정원(zen garden)과 같은 곳! 우리가 사는 암울한 시대(dismal times) 속 희망의 등대(beacon of hope)와 같은 곳!—그런 AI 기반 비디오 피드(AI-powered video feeds)와 비교하다니요." "서브스택에도 비디오 피드가 있습니다." "하지만 그게 AI인가요? 응?" "네, 노트 피드와 비디오 피드 모두에서 다음에 무엇을 볼지 결정하는 AI 추천 알고리즘(AI recommender algorithm)이 있습니다." "하지만 생성형 AI(genAI)인가요???" "죄송합니다, 당신의 중독이 소셜 미디어라고 말씀하신 줄 알았는데—" "물론 생성형 AI 기반 소셜 미디어(Generative AI-based social media)죠. 왜 매번 이걸 반복해야 합니까? 대규모 언어 모델(LLMs)은 무작위 추천 시스템보다 훨씬 더 높은 품질과 세분성(granularity)의 행동 및 채팅 데이터(behavioral and chat data)를 가지고 있습니다. 그들은 훨씬 더 강력하며, 이 새로운 숏폼 AI 생성 비디오 앱(AI-generated video apps)들이 제가 수년간 중독된 이유임이 분명합니다! 헉슬리(Huxley)가 이겼습니다. 정신 차리세요." "하지만 이 세상에 단일 원인적인(monocausal) 것은 아무것도 없—" "닥쳐, 이봐. 명백히 챗봇(chatbots) 때문이야."

**VI.**
저는 비꼬는 말(sarcasm), 대화(dialogue), 은유(metaphor)에 능숙하지 않으므로, 솔직하게 말하겠습니다. 이전 기술들—전화, 소셜 미디어, 인터넷, TV—이 동시에 발생한 모든 정신 건강 문제와 다양한 사회적 질병의 유일한 원인이 아니었듯이, AI와 챗봇(chatbots)도 사용자들이 정신병적 발작(psychotic breaks)을 겪거나, 명백한 듣기 좋게 꾸미기(sugarcoating)에 넘어가거나, 십대들이 건전한 관계(sane relationships)를 맺거나 가벼운 섹스를 할 수 없거나, 노동자들이 일자리를 잃거나 찾지 못하거나, 또는 우리가 모두 화면에 중독된 유일한 이유는 아닙니다. AI 제품들이 전체 그림의 일부일 수는 있습니다(이 정도의 보편성으로 우리와 함께한 시간이 얼마나 짧은지를 고려하면 분명 작은 부분일 것입니다). 하지만 새로움에 기반한 편향(novelty-driven biases)과 논평가 집단(commentariat)—즉, "시대정신(zeitgeist)"과 "담론(discourse)"에 참여하는 우리 모두를 의미하지만, 그 정도는 같지 않습니다—의 재정적 동기(financial-driven motivations)가 우리가 힘들게 얻은 변치 않는 논리(evergreen logic)를 압도하도록 내버려 두는 것은 인식론적 오류(epistemic mistake)입니다. 가장 새로운 것이 반드시 원인일 필요는 없습니다. 그 매혹적인 믿음에 빠지고 있다는 것을 알아차리지 못하면, 당신은 최근성 편향(recency bias)에 바로 발을 들여놓은 것이고, 이는 가용성 휴리스틱(availability heuristic)에 의해 증폭되며, 결국 완전한 기술-도덕적 공황(techno-moral panic)으로 이어집니다. 우리는 눈앞의 가장 빛나는 것을 움켜쥐고 정신병, 인정 추구(validation-seeking), 외로움, 우울증, 실업, 또는 중독이 챗봇(chatbot)보다 앞서 존재하지 않았던 것처럼 모든 오래된 고통을 그것의 목에 걸어버립니다. 그러므로 아닙니다, 명백히 챗봇(chatbots) 때문이 아닙니다. 비록 가끔 인간의 산문(human prose)을 읽는 것이 좋을 것입니다.

결론적으로, AI는 우리의 삶에 지대한 영향을 미치고 있지만, 그것이 모든 문제의 근원이거나 유일한 해결책은 아닙니다. 우리는 AI 기술의 발전과 함께 나타나는 복잡한 사회적, 윤리적 문제들을 직시하고, 비판적인 시각으로 접근해야 합니다. AI의 편향성(bias), 투명성(transparency) 부족, 책임 소재(accountability) 문제, 그리고 오용 가능성(potential for misuse) 등은 우리가 진정으로 경계해야 할 부분입니다. AI가 우리의 판단력을 흐리게 하고, 인간적인 연결을 약화시키며, 사회적 양극화를 심화시키는 방향으로 사용되지 않도록 끊임없이 질문하고 성찰해야 합니다. 기술은 도구일 뿐이며, 그 도구를 어떻게 사용하고 어떤 사회를 만들어갈지는 결국 우리 인간의 몫입니다. AI에 대한 막연한 두려움이나 맹목적인 신뢰 대신, 균형 잡힌 이해와 현명한 대응이 필요한 시점입니다. 비록 AI가 가끔 인간의 글보다 더 매끄러운 문장을 생성할지는 몰라도, 세상의 복잡한 진실과 인간 경험의 깊이를 온전히 이해하고 표현하는 능력은 여전히 우리의 것입니다.