SWE-Bench 개발자들이 Neurips 2024에서 LLM 기반 에이전트의 현재 발전 상태를 논하다
Jay Alammar 2025년 1월 14일 5 1 공유

SWE-Bench 프로젝트는 깃허브(GitHub)의 실제 문제 해결 역량을 기준으로 인공지능(AI) 에이전트들의 소프트웨어 개발 능력을 평가하는 데 사용됩니다. 2024년 한 해 동안, 이 프로젝트는 소프트웨어 엔지니어링 과제를 수행하는 에이전트들의 발전도를 가늠하는 핵심적인 척도로 자리매김했습니다. 본 글에서는 SWE-Bench를 처음 고안한 Ofir Press와 Carlos E. Jimenez 두 분을 만나, 대규모 언어 모델(LLM)을 활용한 에이전트들의 현재 위치와 미래 전망에 대한 그들의 견해를 들어보았습니다.

SWE-Bench: LLM 에이전트의 실제 역량을 조명하다

SWE-Bench는 단순한 성능 측정 도구를 넘어, LLM 기반 에이전트가 실제 소프트웨어 개발 환경에서 직면하는 본질적인 도전 과제들을 명확히 드러냈습니다. 개발자들이 직면하는 복잡한 버그 수정, 새로운 기능 구현, 문서화 작업 등은 에이전트의 심층적인 이해력, 계획 수립 능력, 그리고 외부 도구 활용 능력을 요구합니다. 이 벤치마크는 LLM이 단순한 코드 생성기를 넘어 진정한 소프트웨어 엔지니어링 조력자가 되기 위해 어떤 능력을 갖춰야 하는지 구체적인 방향을 제시합니다.

현재의 도전과 주목할 만한 발전

Press와 Jimenez는 현재 LLM 에이전트가 긴 코드 베이스를 이해하고, 미묘한 버그를 진단하며, 복잡한 시스템에 새로운 코드를 통합하는 데 여전히 어려움을 겪고 있다고 지적합니다. 특히, 모호한 요구사항을 해석하고, 예상치 못한 오류에 대응하는 능력은 개선이 필요합니다. 하지만 최근 들어, 다단계 추론(multi-step reasoning), 자체 수정 메커니즘(self-correction mechanisms), 그리고 외부 API 연동(external API integration)과 같은 기술들이 발전하면서 에이전트의 문제 해결 능력이 눈에 띄게 향상되고 있습니다. 예를 들어, 특정 에이전트는 코드 스니펫(code snippet)을 제안하는 것을 넘어, 테스트 환경을 설정하고, 코드를 실행하여 오류를 디버깅하는 전체 과정을 수행할 수 있게 되었습니다. 이는 실제 개발 워크플로우에 에이전트가 더 깊이 관여할 수 있는 가능성을 보여줍니다.

미래 전망: 인간과 에이전트의 협력 시대

두 창시자는 미래의 소프트웨어 개발이 인간과 LLM 에이전트의 협력을 통해 이루어질 것이라고 전망합니다. 에이전트는 반복적이고 정형화된 작업을 자동화하고, 초기 단계의 코드 초안을 작성하거나, 광범위한 코드베이스에서 정보를 찾아주는 역할을 수행할 것입니다. 이를 통해 개발자는 더 창의적이고 전략적인 문제 해결에 집중할 수 있게 됩니다. 이는 개발 생산성을 혁신적으로 끌어올릴 잠재력을 가지고 있으며, 소프트웨어 개발 패러다임 자체를 변화시킬 수 있습니다. 궁극적으로, SWE-Bench와 같은 벤치마크는 이러한 에이전트가 실제 개발 환경에 안전하고 효과적으로 통합될 수 있도록 그 경로를 제시하는 중요한 역할을 계속 수행할 것입니다.