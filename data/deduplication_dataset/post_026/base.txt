# **쓴 교훈 대 쓰레기통**

Author: Ethan Mollick
URL: https://www.oneusefulthing.org/p/the-bitter-lesson-versus-the-garbage

============================================================

**조직에 관한 제가 가장 좋아하는 학술 논문 중 하나는 루탄 후이싱(Ruthanne Huising)의 논문입니다. 이 논문은 원자재부터 완제품에 이르기까지 조직이 실제로 수행하는 작업을 추적하여 회사의 프로세스 맵(process map)을 만들도록 배정된 팀들의 이야기를 다룹니다. 이 맵을 만들면서 그들은 작업의 상당 부분이 얼마나 이상하고 계획되지 않은 것처럼 보이는지 깨달았습니다. 그들은 아무도 사용하지 않는 결과물을 생산하는 전체 프로세스, 일을 처리하는 이상한 반공식적 경로, 그리고 반복적인 노력의 중복을 발견했습니다. 맵 작업을 하던 직원들 중 상당수는 한때 회사의 떠오르는 별이었지만 환멸을 느끼게 되었습니다.

**프로세스 맵(The Process Map)**
후이싱 교수님이 다음에 무슨 일이 일어났는지 설명하도록 하겠습니다: "일부 사람들은 최고 경영진 중 한두 명이 이러한 설계 및 운영 문제를 알고 있을 것이라는 희망을 품었지만, 그들은 종종 이러한 낙관주의에서 벗어나게 되었습니다. 예를 들어, 한 관리자가 CEO에게 맵을 설명하면서 그가 이전에 본 적 없는 관점을 제시하고, 설계의 부재와 전략 및 운영 간의 단절을 보여주었습니다. CEO는 맵 설명을 들은 후 자리에 앉아 머리를 테이블에 묻고 말했습니다. '이건 내가 상상했던 것보다 훨씬 더 엉망진창이군.' CEO는 자신의 조직 운영이 통제 불능일 뿐만 아니라, 그것에 대한 자신의 이해가 상상에 불과했음을 드러냈습니다."

많은 사람들에게 이것은 놀라운 일이 아닐 수도 있습니다. 조직을 연구하거나(또는 조직에서 일하면서) 배우는 한 가지는, 조직들이 실제로는 모두 다소 혼란스럽다는 것입니다. 사실, 고전적인 조직 이론 중 하나는 실제로 '쓰레기통 모델(Garbage Can Model)'이라고 불립니다. 이 모델은 조직을 문제, 해결책, 의사결정자가 함께 뒤섞여 있는 혼란스러운 "쓰레기통"으로 간주하며, 의사결정은 완전히 합리적인 과정을 통해서라기보다는 이러한 요소들이 무작위로 충돌할 때 종종 발생한다고 봅니다. 물론, 이러한 관점을 너무 극단적으로 받아들이기 쉽습니다. 조직에는 실제로 중요한 구조, 의사결정자, 프로세스가 존재합니다. 다만 이러한 구조는 신중하게 설계되고 잘 기록되기보다는, 종종 사람들과의 협상과 진화를 통해 형성되었다는 점입니다. 쓰레기통 모델은 불문율, 맞춤형 지식, 복잡하고 문서화되지 않은 프로세스가 중요한 세상을 나타냅니다.

미국 근로자의 43%가 직장에서 AI를 사용했음에도 불구하고, 대부분 비공식적인 방식으로 자신의 업무 문제를 해결하는 데 사용하고 있기 때문에, 이러한 상황이 조직 내 AI 도입을 어렵게 만듭니다. 전통적인 자동화(automation)는 명확한 규칙과 정의된 프로세스를 요구하는데, 이는 쓰레기통 모델의 조직들이 부족한 바로 그 요소들이기 때문에, 전사적으로 AI를 확장하는 것은 어렵습니다. AI와 업무의 더 일반적인 문제를 해결하려면 특정 사용 사례(use case)에 맞는 AI 기반 시스템을 신중하게 구축하고, 실제 프로세스를 매핑(mapping)하며, 발견된 문제를 해결할 도구를 만들어야 합니다. 이는 어렵고 느린 과정이며, 전사적 AI 도입에는 시간이 걸릴 것임을 시사합니다. 적어도, AI가 우리가 조직을 이해하는 방식대로 조직을 이해해야 한다고 가정한다면 그렇게 보입니다.

하지만 AI 연구자들은 이러한 종류의 가정에 대해 중요한 것을 배웠습니다.

**쓴 교훈(The Bitter Lesson)**
컴퓨터 과학자 리처드 서튼(Richard Sutton)은 2019년 영향력 있는 에세이에서 AI 연구의 한 패턴을 지적하며 쓴 교훈(Bitter Lesson)이라는 개념을 소개했습니다. 체스에서 인간을 이기는 것과 같은 어려운 문제를 해결하려는 AI 연구자들은 오프닝 수, 위치 평가, 전술 패턴, 엔드게임 데이터베이스(endgame database) 등을 연구하며 우아한 해결책을 반복적으로 모색했습니다. 프로그래머들은 수 세기 동안의 체스 지혜를 수작업으로 만든 소프트웨어에 인코딩했습니다: 중앙을 장악하고, 기물을 일찍 전개하며, 킹의 안전이 중요하고, 통과한 폰(passed pawn)은 가치가 있다는 등. 세계 최고의 인간을 이긴 최초의 체스 컴퓨터인 딥 블루(Deep Blue)는 일부 체스 지식을 사용했지만, 초당 2억 개의 위치를 탐색할 수 있는 무차별 대입(brute force) 방식과 결합했습니다. 2017년 구글은 체스뿐만 아니라 쇼기(shogi)와 바둑에서도 인간을 이길 수 있는 알파제로(AlphaZero)를 출시했으며, 이 모델은 이 게임들에 대한 사전 지식이 전혀 없이 이를 해냈습니다. 대신, AI 모델은 스스로 대결하며 게임을 학습할 때까지 플레이했습니다. 체스의 모든 우아한 지식은 무의미했으며, 순수한 무차별 대입 컴퓨팅(brute force computing)과 머신러닝(machine learning)의 일반화된 접근 방식이 결합된 것만으로도 그들을 이기기에 충분했습니다.

그리고 그것이 바로 쓴 교훈(Bitter Lesson)입니다. 인간의 이해를 AI에 인코딩하는 것은 AI가 문제를 해결하는 방법을 스스로 알아내도록 하고, 어떤 인간보다 더 잘할 수 있을 때까지 충분한 컴퓨팅 파워(computing power)를 추가하는 것보다 나쁜 경향이 있습니다.

이 그래프가 왜 두 가지 버전일까요? 그리고 왜 약간 다를까요? 잠시 후에 답을 알려드리겠습니다!

이 교훈이 쓰디쓴 이유는, 평생의 경험을 통해 쌓아온 문제에 대한 우리의 인간적 이해가 AI로 문제를 해결하는 데 그리 중요하지 않다는 것을 의미하기 때문입니다. 수십 년간 연구자들이 인간의 전문 지식을 인코딩하기 위해 기울인 신중한 노력은 결국 문제에 더 많은 컴퓨팅 자원(computation)을 투입하는 것보다 덜 효과적이었습니다. 우리는 곧 쓴 교훈(Bitter Lesson)이 업무 세계에 광범위하게 적용될지 여부를 알게 될 것입니다.

**에이전트(Agents)**
개인이 챗봇(chatbot)을 사용하는 것만으로도 많은 이점을 얻을 수 있지만, 조직에서 AI를 사용하는 방법에 대한 많은 관심은 에이전트(agent)에 집중되어 있습니다. 에이전트는 제가 '목표 달성을 위해 자율적인 행동을 취할 수 있는 AI 시스템'이라고 정의하는 모호한 용어입니다. 프롬프트(prompt)로 챗봇을 안내하는 것과 달리, 에이전트에게 작업을 위임하면 에이전트가 이를 수행합니다. 하지만 이전 AI 시스템들은 조직의 모든 요구 사항을 처리하기에 충분히 좋지 않았습니다. 현실 세계에는 너무 많은 혼란이 존재합니다. 이것이 바로 1년 전 우리가 첫 AI 기반 교육 게임을 만들었을 때, 좁은 작업을 처리하기 위해 에이전트 시스템(agentic system)의 각 단계를 신중하게 설계해야 했던 이유입니다. 그리고 AI의 자율적으로 작업하는 능력은 매우 빠르게 증가하고 있지만, 대부분의 복잡한 작업에서는 여전히 인간 수준에 훨씬 못 미치며, 복잡한 작업에서는 쉽게 잘못된 길로 빠질 수 있습니다. 이는 80%의 성공률을 기준으로 합니다.

에이전트 시스템(agentic system)의 최첨단 사례로, 클로드(Claude)와 일련의 영리한 접근 방식을 사용하여 실제 작업을 수행할 수 있는 AI 에이전트를 만드는 마누스(Manus)를 살펴보겠습니다. 마누스 팀은 흥미로운 엔지니어링(engineering) 요소와 매우 정교한 프롬프트(prompt) 설계를 포함하여 에이전트 구축을 위한 많은 팁을 공유했습니다. 이 게시물을 작성할 때, 저는 마누스에게 다음과 같이 요청했습니다: "최고의 그랜드마스터(grandmaster) ELO와 최초의 현대 체스 컴퓨터부터 2025년까지 세계 최고의 체스 컴퓨터 ELO를 비교하는 매력적인 그래프가 필요합니다." 그리고 시스템은 작업을 시작했습니다. 먼저, 마누스는 항상 할 일 목록(to-do list)을 만들고, 데이터를 수집하여 여러 파일을 작성했으며, 제가 요청한 몇 가지 사소한 조정 후에 마침내 위 왼쪽에서 볼 수 있는 그래프(그래프 주위에 상자가 없는 것)를 만들어냈습니다. 왜 이런 순서로 작업을 했을까요? 마누스는 수작업으로 구축되었고, 사용 가능한 최고의 범용 에이전트(general purpose agent)가 되도록 신중하게 제작되었기 때문입니다. 할 일 목록을 만드는 방법에 대한 자세한 지침을 포함하여, 시스템 프롬프트(system prompt)에는 수백 줄의 맞춤형 텍스트가 있습니다. 이는 오늘날의 AI 시스템과 에이전트를 작동시키는 방법에 대한 어렵게 얻은 지식을 통합합니다.

잠재적인 문제가 보이시나요? "신중하게 제작된", "맞춤형", "어렵게 얻은 지식 통합" — 이는 쓴 교훈(Bitter Lesson)이 우리에게 피하라고 말하는 바로 그 종류의 작업입니다. 왜냐하면 결국 더 범용적인 기술에 의해 무의미해질 것이기 때문입니다.

최근 챗GPT 에이전트(ChatGPT agent)의 출시로 이것이 가능할 수 있다는 증거가 나타났습니다 (영감을 주지 않는 이름이지만, 적어도 명확하며 OpenAI에게는 큰 진전입니다!). 챗GPT 에이전트는 근본적인 변화를 나타냅니다. 이것은 작업 수행 과정에 대해 훈련되지 않았습니다. 대신, OpenAI는 실제 최종 결과물(outcome)에 대해 AI를 훈련시키기 위해 강화 학습(reinforcement learning)을 사용했습니다. 예를 들어, 인간이 엑셀 파일(Excel file)을 만드는 방식을 가르치지 않고, AI가 개발하는 어떤 방법을 사용하든 좋은 파일을 만들도록 학습할 때까지 AI가 생성하는 엑셀 파일의 품질을 단순히 평가할 것입니다. 강화 학습(reinforcement learning)과 신중한 제작이 어떻게 유사한 결과로 이어지는지 보여주기 위해, 저는 챗GPT 에이전트(ChatGPT agent)에게 정확히 동일한 체스 프롬프트(prompt)를 주었고 위 오른쪽 그래프를 얻었습니다. 하지만 이번에는 할 일 목록(to-do list)도, 따라야 할 스크립트(script)도 없었습니다. 대신 에이전트는 훈련에 따라 저에게 가능한 최고의 결과물을 제공하기 위해 필요한 어떤 신비로운 경로든 찾아냈습니다. 아래에서 그 일부를 볼 수 있습니다:

하지만 외형 외에도 두 차트(chart) 사이에 몇 가지 차이점을 발견할 수 있을 것입니다. 예를 들어, 딥 블루(Deep Blue)의 ELO는 공식적으로 측정된 적이 없기 때문에 각각 딥 블루의 성능에 대한 다른 평가를 가지고 있습니다. 마누스의 평가는 기본적인 검색을 기반으로 했으며, 우리는 추측성 레딧(Reddit) 토론을 발견했습니다. 반면 딥 리서치(Deep Research)에서 사용된 강화 학습(reinforcement learning) 접근 방식으로 훈련된 챗GPT 에이전트(ChatGPT agent)는 주장을 뒷받침하기 위해 애틀랜틱(Atlantic) 기사를 포함한 더 신뢰할 수 있는 출처를 찾아냈습니다. 마찬가지로, 두 에이전트에게 완전히 작동하는 엑셀 파일(Excel file)을 만들어 그래프를 재현해달라고 요청했을 때, 챗GPT의 버전은 작동했지만 마누스의 버전에는 오류가 있었습니다. 챗GPT 에이전트가 마누스보다 더 나은지는 아직 모르겠지만, 경쟁자보다 훨씬 더 빠르게 발전할 가능성이 높다고 생각합니다. 마누스를 개선하려면 더 신중한 제작과 맞춤형 작업이 필요하지만, 챗GPT 에이전트를 개선하려면 단순히 더 많은 컴퓨터 칩(computer chip)과 더 많은 예시가 필요합니다. 쓴 교훈(Bitter Lesson)이 유효하다면, 장기적인 결과는 꽤 명확해 보입니다. 하지만 더 중요하게는, 수작업으로 제작된 에이전트와 결과물 기반으로 훈련된 에이전트 간의 비교는 조직이 AI 도입에 어떻게 접근해야 하는지에 대한 근본적인 질문을 제기합니다.

**쓰레기통 속의 에이전트(Agents in the Garbage Can)**
이것은 우리를 조직의 세계로 다시 데려옵니다. 개인들이 AI를 빠르게 채택하는 동안에도, 기업들은 여전히 쓰레기통 문제(Garbage Can problem)로 고심하며, 어떤 AI 시스템을 배포하기 전에 혼란스러운 프로세스를 매핑(mapping)하는 데 몇 달을 보냅니다. 하지만 그것이 거꾸로 된 것이라면 어떨까요? 쓴 교훈(Bitter Lesson)은 우리가 곧 기업이 결과물을 생산하는 방식을 무시하고 결과물 자체에만 집중할 수도 있음을 시사합니다. 좋은 판매 보고서나 고객 상호작용이 어떤 모습인지 정의한 다음, AI가 그것을 생산하도록 훈련시키세요. AI는 조직의 혼돈 속에서 자신만의 경로를 찾을 것입니다. 이 경로는 인간이 발전시킨 반공식적인 경로보다 더 불투명할 수 있지만, 더 효율적일 수도 있습니다.

쓴 교훈(Bitter Lesson)이 유효한 세상에서는, 머리를 테이블에 묻고 절망하는 CEO의 모습은 부적절합니다. 모든 망가진 프로세스를 풀어내려 하기보다, 그는 성공을 정의하고 AI가 혼란을 헤쳐나가도록 내버려 두기만 하면 됩니다. 사실, 쓴 교훈(Bitter Lesson)은 실제로는 달콤할 수도 있습니다. 조직에 만연한 모든 문서화되지 않은 워크플로우(workflow)와 비공식 네트워크(network)는 중요하지 않을 수도 있습니다. 중요한 것은 좋은 결과물을 보았을 때 그것을 알아볼 수 있는 것입니다. 이것이 사실이라면, 쓰레기통은 여전히 존재하지만, 경쟁 우위(competitive advantage) 자체가 재정의되는 동안 우리가 그것을 일일이 분류할 필요는 더 이상 없습니다. 기업들이 프로세스를 개선하고, 제도적 지식(institutional knowledge)을 구축하며, 운영 우수성(operational excellence)을 통해 경쟁 해자(competitive moat)를 만드는 데 들인 노력은 그들이 생각하는 것보다 덜 중요할 수 있습니다. 만약 AI 에이전트(agent)가 결과물만으로 훈련할 수 있다면, 품질을 정의하고 충분한 예시를 제공할 수 있는 어떤 조직이든, 자신들의 프로세스를 이해하든 못하든 유사한 결과를 달성할 수 있을 것입니다. 아니면 쓰레기통 모델이 승리하여, 인간의 복잡성과 그 혼란스럽고 진화된 프로세스들이 AI가 이해하지 않고는 헤쳐나가기에는 너무 복잡할 수도 있습니다. 우리는 조직이 실제로 어떤 종류의 문제인지 곧 알게 될 것입니다. 즉, 컴퓨팅 규모(computational scale)에 굴복하는 체스 게임과 같은 것인지, 아니면 근본적으로 더 혼란스러운 것인지 말입니다. 어떤 답에 베팅하든 기업들은 이미 움직이고 있으며, 우리는 우리가 실제로 어떤 게임을 하고 있는지 곧 알게 될 것입니다.

구독 공유