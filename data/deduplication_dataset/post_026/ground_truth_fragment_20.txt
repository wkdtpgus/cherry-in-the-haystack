**조직 혁신과 AI: 예측 불가능한 미래를 위한 새로운 접근법**

조직에 관한 우리의 이해는 끊임없이 진화하고 있습니다. 과거에는 기업의 복잡성을 이해하기 위해 수많은 분석과 진단이 이루어졌습니다. 조직이 실제로 수행하는 작업을 추적하는 것은 때때로 예상치 못한 통찰을 제공합니다. 루탄 후이싱(Ruthanne Huising)의 논문은 원자재부터 완제품에 이르기까지 조직이 실제로 수행하는 작업을 추적하여 회사의 프로세스 맵(process map)을 만들도록 배정된 팀들의 이야기를 다룹니다. 이 맵을 만들면서 그들은 작업의 상당 부분이 얼마나 이상하고 계획되지 않은 것처럼 보이는지 깨달았습니다. 그들은 아무도 사용하지 않는 결과물을 생산하는 전체 프로세스, 일을 처리하는 이상한 반공식적 경로, 그리고 반복적인 노력의 중복을 발견했습니다.

그러나 이러한 전통적인 접근 방식만으로는 급변하는 현대 비즈니스 환경의 모든 면을 포착하기 어렵습니다. 디지털 전환의 물결 속에서 기업들은 새로운 기술을 도입하며 대대적인 변화를 모색하고 있습니다. 이러한 변화를 만들면서 우리는 새로운 기술의 잠재력을 깨달았습니다. 새로운 기술은 반복적인 노력의 중복을 줄이고 효율성을 높이는 데 기여할 수 있지만, 기대만큼 쉽게 통합되지 않는다는 현실에 직면하기도 합니다. 맵 작업을 하던 직원들 중 상당수는 한때 회사의 떠오르는 별이었지만 환멸을 느끼게 되었으며, 많은 직원들은 새로운 기술 도입에 대한 기대와 우려를 동시에 느끼게 되었습니다. 기술 도입이 단순히 도구를 바꾸는 것을 넘어, 일하는 방식과 조직 문화 전반에 걸친 근본적인 재구성을 요구하기 때문입니다.

**디지털 전환의 복잡성**

최고 경영진은 새로운 기술 도입에 대한 기대와 우려를 동시에 품었지만, 실제 구현 과정은 종종 예상보다 훨씬 더 복잡합니다. 데이터 분석 결과는 종종 우리가 상상했던 것보다 훨씬 더 복잡한 현실을 보여줍니다. 기존의 프로세스와 새로운 기술 간의 마찰은 불가피하며, 이는 디지털 전환의 가장 큰 난관 중 하나로 작용합니다. 후이싱 교수님의 논문에서 한 관리자가 CEO에게 맵을 설명하면서 그가 이전에 본 적 없는 관점을 제시하고, 설계의 부재와 전략 및 운영 간의 단절을 보여주었습니다. CEO는 맵 설명을 들은 후 자리에 앉아 머리를 테이블에 묻고 말했습니다. '이건 내가 상상했던 것보다 훨씬 더 엉망진창이군.' CEO는 자신의 조직 운영이 통제 불능일 뿐만 아니라, 그것에 대한 자신의 이해가 상상에 불과했음을 드러냈습니다.

조직을 연구하면서 배우는 한 가지는, 혁신적인 기술이 기존의 틀을 얼마나 많이 흔들 수 있는지입니다. 많은 사람들에게 이것은 놀라운 일이 아닐 수도 있습니다. 조직들이 실제로는 모두 다소 혼란스럽다는 것입니다. 사실, 고전적인 조직 이론 중 하나는 실제로 '쓰레기통 모델(Garbage Can Model)'이라고 불립니다. 이 모델은 조직을 문제, 해결책, 의사결정자가 함께 뒤섞여 있는 혼란스러운 "쓰레기통"으로 간주하며, 의사결정은 완전히 합리적인 과정을 통해서라기보다는 이러한 요소들이 무작위로 충돌할 때 종종 발생한다고 봅니다. 물론, 이러한 관점을 너무 극단적으로 받아들이기 쉽습니다. 조직에는 실제로 중요한 구조, 의사결정자, 프로세스가 존재합니다. 다만 이러한 구조는 신중하게 설계되고 잘 기록되기보다는, 종종 사람들과의 협상과 진화를 통해 형성되었다는 점입니다. 쓰레기통 모델은 불문율, 맞춤형 지식, 복잡하고 문서화되지 않은 프로세스가 중요한 세상을 나타내며, 조직 내부의 비공식적인 네트워크와 암묵적인 지식은 새로운 시스템이 예상치 못한 방식으로 작동하거나, 아예 작동하지 않게 만드는 요인이 될 수 있습니다.

미국 근로자의 43%를 포함하여 많은 근로자가 직장에서 AI를 사용하고 있지만, 대부분 비공식적인 방식으로 자신의 업무 문제를 해결하는 데 사용하고 있기 때문에, 이러한 상황이 조직 내 AI 도입을 어렵게 만듭니다. 이는 전사적인 AI 도입의 중요한 장애물이 됩니다. 전통적인 자동화(automation)는 명확한 규칙과 정의된 프로세스를 요구하는데, 이는 쓰레기통 모델의 조직들이 부족한 바로 그 요소들이기 때문에, 전사적으로 AI를 확장하는 것은 단순히 기술을 도입하는 것 이상의 노력이 필요합니다. AI와 업무의 더 일반적인 문제를 해결하려면 특정 사용 사례(use case)에 맞는 AI 기반 시스템을 신중하게 구축하고, 실제 프로세스를 매핑(mapping)하며, 발견된 문제를 해결할 도구를 만들어야 합니다. 이는 어렵고 느린 과정이며, 전사적 AI 도입에는 시간이 걸릴 것임을 시사합니다. 적어도, AI가 우리가 조직을 이해하는 방식대로 조직을 이해해야 한다고 가정한다면 그렇게 보입니다. 하지만 AI 연구자들은 이러한 기존의 가정에 대해 새로운 시각을 제시하고 있습니다.

**쓴 교훈(Bitter Lesson)의 확장**

컴퓨터 과학자 리처드 서튼(Richard Sutton)은 2019년 영향력 있는 에세이에서 AI 연구의 한 패턴을 지적하며 '쓴 교훈(Bitter Lesson)'이라는 중요한 개념을 소개했습니다. 이 교훈은 특정 문제 해결 방식에 대한 우리의 직관과 오랜 경험이 때로는 기술 발전의 흐름에 역행할 수 있음을 보여줍니다. 체스에서 인간을 이기는 것과 같은 어려운 문제를 해결하려는 AI 연구자들은 오프닝 수, 위치 평가, 전술 패턴, 엔드게임 데이터베이스(endgame database) 등을 연구하며 우아한 해결책을 반복적으로 모색했습니다. 프로그래머들은 수 세기 동안의 체스 지혜를 수작업으로 만든 소프트웨어에 인코딩했습니다: 중앙을 장악하고, 기물을 일찍 전개하며, 킹의 안전이 중요하고, 통과한 폰(passed pawn)은 가치가 있다는 등. 세계 최고의 인간을 이긴 최초의 체스 컴퓨터인 딥 블루(Deep Blue)는 일부 체스 지식을 사용했지만, 초당 2억 개의 위치를 탐색할 수 있는 무차별 대입(brute force) 방식과 결합했습니다. 2017년 구글은 체스뿐만 아니라 쇼기(shogi)와 바둑에서도 인간을 이길 수 있는 알파제로(AlphaZero)를 출시했으며, 이 모델은 이 게임들에 대한 사전 지식이 전혀 없이 이를 해냈습니다. 대신, AI 모델은 스스로 대결하며 게임을 학습할 때까지 플레이했습니다. 체스의 모든 우아한 지식은 무의미했으며, 순수한 무차별 대입 컴퓨팅(brute force computing)과 머신러닝(machine learning)의 일반화된 접근 방식이 결합된 것만으로도 그들을 이기기에 충분했습니다.

그리고 그것이 바로 쓴 교훈(Bitter Lesson)의 핵심 메시지입니다. 인간의 이해를 AI에 인코딩하는 것은 AI가 문제를 해결하는 방법을 스스로 알아내도록 하고, 어떤 인간보다 더 잘할 수 있을 때까지 충분한 컴퓨팅 파워(computing power)를 추가하는 것보다 나쁜 경향이 있습니다.

이 교훈이 쓰디쓴 이유는, 평생의 경험을 통해 쌓아온 문제에 대한 우리의 인간적 이해와 전문 지식이 AI로 문제를 해결하는 데 그리 중요하지 않거나 때로는 AI의 학습 능력 앞에서 그 중요성이 퇴색될 수 있다는 것을 의미하기 때문입니다. 수십 년간 연구자들이 인간의 전문 지식을 인코딩하기 위해 기울인 신중한 노력은 결국 문제에 더 많은 컴퓨팅 자원(computation)을 투입하는 것보다 덜 효과적이었습니다. 이는 교육 시스템, 전문직의 미래, 그리고 지식 습득의 본질에 대한 근본적인 질문을 던집니다. 우리는 곧 이러한 '쓴 교훈(Bitter Lesson)'이 다양한 산업 분야에 어떻게 적용될지 목격하게 될 것입니다. 과학 연구, 신약 개발, 심지어 예술 창작에 이르기까지, 인간의 직관과 경험을 뛰어넘는 AI의 발견 능력이 새로운 패러다임을 제시하고 있습니다.

**자율 에이전트(Agents)와 결과 중심 접근**

개인이 챗봇(chatbot)을 사용하는 것만으로도 많은 이점을 얻을 수 있지만, 미래 기술의 핵심은 에이전트(agent)에 집중될 것입니다. 에이전트는 특정 목표 달성을 위해 자율적인 행동을 취할 수 있는 AI 시스템을 의미합니다. 프롬프트(prompt)로 챗봇을 안내하는 것과 달리, 에이전트에게 작업을 위임하면 에이전트가 이를 스스로 수행합니다. 하지만 이전 AI 시스템들은 복잡한 현실 세계의 모든 요구 사항을 처리하기에는 부족했습니다. 현실 세계에는 예측 불가능한 변수와 혼란이 존재합니다. 이것이 바로 1년 전 우리가 첫 AI 기반 교육 게임을 만들었을 때, 좁은 작업을 처리하기 위해 에이전트 시스템(agentic system)의 각 단계를 신중하게 설계해야 했던 이유입니다. AI의 자율적으로 작업하는 능력은 매우 빠르게 증가하고 있지만, 대부분의 복잡한 작업에서는 여전히 인간 수준에 훨씬 못 미치며, 복잡한 작업에서는 쉽게 잘못된 길로 빠질 수 있습니다. 이는 80%의 성공률을 기준으로 하며, AI 시스템의 신뢰성과 설명 가능성(explainability)에 대한 중요한 논의로 이어집니다.

에이전트 시스템(agentic system)의 최첨단 사례로, 클로드(Claude)와 일련의 영리한 접근 방식을 사용하여 실제 작업을 수행할 수 있는 AI 에이전트를 만드는 마누스(Manus)를 살펴보겠습니다. 마누스 팀은 흥미로운 엔지니어링(engineering) 요소와 매우 정교한 프롬프트(prompt) 설계를 포함하여 에이전트 구축을 위한 많은 팁을 공유했습니다. 이 게시물을 작성할 때, 저는 마누스에게 다음과 같이 요청했습니다: "최고의 그랜드마스터(grandmaster) ELO와 최초의 현대 체스 컴퓨터부터 2025년까지 세계 최고의 체스 컴퓨터 ELO를 비교하는 매력적인 그래프가 필요합니다." 그리고 시스템은 작업을 시작했습니다. 먼저, 마누스는 항상 할 일 목록(to-do list)을 만들고, 데이터를 수집하여 여러 파일을 작성했으며, 제가 요청한 몇 가지 사소한 조정 후에 마침내 그래프를 만들어냈습니다. 왜 이런 순서로 작업을 했을까요? 마누스는 수작업으로 구축되었고, 사용 가능한 최고의 범용 에이전트(general purpose agent)가 되도록 신중하게 제작되었기 때문입니다. 할 일 목록을 만드는 방법에 대한 자세한 지침을 포함하여, 시스템 프롬프트(system prompt)에는 수백 줄의 맞춤형 텍스트가 있습니다. 이는 오늘날의 AI 시스템과 에이전트를 작동시키는 방법에 대한 어렵게 얻은 지식을 통합합니다.

잠재적인 문제가 보이시나요? "신중하게 제작된", "맞춤형", "어렵게 얻은 지식 통합" — 이는 쓴 교훈(Bitter Lesson)이 우리에게 피하라고 말하는 바로 그 종류의 작업입니다. 왜냐하면 결국 더 범용적인 기술에 의해 무의미해질 것이기 때문입니다.

최근 챗GPT 에이전트(ChatGPT agent)의 출시로 이러한 가능성이 현실화될 수 있다는 증거가 나타났습니다 (영감을 주지 않는 이름이지만, 적어도 명확하며 OpenAI에게는 큰 진전입니다!). 챗GPT 에이전트는 기술 개발의 근본적인 변화를 나타냅니다. 이러한 시스템은 특정 작업 수행 과정에 대해 직접 훈련되지 않았습니다. 대신, OpenAI는 실제 최종 결과물(outcome) 자체에 초점을 맞춰 AI를 훈련시키기 위해 강화 학습(reinforcement learning)을 활용했습니다. 예를 들어, 인간이 엑셀 파일(Excel file)을 만드는 방식을 가르치지 않고, AI가 개발하는 어떤 방법을 사용하든 좋은 파일을 만들도록 학습할 때까지 AI가 생성하는 엑셀 파일의 품질을 단순히 평가할 것입니다. 강화 학습(reinforcement learning)은 신중한 제작 방식과 유사한 수준의 결과로 이어질 수 있음을 보여주었습니다. 저는 챗GPT 에이전트(ChatGPT agent)에게 정확히 동일한 체스 프롬프트(prompt)를 주었고, 이번에는 명확한 할 일 목록(to-do list)이나 따라야 할 스크립트(script) 없이 자율적으로 작동했습니다. 대신 에이전트는 훈련을 통해 최고의 결과물을 제공하기 위한 최적의 경로를 스스로 찾아냈습니다.

하지만 외형 외에도 두 시스템 사이에는 몇 가지 중요한 차이점을 발견할 수 있습니다. 예를 들어, 딥 블루(Deep Blue)의 ELO는 공식적으로 측정된 적이 없기 때문에 각각 딥 블루의 성능에 대한 다른 평가를 가지고 있습니다. 마누스의 평가는 기본적인 검색을 기반으로 했으며, 우리는 추측성 레딧(Reddit) 토론을 발견했습니다. 반면 딥 리서치(Deep Research)에서 사용된 강화 학습(reinforcement learning) 접근 방식으로 훈련된 챗GPT 에이전트(ChatGPT agent)는 주장을 뒷받침하기 위해 애틀랜틱(Atlantic) 기사를 포함한 더 신뢰할 수 있는 출처를 찾아냈습니다. 마찬가지로, 두 에이전트에게 완전히 작동하는 엑셀 파일(Excel file)을 만들어 그래프를 재현해달라고 요청했을 때, 챗GPT의 버전은 작동했지만 마누스의 버전에는 오류가 있었습니다. 챗GPT 에이전트가 마누스보다 더 나은지는 아직 단정할 수 없지만, 경쟁자보다 훨씬 더 빠르게 발전할 가능성이 높다고 예측됩니다. 마누스를 개선하려면 더 신중한 제작과 맞춤형 작업이 필요하지만, 챗GPT 에이전트를 개선하려면 단순히 더 많은 컴퓨터 칩(computer chip)과 더 많은 예시가 필요합니다. '쓴 교훈(Bitter Lesson)'이 유효하다면, 장기적인 기술 발전의 방향은 꽤 명확해 보입니다. 하지만 더 중요하게는, 수작업으로 제작된 시스템과 결과물 기반으로 훈련된 AI 간의 비교는 조직이 AI 도입에 어떻게 접근해야 하는지에 대한 근본적인 질문을 제기합니다.

**미래 조직의 재정의**

이러한 논의는 우리를 조직의 세계로 다시 데려옵니다. 개인들이 AI를 빠르게 채택하는 동안에도, 기업들은 여전히 복잡한 문제(complex problem)이자 쓰레기통 문제(Garbage Can problem)로 고심하며, 어떤 AI 시스템을 배포하기 전에 혼란스러운 프로세스를 매핑(mapping)하는 데 몇 달을 보냅니다. 하지만 우리가 바라보는 관점이 거꾸로 된 것이라면 어떨까요? '쓴 교훈(Bitter Lesson)'은 기업이 결과물을 생산하는 방식보다 결과물 자체에 집중해야 한다고 시사합니다. 좋은 판매 보고서나 고객 상호작용이 어떤 모습인지 정의한 다음, AI가 그것을 생산하도록 훈련시킨다면 어떨까요? AI는 조직의 혼돈 속에서 자신만의 최적 경로를 찾아낼 것입니다. 이 경로는 인간이 발전시킨 반공식적인 경로보다 더 불투명할 수 있지만, 훨씬 더 효율적일 수도 있습니다.

'쓴 교훈(Bitter Lesson)'이 유효한 세상에서는, 머리를 테이블에 묻고 절망하는 CEO의 모습처럼 과거의 방식에 얽매여 절망하는 것은 부적절합니다. 모든 복잡한 프로세스를 분석하기보다, 성공을 명확히 정의하고 AI가 혼란을 헤쳐나가 스스로 해결책을 찾도록 해야 합니다. 사실, '쓴 교훈(Bitter Lesson)'은 기업에게 달콤한 기회가 될 수도 있습니다. 조직에 만연한 모든 문서화되지 않은 워크플로우(workflow)와 비공식 네트워크(network)는 미래에는 그 중요성이 퇴색될 수 있습니다. 중요한 것은 좋은 결과물을 명확히 정의하고 이를 달성하는 것입니다. 이것이 사실이라면, 쓰레기통은 여전히 존재하지만, 경쟁 우위(competitive advantage) 자체가 재정의되는 동안 우리가 그것을 일일이 분류할 필요는 더 이상 없을 것입니다. 기업들이 프로세스를 개선하고, 제도적 지식(institutional knowledge)을 구축하며, 운영 우수성(operational excellence)을 통해 경쟁 해자(competitive moat)를 만드는 데 들인 노력은 그들이 생각하는 것보다 덜 중요할 수 있습니다. 만약 AI 에이전트(agent)가 결과물만으로 훈련할 수 있다면, 품질을 정의하고 충분한 예시를 제공할 수 있는 어떤 조직이든, 자신들의 프로세스를 이해하든 못하든 유사한 결과를 달성할 수 있을 것입니다.

우리는 조직의 본질적인 문제가 어떤 종류인지 곧 알게 될 것입니다. 즉, 컴퓨팅 규모(computational scale)에 의해 해결되는 체스 게임과 같은 것인지, 아니면 인간의 복잡성이 근본적으로 더 중요한 것인지 말입니다. 어떤 답이 옳든 기업들은 이미 미래를 향해 움직이고 있으며, 우리는 곧 이 변화의 본질을 깨닫게 될 것입니다. 인간의 창의성과 직관이 AI의 압도적인 처리 능력과 어떻게 조화를 이루며 새로운 가치를 창출할지, 그리고 미래의 업무는 어떤 모습일지 지켜보는 것은 흥미로운 여정이 될 것입니다.

구독 공유