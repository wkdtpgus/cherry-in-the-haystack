조직에 관한 제가 아끼는 학술 논문 중 하나는 루탄 후이싱(Ruthanne Huising)의 연구입니다. 이 논문은 원자재에서 최종 제품에 이르기까지 조직이 실제로 어떻게 기능하는지 상세히 추적하여 기업의 프로세스 맵(process map)을 제작하는 임무를 맡은 팀들의 경험을 다룹니다. 이 지도를 그리는 과정에서, 그들은 업무의 상당 부분이 얼마나 비정상적이고 계획되지 않은 것처럼 보이는지 명확히 인식하게 되었습니다. 팀은 아무도 사용하지 않는 결과물을 만들어내는 전체 작업 흐름, 업무를 처리하는 이상하고 비공식적인 경로, 그리고 반복적인 노력의 중복 현상을 발견했습니다. 이 맵 작업에 참여했던 직원들 중 상당수는 한때 회사의 유망주였지만, 이 경험을 통해 큰 실망감을 느끼게 되었습니다.

**프로세스 지도와 조직의 실체 (The Process Map and Organizational Reality)**
후이싱 교수님이 이후의 전개를 설명하도록 하겠습니다: "일부 직원들은 최고 경영진 중 한두 명 정도는 이러한 설계 및 운영상의 문제들을 인지하고 있을 것이라는 막연한 기대를 품었지만, 그들은 종종 이러한 낙관적인 시각에서 벗어나게 되었습니다. 예를 들어, 한 관리자가 CEO에게 맵을 제시하며 그가 이전에 접해본 적 없는 관점을 제공했고, 이는 설계의 부재와 전략 및 운영 간의 심각한 단절을 여실히 보여주었습니다. CEO는 맵 설명을 듣고 난 후 자리에 앉아 머리를 테이블에 묻으며 '이건 내가 상상했던 것보다 훨씬 더 엉망진창이군'이라고 탄식했습니다. CEO의 반응은 자신의 조직 운영이 통제 불능일 뿐만 아니라, 그것에 대한 그의 이해가 실제와는 거리가 먼 상상에 불과했음을 드러내는 순간이었습니다."

많은 이들에게 이러한 상황은 그리 놀라운 일이 아닐 수 있습니다. 조직을 연구하거나 (혹은 조직에서 직접 일하면서) 깨닫는 한 가지 사실은, 실제 조직들은 대부분 어느 정도 혼란스러운 상태에 놓여 있다는 점입니다. 실제로, 고전적인 조직 이론 중 하나는 '쓰레기통 모델(Garbage Can Model)'이라고 불립니다. 이 모델은 조직을 문제, 해결책, 의사결정자가 뒤섞여 있는 혼란스러운 "쓰레기통"으로 간주하며, 의사결정은 완전한 합리적 과정을 통해서라기보다는 이러한 요소들이 무작위로 충돌할 때 자주 발생한다고 설명합니다. 물론, 이러한 관점을 지나치게 극단적으로 받아들이는 것은 경계해야 합니다. 조직에는 분명 중요한 구조, 의사결정자, 그리고 정립된 프로세스가 존재합니다. 다만 이러한 구조들이 신중하게 설계되고 명확하게 문서화되기보다는, 종종 사람들의 상호작용과 시간이 지남에 따른 진화를 통해 형성되었다는 점이 핵심입니다. 쓰레기통 모델은 암묵적인 규칙, 개인화된 지식, 그리고 복잡하고 비공식적인 절차가 중요한 세계를 대변합니다.

미국 근로자의 43%가 업무에 AI를 활용했음에도 불구하고, 대부분 비공식적인 방식으로 개인의 문제 해결에 사용하고 있어, 이러한 조직의 특성은 AI의 전사적 도입을 어렵게 만듭니다. 기존의 자동화(automation)는 명확한 규칙과 잘 정의된 프로세스를 요구하지만, 이는 쓰레기통 모델의 조직들이 흔히 결여하고 있는 요소이므로, AI를 기업 전체로 확장하는 것은 만만치 않습니다. AI를 활용하여 업무의 일반적인 난제를 해결하기 위해서는 특정 사용 사례(use case)에 최적화된 AI 시스템을 신중하게 구축하고, 실제 작업 프로세스를 면밀히 매핑(mapping)하며, 발견된 문제점을 해결할 수 있는 도구를 개발해야 합니다. 이는 어렵고 느린 과정이며, 전사적인 AI 도입에는 상당한 시간이 소요될 것임을 시사합니다. 적어도, AI가 우리가 조직을 이해하는 방식대로 조직을 이해해야 한다고 가정한다면 그렇게 보입니다.

그러나 AI 연구자들은 이러한 종류의 가정에 대해 중요한 교훈을 얻었습니다.

**쓰디쓴 교훈 (The Bitter Lesson)**
컴퓨터 과학자 리처드 서튼(Richard Sutton)은 2019년 발표한 영향력 있는 에세이에서 AI 연구의 특정 패턴을 지적하며 '쓰디쓴 교훈(Bitter Lesson)'이라는 개념을 제시했습니다. 체스에서 인간을 압도하는 것과 같은 어려운 문제에 도전하는 AI 연구자들은 오프닝 수, 위치 평가, 전술 패턴, 엔드게임 데이터베이스(endgame database) 등을 탐구하며 우아한 해결책을 반복적으로 추구했습니다. 프로그래머들은 수세기 동안 축적된 체스 지식을 직접 만든 소프트웨어에 코딩했습니다: 중앙을 장악하고, 기물을 조기에 전개하며, 킹의 안전이 중요하고, 통과한 폰(passed pawn)은 가치가 있다는 등의 규칙 말입니다. 세계 최고 수준의 인간을 이긴 최초의 체스 컴퓨터인 딥 블루(Deep Blue)는 일부 체스 지식을 활용했지만, 초당 2억 개의 위치를 탐색할 수 있는 무차별 대입(brute force) 방식과 결합했습니다. 2017년 구글은 체스뿐만 아니라 쇼기(shogi)와 바둑에서도 인간을 능가할 수 있는 알파제로(AlphaZero)를 선보였으며, 이 모델은 해당 게임들에 대한 사전 지식이 전혀 없는 상태에서 이를 성취했습니다. 대신, AI 모델은 스스로 대결하며 게임을 학습할 때까지 반복적으로 플레이했습니다. 체스의 모든 정교한 지식은 무의미해졌고, 순수한 무차별 대입 컴퓨팅(brute force computing)과 머신러닝(machine learning)의 일반화된 접근 방식이 결합된 것만으로도 인간을 능가하기에 충분했습니다.

그리고 그것이 바로 쓰디쓴 교훈(Bitter Lesson)의 본질입니다. 인간의 이해를 AI에 주입하는 방식은, AI가 문제 해결 방식을 스스로 터득하도록 하고 충분한 컴퓨팅 파워(computing power)를 추가하여 어떤 인간보다도 능숙하게 수행할 수 있도록 하는 것보다 대체로 비효율적입니다.

이 그래프가 왜 두 가지 버전일까요? 그리고 왜 약간 다를까요? 잠시 후에 답을 알려드리겠습니다!

이 교훈이 '쓰디쓰다'고 불리는 이유는, 평생의 경험을 통해 쌓아온 문제에 대한 우리의 인간적 통찰이 AI를 활용한 문제 해결에는 그리 중요하지 않을 수 있음을 의미하기 때문입니다. 수십 년간 연구자들이 인간의 전문 지식을 인코딩하기 위해 기울인 신중한 노력은 결국 문제에 더 많은 컴퓨팅 자원(computation)을 투입하는 것보다 덜 효과적이었습니다. 우리는 곧 쓰디쓴 교훈(Bitter Lesson)이 업무 세계에 광범위하게 적용될지 여부를 목격하게 될 것입니다.

**에이전트 시스템의 진화 (The Evolution of Agent Systems)**
개인이 챗봇(chatbot)을 사용하는 것만으로도 많은 이점을 누릴 수 있지만, 조직 내 AI 활용에 대한 상당한 관심은 '에이전트(agent)'에 집중되어 있습니다. 에이전트는 제가 '목표 달성을 위해 자율적인 행동을 취할 수 있는 AI 시스템'이라고 정의하는 광범위한 용어입니다. 프롬프트(prompt)를 통해 챗봇을 직접 지시하는 것과 달리, 에이전트에게 작업을 위임하면 에이전트가 알아서 이를 수행합니다. 그러나 과거의 AI 시스템들은 조직의 복잡한 요구사항을 모두 처리하기에는 역부족이었습니다. 현실 세계에는 예측 불가능한 변수가 너무 많습니다. 이것이 바로 1년 전 저희가 첫 AI 기반 교육 게임을 개발했을 때, 특정 작업을 처리하기 위해 에이전트 시스템(agentic system)의 각 단계를 매우 신중하게 설계해야 했던 이유입니다. AI의 자율적인 작업 수행 능력은 급속도로 발전하고 있지만, 대부분의 복잡한 작업에서는 여전히 인간 수준에 훨씬 미치지 못하며, 복잡한 상황에서는 쉽게 잘못된 방향으로 나아갈 수 있습니다. 이는 80%의 성공률을 기준으로 할 때의 이야기입니다.

에이전트 시스템(agentic system)의 최첨단 사례로, 클로드(Claude)와 일련의 독창적인 접근 방식을 활용하여 실제 작업을 수행하는 AI 에이전트를 구축한 마누스(Manus)를 살펴보겠습니다. 마누스 팀은 흥미로운 엔지니어링(engineering) 요소와 매우 정교한 프롬프트(prompt) 설계 등 에이전트 구축에 대한 다양한 노하우를 공유했습니다. 이 게시물을 작성할 당시, 저는 마누스에게 다음과 같이 요청했습니다: "최고의 그랜드마스터(grandmaster) ELO와 최초의 현대 체스 컴퓨터부터 2025년까지 세계 최고의 체스 컴퓨터 ELO를 비교하는 매력적인 그래프가 필요합니다." 그러자 시스템은 즉시 작업을 시작했습니다. 먼저, 마누스는 항상 할 일 목록(to-do list)을 생성하고, 데이터를 수집하여 여러 파일을 작성했으며, 제가 요청한 몇 가지 작은 조정 후에 마침내 위 왼쪽에서 볼 수 있는 그래프(그래프 주위에 상자가 없는 것)를 만들어냈습니다. 마누스가 이러한 순서로 작업을 진행한 이유는 무엇일까요? 마누스는 수작업으로 정교하게 제작되었으며, 현존하는 최고의 범용 에이전트(general purpose agent)가 되도록 세심하게 설계되었기 때문입니다. 할 일 목록을 만드는 방법에 대한 자세한 지침을 포함하여, 시스템 프롬프트(system prompt)에는 수백 줄에 달하는 맞춤형 텍스트가 포함되어 있습니다. 이는 오늘날의 AI 시스템과 에이전트를 효과적으로 작동시키는 방법에 대한 어렵게 얻은 지식을 통합한 결과입니다.

여기서 잠재적인 문제점이 보이시나요? "신중하게 제작된", "맞춤형", "어렵게 얻은 지식 통합" — 이는 쓰디쓴 교훈(Bitter Lesson)이 우리에게 피하라고 경고하는 바로 그 유형의 작업입니다. 왜냐하면 결국 더 범용적인 기술에 의해 그 가치가 퇴색될 것이기 때문입니다.

최근 챗GPT 에이전트(ChatGPT agent)의 출시로 이것이 현실이 될 수 있다는 증거가 나타났습니다 (이름은 다소 영감을 주지 않지만, 적어도 명확하며 OpenAI에게는 큰 진전입니다!). 챗GPT 에이전트는 근본적인 변화를 상징합니다. 이 시스템은 작업 수행 과정에 대해 직접적으로 훈련되지 않았습니다. 대신, OpenAI는 실제 최종 결과물(outcome)에 대해 AI를 훈련시키기 위해 강화 학습(reinforcement learning)을 활용했습니다. 예를 들어, 인간이 엑셀 파일(Excel file)을 만드는 방식을 가르치기보다는, AI가 어떤 방법을 사용하든 좋은 파일을 생성하도록 학습할 때까지 AI가 만들어내는 엑셀 파일의 품질을 단순히 평가하는 방식입니다. 강화 학습(reinforcement learning)과 신중한 제작이 어떻게 유사한 결과로 이어지는지 보여주기 위해, 저는 챗GPT 에이전트(ChatGPT agent)에게 정확히 동일한 체스 프롬프트(prompt)를 주었고 위 오른쪽 그래프를 얻었습니다. 하지만 이번에는 할 일 목록(to-do list)도, 따라야 할 스크립트(script)도 없었습니다. 대신 에이전트는 훈련에 따라 저에게 가능한 최고의 결과물을 제공하기 위해 필요한 어떤 신비로운 경로든 찾아냈습니다. 아래에서 그 일부를 볼 수 있습니다:

하지만 외형적인 모습 외에도 두 차트(chart) 사이에는 몇 가지 중요한 차이점을 발견할 수 있을 것입니다. 예를 들어, 딥 블루(Deep Blue)의 ELO는 공식적으로 측정된 적이 없기 때문에 각각 딥 블루의 성능에 대한 다른 평가를 제시합니다. 마누스의 평가는 기본적인 검색에 기반했으며, 우리는 추측성 레딧(Reddit) 토론을 발견했습니다. 반면 딥 리서치(Deep Research)에서 활용된 강화 학습(reinforcement learning) 접근 방식으로 훈련된 챗GPT 에이전트(ChatGPT agent)는 주장을 뒷받침하기 위해 애틀랜틱(Atlantic) 기사를 포함한 더 신뢰할 수 있는 출처를 찾아냈습니다. 마찬가지로, 두 에이전트에게 완전히 작동하는 엑셀 파일(Excel file)을 생성하여 그래프를 재현해달라고 요청했을 때, 챗GPT의 버전은 완벽하게 작동했지만 마누스의 버전에는 오류가 있었습니다. 챗GPT 에이전트가 마누스보다 절대적으로 우수하다고 단정하기는 아직 이르지만, 경쟁자보다 훨씬 더 빠르게 발전할 가능성이 높다고 생각합니다. 마누스를 개선하려면 더 많은 신중한 제작과 맞춤형 작업이 필요하지만, 챗GPT 에이전트를 개선하려면 단순히 더 많은 컴퓨터 칩(computer chip)과 더 많은 학습 예시가 필요합니다. 쓰디쓴 교훈(Bitter Lesson)이 유효하다면, 장기적인 결과는 꽤 명확해 보입니다. 하지만 더 중요하게는, 수작업으로 제작된 에이전트와 결과물 기반으로 훈련된 에이전트 간의 비교는 조직이 AI 도입에 어떻게 접근해야 하는지에 대한 근본적인 질문을 던집니다.

**혼돈 속의 에이전트: 조직의 새로운 접근 방식 (Agents in the Garbage Can: A New Approach to Organizations)**
이러한 통찰은 다시 우리를 조직의 세계로 이끌어줍니다. 개인들이 AI를 빠르게 수용하는 동안에도, 기업들은 여전히 '쓰레기통 문제(Garbage Can problem)'로 고심하며, 어떤 AI 시스템을 배포하기 전에 혼란스러운 프로세스를 매핑(mapping)하는 데 수개월을 소비합니다. 하지만 만약 그 방식이 거꾸로 된 것이라면 어떨까요? '쓰디쓴 교훈(Bitter Lesson)'은 우리가 곧 기업이 결과물을 만들어내는 방식 자체를 무시하고, 오직 결과물에만 집중할 수도 있음을 시사합니다. 예를 들어, 훌륭한 판매 보고서나 만족스러운 고객 상호작용이 어떤 모습이어야 하는지 명확히 정의한 다음, AI가 그것을 생성하도록 훈련시키는 것입니다. AI는 조직 내부의 혼돈 속에서 자신만의 최적 경로를 찾아낼 것입니다. 이 경로는 인간이 발전시킨 비공식적인 경로보다 더 불투명할 수 있지만, 동시에 훨씬 더 효율적일 수도 있습니다.

쓰디쓴 교훈(Bitter Lesson)이 지배하는 세상에서는, 테이블에 머리를 묻고 절망하는 CEO의 모습은 더 이상 적절하지 않습니다. 모든 망가진 프로세스를 하나하나 해결하려 애쓰기보다는, 그는 성공을 명확히 정의하고 AI가 그 혼란을 헤쳐나가도록 내버려 두기만 하면 됩니다. 사실, 쓰디쓴 교훈(Bitter Lesson)은 역설적으로 '달콤한 교훈'이 될 수도 있습니다. 조직에 만연한 모든 문서화되지 않은 워크플로우(workflow)와 비공식 네트워크(network)는 더 이상 결정적이지 않을 수 있습니다. 중요한 것은 좋은 결과물을 보았을 때 그것을 즉시 인식할 수 있는 능력입니다. 만약 이것이 사실이라면, 쓰레기통은 여전히 존재하겠지만, 경쟁 우위(competitive advantage) 자체가 재정의되는 동안 우리가 그것을 일일이 분류할 필요는 더 이상 없을 것입니다. 기업들이 프로세스를 개선하고, 제도적 지식(institutional knowledge)을 구축하며, 운영 우수성(operational excellence)을 통해 경쟁 해자(competitive moat)를 만들려고 들인 노력은 그들이 생각하는 것보다 덜 중요할 수 있습니다. 만약 AI 에이전트(agent)가 오직 결과물만으로 훈련될 수 있다면, 품질을 정의하고 충분한 예시를 제공할 수 있는 어떤 조직이든, 자신들의 내부 프로세스를 완전히 이해하든 못하든 유사한 성과를 달성할 수 있을 것입니다. 아니면 쓰레기통 모델이 결국 승리하여, 인간의 복잡성과 그 혼란스럽고 진화된 프로세스들이 AI가 완전히 이해하지 않고는 헤쳐나가기에는 너무 복잡할 수도 있습니다. 우리는 조직이 실제로 어떤 종류의 문제인지 곧 알게 될 것입니다. 즉, 컴퓨팅 규모(computational scale)에 굴복하는 체스 게임과 같은 것인지, 아니면 근본적으로 더 예측 불가능하고 혼란스러운 것인지 말입니다. 어떤 답에 베팅하든 기업들은 이미 움직이고 있으며, 우리는 우리가 실제로 어떤 게임을 하고 있는지 곧 명확히 알게 될 것입니다.

구독 공유