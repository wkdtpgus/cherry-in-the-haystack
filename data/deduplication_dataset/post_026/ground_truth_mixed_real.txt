조직의 혼돈과 AI 에이전트: 쓴 교훈의 재조명

조직에 관한 제가 가장 좋아하는 학술 논문 중 하나는 루탄 후이싱(Ruthanne Huising)의 연구입니다. 이 논문은 원자재부터 완제품에 이르기까지 조직이 실제로 수행하는 작업을 추적하여 회사의 프로세스 맵(process map)을 만들도록 배정된 팀들의 이야기를 다룹니다. 이 맵을 만들면서 그들은 작업의 상당 부분이 얼마나 이상하고 계획되지 않은 것처럼 보이는지 깨달았습니다. 많은 이들이 아무도 사용하지 않는 결과물을 생산하는 전체 프로세스, 예상치 못한 반공식적 경로, 그리고 불필요한 노력의 중복을 발견했습니다. 이 과정에 참여했던 직원들 중 상당수는 한때 회사의 유망주였지만, 조직의 실체를 마주하며 깊은 회의감을 느끼게 되었습니다.

**프로세스 맵(The Process Map)**

후이싱 교수님이 다음에 무슨 일이 일어났는지 설명하도록 하겠습니다: "일부 사람들은 최고 경영진 중 한두 명이 이러한 설계 및 운영 문제를 알고 있을 것이라는 희망을 품었지만, 그들은 종종 이러한 낙관주의에서 벗어나게 되었습니다. 예를 들어, 한 관리자가 CEO에게 맵을 설명하면서 그가 이전에 본 적 없는 관점을 제시하고, 설계의 부재와 전략 및 운영 간의 단절을 보여주었습니다. CEO는 맵 설명을 들은 후 자리에 앉아 머리를 테이블에 묻고 말했습니다. '이건 내가 상상했던 것보다 훨씬 더 엉망진창이군.' 최고 경영자는 자신의 조직 운영이 통제 불능일 뿐만 아니라, 그것에 대한 자신의 이해가 상상에 불과했음을 드러냈습니다."

이러한 상황은 많은 이들에게 놀라운 일이 아닐 수 있습니다. 조직을 연구하거나 직접 경험하면서 배우는 중요한 교훈 중 하나는, 모든 조직이 실제로는 어느 정도 혼란스럽다는 것입니다. 실제로, 고전적인 조직 이론 중 '쓰레기통 모델(Garbage Can Model)'이라는 개념이 있습니다. 이 모델은 조직을 문제, 해결책, 의사결정자가 뒤섞인 혼란스러운 "쓰레기통"으로 간주하며, 의사결정이 완전히 합리적인 과정을 통하기보다는 이러한 요소들이 무작위로 충돌할 때 자주 발생한다고 설명합니다. 물론, 이 관점을 너무 극단적으로 받아들여서는 안 됩니다. 조직에는 분명 중요한 구조, 의사결정자, 그리고 프로세스가 존재합니다. 다만 이러한 구조가 신중하게 설계되고 잘 문서화되기보다는, 사람들과의 상호작용과 시간이 지남에 따른 진화를 통해 형성되는 경우가 많다는 점이 핵심입니다. 쓰레기통 모델은 불문율, 맞춤형 지식, 그리고 복잡하지만 명확히 문서화되지 않은 프로세스가 지배하는 세상을 잘 보여줍니다.

2025년 현재, 전 세계적으로 AI 기술이 업무 환경에 깊숙이 침투하고 있음에도 불구하고, 여전히 많은 기업은 이러한 '쓰레기통' 문제로 인해 AI 도입에 어려움을 겪고 있습니다. 전통적인 자동화(automation)는 명확한 규칙과 정의된 프로세스를 요구하는데, 이는 쓰레기통 모델의 조직들이 부족한 바로 그 요소들이기 때문에, 전사적으로 AI를 확장하는 것은 여전히 쉽지 않은 과제입니다. AI를 통해 업무의 복잡한 문제들을 해결하려면, 특정 사용 사례(use case)에 맞는 AI 기반 시스템을 신중하게 구축하고, 실제 프로세스를 면밀히 매핑(mapping)하며, 발견된 문제를 해결할 도구를 개발해야 한다는 인식이 지배적이었습니다. 이는 어렵고 시간이 많이 소요되는 과정으로, 전사적 AI 도입에는 상당한 시간이 걸릴 것임을 시사했습니다. 적어도, AI가 우리가 조직을 이해하는 방식대로 조직을 이해해야 한다고 가정한다면 그렇게 보였습니다.

하지만 AI 연구자들은 이러한 종류의 가정에 대해 중요한 것을 배웠습니다.

**쓴 교훈(The Bitter Lesson)**

컴퓨터 과학자 리처드 서튼(Richard Sutton)은 2019년 영향력 있는 에세이에서 AI 연구의 한 패턴을 지적하며 쓴 교훈(Bitter Lesson)이라는 개념을 소개했습니다. 체스에서 인간을 이기는 것과 같은 어려운 문제들을 해결하려던 AI 연구자들은, 오프닝 수, 위치 평가, 전술 패턴, 엔드게임 데이터베이스(endgame database) 등 인간의 지식을 기반으로 한 '우아한' 해결책을 반복적으로 모색했습니다. 프로그래머들은 수 세기 동안의 체스 지혜를 수작업으로 만든 소프트웨어에 인코딩했습니다: 중앙을 장악하고, 기물을 일찍 전개하며, 킹의 안전이 중요하고, 통과한 폰(passed pawn)은 가치가 있다는 등. 세계 최고의 인간을 이긴 최초의 체스 컴퓨터인 딥 블루(Deep Blue)는 일부 체스 지식을 활용했지만, 초당 2억 개의 위치를 탐색할 수 있는 무차별 대입(brute force) 방식과 결합했습니다. 그러다 2017년, 구글은 체스뿐만 아니라 쇼기(shogi)와 바둑에서도 인간을 이길 수 있는 알파제로(AlphaZero)를 출시했습니다. 이 모델은 해당 게임들에 대한 사전 지식이 전혀 없이 이를 해냈습니다. 대신, AI 모델은 스스로 대결하며 게임을 학습할 때까지 플레이했습니다. 체스의 모든 우아한 지식은 무의미했으며, 순수한 무차별 대입 컴퓨팅(brute force computing)과 머신러닝(machine learning)의 일반화된 접근 방식이 결합된 것만으로도 그들을 이기기에 충분했습니다.

그리고 그것이 바로 쓴 교훈(Bitter Lesson)입니다. 인간의 이해를 AI에 인코딩하는 것은 AI가 문제를 해결하는 방법을 스스로 알아내도록 하고, 어떤 인간보다 더 잘할 수 있을 때까지 충분한 컴퓨팅 파워(computing power)를 추가하는 것보다 일반적으로 좋지 않은 결과를 낳습니다.

이 교훈이 쓰디쓴 이유는, 평생의 경험을 통해 쌓아온 문제에 대한 우리의 인간적 이해가 AI로 문제를 해결하는 데 그리 중요하지 않을 수 있다는 것을 의미하기 때문입니다. 수십 년간 연구자들이 인간의 전문 지식을 인코딩하기 위해 기울인 신중한 노력은 결국 문제에 더 많은 컴퓨팅 자원(computation)을 투입하는 것보다 덜 효과적이었습니다. 오늘날 우리는 쓴 교훈(Bitter Lesson)이 업무 세계에 얼마나 광범위하게 적용될지 목격하고 있습니다.

**에이전트(Agents)**

개인이 챗봇(chatbot)을 사용하는 것만으로도 많은 이점을 얻을 수 있지만, 조직에서 AI를 활용하는 방식에 대한 주요 관심사는 에이전트(agent)에 집중되어 있습니다. 에이전트는 제가 '목표 달성을 위해 자율적인 행동을 취할 수 있는 AI 시스템'이라고 정의하는 용어입니다. 프롬프트(prompt)로 챗봇을 안내하는 것과 달리, 에이전트에게 작업을 위임하면 에이전트가 이를 수행합니다. 불과 1년 전만 해도, 이전 AI 시스템들은 조직의 복잡한 요구 사항을 처리하기에 충분히 좋지 않았습니다. 현실 세계에는 너무 많은 혼란이 존재했기 때문입니다. 그래서 좁은 작업을 처리하기 위해 에이전트 시스템(agentic system)의 각 단계를 신중하게 설계해야 했습니다. 그러나 최근 몇 년간 AI의 자율적으로 작업하는 능력은 비약적으로 발전했으며, 특히 복잡한 작업에서도 인간 수준에 근접하거나 능가하는 사례들이 보고되고 있습니다.

에이전트 시스템(agentic system)의 초기 최첨단 사례로, 클로드(Claude)와 일련의 영리한 접근 방식을 사용하여 실제 작업을 수행할 수 있는 AI 에이전트를 만드는 마누스(Manus)를 살펴보겠습니다. 마누스 팀은 흥미로운 엔지니어링(engineering) 요소와 매우 정교한 프롬프트(prompt) 설계를 포함하여 에이전트 구축을 위한 많은 팁을 공유했습니다. 이 게시물을 작성할 당시, 저는 마누스에게 다음과 같이 요청했습니다: "최고의 그랜드마스터(grandmaster) ELO와 최초의 현대 체스 컴퓨터부터 2025년까지 세계 최고의 체스 컴퓨터 ELO를 비교하는 매력적인 그래프가 필요합니다." 시스템은 이 요청에 따라 작업을 시작했습니다. 마누스는 항상 할 일 목록(to-do list)을 만들고, 데이터를 수집하여 여러 파일을 작성했으며, 몇 가지 사소한 조정 후에 마침내 특정 형식의 그래프를 생성했습니다. 이 에이전트가 이런 순서로 작업을 수행한 이유는, 마누스가 수작업으로 구축되었고, 사용 가능한 최고의 범용 에이전트(general purpose agent)가 되도록 신중하게 제작되었기 때문입니다. 할 일 목록을 만드는 방법에 대한 자세한 지침을 포함하여, 시스템 프롬프트(system prompt)에는 수백 줄의 맞춤형 텍스트가 포함되어 있었습니다. 이는 당시의 AI 시스템과 에이전트를 작동시키는 방법에 대한 어렵게 얻은 지식을 통합한 결과였습니다.

잠재적인 문제가 보이시나요? '신중하게 제작된', '맞춤형', '어렵게 얻은 지식 통합' — 이는 쓴 교훈(Bitter Lesson)이 우리에게 피하라고 말하는 바로 그 종류의 작업입니다. 결국 더 범용적인 기술에 의해 그 가치가 퇴색될 것이기 때문입니다.

최근 OpenAI의 강화 학습 기반 에이전트(reinforcement learning-based agent) 출시로 이러한 쓴 교훈의 강력한 증거가 더욱 명확해지고 있습니다. 이 에이전트들은 작업 수행 과정에 대해 직접적으로 훈련되지 않았습니다. 대신, OpenAI는 실제 최종 결과물(outcome)에 대해 AI를 훈련시키기 위해 강화 학습(reinforcement learning)을 사용했습니다. 예를 들어, 인간이 엑셀 파일(Excel file)을 만드는 방식을 가르치지 않고, AI가 개발하는 어떤 방법을 사용하든 좋은 파일을 만들도록 학습할 때까지 AI가 생성하는 엑셀 파일의 품질을 단순히 평가하는 방식입니다. 강화 학습(reinforcement learning)과 수작업 제작이 어떻게 유사한 결과로 이어질 수 있는지 보여주기 위해, 저자는 이러한 에이전트에게도 동일한 체스 관련 요청을 주었고, 그 결과 역시 만족스러운 그래프를 얻을 수 있었습니다. 하지만 이번에는 할 일 목록(to-do list)도, 따라야 할 스크립트(script)도 없었습니다. 대신 에이전트는 훈련에 따라 저에게 가능한 최고의 결과물을 제공하기 위해 필요한 어떤 신비로운 경로든 찾아냈습니다.

두 에이전트가 생성한 차트(chart) 사이에는 외형 외에도 몇 가지 중요한 차이점을 발견할 수 있습니다. 예를 들어, 딥 블루(Deep Blue)의 ELO는 공식적으로 측정된 적이 없기 때문에, 각 에이전트는 딥 블루의 성능에 대해 다른 평가를 제시했습니다. 마누스의 평가는 기본적인 검색을 기반으로 했으며, 추측성 레딧(Reddit) 토론과 같은 출처를 발견했습니다. 반면, 강화 학습(reinforcement learning) 접근 방식으로 훈련된 OpenAI 에이전트는 주장을 뒷받침하기 위해 애틀랜틱(Atlantic) 기사를 포함한 더 신뢰할 수 있는 출처를 찾아냈습니다. 마찬가지로, 두 에이전트에게 완전히 작동하는 엑셀 파일(Excel file)을 만들어 그래프를 재현해달라고 요청했을 때, OpenAI 에이전트의 버전은 작동했지만 마누스의 버전에는 오류가 있었습니다. 현재 OpenAI의 에이전트가 마누스보다 절대적으로 우월하다고 단정하기는 어렵지만, 경쟁자보다 훨씬 더 빠르게 발전할 가능성이 높다고 생각합니다. 마누스를 개선하려면 더 신중한 제작과 맞춤형 작업이 필요하지만, OpenAI의 에이전트를 개선하려면 단순히 더 많은 컴퓨터 칩(computer chip)과 더 많은 예시가 필요합니다. 쓴 교훈(Bitter Lesson)이 유효하다면, 장기적인 결과는 꽤 명확해 보입니다. 하지만 더 중요하게는, 수작업으로 제작된 에이전트와 결과물 기반으로 훈련된 에이전트 간의 비교는 조직이 AI 도입에 어떻게 접근해야 하는지에 대한 근본적인 질문을 제기합니다.

**쓰레기통 속의 에이전트(Agents in the Garbage Can)**

이것은 우리를 다시 조직의 복잡한 세계로 데려옵니다. 개인들이 AI를 빠르게 채택하는 동안에도, 많은 기업들은 여전히 쓰레기통 문제(Garbage Can problem)로 고심하며, 어떤 AI 시스템을 배포하기 전에 혼란스러운 프로세스를 매핑(mapping)하는 데 엄청난 시간과 자원을 소모합니다. 하지만 이러한 접근 방식이 근본적으로 잘못된 것이라면 어떨까요? 쓴 교훈(Bitter Lesson)은 기업이 결과물을 생산하는 '방식'을 무시하고, '결과물 자체'에만 집중할 수도 있음을 강력히 시사합니다. 좋은 판매 보고서나 고객 상호작용이 어떤 모습인지 명확히 정의한 다음, AI가 그것을 생산하도록 훈련시키기만 하면 됩니다. AI는 조직의 혼돈 속에서 자신만의 최적화된 경로를 찾아낼 것입니다. 이 경로는 인간이 발전시킨 반공식적인 경로보다 훨씬 더 불투명할 수 있지만, 동시에 훨씬 더 효율적일 수도 있습니다.

쓴 교훈(Bitter Lesson)이 지배하는 세상에서는, 조직의 복잡한 현실을 마주하고 머리를 테이블에 묻고 절망하는 CEO의 모습은 더 이상 적절하지 않습니다. 모든 망가진 프로세스를 하나하나 풀어내려 하기보다, 그는 성공의 기준을 명확히 정의하고 AI가 그 혼란을 헤쳐나가도록 내버려 두기만 하면 됩니다. 사실, 쓴 교훈(Bitter Lesson)은 실제로는 '달콤한 교훈'이 될 수도 있습니다. 조직에 만연한 모든 문서화되지 않은 워크플로우(workflow)와 비공식 네트워크(network)는 생각보다 중요하지 않을 수도 있습니다. 중요한 것은 좋은 결과물을 보았을 때 그것을 알아볼 수 있는 능력입니다. 이것이 사실이라면, 쓰레기통은 여전히 존재하겠지만, 경쟁 우위(competitive advantage) 자체가 재정의되는 동안 우리가 그것을 일일이 분류할 필요는 더 이상 없을 것입니다. 기업들이 프로세스를 개선하고, 제도적 지식(institutional knowledge)을 구축하며, 운영 우수성(operational excellence)을 통해 경쟁 해자(competitive moat)를 만드는 데 들인 노력은 그들이 생각하는 것보다 덜 중요할 수 있습니다. 만약 AI 에이전트(agent)가 결과물만으로 훈련할 수 있다면, 품질을 정의하고 충분한 예시를 제공할 수 있는 어떤 조직이든, 자신들의 프로세스를 이해하든 못하든 유사한 결과를 달성할 수 있을 것입니다. 하지만 다른 한편으로는, 쓰레기통 모델이 결국 승리하여, 인간의 복잡성과 그 혼란스럽고 진화된 프로세스들이 AI가 이해하지 않고는 헤쳐나가기에는 너무 복잡할 수도 있습니다. 우리는 조직이 실제로 어떤 종류의 문제인지 곧 알게 될 것입니다. 즉, 컴퓨팅 규모(computational scale)에 굴복하는 체스 게임과 같은 것인지, 아니면 근본적으로 더 혼란스러운 것인지 말입니다. 어떤 답에 베팅하든 기업들은 이미 빠르게 움직이고 있으며, 우리는 우리가 실제로 어떤 게임을 하고 있는지 곧 알게 될 것입니다.

2025년, AI 기술의 발전 속도는 예상보다 훨씬 빠릅니다. 특히, 멀티모달(multimodal) 능력과 복잡한 추론(complex reasoning) 기능을 갖춘 에이전트의 등장은 '쓰레기통 모델'의 혼돈 속에서도 예측 불가능한 효율성과 혁신을 가져올 잠재력을 보여주고 있습니다. 이제 기업의 리더들은 단순히 기술을 도입하는 것을 넘어, AI가 조직의 본질적인 목표 달성에 어떻게 기여할 수 있을지, 그리고 그 과정에서 인간의 역할이 어떻게 재정의될지에 대한 근본적인 질문을 던져야 할 시점입니다.