**조직의 혼돈과 AI: 쓴 교훈이 선사할 달콤한 미래**

조직에 관한 제가 가장 좋아하는 학술 논문 중 하나는 루탄 후이싱(Ruthanne Huising)의 논문입니다. 이 논문은 원자재부터 완제품에 이르기까지 조직이 실제로 수행하는 작업을 추적하여 회사의 프로세스 맵(process map)을 만들도록 배정된 팀들의 이야기를 다룹니다. 이 맵을 만들면서 그들은 작업의 상당 부분이 얼마나 이상하고 계획되지 않은 것처럼 보이는지 깨달았습니다. 그들은 아무도 사용하지 않는 결과물을 생산하는 전체 프로세스, 일을 처리하는 이상한 반공식적 경로, 그리고 반복적인 노력의 중복을 발견했습니다. 맵 작업을 하던 직원들 중 상당수는 한때 회사의 떠오르는 별이었지만 환멸을 느끼게 되었습니다.

이러한 조직 내부의 혼돈은 디지털 전환(digital transformation) 시대에 AI 도입을 가로막는 주요 장애물이 됩니다. 많은 기업이 AI 기술의 잠재력을 인식하고 있지만, 실제 업무 프로세스가 명확하게 정의되어 있지 않거나 비공식적인 방식으로 운영되는 경우가 많아 AI 시스템을 통합하는 데 어려움을 겪습니다. 최근 설문 조사에 따르면, 기업의 AI 도입 실패 원인 중 상당수가 '내부 프로세스의 복잡성'과 '데이터의 비정형성'으로 지목되고 있습니다. 이는 단순히 기술적인 문제가 아니라, 조직의 근본적인 운영 방식과 AI 간의 불일치에서 비롯됩니다.

**프로세스 맵(The Process Map)**
후이싱 교수님이 다음에 무슨 일이 일어났는지 설명하도록 하겠습니다: "일부 사람들은 최고 경영진 중 한두 명이 이러한 설계 및 운영 문제를 알고 있을 것이라는 희망을 품었지만, 그들은 종종 이러한 낙관주의에서 벗어나게 되었습니다. 예를 들어, 한 관리자가 CEO에게 맵을 설명하면서 그가 이전에 본 적 없는 관점을 제시하고, 설계의 부재와 전략 및 운영 간의 단절을 보여주었습니다. CEO는 맵 설명을 들은 후 자리에 앉아 머리를 테이블에 묻고 말했습니다. '이건 내가 상상했던 것보다 훨씬 더 엉망진창이군.' CEO는 자신의 조직 운영이 통제 불능일 뿐만 아니라, 그것에 대한 자신의 이해가 상상에 불과했음을 드러냈습니다."

많은 사람들에게 이것은 놀라운 일이 아닐 수도 있습니다. 조직을 연구하거나(또는 조직에서 일하면서) 배우는 한 가지는, 조직들이 실제로는 모두 다소 혼란스럽다는 것입니다. 사실, 고전적인 조직 이론 중 하나는 실제로 '쓰레기통 모델(Garbage Can Model)'이라고 불립니다. 이 모델은 조직을 문제, 해결책, 의사결정자가 함께 뒤섞여 있는 혼란스러운 "쓰레기통"으로 간주하며, 의사결정은 완전히 합리적인 과정을 통해서라기보다는 이러한 요소들이 무작위로 충돌할 때 종종 발생한다고 봅니다. 물론, 이러한 관점을 너무 극단적으로 받아들이기 쉽습니다. 조직에는 실제로 중요한 구조, 의사결정자, 프로세스가 존재합니다. 다만 이러한 구조는 신중하게 설계되고 잘 기록되기보다는, 종종 사람들과의 협상과 진화를 통해 형성되었다는 점입니다. 쓰레기통 모델은 불문율, 맞춤형 지식, 복잡하고 문서화되지 않은 프로세스가 중요한 세상을 나타냅니다.

이러한 쓰레기통 모델은 조직이 디지털 전환을 추진할 때 표면화되는 많은 문제의 근원입니다. 이상적인 프로세스 흐름도와 실제 업무 방식 사이의 괴리는 흔히 발견됩니다. 예를 들어, 고객 불만 처리 시스템을 디지털화하려고 할 때, 공식적인 절차 외에 특정 담당자에게 직접 연락하거나, 비공식적인 채널을 통해 문제를 해결하는 '숨겨진' 프로세스가 존재할 수 있습니다. 이러한 비공식적 경로들은 종종 조직의 효율성을 유지하는 데 중요한 역할을 하지만, 동시에 자동화와 표준화를 어렵게 만듭니다. 결과적으로, 많은 조직은 명확한 규칙과 정의된 프로세스를 요구하는 전통적인 자동화 및 AI 솔루션 도입에 좌절을 경험하게 됩니다. 이는 단순히 기술을 적용하는 문제가 아니라, 조직의 본질적인 혼돈을 어떻게 이해하고 대응할 것인가에 대한 근본적인 질문으로 이어집니다.

하지만 AI 연구자들은 이러한 종류의 가정에 대해 중요한 것을 배웠습니다.

**쓴 교훈(The Bitter Lesson)**
컴퓨터 과학자 리처드 서튼(Richard Sutton)은 2019년 영향력 있는 에세이에서 AI 연구의 한 패턴을 지적하며 쓴 교훈(Bitter Lesson)이라는 개념을 소개했습니다. 체스에서 인간을 이기는 것과 같은 어려운 문제를 해결하려는 AI 연구자들은 오프닝 수, 위치 평가, 전술 패턴, 엔드게임 데이터베이스(endgame database) 등을 연구하며 우아한 해결책을 반복적으로 모색했습니다. 프로그래머들은 수 세기 동안의 체스 지혜를 수작업으로 만든 소프트웨어에 인코딩했습니다: 중앙을 장악하고, 기물을 일찍 전개하며, 킹의 안전이 중요하고, 통과한 폰(passed pawn)은 가치가 있다는 등. 세계 최고의 인간을 이긴 최초의 체스 컴퓨터인 딥 블루(Deep Blue)는 일부 체스 지식을 사용했지만, 초당 2억 개의 위치를 탐색할 수 있는 무차별 대입(brute force) 방식과 결합했습니다. 2017년 구글은 체스뿐만 아니라 쇼기(shogi)와 바둑에서도 인간을 이길 수 있는 알파제로(AlphaZero)를 출시했으며, 이 모델은 이 게임들에 대한 사전 지식이 전혀 없이 이를 해냈습니다. 대신, AI 모델은 스스로 대결하며 게임을 학습할 때까지 플레이했습니다. 체스의 모든 우아한 지식은 무의미했으며, 순수한 무차별 대입 컴퓨팅(brute force computing)과 머신러닝(machine learning)의 일반화된 접근 방식이 결합된 것만으로도 그들을 이기기에 충분했습니다.

그리고 그것이 바로 쓴 교훈(Bitter Lesson)입니다. 인간의 이해를 AI에 인코딩하는 것은 AI가 문제를 해결하는 방법을 스스로 알아내도록 하고, 어떤 인간보다 더 잘할 수 있을 때까지 충분한 컴퓨팅 파워(computing power)를 추가하는 것보다 나쁜 경향이 있습니다.

이 쓴 교훈은 체스나 바둑과 같은 보드 게임을 넘어 다양한 AI 분야에서 반복적으로 관찰되었습니다. 예를 들어, 단백질 접힘(protein folding) 문제를 해결하는 데 있어서도, 과학자들이 수십 년간 축적한 생물학적 지식을 직접 모델링하려는 시도보다는, 방대한 데이터를 기반으로 스스로 패턴을 학습한 알파폴드(AlphaFold)와 같은 AI가 훨씬 뛰어난 성능을 보였습니다. 대규모 언어 모델(LLM) 역시 인간이 언어의 규칙을 명시적으로 코딩하는 대신, 엄청난 양의 텍스트 데이터로부터 언어 구조와 의미를 스스로 학습하여 놀라운 능력을 발휘하고 있습니다. 이러한 사례들은 인간의 직관이나 전문가 지식이 특정 문제 해결에 반드시 필요한 것은 아니며, 때로는 방대한 데이터와 컴퓨팅 자원을 활용한 일반화된 학습 방식이 더 효과적일 수 있음을 시사합니다.

이러한 맥락에서, 쓴 교훈은 AI 개발과 배포에 있어서 인간의 역할에 대한 중요한 질문을 던집니다. 인간의 전문 지식이 더 이상 AI 시스템의 핵심 구성 요소가 아니라면, 인간은 무엇을 해야 할까요? 이는 인간 전문가의 역할이 '해결책을 직접 코딩하는 것'에서 '문제를 명확히 정의하고, AI가 학습할 수 있는 환경과 데이터를 제공하며, AI의 결과물을 평가하고 개선하는 것'으로 변화해야 함을 의미합니다. 즉, AI가 스스로 답을 찾도록 돕는 조력자이자 감독자의 역할이 더욱 중요해지는 것입니다.

**에이전트(Agents): 복잡한 업무 환경 속에서**
개인이 챗봇(chatbot)을 사용하는 것만으로도 많은 이점을 얻을 수 있지만, 조직에서 AI를 사용하는 방법에 대한 많은 관심은 에이전트(agent)에 집중되어 있습니다. 에이전트는 제가 '목표 달성을 위해 자율적인 행동을 취할 수 있는 AI 시스템'이라고 정의하는 모호한 용어입니다. 프롬프트(prompt)로 챗봇을 안내하는 것과 달리, 에이전트에게 작업을 위임하면 에이전트가 이를 수행합니다. 하지만 이전 AI 시스템들은 조직의 모든 요구 사항을 처리하기에 충분히 좋지 않았습니다. 현실 세계에는 너무 많은 혼란이 존재합니다. 이것이 바로 1년 전 우리가 첫 AI 기반 교육 게임을 만들었을 때, 좁은 작업을 처리하기 위해 에이전트 시스템(agentic system)의 각 단계를 신중하게 설계해야 했던 이유입니다. 그리고 AI의 자율적으로 작업하는 능력은 매우 빠르게 증가하고 있지만, 대부분의 복잡한 작업에서는 여전히 인간 수준에 훨씬 못 미치며, 복잡한 작업에서는 쉽게 잘못된 길로 빠질 수 있습니다. 이는 80%의 성공률을 기준으로 합니다.

에이전트 시스템(agentic system)의 최첨단 사례로, 클로드(Claude)와 일련의 영리한 접근 방식을 사용하여 실제 작업을 수행할 수 있는 AI 에이전트를 만드는 마누스(Manus)를 살펴보겠습니다. 마누스 팀은 흥미로운 엔지니어링(engineering) 요소와 매우 정교한 프롬프트(prompt) 설계를 포함하여 에이전트 구축을 위한 많은 팁을 공유했습니다. 이 게시물을 작성할 때, 저는 마누스에게 다음과 같이 요청했습니다: "최고의 그랜드마스터(grandmaster) ELO와 최초의 현대 체스 컴퓨터부터 2025년까지 세계 최고의 체스 컴퓨터 ELO를 비교하는 매력적인 그래프가 필요합니다." 그리고 시스템은 작업을 시작했습니다. 먼저, 마누스는 항상 할 일 목록(to-do list)을 만들고, 데이터를 수집하여 여러 파일을 작성했으며, 제가 요청한 몇 가지 사소한 조정 후에 마침내 위 왼쪽에서 볼 수 있는 그래프(그래프 주위에 상자가 없는 것)를 만들어냈습니다. 왜 이런 순서로 작업을 했을까요? 마누스는 수작업으로 구축되었고, 사용 가능한 최고의 범용 에이전트(general purpose agent)가 되도록 신중하게 제작되었기 때문입니다. 할 일 목록을 만드는 방법에 대한 자세한 지침을 포함하여, 시스템 프롬프트(system prompt)에는 수백 줄의 맞춤형 텍스트가 있습니다. 이는 오늘날의 AI 시스템과 에이전트를 작동시키는 방법에 대한 어렵게 얻은 지식을 통합합니다.

잠재적인 문제가 보이시나요? "신중하게 제작된", "맞춤형", "어렵게 얻은 지식 통합" — 이는 쓴 교훈(Bitter Lesson)이 우리에게 피하라고 말하는 바로 그 종류의 작업입니다. 왜냐하면 결국 더 범용적인 기술에 의해 무의미해질 것이기 때문입니다.

최근 챗GPT 에이전트(ChatGPT agent)의 출시로 이것이 가능할 수 있다는 증거가 나타났습니다 (영감을 주지 않는 이름이지만, 적어도 명확하며 OpenAI에게는 큰 진전입니다!). 챗GPT 에이전트는 근본적인 변화를 나타냅니다. 이것은 작업 수행 과정에 대해 훈련되지 않았습니다. 대신, OpenAI는 실제 최종 결과물(outcome)에 대해 AI를 훈련시키기 위해 강화 학습(reinforcement learning)을 사용했습니다. 예를 들어, 인간이 엑셀 파일(Excel file)을 만드는 방식을 가르치지 않고, AI가 개발하는 어떤 방법을 사용하든 좋은 파일을 만들도록 학습할 때까지 AI가 생성하는 엑셀 파일의 품질을 단순히 평가할 것입니다. 강화 학습(reinforcement learning)과 신중한 제작이 어떻게 유사한 결과로 이어지는지 보여주기 위해, 저는 챗GPT 에이전트(ChatGPT agent)에게 정확히 동일한 체스 프롬프트(prompt)를 주었고 위 오른쪽 그래프를 얻었습니다. 하지만 이번에는 할 일 목록(to-do list)도, 따라야 할 스크립트(script)도 없었습니다. 대신 에이전트는 훈련에 따라 저에게 가능한 최고의 결과물을 제공하기 위해 필요한 어떤 신비로운 경로든 찾아냈습니다. 아래에서 그 일부를 볼 수 있습니다:

하지만 외형 외에도 두 차트(chart) 사이에 몇 가지 차이점을 발견할 수 있을 것입니다. 예를 들어, 딥 블루(Deep Blue)의 ELO는 공식적으로 측정된 적이 없기 때문에 각각 딥 블루의 성능에 대한 다른 평가를 가지고 있습니다. 마누스의 평가는 기본적인 검색을 기반으로 했으며, 우리는 추측성 레딧(Reddit) 토론을 발견했습니다. 반면 딥 리서치(Deep Research)에서 사용된 강화 학습(reinforcement learning) 접근 방식으로 훈련된 챗GPT 에이전트(ChatGPT agent)는 주장을 뒷받침하기 위해 애틀랜틱(Atlantic) 기사를 포함한 더 신뢰할 수 있는 출처를 찾아냈습니다. 마찬가지로, 두 에이전트에게 완전히 작동하는 엑셀 파일(Excel file)을 만들어 그래프를 재현해달라고 요청했을 때, 챗GPT의 버전은 작동했지만 마누스의 버전에는 오류가 있었습니다. 챗GPT 에이전트가 마누스보다 더 나은지는 아직 모르겠지만, 경쟁자보다 훨씬 더 빠르게 발전할 가능성이 높다고 생각합니다. 마누스를 개선하려면 더 신중한 제작과 맞춤형 작업이 필요하지만, 챗GPT 에이전트를 개선하려면 단순히 더 많은 컴퓨터 칩(computer chip)과 더 많은 예시가 필요합니다. 쓴 교훈(Bitter Lesson)이 유효하다면, 장기적인 결과는 꽤 명확해 보입니다. 하지만 더 중요하게는, 수작업으로 제작된 에이전트와 결과물 기반으로 훈련된 에이전트 간의 비교는 조직이 AI 도입에 어떻게 접근해야 하는지에 대한 근본적인 질문을 제기합니다.

최근에는 단일 에이전트를 넘어 여러 에이전트가 협력하여 복잡한 목표를 달성하는 '멀티 에이전트 시스템(multi-agent system)'에 대한 관심이 급증하고 있습니다. 이 시스템들은 마치 작은 팀처럼 각자의 전문성을 가진 AI 에이전트들이 서로 소통하고 작업을 분담하며 목표를 향해 나아갑니다. 예를 들어, 고객 서비스 시나리오를 생각해 봅시다. 과거에는 고객 서비스 챗봇이 FAQ 답변이나 간단한 예약 변경에 그쳤습니다. 그러나 멀티 에이전트 시스템에서는 '고객 지원 에이전트'가 고객의 초기 문의를 응대하고, 필요한 경우 '기술 지원 에이전트'에게 문제를 에스컬레이션하며, '영업 에이전트'와 협력하여 관련 제품 정보를 제공하거나 업셀링(upselling) 기회를 모색할 수 있습니다. 이 과정에서 각 에이전트는 정해진 규칙에 따라 움직이기보다는, 주어진 목표(예: 고객 만족도 극대화)를 달성하기 위해 상황에 맞춰 자율적으로 행동하고 다른 에이전트와 정보를 교환합니다.

이러한 멀티 에이전트 시스템은 '쓰레기통 모델'의 조직 환경에서 특히 강력한 잠재력을 가집니다. 명확하게 정의되지 않은 비공식적 경로가 많은 조직에서, 인간이 모든 프로세스를 설계하고 자동화하는 것은 거의 불가능합니다. 하지만 멀티 에이전트 시스템은 최종 결과물에 대한 명확한 목표만 주어지면, 내부의 복잡하고 혼란스러운 상황 속에서 스스로 최적의 경로를 탐색하고 협업할 수 있습니다. 예를 들어, 신제품 출시 준비 과정을 생각해 보세요. 마케팅 자료 준비, 법적 검토, 생산 일정 조율, 유통망 확보 등 수많은 부서와 비공식적 소통이 필요한 작업입니다. 만약 각 부서의 목표를 이해하고 조율할 수 있는 AI 에이전트들이 있다면, 이들은 인간의 개입 없이도 데이터를 수집하고, 병목 현상을 식별하며, 최적의 출시 일정을 제안할 수 있을 것입니다.

물론, 이러한 결과물 기반의 AI 에이전트 훈련 방식에는 도전 과제도 존재합니다. 무엇보다 '좋은 결과물'을 어떻게 정의하고 측정할 것인가가 중요합니다. 고객 만족도, 판매량, 효율성 증대 등 구체적이고 정량적인 지표가 필요하며, 이러한 지표를 바탕으로 AI를 지속적으로 평가하고 개선하는 피드백 루프(feedback loop)가 필수적입니다. 또한, AI가 자율적으로 내린 결정이 윤리적, 법적 문제를 야기하지 않도록 적절한 가이드라인과 인간 감독이 필요합니다. AI의 '블랙박스(black box)' 특성으로 인해 의사결정 과정을 이해하기 어렵다는 점도 중요한 고려 사항입니다.

**쓰레기통 속의 에이전트(Agents in the Garbage Can)**
이것은 우리를 조직의 세계로 다시 데려옵니다. 개인들이 AI를 빠르게 채택하는 동안에도, 기업들은 여전히 쓰레기통 문제(Garbage Can problem)로 고심하며, 어떤 AI 시스템을 배포하기 전에 혼란스러운 프로세스를 매핑(mapping)하는 데 몇 달을 보냅니다. 하지만 그것이 거꾸로 된 것이라면 어떨까요? 쓴 교훈(Bitter Lesson)은 우리가 곧 기업이 결과물을 생산하는 방식을 무시하고 결과물 자체에만 집중할 수도 있음을 시사합니다. 좋은 판매 보고서나 고객 상호작용이 어떤 모습인지 정의한 다음, AI가 그것을 생산하도록 훈련시키세요. AI는 조직의 혼돈 속에서 자신만의 경로를 찾을 것입니다. 이 경로는 인간이 발전시킨 반공식적인 경로보다 더 불투명할 수 있지만, 더 효율적일 수도 있습니다.

쓴 교훈(Bitter Lesson)이 유효한 세상에서는, 머리를 테이블에 묻고 절망하는 CEO의 모습은 부적절합니다. 모든 망가진 프로세스를 풀어내려 하기보다, 그는 성공을 정의하고 AI가 혼란을 헤쳐나가도록 내버려 두기만 하면 됩니다. 사실, 쓴 교훈(Bitter Lesson)은 실제로는 달콤할 수도 있습니다. 조직에 만연한 모든 문서화되지 않은 워크플로우(workflow)와 비공식 네트워크(network)는 중요하지 않을 수도 있습니다. 중요한 것은 좋은 결과물을 보았을 때 그것을 알아볼 수 있는 것입니다. 이것이 사실이라면, 쓰레기통은 여전히 존재하지만, 경쟁 우위(competitive advantage) 자체가 재정의되는 동안 우리가 그것을 일일이 분류할 필요는 더 이상 없습니다. 기업들이 프로세스를 개선하고, 제도적 지식(institutional knowledge)을 구축하며, 운영 우수성(operational excellence)을 통해 경쟁 해자(competitive moat)를 만드는 데 들인 노력은 그들이 생각하는 것보다 덜 중요할 수 있습니다. 만약 AI 에이전트(agent)가 결과물만으로 훈련할 수 있다면, 품질을 정의하고 충분한 예시를 제공할 수 있는 어떤 조직이든, 자신들의 프로세스를 이해하든 못하든 유사한 결과를 달성할 수 있을 것입니다. 아니면 쓰레기통 모델이 승리하여, 인간의 복잡성과 그 혼란스럽고 진화된 프로세스들이 AI가 이해하지 않고는 헤쳐나가기에는 너무 복잡할 수도 있습니다. 우리는 조직이 실제로 어떤 종류의 문제인지 곧 알게 될 것입니다. 즉, 컴퓨팅 규모(computational scale)에 굴복하는 체스 게임과 같은 것인지, 아니면 근본적으로 더 혼란스러운 것인지 말입니다. 어떤 답에 베팅하든 기업들은 이미 움직이고 있으며, 우리는 우리가 실제로 어떤 게임을 하고 있는지 곧 알게 될 것입니다.

결론적으로, 조직의 혼돈과 AI의 쓴 교훈은 상호 보완적인 관계에 있습니다. 조직의 비공식적인 복잡성을 수동으로 해체하려는 노력이 좌절될 때, 결과물 중심의 AI 접근 방식은 새로운 돌파구를 제공할 수 있습니다. 이는 단순히 기술적 혁신을 넘어, 조직이 가치를 창출하는 방식과 경쟁 우위를 정의하는 패러다임을 근본적으로 변화시킬 잠재력을 가집니다. 중요한 것은 AI가 조직의 '쓰레기통'을 완벽하게 정리하는 것이 아니라, 그 혼돈 속에서도 최적의 경로를 찾아내어 목표를 달성하도록 돕는 것입니다. 이러한 변화를 성공적으로 이끌기 위해서는 명확한 목표 설정, 풍부한 데이터 제공, 그리고 AI의 자율성을 존중하면서도 필요한 통제와 피드백을 제공하는 인간의 역할 재정립이 필수적입니다. 조직은 이제 '어떻게' 일을 하는지에 대한 집착에서 벗어나, '무엇을' 달성할 것인지에 집중해야 할 때입니다.

구독 공유