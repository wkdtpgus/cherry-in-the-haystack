# **대부분의 AI 연구를 신뢰할 수 없는 이유**

Author: Alberto Romero
URL: https://www.thealgorithmicbridge.com/p/why-you-cant-trust-most-ai-studies

============================================================

8월 18일. 생성형 AI에 대한 새로운 MIT 보고서가 발표되었다. 결론은: 생성형 AI 파일럿 프로젝트의 95%가 실패한다는 것이다. 모두가 이 소식을 공유한다. "생성형 AI는 망했어"라고 누군가 말한다. "그럴 줄 알았어! ChatGPT는 숫자도 제대로 더할 줄 모르잖아"라고 다른 사람이 말한다. "결국엔 인간이 승리하는 법이지"라고 세 번째 사람이 말한다. 10월 28일. 생성형 AI에 대한 새로운 와튼(Wharton) 보고서가 발표되었다. 결론은: 기업의 75%가 이미 생성형 AI에서 긍정적인 투자 수익률(ROI)을 보고 있다는 것이다. 모두가 이 소식을 공유한다. "이건 꽤 큰일이야"라고 누군가 말한다. "그리고 이건 시작에 불과해!"라고 다른 사람이 말한다. "AI를 사용하지 않으면 살아남지 못할 거야..."라고 세 번째 사람이 말한다. 나는 두 보고서를 모두 읽었다. 둘 다 언뜻 보기에는 괜찮아 보인다. 도대체 무슨 일일까? 각각 포춘(Fortune)과 월스트리트 저널(Wall Street Journal)의 헤드라인이다 (어조와 표현이 얼마나 다른지 재미있다!).

**AI를 둘러싼 정보의 질은 형편없다**
이 두 보고서에 대해 자세히 설명하기 전에, 세 가지를 명심해야 한다:

**하나의 연구에만 의존하는 사람을 경계하라**: 동료 심사(peer review)를 통과하고, 권위 있는 학술지에 게재되며, 심지어 대중문화에까지 침투한 (예: 밀그램의 복종 실험과 지연된 만족에 대한 마시멜로 테스트) 성숙한 학문 분야(예: 의학 또는 사회 심리학)의 연구들이 복제 불가능하거나 그 결과가 심하게 논란이 되는 경우가 얼마나 많은지 알게 되면 놀랄 것이다. 더 나쁜 경우도 있다: 실제 사실과 정반대의 결과를 처음부터 발견한 연구들 (이를 '반전(reversal)'이라고 한다).

**AI는 전시 상태이며, 이는 서사(narrative) > 진실(truth)을 의미한다**: 지금 이 시점에 AI에 대해 듣는 모든 것 (위선자가 되지 말자면, 이 블로그 게시물조차 포함하여)은 AI가 인기가 많고, 많은 돈이 걸려 있으며, 결과가 어떻게 될지 불확실하다는 사실에 의해 어느 정도 편향되어 있다. 나는 나의 접근 방식에서 정직하려고 노력한다—글쓰기로 버는 돈 외에는 걸린 돈이 전혀 없으며, 이는 정직함에 달려 있다!—하지만 편향이 우리 모두에게 영향을 미친다는 것을 부정할 수는 없다.

**극단이 대화를 주도한다**: 위 내용의 필연적인 결과이다. AI에 대한 당신의 견해가 온건하다면, 더 대담한 (또는 뻔뻔한) 사람이 약간의 과장을 더하는 것만으로 당신의 몫을 차지할 것이다. 그리고 또 다른 사람이 조금 더 과장하여 그들의 몫을 차지할 것이다. 이런 식으로 계속된다. 궁극적인 상황 (이미 일어나고 있음을 깨달을 것이다)은 가장 시끄럽고 뻔뻔한 사람들이 견해 분포의 극단에 모인다는 것이다: 극단적인 반(反)AI와 극단적인 친(親)AI.

위에서 언급한 두 AI 보고서에 대해 이것이 무엇을 의미하는지 설명하겠다: 진실은 "AI는 전혀 작동하지 않으니 없애버리자" (너무 비관적)와 "AI는 너무 잘 작동해서 기다리는 기업들을 망하게 할 것이다" (너무 낙관적) 사이 어딘가에 있을 가능성이 높다. 그러나 진실이 아마도 그 중간에 있는 이유는 "양비론(bothsidesism)" 때문이 아니다; 진실은 양쪽을 조금씩 만족시키려고 하지 않는다; 그것은 잘못된 균형을 위한 필요성 때문에 "중도적"이지 않다 (우선, 진실은 목적론적(teleological)이지 않다!). 그 이유는 전시 상태에서는 어떤 단일 연구라도 진실과 상관없이 스펙트럼의 양극단 중 하나에 속하는 경향이 있기 때문이다. 결과가 시시했다면 아무도 공유하지 않았을 것이다! (이것이 학술지들이 의도한 효과를 찾지 못한 실험을 거의 출판하지 않아 출판 편향(publication bias)을 만드는 이유이기도 하다.) 그래서 당연히 그들은 자신들의 입장과 결과를 왜곡하고 (사람들은 온라인에서 재공유할 때 이를 더욱 왜곡하는 식이다), 진실이 숨을 수 있는 중간 공간을 너무 많이 남겨둔다.

그렇다면, 각 보고서를 가능한 한 가장 불리한 시각으로 분석해 보자; 모두가 원한다고 내가 주장하는 진실을 찾기 위해서는, 어떤 이야기의 엄격함과 저항력을 시험하기 위해 동일하지만 반대되는 가치(valence)의 힘을 적용해야 한다. MIT 보고서에 대해서는 AI 옹호자, AI 애호가의 입장이 되어 볼 것이다. 와튼 보고서에 대해서는 AI 비관론자, AI 혐오자의 입장이 되어 볼 것이다. 어떤 결과가 나올지 보자.

나는 AI 과대광고와 AI 반(反)과대광고를 거의 똑같이 싫어한다 (그것들은 같은 감정적 바탕에서 나온다: "이것은 정말 정말 정말 대단해" 또는 "이것은 정말 정말 정말 끔찍해"). 하지만 나는 진실에 대한 강하고 흔들림 없는 헌신과 애착을 느낀다. 그러므로 진실이 어디에 있든, 나는 그 편에 설 것이다.

**MIT 보고서: 생성형 AI 파일럿 프로젝트의 95%가 실패한다**
이 보고서를 원래 다루었던 포춘(Fortune) 기사의 직설적인 구절을 살펴보자:

강력한 새 모델을 통합하려는 서두름에도 불구하고, AI 파일럿 프로그램의 약 5%만이 빠른 매출 증대를 달성한다; 대다수는 정체되어 손익계산서(P&L)에 측정 가능한 영향을 거의 또는 전혀 미치지 못한다. 150명의 리더 인터뷰, 350명의 직원 설문조사, 300개의 공개 AI 배포 분석을 기반으로 한 이 연구는 성공 사례와 정체된 프로젝트 사이에 명확한 구분을 보여준다. . . . 핵심 문제는? AI 모델의 품질이 아니라 도구와 조직 모두의 "학습 격차(learning gap)"이다. 경영진은 종종 규제나 모델 성능을 탓하지만, MIT의 연구는 결함 있는 기업 통합(enterprise integration)을 지적한다.

이것은 이미 헤드라인을 상당히 제한한다: 그들은 부분적으로 공개 배포 분석과 부분적으로 인터뷰를 기반으로 파일럿 프로젝트의 손익계산서(P&L)를 측정하고 있으며, 문제는 기술 자체가 아니라 통합(integration)이라고 지적한다.

내가 여기서 읽은 것: MIT 보고서는 의미를 갖기에는 너무 일찍 수행되었다. 통합이 성숙하지 않은 도입 첫해에 단기 손익계산서(P&L) 결과로 성공을 측정하는 것은 틀린 것조차 아니다! 그것은 기술이 작동하는지 여부에 대해 아무것도 알려주지 않으며, 사람들이 기존 워크플로우(workflow)에 생성형 AI를 통합하는 데 어려움을 겪고 있는지 등에 대한 것이다 (이는 문제일 수 있지만, "생성형 AI가 작동하지 않는다"는 것과는 다른 결론을 낳는다). 파일럿(pilot)의 개념은 정확히 무언가를 시도해 보고 작동하는지 확인하는 것이다. 그것은 본질적으로 실험적이며, 누구도 측정 가능한 이익을 제공할 것이라고 기대하지 않는 초기 단계의 프로토타입(prototype)이다!

나는 생성형 AI가 생산성 차트(productivity chart)에 반영되지 않고 있다는 것이 나쁜 징조임을 가장 먼저 인정한다—하지만 그것은 기술이 작동하지 않는다는 의미에서 나쁜 징조라기보다는, 우리가 아직 경제 전반에 걸쳐 그것을 횡단적으로(transversally) 구현하는 방법을 알아내지 못했다는 의미에서 나쁜 징조이다. 여기에 필연적인 결과가 있다: 파일럿 프로젝트의 손익계산서(P&L)만 측정한다면 (성공 또는 실패 사이의 이진법), 파일럿 프로젝트가 실제로 할 수 있는 것들을 측정하지 못하는 것이다. 이는 해석에 있어서 모호하고 불분명하지만, 그럼에도 불구하고 근본적이다. 얼마나 많은 시간이 절약되었는가? 오류율은 감소했는가 또는 증가했는가? 정량적이지는 않더라도 정성적으로(qualitatively) 워크플로우(workflow)가 개선되었는가?

보고서에는 두 번째 문제가 있다: 가시성 편향(visibility bias). 이 보고서는 데이터셋(dataset)에 포함될 만큼 충분히 공개된 프로젝트들을 기반으로 하는데, 이는 대부분 "우리가 무엇을 하고 있는지 보라"는 식의 홍보성 실험들로 구성되어 있으며, 이 단계에서는 눈에 띄지 않아 거의 추구되지 않는 지루하고 흥미롭지 않은 자동화(automation)와는 대조적이다 (어쩌면 어느 정도 추구되지만 작동하지 않는 것일 수도 있지만, 보고서는 이에 대해 어떤 언급도 하지 않는다!). AI 파일럿 프로젝트의 95% 실패율은 "기업 연극(corporate theater)"이라고 충실하게 묘사될 수 있는 것이 95%의 확률로 실패한다는 것을 말해주는 것일 수도 있다. 음, 알겠다, 우리는 이미 그것을 알고 있었다.

MIT 보고서는 쓸모없는가? 전혀 그렇지 않다! 그것은 사람들이 측정한다고 생각했던 것과는 다른 것을 측정하고 있을 뿐이다. 그것은 기업들이 영향을 측정하는 방식 (파일럿 프로젝트의 손익계산서(P&L)로, 정말?)과 생성형 AI를 미시적(micro scale) 수준에서 세상에 통합하는 것이 얼마나 어려울 수 있는지에 대한 경고이다. 그게 전부다. 내가 불친절하다면, 그것은 기업의 조급함(corporate impatience)을 완벽하게 측정하는 척도라고 간단히 말할 것이다.

오늘 마감!! 상식과 인간적인 측면에 초점을 맞춘 AI의 모든 것에 대한 독점 콘텐츠와 심층 보도를 이용하려면 구독하세요. 과대광고도, 판매도, 비관론도 없습니다. 오직 냉철한 견해만 허용됩니다!

11월 3일 (월요일)까지 무료 구독자를 대상으로 33% 할인된 할로윈 세일을 진행합니다. 2026년까지는 다시 제공하지 않을 예정이니, 할인된 가격으로 꼭 구매하세요. 표준 월간 구독도 가능합니다.

할인 받기

**와튼 보고서: 기업의 75%가 긍정적인 투자 수익률(ROI)을 본다**
와튼 보고서는 MIT 보고서보다 풀기가 더 까다롭고, 우리가 그렇게 하는 것이 더 중요하다. 한 가지 간단한 이유 때문이다: MIT 보고서와는 달리, 와튼 보고서는 긍정적인 발견을 제시한다—즉, 작동한다는 것이다! 그러니 AI 회의론자 모자를 쓰고 방금 했던 것과 똑같이 더 세심하게 분석해 보자.