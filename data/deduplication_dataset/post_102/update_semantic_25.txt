팔월 십팔일, 매사추세츠 공과대학교(MIT)에서 인공지능 관련 최신 연구 결과가 공개되었다. 주요 내용은 생성형 인공지능 시범 사업 중 대다수인 95퍼센트가 성공에 이르지 못한다는 점이었다. 이 소식이 널리 퍼지자, 사람들은 "생성형 AI는 기대 이하다"라거나 "챗GPT가 기본적인 연산조차 제대로 못 하니 당연한 결과"라며 비관적인 반응을 보였고, 일부는 "결국 인간의 지능이 우세하다"는 의견을 내놓았다.

시월 이십팔일, 와튼 스쿨(Wharton School)에서 인공지능 기술의 기업 활용에 대한 새로운 분석 보고서가 나왔다. 보고서의 핵심은 기업 중 4분의 3에 해당하는 곳들이 이미 생성형 AI 도입으로 상당한 투자 회수율(ROI)을 달성하고 있다는 내용이었다. 이 소식은 빠르게 확산되었고, 사람들은 "이는 중대한 발전이다", "아직 시작에 불과하다", "AI를 도입하지 않으면 경쟁에서 도태될 것"이라는 낙관적인 전망을 쏟아냈다.

두 보고서를 직접 검토해 보니, 표면적으로는 모두 합리적인 주장을 담고 있었다. 그렇다면 이 상반된 결과는 대체 무엇을 의미하는가? 각각 <포춘>(Fortune)지와 <월스트리트 저널>(Wall Street Journal)에서 다룬 기사 제목들인데, 이들의 논조와 서술 방식의 차이는 흥미로운 지점이다. 이러한 극명한 대조는 인공지능이라는 주제를 둘러싼 정보 환경의 복잡성을 여실히 보여준다. 우리는 종종 기술에 대한 상충되는 서사(narrative)에 노출되며, 이는 기술의 실제 가치를 평가하는 데 혼란을 가중시킨다.

**AI를 둘러싼 정보의 신뢰성은 매우 떨어진다**
이 두 연구 결과를 더 깊이 파고들기 전에, 반드시 기억해야 할 몇 가지 중요한 관점이 있다.

**단일한 연구 결과에만 맹신하는 태도를 경계해야 한다**: 동료 검토를 거치고 명망 있는 학술지에 실렸으며, 심지어 대중에게 널리 알려진 (예를 들어, 밀그램의 권위에 대한 복종 연구나 마시멜로 실험 같은) 안정된 학문 분야(의학이나 사회 심리학 등)의 연구조차도 재현이 불가능하거나 그 내용이 심각하게 논쟁의 대상이 되는 경우가 허다하다는 사실을 알면 놀랄 것이다. 심지어 실제 진실과는 정반대의 결론을 도출하여 나중에 뒤집히는(reversal) 연구 사례들도 존재한다. 연구의 방법론적 한계, 표본의 대표성 부족, 또는 특정 가설에 대한 과도한 집착 등이 이러한 결과를 초래하기도 한다. 또한, 우리는 종종 자신의 기존 신념을 뒷받침하는 정보만을 선택적으로 받아들이는 확증 편향(confirmation bias)에 빠지거나, 성공한 소수의 사례만을 보고 전체를 판단하는 생존자 편향(survivorship bias)의 함정에 빠지기 쉽다.

**인공지능 분야는 현재 일종의 '전쟁 상태'에 있으며, 이는 곧 '이야기(narrative)'가 '진실(truth)'보다 우위에 있음을 뜻한다**: 현재 인공지능에 관해 접하는 모든 정보(솔직히 말해, 이 글마저도)는 AI의 높은 인기, 막대한 자본 투자, 그리고 미래 예측의 불확실성이라는 요인들로 인해 어느 정도 치우쳐 있을 수밖에 없다. 나는 글을 통해 얻는 수입 외에는 어떠한 이해관계도 없으므로 최대한 객관적으로 접근하려 애쓰지만, 편향성이 모든 이에게 영향을 미친다는 사실은 부인할 수 없다. 특히 기술의 발전 속도가 워낙 빨라, 심층적인 검증보다는 즉각적인 성과나 실패에 대한 단편적인 서사가 더 주목받는 경향이 있다. 벤처 캐피탈(VC)의 투자 유치, 미디어의 클릭 경쟁, 그리고 기업들의 경쟁 우위 확보를 위한 압박 등 복합적인 요인들이 합쳐져 인공지능에 대한 과장된 기대를 형성하거나 반대로 과도한 비관론을 조장하기도 한다.

**논의는 극단적인 시각에 의해 좌우된다**: 위 내용의 필연적인 결과이다. 인공지능에 대한 당신의 관점이 중립적이라 할지라도, 더 과감하거나 노골적인 주장을 펼치는 이들이 조금의 과장만으로도 당신의 의견을 압도할 것이다. 이후 또 다른 이가 한층 더 부풀려 주도권을 가져가는 패턴이 반복된다. 결국 (이미 목격하고 있듯이) 가장 목소리가 크고 대담한 이들이 의견 스펙트럼의 양극단에 자리 잡게 되며, 이는 극단적인 AI 비판론과 극단적인 AI 옹호론으로 나타난다. 소셜 미디어와 같은 즉각적인 정보 공유 플랫폼은 이러한 극단적인 견해의 확산을 더욱 부추기며, 미묘하고 복잡한 현실을 단순한 이분법적 논리로 몰아가는 경향이 있다. 이러한 '에코 챔버(echo chamber)' 현상 속에서, 합리적이고 균형 잡힌 시각은 쉽게 묻히고 만다.

실제 사실은 "인공지능은 전혀 쓸모없으니 폐기해야 한다"(지나치게 부정적)와 "AI는 너무나 강력해서 주저하는 기업들을 파멸로 이끌 것이다"(과도하게 낙관적)라는 양 극단의 중간 지점에 놓여 있을 가능성이 크다. 하지만 진실이 중간에 존재한다고 해서 단순히 '양비론적' 관점에서 양측을 모두 만족시키려는 시도는 아니다. 진실은 어설픈 균형을 맞추기 위해 '중립'을 지향하는 것이 아니며 (애초에 진실은 어떤 목적을 가지고 존재하지 않는다!). 그보다는, 현재와 같은 '전시' 상황에서는 어떠한 단일 연구 결과라도 실제 사실과는 무관하게 스펙트럼의 한쪽 극단에 치우치는 경향이 있기 때문이다. 만약 결과가 평범했다면 아무도 그것을 공유하지 않았을 것이다! (이는 학술지들이 기대했던 효과를 찾지 못한 실험 결과를 거의 출판하지 않아 발생하는 '출판 편향'과도 관련이 있다.) 결과적으로, 연구자들은 자신들의 주장을 뒷받침하기 위해 결과를 과장하거나 (온라인에서 재배포될 때 이러한 왜곡은 더욱 심화된다), 진실이 자리 잡을 수 있는 중간 지대를 너무나도 협소하게 만든다.

따라서, 각 보고서를 가장 비판적인 관점에서 해부해 볼 필요가 있다. 모두가 진정으로 알고 싶어 하는 진실을 찾아내려면, 특정 주장의 견고함과 탄력성을 시험하기 위해 정반대의 논리적 힘을 가해야 한다. MIT 연구 결과에 대해서는 AI를 적극 지지하고 사랑하는 사람의 입장에서, 와튼 연구 결과에 대해서는 AI에 대해 회의적이고 부정적인 시각을 가진 사람의 입장에서 접근해 볼 것이다. 그 결과가 어떻게 나타날지 지켜보자.

나는 인공지능에 대한 과도한 찬양과 그에 맞서는 지나친 비방 모두를 거의 동등하게 불쾌하게 여긴다. 왜냐하면 이들은 모두 "이것은 정말이지 경이롭다" 또는 "이것은 정말이지 끔찍하다"는 식의 동일한 감정적 기반에서 비롯되기 때문이다. 그러나 나는 진실 그 자체에 대한 확고하고 변함없는 신념과 애정을 가지고 있다. 따라서 진실이 어느 쪽에 있든지, 나는 그 진실을 따를 것이다.

**MIT 보고서: 생성형 AI 시범 프로젝트의 95%가 성공에 이르지 못한다**
이 연구를 처음 보도했던 <포춘>지 기사의 핵심 내용을 직접 인용해 보자:

"최신 강력 모델을 서둘러 도입하려는 노력에도 불구하고, AI 시범 사업 중 약 5%만이 즉각적인 수익 증대를 이끌어냈으며, 대부분은 정체 상태에 머물러 손익에 거의 영향을 주지 못했다. 150명의 경영진 면담, 350명의 직원 설문, 그리고 300건의 공개된 AI 도입 사례 분석을 토대로 한 이 연구는 성공적인 프로젝트와 정체된 프로젝트 간의 명확한 차이를 드러냈다. 문제의 본질은? 인공지능 모델 자체의 성능이 아니라, 활용 도구와 조직 문화 전반에 걸친 '학습 격차(learning gap)'에 있다는 것이다. 경영진은 흔히 규제나 모델의 한계를 지적하지만, 매사추세츠 공과대학교의 연구는 미흡한 기업 내 통합 프로세스를 주된 원인으로 꼽는다."

이러한 내용은 이미 기사 제목의 의미를 크게 축소시킨다. 연구는 공개된 배포 사례와 인터뷰를 바탕으로 시범 프로젝트의 손익을 평가하고 있으며, 핵심 문제는 기술 자체보다도 통합 과정에 있다고 지적한다. 내가 파악한 바에 따르면, 매사추세츠 공과대학교의 보고서는 그 의미를 제대로 부여하기에는 너무 성급하게 진행되었다. 도입 초기 단계에서 통합이 아직 미숙한 시기에 단기적인 손익 결과로 성공 여부를 판단하는 것은 잘못된 접근 방식조차 아니다. 이는 기술의 실제 작동 여부에 대해 어떤 정보도 제공하지 못하며, 단지 사람들이 기존 업무 흐름에 생성형 AI를 접목하는 데 어려움을 겪고 있다는 사실만을 보여줄 뿐이다 (이는 분명 문제이지만, "생성형 AI가 작동하지 않는다"는 결론과는 본질적으로 다르다). 시범 운영(pilot)이라는 개념 자체가 무언가를 시험해 보고 그 작동 방식을 확인하는 데 목적이 있다. 이는 근본적으로 실험적인 성격을 띠며, 초기 단계의 시제품(prototype)에서 당장 가시적인 수익을 기대하는 것은 무리다!

가트너(Gartner)의 '하이프 사이클(Hype Cycle)'과 같은 기술 수용 주기 모델을 고려하면, 생성형 AI는 현재 '과대광고의 정점(Peak of Inflated Expectations)'을 지나 '환멸의 계곡(Trough of Disillusionment)'으로 진입하는 단계에 있을 수 있다. 이 시기에는 초기 기대에 미치지 못하는 결과가 흔히 나타나며, 이는 기술의 실패라기보다는 현실적인 기대치 조정 과정으로 볼 수 있다. 기업들이 기술의 잠재력을 완전히 실현하기까지는 상당한 시간과 노력이 필요하다는 점을 간과해서는 안 된다.

생성형 인공지능이 아직 생산성 지표에 뚜렷하게 나타나지 않는다는 점은 분명 부정적인 신호임을 나 또한 인정한다. 그러나 이는 기술 자체가 무용하다는 의미의 나쁜 징조가 아니라, 우리가 아직 경제 전반에 걸쳐 이 기술을 효율적으로 적용하는 방안을 찾아내지 못했음을 시사하는 것이다. 이러한 접근 방식의 필연적인 결과는 다음과 같다: 시범 프로젝트의 손익만을 (성공 또는 실패의 이분법적 관점에서) 측정한다면, 해당 프로젝트가 실제로 달성할 수 있는 여러 중요한 가치들을 간과하게 된다. 이러한 측정 방식은 해석에 있어 모호하고 불완전하지만, 그 근본적인 문제점은 명확하다. 과연 얼마나 많은 시간이 절약되었는가? 오류 발생률은 줄었는가, 아니면 늘었는가? 정량적인 수치로는 나타나지 않더라도, 업무 과정이 질적으로 향상되었는가? 단순히 재무적 성과만을 기준으로 '실패'를 선언하는 것은, 장기적인 관점에서 기술 도입의 진정한 가치를 놓치는 결과를 초래할 수 있다.

보고서가 지적한 '학습 격차'는 기술 자체의 문제가 아니라, 기업 내부의 '조직 관성(organizational inertia)'과 깊이 연관되어 있다. 새로운 기술은 단순히 도입하는 것을 넘어, 기존의 업무 프로세스, 인력 구성, 조직 문화 전반에 걸친 대대적인 변화를 요구한다. 이러한 변화 관리(change management)의 어려움이 바로 '통합 문제'의 핵심이며, 이는 기술의 혁신성만큼이나 중요한 성공 요인으로 작용한다. 인공지능 기술은 그 자체로 강력할지라도, 이를 수용하고 활용할 준비가 되지 않은 조직에서는 그 잠재력을 온전히 발휘하기 어렵다.

이 보고서는 또 다른 문제점인 '가시성 편향(visibility bias)'을 안고 있다. 해당 연구는 공개될 정도로 충분히 가시성을 확보한 프로젝트들을 기반으로 하는데, 이들은 대개 '우리의 성과를 보라'는 식의 홍보 목적 실험들로 이루어져 있다. 이는 현재 단계에서 주목받지 못해 거의 시도되지 않는, 지루하고 흥미롭지 않은 자동화 프로젝트들과는 대조적이다 (물론 일부 시도되었으나 실패했을 수도 있지만, 보고서는 이에 대해 전혀 언급하지 않는다!). 인공지능 시범 프로젝트의 95% 실패율은, '기업의 보여주기식 활동(corporate theater)'이라 불릴 만한 것들이 95%의 확률로 실패한다는 사실을 말해주는 것일 수도 있다. 글쎄, 우리는 이미 그런 사실을 알고 있었다. 더 나아가, 이 보고서는 '기술적 가능성(technical feasibility)'을 '사업적 타당성(business viability)'과 혼동하는 경향이 있다. 파일럿 프로젝트는 종종 기술이 특정 문제를 해결할 수 있음을 증명하는 데 성공하지만, 이를 대규모로 확장하고 실제 비즈니스 가치로 연결하는 과정에서 수많은 난관에 봉착한다. 이 과정에서의 어려움을 기술 자체의 실패로 단정하는 것은 섣부른 판단이다.

매사추세츠 공과대학교의 보고서가 전혀 무용하다는 말인가? 결코 그렇지 않다! 단지 사람들이 예상했던 것과는 다른 대상을 측정하고 있을 뿐이다. 이 연구는 기업들이 성과를 평가하는 방식(시범 프로젝트의 손익 계산서로? 과연?)과 생성형 AI를 미시적인 관점에서 실제 업무 환경에 통합하는 것이 얼마나 까다로운 일인지를 경고하는 메시지다. 그것이 전부다. 만약 내가 더 냉정하게 평가한다면, 이 보고서는 기업들의 '성급함(corporate impatience)'을 완벽하게 측정하는 지표라고 간단히 결론 내릴 것이다. 파일럿 프로젝트의 '실패'라는 단어는 오해의 소지가 크다. 이는 오히려 '학습 과정'의 일환으로 이해되어야 하며, 초기 단계의 시행착오는 장기적인 성공을 위한 필수적인 단계일 수 있다.

오늘 마감!! 상식과 인간적인 측면에 초점을 맞춘 AI의 모든 것에 대한 독점 콘텐츠와 심층 보도를 이용하려면 구독하세요. 과대광고도, 판매도, 비관론도 없습니다. 오직 냉철한 견해만 허용됩니다!

11월 3일 (월요일)까지 무료 구독자를 대상으로 33% 할인된 할로윈 세일을 진행합니다. 2026년까지는 다시 제공하지 않을 예정이니, 할인된 가격으로 꼭 구매하세요. 표준 월간 구독도 가능합니다.

할인 받기

**와튼 보고서: 기업의 75%가 긍정적인 투자 수익률(ROI)을 경험한다**
와튼 보고서는 MIT 보고서보다 분석하기가 더 복잡하며, 우리가 이를 더 면밀히 파헤쳐야 할 이유가 있다. 이는 한 가지 간단한 이유 때문이다: MIT 보고서와는 달리, 와튼 보고서는 긍정적인 결과를 제시한다—즉, 인공지능이 실제로 효과를 내고 있다는 것이다! 그러므로 AI 회의론자의 입장에서, 방금 전 MIT 보고서에 했던 것과 동일한 방식으로, 하지만 더욱 세심하게 이 보고서를 분석해 보자. 긍정적인 소식은 종종 비판적인 검토를 회피하는 경향이 있는데, 이는 우리가 성공 사례에 대해 더 쉽게 믿고 싶어 하기 때문이다. 그러나 진실을 찾기 위해서는 긍정적인 데이터 또한 냉정하게 바라볼 필요가 있다.