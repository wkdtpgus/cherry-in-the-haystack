8월 18일. 생성형 AI에 대한 새로운 MIT 보고서가 발표되었다. 결론은: 생성형 AI 파일럿 프로젝트의 95%가 실패한다는 것이다. 모두가 이 소식을 공유한다. "생성형 AI는 망했어"라고 누군가 말한다. "그럴 줄 알았어! ChatGPT는 숫자도 제대로 더할 줄 모르잖아"라고 다른 사람이 말한다. "결국엔 인간이 승리하는 법이지"라고 세 번째 사람이 말한다. 10월 28일. 생성형 AI에 대한 새로운 와튼(Wharton) 보고서가 발표되었다. 결론은: 기업의 75%가 이미 생성형 AI에서 긍정적인 투자 수익률(ROI)을 보고 있다는 것이다. 모두가 이 소식을 공유한다. "이건 꽤 큰일이야"라고 누군가 말한다. "그리고 이건 시작에 불과해!"라고 다른 사람이 말한다. "AI를 사용하지 않으면 살아남지 못할 거야..."라고 세 번째 사람이 말한다. 나는 두 보고서를 모두 읽었다. 둘 다 언뜻 보기에는 괜찮아 보인다. 도대체 무슨 일일까? 각각 포춘(Fortune)과 월스트리트 저널(Wall Street Journal)의 헤드라인이다 (어조와 표현이 얼마나 다른지 재미있다!).

**AI를 둘러싼 정보의 질은 형편없다: 하이프와 현실 사이**

생성형 AI는 기술 혁신의 최전선에 있지만, 그만큼 정보의 홍수 속에서 진실을 가려내기 어려운 영역이기도 하다. 앞서 언급된 두 보고서의 상반된 결론은 AI 기술에 대한 대중의 이해를 더욱 혼란스럽게 만든다. 이러한 정보의 불확실성은 여러 요인에서 비롯된다.

첫째, AI는 현재 기술 하이프 사이클(hype cycle)의 정점에 있다. 새로운 기술이 등장하면 과도한 기대와 함께 그 잠재력이 부풀려지고, 이후 실망의 골짜기를 거쳐 점진적으로 현실적인 가치를 찾아가는 과정을 겪는다. 생성형 AI는 바로 이 하이프 단계에 있으며, 이로 인해 언론 보도나 시장 분석은 종종 극단적인 낙관론이나 비관론에 치우치기 쉽다. 기업들은 투자 유치나 시장 선점을 위해 AI 도입 사례를 과장하거나, 반대로 실패 사례는 축소하는 경향이 있다. 이는 '서사(narrative) > 진실(truth)'이라는 공식이 AI 분야에서 특히 두드러지는 이유이다.

둘째, 하나의 연구에만 의존하는 것은 위험하다. AI와 같은 빠르게 발전하는 분야에서는 특정 시점의 단일 연구 결과가 전체 상황을 대변하기 어렵다. 과학 연구 분야에서도 동료 심사(peer review)를 거친 연구조차 복제 불가능하거나 논란이 되는 경우가 많다. AI 관련 연구는 기술의 급변성, 다양한 적용 분야, 그리고 측정의 복잡성 때문에 더욱 그러하다. 따라서 특정 보고서의 결론을 맹신하기보다는, 여러 출처의 정보를 비판적으로 분석하고 그 한계를 이해하려는 노력이 필요하다.

셋째, 극단적인 견해가 대화를 주도하는 경향이 있다. AI에 대한 온건하고 균형 잡힌 시각은 종종 더 자극적이고 과장된 주장들에 의해 묻히기 쉽다. "AI가 세상을 바꿀 것"이라는 주장과 "AI는 인류를 위협할 것"이라는 주장은 모두 사람들의 이목을 끌기 쉽고, 소셜 미디어 등을 통해 빠르게 확산된다. 이러한 극단적인 서사는 진실이 숨을 수 있는 중간 지대를 사라지게 만들며, AI에 대한 합리적인 논의를 방해한다.

결국 AI에 대한 진실은 "AI는 전혀 작동하지 않으니 없애버리자" (너무 비관적)와 "AI는 너무 잘 작동해서 기다리는 기업들을 망하게 할 것이다" (너무 낙관적) 사이 어딘가에 있을 가능성이 높다. 그러나 진실이 아마도 그 중간에 있는 이유는 "양비론(bothsidesism)" 때문이 아니다; 진실은 양쪽을 조금씩 만족시키려고 하지 않는다; 그것은 잘못된 균형을 위한 필요성 때문에 "중도적"이지 않다 (우선, 진실은 목적론적(teleological)이지 않다!). 그 이유는 전시 상태에서는 어떤 단일 연구라도 진실과 상관없이 스펙트럼의 양극단 중 하나에 속하는 경향이 있기 때문이다. 결과가 시시했다면 아무도 공유하지 않았을 것이다! (이것이 학술지들이 의도한 효과를 찾지 못한 실험을 거의 출판하지 않아 출판 편향(publication bias)을 만드는 이유이기도 하다.) 그래서 당연히 그들은 자신들의 입장과 결과를 왜곡하고 (사람들은 온라인에서 재공유할 때 이를 더욱 왜곡하는 식이다), 진실이 숨을 수 있는 중간 공간을 너무 많이 남겨둔다.

그렇다면, 각 보고서를 가능한 한 가장 불리한 시각으로 분석해 보자; 모두가 원한다고 내가 주장하는 진실을 찾기 위해서는, 어떤 이야기의 엄격함과 저항력을 시험하기 위해 동일하지만 반대되는 가치(valence)의 힘을 적용해야 한다. MIT 보고서에 대해서는 AI 옹호자, AI 애호가의 입장이 되어 볼 것이다. 와튼 보고서에 대해서는 AI 비관론자, AI 혐오자의 입장이 되어 볼 것이다. 어떤 결과가 나올지 보자.

나는 AI 과대광고와 AI 반(反)과대광고를 거의 똑같이 싫어한다 (그것들은 같은 감정적 바탕에서 나온다: "이것은 정말 정말 정말 대단해" 또는 "이것은 정말 정말 정말 끔찍해"). 하지만 나는 진실에 대한 강하고 흔들림 없는 헌신과 애착을 느낀다. 그러므로 진실이 어디에 있든, 나는 그 편에 설 것이다.

**MIT 보고서: 생성형 AI 파일럿 프로젝트의 95%가 실패한다**
이 보고서를 원래 다루었던 포춘(Fortune) 기사의 직설적인 구절을 살펴보자:

강력한 새 모델을 통합하려는 서두름에도 불구하고, AI 파일럿 프로그램의 약 5%만이 빠른 매출 증대를 달성한다; 대다수는 정체되어 손익계산서(P&L)에 측정 가능한 영향을 거의 또는 전혀 미치지 못한다. 150명의 리더 인터뷰, 350명의 직원 설문조사, 300개의 공개 AI 배포 분석을 기반으로 한 이 연구는 성공 사례와 정체된 프로젝트 사이에 명확한 구분을 보여준다. . . . 핵심 문제는? AI 모델의 품질이 아니라 도구와 조직 모두의 "학습 격차(learning gap)"이다. 경영진은 종종 규제나 모델 성능을 탓하지만, MIT의 연구는 결함 있는 기업 통합(enterprise integration)을 지적한다.

이것은 이미 헤드라인을 상당히 제한한다: 그들은 부분적으로 공개 배포 분석과 부분적으로 인터뷰를 기반으로 파일럿 프로젝트의 손익계산서(P&L)를 측정하고 있으며, 문제는 기술 자체가 아니라 통합(integration)이라고 지적한다.

내가 여기서 읽은 것: MIT 보고서는 의미를 갖기에는 너무 일찍 수행되었다. 통합이 성숙하지 않은 도입 첫해에 단기 손익계산서(P&L) 결과로 성공을 측정하는 것은 틀린 것조차 아니다! 그것은 기술이 작동하는지 여부에 대해 아무것도 알려주지 않으며, 사람들이 기존 워크플로우(workflow)에 생성형 AI를 통합하는 데 어려움을 겪고 있는지 등에 대한 것이다 (이는 문제일 수 있지만, "생성형 AI가 작동하지 않는다"는 것과는 다른 결론을 낳는다). 파일럿(pilot)의 개념은 정확히 무언가를 시도해 보고 작동하는지 확인하는 것이다. 그것은 본질적으로 실험적이며, 누구도 측정 가능한 이익을 제공할 것이라고 기대하지 않는 초기 단계의 프로토타입(prototype)이다!

생성형 AI 파일럿 프로젝트의 성공 여부를 오직 손익계산서(P&L)만으로 판단하는 것은 단기적인 시야에 갇힌 접근 방식이다. 파일럿 프로젝트는 본질적으로 학습과 탐색의 과정이며, 즉각적인 재무적 성과보다는 다음과 같은 비재무적 지표들이 더 중요하게 고려되어야 한다:
*   **학습 및 역량 강화**: 조직이 새로운 AI 기술을 얼마나 잘 이해하고 활용하는가? 직원들의 AI 리터러시(literacy)는 향상되었는가?
*   **프로세스 효율성 개선**: 특정 업무 프로세스에서 AI가 시간이나 자원을 얼마나 절약했는가? 오류율은 감소했는가?
*   **사용자 만족도 및 채택률**: AI 도구가 사용자(직원 또는 고객)에게 얼마나 유용하며, 얼마나 적극적으로 활용되는가?
*   **데이터 품질 및 접근성 향상**: AI 모델 학습을 위한 데이터 인프라가 개선되었는가?
*   **잠재적 확장성 평가**: 파일럿 프로젝트에서 얻은 통찰이 더 큰 규모의 AI 도입으로 이어질 가능성은 얼마나 되는가?

MIT 보고서가 지적한 '학습 격차'와 '결함 있는 기업 통합'은 바로 이러한 비재무적 측면의 중요성을 역설한다. 기술 자체의 성능 문제가 아니라, 조직이 AI를 효과적으로 내재화하고 활용하는 능력의 문제인 것이다. 따라서 파일럿 단계에서 P&L만을 기준으로 95%의 실패율을 논하는 것은, 초기 단계의 실험에 대한 잘못된 평가 기준을 적용한 결과일 수 있다.

또한, 보고서의 '가시성 편향(visibility bias)'은 중요한 문제이다. 이 보고서는 대중에게 공개될 만큼 '가시적인' 프로젝트들을 주로 분석했을 가능성이 높다. 이러한 프로젝트들은 종종 기업의 홍보성 실험이거나, '기업 연극(corporate theater)'의 일환으로 진행되는 경우가 많다. 즉, 실제 비즈니스 가치 창출보다는 외부 시선이나 내부적인 '보여주기'에 초점이 맞춰진 프로젝트일 수 있다. 이러한 '보여주기식' 프로젝트는 애초에 성공 가능성이 낮거나, 지속적인 개선 동기가 부족하여 실패로 끝날 확률이 높다. 따라서 95%의 실패율은 "기업 연극"이 실패할 확률을 보여주는 것일 수도 있으며, 이는 실제 AI 기술의 유용성이나 잠재력과는 거리가 멀 수 있다.

MIT 보고서는 쓸모없는가? 전혀 그렇지 않다! 그것은 사람들이 측정한다고 생각했던 것과는 다른 것을 측정하고 있을 뿐이다. 그것은 기업들이 영향을 측정하는 방식 (파일럿 프로젝트의 손익계산서(P&L)로, 정말?)과 생성형 AI를 미시적(micro scale) 수준에서 세상에 통합하는 것이 얼마나 어려울 수 있는지에 대한 경고이다. 그게 전부다. 내가 불친절하다면, 그것은 기업의 조급함(corporate impatience)을 완벽하게 측정하는 척도라고 간단히 말할 것이다.

오늘 마감!! 상식과 인간적인 측면에 초점을 맞춘 AI의 모든 것에 대한 독점 콘텐츠와 심층 보도를 이용하려면 구독하세요. 과대광고도, 판매도, 비관론도 없습니다. 오직 냉철한 견해만 허용됩니다!

11월 3일 (월요일)까지 무료 구독자를 대상으로 33% 할인된 할로윈 세일을 진행합니다. 2026년까지는 다시 제공하지 않을 예정이니, 할인된 가격으로 꼭 구매하세요. 표준 월간 구독도 가능합니다.

할인 받기

**와튼 보고서: 기업의 75%가 긍정적인 투자 수익률(ROI)을 본다**
와튼 보고서는 MIT 보고서보다 풀기가 더 까다롭고, 우리가 그렇게 하는 것이 더 중요하다. 한 가지 간단한 이유 때문이다: MIT 보고서와는 달리, 와튼 보고서는 긍정적인 발견을 제시한다—즉, 작동한다는 것이다! 그러니 AI 회의론자 모자를 쓰고 방금 했던 것과 똑같이 더 세심하게 분석해 보자.

와튼 보고서의 "기업의 75%가 긍정적인 ROI를 보고 있다"는 주장은 매우 인상적이지만, 이 또한 비판적인 시각으로 접근해야 한다. 이 주장을 액면 그대로 받아들이기 전에 몇 가지 질문을 던져야 한다.

첫째, '긍정적인 ROI'의 정의는 무엇인가? 작은 비용 절감이나 미미한 효율성 증대도 '긍정적'으로 분류될 수 있다. 예를 들어, 특정 부서의 업무 처리 시간을 1% 단축한 것도 긍정적인 ROI로 보고될 수 있지만, 이것이 기업 전체의 전략적 목표 달성에 얼마나 기여하는지는 불분명하다. 또한, ROI 측정 기준이 단기적인 재무적 이익에만 초점을 맞추었을 가능성도 있다. 장기적인 관점에서 AI 도입이 가져올 수 있는 혁신적 가치(예: 새로운 비즈니스 모델 창출, 고객 경험 개선, 시장 경쟁력 강화)는 즉각적인 ROI로 측정하기 어렵다.

둘째, 보고서의 표본 구성과 데이터 수집 방식에 편향은 없는가? 75%라는 높은 수치는 설문조사 기반일 가능성이 높으며, 이 경우 다음과 같은 문제가 발생할 수 있다:
*   **보고 편향(Reporting Bias)**: 기업들은 성공적인 AI 도입 사례를 자랑스럽게 보고하려는 경향이 있다. 반대로 실패했거나 ROI가 낮은 프로젝트는 보고하지 않거나 축소하려는 동기가 있을 수 있다.
*   **선택 편향(Selection Bias)**: 설문조사에 참여한 기업들은 이미 AI 도입에 적극적이고 어느 정도 성공을 경험한 기업들일 가능성이 높다. AI 도입에 실패했거나 아예 시도조차 하지 않은 기업들은 표본에서 제외되었을 수 있다.
*   **주관적 평가**: '긍정적인 ROI'라는 것이 객관적인 재무 지표보다는 담당자의 주관적인 판단에 의해 평가되었을 수도 있다. 기업 내부의 AI 추진 담당자는 자신의 프로젝트가 성공적이라고 보고할 동기가 충분하다.

셋째, 어떤 종류의 AI 사용 사례가 ROI를 창출했는가? 75%의 성공 사례가 주로 저위험/고효율(low-hanging fruit)의 자동화 또는 특정 반복 작업의 최적화에 집중된 것일 수 있다. 예를 들어, 고객 서비스 챗봇, 내부 문서 요약, 코드 생성 지원 등은 비교적 쉽게 ROI를 달성할 수 있는 영역이다. 하지만 이러한 성공이 AI의 광범위한 혁신적 잠재력을 대변한다고 보기는 어렵다. 진정으로 변혁적인 AI 도입은 더 많은 투자와 시간, 그리고 조직 전체의 변화를 요구하며, 그만큼 실패 위험도 높다.

결론적으로 와튼 보고서는 AI가 특정 영역에서 이미 실질적인 가치를 창출하고 있음을 보여주지만, 그 성공의 깊이와 폭에 대해서는 추가적인 질문을 던지게 한다. 이는 AI 도입이 모든 기업에게 만능 해결책이 아니며, 전략적인 접근과 신중한 평가가 필요하다는 점을 시사한다.

**두 보고서의 교차점: AI 도입의 현실과 미래**

MIT와 와튼 보고서는 극단적인 시각처럼 보이지만, 실제로는 AI 도입의 서로 다른 단계를 반영하고 있을 수 있다. MIT 보고서는 AI 도입 초기 단계에서 겪는 통합의 어려움과 측정의 오류를 지적한다. 많은 기업이 AI 기술의 잠재력에 이끌려 서둘러 파일럿 프로젝트를 시작하지만, 명확한 전략이나 충분한 내부 역량 없이 진행될 경우 실패할 확률이 높다는 것이다. 반면 와튼 보고서는 일정 수준 이상의 경험과 전략을 갖춘 기업들이 AI를 통해 이미 가시적인 성과를 내고 있음을 보여준다.

결국 AI 도입의 성공은 기술 자체의 우수성뿐만 아니라, 기업의 전략적 비전, 조직 문화, 데이터 인프라, 그리고 '학습 격차'를 해소하려는 노력에 달려 있다. 생성형 AI는 더 이상 미래의 기술이 아니라 현재의 비즈니스 도구이지만, 그 활용은 여전히 복잡하고 도전적이다. 따라서 기업들은 단순히 AI를 '도입'하는 것을 넘어, AI를 '통합'하고 '최적화'하며, 그 성과를 '정확하게 측정'하는 방법을 고민해야 한다. 과도한 낙관론이나 비관론에 흔들리지 않고, 현실적인 기대를 가지고 장기적인 관점에서 AI 전략을 수립하는 것이 중요하다.