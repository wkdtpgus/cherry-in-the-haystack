8월 18일, 한 MIT 보고서가 발표되어 세간의 이목을 집중시켰다. 그 핵심 메시지는 생성형 AI 파일럿 프로젝트의 95%가 실제 비즈니스 가치를 창출하는 데 실패한다는 내용이었다. 이 소식은 빠르게 퍼져나갔고, 다양한 반응을 불러일으켰다. 어떤 이는 "생성형 AI는 결국 실패할 것"이라 단언했고, 또 다른 이는 "ChatGPT 같은 것도 숫자 계산조차 제대로 못 하는데 당연한 결과"라며 비아냥거렸다. 심지어 "결국 인간의 지혜가 승리하는 법"이라는 낙관적인 의견도 있었다. 하지만 두 달여 뒤인 10월 28일, 와튼 스쿨(Wharton School)에서 발표된 또 다른 보고서는 전혀 다른 결론을 제시했다: 기업의 75%가 생성형 AI 도입을 통해 이미 긍정적인 투자 수익률(ROI)을 경험하고 있다는 것이었다. 이 소식 역시 빠르게 공유되며 "이건 엄청난 변화의 시작이다", "AI를 활용하지 못하는 기업은 도태될 것"이라는 등의 반응을 이끌어냈다. 나는 이 상반된 두 보고서를 모두 살펴보았다. 언뜻 보기에는 둘 다 합리적인 주장을 펼치는 듯했다. 과연 무엇이 진실일까? 흥미롭게도 이 두 보고서는 각각 포춘(Fortune)과 월스트리트 저널(Wall Street Journal)의 헤드라인을 장식했는데, 보도 태도와 표현 방식의 차이가 매우 인상적이었다.

**AI 관련 정보의 신뢰도 문제**
이 두 상반된 보고서의 내용을 더 깊이 파고들기 전에, 우리는 몇 가지 중요한 사실을 염두에 두어야 한다.

**단일 연구 결과에 대한 맹신을 경계해야 한다**: 동료 심사(peer review)를 거쳐 권위 있는 학술지에 게재되고, 심지어 대중문화에까지 영향을 미친 성숙한 학문 분야(예: 의학이나 사회 심리학)의 연구조차도, 복제 불가능하거나 그 결과가 심각하게 논란이 되는 경우가 얼마나 많은지 알면 놀랄 것이다. 더 나쁜 경우도 있다: 초기에 발표된 연구 결과가 실제 사실과 정반대임이 밝혀지는 '반전(reversal)' 현상도 빈번하다.

**AI 분야는 현재 치열한 경쟁 상황이며, 이는 사실보다 이야기가 우선시됨을 의미한다**: 지금 우리가 AI에 대해 접하는 거의 모든 정보(솔직히 말해, 이 블로그 게시물조차도)는 AI가 지닌 높은 인기, 막대한 투자금, 그리고 불확실한 미래라는 현실에 의해 어느 정도 왜곡될 수밖에 없다. 나는 나의 글쓰기에서 최대한 객관적인 시각을 유지하려 노력한다—글쓰기로 버는 돈 외에는 걸린 돈이 전혀 없으며, 이는 정직함에 달려 있다!—하지만 이러한 편향성이 우리 모두에게 영향을 미친다는 사실을 부정할 수는 없다.

**논의는 극단적인 주장들에 의해 좌우된다**: 이는 앞서 언급한 현상들의 필연적인 결과이다. AI에 대한 당신의 견해가 온건하다면, 더 과감하거나 노골적인 주장을 펼치는 이들이 당신의 목소리를 쉽게 압도할 것이다. 그리고 그 주장은 또 다른 이들에 의해 더욱 과장되어 퍼져나간다. 이 과정이 반복되면서, 결국 가장 시끄럽고 대담한 사람들이 견해 분포의 양극단—극단적인 반(反)AI와 극단적인 친(親)AI—에 모이게 된다.

이러한 맥락에서 앞서 언급된 두 AI 보고서의 의미를 해석해 보자: 진실은 아마도 "AI는 전혀 쓸모없으니 폐기해야 한다"는 극단적인 비관론과 "AI는 너무나 강력하여 이를 외면하는 기업은 곧 망할 것"이라는 맹목적인 낙관론 사이 어딘가에 있을 가능성이 높다. 그러나 이러한 중간 지점이 단순히 '양쪽의 주장을 절충하는' 양비론적 태도에서 비롯된 것은 아니다. 진실은 양쪽을 만족시키기 위해 애쓰지 않으며, 잘못된 균형을 맞추기 위해 '중도적'인 입장을 취하지도 않는다. 그 이유는 현재와 같은 경쟁적 상황에서는 어떤 단일 연구 결과라도 그 내용이 진실이든 아니든, 스펙트럼의 양극단 중 하나에 속하는 경향이 있기 때문이다. 만약 연구 결과가 평범했다면, 아무도 그것을 공유하려 하지 않았을 것이다! (이것이 학술지들이 의도한 효과를 찾지 못한 실험 결과는 거의 출판하지 않아 '출판 편향(publication bias)'을 초래하는 이유이기도 하다.) 따라서 당연히 연구자들은 자신들의 입장과 결과를 과장하여 포장하고, 대중은 이를 온라인에서 재공유하며 더욱 왜곡하는 경향이 있다. 이로 인해 진실이 숨어들 수 있는 중간 지점은 점점 더 사라지게 된다.

그렇다면, 이제 각 보고서를 가능한 한 가장 비판적인 시각으로 분석해 보자. 우리가 찾고자 하는 진실을 발견하기 위해서는, 어떤 주장의 엄격성과 견고함을 시험하기 위해 동일하지만 반대되는 관점의 힘을 적용해야 한다. MIT 보고서에 대해서는 AI 옹호자, 즉 AI 낙관론자의 입장에서 접근할 것이다. 와튼 보고서에 대해서는 AI 비관론자, 즉 AI 회의론자의 입장에서 분석해 볼 것이다. 과연 어떤 통찰을 얻게 될지 기대된다.

나는 AI에 대한 과도한 낙관론(hype)과 과도한 비관론(anti-hype)을 거의 동등하게 싫어한다. 왜냐하면 이 둘은 "이것은 정말 대단해!" 또는 "이것은 정말 끔찍해!"라는 동일한 감정적 기반에서 비롯되기 때문이다. 그러나 나는 진실 그 자체에 대해서는 강하고 흔들림 없는 헌신과 애착을 느낀다. 따라서 진실이 어디에 있든, 나는 그 편에 설 것이다.

**MIT 보고서: 생성형 AI 파일럿 프로젝트의 95% 실패 사례 분석**
이 보고서의 내용을 처음 다루었던 포춘(Fortune) 기사의 핵심 구절을 다시 살펴보자:

"강력한 새 모델을 서둘러 도입하려는 노력에도 불구하고, AI 파일럿 프로그램 중 약 5%만이 단기간 내에 상당한 매출 증대를 이끌어냈다. 대다수는 정체되어 손익계산서(P&L)에 측정 가능한 영향을 거의 또는 전혀 미치지 못했다. 150명의 리더 인터뷰, 350명의 직원 설문조사, 그리고 300개의 공개된 AI 배포 사례 분석을 기반으로 한 이 연구는 성공적인 사례와 정체된 프로젝트 사이에 명확한 경계를 보여준다. . . . 본질적인 원인은 무엇인가? AI 모델 자체의 성능 문제가 아닌, 사용 도구와 조직 내의 '학습 격차(learning gap)'에 있었다. 경영진은 종종 규제나 모델 성능을 문제 삼지만, MIT 연구는 기업의 통합(enterprise integration) 과정에서의 결함을 지적한다."

이 내용은 이미 헤드라인의 의미를 상당히 제한하고 있다. 즉, 보고서는 부분적으로 공개 배포 사례 분석과 인터뷰를 바탕으로 파일럿 프로젝트의 손익계산서(P&L)를 평가하고 있으며, 그 실패의 원인을 기술 자체가 아닌 '통합(integration)' 문제로 지목하고 있다.

여기서 내가 읽어내는 바는 다음과 같다: MIT 보고서는 의미 있는 결론을 도출하기에는 너무 이른 시점에 수행된 연구라는 것이다. 도입 초기 단계에서 단기적인 손익계산서(P&L) 결과만을 가지고 파일럿 프로젝트의 성공 여부를 판단하는 것은, 잘못된 평가 기준을 적용하는 것 이상으로 문제가 있다! 이는 기술 자체의 작동 여부에 대한 어떤 정보도 제공하지 않으며, 단지 사람들이 기존 워크플로우(workflow)에 생성형 AI를 통합하는 데 어려움을 겪고 있다는 사실만을 보여줄 뿐이다. 물론 이는 중요한 문제일 수 있지만, "생성형 AI가 작동하지 않는다"는 결론과는 다른 차원의 이야기이다. 파일럿(pilot) 프로젝트의 본질적인 목적은 무언가를 시험해보고 그 가능성을 확인하는 데 있다. 이는 근본적으로 실험적인 성격을 띠며, 누구도 초기 단계의 프로토타입(prototype)에서 즉각적인 측정 가능한 이익을 기대하지 않는다!

나는 생성형 AI가 아직 생산성 지표(productivity chart)에 뚜렷하게 반영되지 않고 있다는 점이 부정적인 신호임을 가장 먼저 인정한다. 그러나 이는 기술 자체가 작동하지 않는다는 의미의 부정적인 신호라기보다는, 우리가 아직 경제 전반에 걸쳐 이 기술을 효과적으로 적용하는 방법을 완전히 이해하지 못했다는 의미로 해석되어야 한다. 여기에 필연적인 결과가 따른다: 만약 파일럿 프로젝트의 손익계산서(P&L)만을 측정한다면 (성공 또는 실패라는 이분법적 관점에서), 우리는 파일럿 프로젝트가 실제로 달성할 수 있는 다른 중요한 가치들을 간과하게 된다. 이는 미묘하고 불분명하게 느껴질 수 있지만, 근본적으로 중요한 부분이다. 예를 들어, 얼마나 많은 시간이 절약되었는가? 오류율은 감소했는가 또는 증가했는가? 정량적으로 측정하기 어렵더라도, 정성적으로(qualitatively) 워크플로우(workflow)가 개선되었는가? 이러한 질문들이 간과되어서는 안 된다.

보고서에는 또 다른 문제가 있다: 가시성 편향(visibility bias). 이 보고서는 데이터셋(dataset)에 포함될 만큼 충분히 공개된 프로젝트들을 기반으로 하는데, 이는 대부분 "우리가 무엇을 하고 있는지 보라"는 식의 홍보성 실험들로 구성되어 있을 가능성이 높다. 이러한 프로젝트들은 눈에 띄기 쉽고 흥미를 유발하지만, 실제 비즈니스에 조용히 통합되어 효율성을 높이는 '지루하고 재미없는 자동화(automation)' 프로젝트들과는 대조적이다. 후자의 경우 초기 단계에서는 거의 주목받지 못한다 (물론, 일부는 시도되었으나 작동하지 않았을 수도 있지만, 보고서는 이에 대해 아무런 언급도 하지 않는다!). 따라서 AI 파일럿 프로젝트의 95% 실패율은 사실상 '기업 연극(corporate theater)'이라 불릴 만한 프로젝트들이 95%의 확률로 실패한다는 것을 말해주는 것일 수도 있다. 음, 그렇다면 우리는 이미 그 사실을 알고 있었던 셈이다.

그렇다면 MIT 보고서는 완전히 쓸모없는 것인가? 전혀 그렇지 않다! 단지 이 보고서는 사람들이 측정한다고 생각했던 것과는 다른 것을 측정하고 있을 뿐이다. 이 보고서는 기업들이 AI의 영향을 측정하는 방식(파일럿 프로젝트의 손익계산서(P&L)로 측정하는 것이 과연 합당한가?)과 생성형 AI를 미시적(micro scale) 수준에서 실제 비즈니스 환경에 통합하는 것이 얼마나 어려운 일인지를 보여주는 경고등 역할을 한다. 그것이 전부다. 만약 내가 좀 더 냉정하게 평가한다면, 이 보고서는 기업의 조급함(corporate impatience)을 완벽하게 측정하는 척도라고 간단히 말할 수 있을 것이다.

오늘 마감!! 상식과 인간적인 측면에 초점을 맞춘 AI의 모든 것에 대한 독점 콘텐츠와 심층 보도를 이용하려면 구독하세요. 과대광고도, 판매도, 비관론도 없습니다. 오직 냉철한 견해만 허용됩니다!

11월 3일 (월요일)까지 무료 구독자를 대상으로 33% 할인된 할로윈 세일을 진행합니다. 2026년까지는 다시 제공하지 않을 예정이니, 할인된 가격으로 꼭 구매하세요. 표준 월간 구독도 가능합니다.

할인 받기

**와튼 보고서: 기업의 75%가 긍정적인 투자 수익률(ROI)을 경험한다**
와튼 보고서는 MIT 보고서보다 분석하기가 더 까다롭고, 그렇기에 우리의 세심한 분석이 더욱 중요하다. 한 가지 간단한 이유 때문이다: MIT 보고서와는 달리, 와튼 보고서는 긍정적인 결과를 제시한다—즉, 생성형 AI가 실제로 작동한다는 것이다! 그러니 이제 AI 회의론자의 입장에서, 방금 MIT 보고서를 분석했던 것과 마찬가지로 더욱 면밀하게 이 보고서를 파헤쳐 보자. 이 보고서가 과연 무엇을 측정하고 있으며, 어떤 조건에서 이러한 긍정적인 ROI가 발생했는지를 이해하는 것이 핵심이다. 예를 들어, 보고서에 언급된 '긍정적인 ROI'가 특정 산업 분야나 규모의 기업에 국한된 것인지, 아니면 전반적인 현상인지 살펴보아야 한다. 또한, ROI 측정 기준이 단기적인 비용 절감에 초점을 맞춘 것인지, 아니면 장기적인 혁신과 시장 경쟁력 강화까지 포함하는 것인지도 중요한 분석 포인트가 될 것이다. 와튼 보고서의 긍정적인 메시지 뒤에 숨겨진 맥락과 한계를 탐구함으로써, 우리는 생성형 AI의 실제 가치와 도입 전략에 대한 보다 균형 잡힌 시각을 얻을 수 있을 것이다.