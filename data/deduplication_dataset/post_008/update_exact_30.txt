최근 몇 달 동안 추론 모델(reasoning models)에 대해 많은 글을 썼습니다(연속 4편)! 모든 "에이전트(agentic)" 관련 주제와 더불어, 추론은 2025년 LLM의 가장 큰 주제 중 하나입니다. 하지만 이번 달에는 LLM이 어떻게 작동하는지 이해하는 가장 좋은 방법 중 하나인 LLM 코딩 방법에 대한 더 근본적이고 "기초적인" 내용을 여러분과 공유하고 싶었습니다. 왜냐고요? 작년에 제가 공유했던 요약된 LLM 워크숍, 즉 **밑바닥부터 LLM 구축하기: 3시간 코딩 워크숍** (Sebastian Raschka, PhD · 2024년 8월 31일 전체 스토리 읽기)을 많은 분들이 좋아하고 유용하게 활용했기 때문입니다. 그래서 저는 약 5배 더 길고 상세한 이 내용(총 약 15시간)이 훨씬 더 유용할 것이라고 생각했습니다.

지난 몇 주간은 개인적으로 쉽지 않은 시간이었습니다. 건강 문제로 컴퓨터 작업에 제약이 있었지만, 어려움 속에서도 여러분께 유익한 LLM 코딩 워크숍 영상 시리즈를 공유하게 되어 기쁩니다. 이 자료가 여러분의 학습에 도움이 되기를 진심으로 바랍니다.

추신: 이 영상들은 원래 제 **밑바닥부터 대규모 언어 모델 구축하기(Build a Large Language Model (From Scratch))** 책의 보충 자료로 시작되었습니다. 하지만 독립적인 콘텐츠로도 꽤 잘 작동한다는 것을 알게 되었습니다. 왜 밑바닥부터 구축해야 할까요? 아마도 LLM이 실제로 어떻게 작동하는지 배우는 가장 좋고 효율적인 방법일 것입니다. 게다가 많은 독자들이 이 과정을 통해 많은 즐거움을 얻었다고 말해주었습니다.

밑바닥부터 LLM을 구축하는 과정은 시스템의 각 구성 요소를 깊이 이해하고 문제 해결 능력을 키우는 데 중요합니다. 최근 LoRA(Low-Rank Adaptation)나 QLoRA(Quantized LoRA) 같은 효율적인 미세 조정(fine-tuning) 기법이 중요해지고 있으며, LLM 내부 작동 방식을 아는 것은 최신 기술 적용에 필수적인 기반 지식을 제공합니다.

**참고 자료**
*   밑바닥부터 LLM 구축하기 책 (Manning | Amazon)
*   밑바닥부터 LLM 구축하기 GitHub 저장소

이 워크숍은 총 7개의 심층 영상으로 구성되어 있으며, LLM의 핵심 개념들을 단계별로 직접 코딩하며 학습할 수 있도록 설계되었습니다.

**1 - 코딩 환경 설정 (0:21:01)**
이 영상은 `uv`를 활용한 파이썬(Python) 환경 설정 방법을 설명합니다. 윈도우(Windows) 환경의 `텐서플로우(TensorFlow)` 설치 문제에 대한 대안으로 `파이토치(PyTorch)` 기반 `GPT-2` 가중치(weights) 로딩 방법을 제시합니다.

**2 - 텍스트 데이터 작업 (1:28:01)**
LLM 훈련의 핵심인 텍스트 데이터 준비 과정을 다룹니다. `토큰화(tokenization)`, `바이트 페어 인코딩(byte pair encoding, BPE)` 및 효율적인 `데이터 로더(data loaders)` 구현 방법을 배웁니다.

**3 - 어텐션 메커니즘(attention mechanisms) 코딩 (2:15:40)**
이 영상은 어텐션 메커니즘(attention mechanisms) (셀프 어텐션(self-attention), 인과적 어텐션(causal attention), 멀티 헤드 어텐션(multi-head attention))이 어떻게 작동하는지 밑바닥부터 코딩하여 설명하는 보충 영상입니다. 자동차의 엔진을 만드는 것(프레임, 좌석, 바퀴를 추가하기 전)으로 생각할 수 있습니다.

**4 - LLM 아키텍처 코딩 (0:21:01)**
이 영상은 현대 LLM의 근간인 트랜스포머(Transformer) 아키텍처, 특히 디코더 전용(decoder-only) 모델을 밑바닥부터 구현하는 방법을 다룹니다.

**5 - 레이블 없는 데이터로 사전 훈련 (2:36:44)**
LLM이 방대한 텍스트 데이터에서 일반적인 언어 패턴을 학습하는 사전 훈련(pre-training) 과정을 배웁니다. 레이블 없는 대규모 데이터셋을 사용하여 모델을 훈련하고, 훈련 루프(training loop)를 구현하는 실제적인 방법을 경험합니다.

**6 - 분류를 위한 미세 조정(Finetuning) (2:15:29)**
사전 훈련된 LLM을 다양한 하류 작업(downstream tasks)에 활용하기 위한 미세 조정(fine-tuning) 개념을 소개합니다. LoRA(Low-Rank Adaptation) 같은 `PEFT` 기법을 통한 효율적인 미세 조정 트렌드도 언급합니다.

**7 - 명령어 미세 조정(Instruction Finetuning) (1:46:04)**
LLM이 사용자의 지시를 따르고 유용한 답변을 생성하도록 만드는 핵심 기술인 명령어 미세 조정(instruction finetuning) 방법을 다룹니다. 유용한 'AI 조수'를 만드는 기반을 다지게 될 것입니다.

**보너스: LLM의 과거와 현재 (2018년부터 2025년까지)**
유료 구독자분들을 위한 특별 보너스 영상입니다. 2018년 GPT-2(Generative Pre-trained Transformer 2)부터 2025년 현재까지 LLM 환경 변화와 `라마 3(Llama 3)` 같은 최신 모델들의 기술 발전을 조명합니다.

마무리하며
이 워크숍 영상 시리즈는 LLM 개발에 대한 깊이 있는 이해를 돕기 위해 제작되었습니다. 밑바닥부터 직접 코드를 작성하며 배우는 과정은 도전적일 수 있지만, 값진 경험과 통찰을 제공할 것입니다. 여러분의 지속적인 관심과 성원에 감사드립니다.