최근 몇 달간 사고(思考) 모형(reasoning models) 관련 주제를 심도 깊게 다루는 여러 콘텐츠를 발행했습니다(벌써 4편째입니다)! 모든 '자율 작동(agentic)' 시스템과 더불어, 2025년 거대 언어 모델(LLM) 분야의 핵심 동향 중 하나로 사유(思惟) 과정의 심화가 주목받고 있습니다. 그러나 이번 달에는 LLM의 작동 원리를 깊이 있게 파악하는 최상의 경로 중 하나인 LLM 개발 기법에 대한 더욱 근원적이고 '기본적인' 정보를 독자 여러분께 제시하고자 했습니다. 그 이유는 무엇일까요? 지난해 제가 제공했던 압축적인 LLM 실습 강좌, 즉 **바닥부터 LLM 구현하기: 3시간 코딩 세션** (Sebastian Raschka, PhD · 2024년 8월 31일 전체 글 확인)이 다수의 참여자가 긍정적인 반응을 보이며 실질적인 도움을 받았기 때문입니다. 이에 따라 기존보다 5배가량 확장된 상세한 교육 과정(총 15시간 분량)이 더욱 큰 가치를 제공하리라 판단했습니다. 이러한 심층적인 접근은 단순한 API 활용을 넘어, 모델의 본질적 이해와 문제 해결 능력을 향상시키는 데 필수적입니다.

또한, 안타깝게도 심각한 경추 부상으로 인해 지난 3주간 정상적인 컴퓨터 작업이 불가능했습니다. 현재는 외과적 개입을 검토하기에 앞서 비수술적 요법을 우선적으로 시도하는 중입니다. 업무 흐름을 정상화하려던 시점에 돌발적인 역경에 직면하게 되어 매우 아쉬운 상황입니다. 이러한 개인적인 어려움 속에서도 여러분과의 소통을 이어가기 위해, 회복기에 접어든 동안, 이전 몇 달간 제작해 두었던 영상 자료들을 임시 콘텐츠로 배포하는 것이 적절하다고 판단했습니다. 이 자료들이 여러분께 유용하길 바라며, 지속적인 성원에 깊이 감사드립니다! 장기적인 관점에서 건강은 창의적이고 생산적인 활동의 기반이 되므로, 빠른 회복을 통해 더 풍부한 콘텐츠를 제작할 수 있기를 기대하고 있습니다.

추신: 이 영상들은 원래 제 **밑바닥부터 대규모 언어 모델 구축하기(Build a Large Language Model (From Scratch))** 책의 보조 자료로 기획되었습니다. 하지만 독립적인 콘텐츠로도 상당한 완성도를 갖추고 있음을 확인했습니다. 왜 '바닥부터' 구축해야 할까요? 이는 대규모 언어 모델이 실제로 어떤 방식으로 기능하는지 습득하는 데 가장 효과적이고 능률적인 접근법일 것입니다. 게다가, 많은 독자들이 이 과정을 통해 깊은 만족감을 느꼈다고 피드백을 주었습니다. 비유를 들자면, 만약 차량에 흥미가 있고 그 작동 원리를 이해하고 싶다면, 가장 기본적인 부품부터 직접 조립하는 과정을 다룬 안내서를 따르는 것이 탁월한 학습 경험을 선사할 것입니다. 물론, 첫 프로젝트로 포뮬러 1(Formula 1) 경주용 차량을 만드는 것부터 시작하고 싶지는 않을 것입니다. 이는 엄청나게 고가이고 지나치게 복잡할 테니까요. 대신, 고카트(go-kart)와 같이 좀 더 단순한 대상을 선택하는 것이 합리적입니다. 간단한 카트 제작만으로도 조향 시스템의 메커니즘이나 엔진의 구동 방식을 터득할 수 있습니다. 전문 경주용 차량을 다루기 전(혹은 차량 제작에 특화된 기업이나 팀에 합류하기 전)에 트랙에서 연습하고(이 과정에서 많은 즐거움을 얻을 수 있습니다). 결국, 최고의 경주 드라이버들은 종종 자신만의 고카트를 만들고 개선하며 경력을 시작했습니다(미하엘 슈마허(Michael Schumacher)와 아일톤 세나(Ayrton Senna)를 떠올려 보세요). 이러한 과정을 통해 그들은 차량에 대한 탁월한 직관을 길렀을 뿐만 아니라, 엔지니어들에게 중요한 의견을 전달하여 다른 경쟁자들보다 유리한 고지를 점할 수 있었습니다. 이처럼 '바닥부터' 배우는 것은 단순히 지식을 습득하는 것을 넘어, 문제 해결 능력과 혁신적인 아이디어를 발현시키는 데 결정적인 역할을 합니다.

**참고 자료**
*   밑바닥부터 LLM 구축하기 책 (Manning | Amazon)
*   밑바닥부터 LLM 구축하기 GitHub 저장소

**1 - 코딩 환경 설정 (0:21:01)**
해당 영상은 'uv' 도구를 활용하여 파이썬(Python) 개발 환경을 구축하는 방법을 설명하는 보조 자료입니다. 특히, 본 문서에서 언급하는 'uv pip' 명령어를 사용합니다. 또는, 기본적인 'uv add' 구문(syntax) (이 영상에서는 언급되었으나 명시적으로 다루지는 않음)은 여기에서 설명합니다.
참고 / 팁: 설치 시 특정 버전의 윈도우(Windows)에서 문제가 발생할 수 있습니다. 만약 윈도우(Windows) 운영체제 환경에서 설치 과정 중 어려움을 겪는다면 (영상 5에서 OpenAI의 오리지널 GPT-2 모델 가중치(weights)를 로드하기 위한 텐서플로우(TensorFlow) 종속성(dependency) 때문일 가능성이 높음), 걱정하지 마시고 텐서플로우(TensorFlow) 구성 요소를 제외하고 진행하셔도 무방합니다 (요구 사항(requirements) 파일에서 텐서플로우(TensorFlow) 관련 항목을 제거하여 이 작업을 수행할 수 있습니다). 대안을 제공하기 위해, 저는 GPT-2 모델 가중치(weights)를 텐서플로우(TensorFlow) 텐서(tensor) 형식에서 파이토치(PyTorch) 텐서(tensors)로 변환하여 허깅 페이스(Hugging Face) 모델 허브(model hub)에 공유했습니다. 이는 영상 5의 가중치(weight) 로딩 부분에 대한 대안으로 활용될 수 있습니다: https://huggingface.co/rasbt/gpt2-from-scratch-pytorch. 어쨌든, 영상 5의 후반부까지는 이 가중치(weight) 로딩 코드에 대해 미리 염려할 필요가 없습니다. 올바른 개발 환경 설정은 모든 프로젝트의 성공적인 시작을 위한 첫걸음이며, 불필요한 오류를 방지하는 데 중요합니다.

**2 - 텍스트 데이터 작업 (1:28:01)**
이 영상은 LLM 훈련을 위한 텍스트 데이터의 전처리 단계(토큰화(tokenization), 바이트 페어 인코딩(byte pair encoding), 데이터 로더(data loaders) 등)를 포괄적으로 다룹니다. 효율적인 토큰화는 모델이 언어를 이해하는 방식에 직접적인 영향을 미치며, 특히 바이트 페어 인코딩(BPE)은 희귀 단어(OOV: Out-Of-Vocabulary) 문제에 대한 효과적인 해결책을 제시합니다.

**3 - 어텐션 메커니즘(attention mechanisms) 코딩 (2:15:40)**
이 영상은 어텐션 메커니즘(attention mechanisms) (셀프 어텐션(self-attention), 인과적 어텐션(causal attention), 멀티 헤드 어텐션(multi-head attention))이 어떻게 작동하는지 밑바닥부터 코딩하여 설명하는 보충 영상입니다. 이는 마치 자동차의 엔진을 직접 제작하는 것과 같습니다(차체, 좌석, 바퀴를 부착하기 전의 핵심 과정입니다). 어텐션은 장거리 의존성(long-range dependencies)을 효과적으로 포착하여, 기존 순환 신경망(RNNs)이나 합성곱 신경망(CNNs)의 한계를 극복하는 트랜스포머(Transformer) 아키텍처의 핵심 요소입니다.

**4 - LLM 아키텍처 코딩 (0:21:01)**
이 영상은 트랜스포머 기반의 LLM 아키텍처(architecture)를 밑바닥부터 코딩하는 방법을 다룹니다. 여기서는 인코더-디코더 구조, 피드포워드 네트워크(feed-forward networks), 잔차 연결(residual connections) 등 모델의 주요 구성 요소를 심도 있게 분석하고 구현합니다.

**5 - 레이블 없는 데이터로 사전 훈련 (2:36:44)**
이 영상은 방대한 양의 레이블 없는 데이터셋을 활용하여 LLM을 사전 훈련하는 방법을 상세히 설명합니다. 사전 훈련은 모델이 일반적인 언어 패턴과 지식을 습득하는 데 필수적인 과정입니다.

**6 - 분류를 위한 미세 조정(Finetuning) (2:15:29)**
이 영상은 다음 영상에서 LLM을 명령어 미세 조정(instruction finetuning)하기 전에, 미세 조정(finetuning)에 대한 부드러운 소개로 LLM을 분류기(classifier)로 미세 조정(fine-tune)하는 방법(여기서는 스팸 분류 예시를 사용)을 설명합니다. 효율적인 미세 조정을 위한 다양한 기법들, 예를 들어 PEFT(Parameter-Efficient Finetuning)나 LoRA(Low-Rank Adaptation) 등에 대한 소개도 포함됩니다.

**7 - 명령어 미세 조정(Instruction Finetuning) (1:46:04)**
마지막으로, 이 영상은 특정 지침이나 명령에 따라 LLM의 응답을 최적화하는 명령어 미세 조정(instruction finetune) 방법을 설명합니다. 이는 모델이 사용자의 의도를 더 정확하게 파악하고 유용한 결과물을 생성하도록 돕는 중요한 단계입니다.

즐겁게 시청하고, 직접 코드를 만지작거리며 깊이 있게 탐구해 보세요!

**보너스: LLM의 과거와 현재 (2018년부터 2025년까지)**
유료 회원 여러분께 감사의 마음을 담아, 라마 4(Llama 4) 공개 직후인 4월 초에 촬영된 2.5시간 길이의 (비코딩) 추가 영상을 제공하고자 합니다. 본 강연에서는 2018년 GPT-2 출현 이후의 변화 양상에 중점을 두고 2025년 현재의 LLM 생태계에 대한 심층적인 논의를 펼칩니다. 트랜스포머(Transformer) 아키텍처의 확산, 스케일링 법칙(scaling laws)의 발견, 명령어 튜닝(instruction tuning) 및 인간 피드백 기반 강화 학습(RLHF)의 도입, 그리고 오픈 소스 모델의 부상에 이르기까지 주요 이정표들을 다룹니다. 또한, 2025년 이후 LLM이 직면할 효율성, 편향성, 안전성 문제와 더불어 새로운 산업 분야에서의 응용 가능성도 함께 조망합니다.

독립적이고 자율적으로 연구 활동을 펼치는 저에게 여러분의 성원은 정말 큰 의미가 있습니다! 앞으로 더 많은 흥미로운 아이디어들을 글로 풀어내고 싶으니, 몇 주 또는 몇 달 안에 상황이 호전되기를 진심으로 바랍니다. 여러분의 지속적인 관심과 지지에 다시 한번 감사드립니다.