최근 몇 달 동안 추론 모델(reasoning models)에 대해 많은 글을 썼습니다(연속 4편)! 모든 "에이전트(agentic)" 관련 주제와 더불어, 추론은 2025년 LLM의 가장 큰 주제 중 하나입니다. 하지만 이번 달에는 LLM이 어떻게 작동하는지 이해하는 가장 좋은 방법 중 하나인 LLM 코딩 방법에 대한 더 근본적이고 "기초적인" 내용을 여러분과 공유하고 싶었습니다. 왜냐고요? 작년에 제가 공유했던 요약된 LLM 워크숍, 즉 **밑바닥부터 LLM 구축하기: 3시간 코딩 워크숍** (Sebastian Raschka, PhD · 2024년 8월 31일 전체 스토리 읽기)을 많은 분들이 좋아하고 유용하게 활용했기 때문입니다. 그래서 저는 약 5배 더 길고 상세한 이 내용(총 약 15시간)이 훨씬 더 유용할 것이라고 생각했습니다.

또한, 안타깝게도 저는 심한 목 부상으로 지난 3주 동안 컴퓨터 작업을 제대로 할 수 없었습니다. 현재는 권고된 수술적 방법을 고려하기 전에 보존적 치료를 시도하고 있습니다. 이제 막 정상 궤도에 오르려던 참에 또 다른 예상치 못한 난관에 부딪히게 되어 최악의 타이밍입니다. 그래서 회복 기간 동안 지난 몇 달 동안 녹화했던 이 영상들을 공유하는 것이 좋은 중간 콘텐츠가 될 것이라고 생각했습니다. 이 자료가 유용하시기를 바라며, 여러분의 성원에 감사드립니다!

추신: 이 영상들은 원래 제 **밑바닥부터 대규모 언어 모델 구축하기(Build a Large Language Model (From Scratch))** 책의 보충 자료로 시작되었습니다. 하지만 독립적인 콘텐츠로도 꽤 잘 작동한다는 것을 알게 되었습니다. 왜 밑바닥부터 구축해야 할까요? 아마도 LLM이 실제로 어떻게 작동하는지 배우는 가장 좋고 효율적인 방법일 것입니다. 게다가 많은 독자들이 이 과정을 통해 많은 즐거움을 얻었다고 말해주었습니다. 비유를 들자면, 자동차에 관심이 있고 자동차가 어떻게 작동하는지 이해하고 싶다면, 밑바닥부터 자동차를 만드는 과정을 안내하는 튜토리얼을 따르는 것이 훌륭한 학습 방법입니다. 물론, 첫 프로젝트로 포뮬러 1(Formula 1) 경주용 자동차를 만드는 것부터 시작하고 싶지는 않을 것입니다. 엄청나게 비싸고 지나치게 복잡할 테니까요. 대신, 고카트(go-kart)처럼 더 간단한 것으로 시작하는 것이 더 합리적입니다. 고카트를 만드는 것만으로도 조향 장치가 어떻게 작동하는지, 모터 기능은 어떤지 등을 배울 수 있습니다. 전문 경주용 자동차를 타기 전(또는 자동차 제작에 집중하는 회사나 팀에 합류하기 전)에 트랙에 가져가서 연습하고(그리고 많은 즐거움을 얻을 수 있습니다). 결국, 최고의 경주 드라이버들은 종종 자신만의 고카트를 만들고 만지작거리며 경력을 시작했습니다(미하엘 슈마허(Michael Schumacher)와 아일톤 세나(Ayrton Senna)를 생각해 보세요). 그렇게 함으로써 그들은 자동차에 대한 뛰어난 감각을 개발했을 뿐만 아니라 정비사들에게 귀중한 피드백을 제공하여 다른 드라이버들보다 우위를 점할 수 있었습니다.
밑바닥부터 LLM을 구축하는 과정은 시스템의 각 구성 요소를 깊이 이해하고 문제 해결 능력을 키우는 데 중요합니다. 최근 LoRA(Low-Rank Adaptation)나 QLoRA(Quantized LoRA) 같은 효율적인 미세 조정(fine-tuning) 기법이 중요해지고 있으며, LLM 내부 작동 방식을 아는 것은 최신 기술 적용에 필수적인 기반 지식을 제공합니다.

**참고 자료**
*   밑바닥부터 LLM 구축하기 책 (Manning | Amazon)
*   밑바닥부터 LLM 구축하기 GitHub 저장소

이 워크숍은 총 7개의 심층 영상으로 구성되어 있으며, LLM의 핵심 개념들을 단계별로 직접 코딩하며 학습할 수 있도록 설계되었습니다.

**1 - 코딩 환경 설정 (0:21:01)**
이 영상은 `uv`를 활용한 파이썬(Python) 환경 설정 방법을 설명합니다. 특히, 윈도우(Windows) 환경에서 `텐서플로우(TensorFlow)` 설치 시 발생할 수 있는 문제(영상 5에서 OpenAI의 오리지널 `GPT-2` 모델 가중치(weights) 로드 시 종속성 때문일 가능성이 높음)에 대한 대안으로 `파이토치(PyTorch)` 기반 `GPT-2` 가중치(weights) 로딩 방법을 제시합니다. 대안으로 사용할 수 있는 허깅 페이스(Hugging Face) 모델 허브 링크는 다음과 같습니다: https://huggingface.co/rasbt/gpt2-from-scratch-pytorch.

**2 - 텍스트 데이터 작업 (1:28:01)**
LLM 훈련의 핵심인 텍스트 데이터 준비 과정을 다룹니다. `토큰화(tokenization)`, `바이트 페어 인코딩(byte pair encoding, BPE)` 및 효율적인 `데이터 로더(data loaders)` 구현 방법을 배웁니다.

**3 - 어텐션 메커니즘(attention mechanisms) 코딩 (2:15:40)**
이 영상은 어텐션 메커니즘(attention mechanisms) (셀프 어텐션(self-attention), 인과적 어텐션(causal attention), 멀티 헤드 어텐션(multi-head attention))이 어떻게 작동하는지 밑바닥부터 코딩하여 설명하는 보충 영상입니다. 자동차의 엔진을 만드는 것(프레임, 좌석, 바퀴를 추가하기 전)으로 생각할 수 있습니다.

**4 - LLM 아키텍처 코딩 (0:21:01)**
이 영상은 현대 LLM의 근간인 트랜스포머(Transformer) 아키텍처, 특히 디코더 전용(decoder-only) 모델을 밑바닥부터 구현하는 방법을 다룹니다.

**5 - 레이블 없는 데이터로 사전 훈련 (2:36:44)**
LLM이 방대한 텍스트 데이터에서 일반적인 언어 패턴을 학습하는 사전 훈련(pre-training) 과정을 배웁니다. 레이블 없는 대규모 데이터셋을 사용하여 모델을 훈련하고, 훈련 루프(training loop)를 구현하는 실제적인 방법을 경험합니다.

**6 - 분류를 위한 미세 조정(Finetuning) (2:15:29)**
사전 훈련된 LLM을 다양한 하류 작업(downstream tasks)에 활용하기 위한 미세 조정(fine-tuning) 개념을 소개합니다. 이 영상에서는 다음 영상의 명령어 미세 조정(instruction finetuning)에 앞서, LLM을 분류기(classifier)로 미세 조정(fine-tune)하는 방법(스팸 분류 예시 사용)을 다룹니다. 또한, LoRA(Low-Rank Adaptation) 같은 `PEFT` 기법을 통한 효율적인 미세 조정 트렌드도 언급합니다.

**7 - 명령어 미세 조정(Instruction Finetuning) (1:46:04)**
LLM이 사용자의 지시를 따르고 유용한 답변을 생성하도록 만드는 핵심 기술인 명령어 미세 조정(instruction finetuning) 방법을 다룹니다. 유용한 'AI 조수'를 만드는 기반을 다지게 될 것입니다.

**보너스: LLM의 과거와 현재 (2018년부터 2025년까지)**
유료 구독자분들을 위한 특별 보너스 영상입니다. 라마 4(Llama 4) 출시 약 2일 후인 4월 초에 녹화되었던 2.5시간 분량의 (코딩이 아닌) 이 강연에서는 2018년 `GPT-2(Generative Pre-trained Transformer 2)`부터 2025년 현재까지 LLM 환경 변화와 `라마 3(Llama 3)` 같은 최신 모델들의 기술 발전을 조명합니다.

마무리하며, 이 워크숍 영상 시리즈는 LLM 개발에 대한 깊이 있는 이해를 돕기 위해 제작되었습니다. 밑바닥부터 직접 코드를 작성하며 배우는 과정은 도전적일 수 있지만, 값진 경험과 통찰을 제공할 것입니다. 독립적이고 자영업을 하는 연구자로서 여러분의 지속적인 관심과 성원은 저에게 정말 큰 의미가 있습니다. 다가오는 글들에 대한 아이디어가 많고 빨리 작업하고 싶으니, 앞으로 몇 주/몇 달 안에 상황이 나아지기를 바랍니다. 여러분의 성원에 다시 한번 감사드립니다.