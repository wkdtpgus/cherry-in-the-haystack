추론은 LLM의 핵심 기능 중 하나입니다. 하지만 이번 달에는 LLM 코딩 방법에 대한 실용적인 내용을 여러분과 공유하고 싶었습니다. 작년에 공유했던 요약된 딥러닝 워크숍에 대한 반응이 뜨거웠습니다. 그래서 저는 새로운 약 15시간 분량의 콘텐츠가 훨씬 더 유용할 것이라고 생각했습니다. 이 과정은 모델의 본질을 파악하는 데 중점을 둡니다.

또한, 안타깝게도 저는 최근 개인적인 사정으로 인해 컴퓨터 작업을 제대로 할 수 없었습니다. 현재는 권고된 최신 기술을 고려하기 전에 기본 원리를 다시 살펴보는 중입니다. 회복 기간 동안 학습했던 다양한 기술들을 공유하는 것이 좋은 중간 콘텐츠가 될 것이라고 생각했습니다. 이 자료가 유용하시기를 바라며, 독자 여러분의 성원에 감사드립니다! 근본적인 질문이 더 큰 진보를 가져옵니다.

추신: 이 자료들은 원래 제 **밑바닥부터 인공지능 시스템 구축하기** 프로젝트의 보충 자료로 시작되었습니다. 하지만 독립적인 콘텐츠로도 꽤 잘 작동한다는 것을 알게 되었습니다. 왜 밑바닥부터 구축해야 할까요? LLM이 실제로 어떻게 작동하는지 배우는 가장 좋은 방법 중 하나입니다. 비유를 들자면, 시스템 작동 원리를 이해하려면 밑바닥부터 핵심 컴포넌트를 만드는 과정이 훌륭한 학습 방법입니다. 물론, 첫 프로젝트로 복잡한 최신 모델을 처음부터 만드는 것부터 시작하고 싶지는 않을 것입니다. 대신, 고카트처럼 더 간단한 구조로 시작하는 것이 더 합리적입니다. 고카트를 만드는 것만으로도 핵심 원리와 각 부품의 기능을 배울 수 있습니다. 기본기를 다지는 것은 매우 중요합니다. 결국, 최고의 엔지니어와 개발자들은 종종 자신만의 작은 프로젝트를 만들고 만지작거리며 경력을 시작했습니다(위대한 인물들을 생각해 보세요). 그들은 뛰어난 감각을 개발하고 우위를 점할 수 있었습니다.

**참고 자료**
*   밑바닥부터 AI 시스템 구축하기 책 (Manning | Amazon)
*   밑바닥부터 AI 시스템 구축하기 GitHub 저장소

**1 - 개발 환경 설정 (0:21:01)**
이 영상은 uv를 사용하여 파이썬(Python) 개발 환경을 설정하는 방법을 설명하는 핵심 영상입니다. 설치 시 특정 환경에서 호환성 문제가 발생할 수 있습니다. 필요하다면 불필요한 라이브러리 설치를 건너뛰셔도 됩니다. 대안으로, 저는 필수 모델 가중치(weights)를 여러 프레임워크 형식으로 변환하여 허깅 페이스(Hugging Face) 모델 허브에 최신 버전을 공유했습니다. 핵심 개념 이해가 중요하므로, 로딩 코드에 대해 미리 걱정할 필요는 없습니다.

**2 - 텍스트 데이터 전처리 (1:28:01)**
이 영상은 LLM 훈련을 위한 효과적인 데이터 준비 단계, 즉 토큰화(tokenization), 바이트 페어 인코딩(byte pair encoding), 데이터 로더(data loaders) 등)의 중요성을 다룹니다. 이 단계는 모델 구축의 핵심 요소입니다. 대규모 텍스트 데이터셋을 효율적으로 처리하고 편향(bias)을 줄이는 실용적인 조언도 포함되어 있습니다.

**3 - 어텐션 메커니즘(attention mechanisms) 구현 (2:15:40)**
이 영상은 어텐션 메커니즘(attention mechanisms) (셀프 어텐션(self-attention), 인과적 어텐션(causal attention), 멀티 헤드 어텐션(multi-head attention))이 어떻게 작동하는지 밑바닥부터 코딩하여 설명하는 필수 영상입니다. 어텐션은 현대 LLM의 핵심이며, 모델이 장거리 의존성(long-range dependencies)을 효과적으로 포착하게 합니다. 자동차 엔진과 유사하게, 모델 핵심 기능을 구현하는 단계입니다.

**4 - LLM 아키텍처 코딩 (2:00:00)**
이 영상은 밑바닥부터 LLM 아키텍처(architecture)를 코딩하는 핵심적인 방법을 다룹니다. 트랜스포머(Transformer)의 인코더-디코더 구조부터 시작하여, 각 구성 요소의 상호 작용을 심층적으로 탐구합니다. 효율적인 모델 설계와 최적화 기법도 논의합니다.

**5 - 대규모 데이터로 사전 훈련 (2:36:44)**
이 영상은 밑바닥부터 LLM을 효과적으로 사전 훈련하는 방법을 설명합니다. 대규모 레이블 없는 데이터셋을 활용하여 모델이 언어의 패턴과 구조를 학습하는 과정을 다룹니다. 사전 훈련의 목표(pre-training objectives)와 손실 함수(loss functions) 선택이 모델 성능에 미치는 영향에 대해 깊이 있게 탐구합니다.

**6 - 특정 작업을 위한 미세 조정(Finetuning) (2:15:29)**
이 영상은 다음 단계로 넘어가기 전에, 미세 조정(finetuning)에 대한 부드러운 소개로 LLM을 분류기(classifier)로 미세 조정(fine-tune)하는 방법(여기서는 스팸 분류 예시를 사용)을 명확히 설명합니다. LLM 활용의 핵심 기술인 전이 학습(transfer learning) 원리를 이해하고, 적은 데이터로도 뛰어난 성능을 달성하는 방법을 배울 수 있습니다.

**7 - 명령어 미세 조정(Instruction Finetuning)과 정렬 (1:46:04)**
마지막으로, 이 영상은 LLM을 명령어 미세 조정(instruction finetune)하는 고급 방법을 설명합니다. 이는 모델이 사용자의 의도를 더 잘 이해하고 특정 지시를 따르도록 훈련시키는 과정입니다. 인간 피드백 기반 강화 학습(RLHF)과 같은 기술을 통해 모델의 정렬(alignment)을 개선하고, 유용하고 안전한 인공지능 시스템을 구축하는 데 기여합니다.

즐겁게 시청하고 탐구해 보세요!

**보너스: LLM의 과거와 현재, 그리고 미래 (2018년부터 현재까지)**
유료 구독자분들께 큰 감사의 마음을 담아, 최신 모델 출시 약 2일 후인 최근에 녹화했던 2.5시간 분량의 (코딩이 아닌) 보너스 영상을 공유하고 싶습니다. 이 강연에서는 2018년 GPT-2 이후로 무엇이 어떻게 변했는지에 초점을 맞춰 현재의 AI 환경에 대해 논의합니다. 기술 발전 속도, 윤리적 고려 사항, 그리고 미래 방향을 조망합니다.

독립적인 연구자로서 여러분의 성원은 저에게 정말 큰 의미가 있습니다! 여러분의 지지는 제가 유익한 콘텐츠를 만들고 기술을 쉽게 풀어낼 원동력입니다. 다가오는 글들에 대한 아이디어가 많고 빨리 작업하고 싶으니, 앞으로 몇 주/몇 달 안에 더 좋은 소식을 전할 수 있기를 바랍니다!