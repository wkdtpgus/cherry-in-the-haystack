최근 몇 년간 추론 모델(reasoning models)과 에이전트(agentic) 관련 주제들은 대규모 언어 모델(LLM) 분야에서 가장 중요한 동향으로 자리 잡았습니다. 작년에 많은 분들이 제가 공유했던 "밑바닥부터 LLM 구축하기: 3시간 코딩 워크숍" (Sebastian Raschka, PhD · 2024년 8월 31일 전체 스토리 읽기)을 통해 LLM의 작동 원리를 이해하는 데 큰 도움을 받으셨습니다. 이러한 긍정적인 반응에 힘입어, 저는 LLM이 어떻게 작동하는지 이해하는 가장 좋은 방법 중 하나인 LLM 코딩 방법에 대한 더 근본적이고 "기초적인" 내용을 담은, 이전 워크숍보다 약 5배 더 길고 상세한 (총 약 15시간) 심층 학습 자료를 여러분과 공유하고자 합니다. 이 자료는 LLM의 내부를 깊이 들여다보고 그 작동 방식을 체계적으로 이해하는 가장 효과적인 방법 중 하나가 될 것입니다.

또한, 안타깝게도 저는 심한 목 부상으로 지난 3주 동안 컴퓨터 작업을 제대로 할 수 없었습니다. 현재는 권고된 수술적 방법을 고려하기 전에 보존적 치료를 시도하고 있습니다. 이제 막 정상 궤도에 오르려던 참에 또 다른 예상치 못한 난관에 부딪히게 되어 최악의 타이밍입니다. 그래서 회복 기간 동안 지난 몇 달 동안 녹화했던 이 영상들을 공유하는 것이 좋은 중간 콘텐츠가 될 것이라고 생각했습니다. 이 자료가 유용하시기를 바라며, 여러분의 성원에 감사드립니다!

이 영상들은 원래 제 **밑바닥부터 대규모 언어 모델 구축하기(Build a Large Language Model (From Scratch))** 책의 보충 자료로 시작되었습니다. 하지만 독립적인 콘텐츠로도 꽤 잘 작동한다는 것을 알게 되었습니다. 왜 밑바닥부터 구축해야 할까요? 아마도 LLM이 실제로 어떻게 작동하는지 배우는 가장 좋고 효율적인 방법일 것입니다. 게다가 많은 독자들이 이 과정을 통해 많은 즐거움을 얻었다고 말해주었습니다. 비유를 들자면, 자동차에 관심이 있고 자동차가 어떻게 작동하는지 이해하고 싶다면, 밑바닥부터 자동차를 만드는 과정을 안내하는 튜토리얼을 따르는 것이 훌륭한 학습 방법입니다. 물론, 첫 프로젝트로 포뮬러 1(Formula 1) 경주용 자동차를 만드는 것부터 시작하고 싶지는 않을 것입니다. 엄청나게 비싸고 지나치게 복잡할 테니까요. 대신, 고카트(go-kart)처럼 더 간단한 것으로 시작하는 것이 더 합리적입니다. 고카트를 만드는 것만으로도 조향 장치가 어떻게 작동하는지, 모터 기능은 어떤지 등을 배울 수 있습니다. 전문 경주용 자동차를 타기 전(또는 자동차 제작에 집중하는 회사나 팀에 합류하기 전)에 트랙에 가져가서 연습하고(그리고 많은 즐거움을 얻을 수 있습니다). 결국, 최고의 경주 드라이버들은 종종 자신만의 고카트를 만들고 만지작거리며 경력을 시작했습니다(미하엘 슈마허(Michael Schumacher)와 아일톤 세나(Ayrton Senna)를 생각해 보세요). 그렇게 함으로써 그들은 자동차에 대한 뛰어난 감각을 개발했을 뿐만 아니라 정비사들에게 귀중한 피드백을 제공하여 다른 드라이버들보다 우위를 점할 수 있었습니다.

**참고 자료**
*   밑바닥부터 LLM 구축하기 책 (Manning | Amazon)
*   밑바닥부터 LLM 구축하기 GitHub 저장소

**1 - 코딩 환경 설정 (0:21:01)**
이 영상은 `uv`를 사용하여 파이썬(Python) 환경을 설정하는 방법을 설명하는 보충 영상입니다. 특히, 이 문서에서 설명하는 "uv pip"를 사용합니다. 최근에는 개발 환경의 일관성과 재현성을 위해 도커(Docker)와 같은 컨테이너 기술을 활용하는 경우도 많지만, 본 영상에서는 기본적인 `uv add` 구문(syntax)을 포함한 `uv` 사용법을 다룹니다.
참고 / 팁: 설치 시 특정 버전의 윈도우(Windows)에서 문제가 발생할 수 있습니다. 윈도우(Windows) 컴퓨터를 사용 중이고 설치에 문제가 있다면 (영상 5에서 OpenAI의 오리지널 GPT-2 모델 가중치(weights)를 로드하기 위한 텐서플로우(TensorFlow) 종속성(dependency) 때문일 가능성이 높음), 걱정하지 마시고 텐서플로우(TensorFlow) 설치를 건너뛰셔도 됩니다 (요구 사항(requirements) 파일에서 텐서플로우(TensorFlow) 줄을 제거하여 이 작업을 수행할 수 있습니다). 대안을 제공하기 위해, 저는 GPT-2 모델 가중치(weights)를 텐서플로우(TensorFlow) 텐서(tensor) 형식에서 파이토치(PyTorch) 텐서(tensors)로 변환하여 허깅 페이스(Hugging Face) 모델 허브(model hub)에 공유했습니다. 이는 영상 5의 가중치(weight) 로딩 부분에 대한 대안으로 사용할 수 있습니다: https://huggingface.co/rasbt/gpt2-from-scratch-pytorch. 어쨌든, 영상 5의 끝까지는 이 가중치(weight) 로딩 코드에 대해 걱정할 필요가 없습니다.

**2 - 텍스트 데이터 작업 (1:28:01)**
이 영상은 LLM 훈련을 위한 텍스트 데이터 준비 단계(토큰화(tokenization), 바이트 페어 인코딩(byte pair encoding), 데이터 로더(data loaders) 등)를 다룹니다.

**3 - 어텐션 메커니즘(attention mechanisms) 코딩 (2:15:40)**
이 영상은 어텐션 메커니즘(attention mechanisms) (셀프 어텐션(self-attention), 인과적 어텐션(causal attention), 멀티 헤드 어텐션(multi-head attention))이 어떻게 작동하는지 밑바닥부터 코딩하여 설명하는 보충 영상입니다. 이는 마치 자동차의 핵심 엔진을 직접 만들어 보는 과정과 같습니다.

**4 - LLM 아키텍처 코딩 (2:20:15)**
이 영상은 대규모 언어 모델의 전체 아키텍처(architecture)를 밑바닥부터 구현하는 방법을 상세히 다룹니다.

**5 - 레이블 없는 데이터로 사전 훈련 (2:36:44)**
이 영상은 밑바닥부터 LLM을 사전 훈련하는 방법을 설명합니다.

**6 - 분류를 위한 미세 조정(Finetuning) (2:15:29)**
LLM을 분류기(classifier)로 미세 조정(fine-tune)하는 방법(여기서는 스팸 분류 예시를 사용)을 통해 미세 조정(finetuning)에 대한 기본적인 이해를 돕습니다. 이는 다음 영상에서 다룰 명령어 미세 조정(instruction finetuning)에 앞선 중요한 단계입니다.

**7 - 명령어 미세 조정(Instruction Finetuning) (1:46:04)**
마지막으로, 이 영상은 LLM을 명령어 미세 조정(instruction finetune)하는 방법을 설명합니다.

이 영상들을 통해 LLM 구축의 즐거움을 만끽하시길 바랍니다!

**보너스: LLM의 과거와 현재 (2018년부터 2026년까지)**
유료 구독자분들께 큰 감사의 마음을 담아, LLM의 과거와 현재에 대한 2.5시간 분량의 (코딩이 아닌) 보너스 영상을 공유합니다. 이 강연에서는 2018년 GPT-2 이후 LLM 기술이 어떻게 발전해왔는지, 그리고 2026년 현재 최신 LLM 환경은 어떠한지 심층적으로 다룹니다. 최근 등장한 라마 3 (Llama 3), 클로드(Claude) 3.5, 그리고 멀티모달(multimodal) LLM의 발전과 같은 주요 변화들을 분석하며, 검색 증강 생성(RAG)과 같은 새로운 패러다임이 LLM 개발에 미치는 영향 및 미래 방향성을 제시합니다.

독립적인 연구자로서 여러분의 지속적인 성원은 저에게 큰 힘이 됩니다. 앞으로도 LLM 분야의 최신 동향과 실용적인 지식을 담은 콘텐츠로 찾아뵙겠습니다. 여러분의 관심과 응원에 다시 한번 감사드립니다!