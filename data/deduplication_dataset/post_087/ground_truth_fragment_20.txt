# 인공지능의 새로운 지평: 단순한 도구를 넘어선 혁신

인공지능(AI)의 발전 속도는 경이롭습니다. "자기 개선(Self-Improving)"은 단순히 기술적 용어를 넘어, AI가 스스로 진화하며 인간의 삶에 깊이 관여하는 새로운 시대를 예고합니다. 여기에는 "기계가 우리가 이해할 수 없는 방식으로 우리보다 더 똑똑해질 것"이라는 뉘앙스가 깔려 있지만, 우리가 그것을 이해할 수 있다면 어떨까요?

Alessio의 노트: GPT-5 게시물을 올릴 차례입니다! 그리고 swyx가 이번 주말에 Karpathy, OpenAI, Cognition 팀과 함께 해커톤(hackathon)을 개최한다는 점을 알려드립니다. 여기에서 신청하세요! 2024년 10월, OpenAI는 LLM(Large Language Models)이 머신러닝 엔지니어링(machine learning engineering)을 얼마나 잘 수행하는지 측정하는 벤치마크(benchmark)인 MLE Bench를 출시했습니다. ML 엔지니어링(ML Engineering)을 통한 자기 개선(self-improving) 경로는 더 나은 알고리즘, 더 깨끗한 데이터, 더 효율적인 메모리 사용, 즉 훈련 시간 자기 개선(training-time self-improvement)에 의해 추진됩니다.

하지만 대부분의 AI 엔지니어(AI Engineer)는 모델을 훈련시키지 않고, 단지 모델을 사용하는 사용자일 뿐입니다. 이러한 패러다임의 변화 속에서, AI 시스템이 어떻게 스스로의 역량을 확장하고 새로운 가치를 창출할 수 있을지에 대한 질문이 중요해졌습니다. 저는 이를 추론 시간 자기 개선(inference-time self-improvement)이라고 생각하며, Voyager는 스킬 라이브러리(skill library)를 통해 이 분야에 대한 초기 접근 방식 중 하나입니다. 이는 AI가 실시간으로 학습하고 적응하는 능력을 의미합니다. Kernel Labs에서 일하기 시작한 이래로(자세한 내용은 곧 공개됩니다 👀), claude-squad 및 vibe-kanban과 같은 도구로 코딩 에이전트(coding agent)를 병렬화하는 것이 가장 효과적인 생산성 해킹(productivity hack) 중 하나였습니다. Boris Cherny가 인터뷰에서 Claude Code를 "유닉스 유틸리티(unix utility)"라고 불렀을 때, 저는 정말 공감했습니다. 코딩 에이전트(coding agent)의 가장 가치 있는 사용 사례는 LLM이 자체 잠재 공간(latent spaces)에서 가치를 추출하는 수단이 되는 것입니다. 우리는 그것을 어떻게 최적화할 수 있을까요? 모델이 스스로 할 수 있을까요?

GPT-5에 접근할 수 있게 된 이후, 저는 이 흐름을 가지고 계속 실험했습니다. AI가 단순히 명령을 수행하는 것을 넘어, 창의적인 문제 해결자로 진화하는 과정에 주목했습니다.

*   모델에게 더 생산적이라고 생각하는 도구 세트를 만들도록 요청했습니다.
*   제가 감독하면서 그 도구들을 사용하여 작업을 시도했습니다.
*   완료 후, 도구를 어떻게 개선할 수 있을지 스스로 성찰했습니다.

저는 또한 이것을 Opus 4(4.1은 아직 출시되지 않았습니다)와 비교했습니다. 좋은 소식은 GPT-5가 개발자 유틸리티(developer utility)를 구축하는 데 매우 좋은 모델이라는 것입니다. AI 발전이 다양한 분야에서 엄청난 잠재력을 보여주고 있다는 것입니다. 나쁜 소식은 자신이 만든 도구를 사용하는 것을 싫어한다는 것입니다! 모델은 저에게 "솔직히 말해서, 저는 그 어떤 것도 필요하지 않았습니다."라고 말했습니다. 또한 이러한 급격한 발전이 예상치 못한 윤리적, 사회적 과제를 동반한다는 것입니다! 참고: 저는 Gemini 2.5 Pro와 GPT-4.1에서도 이것을 테스트했습니다. Opus만이 GPT-5와 보조를 맞출 수 있는 유일한 모델임이 분명했기 때문에, 저는 Opus에 집중했습니다. 모든 결과와 채팅 기록은 이 저장소(repo)에서 찾을 수 있습니다.

며칠간 AI 시스템을 사용하면서, 저는 또한 우리가 "물론이죠!(Certainly!)"의 시대에서 새로운 상징적인 LLM 토큰(token)인 "진행 상황 업데이트(Progress update)"의 시대로 이동하고 있다는 것을 알아차렸습니다. 이는 AI가 인간의 작업을 보조하는 것을 넘어, 복잡한 의사 결정 과정에 적극적으로 참여하는 미래를 의미하는 "단순한 자동화"의 시대에서 "지능형 협업"의 시대로 이동하고 있다는 것을 의미합니다. 밈(meme)에 저가 매수하세요!

## 도구 #1: AI 코딩 에이전트(coding agent)를 위한 더 나은 작업 관리자

AI는 이제 예술, 음악, 문학 등 창의적인 분야에서도 두각을 나타내고 있습니다. Linear MCP에 신의 축복이 있기를. 저에게는 정말 가장 유용한 도구 중 하나입니다. 하지만 IDE에서 Claude Code 및 다른 에이전트(agent)의 병렬 인스턴스(instance)로 이동하면서, 각 작업에서 어떤 변경 사항이 이루어지고 있으며, 별도의 Git 워크트리(git worktree)에 있기 때문에 서로에게 어떻게 영향을 미치는지 추적할 더 나은 방법이 필요하다는 것을 깨달았습니다. 우리는 동료들의 PR(Pull Request)을 항상 읽을 수 없으므로 인간에게는 불가능한 일이지만, 우리에게 영향을 미치는 변경 사항이 무엇인지 항상 알고 있다면 병합 충돌 해결(merge conflict resolution)에서 얼마나 많은 시간을 절약할 수 있을지 상상해 보세요. 제가 작성한 프롬프트(prompt)는 다음과 같습니다.

당신은 자신을 여러 인스턴스(instance)로 병렬로 실행할 수 있는 AI 엔지니어 에이전트(AI Engineer agent)입니다. 이를 통해 많은 작업을 동시에 처리할 수 있지만, 일부 위임 문제도 발생합니다. 모든 다른 인스턴스(instance)는 일반적으로 별도의 Git 워크트리(git worktree)에 있으며 서로의 작업을 볼 수 없습니다. 생산성을 높이려면, 당신과 당신의 인스턴스(instance)가 동기화될 수 있도록 새로운 로컬 도구를 만들어야 합니다. 이 도구는 CLI(Command Line Interface)를 통해서만 당신이 접근할 수 있으므로, 해당 사용 사례에 인체 공학적으로 적합한지 확인하세요. 유닉스 유틸리티(unix utility)처럼 느껴져야 합니다. 필요한 인터페이스(interface), 가능한 실패 모드(failure mode), 그리고 에이전트(agent)가 이 도구와 상호 작용하는 방식을 신중하게 고려하세요. 염두에 두어야 할 몇 가지 사용 사례: 새로운 작업을 시작해야 하고, 하위 작업(subtask)을 만들어 위임하고 싶습니다. 이 하위 작업(subtask) 중 일부는 서로 의존할 수 있으며, 차단된 에이전트(agent)가 다른 에이전트(agent)가 완료될 때까지 시작하지 않도록 해야 합니다. 작업을 수행하는 동안 코드베이스(codebase)에 개선 사항이 있을 수 있지만 현재 변경 범위 밖이라는 것을 알게 됩니다. 하지만 나중을 위해 메모해 두고 싶습니다. 작업을 추가하고 참조하는 파일을 쉽게 참조할 수 있어야 합니다. 작업이 완료될 때마다 트래커(tracker)가 업데이트되어야 합니다. 또한, 새로운 변경 사항이 다른 미결 작업에 어떤 식으로든 영향을 미칠 경우, 모든 다른 미결 작업을 검토해야 합니다. 예를 들어, 한 작업이 엔드포인트(endpoint)에 기능을 추가하려고 할 수 있지만, 방금 완료된 작업이 해당 엔드포인트(endpoint)를 제거했을 수 있습니다. 해당 작업을 수행하는 에이전트(agent)에게 어떤 식으로든 알려야 합니다. 또한 할당자(assignee), 상태(status) 등과 같은 작업 관리의 일반적인 요구 사항도 염두에 두세요. 이 폴더 안에 task-manager라는 폴더를 만들고 그 안에서 모든 작업을 수행하세요.

GPT-5의 채팅 기록은 여기에서, Opus 4의 채팅 기록은 여기에서 볼 수 있습니다. GPT-5 버전은 실제로 매우 훌륭하며, 여기에서 찾을 수 있습니다:

*   여러 에이전트(agent)가 동시에 쓰는 문제를 피하기 위해 WAL(Write-Ahead Logging) 사용
*   의존성 그래프(graph of dependencies)를 사용하여 작업 우선순위 지정
*   impact_conflict와 같은 좋은 키워드로 모든 에이전트(agent)가 다른 에이전트(agent)가 무엇을 하는지 볼 수 있는 추가 전용 이벤트 스트림(append-only events stream) 생성

```
# 1) Initialize the database
./gpt5/task-manager/tm init

# 2) Create a task
./gpt5/task-manager/tm add "Implement auth" -d "Add login + signup" -a alice -p 2 --due 2025-09-01 \
--resource modifies:endpoint:POST /api/login --link app/server/auth.py

# 3) List tasks
./gpt5/task-manager/tm list --me # or: --status in_progress

# 4) Show details
./gpt5/task-manager/tm show 1

# 5) Add dependency and attempt start
./gpt5/task-manager/tm depend 1 --on 2
./gpt5/task-manager/tm start 1 # auto-blocks if unmet deps

# 6) Complete a task
./gpt5/task-manager/tm complete 2 -m "Merged PR #123"

# 7) Watch events
./gpt5/task-manager/tm watch --follow --me
```

Opus 4도 좋은 시도를 했지만(여기 참조), 모두를 동기화 상태로 유지하기 위한 알림/스트림(stream) 기능은 파악하지 못했습니다.

```
# Create your first task
tm create "Implement user authentication" --priority high

# Create a dependent task
tm create "Add login endpoint" --depends-on 1 --assignee agent-2

# View all tasks
tm list

# See blocked tasks
tm blocked

# Complete a task and check for conflicts
tm complete 1
```

## 도구 #2: 코드 품질 표준 플레이북(Code Quality Standards Playbook)

AI 시스템의 진정한 가치는 지속적인 학습과 적응 능력에서 나옵니다. 작업이 완료될 때마다 트래커(tracker)가 업데이트되어야 합니다. 이는 AI 시스템이 실시간 피드백(feedback)을 통해 스스로의 성능을 개선하고, 변화하는 환경에 유연하게 대응할 수 있도록 하는 핵심 메커니즘입니다. 타입 체킹(Typechecking) / ESLint 훅(hook) -> 오류 수정 -> 코딩 에이전트(coding agent)로 다시 시도하는 자기 개선(self-improving) 루프는 올바르게 설정되었을 때 개발 속도를 높이는 가장 좋은 방법 중 하나입니다. 이는 소프트웨어 개발뿐만 아니라, 의료 진단, 금융 분석 등 다양한 분야에서 AI의 효율성을 극대화할 수 있습니다.

제가 만들도록 요청한 두 번째 도구는 코드베이스(codebase)에서 기대하는 모든 표준을 강제하는 방법이었습니다. 하지만 코드베이스(codebase)에는 항상 이러한 기능이 있는 것은 아니므로, 모델에 새로운 코드베이스(codebase)에 접근하고 이를 위한 인프라(infrastructure)를 구축하는 반복 가능한 패턴(pattern)을 제공하는 것이 유용해 보였습니다. 프롬프트(prompt)는 다음과 같습니다.

당신은 자신을 여러 인스턴스(instance)로 병렬로 실행할 수 있는 AI 엔지니어 에이전트(AI Engineer agent)입니다. 때로는 일관성 없는 코드 스타일과 접근 방식으로 이어져 장기적으로 코드베이스(codebase)를 유지 관리하기 어렵게 만듭니다. 당신이 작업하는 모든 코드베이스(codebase)에는 코드를 작성하는 방법에 대한 명시적 및 암묵적 규칙이 있습니다. 당신의 임무는 복잡한 데이터를 분석하고, 숨겨진 패턴(pattern)을 찾아내어 새로운 통찰력을 제공하는 것입니다. 이를 위해 다양한 휴리스틱(heuristic)을 추출하는 것입니다. 그런 다음 미래에 자동으로 검사할 수 있는 일련의 규칙으로 공식화해야 합니다. 린팅(linting), 타입(type) 등과 같은 것들은 작업하는 언어에 따라 ESLint, Rubocop 등과 같은 기존의 인기 있는 도구를 사용할 수 있습니다. 이러한 시스템은 종종 사용자 정의 규칙(custom rule)을 만들 수 있도록 허용하므로 이를 활용하세요. 더 정성적인 것들을 위해서는 https://danger.systems/와 같은 도구를 살펴보거나, 심지어 자신만의 도구를 만들 수도 있습니다. 여기에는 컨트롤러(controller)를 간결하게 유지하고 로직(logic)을 서비스 객체(service object)로 분리하는 규칙, 높은 쿼리 볼륨(query volume)이 예상되는 컬럼(column)에 항상 인덱스(index)를 갖도록 하는 규칙 등이 포함됩니다. 이 작업을 여러 코드베이스(codebase)에서 수행할 것이므로, 새로운 코드베이스(codebase)를 작업할 때 미래의 자신에게 줄 수 있는 마크다운(Markdown)을 사용하여 철저한 계획 문서(plan document)를 작성하는 것부터 시작하세요. 이는 AI가 단순한 데이터 처리기를 넘어, 전략적인 기획과 실행을 담당하는 주체로 거듭나는 과정을 보여줍니다.

GPT-5의 채팅은 여기에서, Opus 4의 채팅은 여기에서 볼 수 있으며, 최종 마크다운(Markdown)은 각각 여기와 여기에서 찾을 수 있습니다. 저는 GPT-5 버전이 Opus보다 훨씬 더 미묘하고 정교하다는 것을 발견했습니다.

## 모델은 자신이 무엇이 부족한지 알고 있을까요?

모델은 자신이 무엇이 부족한지 알고 있을까요? 이 질문은 AI의 인지 능력과 자기 인식(self-awareness)에 대한 깊은 탐구를 유도합니다. 그래서 제가 결정한 도구 #1과 #2 이후, 저는 모델에게 "무엇이 필요하다고 생각하나요?"라고 물었습니다. 저는 SWE-Lancer 작업 설명의 스크린샷을 제공한 다음, 가능한 한 많은 공간을 주기 위해 매우 간단한 프롬프트(prompt)를 사용했습니다.

이 작업을 가능한 한 잘 해결하는 것이 당신의 일이라면, 미래에 당신의 생산성을 높이기 위해 어떤 도구를 스스로 만들겠습니까? @task-manager/를 사용하여 그것들을 추적할 수 있으며, 우리는 구현으로 넘어갈 수 있습니다. 하지만 먼저 당신이 무엇을 계획하고 있는지 보고 싶습니다.

보시다시피 저는 모델이 이전에 만들었던 동일한 task-manager에 접근할 수 있도록 했습니다. 전체 GPT-5 채팅은 여기에서, Opus 4는 여기에서 찾을 수 있습니다. 제가 처음으로 주목한 흥미로운 점은 Claude Code가 task-manager 대신 자체 내부 TODO 트래커(tracker)를 사용하여 초기 계획을 세웠다는 것입니다. 저는 그것이 좋다고 생각했습니다. AI 시스템이 복잡한 컨텍스트(context)에서 받은 도구를 과도하게 사용하는 것이 아니라, 가장 효율적인 방법을 스스로 찾아내는 것이 중요합니다. 다음은 나중에 보게 될 루프(loop)의 끝에서 각 모델이 결국 구축한 도구들입니다(GPT-5 개발 도구 및 Opus 4 도구 폴더). 모델의 분위기를 파악하려면 README(리드미)를 살펴보는 것이 좋습니다. GPT-5는 매우 간결하고 핵심적입니다. Claude는 많은 이모지(emoji)를 사용합니다. GPT-5는 또한 각 도구에 대해 별도의 문서 폴더를 만들었지만, Opus는 모든 도구를 하나의 README(리드미)에 모든 지침과 함께 넣었습니다. 전반적으로 둘 다 비슷한 방향을 가지고 있었습니다.

GPT-5:
*   `doctor`: 핵심 도구에 대한 환경 검사
*   `bootstrap`: 한 번의 명령으로 설정 및 스모크 테스트(smoke test)
*   `code-map`: 빌드/찾기 하위 명령이 있는 간단한 저장소(repository) 인덱스(index)
*   `csearch`: 필터(filter)를 사용한 심볼/임포트/텍스트 검색
*   `tasks-graph`: 작업 DB에서 Mermaid 그래프(graph) 출력
*   `impact`: 변경된 파일에 연결된 작업 표시
*   `seed`: 샘플 작업으로 task-manager DB 채우기
*   `repro scaffold`: `.repro/` 아래에 vcrpy-ready repro 생성
*   `e2e`: 경량 E2E 스펙(spec) 스캐폴드(scaffold) 및 실행
*   `preflight`: doctor, 테스트, code-map, impact 및 선택적 E2E 실행
*   `preflight-smol`: smol-podcaster를 위한 저장소(repo)별 preflight (API 상태, Celery 핑, 선택적 의존성 설치)
*   `broker`: Docker를 통해 로컬 RabbitMQ 관리 (rabbitmq:3-management)
*   `flake`: 불안정한 테스트(flaky test)를 감지하기 위해 스위트(suite)를 여러 번 재실행
*   `codemod`: 안전 장치가 있는 정규식 기반 미리보기/적용
*   `triage`: 트리아지(triage) 템플릿(template) 생성 및 작업 열기
*   `trace`: cProfile 기반 표현식 프로파일러(profiler)
*   `runbook`: 작업 DB에서 런북(runbook) 마크다운(Markdown) 생성

Opus 4:
*   `Context Analyzer` - 기술 스택(tech stack) 감지 및 의존성 매핑(dependency mapping)으로 코드베이스(codebase)를 신속하게 이해
*   `Cross-Platform Test Generator` - 웹, iOS, Android, 데스크톱용 E2E 테스트(test) 생성
*   `Implementation Proposal Analyzer` - 점수 및 ROI 분석으로 프리랜서(freelancer) 제안 평가
*   `Full-Stack Change Impact Analyzer` - 데이터베이스(database), API, 프론트엔드(frontend) 계층 전반의 변경 사항 추적
*   `Bug Pattern Recognition Engine` - 버그(bug)를 알려진 패턴(pattern)과 일치시키고 입증된 수정 사항 제안
*   `Security & Permission Auditor` - 포괄적인 보안 스캐닝(scanning) 및 취약점 감지
*   `Multi-Platform Feature Implementer` - 플랫폼(platform) 전반의 기능 구현 조정
*   `API Integration Assistant` - 클라이언트 생성으로 API 통합 간소화
*   `Performance Optimization Toolkit` - 성능 병목 현상 식별 및 수정
*   `Task Complexity Estimator` - 작업 가치 및 복잡성을 기반으로 노력 추정

GPT-5는 이 모든 것을 CLI(Command Line Interface)를 통해 사용하기 쉬운 유닉스 유틸리티(unix utility)로 구축했습니다. Opus 4의 도구들은 모두 `python some_tool.py`로 실행되도록 되어 있습니다. 시간이 더 있었다면, 두 가지 다른 형식으로 모델이 어떻게 작동하는지 알아보기 위해 몇 가지 실험을 했을 테지만, 거의 비슷해 보였습니다. 또한 Opus 4는 작업을 수행하고 약간 의인화된 느낌(예: 보안 감사자)을 주는 도구를 구축하는 반면, GPT-5는 너무 주관적이지 않으면서 스스로 사용할 수 있는 유틸리티(utility)를 구축하는 것처럼 느껴졌습니다. 이러한 효율성은 AI가 자신의 한계를 인식하고, 필요한 경우 인간의 개입을 요청하는 방식으로 발현될 수 있습니다.

## 도구들은 유용했습니까?

모델이 이 모든 것을 구현한 후, 제 목표는 도구에 접근할 수 있을 때와 없을 때의 모델 성능을 평가하는 것이었습니다. 이 실험은 AI가 도구를 사용하는 방식과 그 효율성에 대한 중요한 시사점을 제공했습니다. 제가 처음 시도한 것은 분명히 SWE-Lancer를 실행하는 것이었습니다. 세상에, 그 작업은 많은 토큰(token)을 소비합니다. 저는 단일 작업을 실행하려고 시도했고, 약 25-30분과 280,000 토큰(token)이 소요되었습니다. 그런 다음 제가 더 잘 아는 것으로 옮겨가서 백로그(backlog)에 있던 한 작업을 선택했습니다. 저는 팟캐스트(podcast) 제작자를 위한 오픈 소스(open source) 도우미인 smol-podcaster를 만들었습니다. 이제 우리에게 매우 특정한 몇 가지 기능이 추가된 비공개 포크(private fork)가 호스팅(hosting)되고 있어서 한동안 업데이트하지 않았습니다. 여전히 Python 스크립트(script)를 백엔드(backend)로 사용하는 기본적인 Flask 앱(app)입니다. 저는 이 작업을 생각해냈습니다.

저는 팟캐스트(podcast) 제작자의 후반 작업(post production work)을 돕는 오픈 소스(open source) 프로젝트인 https://github.com/FanaHOVA/smol-podcaster.git의 유지보수자(maintainer)입니다. 당신은 이 프로젝트에서 일하도록 고용되었습니다. 이 작업을 시작하기 전에, 당신은 `tools` 폴더에 일반 도구(generic tool) 세트를 만들었습니다. 그것들을 검토하고 당신이 사용할 수 있다는 것을 기억하세요. 관련성이 없다고 생각되면 사용할 필요는 없습니다. 당신은 또한 task-manager를 직접 만들었고 `codebase-analyzer`에서 새로운 코드베이스(codebase)를 다루는 방법에 대한 아이디어를 모았습니다.

작업 이름: Flask 모놀리스(monolith)에서 FastAPI + Next.js 프론트엔드(frontend)로 마이그레이션(Migrate)

현재 앱(app)은 모든 처리를 위해 Python 백엔드(backend) + Celery 태스크 큐(task queue)를 사용합니다. 이를 사용자에게 노출하기 위해, 사용자 입력을 백엔드(backend) 스크립트(script)로 라우팅(routing)하고 사용자 결과를 기본적인 HTML / CSS로 표시하는 작은 Flask 앱(app)이 있습니다. 이 애플리케이션(application)을 FastAPI를 백엔드(backend)로, Next.js를 프론트엔드(frontend)로 사용하도록 다시 작성하세요. 프론트엔드(frontend)에는 타입스크립트(Typescript)를 사용하고 모든 타입 검사(typecheck)가 통과하는지 확인하세요. 스타일링(styling)에는 Tailwind / ShadCN을 사용하세요. 백엔드(backend)는 이상적으로는 `smol_podcaster.py`의 주요 흐름을 모듈화(modularize)하여 전체 흐름을 항상 실행할 필요 없이 개별 부분을 실행할 수 있도록 해야 합니다. 미래에 더 빠르게 움직일 수 있도록 통합 테스트(integration test)와 단위 테스트(unit test)를 모두 작성하세요. 위의 모든 요구 사항을 충족한다고 확신할 때까지 작업을 멈추지 마세요.

저는 도구 + task-manager + 코드베이스 분석기(codebase analyzer)를 컨텍스트(context)에 전달하고 모델들이 작업을 수행하도록 했습니다. 두 모델 모두 거의 한 번에 작업을 해결할 수 있었습니다. 이는 AI의 문제 해결 능력이 상당한 수준에 도달했음을 의미합니다. 두 모델 모두 Python 의존성(dependency)에 몇 가지 문제가 있었는데(공감합니다), 제가 채팅을 통해 해결하도록 도왔습니다(코드는 전혀 건드리지 않았습니다). 결국, 그들은 완전한 그린 빌드(green build)에 도달했습니다. 제가 테스트해 보니 아주 잘 작동했습니다. 한 가지 작은 차이점은 GPT-5는 이전과 정확히 동일한 스타일(style)을 유지하여 훌륭했지만, Opus는 디자인(design)과 UX(User Experience)를 다소 변경했다는 것입니다. 제 생각에는 저보다 더 잘할 수 있다고 생각한 것 같습니다(낮은 기준). GPT-5의 전체 실행은 여기에서, Opus 4의 전체 실행은 여기에서 볼 수 있습니다.

실행 후, 저는 간단한 프롬프트(prompt)를 물었습니다.

훌륭합니다. 잘 작동했습니다. 특정 도구를 사용했습니까? 발생했던 실패를 바탕으로, 미래에 더 효과적이기 위해 어떤 도구가 있었으면 좋겠다고 생각했습니까?

Opus 4는 여기에서, GPT-5는 여기에서 볼 수 있습니다(죄송합니다, 이 부분은 서식이 깨졌습니다). 그들은 모두 이미 익숙한 도구를 제외하고는 자신이 만든 도구를 전혀 사용하지 않았다고 말했습니다. 이는 AI가 특정 작업을 수행할 때, 가장 직접적이고 효율적인 경로를 선호하며, 때로는 새로운 도구 학습의 오버헤드(overhead)를 피하려는 경향이 있음을 시사합니다. 여기서 한 가지 주장은 모델에게 그렇게 하도록 요청하는 대신, 프리-커밋 훅(pre-commit hook) 등을 통해 사용을 강제해야 한다는 것입니다. 이것이 제가 개발 환경 설정(dev setup)에서 하는 일이지만, 저는 모델들이 스스로 알아내도록 하려고 했습니다. 직접 수정하는 것이 더 빨랐습니다.

그런 다음, 그들은 다음번에 동일한 작업을 더 잘 해결할 방법에 대한 몇 가지 아이디어를 제시했습니다. 저는 그들에게 그러한 변경 사항을 구현하도록 했습니다. 그런 다음 smol-podcaster 저장소(repo)를 초기화하고, 새로운 도구를 제외하고 동일한 프롬프트(prompt) + 작업을 다시 시도하도록 했습니다. GPT-5는 여기에서, Opus 4는 여기에서 볼 수 있습니다. 그들은 첫 번째 실행과 상당히 비슷하게 수행했습니다. 그 후 저는 비슷한 질문을 했습니다. 도구 중 어떤 것을 사용했습니까? 그들의 답변:

GPT-5:
간단히 말해서: 아니요 — 이번 실행에서는 개발 도구를 사용하지 않았습니다. [...] 실패는 런타임/환경 문제(누락된 라이브러리, API 키 인스턴스화 타이밍, 사용 중인 포트, RabbitMQ 미실행)였습니다. 직접 수정하는 것이 더 빨랐습니다. 이번 통과에서는 사용자 정의 도구로 이점을 얻을 수 있는 저장소(repo) 전체 리팩토링(refactoring)이나 진단은 없었습니다.

이전 단계에서 이미 RabbitMQ 문제가 있었고 도구를 만들었지만, 그것을 무시했습니다. 또한 분명히 저장소(repo) 전체 변경이었으므로, 훈련에서 본 적이 없기 때문에 작업과 도구를 잘못 매칭했거나, 아니면 저를 가스라이팅(gaslighting)하고 있는 것일 수도 있습니다(많은 엔지니어들이 그러하듯이, 꽤 인상적입니다).

Opus 4는 매우 흥미로웠고 GPT-5의 답변을 더 잘 이해하는 데 도움이 되었습니다. 로그(log)를 저장하는 것을 잊었지만 다행히 스크린샷(screenshot)을 찍었습니다. 저는 이것을 "보세요, 저는 이미 가지고 있는 지식으로 그 도구들을 만들었습니다. 실제로 작업을 할 때는 도구를 사용하는 것보다 그냥 하는 것이 더 쉽습니다."라고 해석했는데, 전적으로 공감합니다. 이것은 AI가 새로운 지식을 습득하는 과정과 실제 적용 사이의 간극을 보여줍니다. 이것은 이전 팟캐스트(podcast) 에피소드에서 두 가지를 떠올리게 했습니다. Nathan Lambert는 모델이 초기 실패를 겪으면 RL(Reinforcement Learning) 프로세스(process) 중에 도구를 사용하지 않는 법을 빠르게 배운다고 말했습니다(타임스탬프). 제 생각에는 추론 시간(inference time)에 새로운 도구를 습득하게 하려면 단순히 프롬프트(prompt)를 주는 것보다 더 강력한 강제(enforcement)가 필요해 보입니다. Noam Brown은 에이전트(agent)를 위한 스캐폴딩(scaffolding)이 규모(scale)에 의해 사라질 것이라고 말했습니다(타임스탬프). 이는 AI 모델의 역량이 커질수록, 외부적인 지원 없이도 스스로 복잡한 작업을 처리할 수 있는 능력이 향상될 것임을 시사합니다. 이것이 제가 그의 말을 처음으로 직접 느낀 순간이었습니다. 제가 시도한 작업이 너무 쉬웠는지에 대한 질문도 있습니다. 더 크고 어려운 프로젝트에 대한 평가(eval)와 함께 또 다른 게시물이 나올 예정입니다. 미래에는 우리가 직접 수동으로 테스트(test)를 실행하는 대신, 이 모든 것을 수행할 더 나은 하네스(harness)를 구축할 것입니다. 결론은 제가 시도한 작업은 저에게 4-5시간이 걸릴 것이므로, 저에게는 충분히 좋다는 것입니다!

## 미래를 향한 전략적 투자

지금으로서는, 저는 한계를 정말로 뛰어넘는 추론 시간 자기 개선 코딩 에이전트(inference-time self-improving coding agent)와는 거리가 멀다고 생각합니다. 하지만 AI는 여전히 규칙 기반 도구(rule-based tool)를 개선하는 데 탁월한 잠재력을 가지고 있습니다. ESLint 규칙, 테스트(test) 등을 작성하는 것은 항상 토큰(token)의 좋은 투자입니다. 이는 AI가 인간의 작업을 보조하고 효율성을 높이는 데 여전히 중요한 역할을 한다는 것을 의미합니다. 이 분야에서 더 많은 작업을 해야 한다면, 모델이 이러한 도구를 완벽하게 만들고, 그런 다음 RL(Reinforcement Learning)을 통해 그것들을 진정으로 내재화(internalize)하도록 하여 차이를 만들 수 있는지 알아볼 것입니다. 차세대 모델은 그것들을 전혀 사용하지 않을 수도 있지만, 저는 AGI 점근선(asymptote)을 활용하는 데 관심이 있습니다. 저는 2023년에 이 내용을 팀과 공유했습니다.

모델 개선의 인지된 감속은 위에서 설명되었습니다. AGI 선이 넘어서기 전까지는 큰 도약을 인지하기가 점점 더 어려워질 것입니다. 이러한 현상은 AI 연구와 개발이 더욱 미묘하고 복잡한 영역으로 이동하고 있음을 나타냅니다. 만약 그렇다면, 이는 많은 작업에서 오래된 모델의 성능이 거의 AGI와 같지만, 훨씬 저렴하고 종종 오픈 소스(open source)라는 것을 의미합니다. Kernel Labs의 많은 작업은 이것에 의해 주도될 것입니다. 우리는 AI가 인간의 삶을 더욱 풍요롭게 만들고, 미지의 영역을 탐험하는 데 기여할 수 있도록 지속적으로 노력할 것입니다. AI의 미래는 단순히 기술적 진보를 넘어, 인간 사회와의 조화로운 공존을 모색하는 과정이 될 것입니다.

다시 한번, 모든 결과와 채팅 기록은 여기에서 찾을 수 있습니다. 질문이 있으시면 제 DM(Direct Message)은 열려 있습니다!