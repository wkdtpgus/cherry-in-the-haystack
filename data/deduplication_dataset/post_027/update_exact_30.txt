저는 점점 더 많은 사람들이 제게 “AI가 뇌를 손상시키나요?”라고 묻는 것을 발견합니다. 이는 많은 것을 드러내는 질문입니다. AI가 문자 그대로의 뇌 손상(그렇지 않습니다)을 유발하기 때문이 아니라, 질문 자체가 AI가 우리의 사고 능력에 어떤 영향을 미칠지에 대해 우리가 얼마나 깊이 두려워하는지를 보여주기 때문입니다. 그래서 이 글에서는 AI를 사용하여 마음을 해치기보다는 돕는 방식에 대해 논의하고자 합니다.

하지만 왜 AI가 우리의 뇌를 손상시킨다는 강박관념에 사로잡혀 있을까요? 이러한 생각의 일부는 MIT 미디어 랩(MIT Media Lab)에서 발표된 (다른 기관의 저자들도 참여한) “ChatGPT를 사용하는 당신의 뇌(Your Brain on ChatGPT)”라는 제목의 널리 알려진 논문에 대한 오해에서 비롯됩니다. 실제 연구 내용은 언론 보도보다 훨씬 덜 극적입니다. 이 연구에는 소수의 대학생 그룹이 참여했으며, 이들은 혼자서, 구글(Google)을 사용하거나, 챗GPT(ChatGPT)를 사용하여 (다른 도구 없이) 에세이를 작성하도록 배정되었습니다. 챗GPT를 사용한 학생들은 AI를 사용하지 않은 그룹보다 참여도가 낮았고 에세이에 대해 기억하는 내용도 적었습니다. 4개월 후, 챗GPT 사용자 중 9명에게 챗GPT 없이 에세이를 다시 작성하도록 요청했는데, 이들은 처음에 AI를 사용하지 않았던 학생들보다 더 나쁜 성과를 보였고 (새로운 실험에서는 AI를 사용해야 했지만) 글을 쓸 때 뇌파(EEG) 활동이 더 적었습니다. 물론 뇌 손상은 없었습니다.

이러한 두려움은 새로운 기술에 대한 오랜 인류의 불안감을 반영합니다. 과거 플라톤(Plato)이 글쓰기가 기억력을 약화시킬 것이라 우려했듯이, 전화번호를 외울 필요가 없어진 휴대폰 등장 당시에도 우리는 인지 능력의 퇴화를 걱정했습니다. 오늘날 AI는 단순한 도구를 넘어 우리의 사고 과정 깊숙이 침투하며, 인지 부하(cognitive load)를 줄여주는 동시에 우리의 뇌가 특정 기능을 덜 사용하게 만들 수 있다는 우려를 낳습니다. 이는 기술이 우리의 인지 기능을 확장(extended cognition)하는 동시에, 특정 측면에서는 인지적 위축(cognitive atrophy)을 초래할 수 있다는 복합적인 양면성을 지닙니다.

### 학습하는 뇌

특히 교활한(insidious) 점은 학생들이 좋은 의도를 가지고 있을 때조차도 해가 발생한다는 것입니다. AI는 당신을 돕고 질문에 답하도록 훈련되어 있습니다. 학생들처럼 당신도 숙제에 접근하는 방법에 대한 AI의 지도를 원할 수 있지만, AI는 종종 그냥 답을 줄 것입니다. MIT 미디어 랩(MIT Media Lab) 연구에서 보여주듯이, 이것은 (때로는 불쾌한) 학습을 만들어내는 정신적 노력을 단락(short-circuit)시킨다는 것입니다. 문제는 단순히 부정행위가 아닙니다. 물론 AI가 부정행위를 더 쉽게 만들기는 하지만 말입니다. 문제는 AI의 기본 모드(default mode)가 당신과 함께 일하는 것이 아니라 당신을 위해 일을 하는 것이기 때문에 AI의 도움을 받으려는 정직한 시도조차도 역효과를 낼 수 있다는 것입니다.

이러한 AI의 '답 제공' 방식은 깊이 있는 학습에 필수적인 노력적 처리(effortful processing) 과정을 방해할 수 있습니다. 지식을 내면화하고 스키마(schema)를 형성하기 위해서는 스스로 정보를 탐색하고, 연결하고, 문제를 해결하는 인지적 노력이 필요합니다. AI를 단순히 답을 얻는 수단으로 사용하면 이러한 기회를 놓치게 됩니다. 하지만 AI는 학습을 방해하는 대신 촉진할 수도 있습니다. 예를 들어, 메타인지(metacognition)를 유도하는 프롬프트(prompt)를 통해 AI가 "왜 그렇게 생각하나요?" 또는 "이 개념을 다른 방식으로 설명해 볼 수 있을까요?"와 같이 질문하게 함으로써 학생 스스로 사고 과정을 되돌아보게 할 수 있습니다. 또한, AI 기반의 적응형 학습 플랫폼(adaptive learning platforms)은 개인의 학습 속도와 스타일에 맞춰 콘텐츠를 제공하고, 능동적 회상(active recall)이나 간격 반복(spaced repetition)을 유도하여 학습 효과를 극대화할 수 있습니다.

궁극적으로, 학습할 때 AI가 뇌에 도움이 되는지 해가 되는지를 결정하는 것은 AI의 사용 여부가 아니라 **어떻게 AI를 사용하는지**입니다. AI에게 숙제를 도와달라고 요청하는 것에서 벗어나 튜터(tutor)로서 학습을 돕도록 하는 것이 유용한 단계입니다. 불행히도, 대부분의 AI 모델(AI models)의 기본 버전(default version)은 주제에 대해 튜터링(tutoring)하기보다는 답을 주려고 하므로, 특화된 프롬프트(prompt)를 사용하고 싶을 수 있습니다. 완벽한 튜터 프롬프트(tutor prompt)를 개발한 사람은 없지만, 일부 교육 연구에서 사용되었고 당신에게 유용할 수 있는 프롬프트가 있으며, 와튼 생성형 AI 랩 프롬프트 라이브러리(Wharton Generative AI Lab prompt library)에서 더 많은 정보를 찾을 수 있습니다. 자유롭게 수정하세요 (크리에이티브 커먼즈(Creative Commons) 라이선스 하에 있습니다).

튜터로서 AI를 활용하는 구체적인 방법 중 하나는 AI에게 능동적인 질문을 유도하는 프롬프트를 주는 것입니다. 예를 들어, "이 개념을 5살 아이가 이해할 수 있도록 쉽게 설명해 줘" 또는 "이 주제에 대해 내가 흔히 가질 수 있는 오해 3가지를 지적하고 바로잡아 줘"와 같이 요청할 수 있습니다. 또한, "내 이해도를 점검할 수 있는 객관식 문제를 5개 만들어 줘"와 같이 스스로 학습 성과를 평가하게 할 수도 있습니다. 이러한 상호작용은 AI를 단순한 정보 제공자가 아닌, 학습을 위한 대화형 파트너로 만듭니다. 결국, AI의 교육적 활용은 기술 자체의 발전뿐만 아니라, 인간 교육자가 AI를 교육 과정에 효과적으로 통합하고 학습자의 메타인지를 증진시키는 방법을 설계하는 능력에 달려 있습니다.

### 창의적인 뇌

AI는 아이디어 생성, 패턴 인식, 그리고 다양한 조합을 통해 창의성을 증진시키는 데 탁월한 능력을 보여줍니다. 특히 발산적 사고(divergent thinking) 측면에서 인간의 역량을 뛰어넘는 결과를 내놓기도 합니다. 하지만 진정한 창의성은 단순히 많은 아이디어를 내는 것을 넘어, 그 아이디어들을 평가하고, 연결하고, 의미를 부여하며, 특정 목표에 맞게 수렴하는 과정(convergent thinking)을 포함합니다. AI는 이러한 수렴적 사고와 인간 고유의 감성, 경험, 직관을 대체하기보다는 보완하는 "인간-AI 협업(human-AI collaboration)" 모델에서 가장 큰 잠재력을 발휘합니다. AI는 작가에게 새로운 시놉시스를, 디자이너에게 다양한 시각적 레퍼런스를 제공하는 등 창작의 초기 단계에서 강력한 조력자가 될 수 있습니다.

AI가 생성한 아이디어에 앵커링(anchoring)되는 것을 방지하고 진정한 창의성을 발휘하기 위해서는 사용 방식의 순서가 중요합니다. 먼저 자신만의 아이디어를 충분히 탐색하고 기록한 다음, AI를 활용하여 이를 확장하거나 변형하는 것이 효과적입니다. 예를 들어, "내 아이디어 A를 전혀 다른 3가지 장르의 이야기로 변형해 줘" 또는 "이 제품 아이디어를 10대와 노년층을 위한 버전으로 각각 개발해 줘"와 같이 구체적인 제약을 주어 AI의 발산적 사고를 유도할 수 있습니다. 또한, AI에게 "내 아이디어의 가장 큰 약점은 무엇이고, 어떻게 개선할 수 있을까?"와 같이 비판적 관점을 요청하여 아이디어를 정교화하는 데 활용할 수도 있습니다. AI의 결과물을 맹목적으로 수용하기보다는, 인간의 비판적 사고와 미적 판단으로 걸러내고 재구성하는 과정이 필수적입니다.

많은 작가들이 "글쓰기는 사고이다"라고 주장하듯이, 글을 쓰는 행위는 아이디어를 명확히 하고 심화하는 과정입니다. 이 원칙은 AI 시대에도 변함없이 중요합니다. 저의 경우, 글의 초고를 작성할 때는 AI의 도움 없이 오직 저의 생각으로만 채워 넣습니다. 글쓰기가 곧 사고의 과정이기 때문입니다. 초고가 완성된 후에는 AI를 정교한 편집 보조 도구로 활용합니다. 예를 들어, AI에게 "이 글의 주장이 논리적으로 타당한지 분석하고, 논리적 비약이 있다면 지적해 줘" 또는 "이 문단의 어조를 더 설득력 있게 바꾸려면 어떻게 해야 할까?"와 같이 요청합니다. AI는 스타일, 어조, 문법, 심지어 논리적 흐름에 대한 객관적인 피드백을 제공하여 글을 다듬고 가능성을 확장하는 데 큰 도움을 줍니다. 핵심은 사고의 주도권을 인간이 쥐고, AI를 그 사고를 증폭시키는 도구로 사용하는 것입니다.

### 집단 지성(Collective Brain)

팀워크와 회의는 이상적으로는 집단 지성을 통해 시너지를 창출해야 하지만, 현실에서는 비효율과 불균형이 발생하기 쉽습니다. AI는 이러한 전통적인 협업의 한계를 넘어서는 새로운 가능성을 제시합니다. 단순히 회의록을 요약하는 것을 넘어, AI는 회의 전 아젠다를 사전 분석하여 예상되는 논점이나 잠재적 갈등 요소를 식별할 수 있습니다. 또한, 회의 중에는 익명 피드백(anonymous feedback) 시스템을 통해 모든 참가자의 의견을 수렴하고, 소극적인 참여자도 자신의 생각을 자유롭게 표현할 수 있는 심리적 안전(psychological safety)을 조성하는 데 기여할 수 있습니다.

AI는 회의의 객관적인 관찰자(objective observer) 역할도 수행할 수 있습니다. 누가 가장 많이 발언하는지, 누가 자주 말을 끊는지 등 대화 패턴을 분석하여 팀 내 발언권의 불균형을 파악하고, 진행자에게 적절한 개입을 제안할 수 있습니다. 브레인스토밍(brainstorming) 세션에서는 AI가 모든 아이디어를 빠짐없이 기록하고 범주화하며, 심지어 "악마의 변호인(devil's advocate)" 역할을 수행하여 제안된 아이디어의 약점을 미리 파악하고 개선점을 찾는 데 도움을 줄 수도 있습니다. 이러한 AI의 활용은 인간 진행자의 부담을 줄이고, 팀이 보다 효율적이고 포괄적인 의사결정을 내릴 수 있도록 지원합니다.

물론, AI를 집단 지성에 통합하는 과정에는 윤리적 고려가 필수적입니다. 데이터 프라이버시, 알고리즘 편향(algorithmic bias), 그리고 복잡한 인간 상호작용을 정량화된 지표로 환원하려는 위험에 대한 인식이 필요합니다. AI는 인간의 비판적 사고나 감성 지능을 대체하는 것이 아니라, 오히려 인간 진행자와 참가자들이 본질적인 문제 해결과 창의적 사고에 더 집중할 수 있도록 역량을 강화하는 도구로 활용되어야 합니다. 팀 내에서 AI 활용에 대한 투명성을 확보하고, 그 한계를 명확히 인지하는 것이 중요합니다.

### “뇌 손상”에 반대하며

AI는 우리의 뇌를 손상시키지 않지만, 생각 없는 사용은 우리의 사고를 손상시킬 수 있습니다. 위험에 처한 것은 우리의 뉴런(neuron)이 아니라 우리의 사고 습관입니다. AI로 자동화하거나 대체할 가치가 있는 작업은 많지만 (우리는 계산기로 하는 수학을 애도하는 일은 거의 없습니다), 우리의 사고가 중요한 작업도 많습니다. 이러한 문제에 대해 연구는 우리에게 명확한 답을 줍니다. 작업의 인간적인 부분을 유지하고 싶다면: 먼저 생각하고, 먼저 쓰고, 먼저 만나세요.

궁극적으로 AI는 우리의 인지적 파트너(cognitive partner)가 될 수 있으며, 인간의 능력을 증강(human-AI augmentation)시키는 강력한 도구입니다. AI가 우리의 뇌를 퇴화시키는 것이 아니라, 올바른 방식으로 사용될 때 우리의 인지적 지평을 확장하고 더 복잡한 문제에 도전할 수 있도록 돕는다는 점을 이해해야 합니다. 이를 위해서는 우리 스스로 AI 활용 능력(AI literacy)과 비판적 사고(critical thinking) 능력을 키워야 합니다. AI가 제공하는 편리함에 무조건적으로 의존하기보다는, 언제 AI를 활용하고 언제 스스로 사고해야 할지 현명하게 선택하는 것이 중요합니다. 우리의 뇌는 안전하지만, 우리의 사고는 우리가 어떻게 AI를 다루느냐에 달려 있습니다. 의도적인 선택을 통해 우리는 AI와 함께 더욱 강력한 인지적 미래를 만들어갈 수 있습니다.

구독 공유