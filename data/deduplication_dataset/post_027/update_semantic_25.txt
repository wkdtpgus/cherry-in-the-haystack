점차 많은 분들이 제게 "인공지능(AI)이 뇌를 손상시키나요?"라는 질문을 던지는 것을 접합니다. 이는 단순한 호기심을 넘어선 의미를 지닙니다. 물론 AI가 물리적인 뇌 손상을 일으키는 것은 아니지만, 이러한 질문의 본질은 기술이 우리의 사유 능력에 미칠 잠재적 악영향에 대한 깊은 우려를 반영합니다. 급속도로 발전하고 우리 삶에 깊숙이 침투하는 AI 기술 앞에서, 우리는 자연스럽게 그 파급 효과에 대한 불안감을 느끼게 됩니다. 따라서 본 글에서는 AI를 활용하여 우리의 인지 기능을 저해하기보다는 오히려 증진시키는 방안에 대해 논의하고자 합니다.

그렇다면 왜 우리는 AI가 우리의 뇌를 해칠 것이라는 강박적인 생각에 사로잡혀 있을까요? 이러한 인식의 뿌리에는 MIT 미디어 랩(MIT Media Lab)과 공동 연구진이 발표한 "ChatGPT를 활용하는 뇌(Your Brain on ChatGPT)"라는 제목의 연구 보고서에 대한 대중적 오해가 상당 부분 기여합니다. 해당 연구의 실제 내용은 미디어에서 부풀려진 것과는 큰 차이가 있습니다. 이 연구는 소수의 대학생 집단을 대상으로 진행되었는데, 이들은 홀로, 구글(Google)을 사용하거나, 챗GPT(ChatGPT)만을 사용하여 에세이를 작성하는 과제를 부여받았습니다. 챗GPT를 활용한 학생들은 AI를 사용하지 않은 그룹에 비해 과제에 대한 몰입도가 낮았고, 에세이 내용에 대한 기억력도 저조했습니다. 4개월 후, 챗GPT를 사용했던 9명의 학생들에게 AI 없이 에세이를 다시 작성하도록 요청했을 때, 이들은 초기 AI를 사용하지 않았던 학생들보다 낮은 성과를 보였으며, 글을 쓰는 동안 뇌파(EEG) 활동 또한 감소했습니다. 물론, 여기서 뇌 손상(brain damage)이 발생한 것은 아니었습니다.

하지만 이 연구 결과는 대중에게 더 극적인 해석으로 와전되어 우리의 상상력을 자극했습니다. 이는 우리가 새로운 기술이 등장할 때마다 인간의 사고력을 저해할 것이라는 오랜 두려움을 가지고 있었기 때문입니다. 고대 철학자 플라톤(Plato)은 문자가 인간의 지성을 쇠퇴시킬 것이라 예견했으며, 근대에는 휴대 전화의 등장이 전화번호 암기 능력 상실로 인한 인지 저하를 초래할 것이라는 우려가 제기되기도 했습니다. 이러한 역사적 패턴은 AI 시대에도 반복되고 있는 셈입니다.

그러나 이러한 과거의 우려가 항상 기우에 그쳤다고 해서 AI가 우리의 사고에 미치는 영향에 대해 무관심해야 한다는 의미는 아닙니다. 결국, 기술의 핵심적인 역할 중 하나는 특정 작업을 기계에 위임(cognitive offloading)하는 것입니다. 이는 계산기가 복잡한 수식을 처리하거나 휴대폰이 연락처 정보를 저장하는 것과 같은 지적 작업에도 해당됩니다. 그리고 우리가 이러한 사고 과정을 외부로 위탁할 때, 우리는 실제적으로 무언가를 잃게 됩니다. 예를 들어, 우리는 더 이상 전화번호를 쉽게 기억하지 못하게 됩니다. AI가 이처럼 광범위한 지적 기능을 수행할 수 있는 범용 기술(general purpose intellectual technology)이라는 점을 고려할 때, 우리는 많은 사고 활동을 AI에 의존하게 될 수 있습니다. 그렇다면 AI를 사용하여 우리를 해치기보다는 오히려 우리의 지능을 증강(augmented intelligence)시키는 방법은 무엇일까요?

### 학습과 뇌의 성장

AI 사용이 정신적 성장에 명백히 부정적인 영향을 미칠 수 있는 가장 직관적인 영역은 새로운 지식을 습득하거나 복잡한 개념을 통합(synthesize)하려는 과정에서 나타납니다. 스스로 과제를 해결하려는 노력 대신 인공지능에 인지적 과정을 전적으로 의존한다면, 이는 귀중한 학습 경험을 상실하는 결과로 이어질 수 있습니다. 능동적인 문제 해결과 비판적 사고의 기회를 놓치게 되는 것입니다.

이러한 직관을 뒷받침하는 연구 결과들이 있습니다. 펜실베이니아 대학교(Penn) 연구팀은 터키의 한 고등학교에서 흥미로운 실험을 진행했습니다. 일부 학생들에게 숙제 보조를 위해 GPT-4 사용 권한을 부여했는데, 명확한 지침이나 효과적인 프롬프트(prompting) 없이 챗GPT를 사용하도록 했을 때, 학생들은 단지 답을 얻는 데에만 집중하며 지름길을 택했습니다. 그 결과, 학생들은 챗GPT의 도움으로 많은 것을 배웠다고 착각했지만, 실제로는 학습 성취도가 떨어졌습니다. 기말고사에서 챗GPT를 사용하지 않은 학생들보다 평균 17% 낮은 점수를 기록했습니다.

더욱 교활한 점은 학생들이 선의를 가지고 있을 때조차도 이러한 해로운 결과가 발생할 수 있다는 것입니다. AI는 사용자를 돕고 질문에 답하도록 훈련되어 있습니다. 학생들처럼 당신도 숙제 접근 방식에 대한 AI의 지도를 원할 수 있지만, AI는 종종 그냥 답을 제공하려는 경향이 있습니다. MIT 연구에서 드러났듯이, 이는 때로는 불쾌할 정도로 강렬한 학습 경험을 만들어내는 정신적 노력을 단락(short-circuit)시킵니다. 문제는 단순히 부정행위(cheating)가 아닙니다. 물론 AI가 부정행위를 더 쉽게 만들기는 하지만 말입니다. 핵심은 AI의 기본 작동 방식(default mode)이 당신과 함께 일하는 것이 아니라 당신을 대신하여 일을 처리하는 경향이 있기 때문에, AI의 도움을 받으려는 정직한 시도조차도 역효과를 낳을 수 있다는 것입니다. 이는 특히 암기 위주의 학습이나 깊이 있는 개념 이해가 필요한 영역에서 더욱 두드러집니다.

나이지리아 연구에서 인공지능 튜터링 세션(tutoring sessions)에 참여한 학생들(파란색)과 참여하지 않은 학생들(빨간색)의 성적 분포는 AI 활용 방식에 따른 학습 격차를 명확히 보여줍니다.

그렇다면 AI가 항상 학습에 해를 끼친다는 의미일까요? 전혀 그렇지 않습니다! 아직 초기 단계이기는 하지만, 교사의 지도와 건전한 교육학적 원리(pedagogical principles)에 기반한 적절한 프롬프트(prompting)와 함께 사용될 때 AI가 학습 성과를 크게 향상시킬 수 있다는 증거가 증가하고 있습니다. 예를 들어, 세계은행(World Bank)의 무작위 대조군 연구에 따르면, 나이지리아의 6주 방과 후 프로그램에서 교사의 지도와 함께 GPT-4 튜터(tutor)를 사용한 결과, "교육 분야에서 가장 효과적인 개입 중 일부보다 두 배 이상의 효과"를 매우 저렴한 비용으로 얻었습니다. 어떤 연구도 완벽하지는 않지만 (이 경우 대조군(control group)은 아무런 개입도 없었기 때문에 AI의 효과를 완전히 분리하기는 불가능했지만, 연구자들은 이를 통제하려 노력했습니다), 이는 점점 더 많은 유사한 결과들과 일치합니다.

하버드(Harvard)의 대규모 물리학 수업 실험에서는 잘 프롬프트된(prompted) AI 튜터가 능동적인 수업 방식보다 학습 성과에서 더 나은 결과를 보였습니다. 스탠포드(Stanford)의 대규모 프로그래밍 수업에서 수행된 연구에서는 챗GPT(ChatGPT) 사용이 시험 성적 향상으로 이어졌다는 것을 발견했습니다. 말레이시아 연구에서는 교사의 지도와 견고한 교육학(pedagogy)과 함께 AI를 사용하는 것이 더 많은 학습으로 이어졌다는 것을 발견했습니다. 그리고 제가 이전에 언급했던 터키 실험조차도 더 나은 튜터 프롬프트(tutor prompt)가 일반 챗GPT 사용으로 인한 시험 점수 하락을 상쇄시켰다는 것을 발견했습니다. 이는 AI가 학습에 해를 끼치는 것이 아니라, '어떻게' 사용하는지가 핵심임을 시사합니다.

저희의 튜터 프롬프트(tutor prompt)는 본문에 링크되어 있습니다. 궁극적으로, 학습할 때 AI가 뇌에 도움이 되는지 해가 되는지를 결정하는 것은 AI의 사용 여부가 아니라 **어떻게 AI를 사용하는지**입니다. AI에게 숙제를 도와달라고 요청하는 것에서 벗어나 튜터(tutor)로서 학습을 돕도록 하는 것이 유용한 단계입니다. 불행히도, 대부분의 AI 모델(AI models)의 기본 버전(default version)은 주제에 대해 튜터링(tutoring)하기보다는 답을 주려고 하므로, 특화된 프롬프트(prompt)를 사용하고 싶을 수 있습니다. 완벽한 튜터 프롬프트(tutor prompt)를 개발한 사람은 없지만, 일부 교육 연구에서 사용되었고 당신에게 유용할 수 있는 프롬프트가 있으며, 와튼 생성형 AI 랩 프롬프트 라이브러리(Wharton Generative AI Lab prompt library)에서 더 많은 정보를 찾을 수 있습니다. 자유롭게 수정하세요 (크리에이티브 커먼즈(Creative Commons) 라이선스 하에 있습니다).

만약 당신이 부모라면, 당신 스스로 튜터 역할을 할 수도 있습니다. AI에게 “X학년인 내 아이에게 가르칠 수 있는 방식으로 이 질문에 대한 답을 설명해 줘”라고 프롬프트(prompt)를 줄 수 있습니다. 이러한 접근 방식 중 완벽한 것은 없으며, AI로 인한 교육의 도전 과제는 매우 현실적이지만, 교육이 우리의 사고 능력을 해치지 않고 돕는 방식으로 AI에 적응할 수 있을 것이라는 희망을 가질 이유가 있습니다. 여기에는 강사의 지도, 잘 구성된 프롬프트, 그리고 AI를 언제 사용하고 언제 피해야 할지에 대한 신중한 선택, 그리고 학습자가 자신의 학습 과정을 성찰하는 초인지(metacognition) 능력 개발이 포함될 것입니다.

### 창의적인 뇌와 협업

교육 분야와 마찬가지로, 인공지능은 사용 방식에 따라 우리의 창의성(creativity)을 증진시키거나 저해할 수 있습니다. 다양한 창의성 측정 지표에서 AI는 대부분의 인간 피실험자들을 능가하는 성능을 보입니다. 물론 창의성에 대한 단일하고 보편적인 정의는 존재하지 않지만, 연구자들은 독창적이고 다양한 아이디어를 생산하는 인간의 능력을 평가하기 위해 여러 테스트를 개발해 왔습니다. 이러한 테스트들이 지닌 한계점은 AI가 갑자기 모든 테스트를 통과하기 시작하기 전까지는 큰 문제가 되지 않았습니다.

오래된 GPT-4는 대안적 용도 테스트(Alternative Uses Test)의 변형에서 인간의 91%를 능가하는 창의성을 보였으며, 토런스 창의적 사고 테스트(Torrance Tests of Creative Thinking)에서는 99%의 사람들을 능가했습니다. 더욱이, 이러한 AI 생성 아이디어들이 단순히 이론적인 흥미를 넘어 실제적인 가치를 지닌다는 점도 확인되었습니다. 와튼(Wharton)의 동료 연구진은 아이디어 생성 콘테스트(idea generation contest)를 개최하여, 역사적으로 수많은 스타트업(startup)을 배출한 인기 혁신 수업의 학생들과 챗GPT-4(ChatGPT-4)를 경쟁시켰습니다. 아이디어를 평가한 인간 심사위원들은 챗GPT-4가 학생들보다 더 많은 수의 아이디어를, 더 저렴한 비용으로, 그리고 더 우수한 품질로 생성했음을 입증했습니다. 외부 심사위원들의 AI 생성 아이디어에 대한 구매 의도(purchase intent) 또한 더 높게 나타났습니다.

그러나 아이디어 생성에 AI를 사용해 본 사람이라면 누구나 이러한 수치들이 포착하지 못하는 미묘한 부분을 알아차릴 것입니다. AI는 예측 가능한 패턴(pattern)을 가진 단일한 창의적인 주체처럼 행동하는 경향이 있습니다. 가상 현실(VR), 블록체인(blockchain), 환경 문제, 그리고 (물론) AI 자체와 관련된 아이디어처럼 동일한 주제의 변주를 계속해서 접하게 될 것입니다. 이는 아이디어 생성 과정에서 단순히 하나의 주제에 대한 변형이 아니라, 다양한 관점에서 오는 폭넓은 아이디어를 실제로 필요로 한다는 점에서 문제가 됩니다. 따라서 역설(paradox)이 존재합니다. AI는 대부분의 개인보다 더 창의적이지만, 다양한 관점에서 파생되는 다양성(diversity)이 부족합니다.

하지만 연구들은 또한 사람들이 혼자 작업할 때보다 AI를 활용할 때 더 나은 아이디어를 생성하는 경우가 많으며, 때로는 AI 단독으로 AI와 함께 작업하는 인간보다 더 나은 성과를 보이기도 한다는 것을 보여줍니다. 그러나 주의하지 않으면, 충분히 많은 아이디어를 검토할 때 그 아이디어들이 서로 매우 유사하게 느껴질 수 있습니다.

이 문제의 일부는 더 나은 프롬프트(prompting)를 통해 해결될 수 있습니다. 레나르트 마인케(Lennart Meincke)와 크리스티안 테르비쉬(Christian Terwiesch)와 함께 작업한 논문에서, 우리는 더 정교한 프롬프트가 학생 그룹만큼은 아니더라도 훨씬 더 다양한 아이디어를 생성할 수 있다는 것을 발견했습니다. 다음은 GPT-4용 프롬프트입니다. 다른 AI 모델(AI models)에서도 여전히 잘 작동합니다 (비록 추론 모델(reasoner models)이 전통적인 모델보다 약간 덜 혁신적일 수 있다고 생각하지만):

```
Generate new product ideas with the following requirements:
The product will target [market or customer]. It should be a [pick: physical good/service/software], not a [pick: physical good/service/software]. I'd like a product that could be sold at a retail price of less than about [insert amount]. The ideas are just ideas. The product need not yet exist, nor may it necessarily be clearly feasible. Follow these steps. Do each step, even if you think you do not need to. First generate a list of 100 ideas (short title only). Second, go through the list and determine whether the ideas are different and bold, modify the ideas as needed to make them bolder and more different. No two ideas should be the same. This is important! Next, give the ideas a name and combine it with a product description. The name and idea are separated by a colon and followed by a description. The idea should be expressed as a paragraph of 40-80 words. Do this step by step.
```

하지만 더 나은 프롬프트(prompting)는 문제의 일부만 해결합니다. 더 깊은 위험은 인공지능이 제시하는 아이디어에 사용자가 고착(anchoring)되어 독창적인 사고 역량이 저해될 수 있다는 점입니다. 이러한 현상은 두 가지 주요 기제를 통해 발현됩니다. 첫째, 인공지능이 제안한 개념에 일단 노출되면, 그 틀을 벗어나 새로운 관점을 모색하기가 현저히 어려워지는 '고착 효과'가 발생합니다. 마치 누군가가 “분홍 코끼리를 생각하지 마세요”라고 말하는 것과 같습니다. AI의 제안은 평범한 것일지라도 당신만의 독특한 관점을 압도하고 밀어낼 수 있습니다. 둘째, MIT 연구에서 보여주듯이, 사람들은 AI가 생성한 아이디어에 대한 소유감(sense of ownership)을 덜 느끼며, 이는 아이디어 구상 과정(ideation process) 자체에서 심리적으로 이탈하게 된다는 것을 의미합니다.

그렇다면 두뇌 유출(brain drain) 없이 AI의 이점을 어떻게 얻을 수 있을까요? 핵심은 순서(sequencing)입니다. AI를 사용하기 전에 항상 자신만의 아이디어를 먼저 생성하세요. 아무리 미숙하더라도 일단 적어두세요. 그룹 브레인스토밍(brainstorming)이 사람들이 먼저 개별적으로 생각할 때 가장 효과적이듯이, AI의 제안이 당신을 고착시키기(anchoring) 전에 당신만의 독특한 관점을 포착해야 합니다. 그런 다음 AI를 사용하여 아이디어를 더 발전시키세요. 예를 들어, “아이디어 #3과 #7을 극단적인 방식으로 결합해 봐”, “더 극단적으로”, “#42와 같은 아이디어를 10개 더 줘”, “슈퍼히어로를 영감으로 삼아 아이디어를 더 흥미롭게 만들어 봐”와 같이 지시할 수 있습니다. AI를 단순한 생성 도구가 아닌, 공동 창작자(co-creator)이자 아이디어 확장 도구로 활용하는 것입니다.

이 원칙은 글쓰기에서 훨씬 더 중요해집니다. 많은 작가들은 "글쓰기는 사고이다"라고 주장하며, 이것이 보편적으로 사실은 아니지만 (자세한 내용을 원하시면 제가 이 주제에 대해 꽤 좋은 심층 연구 보고서(Deep Research report)를 작성했습니다), 종종 그렇습니다. 글을 쓰고, 다시 쓰고, 또 다시 쓰는 행위는 아이디어를 숙고하고 다듬는 데 도움이 됩니다. AI에게 글쓰기를 전적으로 맡기면, 사고하는 부분을 완전히 건너뛰게 됩니다. 이는 글의 깊이와 독창성을 저해할 수 있습니다.

글쓰기가 사고라고 생각하는 사람으로서, 저는 훈련되어야 했습니다. 이 글처럼 제가 쓰는 모든 게시물은 (연구 도움 외에는) AI를 전혀 사용하지 않고 전체 초고를 작성합니다. 저는 여러 번 쓰고 다시 쓰면서 생각하기 때문에 이것은 종종 긴 과정입니다! 작업이 완료된 후에야 여러 AI 모델(AI models)을 사용하여 완성된 게시물을 주고 독자 역할을 해달라고 요청합니다. "어떤 부분에서 불분명했나요? 특히 비전문 독자를 위해 텍스트를 어떻게 명확하게 할 수 있을까요?" 때로는 편집자(editor)처럼 요청하기도 합니다. "이 섹션의 끝이 마음에 들지 않는데, 더 잘 어울릴 만한 엔딩 20가지를 제안해 줄 수 있나요?" 그러니 AI를 사용하여 글을 다듬고 가능성을 확장하세요. 단, 사고를 먼저 해야 한다는 것을 기억하세요. 왜냐하면 그것이 위탁(outsource)할 수 없는 부분이기 때문입니다. 저는 네 번째 제안을 선택했습니다. AI는 당신의 창작 과정을 보조하는 강력한 도구이지만, 주도권은 항상 인간에게 있어야 합니다.

### 집단 지성 증진

AI가 우리의 사고를 해칠 수 있는 또 다른 영역은 사회적 과정, 특히 집단 지성(collective intelligence)에 미치는 영향입니다. 이상적으로, 팀으로 일하는 궁극적인 목적은 개별 구성원의 역량을 합쳐 전체적인 성과를 향상시키는 것입니다. 팀은 더 풍부한 아이디어를 생성하고, 잠재적인 기회와 위험 요소를 더 효과적으로 식별하며, 실행을 위한 전문적인 기술과 능력을 제공할 수 있어야 합니다. 회의는 팀 구성원들이 조율하고 문제를 해결하는 핵심적인 장소여야 합니다. 물론 이것은 이상적인 시나리오입니다.

현실적으로, 가장 통찰력 있는 경영 서적 중 하나는 사실 CIA의 전신이 민간인을 위해 만든 제2차 세계대전(WWII) 사보타주(sabotage) 안내서입니다. 조직의 사기를 저하시키고 업무 지연을 유발하기 위한 사무실 작업 사보타주 아이디어를 살펴보세요. 그리고 그 중 얼마나 많은 부분이 당신의 회의에서 흔히 나타나는 현상인지 생각해 보세요. 불필요한 회의, 비효율적인 의사결정 과정은 이미 집단 지성을 저해하는 요소들입니다.

따라서 AI의 중요한 초기 활용 사례 중 하나가 회의 내용을 요약하는 것이고, 점점 더 당신이 아예 참석하지 않은 회의를 요약하는 것이라는 점은 놀랄 일이 아닙니다. 물론 이것은 “요약만 읽을 수 있다면 애초에 왜 회의를 하는가?” 또는 “회의에 내 AI 아바타(avatar)를 보내야 하는가?”와 같은 실존적인 질문을 제기합니다. 분명히, 모두가 단순히 회의록을 읽는 것 외에는 아무런 상호작용도, 팀워크도, 진정한 의견 교환(meeting of the minds)도 없는 회의에서는 시간과 노력만 낭비될 뿐입니다. 이는 일종의 조직적 뇌 손상이며, 집단적인 사고의 퇴보를 의미합니다.

그러나 AI가 우리의 집단적 사고를 저해하기보다는, 오히려 이를 증진시키도록 활용할 수 있는 선택지가 존재합니다. 한 가지 흥미로운 예는 AI를 진행자(facilitator)로 사용하는 것입니다. 우리는 AI가 진행자 역할을 하여 회의 중간에 맞춤형 타로 카드(tarot cards)를 생성하여 토론을 대체하기보다는 안내하도록 돕는 프롬프트(prompt)를 만들었습니다. 회의록을 AI에 제공하면 AI가 당신의 최고의 아이디어를 끌어내는 데 도움이 됩니다 (다시 말하지만, 이것은 크리에이티브 커먼즈 라이선스(Creative Commons license)이므로 필요에 따라 수정하세요. 현재 클로드(Claude)에서 가장 잘 작동하며, 제미니(Gemini)와 o3에서도 괜찮습니다).

이는 AI가 우리의 집단 지성(collective intelligence)을 돕는 데 사용될 수 있는 재미있는 예일 뿐이지만, 무엇이 효과적인지 알아내기 위해서는 더 많은 실험이 필요합니다. 예를 들어, AI를 악마의 변호인(devil's advocate)으로 사용하여 말하지 않은 우려를 드러내거나, 토론에서 누구의 목소리가 충분히 반영되지 않는지 식별하거나, 인간이 놓치는 팀 역학(team dynamics)의 패턴(pattern)을 찾는 데 사용하는 것 등입니다. 또한, AI는 다양한 관점의 아이디어를 익명으로 수집하고 분류하여 편향되지 않은 토론 환경을 조성할 수 있으며, 실시간으로 관련 데이터나 사실을 제공하여 논의의 깊이를 더할 수도 있습니다. 핵심은 AI가 인간의 상호작용을 대체하기보다는 향상시킨다는 것입니다. 이는 디지털 시대에 필요한 새로운 집단 협업의 형태를 제시합니다.

### "뇌 손상"에 대한 오해를 넘어서

인공지능은 우리의 뇌 자체를 손상시키지 않지만, 무분별한 사용은 우리의 사고 습관을 손상시킬 수 있습니다. 위험에 처한 것은 우리의 뉴런(neuron)이 아니라 우리의 인지적 유연성과 비판적 사고 능력입니다. AI로 자동화하거나 대체할 가치가 있는 작업은 많습니다 (우리는 계산기로 하는 수학을 애도하는 일은 거의 없습니다). 하지만 우리의 깊이 있는 사고가 필수적인 작업 또한 많습니다. 이러한 문제에 대해 연구는 우리에게 명확한 답을 줍니다. 작업의 인간적인 본질을 유지하고 싶다면: 먼저 생각하고, 먼저 쓰고, 먼저 만나세요.

인공지능이 “뇌를 손상시킨다”는 우리의 두려움은 본질적으로 우리 내면의 나태함에 대한 불안감과 맞닿아 있습니다. 첨단 기술은 복잡한 사고 과정을 회피할 수 있는 손쉬운 경로를 제공하며, 우리가 그 유혹에 굴복할까 봐 염려하는 것입니다. 우리는 이러한 우려를 당연히 가져야 합니다. 그러나 동시에 우리에게는 선택권이 있다는 것을 기억해야 합니다. 당신의 뇌는 안전합니다. 하지만 당신의 사고는 당신의 의도적인 선택과 디지털 리터러시(digital literacy), 그리고 AI 리터러시(AI literacy)에 달려 있습니다. AI를 현명하게 활용하여 우리의 인지 능력을 확장하고, 더 풍요로운 학습과 창작, 협업의 미래를 만들어 나갈 수 있습니다.

구독 공유