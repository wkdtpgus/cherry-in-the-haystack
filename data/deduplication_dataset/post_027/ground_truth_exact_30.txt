저는 점점 더 많은 사람들이 제게 “AI가 뇌를 손상시키나요?”라고 묻는 것을 발견합니다. 이는 많은 것을 드러내는 질문입니다. AI가 문자 그대로의 뇌 손상(그렇지 않습니다)을 유발하기 때문이 아니라, 질문 자체가 AI가 우리의 사고 능력에 어떤 영향을 미칠지에 대해 우리가 얼마나 깊이 두려워하는지를 보여주기 때문입니다. 그래서 이 글에서는 AI를 사용하여 마음을 해치기보다는 돕는 방식에 대해 논의하고자 합니다.

하지만 왜 AI가 우리의 뇌를 손상시킨다는 강박관념에 사로잡혀 있을까요? 이러한 생각의 일부는 MIT 미디어 랩(MIT Media Lab)에서 발표된 (다른 기관의 저자들도 참여한) “ChatGPT를 사용하는 당신의 뇌(Your Brain on ChatGPT)”라는 제목의 널리 알려진 논문에 대한 오해에서 비롯됩니다. 실제 연구 내용은 언론 보도보다 훨씬 덜 극적입니다. 이 연구에는 소수의 대학생 그룹이 참여했으며, 이들은 혼자서, 구글(Google)을 사용하거나, 챗GPT(ChatGPT)를 사용하여 (다른 도구 없이) 에세이를 작성하도록 배정되었습니다. 챗GPT를 사용한 학생들은 AI를 사용하지 않은 그룹보다 참여도가 낮았고 에세이에 대해 기억하는 내용도 적었습니다. 4개월 후, 챗GPT 사용자 중 9명에게 챗GPT 없이 에세이를 다시 작성하도록 요청했는데, 이들은 처음에 AI를 사용하지 않았던 학생들보다 더 나쁜 성과를 보였고 (새로운 실험에서는 AI를 사용해야 했지만) 글을 쓸 때 뇌파(EEG) 활동이 더 적었습니다. 물론 뇌 손상은 없었습니다.

이러한 두려움은 새로운 기술에 대한 오랜 인류의 불안감을 반영합니다. 과거 플라톤(Plato)이 글쓰기가 기억력을 약화시킬 것이라 우려했듯이, 전화번호를 외울 필요가 없어진 휴대폰 등장 당시에도 우리는 인지 능력의 퇴화를 걱정했습니다. 오늘날 AI는 단순한 도구를 넘어 우리의 사고 과정 깊숙이 침투하며, 인지 부하(cognitive load)를 줄여주는 동시에 우리의 뇌가 특정 기능을 덜 사용하게 만들 수 있다는 우려를 낳습니다. 이는 기술이 우리의 인지 기능을 확장(extended cognition)하는 동시에, 특정 측면에서는 인지적 위축(cognitive atrophy)을 초래할 수 있다는 복합적인 양면성을 지닙니다. 그러나 그렇다고 해서 AI가 우리의 사고에 미치는 영향에 대해 걱정하지 말아야 한다는 의미는 아닙니다. 결국, 기술의 핵심 목적 중 하나는 기계에 작업을 위탁(outsource)하는 것입니다. 여기에는 계산기가 수학을 하도록 하거나 휴대폰이 전화번호를 기록하도록 하는 것과 같은 지적 작업도 포함됩니다. 그리고 우리가 사고를 위탁할 때, 우리는 실제로 무언가를 잃게 됩니다. 예를 들어, 우리는 전화번호를 잘 기억하지 못하게 됩니다. AI가 이처럼 범용 지적 기술(general purpose intellectual technology)이라는 점을 고려할 때, 우리는 우리의 많은 사고를 AI에 위탁할 수 있습니다. 그렇다면 AI를 사용하여 우리를 해치기보다는 돕는 방법은 무엇일까요?

### 학습하는 뇌

AI 사용이 정신적 성장에 분명히 해를 끼칠 수 있는 가장 덜 놀라운 부분은 새로운 지식을 배우거나 종합(synthesize)하려고 할 때입니다. 스스로 작업을 수행하는 대신 AI에 사고를 위탁(outsource)한다면, 학습 기회를 놓치게 될 것입니다.

이러한 직관을 뒷받침하는 증거가 있습니다. 펜실베이니아 대학교(Penn)의 동료들이 터키의 한 고등학교에서 실험을 진행했는데, 일부 학생들에게 숙제를 돕기 위해 GPT-4에 대한 접근 권한을 주었습니다. 안내나 특별한 프롬프트(prompting) 없이 챗GPT를 사용하라는 지시를 받았을 때, 학생들은 지름길을 택해 답을 얻는 데 그쳤습니다. 그래서 학생들은 챗GPT의 도움으로 많은 것을 배웠다고 생각했지만, 실제로는 덜 배웠습니다. 기말고사에서 17% 더 낮은 점수를 받았습니다(챗GPT를 사용하지 않은 학생들과 비교하여).

특히 교활한(insidious) 점은 학생들이 좋은 의도를 가지고 있을 때조차도 해가 발생한다는 것입니다. AI는 당신을 돕고 질문에 답하도록 훈련되어 있습니다. 학생들처럼 당신도 숙제에 접근하는 방법에 대한 AI의 지도를 원할 수 있지만, AI는 종종 그냥 답을 줄 것입니다. MIT 미디어 랩(MIT Media Lab) 연구에서 보여주듯이, 이것은 (때로는 불쾌한) 학습을 만들어내는 정신적 노력을 단락(short-circuit)시킨다는 것입니다. 문제는 단순히 부정행위가 아닙니다. 물론 AI가 부정행위를 더 쉽게 만들기는 하지만 말입니다. 문제는 AI의 기본 모드(default mode)가 당신과 함께 일하는 것이 아니라 당신을 위해 일을 하는 것이기 때문에 AI의 도움을 받으려는 정직한 시도조차도 역효과를 낼 수 있다는 것입니다.

이러한 AI의 '답 제공' 방식은 깊이 있는 학습에 필수적인 노력적 처리(effortful processing) 과정을 방해할 수 있습니다. 지식을 내면화하고 스키마(schema)를 형성하기 위해서는 스스로 정보를 탐색하고, 연결하고, 문제를 해결하는 인지적 노력이 필요합니다. AI를 단순히 답을 얻는 수단으로 사용하면 이러한 기회를 놓치게 됩니다. 하지만 AI는 학습을 방해하는 대신 촉진할 수도 있습니다. 예를 들어, 메타인지(metacognition)를 유도하는 프롬프트(prompt)를 통해 AI가 "왜 그렇게 생각하나요?" 또는 "이 개념을 다른 방식으로 설명해 볼 수 있을까요?"와 같이 질문하게 함으로써 학생 스스로 사고 과정을 되돌아보게 할 수 있습니다. 또한, AI 기반의 적응형 학습 플랫폼(adaptive learning platforms)은 개인의 학습 속도와 스타일에 맞춰 콘텐츠를 제공하고, 능동적 회상(active recall)이나 간격 반복(spaced repetition)을 유도하여 학습 효과를 극대화할 수 있습니다.

나이지리아 연구에서 AI 튜터링 세션(tutoring sessions)에 참여한 학생들(파란색)과 참여하지 않은 학생들(빨간색)의 성적 분포입니다.

그렇다면 AI가 항상 학습에 해를 끼친다는 의미일까요? 전혀 그렇지 않습니다! 아직 초기 단계이기는 하지만, 교사의 지도와 건전한 교육학적 원리(pedagogical principles)에 기반한 좋은 프롬프트(prompting)와 함께 사용될 때 AI가 학습 성과를 크게 향상시킬 수 있다는 증거가 증가하고 있습니다. 예를 들어, 무작위 대조군 세계은행(World Bank) 연구에 따르면 나이지리아의 6주 방과 후 프로그램에서 교사의 지도와 함께 GPT-4 튜터(tutor)를 사용한 결과, "교육 분야에서 가장 효과적인 개입 중 일부보다 두 배 이상의 효과"를 매우 저렴한 비용으로 얻었습니다. 어떤 연구도 완벽하지는 않지만 (이 경우 대조군(control group)은 아무런 개입도 없었기 때문에 AI의 효과를 완전히 분리하기는 불가능하지만, 연구자들은 그렇게 하려고 노력합니다), 이는 점점 더 많은 유사한 결과들과 일치합니다.

하버드(Harvard)의 대규모 물리학 수업 실험에서는 잘 프롬프트된(prompted) AI 튜터가 능동적인 수업보다 학습 성과에서 더 나은 성과를 보였습니다. 스탠포드(Stanford)의 대규모 프로그래밍 수업에서 수행된 연구에서는 챗GPT(ChatGPT) 사용이 시험 성적 향상으로 이어졌다는 것을 발견했습니다. 말레이시아 연구에서는 교사의 지도와 견고한 교육학(pedagogy)과 함께 AI를 사용하는 것이 더 많은 학습으로 이어졌다는 것을 발견했습니다. 그리고 제가 이전에 언급했던 터키 실험조차도 더 나은 튜터 프롬프트(tutor prompt)가 일반 챗GPT 사용으로 인한 시험 점수 하락을 없앴다는 것을 발견했습니다.

저희의 튜터 프롬프트(tutor prompt)는 본문에 링크되어 있습니다. 궁극적으로, 학습할 때 AI가 뇌에 도움이 되는지 해가 되는지를 결정하는 것은 AI의 사용 여부가 아니라 **어떻게 AI를 사용하는지**입니다. AI에게 숙제를 도와달라고 요청하는 것에서 벗어나 튜터(tutor)로서 학습을 돕도록 하는 것이 유용한 단계입니다. 불행히도, 대부분의 AI 모델(AI models)의 기본 버전(default version)은 주제에 대해 튜터링(tutoring)하기보다는 답을 주려고 하므로, 특화된 프롬프트(prompt)를 사용하고 싶을 수 있습니다. 완벽한 튜터 프롬프트(tutor prompt)를 개발한 사람은 없지만, 일부 교육 연구에서 사용되었고 당신에게 유용할 수 있는 프롬프트가 있으며, 와튼 생성형 AI 랩 프롬프트 라이브러리(Wharton Generative AI Lab prompt library)에서 더 많은 정보를 찾을 수 있습니다. 자유롭게 수정하세요 (크리에이티브 커먼즈(Creative Commons) 라이선스 하에 있습니다).

튜터로서 AI를 활용하는 구체적인 방법 중 하나는 AI에게 능동적인 질문을 유도하는 프롬프트를 주는 것입니다. 예를 들어, "이 개념을 5살 아이가 이해할 수 있도록 쉽게 설명해 줘" 또는 "이 주제에 대해 내가 흔히 가질 수 있는 오해 3가지를 지적하고 바로잡아 줘"와 같이 요청할 수 있습니다. 또한, "내 이해도를 점검할 수 있는 객관식 문제를 5개 만들어 줘"와 같이 스스로 학습 성과를 평가하게 할 수도 있습니다. 이러한 상호작용은 AI를 단순한 정보 제공자가 아닌, 학습을 위한 대화형 파트너로 만듭니다. 결국, AI의 교육적 활용은 기술 자체의 발전뿐만 아니라, 인간 교육자가 AI를 교육 과정에 효과적으로 통합하고 학습자의 메타인지를 증진시키는 방법을 설계하는 능력에 달려 있습니다.

만약 당신이 부모라면, 당신 스스로 튜터 역할을 할 수도 있습니다. AI에게 “X학년인 내 아이에게 가르칠 수 있는 방식으로 이 질문에 대한 답을 설명해 줘”라고 프롬프트(prompt)를 줄 수 있습니다. 이러한 접근 방식 중 완벽한 것은 없으며, AI로 인한 교육의 도전 과제는 매우 현실적이지만, 교육이 우리의 사고 능력을 해치지 않고 돕는 방식으로 AI에 적응할 수 있을 것이라는 희망을 가질 이유가 있습니다. 여기에는 강사의 지도, 잘 구성된 프롬프트, 그리고 AI를 언제 사용하고 언제 피해야 할지에 대한 신중한 선택이 포함될 것입니다.

### 창의적인 뇌

AI는 아이디어 생성, 패턴 인식, 그리고 다양한 조합을 통해 창의성을 증진시키는 데 탁월한 능력을 보여줍니다. 특히 발산적 사고(divergent thinking) 측면에서 인간의 역량을 뛰어넘는 결과를 내놓기도 합니다. 하지만 진정한 창의성은 단순히 많은 아이디어를 내는 것을 넘어, 그 아이디어들을 평가하고, 연결하고, 의미를 부여하며, 특정 목표에 맞게 수렴하는 과정(convergent thinking)을 포함합니다. AI는 이러한 수렴적 사고와 인간 고유의 감성, 경험, 직관을 대체하기보다는 보완하는 "인간-AI 협업(human-AI collaboration)" 모델에서 가장 큰 잠재력을 발휘합니다. AI는 작가에게 새로운 시놉시스를, 디자이너에게 다양한 시각적 레퍼런스를 제공하는 등 창작의 초기 단계에서 강력한 조력자가 될 수 있습니다.

하지만 아이디어 생성에 AI를 사용해 본 사람이라면 누구나 이러한 수치들이 포착하지 못하는 무언가를 알아차릴 것입니다. AI는 예측 가능한 패턴(pattern)을 가진 단일한 창의적인 사람처럼 행동하는 경향이 있습니다. VR, 블록체인(blockchain), 환경, 그리고 (물론) AI 자체와 관련된 아이디어처럼 동일한 주제를 계속해서 보게 될 것입니다. 이것은 아이디어 생성에서 하나의 주제에 대한 변형이 아니라 선택할 수 있는 다양한 아이디어를 실제로 원하기 때문에 문제입니다. 따라서 역설(paradox)이 존재합니다. AI는 대부분의 개인보다 더 창의적이지만, 다양한 관점에서 오는 다양성이 부족합니다.

그러나 연구들은 또한 사람들이 혼자 일할 때보다 AI를 사용할 때 더 나은 아이디어를 생성하는 경우가 많으며, 때로는 AI 단독으로 AI와 함께 일하는 인간보다 더 나은 성과를 보이기도 한다는 것을 보여줍니다. 하지만 주의하지 않으면, 충분히 많은 아이디어를 볼 때 그 아이디어들은 서로 매우 유사해 보입니다.

이 문제의 일부는 더 나은 프롬프트(prompting)로 해결할 수 있습니다. 레나르트 마인케(Lennart Meincke)와 크리스티안 테르비쉬(Christian Terwiesch)와 함께 작업한 논문에서, 우리는 더 나은 프롬프트가 학생 그룹만큼 좋지는 않더라도 훨씬 더 다양한 아이디어를 생성할 수 있다는 것을 발견했습니다. 다음은 GPT-4용 프롬프트입니다. 다른 AI 모델(AI models)에서도 여전히 잘 작동합니다 (비록 추론 모델(reasoner models)이 전통적인 모델보다 약간 덜 혁신적일 수 있다고 생각하지만):

```
Generate new product ideas with the following requirements:
The product will target [market or customer]. It should be a [pick: physical good/service/software], not a [pick: physical good/service/software]. I'd like a product that could be sold at a retail price of less than about [insert amount]. The ideas are just ideas. The product need not yet exist, nor may it necessarily be clearly feasible. Follow these steps. Do each step, even if you think you do not need to. First generate a list of 100 ideas (short title only). Second, go through the list and determine whether the ideas are different and bold, modify the ideas as needed to make them bolder and more different. No two ideas should be the same. This is important! Next, give the ideas a name and combine it with a product description. The name and idea are separated by a colon and followed by a description. The idea should be expressed as a paragraph of 40-80 words. Do this step by step.
```

하지만 더 나은 프롬프트(prompting)는 문제의 일부만 해결합니다. 더 깊은 위험은 AI가 당신을 자신의 제안에 앵커링(anchoring)함으로써 실제로 창의적으로 사고하는 능력을 해칠 수 있다는 것입니다. 이것은 두 가지 방식으로 발생합니다. 첫째, 앵커링 효과(anchoring effect)가 있습니다. 일단 AI의 아이디어를 보면, 그 경계를 벗어나 생각하기가 훨씬 더 어려워집니다. 마치 누군가가 “분홍 코끼리를 생각하지 마세요”라고 말하는 것과 같습니다. AI의 제안은 평범한 것일지라도 당신만의 독특한 관점을 밀어낼 수 있습니다. 둘째, MIT 연구에서 보여주듯이, 사람들은 AI가 생성한 아이디어에 대한 소유감을 덜 느끼며, 이는 아이디어 구상 과정(ideation process) 자체에서 이탈하게 된다는 것을 의미합니다.

AI가 생성한 아이디어에 앵커링(anchoring)되는 것을 방지하고 진정한 창의성을 발휘하기 위해서는 사용 방식의 순서가 중요합니다. 먼저 자신만의 아이디어를 충분히 탐색하고 기록한 다음, AI를 활용하여 이를 확장하거나 변형하는 것이 효과적입니다. 예를 들어, "내 아이디어 A를 전혀 다른 3가지 장르의 이야기로 변형해 줘" 또는 "이 제품 아이디어를 10대와 노년층을 위한 버전으로 각각 개발해 줘"와 같이 구체적인 제약을 주어 AI의 발산 사고를 유도할 수 있습니다. 또한, AI에게 "내 아이디어의 가장 큰 약점은 무엇이고, 어떻게 개선할 수 있을까?"와 같이 비판적 관점을 요청하여 아이디어를 정교화하는 데 활용할 수도 있습니다. AI의 결과물을 맹목적으로 수용하기보다는, 인간의 비판적 사고와 미적 판단으로 걸러내고 재구성하는 과정이 필수적입니다.

많은 작가들이 "글쓰기는 사고이다"라고 주장하듯이, 글을 쓰는 행위는 아이디어를 명확히 하고 심화하는 과정입니다. 이 원칙은 AI 시대에도 변함없이 중요합니다. 저의 경우, 글의 초고를 작성할 때는 AI의 도움 없이 오직 저의 생각으로만 채워 넣습니다. 글쓰기가 곧 사고의 과정이기 때문입니다. 초고가 완성된 후에는 AI를 정교한 편집 보조 도구로 활용합니다. 예를 들어, AI에게 "이 글의 주장이 논리적으로 타당한지 분석하고, 논리적 비약이 있다면 지적해 줘" 또는 "이 문단의 어조를 더 설득력 있게 바꾸려면 어떻게 해야 할까?"와 같이 요청합니다. AI는 스타일, 어조, 문법, 심지어 논리적 흐름에 대한 객관적인 피드백을 제공하여 글을 다듬고 가능성을 확장하는 데 큰 도움을 줍니다. 핵심은 사고의 주도권을 인간이 쥐고, AI를 그 사고를 증폭시키는 도구로 사용하는 것입니다.

### 집단 지성(Collective Brain)

팀워크와 회의는 이상적으로는 집단 지성을 통해 시너지를 창출해야 하지만, 현실에서는 비효율과 불균형이 발생하기 쉽습니다. AI는 이러한 전통적인 협업의 한계를 넘어서는 새로운 가능성을 제시합니다. 단순히 회의록을 요약하는 것을 넘어, AI는 회의 전 아젠다를 사전 분석하여 예상되는 논점이나 잠재적 갈등 요소를 식별할 수 있습니다. 또한, 회의 중에는 익명 피드백(anonymous feedback) 시스템을 통해 모든 참가자의 의견을 수렴하고, 소극적인 참여자도 자신의 생각을 자유롭게 표현할 수 있는 심리적 안전(psychological safety)을 조성하는 데 기여할 수 있습니다.

현실적으로, 가장 계시적인 경영 서적 중 하나는 실제로 CIA의 전신이 민간인을 위해 만든 제2차 세계대전(WWII) 사보타주(sabotage) 안내서입니다. 사기 저하와 지연을 유발하기 위한 사무실 작업 사보타주 아이디어를 살펴보세요. 그리고 그 중 얼마나 많은 것이 당신의 회의에서 일반적인 부분인지 생각해 보세요.

그러나 AI가 우리의 집단적 사고를 해치기보다는, AI가 우리를 더 나은 방향으로 돕도록 할 수 있는 선택지가 있습니다. 한 가지 흥미로운 예는 AI를 진행자(facilitator)로 사용하는 것입니다. 우리는 AI가 진행자 역할을 하여 회의 중간에 맞춤형 타로 카드(tarot cards)를 생성하여 토론을 대체하기보다는 안내하도록 돕는 프롬프트(prompt)를 만들었습니다. 회의록을 AI에 제공하면 AI가 당신의 최고의 아이디어를 끌어내는 데 도움이 됩니다 (다시 말하지만, 이것은 크리에이티브 커먼즈 라이선스(Creative Commons license)이므로 필요에 따라 수정하세요. 현재 클로드(Claude)에서 가장 잘 작동하며, 제미니(Gemini)와 o3에서도 괜찮습니다).

AI는 회의의 객관적인 관찰자(objective observer) 역할도 수행할 수 있습니다. 누가 가장 많이 발언하는지, 누가 자주 말을 끊는지 등 대화 패턴을 분석하여 팀 내 발언권의 불균형을 파악하고, 진행자에게 적절한 개입을 제안할 수 있습니다. 브레인스토밍(brainstorming) 세션에서는 AI가 모든 아이디어를 빠짐없이 기록하고 범주화하며, 심지어 "악마의 변호인(devil's advocate)" 역할을 수행하여 제안된 아이디어의 약점을 미리 파악하고 개선점을 찾는 데 도움을 줄 수도 있습니다. 이러한 AI의 활용은 인간 진행자의 부담을 줄이고, 팀이 보다 효율적이고 포괄적인 의사결정을 내릴 수 있도록 지원합니다.

물론, AI를 집단 지성에 통합하는 과정에는 윤리적 고려가 필수적입니다. 데이터 프라이버시, 알고리즘 편향(algorithmic bias), 그리고 복잡한 인간 상호작용을 정량화된 지표로 환원하려는 위험에 대한 인식이 필요합니다. AI는 인간의 비판적 사고나 감성 지능을 대체하는 것이 아니라, 오히려 인간 진행자와 참가자들이 본질적인 문제 해결과 창의적 사고에 더 집중할 수 있도록 역량을 강화하는 도구로 활용되어야 합니다. 팀 내에서 AI 활용에 대한 투명성을 확보하고, 그 한계를 명확히 인지하는 것이 중요합니다.

### “뇌 손상”에 반대하며

AI는 우리의 뇌를 손상시키지 않지만, 생각 없는 사용은 우리의 사고를 손상시킬 수 있습니다. 위험에 처한 것은 우리의 뉴런(neuron)이 아니라 우리의 사고 습관입니다. AI로 자동화하거나 대체할 가치가 있는 작업은 많지만 (우리는 계산기로 하는 수학을 애도하는 일은 거의 없습니다), 우리의 사고가 중요한 작업도 많습니다. 이러한 문제에 대해 연구는 우리에게 명확한 답을 줍니다. 작업의 인간적인 부분을 유지하고 싶다면: 먼저 생각하고, 먼저 쓰고, 먼저 만나세요.

궁극적으로 AI는 우리의 인지적 파트너(cognitive partner)가 될 수 있으며, 인간의 능력을 증강(human-AI augmentation)시키는 강력한 도구입니다. AI가 우리의 뇌를 퇴화시키는 것이 아니라, 올바른 방식으로 사용될 때 우리의 인지적 지평을 확장하고 더 복잡한 문제에 도전할 수 있도록 돕는다는 점을 이해해야 합니다. 이를 위해서는 우리 스스로 AI 활용 능력(AI literacy)과 비판적 사고(critical thinking) 능력을 키워야 합니다. AI가 제공하는 편리함에 무조건적으로 의존하기보다는, 언제 AI를 활용하고 언제 스스로 사고해야 할지 현명하게 선택하는 것이 중요합니다. 우리의 뇌는 안전하지만, 우리의 사고는 우리가 어떻게 AI를 다루느냐에 달려 있습니다. 의도적인 선택을 통해 우리는 AI와 함께 더욱 강력한 인지적 미래를 만들어갈 수 있습니다.

구독 공유