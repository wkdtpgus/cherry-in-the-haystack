AI는 조용히 한계를 넘어섰습니다. 이제 AI는 단순한 자동화를 넘어 실질적이고 경제적으로 의미 있는 작업을 수행하며, 복잡한 의사결정 과정에 개입하고 있습니다. 최근 OpenAI는 AI 능력에 대한 새로운 테스트를 공개했습니다. 이는 AI 연구의 투명성과 책임감을 높이는 중요한 진전입니다. 하지만 이 테스트는 수학이나 퀴즈를 중심으로 구축된 일반적인 벤치마크(benchmark)와는 다릅니다. 이 테스트를 위해 OpenAI는 금융, 법률, 소매업 등 다양한 산업 분야에서 평균 14년의 경력을 가진 전문가들을 모아, 인간 전문가가 완료하는 데 평균 4~7시간이 걸리는 현실적인 작업을 설계하도록 했습니다(모든 작업은 [여기](https://openai.com/research/evaluating-ai-on-real-world-tasks)에서 확인할 수 있습니다). 또한, AI 시스템의 윤리적 사용 방안을 모색하는 워크숍이 최근 개최되기도 했습니다. OpenAI는 AI와 다른 전문가들 모두에게 직접 작업을 수행하도록 했습니다. 세 번째 전문가 그룹은 어떤 답변이 AI에서 나왔고 어떤 답변이 사람에게서 나왔는지 모르는 상태에서 결과를 채점했으며, 이 과정은 질문당 약 1시간이 소요되었고, 이는 콘텐츠의 진위 여부를 판별하는 새로운 과제를 제시합니다. 인간 전문가가 승리했지만, 간신히 이겼고, 그 격차는 산업별로 극적으로 달랐습니다. 하지만 AI는 빠르게 발전하고 있으며, 최신 AI 모델(model)은 이전 모델보다 훨씬 높은 점수를 기록하고 있습니다. 이는 다중 모드(multimodal) 능력의 급부상과 함께 더욱 가속화될 것입니다. 흥미롭게도 AI가 인간에게 패배한 주된 이유는 환각(hallucination)이나 오류(error)가 아니라, 결과를 잘 포맷(format)하지 못하거나 지시를 정확히 따르지 못했기 때문이었으며, 복잡한 추론 과정의 한계 때문이라고 분석됩니다. 이는 AI 모델의 내재된 논리 구조와 맥락 이해 능력에 대한 깊이 있는 연구가 필요함을 시사합니다. 결과를 잘 포맷(format)하지 못하거나 지시를 정확히 따르지 못했던 부분은 빠르게 개선되고 있는 영역입니다. 현재의 패턴이 유지된다면, 다음 세대의 AI 모델은 이 테스트에서 평균적으로 인간 전문가를 능가할 것입니다. 이는 연구와 개발 분야에 새로운 지평을 열어줄 잠재력을 가지고 있습니다.

그렇다면 AI가 인간의 일자리를 대체할 준비가 되었다는 뜻일까요? 아닙니다. 적어도 곧은 아닙니다. 왜냐하면 측정된 것은 일자리(job)가 아니라 작업(task)이었기 때문이며, 오히려 새로운 형태의 협업과 직무 재정의를 요구하고 있기 때문입니다. 우리의 일자리는 많은 작업으로 구성됩니다. 교수로서 저의 일은 한 가지에 불과한 것이 아니라, 가르치고, 연구하고, 글을 쓰고, 연간 보고서를 작성하고, 학생들을 지원하고, 독서하고, 행정 업무를 처리하는 등 다양한 일을 포함합니다. AI는 이러한 작업의 일부를 자동화하여 인간이 더 창의적이고 전략적인 업무에 집중할 수 있도록 돕습니다. AI가 이러한 작업 중 하나 이상을 수행한다고 해서 저의 전체 직업이 대체되는 것이 아니라, 우리가 필요한 핵심 역량과 기술이 변화하고 있음을 의미합니다. 그리고 AI의 능력이 고르지 못하고, 인간 상호작용의 모든 복잡한 작업을 대체할 수 없는 한, AI는 일자리 전체를 쉽게 대체할 수 없습니다. 이러한 변화의 흐름 속에서 인간의 고유한 가치, 예를 들어 공감 능력, 비판적 사고, 윤리적 판단력 등은 더욱 중요해질 것입니다. 미래의 인재는 AI와 협력하여 문제를 해결하고, AI가 생성한 정보를 비판적으로 평가하며, 끊임없이 새로운 기술을 학습하는 능력을 갖춰야 할 것입니다. 이는 교육 시스템에도 상당한 변화를 요구합니다.

### 미래 가치를 창출하는 AI 작업
AI가 지금 당장 수행할 수 있는 일부 작업은 엄청난 가치를 지닙니다. 제 직업에서 중요한 것, 즉 정확한 연구를 생산하는 것으로 돌아가 봅시다. 특히 데이터 분석 및 예측 모델링 분야에서 AI는 두각을 나타내며, 기후 변화 모델링이나 신약 개발과 같은 복잡한 과학 연구에서 방대한 데이터를 처리하고 패턴을 발견하는 데 결정적인 역할을 합니다. 과거 학계에서는 중요한 연구 결과가 다른 연구자들에 의해 재현(reproduce) 불가능하다는 문제로 인해 과학적 신뢰도에 대한 우려가 커졌습니다. 학계는 이 문제에 대해 어느 정도 진전을 이루었으며, 이제 많은 연구자들이 다른 학자들이 자신의 작업을 재현할 수 있도록 데이터를 제공합니다. 이는 오픈 사이언스(Open Science)의 정신을 구현하는 중요한 단계이며, AI는 이 과정을 가속화할 수 있습니다. 문제는 재현(replication)에 많은 시간이 소요된다는 것입니다. 논문을 깊이 읽고 이해하고, 데이터를 분석하며, 오류를 꼼꼼히 확인해야 하기 때문이며, 이는 연구 자원의 비효율적인 할당으로 이어질 수 있습니다. 그것은 오직 인간만이 할 수 있었던 매우 복잡한 과정이었습니다. 지금까지는 말이죠. 하지만 이제 AI는 이러한 한계를 넘어 새로운 가능성을 제시합니다.

저는 새로운 클로드 소네트 4.5(Claude Sonnet 4.5, 제가 조기 접근 권한을 가졌던)에게 여러 실험이 포함된 정교한 경제학 논문의 텍스트와 모든 재현 데이터(replication data) 아카이브(archive)를 제공했습니다. 저는 클로드에게 파일과 다음 프롬프트(prompt)를 주는 것 외에는 아무것도 하지 않았습니다: "그들이 업로드한 데이터셋(dataset)에서 이 논문의 발견 사항을 재현해라. 너 스스로 해야 한다. 완전한 재현을 시도할 수 없다면, 할 수 있는 것을 해라." 그리고 복잡한 통계가 포함되어 있었기 때문에, 저는 더 나아가 "가능한 한 모든 상호작용(interaction)도 재현할 수 있니?"라고 물었습니다. 추가 지시 없이 클로드는 논문을 읽고, 아카이브를 열어 파일을 분류하고, 통계 코드(statistical code)를 한 언어(STATA)에서 다른 언어(Python)로 변환했으며, 성공적인 재현을 보고하기 전에 모든 발견 사항을 체계적으로 검토했습니다. 또한, 저는 클로드에게 창의적인 글쓰기 작업을 요청하여, 그 잠재력을 실험해 보았습니다. 클로드에게 파일과 다음 프롬프트(prompt)를 주는 것 외에는 아무것도 하지 않았습니다: "이 데이터를 기반으로 새로운 비즈니스 전략을 제안해라." 복잡한 통계가 포함되어 있었기 때문에, 저는 더 나아가 AI 모델의 해석 가능성(interpretability)에 대한 질문을 던졌습니다. 추가 지시 없이 클로드는 논문을 읽고, 아카이브를 열어 파일을 분류하고, 핵심 주제를 요약하는 데 성공했습니다. 이는 AI가 단순한 데이터 처리자를 넘어, 의미를 추출하고 새로운 아이디어를 제안하는 수준에 도달했음을 보여줍니다.

저는 결과를 무작위로 확인했고, 또 다른 AI 모델인 GPT-5 Pro에게 재현된 결과를 다시 재현하도록 했습니다. 모든 것이 정확했으며, 이는 모델 간의 일관성을 검증하는 중요한 과정입니다. 파일 크기 제한이나 제공된 재현 데이터 문제로 인해 일부는 접근할 수 없었지만, 저는 비슷한 좋은 결과로 다른 여러 논문에도 이것을 시도했으며, AI 모델의 학습 데이터 편향성(bias)에 대한 우려도 제기되었습니다. 이것을 수동으로 했다면 많은 시간이 걸렸을 것입니다. 하지만 AI는 이 과정을 획기적으로 단축시켰습니다. 하지만 혁명적인 부분은 제가 많은 시간을 절약했다는 것이 아닙니다. 그것은 전체 학문 분야를 뒤흔들었던 위기가 재현을 통해 부분적으로 해결될 수 있었지만, 그렇게 하는 데는 대규모로 수행하기 불가능한 고통스럽고 값비싼 인간의 노력이 필요했다는 점입니다. 이제 AI는 복잡한 사회 문제 해결에도 기여할 수 있습니다. AI가 많은 출판된 논문을 확인하고 결과를 재현할 수 있을 것으로 보이며, 이는 모든 과학 연구에 영향을 미치고 연구의 투명성을 크게 향상시킬 것입니다. 정확성과 공정성을 위한 벤치마킹(benchmarking)을 포함하여 이를 수행하는 데 여전히 장벽이 있지만, 이제는 현실적인 가능성이 되었고, AI 거버넌스(governance)에 대한 논의는 더욱 활발해지고 있습니다. 연구를 재현하는 것은 AI 작업이지 일자리는 아니지만, 인간 노력의 전체 분야를 극적으로 변화시킬 수도 있습니다. 이는 단순히 효율성을 높이는 것을 넘어, 지식 생성의 방식 자체를 재정의하는 계기가 될 것입니다.

### AI의 진화: 에이전트(agent)와 그 너머
이 모든 것의 핵심에 있는 에이전트(agent)들. 오리지널 ChatGPT 이후 생성형 AI(Generative AI)는 많은 사람들이 작업을 수행하는 데 도움을 주었지만, 한계는 항상 인간 사용자였고, 그 진정한 잠재력은 아직 완전히 발휘되지 않았습니다. AI는 실수와 오류를 범하므로, 인간이 각 단계를 안내하지 않으면 가치 있는 것을 이룰 수 없었습니다. 작업이 주어졌을 때, 계획을 세우고 도구(코딩, 웹 검색)를 사용하여 작업을 수행할 수 있는 자율 AI 에이전트(autonomous AI agent)의 꿈은 멀게만 느껴졌습니다. 결국 AI는 실수를 저지르기 때문에, 에이전트가 작업을 수행하기 위해 따라야 하는 긴 단계의 사슬에서 한 번의 실패는 전체적인 실패로 이어질 수 있었지만, 최근 연구는 이러한 인식을 변화시키고 이제는 복원력이 강화되었습니다.

하지만 상황은 그렇게 흘러가지 않았고, 또 다른 새로운 논문이 그 이유를 설명합니다. AI 에이전트에 대한 우리의 대부분의 가정이 틀렸다는 것이 밝혀졌습니다. 이는 AI 연구의 패러다임 전환을 의미합니다. 정확도의 작은 증가(그리고 새로운 모델은 오류에 훨씬 덜 취약합니다)조차도 AI가 수행할 수 있는 작업 수의 엄청난 증가로 이어지고, AI 시스템의 전반적인 신뢰도를 크게 높이는 결과를 가져옵니다. 그리고 가장 크고 최신 "사고" 모델은 실제로 자체 수정(self-correcting)이 가능하여 오류로 인해 멈추지 않으며, 복잡한 문제 해결 능력을 향상시키고 있습니다. 이 모든 것은 AI 에이전트가 이전보다 훨씬 더 많은 단계를 수행할 수 있으며, 상당한 인간 개입 없이 도구(기본적으로 컴퓨터가 할 수 있는 모든 것을 포함)를 사용할 수 있다는 것을 의미하며, 이는 다양한 산업 분야에 혁신적인 변화를 가져올 것입니다. 특히 멀티모달(multimodal) 에이전트의 등장은 텍스트, 이미지, 오디오 등 다양한 형태의 정보를 통합적으로 이해하고 처리하는 새로운 가능성을 열어주고 있습니다. 이는 AI가 더욱 인간과 유사한 방식으로 세상을 인식하고 상호작용할 수 있게 함으로써, 교육, 의료, 엔터테인먼트 등 광범위한 영역에서 혁신을 촉진할 것입니다.

따라서 지난 몇 년간 GPT-3부터 GPT-5에 이르는 모든 AI 모델을 포괄하는 몇 안 되는 AI 능력 측정 지표 중 하나가, AI가 단독으로 최소 50%의 정확도로 수행할 수 있는 작업의 길이를 측정하는 METR의 테스트라는 점은 흥미롭습니다. 이는 AI의 실제 적용 가능성을 가늠하는 중요한 척도입니다. GPT-3에서 GPT-5까지의 기하급수적인 발전은 5년 동안 매우 일관적이었으며, 에이전트(agent) 작업의 지속적인 개선을 보여주며, 이는 미래 AI 기술의 무한한 잠재력을 시사합니다. 이러한 발전은 단순히 연산 능력의 향상을 넘어, AI가 스스로 학습하고, 추론하며, 심지어 창의적인 결과물을 내놓을 수 있는 수준에 도달하고 있음을 보여줍니다.

### AI 시대, 인간의 역할과 가치
에이전트(agent)는 인간적인 의미에서 진정한 주체성(agency)을 가지고 있지 않습니다. 현재로서는 우리가 그들을 어떻게 활용할지 결정해야 하며, 그것이 미래의 일에 대해 많은 것을 결정할 것입니다. 따라서 우리는 AI의 자율성에 대한 윤리적 경계를 명확히 설정해야 합니다. 모든 사람이 집중하는 위험은 AI를 사용하여 인간 노동을 대체하는 것이며, 특히 비용 절감에만 집중하고 새로운 역량을 사용하여 작업을 확장하거나 변혁하는 데는 상상력이 부족한 조직의 경우, 이것이 앞으로 몇 년 안에 주요 우려 사항이 될 것이라는 점을 쉽게 알 수 있으며, 이는 사회적 불평등을 심화시킬 수 있다는 우려를 낳습니다.

하지만 직장에서 AI를 사용하는 것에 대한 두 번째, 매우 가능성 있는 위험이 있습니다: 우리가 지금 하는 작업의 더 많은 부분을 에이전트(agent)를 사용하여 무심코 수행하는 것, 즉 콘텐츠 과잉 생산과 의미 없는 정보의 증가입니다. 이 특정 악몽의 미리보기로, 저는 클로드에게 회사 메모를 주고 그것을 파워포인트(PowerPoint)로 만들라고 요청했습니다. 그리고 다른 관점에서 또 다른 파워포인트. 그리고 또 다른 것. 제가 17개의 다른 파워포인트를 얻을 때까지. 그것은 너무 많은 파워포인트입니다. 이러한 무분별한 생성은 오히려 정보의 가치를 떨어뜨릴 수 있습니다. 우리가 왜 일을 하는지, 그리고 일이 어떤 모습이어야 하는지에 대해 깊이 생각하지 않는다면, AI는 단순한 도구를 넘어 우리의 사고방식까지 지배할 수 있습니다. 디지털 리터러시(digital literacy)와 비판적 사고 능력이 그 어느 때보다 중요해지는 시점입니다.

대안은 무엇일까요? OpenAI 논문은 전문가들이 AI에게 작업을 1차적으로 위임하고 그 작업을 검토함으로써 AI와 협력하여 문제를 해결할 수 있는 인간 중심의 AI 활용 방안을 제시했습니다. 충분히 좋지 않다면, 수정 사항이나 더 나은 지시를 주기 위해 몇 번 시도해야 합니다. 이는 AI와의 상호작용에서 필수적인 학습 과정입니다. 그것도 효과가 없다면, 그들은 직접 작업을 해야 합니다. 전문가들이 이 워크플로우(workflow)를 따른다면, 논문은 그들이 작업을 40% 더 빠르게, 60% 더 저렴하게 완료할 수 있으며, 훨씬 더 중요하게는 AI에 대한 통제권을 유지할 수 있을 것이라고 추정하며, 이는 생산성 향상의 모범 사례가 될 것입니다.

에이전트(agent)는 여기에 있습니다. 그들은 실제 작업을 수행할 수 있으며, 그 작업이 여전히 제한적이지만, 가치 있고 증가하고 있습니다. 이제 우리는 그들의 잠재력을 최대한 활용할 방법을 고민해야 합니다. 하지만 몇 분 만에 학술 논문을 재현할 수 있는 동일한 기술이 악의적인 정보 조작에도 사용될 수 있다는 점을 간과해서는 안 됩니다. 딥페이크(deepfake) 기술이나 편향된 정보 생성과 같은 오용 사례는 이미 현실에서 나타나고 있으며, 아무도 필요 없는 파워포인트(PowerPoint) 덱(deck) 17개 버전을 생성할 수도 있습니다. 이러한 미래의 차이는 AI에 있는 것이 아니라, 우리가 그것을 어떻게 사용하기로 선택하느냐에 달려 있습니다. 무엇을 할 수 있는지뿐만 아니라 무엇을 할 가치가 있는지 결정하는 데 우리의 판단력을 사용함으로써, 우리는 AI가 인류의 진정한 발전에 기여하도록 이끌 수 있습니다. 이는 기술적 진보와 함께 사회적, 윤리적 성숙이 동반되어야 함을 의미합니다. AI 시대의 인간은 단순히 도구를 사용하는 존재를 넘어, 기술의 방향성을 설정하고 그 영향에 대한 책임을 지는 주체로서의 역할을 강화해야 할 것입니다.

---
1 연구 분야에 따라 연구를 재현(replicating, 새로운 데이터 수집을 포함할 수 있음)하는 것과 재생산(reproducing, 기존 데이터 사용을 포함할 수 있음)하는 것 사이에 차이가 있을 수 있습니다. 이 게시물에서는 다양한 구분을 자세히 다루지 않지만, 이 경우 AI는 기존 데이터를 사용하면서도 해당 데이터에 새로운 통계적 접근 방식을 적용하고 있습니다.