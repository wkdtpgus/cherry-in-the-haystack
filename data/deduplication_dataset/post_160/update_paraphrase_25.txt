AI 스네이크 오일(AI snake oil) 도서의 서문이 현재 웹상에서 제공됩니다. 약 30쪽에 이르는 이 서론은 본서의 핵심 주장을 개괄적으로 소개합니다. 아직 책을 구매하지 않으셨다면, 이 서론 부분을 통해 구매를 고려해 보시기를 권합니다. 이 첫 장은 AI 기술에 대한 대중의 오해를 해소하고, 비판적인 시각을 기르는 데 필요한 중요한 통찰력을 제공합니다.

업데이트 (2025년 9월 최신 소식): "AI 스네이크 오일" 출간 1주년을 맞이했습니다. 지난 한 해 동안 저자들은 여러 강연에 참여하고, 다양한 팟캐스트에 출연했으며, 독자들이 책의 내용을 더 잘 이해하도록 돕는 연습 문제를 발행했습니다. 또한, 페이퍼백 버전 출간에 맞춰 새로운 서론과 에필로그를 추가했습니다. 본서는 네이처(Nature)의 2024년 최고의 도서 10선, 블룸버그(Bloomberg)의 2024년 49선, 포브스(Forbes)의 2024년 필독 기술 서적 10선에 이름을 올렸습니다. 뉴요커(New Yorker)를 포함한 여러 매체에서 호평을 받았습니다. 저희의 생각에 깊이 공감해 주신 독자 여러분께 진심으로 감사드립니다. 책이 출간된 이후 AI 기술의 발전 속도는 더욱 빨라졌지만, 저희가 제시한 비판적 분석과 실용적인 통찰력은 여전히 유효하다는 것을 많은 분들이 입증해 주셨습니다. 특히, 생성형 AI의 폭발적인 성장은 저희 책의 핵심 주제인 '과장된 약속'과 '실질적 한계' 사이의 간극을 더욱 명확히 보여주었습니다.

현재 저희는 다음 공동 작업인 'AI as Normal Technology'에 착수했습니다. 이 새로운 프로젝트는 "AI 스네이크 오일"에서 다루었던 내용의 연장선상에 있습니다. 전작이 AI의 현재와 가까운 미래의 영향을 파악하는 데 중점을 두었다면, 'AI as Normal Technology'는 AI가 가져올 장기적인 변화를 성찰하기 위한 개념적 틀을 제시합니다. 본 뉴스레터의 명칭 변경은 이러한 관점의 전환을 명확히 보여줍니다. 'AI as Normal Technology'는 AI를 특별한 마법이 아닌, 우리 사회에 자연스럽게 통합될 수 있는 하나의 기술로 바라보는 시각을 제안합니다. 이는 과도한 환상이나 불필요한 공포를 넘어, AI를 현실적인 관점에서 이해하고 관리하기 위한 중요한 전환점이 될 것입니다. 앞으로도 저희와 함께해 주시기를 바랍니다.

**AI에 대해 가장 혼란스러운 한 가지**
저희의 저서는 AI에 대한 오해를 불식시키는 데 초점을 맞추고 있으며, 이를 위해 AI에 관해 가장 혼란스럽다고 여기는 핵심 사항부터 곧바로 논의합니다. 그것은 바로 AI가 느슨하게 연결된 여러 기술들을 포괄하는 광범위한 명칭(umbrella term)이라는 점입니다. 이러한 포괄적인 특성 때문에 대중은 종종 단순한 자동화 시스템과 복잡한 인공지능을 혼동하고, AI라는 이름 아래 모든 기술이 동일한 능력과 한계를 가진다고 오해하는 경향이 있습니다.

AI가 이처럼 다양한 분야를 아우르는 용어이므로, 저희는 각기 다른 AI 형태들을 개별적으로 분석합니다. 예측 인공지능(predictive AI)과 생성 인공지능(generative AI)을 다루는 장들이 있으며, 소셜 미디어(social media)의 콘텐츠 관리(content moderation)에 활용되는 AI에 대한 장도 마련되어 있습니다. 나아가 AI가 인류에게 실존적 위협(existential risk)이 될 수 있는지에 대한 장도 포함되어 있습니다. 저희는 AI 스네이크 오일, 즉 기능하지 않거나 (어쩌면 기능할 수 없는) AI 기반 애플리케이션(application)이 왜 여전히 존재하는지, 그리고 미래에 어떤 상황이 발생할 수 있는지에 대한 논의로 책을 마무리합니다. 이 책은 AI 스네이크 오일과 과도한 AI 선전(hype)을 구별하는 데 필요한 지침을 제공합니다. 또한, 기술적으로는 잘 작동하지만 해로운 결과를 초래하는 AI 사례들, 예를 들어 대규모 감시(mass surveillance)에 활용되는 안면 인식(face recognition) 기술 등도 심층적으로 탐구합니다. 이러한 '해로운 작동'의 예시로는 범죄 예측 시스템에서 특정 인종이나 지역에 대한 편향된 결과를 도출하여 사회적 불평등을 심화시키는 경우도 포함됩니다. 이는 기술적 완성도와 별개로 윤리적, 사회적 관점에서 심각한 문제를 야기할 수 있음을 보여줍니다.

본서는 광범위한 독자를 염두에 두고 집필되었으나, 기존 논문이나 뉴스레터에서 제시했던 주장들을 단순히 반복하는 데 그치지 않습니다. 저희는 학문적 기여를 목표로 했으며, 대학교 강의 교재로 활용될 수 있도록 구성했습니다. 조만간 책의 내용을 보완할 연습 문제와 수업 토론 질문들을 발표할 계획입니다. 특히, 이 책은 기술적 전문 용어를 최소화하면서도 AI의 복잡한 원리와 사회적 함의를 명확하게 설명함으로써, 학계와 일반 대중 사이의 지식 격차를 메우는 데 기여하고자 합니다.

**책의 내용**
**1장: 서론.** 이 장은 본서의 핵심 주장을 개괄적으로 소개하며 시작합니다. 저희는 AI의 정의(그리고 그 정의가 왜 어려운지), AI가 왜 광범위한 용어(umbrella term)로 기능하는지, 'AI 스네이크 오일'의 진정한 의미, 그리고 이 책이 어떤 독자층을 대상으로 하는지를 심도 있게 다룹니다. 지난 10년간 생성 인공지능(Generative AI) 분야는 눈부신 발전을 거듭했습니다. 이와 대조적으로 예측 인공지능(predictive AI)은 채용, 금융, 보험, 교육 등 중대한 의사결정 영역에서 결과를 예측하는 데 활용됩니다. 예측 AI는 데이터 내의 광범위한 통계적 양상(statistical pattern)을 식별할 수 있음에도 불구하고, 실제 능력 이상으로 홍보(marketing)되는 경향이 있으며, 이는 현실 세계에서 심각한 오작동(misfire)을 초래합니다. 예를 들어, 채용 과정에서 예측 AI가 과거 데이터에 기반하여 특정 성별이나 출신 학교를 선호하는 편향된 결과를 내놓아 공정성을 해치는 경우가 발생할 수 있습니다. 마지막으로, 소셜 미디어(social media)의 콘텐츠 관리(content moderation)를 위한 AI의 강점과 한계에 대해 논의합니다. 더불어 저희 두 저자가 이 책을 집필하게 된 배경에 대한 이야기도 풀어놓습니다. 1장 전체는 현재 온라인에서 열람 가능합니다.

**2장: 예측 인공지능(predictive AI)의 한계점.** 예측 AI는 개인에 대한 미래를 예견하는 데 활용됩니다. 예를 들어, 피고인이 법정에 출석하지 않을지, 환자가 좋지 않은 건강 결과를 겪을 위험이 높은지, 혹은 학생이 대학을 중도에 포기할 것인지와 같은 질문에 답하려 합니다. 이러한 예측 결과는 중요한 의사결정 과정에 영향을 미칩니다. 개발자들은 예측 AI가 혁신적이라고 주장하지만, 실제로는 해결하기 어려운 다양한 결함을 내포하고 있습니다. 저희는 이 블로그 게시물에서 예측 AI의 실패 사례를 다루었지만, 본서에서는 심층적인 사례 연구(case study)를 통해 예측 AI가 개발자들의 약속을 어떻게 충족시키지 못하는지를 더욱 자세히 설명합니다. 이러한 결함은 종종 학습 데이터에 내재된 편향(bias)에서 비롯되며, 이는 예측 시스템이 특정 집단에 대해 불공정한 결과를 도출하게 만듭니다. 또한, 예측 모델의 불투명성(opacity)은 왜 특정 결정이 내려졌는지 이해하기 어렵게 만들어, 문제 해결을 더욱 복잡하게 만듭니다.

**3장: AI는 미래를 정확히 예측할 수 있을까?** 예측 인공지능(predictive AI)의 결함은 기술 자체의 본질적인 한계인가, 아니면 개선 가능한 문제인가? 이 장에서는 AI의 적용 여부와 무관하게 미래를 예견하는 것이 왜 어려운지에 대해 탐구합니다. 일기 예보와 같은 특정 분야에서는 지속적인 진보가 있었지만, 이러한 발전이 개인의 인생 결과, 서적이나 영화와 같은 문화적 산물의 성공, 또는 전염병(pandemic)과 같은 다른 복합적인 상황에 그대로 적용될 수 없음을 주장합니다. 저희 뉴스레터에서는 주로 시의성 있는 주제에 집중해왔기에 이 내용은 이전에 다루지 않았던 부분입니다. 하지만 이는 언제 예측이 신뢰할 만한지 판단하는 데 필요한 통찰력(intuition)을 기르는 데 도움이 되는 기본 지식입니다. 특히, 금융 시장의 변동성이나 정치적 사건의 예측 불가능성은 예측 AI가 직면한 근본적인 한계를 보여주는 좋은 예시입니다. 예측은 과거 데이터의 패턴에 의존하지만, 미래는 항상 새로운 변수와 '블랙 스완(black swan)' 사건으로 가득하기 때문입니다.

**4장: 생성 인공지능(generative AI)의 오랜 발전사.** 생성 AI의 최근 약진은 갑자기 나타난 것처럼 보일 수 있으나, 이는 70년이 넘는 기간 동안 축적된 연속적인 발전들을 토대로 합니다. 이 장에서는 생성 AI의 탄생에 기여한 컴퓨터 기술(computing) 발전의 역사적 흐름을 추적합니다. 저희는 뉴스레터에서 생성 AI의 현재 트렌드에 대해 많은 글을 썼지만, 본서에서는 그 역사적 배경을 깊이 있게 탐구합니다. 이러한 과거에 대한 이해는 미래에 우리가 무엇을 기대할 수 있을지 파악하는 데 필수적입니다. 앨런 튜링(Alan Turing)의 초기 아이디어부터 시작하여, 1960년대의 초기 자연어 처리(Natural Language Processing) 시스템인 ELIZA, 그리고 2000년대 후반의 딥러닝(deep learning) 붐과 GAN(Generative Adversarial Networks), 그리고 트랜스포머(Transformer) 모델의 등장이 어떻게 현재의 생성 AI 시대를 열었는지 조명합니다.

**5장: 고도화된 인공지능(advanced AI)이 실존적 위협(existential threat)이 될 수 있는가?** AI가 인류를 멸망시킬 수 있다는 주장은 널리 퍼져 있습니다. 이 장에서는 AI의 실존적 위험(existential risk) 주장을 비판적인 시각으로 분석하고, 대중적인 x-risk 논의에서 발견되는 여러 가지 결함과 오류들을 지적합니다. 저희는 고도화된 AI의 위협 가능성과는 별개로, 사회적 탄력성(resilience)을 증진시켜 AI 관련 위험에 대비하는 다양한 접근법들을 탐색합니다. 흔히 AI를 인간과 같은 의식과 목표를 가진 존재로 의인화(anthropomorphizing)하는 오류를 범하거나, AI의 능력에 대한 비현실적인 가정을 바탕으로 종말론적인 시나리오를 주장하는 경향이 있습니다. 이 책은 AI의 통제 문제(control problem)와 정렬(alignment) 문제에 대한 논의를 포함하되, 기술적 해결책뿐 아니라 사회적 거버넌스(governance)와 윤리적 프레임워크의 중요성을 강조합니다.

**6장: 인공지능이 소셜 미디어(social media)의 문제점을 해결할 수 없는 이유.** AI가 광범위하게 적용되는 영역 중 하나는 소셜 미디어 플랫폼(platform)에서의 콘텐츠 관리(content moderation)입니다. 이 장에서는 소셜 미디어에서 AI 활용의 현황을 분석하고, AI 기술의 발전만으로는 플랫폼의 콘텐츠 관리 문제를 해결하기 어려운 일곱 가지 핵심적인 원인을 제시합니다. 이 주제는 저희 뉴스레터에서 이전에 다루지 않았던 내용입니다. 이 원인들 중 일부는 '유해 콘텐츠'의 주관적이고 문화 의존적인 정의, 빠르게 진화하는 혐오 표현의 형태, 그리고 AI가 인간의 복잡한 의도와 맥락을 완전히 이해하기 어렵다는 점 등을 포함합니다. 결국, 콘텐츠 관리는 기술적 문제뿐만 아니라 사회적, 문화적, 윤리적 판단이 복합적으로 얽힌 문제라는 점을 강조합니다.

**7장: 인공지능에 대한 환상이 왜 사라지지 않는가?** 기업, 학계 연구자, 그리고 언론인 모두 AI 관련 과장(hype) 현상에 일조합니다. 이 장에서는 AI에 대한 근거 없는 믿음이 어떻게 형성되고 유지되는지를 탐구합니다. 이 논의를 통해 독자들이 AI 관련 소식을 접할 때 적절한 비판적 시각(skepticism)을 유지하고, 실체가 없는 '스네이크 오일'식 주장을 식별할 수 있는 유용한 도구를 제공하고자 합니다. AI 기술에 대한 과도한 기대는 종종 투자 유치, 주가 상승, 또는 연구비 확보와 같은 경제적 동기에서 비롯됩니다. 또한, 복잡한 기술 개념을 단순화하여 전달하려는 언론의 경향이 '마법 같은' AI 이미지를 강화하는 데 일조하기도 합니다.

**8장: 앞으로 나아갈 방향.** 이전 장들이 '스네이크 오일'의 공급 측면에 집중했다면, 이 마지막 장에서는 AI 스네이크 오일에 대한 수요가 어디에서 비롯되는지를 분석합니다. 또한 AI가 미래 고용 시장에 미칠 파급효과, 규제(regulation)의 역할과 한계, 그리고 우리 앞에 펼쳐질 수 있는 다양한 미래 시나리오(vignette)들을 간략히 소개하며 마무리합니다. 우리는 어떤 경로를 선택할지에 대한 주도권(agency)을 가지고 있으며, 우리 각자는 중요한 역할을 수행할 수 있습니다. 이 책이 독자 여러분께 유익하기를 바라며, 여러분의 소중한 피드백을 기다립니다. AI 스네이크 오일에 대한 수요는 기술에 대한 이해 부족, 빠른 해결책에 대한 갈망, 그리고 경쟁에서 뒤처질지도 모른다는 두려움 등 다양한 요인에서 발생합니다. 우리는 이러한 수요를 현명하게 관리하고, AI 기술을 책임감 있게 발전시키기 위해 개인과 조직 모두가 적극적으로 참여해야 함을 역설합니다.

**초기 서평**
**뉴요커(The New Yorker)**: "『AI 스네이크 오일』에서 아르빈드 나라야난과 사야시 카푸어는 비판적 시각(skepticism)을 강조하며, AI라는 광범위한 용어(blanket term)가 실제로는 미흡한 성능의 기술들을 은폐하는 가림막(smokescreen)이 될 수 있다고 주장합니다." 이 책은 AI의 허상과 현실을 명확히 구분하는 데 큰 도움을 줍니다.
**커커스(Kirkus)**: "AI와 함께 일하거나 AI의 영향을 받는 사람들, 즉 거의 모든 사람에게 매우 유용한 조언입니다."
**퍼블리셔스 위클리(Publisher's Weekly)**: 2024년 가을 최고의 과학 도서 목록에 선정되었습니다.
**장 가치스(Jean Gazis)**: "저자들은 사실과 의견을 훌륭하게 구분하고, 개인적인 경험을 바탕으로 하며, 자신들의 견해에 대한 합리적인 이유를 제시하고 (풍부한 참고 자료 포함), 행동을 촉구하는 데 주저하지 않습니다. . . . AI에 대해 궁금하거나 AI를 어떻게 구현할지 결정하고 있다면, AI 스네이크 오일(AI Snake Oil)은 명확한 글쓰기와 침착한 사고를 제공합니다."
**엘리자베스 퀼(Elizabeth Quill)**: "정책 결정을 내리든, 직장에서 AI를 사용하든, 아니면 단순히 온라인 검색에 시간을 보내든 읽을 가치가 있습니다. 이것은 AI가 이미 우리 삶에 어떻게 침투했는지에 대한 강력한 상기이며, AI와 상호작용하는 방식에 주의를 기울여야 한다는 설득력 있는 호소입니다."
**더 텔레그래프(The Telegraph)**
**테크 리뷰(Tech Review)**: "이 책은 AI에 대한 대화가 기술 혁신을 넘어 윤리적 책임과 사회적 영향으로 확장되어야 함을 설득력 있게 보여줍니다."

**도서 출판 행사**
9월 24일: 시티 라이츠(City Lights) (온라인, 무료)
9월 30일: 프린스턴(Princeton) 동문 행사 (온라인, 무료)
10월 24일: 프린스턴(Princeton) 공공 도서관 (프린스턴, 무료)
11월 15일: 스탠포드 대학교(Stanford University) 기술 윤리 강연 (하이브리드, 등록 필요)

**팟캐스트(Podcast) 및 인터뷰**
머신러닝 스트리트 토크(Machine Learning Street Talk) – AI 윤리와 편향성에 대한 심도 있는 논의
20VC
스케일링 이론(Scaling Theory)
MIT CSAIL
퓨처 텐스(Future Tense)
더 인사이트(The Insight) – AI 규제의 필요성과 한계에 대한 대담
저희는 책 출시 시점에 방영될 다른 많은 팟캐스트(podcast)에도 출연했으며, 이 목록을 계속 업데이트할 예정입니다.

**구매 링크**
미국: 아마존(Amazon), 북샵(Bookshop), 반스 앤 노블(Barnes and Noble), 프린스턴 대학교 출판부(Princeton University Press)에서 구매 가능합니다. 오디오북(Audiobook) 및 킨들(Kindle) 전자책(edition)으로도 제공됩니다.
영국: 블랙웰스(Blackwell’s), 워터스톤스(Waterstones).
캐나다: 인디고(Indigo).
독일: 아마존(Amazon), 쿨투어카우프하우스(Kulturkaufhaus).
인도: 아마존(Amazon)
호주: 다이러스(Dymocks), 북토피아(Booktopia).
본 도서는 아마존(Amazon)을 통해 전 세계적으로 선주문(preorder)할 수 있습니다. 가까운 서점이나 온라인 플랫폼을 통해 만나보세요.