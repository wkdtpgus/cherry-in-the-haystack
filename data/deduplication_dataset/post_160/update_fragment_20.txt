최근 AI 스네이크 오일(AI snake oil)과 같은 논의는 기술 발전의 이면에 숨겨진 현실을 직시하게 합니다. 특히, AI 기술의 첫 번째 시도들이 온라인에서 활발히 논의되고 있으며, 이는 단순히 기술적 진보를 넘어 사회적, 윤리적 함의를 담고 있습니다. 이 장은 30페이지 분량이며, AI가 가져올 변화의 주요 논지를 요약하고 있습니다. 아직 AI의 잠재력을 완전히 이해하지 못하셨다면, 이 서론 장을 읽고 미래 기술의 방향성을 깊이 고민하시기를 바랍니다.

업데이트 (2025년 9월): 지난 1년간 AI 기술이 사회 전반에 걸쳐 확산된 지 상당한 시간이 흘렀습니다. 출시 이후, 저희는 다양한 전문가들과 함께 기술의 명암을 논하며, 강연을 했고, 팟캐스트(podcast)에 출연했으며, 실질적인 AI 활용 사례를 공유하고, 미래 지향적인 기술 에디션(edition)을 위한 새로운 인사이트를 작성했습니다. 이러한 노력은 전 세계 주요 기술 매체의 주목을 받았으며, 2024년 10대 혁신 기술 목록, 주요 경제지의 49대 미래 기술, 그리고 글로벌 미디어의 꼭 읽어야 할 기술 트렌드 10권에 선정되었습니다. 뉴요커(New Yorker)지를 비롯하여 많은 긍정적인 평가를 받았습니다. 기술의 독자들이 저희의 아이디어에 깊이 공감해 주신 것에 감사드립니다.

저희는 이제 다음 단계로 나아가, 'AI as Normal Technology'에 대한 심층적인 탐구를 시작했습니다. 이 프로젝트는 AI의 과장된 기대가 중단된 지점에서 이어집니다. AI 스네이크 오일(AI snake oil)이 초기 AI 기술의 허와 실을 조명하려는 시도였다면, 'AI as Normal Technology'는 AI의 미래 영향을 생각하기 위한 새로운 프레임워크(framework)를 제시합니다. 이 변화는 단순히 기술적 관점을 넘어, 사회 전반에 걸친 AI의 통합을 반영합니다. 저희는 이러한 새로운 관점을 통해 더욱 현실적이고 지속 가능한 AI 발전을 모색하며, 독자 여러분의 지속적인 관심과 참여를 바랍니다.

**AI 시대의 가장 혼란스러운 한 가지**
현재 AI 기술의 본질을 이해하는 것에 관한 것입니다. 저희는 AI의 신비화를 해소하는 것에 관한 것이므로, 기술적 오해를 바로잡고 실제 적용 사례를 탐구합니다. 바로 AI는 단순히 느슨하게 관련된 기술들의 집합을 아우르는 포괄적인 용어(umbrella term)가 아니라, 각기 다른 목적과 한계를 가진 복잡한 시스템의 총체라는 것입니다. 이러한 복잡성은 AI의 잠재력만큼이나 많은 과제를 안겨줍니다.

AI가 포괄적인 용어(umbrella term)를 넘어 실생활에 깊숙이 침투하면서, 저희는 각 유형의 AI를 다르게 다룹니다. 오늘날 예측 AI(predictive AI)는 금융, 의료 분야에서 중요한 의사결정을 지원하며, 생성 AI(generative AI)는 창작의 영역을 확장하고 있습니다. 또한 소셜 미디어(social media) 콘텐츠 조정(content moderation)에 사용되는 AI는 정보의 홍수 속에서 질서를 유지하려 노력합니다. 이와 함께 AI가 실존적 위험(existential risk)인지 여부에 대한 논쟁은 여전히 뜨겁습니다. 저희는 AI 스네이크 오일(AI snake oil)이 왜 계속 존재하는지, 그리고 미래에 어떤 일이 일어날 수 있는지에 대한 깊이 있는 논의로 마무리합니다. AI 스네이크 오일(AI snake oil)이란 실제 가치 없이 과장되거나, 작동하지 않거나 (어쩌면 작동할 수 없는) AI 애플리케이션(application)을 의미하며, 이러한 현상은 여전히 우리 주변에 만연합니다. 저희의 목표는 AI 기술의 과장(hype)을 식별하기 위한 명확한 가이드(guide)를 제공하는 것입니다. 더 나아가, 잘 작동하더라도 해로운 AI도 살펴봅니다. 예를 들어, 대규모 감시(mass surveillance)에 사용되는 안면 인식(face recognition)과 같은 기술의 윤리적 딜레마를 심층 분석합니다.

이러한 논의는 폭넓은 독자층을 대상으로 하지만, 저희는 단순히 기존의 주장들을 되풀이하지 않습니다. 저희는 학술적 기여를 하며, 실제 적용 사례를 통해 AI의 복잡성을 해부합니다. 곧 AI 교육에 활용될 수 있는 실습 문제와 심층 토론 질문을 공개할 예정입니다. 이는 일반 대중뿐만 아니라 정책 입안자, 개발자, 그리고 AI를 연구하는 모든 이들에게 비판적 사고를 촉진하고, 정보에 입각한 의사결정을 내릴 수 있도록 돕기 위함입니다.

**AI 개념의 재정의 및 적용**
저희는 이 논의의 주요 논지를 요약하는 것으로 시작합니다. AI의 정의(더 중요하게는, 왜 정의를 내리기 어려운지)에 대한 탐구는 기술 이해의 첫걸음입니다. 생성 AI(Generative AI)는 지난 10년간 엄청난 발전을 이루었으며, 예술, 디자인, 연구 등 다양한 분야에서 혁신적인 변화를 이끌고 있습니다. 반면에 예측 AI(predictive AI)는 채용, 은행 업무, 보험, 교육 등에서 중요한 결정을 내리기 위해 결과를 예측하는 데 사용됩니다. 하지만 예측 AI(predictive AI)는 데이터에서 광범위한 통계적 패턴(statistical pattern)을 찾을 수 있지만, 그것보다 훨씬 더 많은 것을 할 수 있는 것처럼 마케팅(marketing)되고 있으며, 이는 실제 세계에서 큰 오작동(misfire)으로 이어집니다. 마지막으로, 저희는 소셜 미디어(social media) 콘텐츠 조정(content moderation)을 위한 AI의 이점과 한계를 논의합니다. 이러한 논의는 AI 기술의 실제적 가치와 잠재적 위험을 동시에 조명합니다.

**예측 AI의 한계와 윤리적 문제**
예측 AI(predictive AI)는 사람들에 대한 예측을 하는 데 사용됩니다. 예를 들어, 신용 평가, 범죄 재범 위험 예측, 심지어는 직무 성과 예측에 이르기까지 그 범위는 광범위합니다. 이러한 예측은 중요한 결정을 내리는 데 사용됩니다. 그러나 개발자들은 종종 그 효용성을 과장하지만, 실제로는 고치기 어려운 여러 가지 단점을 가지고 있습니다. 저희는 이 분야에서 예측 AI(predictive AI)가 실패한 다양한 사례들을 분석하고, 실제 세계에서 데이터 편향(bias)과 알고리즘의 불투명성(opacity)이 어떻게 심각한 사회적 불평등을 야기하는지 보여줍니다.

**미래 예측의 불확실성**
과연 AI는 미래를 예측할 수 있는가? 예측 AI(predictive AI)의 단점은 기술적 한계에 기인하는가, 아니면 근본적인 불확실성에 뿌리를 두고 있는가? 이 장에서는 AI의 유무와 관계없이 미래를 예측하는 것이 왜 어려운지 살펴봅니다. 일기 예보와 같은 일부 영역에서는 꾸준한 발전을 이루었지만, 복잡계(complex system)로서의 사회 현상이나 인간 행동의 예측은 여전히 난제로 남아있습니다. 이러한 발전이 개인의 삶의 결과, 혁신적인 기술의 시장 성공, 또는 기후 변화(climate change)와 같은 다른 환경으로 쉽게 전환될 수 없다고 주장합니다. 이것은 예측이 언제 정확할 것으로 기대해야 하는지에 대한 직관(intuition)을 기르는 데 도움이 될 수 있는 기초 지식입니다.

**생성 AI(generative AI)로 가는 긴 여정**
생성 AI(generative AI)의 최근 발전은 갑작스러워 보일 수 있지만, 이는 70년 이상에 걸친 일련의 개선 사항들을 기반으로 합니다. 이 장에서는 생성 AI(generative AI)로 이어진 컴퓨팅(computing) 발전의 역사를 되짚어보며, 인공지능 분야의 핵심 패러다임(paradigm) 전환을 분석합니다. 저희는 생성 AI(generative AI)의 현재 동향에 대해 많이 썼지만, 이 글에서는 그 과거를 살펴봅니다. 특히, 대규모 언어 모델(Large Language Models, LLM)과 확산 모델(diffusion models)의 등장 배경과 기술적 원리를 심층적으로 다루며, 이는 미래에 무엇을 기대해야 할지 이해하는 데 중요합니다.

**AI와 실존적 위험(existential threat) 논쟁**
과연 고급 AI(advanced AI)는 실존적 위협(existential threat)인가? AI가 인류를 전멸시킬 것이라는 주장은 흔합니다. 여기서는 AI의 실존적 위험(existential risk)에 대한 주장을 비판적으로 평가하고, x-risk에 대한 대중적인 논의에서 여러 가지 단점과 오류를 발견합니다. 저희는 이러한 종말론적 시나리오(scenario)가 현실적 근거가 부족하며, 오히려 현재 우리가 직면한 AI의 윤리적, 사회적 문제들을 간과하게 만들 수 있다고 주장합니다. 고급 AI(advanced AI)의 위협 여부와 관계없이, 저희는 사회적 회복력(resilience)을 향상시키는 AI 위험에 대비하는 실용적인 접근 방식들을 논의합니다.

**AI는 왜 소셜 미디어(social media)를 고칠 수 없는가?**
AI가 많이 사용되는 한 분야는 소셜 미디어(social media) 플랫폼(platform)의 콘텐츠 조정(content moderation)입니다. 저희는 소셜 미디어(social media)에서 AI 사용의 현재 상태를 논의하고, AI의 개선만으로는 플랫폼(platform)의 콘텐츠 조정(content moderation) 문제를 해결하기 어려운 일곱 가지 이유를 강조합니다. 여기에는 인간의 복잡한 의도를 파악하기 어려운 AI의 한계, 문화적 맥락(context)의 이해 부족, 그리고 악의적인 사용자들이 끊임없이 새로운 회피 전략(evasion strategy)을 개발한다는 점 등이 포함됩니다. 이러한 기술적 한계는 정책적, 사회적 접근 방식의 중요성을 더욱 부각시킵니다.

**AI에 대한 신화는 왜 지속되는가?**
기업, 연구자, 언론인 모두 AI 과장(hype)에 기여하며, 이는 일반 대중의 AI에 대한 이해를 왜곡시키는 주된 원인이 됩니다. 저희는 AI에 대한 신화가 어떻게 만들어지고 어떻게 지속되는지 논의합니다. 이 과정에서 여러분이 적절한 회의론(skepticism)을 가지고 AI 뉴스를 읽고, 스네이크 오일(snake oil)을 팔려는 시도를 식별할 수 있는 도구를 제공하고자 합니다. 또한, 특정 기술이 만능 해결책인 것처럼 포장되는 경향을 비판적으로 분석하며, 실제 AI 기술의 한계와 잠재력을 균형 있게 이해하는 것이 중요함을 역설합니다.

**이제 어디로 가야 하는가?**
이전 논의가 기술의 공급 측면에 초점을 맞추는 동안, 마지막으로는 AI 스네이크 오일(AI snake oil)에 대한 수요가 어디에서 오는지 살펴봅니다. 이는 단순히 기술 공급자의 문제가 아니라, 사회적 기대와 인식의 문제임을 지적합니다. 또한 AI가 미래의 일자리에 미치는 영향, 규제(regulation)의 역할과 한계, 그리고 우리 앞에 놓인 많은 가능한 미래에 대한 짧은 이야기(vignette)들로 마무리합니다. 저희는 기술 발전의 방향을 결정할 주체성(agency)을 가지고 있으며, 우리 각자는 이러한 미래를 형성하는 데 중요한 역할을 할 수 있습니다. 이 글이 유용하다고 생각하시기를 바라며, 여러분의 건설적인 의견을 듣기를 기대합니다.

**전문가 의견 및 산업 동향**
이 분야의 선도적인 논의에서, 뉴요커(The New Yorker)지를 비롯한 주요 매체들은 AI라는 포괄적인 용어(blanket term)가 성능이 떨어지는 기술들을 가리는 연막(smokescreen) 역할을 할 수 있다고 주장하며, 비판적 회의론(skepticism)을 촉구합니다. 이는 AI와 함께 일하거나 AI의 영향을 받는 사람들, 즉 거의 모든 사람에게 매우 유용한 조언입니다. 2024년 가을 최고의 기술 혁신 목록에 AI의 윤리적 사용이 선정되었으며, 전문가들은 "사실과 의견을 훌륭하게 구분하고, 개인적인 경험을 바탕으로 하며, 자신들의 견해에 대한 합리적인 이유를 제시하고 (풍부한 참고 자료 포함), 행동을 촉구하는 데 주저하지 않습니다."라고 평가합니다. AI에 대해 궁금하거나 AI를 어떻게 구현할지 결정하고 있다면, 이러한 논의는 명확한 통찰력과 침착한 사고를 제공합니다. 정책 결정을 내리든, 직장에서 AI를 사용하든, 아니면 단순히 온라인 검색에 시간을 보내든, AI가 이미 우리 삶에 어떻게 침투했는지에 대한 강력한 상기이며, AI와 상호작용하는 방식에 주의를 기울여야 한다는 설득력 있는 호소입니다.

**향후 AI 관련 행사**
9월 24일: 미래 기술 포럼(Future Tech Forum) (온라인, 무료) – AI 윤리와 사회적 영향에 대한 심층 토론.
9월 30일: 혁신 기술 동문 행사(Innovation Alumni Event) (온라인, 무료) – 실제 산업 사례를 통한 AI 적용 전략 공유.
10월 24일: 지역 기술 커뮤니티 미팅(Local Tech Community Meeting) (지역 거점, 무료) – AI 개발자 및 사용자 네트워킹(networking) 기회.

**주요 AI 팟캐스트(Podcast) 및 인터뷰**
머신러닝 스트리트 토크(Machine Learning Street Talk)의 최신 에피소드, 20VC의 AI 산업 분석, 스케일링 이론(Scaling Theory)의 기술 스타트업(startup) 이야기, MIT CSAIL의 연구 동향, 그리고 퓨처 텐스(Future Tense)의 미래 전망 등 다양한 채널에서 AI에 대한 심층적인 논의를 찾아볼 수 있습니다. 저희는 기술 출시 시점에 방영될 다른 많은 팟캐스트(podcast)에도 출연했으며, 이 목록을 계속 업데이트할 예정입니다.

**AI 학습 및 참여 리소스**
다양한 AI 학습 및 참여 리소스를 통해 AI 기술에 대한 이해를 심화할 수 있습니다:
미국: 아마존(Amazon) 학습 플랫폼, 온라인 코스웨어(courseware) 북샵(Bookshop), 기술 서적 전문점 반스 앤 노블(Barnes and Noble), 주요 대학교 출판부(University Press)의 학술 자료. 오디오북(Audiobook) 및 킨들(Kindle) 에디션(edition)으로도 제공됩니다.
영국: 블랙웰스(Blackwell’s)의 기술 서적, 워터스톤스(Waterstones)의 대중 과학 서적.
캐나다: 인디고(Indigo)의 AI 관련 도서 및 자료.
독일: 아마존(Amazon), 쿨투어카우프하우스(Kulturkaufhaus)의 전문 서적.
인도: 아마존(Amazon)을 통해 국제적으로 다양한 AI 리소스들을 사전 주문(preorder)할 수 있습니다.