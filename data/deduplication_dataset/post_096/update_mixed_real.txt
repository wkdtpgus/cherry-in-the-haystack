YouTube에서 시청하거나, Apple Podcast, Spotify에서 듣거나, 즐겨 사용하는 플레이어에 저희 RSS 피드를 추가하세요!

Chris Lattner가 저희 팟캐스트에 처음 출연했을 때, 저희는 에피소드 제목을 '어려운 길을 가다(Doing it The Hard Way)'로 정했습니다. 당시 Modular 팀은 단순히 추론 플랫폼을 만들고 GPU 성능 차트를 자랑하는 것을 넘어, 컴파일러(compiler) 수준의 깊이까지 파고들어 전체 소프트웨어 스택을 처음부터 재구축하는 길을 선택했습니다. Chris Lattner가 설명하는 것처럼, Modular는 '동심원(concentric circles)' 구조로 설계되어 있습니다. 사용자는 필요한 레이어에만 집중할 수 있으며, 그 아래의 복잡한 기반 시설(plumbing)은 선택적으로 활용하거나 건드릴 필요가 없습니다.

이전 에피소드에서 Mojo의 근본적인 설계 원칙에 대해 깊이 있게 다루었으니, 더 자세한 내용은 해당 에피소드를 참고하시면 좋습니다. Mojo의 독창성 핵심은 명확합니다. Mojo는 텐서 코어(tensor cores), TMA(Tensor Memory Accelerator)와 같은 모든 가속기 명령어를 파이썬에 익숙한(Python-familiar) 구문으로 노출함으로써, 개발자들이 다음과 같은 이점을 누릴 수 있도록 합니다.

*   **하드웨어 독립성**: 한 번 작성된 코드를 H100, MI300, 또는 최근 발표된 MI325 및 미래의 Blackwell과 같은 다양한 가속기 하드웨어로 손쉽게 리타겟팅(re-target)할 수 있습니다.
*   **압도적인 성능**: CPython 대비 10배에서 100배 이상 빠른 실행 속도를 자랑하며, 동일한 알고리즘을 사용했을 때 Rust보다도 뛰어난 성능을 보이는 경우가 많습니다.
*   **제로 바인딩 확장성**: 바인딩이 필요 없는(zero-binding) 확장 언어로서 기능하며, `import my_fast_fn.mojo`와 같은 간단한 구문을 사용하여 일반 파이썬 코드에서 Mojo 모듈을 직접 호출할 수 있습니다.

이러한 Mojo의 특성은 기존에 필요했던 Triton/CUDA 커널(kernel)이나 복잡한 C++ '글루(glue)' 코드의 필요성을 크게 줄여주어 개발 과정을 간소화합니다.

이와 동일한 풀스택(full-stack) 최적화 접근 방식은 Modular의 MAX 추론 플랫폼에도 일관되게 적용되었습니다.

MAX의 주요 특징은 다음과 같습니다:
*   **경량화된 기본 이미지**: 파이썬 디스패치 경로(Python dispatch path)를 제거함으로써 Max의 기본 이미지 크기는 약 1GB에 불과합니다.
*   **광범위한 모델 지원 및 최적화**: Flash-Attention, Paged KV, DeepSeek 스타일 MLA(Multi-Layer Attention) 등 최신 LLM(Large Language Model) 추론에 필수적인 모든 최적화 기술이 포함된 사전 빌드된 컨테이너(container)를 통해 500개 이상의 모델을 지원합니다.
*   **오픈 소스 커뮤니티 활성화**: 오픈 소스 커뮤니티의 적극적인 참여와 기여를 장려하기 위해 정기적인 나이틀리 빌드(nightly builds)를 배포하고 있습니다.

**최신 소식: AMD와의 협력 강화 및 멀티벤더 전략**
최근 Modular는 AMD와의 전략적 협력을 통해 중요한 발표를 했습니다. 인기 있는 오픈 소스 모델들을 vLLM 환경에서 실행했을 때, NVIDIA의 최신 H200 GPU와 AMD의 MI325 GPU 간의 성능이 거의 대등하다는 것을 입증했습니다. 이는 AI 가속기 시장에서 NVIDIA의 독점적인 지위를 넘어 멀티벤더 생태계를 구축하려는 Modular의 비전이 현실화되고 있음을 보여주는 강력한 신호입니다. 이러한 움직임은 개발자들에게 더 넓은 하드웨어 선택권을 제공하고, 특정 벤더에 대한 종속성을 줄이는 데 크게 기여할 것입니다.

Chris Lattner는 현재 'AI 컴퓨팅의 민주화(Democratizing AI Compute)'라는 제목의 블로그 시리즈를 통해 활발한 활동을 이어가고 있습니다. 이 시리즈는 CUDA가 해결하고자 했던 문제들에 대한 심도 깊은 분석을 제공하는 동시에, Modular의 독특한 접근 방식을 가장 명확하고 일관되게 설명하는 자료로 평가받고 있습니다. 더 자세한 내용은 다음 링크에서 확인하실 수 있습니다: https://www.modular.com/democratizing-ai-compute

Chris Lattner는 이미 GCC를 LLVM으로, 그리고 Objective-C를 Swift로 성공적으로 대체한 경험이 있습니다. 과연 Mojo가 AI 시대의 CUDA를 대체하는 다음 주자가 될 수 있을까요? 이번 에피소드에서는 이러한 비전을 현실로 만들기 위해 어떤 노력과 기술적 진보가 필요한지에 대해 심도 있게 다루었습니다. 지금 바로 에피소드를 감상하고, 미래 AI 컴퓨팅의 방향을 함께 확인해 보세요!

**쇼 노트**

*   Chris Lattner
*   Tim Davis
*   Modular
*   LLVM Foundation
*   MAX
*   MLIR
*   PyBind11
*   NanoBind
*   GPU Mode Keynotes

**타임스탬프**

*   [00:00:00] 소개
*   [00:00:12] Modular 개요 및 컴퓨팅의 형태
*   [00:02:27] Modular의 R&D 단계
*   [00:06:55] CPU 최적화에서 GPU 지원까지
*   [00:11:14] MAX: Modular의 추론 프레임워크
*   [00:12:52] Mojo 프로그래밍 언어
*   [00:18:25] MAX 아키텍처: Mojo에서 클러스터 규모 추론까지
*   [00:29:16] 오픈 소스 기여 및 커뮤니티 참여
*   [00:32:25] VLLM 및 SGLang과 Modular의 차별점
*   [00:41:37] Modular의 비즈니스 모델 및 수익화 전략
*   [00:53:17] DeepSeek의 영향과 저수준 GPU 프로그래밍
*   [01:00:00] 추론 시간 컴퓨팅 및 추론 모델
*   [01:02:31] Modular를 이끌며 느낀 개인적인 소회
*   [01:08:27] 창업자로서의 일과 및 시간 관리
*   [01:13:24] AI 코딩 도구 사용 및 최신 연구 동향 파악
*   [01:14:47] 개인 프로젝트와 일과 삶의 균형
*   [01:17:05] 채용, 오픈 소스, 커뮤니티 참여

**대본**

Alessio [00:00:05]: 안녕하세요, 여러분. Latent Space 팟캐스트에 오신 것을 환영합니다. 저는 Decibel의 파트너이자 CTO인 Alessio입니다. 그리고 제 공동 진행자인 SmolAI의 창립자 Swyx와 함께합니다.

**Modular 개요 및 컴퓨팅의 형태**

Swyx [00:00:12]: 그리고 Mojo / Modular의 Chris Lattner와 함께 스튜디오에 다시 오게 되어 정말 기쁩니다. 다시 오신 것을 환영합니다.

Chris: 네, 여기 오게 되어 정말 기쁩니다. 아시다시피, 저는 두 분과 이 팟캐스트, 그리고 업계에서 일어나는 많은 일들의 열렬한 팬입니다. 초대해 주셔서 감사합니다.

Swyx: 저희를 당신의 여정에 계속 참여시켜 주셔서 감사합니다. 당신의 시간은 매우 소중하지만, 글을 쓰는 데 많은 시간을 할애하며 세상 사람들을 교육하고 계신 것 같아요. 얼마 전 GPU 모드(GPU mode) 분들과 함께한 두 시간 반짜리 워크숍을 봤는데, 정말 흥미로웠습니다. 저희는 당신의 스웩(swag)으로 한껏 꾸몄습니다. 당신이 엄청난 생산성을 가진 인간 기계이고 정말 많은 일을 해내는 부분에 대해서도 이야기해 볼 텐데요. 개인적인 차원에서도 배울 점이 많다고 생각합니다. 하지만 많은 분들이 Modular의 현황 때문에 이 자리에 오셨을 것 같아요. 저희는 이걸 컴퓨팅의 형태라고도 부르고 있는데, 아마 팟캐스트 제목이 될 것 같습니다.

Chris: 네, 정말 흥미롭습니다. 업계에 하드웨어, 소프트웨어, 그리고 모든 곳에서 혁신이 정말 많이 일어나고 있으니까요. 대부분의 사람들은 저희가 처음 했던 에피소드를 통해 Modular에 대해 알 수 있을 겁니다. 제 생각에 사람들은 그 이후로 당신이 오픈 소스화했고, 많은 업데이트가 있었다는 것을 알고 싶어 할 것 같아요. 지난 1년여간의 업데이트 중 어떤 점을 강조하고 싶으신가요? 네. 그래서 크게 봐서 Modular가 무엇이냐고 묻는다면, 네. 저희는 이제 막 4년이 넘는 시간 동안 운영되어 온 회사입니다. 꽤 오래됐죠. 처음 몇 년은 많은 사람들에게 매우 미스터리한 시간이었습니다. 왜냐하면 저는 사람들이 저희 것을 정말로 사용하기를 원하지 않았기 때문입니다. 왜 그랬을까요? 왜 사람들이 사용하지 않기를 바라는 것을 만들었을까요? 음, 그건 저희가 모든 것을 알아가는 과정에 있었기 때문입니다. 그래서 저는 저희가 매우 연구 단계에 있었다고 설명합니다. 저희는 이 정말 어려운 문제, 즉 이기종 컴퓨팅(heterogeneous compute)의 잠재력을 어떻게 열 것인가? GPU 프로그래밍을 어떻게 훨씬 더 쉽게 만들 것인가? AI 스택 전반에 걸친 풀스택(full stack) 혁신을 어떻게 더 간단하게 만들고 복잡성을 몰아냄으로써 가능하게 할 것인가? 와 같은 핵심적인 질문들을 해결하려고 노력하고 있었습니다. 그리고 저는 많은 가설을 가지고 있었죠. 하지만 기존 스택만큼 좋지 않은 대체 AI 스택을 만드는 것은 별로 유용하지 않습니다. 왜냐하면 사람들은 항상 그것을 최신 기술(state of the art)과 비교하여 평가할 것이기 때문입니다. 그 시점에서, "좋아, 그럼 이걸 일반적인 엔지니어링 문제처럼 분석해 보자"라고 말하게 됩니다. 더 이상 R&D가 아니라 엔지니어링 문제인 거죠. "좋아, 멋지군. 이 API들을 리팩터링하고, 이 기능을 폐기하고, 아, H100 지원을 추가하고, 함수 호출(function calling)과 토큰 샘플링(token sampling) 등 필요한 모든 것들을 추가하자"라고 말하게 됩니다. 그런 것들은 프로젝트 관리가 가능하죠. 그래서 저희는 6주마다 새로운 릴리스를 출시해왔습니다. 그래서 모든 함수 호출 기능을 추가했고, 이제는 에이전틱 워크플로우(agentic workflows)를 갖게 되었습니다. 현재 500개 이상의 모델을 지원하며, H100은 물론 AMD MI300 및 MI325 지원을 출시했으며, 미래의 Blackwell 같은 차세대 하드웨어까지 아우르고 있습니다. 이 모든 것들이 이제 제품에 통합되었습니다. 이렇게 되면서 갑자기 "아, 이제 알겠다" 싶어지는 거죠. 하지만 이것은 저희에게 근본적으로 다른 단계입니다. 왜냐하면 이제 작동하니까요. 일단 작동하면, 처음부터 끝까지 볼 수 있고, 많은 사람들이 머릿속에서 조각들을 맞출 수 있습니다. 더 이상 제 머릿속이나, 각각의 개별 조각들이 어떻게 작동하는지 이해하는 몇몇 사람들의 머릿속에만 있는 것이 아닙니다. 이제는 모두가 볼 수 있게 된 거죠. 그래서 저희가 국면 전환을 하면서, 갑자기 "그래, 좋아, 오픈 소스화하자"가 되는 겁니다. 이제 더 많은 사람들이 참여하기를 원하니까요. 이제 이런 각각의 일들을 해보자는 거죠. 사실, 저희는 해커톤(hackathon)을 열었습니다. 100명의 사람들을 초대해서 저희와 함께 하루를 보내고, GPU 프로그래밍을 처음부터 배웠습니다. 그리고 저희는 매우 멋진 추론 프레임워크(inference framework)를 만들었죠. 해커톤 우승팀은 4명으로 구성된 팀이었는데, 하루 만에, 그들은 이전에 Mojo를 사용해 본 적도, GPU를 프로그래밍해 본 적도 없었는데, 훈련 시스템을 만들었습니다. Adam 옵티마이저(Adam Optimizer)와 여러 훈련 커널을 작성하고, 간단한 역전파(backprop) 시스템을 구축해서, 저희가 추론을 위해 만든 모든 것들을 사용해서 모델을 훈련시킬 수 있다는 것을 실제로 보여주었습니다. 왜냐하면 그것이 매우 해킹하기 쉽고(hackable), 또한 AI 코딩 도구들이 훌륭하기 때문이죠. 하지만 이것이 바로 확장할 준비가 되었을 때 할 수 있는 일의 힘입니다. 만약 저희가 6개월 전이나 12개월 전에 그것을 했다면, 엄청난 혼란이었을 겁니다. 모든 것이 망가지고, 버그가 많았을 테니까요. 솔직히 말해서, 오늘날에도 여전히 초기 단계 시스템이고, 아직 버그가 좀 있지만, 이제는 유용합니다. 실제 문제를 해결할 수 있죠. 그것이 바로 차이점이고, 저희 팀이 겪어온 진화 과정입니다.

**CPU 최적화에서 GPU 지원까지**

Alessio [00:06:55]: 처음에 뵈었을 때, 사실 CPU에 집중하고 계셨던 것으로 기억합니다. CPU 작업은 얼마나 하셨고, CPU에서 GPU로 넘어가는 것은 얼마나 큰 도약이었나요?

Chris [00:07:06]: 음, 제가 Modular를 설명하는 방식은, 지난 4년간의 R&D 여정을 보면, 조금 반올림해서, 첫해는 컴파일 철학을 증명하는 것이었습니다. 이것은 매우 추상적인 컴파일러 작업을 작성하는 것이었고, 그 다음으로는 인텔 실리콘에서 인텔 MKL의 행렬 곱셈보다 더 빠르게 행렬 곱셈(matrix multiplication)을 수행하고, 구성 가능하게 만들고, 여러 데이터 타입을 지원하는 등 매우 좁은 문제를 증명하는 것이었습니다. 그리고 이 모든 것을 MLIR 컴파일러 표현(MLIR compiler representation)을 직접 손으로 작성함으로써 해냈는데, 정말 끔찍했죠. 하지만 우리는 기술과 기술적 이정표를 증명했습니다. 2년차에는 "좋아, 멋지군. 근본적인 접근 방식이 작동할 수 있다고 믿어. 하지만 사용성이 끔찍해. 내부 컴파일러를 손으로 작성하는 건 정말 싫어. 그리고 행렬 곱셈은 AI 프레임워크와는 거리가 멀어."라고 말하게 되었습니다. 그래서 2년차에는 두 가지 길을 갔습니다. 하나는 Mojo입니다. 프로그래밍 언어 구문, 파이썬 계열의 일원으로서, 커널 작성과 성능 등을 훨씬 더 접근하기 쉽고 쉽게 만드는 것이죠. 그리고 두 번째는, 말씀하신 대로 CPU용 AI 프레임워크를 구축하여 인텔 CPU에서 OpenVINO 같은 것들을 이기는 것이었습니다. 2년차 말에 우리는 "휴, 이 놀라운 것을 달성했어. 하지만 멋지군. GPU."라고 생각하게 되었습니다. 그래서 다시 두 가지를 말했습니다. "좋아, GPU를 할 수 있다는 것을 증명하자." 첫째, 또한 그냥 소위 말하는 'CUDA 대체재'를 만드는 것이 아니라, 실제로 유용한 것을 할 수 있다는 것을 보여주자. LLM 서빙(LLM serving)에 도전해 보자. 별거 아니지. 그렇죠. 그래서 다시, "우리가 어떤 것을 할 수 있다는 것을 증명하고, 그것을 정말 어려운 벤치마크에 대해 검증하자"라고 말한 두 가지가 저희를 3년차, 그리고 그 이후의 현재 단계로 이끌었습니다. 네. 그래서 이 각 단계는 정말 어렵고 흥미로운 기술적 문제들이 많았습니다. 음, 아마도 당신이 마주하는 가장 큰 문제는, 끊임없이 불가능하다고 말하는 사람들을 마주하는 것입니다. 하지만 다시 말하지만, 조금 고집을 부리고 자신을 믿고 열심히 일하며 이정표에 집중해야 합니다.

그들이 불가능하다고 말할 때, 그게 불가능하다는 뜻인가요, 아니면 매우, 매우 어렵다는 뜻인가요?

음, 그러니까, CUDA가 거의 20년이 되었고, NVIDIA에는 수백, 수천 명의 사람들이 작업하고 있다는 것은 상식입니다. 전 세계가 수년 동안 CUDA 코드를 작성해왔고, 매우, 매우 어렵습니다. 그래서, 아니요, 많은 사람들은 스타트업이 이 분야에서 무언가를 하는 것이 불가능하다고 생각합니다. 네. 그건 그냥 상식이죠. 이 모든 사람들이 이 모든 다른 시스템에 그 모든 돈을 쏟아부었고, 모두 실패했습니다. 다른 똑똑한 사람들이 만든 다른 모든 것들이 실패했는데, 왜 당신의 것이 성공할 것이라고 생각하나요? 그렇죠. 그래서 변화가 불가능하다는 것이 일반적인 통념이지만, 이봐요, 우리는 AI 시대에 살고 있잖아요. 우리 주변에는 항상 변화가 있죠. 그렇죠. 그래서 당신이 해야 할 일은 성공 기준이 무엇인지, 변화가 실제로 작동하게 하는 원인이 무엇인지를 계획하는 것입니다. 그리고 제 경력 전반에 걸쳐, LLVM 때처럼, 모든 GCC 사람들은 저에게 불가능하다고 말했습니다. "LLVM은 실패할 거야. 왜냐하면 GCC는 20년이 되었고, 수백 명의 사람들이 작업해왔고, 어쩌고 저쩌고. 그리고 스펙 벤치마크." 그리고 뭐든 간에. 밖에서는 아무도 저에게 불가능하다고 말하지 않았습니다. 왜냐하면 비밀이었으니까요. 그래서 그건 좀 달랐지만, 애플 내부에서 그것에 대해 아는 모든 사람들은 "아니, 아니, Objective-C는 괜찮아. 그냥 Objective-C를 개선해야 해. 세상은 새로운 프로그래밍 언어가 필요 없어. 새로운 프로그래밍 언어는 절대 채택되지 않아."라고 말했습니다. 네. 그렇죠. 그리고 "새로운 프로그래밍 언어는 아무 데도 가지 못한다"는 것은 상식입니다. 그것이 일반적인 통념이죠. 아시다시피, MLIR은 정말 웃깁니다. MLIR은 또 다른 컴파일러입니다. 그래서 이걸 만들어서 LLVM 커뮤니티에 가져가서 "이봐요, 우리 이거 오픈 소스화했어요. LLVM에서 작동하나요? 저 LLVM 사람들 좀 알아요."라고 말했습니다. 그렇죠? 제 박사 과정 프로젝트였고, 커뮤니티의 모든 LLVM 권위자들(LLVM Illuminati)은 15년 동안 LLVM 작업을 해왔습니다. 그들은 "아니, 아니, LLVM은 충분히 좋아. 새로운 건 필요 없어. 머신러닝은 그렇게 중요하지 않아."라고 말했습니다. 그래서 다시, 분명히 이런 종류의 도전을 해결하기 위한 몇 가지 기술을 개발했지만, 인간은 변화를 좋아하지 않는다는 현실로 돌아가게 됩니다. 그리고 변화가 있을 때, 그것이 생태계에 확산되는 데는 시간이 걸립니다. 사람들이 그것을 처리하는 데 시간이 걸리죠. 그리고 이것이 우리가 해커톤에 대해 이야기하는 부분입니다. 새로운 것에 대해 사람들을 가르쳐야 합니다. 그래서 블로그 포스트 시리즈 같은 것들이 모두 이런 교육 캠페인의 일부인 것입니다. 왜냐하면 이 모든 것들이 실제로 불가능한 것은 아니기 때문입니다. 단지 정말 힘든 작업이고, 엘리트 팀과 좋은 비전, 지도 등이 필요할 뿐입니다. 하지만 이것을 하는 것이 불가능하다는 것이 이해할 만한 일반적인 통념입니다.

**MAX: Modular의 추론 프레임워크**

Alessio [00:11:14]: 그리고 기본적으로 서빙을 구축하려는 아이디어군요. 이게 얼마나 더 좋은지 말할 필요도 없이, 그냥 우리 플랫폼을 사용해서 모델을 실제로 서빙하면 얼마나 더 빠른지 볼 수 있고, 그러면 당연히 채택하게 될 거라는 거죠. 네.

Chris [00:11:27]: 음, 오늘 MAX를 다운로드할 수 있습니다. 무료로 제공되고요. 원한다면 수천 개의 GPU로 확장할 수도 있습니다. 무료로요. 몇 가지 멋진 점을 말씀드리죠. VLLM 같은 것만큼 좋지는 않습니다. 몇 가지 기능이 빠져 있고, 예를 들어 NVIDIA와 AMD 하드웨어만 지원하니까요. 하지만 그런데, 컨테이너가 1기가바이트 정도밖에 안 돼요. 와. 그렇죠. 왜 1기가바이트일까요? 음, 완전히 새로운 스택이기 때문입니다. 필요가 없죠. CUDA를 사용할 수도 있고, 임의의 PyTorch 모델을 실행할 수도 있습니다. 만약 그렇다면, 몇 가지 의존성을 가져와야겠죠. 하지만 사람들이 정말로 신경 쓰는 일반적인 LLM과 Gen AI 모델을 실행한다면, 글쎄요, 완전히 네이티브 스택입니다. 매우 효율적이죠. 즉시 실행 모드 연산 디스패치(eager mode op dispatch) 같은 것을 위해 루프에 파이썬이 없습니다. 왜냐하면 그런 모든 의존성이 없기 때문이죠. 서버가 정말 빨리 시작됩니다. 그래서 수평적 자동 확장(horizontal auto scaling)에 관심이 있다면, 그건 정말 멋진 일입니다. 신뢰성에 관심이 있다면, 그것도 꽤 멋지죠. 그 안에는 이런 이상한 것들이 쌓여 있지 않습니다. 만약 약간 커스텀한 것을 하고 싶다면, 모든 것을 완전히 제어할 수 있고, 모든 것이 오픈 소스입니다. 그래서 해킹할 수 있죠. 이건 VLM보다 더 오픈 소스입니다. 왜냐하면 VLM은 NVIDIA에서 온 불투명한 덩어리인 온갖 이상한 바이너리 CUDA 커널(binary CUDA kernels)에 의존하기 때문입니다. 그렇죠. 그래서 이것은 매우 다른 세상입니다. 그래서 저는 모든 사람들이 하룻밤 사이에 VLM을 버리기를 원하지는 않습니다. 왜냐하면 저는 그것이 훌륭한 프로젝트라고 생각하기 때문입니다. 그렇죠. 하지만 제 생각에는 여기에 몇 가지 흥미로운 점이 있고, 특정 사람들에게 흥미로운 구체적인 이유가 있습니다.

Alessio [00:12:47]: MAX의 구성 요소에 대해 간단히 설명해 주실 수 있나요? 지난번에는 이런 것들이 전혀 없었던 것 같아서요.

**Mojo 프로그래밍 언어**

Chris [00:12:52]: 네, 맞아요. 지난번은 AI 시간으로도, Modular 시간으로도 아주 오래전이었죠. 네. 저희 스택의 맨 아래에는, 저희는 이것을 동심원(concentric circles)으로 생각하는데요. 안쪽에는 Mojo라는 프로그래밍 언어가 있습니다. "Chris, 왜 또 다른 프로그래밍 언어를 만들어야 했나요?" 음, 대답은 기존 언어 중 어느 것도 실제로 문제를 해결하지 못했기 때문입니다. 그럼 문제는 무엇일까요? 음, 문제는 이제 모든 컴퓨팅이 가속화되었다는 것입니다. 네. GPU가 있고, TPU가 있고, 이 모든 칩들이 있고, CPU도 있습니다. 그래서 우리는 이 모든 것을 아우를 수 있는 프로그래밍 언어가 필요합니다. 그래서 쇼핑을 가서 그것을 보면, 가장 좋은 것은 C++ 정도입니다. OpenCL이나 SYCL 같은 것들이 있고, HPC 커뮤니티에서 나온 수많은 것들이 다른 종류의 하드웨어를 아우르려고 시도했습니다. 제가 먼저 말씀드리자면, 그리고 이제는 이렇게 말해도 괜찮을 것 같은데, C++는 형편없습니다. 저는 그럴 자격이 있습니다. 그렇게 많이 작성했으니까요. 그리고 AI 사람들은 일반적으로 C++를 좋아하지 않는다고 주장하겠습니다. 그들은 무엇을 좋아할까요? 그들은 파이썬을 좋아합니다. 그렇죠. 그래서 저희가 결정한 것은, "좋아, C++의 영역 내에서도 텐서 코어(tensor cores) 같은 것들과 통신할 수 있는 실제로 좋은 통합적인 것이 없다"는 것이었습니다. 그래서 저희는 "좋아, 나는, Chris가 비합리적이게도, 한 공급업체에서 나온 칩 하나만이 아니라, 어떤 칩의 모든 성능을 드러낼 수 있는 것을 원한다. 그것은 그래프 컴파일러(graph compilers)와 같은 다음 수준의 매우 멋진 컴파일러와 다른 것들을 지원해야 하고, 이식성이 있어야 한다. 공급업체 간에 이식성이 있어야 하고, 이식 가능한 코드를 가능하게 해야 한다."고 말했습니다. 네, H100과 AMD 칩은 실제로는 꽤 다릅니다. 그건 사실입니다. 하지만 그 사이에는 재사용할 수 있는 것이 많습니다. 그래서 공통 코드가 많을수록 좋습니다. 다른 부분은 사용성입니다. 그래서 우리는 사람들이 실제로 사용하고 배울 수 있는 것을 원합니다. 그래서 파이썬 구문을 갖는 것만으로는 충분하지 않습니다. 성능과 제어, 그리고 다시 말해, 하드웨어의 모든 성능을 원합니다. 그리고 이것이 Mojo가 탄생한 배경입니다. 그래서 오늘날 Mojo는 두 가지에 정말 유용합니다. Mojo는 시간이 지남에 따라 성장할 것이지만, 오늘날 저는 성능이 중요한 곳에 사용하기를 권장합니다. 예를 들어 GPU에서 실행되는 것이나, 웹 서버 내에서 연속적인 배치 처리를 하는 것과 같이 매우 고성능이 필요한 경우, 또는 멋진 해싱을 해야 하는 경우 등 성능이 중요하다면 Mojo는 좋은 것입니다. 우리가 곧 이야기할 또 다른 멋진 점은, 계속 주목해 주세요, 파이썬을 확장하는 가장 좋은 방법이라는 것입니다. 만약 당신이 큰 파이썬 코드 덩어리를 가지고 있고, 성능에 신경을 쓴다면, 파이썬에서 성능 부분을 빼내고 싶을 겁니다. 우리는 그것을 Mojo로 옮기는 것을 매우 쉽게 만듭니다. Mojo는 파이썬보다 약간 더 빠른 것이 아니라, Rust보다 빠릅니다. 파이썬보다 수만 배 빠르죠. 그리고 파이썬 계열에 속해 있습니다. 그래서 말 그대로 일부 for 루프를 뜯어내서 Mojo에 넣으면 성능 향상을 얻을 수 있습니다. 그리고 그 자리에서 코드를 개선하기 시작할 수 있습니다. GPU로 오프로드할 수도 있고, 이런 것들을 할 수 있습니다. 그리고 모든 패키징은 매우 간단하며, 파이썬 코드를 빠르게 만드는 아름다운 방법입니다.

Swyx: 좀 더 자세히 설명해 주시자면, 이걸 곧 출시할 거라고 하셨나요?

Chris: 기술적으로는 저희 나이틀리 빌드(nightlies)에 있지만, 아직 공식적으로 발표하지는 않았습니다. 그렇지 않나요? 좋아요. 저희는 그런 일을 많이 합니다. 왜냐하면 저희는 매우 개발자 중심적이기 때문입니다. 그래서 저희 Discord나 Discourse에 가입하면, 나이틀리 빌드는 훌륭합니다. 최고의 프로그램이죠. 네. 그래서 저희는 발표되지 않았지만 커뮤니티에서는 잘 알려진 것들이 많이 있습니다.

좋아요. 저는 이게 이미 출시된 줄 알았어요. 네. 네.

Alessio [00:16:12]: 그리고 뜯어낸다고 하셨는데, 이건 Mojo를 실행하기 위한 파이썬 바인딩이 있다는 건가요? C 바인딩 같은 게 있나요, 아니면 어떻게 작동하나요?

Chris [00:16:19]: 이게 멋진 점인데, 바인딩이 필요 없습니다(binding-free). 생각해보세요, 오늘날, 죄송합니다, 제가 이것에 대해 흥분해서 우리 벽 밖의 세상이 얼마나 비극적인지 잊어버리네요. 우리가 경쟁하는 것은, 만약 당신이 큰 파이썬 코드 덩어리를 가지고 있다면, 우리 중 많은 사람들이 그렇듯이, 그것을 만들고, 만들고, 만들고, 만들다 보면 성능이 문제가 됩니다. 좋아요. 그럼 어떻게 해야 할까요? 음, 몇 가지 다른 방법이 있습니다. "내 전체 애플리케이션을 Rust 같은 걸로 다시 작성하겠다"고 말할 수 있습니다. 그렇죠? 어떤 사람들은 그렇게 합니다. 다른 방법은 "좋아, Pybind나 Nanobind 또는 어떤 Rust 도구 같은 것을 사용해서 내 모듈의 일부, 성능이 중요한 부분을 다시 작성하겠다"고 말하는 것입니다. 이제 이 바인딩 로직과 이 빌드 시스템의 복잡함, 그리고 이쪽에 Rust 코드가 있고 저쪽에 파이썬 코드가 있는 이 모든 복잡성을 감당해야 합니다. 아, 그리고 이제 Rust와 파이썬 작업을 할 수 있는 사람들을 고용해야 합니다. 그렇죠. 그래서 이것은 팀을 분열시킵니다. Rust 개발자를 고용하는 것은 매우 어렵습니다. 저는 그들을 사랑하지만, 그 수가 너무 적습니다. 그래서 우리가 하는 일은 "좋아, 기본적으로 같은 언어를 유지하자"고 말하는 것입니다. Mojo는 파이썬이 가진 모든 기능을 가지고 있지는 않습니다. 특히, Mojo에는 클래스가 없습니다. 하지만 함수는 있습니다. 네, 임의의 파이썬 객체를 사용할 수 있습니다. 이 바인딩 없는 경험을 얻을 수 있고, 매우 유사합니다. 그래서 이것을 매우 빠르고, 약간 더 제한적인 파이썬으로 볼 수 있습니다. 그리고 이제 생태계 내에서 응집력이 생깁니다. 네. 그래서 저는 이것이 단지 AI 생태계를 넘어서서 유용하다고 생각합니다. 이것은 파이썬 전반에 걸쳐 꽤 멋진 것이라고 생각합니다. 하지만 이제 GPU를 가져와서 "좋아, 당신의 코드를 가져와서 정말 빠르게 만들 수 있다"고 말합니다. 왜냐하면 CPU에는 자체 텐서 코어와 SIMD, 그리고 이 모든 것들과 같은 멋진 기능들이 많이 있기 때문입니다. 그런 다음 그것을 GPU에 올릴 수 있습니다. 그리고 그것을 8개의 GPU에 올릴 수 있습니다. 그래서 계속 나아갈 수 있습니다. 그리고 이것은 Rust가 할 수 없는 것입니다. 그렇죠. Rust를 GPU에 올릴 수는 없습니다, 정말로요. 그렇죠. 이런 것들처럼요. 그리고 이것은 우리가 세상에 내놓고 있는 새로운 기술의 물결의 일부입니다. 그리고 또한, 죄송합니다, 제가 우리가 출시한 것과 곧 출시할 것에 대해 흥분해서요. 하지만 2024년 가을은 훨씬 더 재미있을 겁니다. 좋아요. 그러니 계속 주목해 주세요. AMD와 NVIDIA 외에 더 많은 하드웨어가 있을 수 있습니다. 멋지네요.

**MAX 아키텍처: Mojo에서 클러스터 규모 추론까지**

Swyx [00:18:25]: 그게 Mojo였군요. 네. 첫 번째 동심원. 네.

Chris [00:18:28]: 제가 길을 잃지 않게 해주셔서 감사합니다. 그래서 안쪽 원은 프로그래밍 언어입니다. 그렇죠? 그리고 그것은 무언가를 빠르게 만드는 좋은 방법입니다. 그리고 다음 단계는 "좋아, 멋진 게 뭔지 알아? AI야. 내가 설득했나?"라고 말하는 것입니다. 그래서 AI의 세계로 들어가면 모델에 대해 생각하기 시작합니다. 그리고 모델을 넘어서, 이제 우리는 Gen AI를 가지고 있습니다. 그래서 파이프라인 같은 것들이 있죠. 그리고 KV 캐시 오케스트레이션(KV cache orchestration)과 상태 기반 배치 처리(stateful batching)가 있는 전체 파이프라인이 있습니다. 제 말은, 여러분이 전문가시잖아요, 에이전틱(agentic)한 모든 것과 이런 종류의 모든 것들이요. 그래서 다음 단계는 Max라고 부르는 매우 간단한 Gen AI 추론 중심의 프레임워크입니다. 그래서 Max에는 서빙 구성 요소가 있습니다.

Max 엔진(Max Engine)인가요? 네. 네. 좋아요. 다른 섹션들이 있군요.

우리는 그냥 Max라고 부릅니다. 하위 브랜드로 너무 복잡해졌어요. 이것도 우리 브랜딩에 대한 R&D의 일부입니다.

HBO도 같은 문제가 있죠.

네, 맞아요. 그리고 또, 누가 LLVM이라고 이름 지었을까요? 도대체 그게 무슨 뜻이죠? 그렇죠? 그래서-

솔직히, 짧고 구글 검색도 잘 돼요. 최악은 아니죠.

네. 그리고 VLLM이 와서 그걸 망쳐놨죠. 네. 네. 아니요. 그래서 Max는, 그것에 대해 생각하는 방식은, PyTorch가 아니라는 겁니다. 그것이 되고자 하는 것이 아니라, 추론에 정말 집중되어 있습니다. 성능과 제어, 그리고 지연 시간에 정말 집중되어 있죠. 그리고 만약 모델 로직의 루프에서 파이썬을 빼내는 것을 작성하고 싶다면, 제어에 정말 좋습니다. 그래서 Mojo와 직접적으로 작동하도록 설계되었습니다. 많은 LLVM 내에서, LLM 애플리케이션에는, 여러분도 아시다시피, 매우 맞춤화된 GPU 커널이 많이 있습니다. 그래서 최근에 나온 딥시크(deep seek) 같은 것들처럼 미친 형태의 어텐션이 많이 있고, 이런 것들은 항상 변합니다. 그래서 그들 중 많은 것들이 커스텀 커널입니다. 하지만 그 밖에는 그래프 레벨이 있습니다. 그리고 그것이 항상 작동해온 방식은, 예를 들어, 내부에 CUDA나 Tritonlang 같은 것들이 있고, 외부에 파이썬이 있는 것입니다. 우리는 그 모델을 받아들였습니다. 깨지지 않은 것은 고치지 말자는 거죠. 그래서 우리는 모델 레벨에 순수 파이썬을 사용합니다. 그래서 API가 있습니다. 매우 간단합니다. 화려하게 디자인된 것은 아니지만, 매우 간단한 PyTorch처럼 느껴집니다. 그리고 "어텐션 블록을 줘, 이 블록들을 줘, 이 연산들을 구성해 줘"라고 말할 수 있지만, Mojo와 직접적으로 통합됩니다. 그래서 이제 완전한 통합을 얻게 됩니다. 그리고 다른 프레임워크나 그런 것들은 당신이 실행하는 코드를 들여다볼 수 없기 때문에 얻을 수 없는 방식으로요. 그래서 이것은 자동 커널 퓨전(automatic kernel fusion) 같은 것을 얻게 된다는 것을 의미합니다. 그게 뭘까요? 음, 그것은 "좋아, 플래시 어텐션의 한 버전을 작성하면, 멋지네. 우리가 자동으로 퓨전할 수 있어"라고 말할 수 있게 해주는 매우 멋진 컴파일러 기술입니다. 그래서 당신이 사용하고 싶을 수 있는 다른 활성화 함수들을 자동으로 퓨전할 수 있고, 이 커널들의 모든 순열을 작성할 필요가 없습니다. 하지만 그것은 단지 당신이 더 생산적이 된다는 것을 의미합니다. 더 나은 성능을 얻게 된다는 것을 의미합니다. 제 말은, 많은 것들처럼, 그것은 단지 시스템의 복잡성을 낮추는 것입니다. 그래서 멋진 컴파일러가 있다는 것을 알 필요가 없어야 합니다. 모두가 컴파일러를 싫어해야 합니다. 사람들이 컴파일러에 대해 알아야 하는 유일한 이유는 그것들이 고장 났을 때입니다. 그렇죠? 그래서 이것은 마치 맞춤형 모델을 만들고 기존 모델을 맞춤화하는 것과 같은 매우 멋지고, 매우 인체공학적이며 효율적인 방법처럼 느껴집니다. 그래서 max를 사용하면, 500~600개의 매우 일반적인 모델 패밀리가 있고, build.modular.com에서 볼 수 있는 구현된 것들이 있습니다. 모델이 많이 있고, 스크롤해서 볼 수 있고, 소스 코드를 얻어서 가지고 놀 수 있습니다. 이것은 서빙과 연구, 그리고 이런 종류의 모든 것에 관심이 있는 사람들에게 정말 좋습니다. 다음 레이어는 "좋아, 단일 노드에서 서빙을 하는 매우 멋진 방법이 있네. 꽤 유용하고 중요하지. 하지만 실제로 멋진 것은 대규모 배포야."라고 말하는 것입니다. 그래서 다음 레벨, 클러스터 레벨이 있습니다. 그것은 "좋아, 멋지군. 쿠버네티스 클러스터가 있고, 플랫폼 팀이 있어. 그들은 300개의 GPU에 대해 3년 약정을 맺었어. 그리고 이제 제품 팀이 있어. 이 공유 컴퓨팅 풀에 워크로드를 던지고 싶어. 그리고 호출기를 들고 있는 사람들은 제품 팀이 제대로 행동하기를 원하고, 그래서 실제로 무슨 일이 일어나고 있는지 추적하고 싶어해."라는 것입니다. 그것이 바로 밖으로 나가는 클러스터 레벨입니다. 그리고 각 노드별로 매우 멋진 접두사 캐싱(prefix caching)이 있고, 지능적인 라우팅이 있으며, 분리된 프리필(disaggregated pre-fill)과 같은 멋진 기술들이 각 레이어에 많이 있습니다. 하지만 멋진 점은 그것들이 모두 공동으로 설계되었다는 것입니다. 네. 그리고 내부가 이기종이기 때문에, "이봐, AMD도 있고, Nvidia도 있어. 이봐, 모델을 던져서 최고의 아키텍처에서 실행해."라고 말할 수 있습니다. 음, 이것은 실제로 많은 관리 문제를 단순화합니다. 그래서 우리 모두가 AI에 내재된 것으로 내면화한 복잡성의 상당 부분은 실제로는 함께 설계되고 있는 이러한 시스템의 결과입니다. 그래서 저에게, 아시다시피, 지금 저의 최우선 목표는 복잡성을 몰아내는 것입니다. 우리 스택의 복잡성도요. 왜냐하면 우리는 여전히 고치고 있는 기술 부채가 좀 있거든요. 하지만 AI 전반의 복잡성을 몰아내는 것이죠. 그리고 AI 전반에는 그럴 만한 것보다 훨씬 더 많은 기술 부채가 있습니다.

Swyx: 음, 네. 제 말은, 당신을 제외한 대부분의 사람들이 스택의 자기 부분을 이해하고 최적화하기 위해 할 수 있는 일에는 한계가 있다는 거죠. VLLM 대 SGLang 그리고 버클리에서 나오는 모든 것들에 대해 어떤 견해나 내부자 정보가 있는지 궁금합니다.

Chris: 네, 저는 외부자 관점을 가지고 있습니다. 내부 정보는 전혀 없습니다. 음, SG Lang은 외부인으로서 제게는, 그래서 저는 어느 커뮤니티에도 직접 관여하지 않습니다.

물론이죠. 음, 그래서 저는 참여하지 않고도 팬이 될 수 있습니다만, 음, 그녀는, 그들은 싸우고 있습니다.

그래서 저는 정치나 드라마는 모르지만, SG Lang은 제게 매우 집중된 팀으로 보입니다. 특정 목표와 증명하고 싶은 것들이 있고, Modular 팀처럼 특정 목표를 향해 정말 열심히 실행하고 있습니다. 그렇죠. 그래서 거기에는 어떤 동질감이 있다고 생각합니다. VLM은 훨씬 더 많은 이해관계자와 많은 일들이 벌어지고 있는 거대한 커뮤니티처럼 보이고, 좀 엉망진창인 것 같습니다. 그래서.

하지만 그들은 모두가 벤치마킹하는 기본 추론 플랫폼이 되고 싶어 하죠.

음, 그리고, 제 생각에, 제가 아는 한, 그것은 TRT LLM이나 다른 오래된 시스템들을 압도하고 있습니다. 그래서 제 생각에 메트릭은 아마도 그것에 대해 좋을 것입니다. 그래서 저는 그들의 야망에 대해 말할 수는 없지만, 구조적으로는 매우 다른 접근 방식인 것 같습니다. 하나는 "정말 중요한 소수의 일에 정말 잘하자"고 말하는 것입니다. 네. 그것이 우리의 접근 방식이기도 합니다. 하나는 "많은 것에 '예'라고 말하자. 그러면 많은 것을 갖게 될 것이고, 그중 일부는 작동하고 일부는 작동하지 않을 것이다"라고 말하는 것입니다. VLM에 대해 제가 끊임없이 듣는 도전 과제 중 하나는, 웹페이지에 가보면, "네, 우리는 이 모든 하드웨어를 지원합니다. 구글 TPU, Inferentia, AMD, 그리고 당연히 Nvidia, CPU 등등을 지원합니다."라고 말한다는 것입니다. 그리고 그들이 지원하는 것들의 거대한 목록이 있습니다. 하지만 그리고 나서 VLM으로 무언가를 하는 방법에 대한 어떤 임의의 웹페이지의 데모를 따라 하려고 하면, 비-NVIDIA 하드웨어에서 하면 실패합니다. 그래서 VLM 같은 것의 가치는 무엇일까요? 음, 가치는 그 위에 구축하고 싶다는 것입니다. 일반적으로, 당신은 그것의 내부에 대해 집착하고 싶지 않습니다. 만약 당신이 작동한다고 광고하는 것을 가지고 있는데, 그것을 집어 들었을 때 작동하지 않고 디버깅해야 한다면, 그것은 목표에 대한 배신과도 같습니다. 그래서 저에게, 다시 말하지만, 저는 그것이 얼마나 어려운지 압니다. 저는 그들이 발명하지 않은, 솔직히 말해서 잘 작동하지 않는, 그들 아래에 있는 많은 것들 위에 구축하려고 하는 근본적인 이유를 압니다. 그렇죠. 왜냐하면 우리는 하드웨어가 어렵고, 하드웨어를 위한 소프트웨어는 요즘 훨씬 더 어렵다는 것을 알기 때문입니다. 그래서 저는 왜 그런지 이해하지만, "우리가 할 수 있는 모든 것들이 여기 있습니다"라고 말하고, 실제로 작동하는 것들의 희소 행렬을 갖는 그 접근 방식은, "좋아, 우리는 소수의 일을 정말 잘하고, 당신은 그것에 의존할 수 있다"고 말하는 보수적인 접근 방식과는 매우 다릅니다. 그래서 저는 어느 것이 더 나은지 말할 수 없습니다. 제 말은, 저는 둘 다 감사하고, 둘 다 훌륭한 아이디어를 가지고 있습니다. 그리고 경쟁이 있다는 사실은 업계의 모든 사람들에게 좋습니다.

그렇습니다. 그래서. 그들은 이 산업이 진화하는 방식의 벤치마크 전쟁 상태에 있습니다.

맞습니다. 하지만, 하지만, 저는 또한 기업 측면에서 그들이 모두 너무 좋아서 드라마를 따르고 싶어하지 않는다는 말을 듣습니다. 그렇죠. 그래서, 이것이 바로 혼란이 적고, 함께 일할 수 있는 누군가가 있다는 것이 요즘 정말 가치 있는 이유입니다. 그리고 최첨단 기술과 성능 등이 필요하지만, 잘 실행하고 함께 일할 수 있는 누군가가 있다는 것도 매우 중요합니다.

Swyx: 제품군 소개가 다 끝났나요? Max에 대해 이야기하셨죠. 네. 네. 저는 당신이 회사 이름을 Modular라고 짓고 이 모든 것을 매우 모듈식으로 설계했다는 사실에 감명받았습니다. 네. 거기에 어떤 희생이 따르는지, 아니면 모듈식이 모든 것에 대한 올바른 접근 방식인지 궁금합니다. 트레이드오프는 없나요?

Chris: 제가 나이를 좀 드러내도 괜찮다면, 모듈식 설계에 대한 저의 집착은 LLVM을 만들던 시절로 거슬러 올라갑니다. 좋아요. 그 당시에는 GCC가 있었습니다. GCC는 다시 말하지만, 저는 C와 C++ 컴파일러로서 그것을 사랑하고 존중합니다. 그렇죠. 그리고 그것에 대해 많은 존경심을 가지고 있지만, 그것은 모놀리스(monolith)입니다. 그것은 오래된 유닉스 방식, 즉 컴파일러는 유닉스 파이프이고, 모든 것이 전역 변수이며, C 코드로 설계되었습니다. 그것은 KNRC로 작성되었는데, 만약 당신이 그것이 무엇인지 안다면 말이죠. 그래서 그것은 다른 소프트웨어 시대의 것이었고, LLVM이 와서 "모두가 학교에서 가르치는 것은 프론트엔드, 옵티마이저, 코드 생성기가 있다는 것이다. 그것을 깔끔하게 만들자"고 말했습니다. 그렇죠. 그래서 그 당시 사람들은 저에게 다시, 우선, GCC를 대체하는 것은 불가능하다고 말했습니다. 왜냐하면 너무 확고하게 자리 잡았기 때문이죠. 등등. 하지만 또한 깔끔한 설계를 가질 수 없다고 말했습니다. 왜냐하면 GCC가 한 것을 보라, 그것은 성공적이다. 따라서 그것 없이는 성능이나 하드웨어에 대한 좋은 지원 등을 가질 수 없다는 것이죠. 그들이 맞을 수도 있습니다. 무한히 완벽한 우주에서는요. 하지만 우리는 무한히 완벽한 우주에 살고 있지 않습니다. 대신, 우리가 사는 우주는 팀이 있는 곳입니다. 파서를 잘 쓰는 사람들, 옵티마이저를 잘 쓰는 사람들, x86용 코드 생성기를 잘 쓰는 사람들 같은 사람들이 있죠. 그래서 이것들은 매우 다른 기술 세트입니다. 또한, AI에서 보듯이, 요구 사항은 항상 바뀝니다. 그래서 만약 당신이 오늘 매우 하드코딩되고 해킹된 모놀리스를 작성한다면, 2년 후에는 그것이 관련이 있을까요? 그리고 이것이 우리가 AI에서 많이 보는 것입니다. 우리는 정말 멋지고 매우 유망한 시스템들이 나타나고 매우 빠르게 성장했다가 결국 무너지는 것을 봅니다. 그것은 거의 일회용 프레임워크이기 때문입니다. 이 개념은 정말로... 언어는 프레임워크입니다. 이 시스템들 각각은 결국 달라집니다. 하지만 제가 매우 강력하게 믿는 것은 AI에서 우리는 진보가 더 느려지는 것이 아니라 더 빨라지기를 원한다는 것입니다. 그것은 논란의 여지가 있습니다. 왜냐하면 이미 너무 빠르기 때문이죠. 그렇죠? 하지만 우리가 일을 가속화할 수 있다면, 우리는 우리 삶에 더 많은 제품 가치를 얻게 됩니다. 우리는 더 많은 영향을 미치게 됩니다. 우리는 AI와 함께 오는 모든 좋은 것들을 얻게 됩니다. 저는, 참고로, 최대주의자입니다. 하지만 그것과 함께... 현실은 모든 것이 변하고 깨질 것이라는 것입니다. 그래서 만약 당신이 모듈성을 가지고 있다면, 만약 당신이 깔끔한 아키텍처를 가지고 있다면, 당신은 설계를 진화시키고 변경할 수 있습니다. 그것은 특정 사용 사례에 과도하게 전문화되지 않습니다. 도전 과제는 당신의 기준선과 메트릭을 올바르게 설정해야 한다는 것입니다. 이것이 바로 "업계 최고와 비교하라"고 하는 이유입니다. 그렇죠? 그래서 "최고보다 80% 좋은 것을 만들자. 하지만 다른 이점이 있다"고 말하는 것은, 적어도 저에게는 만족스럽지 않습니다. 저는 우리가 신경 쓰는 카테고리에서 최고가 되고 싶습니다.

**오픈 소스 기여 및 커뮤니티 참여**

Alessio [00:29:16]: 그리고 접두사 캐싱(prefix caching), 사용량 기반 과금(pay-per-use) 등을 사용할 때, 페이징된 어텐션(paged attention) 같은 것들요. 어떤 것을 혁신할지, 아니면 "이봐, 당신들이 실제로 최고의 것을 만든 팀이니, 우리는 그냥 그걸 사용할게"라고 할지 어떻게 결정하나요? 네.

Chris [00:29:28]: 저는 좋은 아이디어가 어디서 오든 그것을 사용하는 데 전혀 부끄러움이 없습니다. 모든 것은 리믹스(remix)잖아요. 그렇죠? 그래서 누군가, 그게 누구든 상관없어요. NVIDIA든, SGLang이든, VLM이든, 누군가 좋은 아이디어를 가지고 있다면, 그것을 함께 모으는 거죠. 하지만 핵심은 그것을 구성 가능하고(composable), 직교적이며(orthogonal), 유연하고(flexible), 표현력이 풍부하게(expressive) 만드는 것입니다. 저에게, 제가 보는 것은 사람들이 해온 것들, 그리고 함께 모아놓은 것들뿐만이 아닙니다. 저는 그것을 VLM에 넣지 않습니다, 예를 들어. 하지만 아카이브 논문들의 지속적인 흐름이죠. 그렇죠? 그래서 저는, 아시다시피, 추론 연구를 둘러싼 매우 활발한 산업이 있다는 것을 따릅니다. 예전에는 훈련 연구만 있었죠. 그렇죠? 그리고 그 중 많은 것들이 이러한 표준 프레임워크에 들어가지 못합니다. 그렇죠? 그리고 그 이유는 새로운 것을 위해 대규모로 손으로 코딩된 CUDA 커널과 이 모든 것들을 작성해야 하기 때문입니다. 그리고 저는 새로운 데이터 타입을 하나 원하는데, 모든 것을 바꿔야 합니다. 왜냐하면 아무것도 구성되지 않기 때문입니다. 음-흠. 그래서 이것이, 다시 말하지만, 만약 당신이 이러한 소프트웨어 아키텍처적인 것들을 제대로 한다면, 물론 그것은 당신이 새로운 프로그래밍 언어를 발명해야 한다는 것을 요구합니다. 이 문제에는 몇 가지 어려운 부분이 있지만, 그것의 멋진 점은 당신이 훨씬 더 빠르게 움직일 수 있다는 것입니다. 그래서 제가 그 예시를 하나 들어드리겠습니다. 이것은 완전히 공개된 것입니다. 왜냐하면 우리는 우리 것을 오픈 소스화했을 뿐만 아니라, 모든 버전 관리 기록을 오픈 소스화했기 때문입니다. 그래서 시간을 거슬러 올라가서, "Chris는 오픈 소스 소프트웨어를 좋아해"라고 말할 수 있습니다. 제가 이것을 설득해 드리겠습니다. 저는 사람들이 제 일에 너무 일찍 간섭하는 것을 좋아하지 않습니다. 하지만 저는 오픈 소스 소프트웨어를 좋아합니다. 그래서 당신은 우리가 어떻게 H100을 가져왔는지, 몇 주 만에 처음부터 플래시 어텐션을 구축했는지, 이 모든 것들을 볼 수 있습니다. 우리는 예를 들어, 모두가 사용하는 Tri Dao의 참조 구현을 이기고 있습니다. 그렇죠? 완전히 Mojo로 작성되었습니다. 다시 말하지만, 우리의 모든 GPU 커널은 Mojo로 작성되었습니다. 당신은 팀이 이것을 구축하는 역사를 볼 수 있고, 그것은 단 몇 주 만에 이루어졌습니다. 그렇죠? 그래서 우리는 완전히 새로운 GPU 아키텍처인 H100을 가져왔습니다. 만약 당신이 익숙하다면, 그것은 매우 멋진 비동기 기능과 텐서 메모리 가속기 같은 것들을 가지고 있습니다. 그리고 그들이 추가한 이 모든 이상한 것들은 성능에 정말 중요합니다. 그리고 다시, 우리의 목표는 QDNN과 TRTLM 같은 것들을 만나고 이기는 것입니다. 그래서, 성공으로 가는 빠른 길만 있는 것이 아닙니다. 모든 것을 제대로 하고 모든 것이 맞아떨어져야 합니다. 왜냐하면 작은 것 하나라도 잘못되면 성능이 저하되기 때문입니다. 그리고 우리는 그것을, 제 생각에, 두 달도 안 돼서 해냈습니다. 깃허브에 공개적으로요. 그렇죠? 그래서, 그 속도는 정말 놀랍습니다. 제 생각에 플래시 어텐션을 발명하는 데 9개월 또는 12개월이 걸렸고, VLM에 들어가는 데 또 6개월이 걸렸습니다. 그리고 이것은 단지, 후자는 단지 통합 작업일 뿐입니다. 그렇죠? 그래서 이제 당신은, 다른 아키텍처에 대해 확장되고 이러한 장점을 가진 구성 가능한 방식으로 이 모든 것을 처음부터 구축하는 것에 대해 이야기하고 있습니다. 그것은 그냥 다른 수준입니다. 어쨌든, 우리 것은 여러 면에서 아직 초기 단계입니다. 그래서 기능이 부족합니다. 하지만 만약 당신이 우리가 하는 일에 관심이 있다면, 변경 로그를 완전히 따라갈 수 있습니다. 그리고 당신은, 우리가 모든 멋진 것들을 게시하는 나이틀리 빌드를 따라갈 수 있고, 모든 커널은 공개되어 있습니다. 그래서 당신은 그것을 보고 기여할 수 있습니다. 그리고 만약 당신이 관심이 있다면, 당신도 이것을 할 수 있습니다.

Alessio [00:32:19]: 네. Modular 외부에서 사람들이 맡아야 할 프로젝트 중에, 당신이 가져오고 싶지 않은 프로젝트에 대한 요청이 있나요?

**VLLM 및 SGLang과 Modular의 차별점**

Chris [00:32:25]: 물론입니다. 저희는 작은 팀입니다. 100명이 넘지만요. 하지만 우리가 맡고 있는 문제의 크기에 비하면요.

당신의 야망의 크기에 비하면요.

네. 우리는 AI 산업의 크기에 비하면 극히 미미합니다. 그렇죠? 그래서 예를 들어, 우리는 Turing 지원에 별로 신경 쓰지 않았습니다. Turing은 오래된 GPU 아키텍처입니다. 그래서 커뮤니티의 누군가가 "좋아, 나도 새로운 GPU 아키텍처를 활성화할게"라고 했습니다. 그래서 그들이 Turing 지원을 기여했습니다. 이제 Max와 Colab을 무료로 사용할 수 있습니다. 꽤 멋지죠. 여러 연산자들이 있습니다. 우리는 AI와 Gen AI 같은 것에 매우 집중하고 있습니다. 그런데, 우리 것은 AI에만 국한되지 않습니다. 그래서 레이 트레이서(ray tracer)를 작성한 사람들도 있고, 비행 안전을 연구하는 사람들도 있고, 온갖 이상한 일들을 하는 사람들이 있습니다.

비행 시뮬레이션이요?

우리 해커톤에서 누군가가, 제 생각엔 음성 기록이었던 것 같은데, 블랙박스 같은 트래픽을 보고 조종사가 실수를 했을 때를 예측하는 데모를 만들었습니다. 그리고 비행기에 큰 문제가 생길 것이고, 그것을 높은 신뢰도로 예측하는 거죠. 마치 당신의 차처럼, 당신이 차를 운전하다가 속도를 줄이지 않으면 삐 소리가 나기 시작하는 것과 같습니다.

차선 유지 보조 장치 같은 거요. 네, 네, 네. 알겠습니다.

그런 종류의 것이지만, FAA를 위한 거죠. 와. 그리고 이런 것들이요. 그렇죠? 그리고 저는 그것에 대해 아무것도 모릅니다. 이것은 제 영역이 아닙니다. 저를 믿으세요. 이것이 바로 우리 산업에 거의 무한히 똑똑하다고 느껴지는 사람들이 너무 많다는 것의 힘입니다. 그들은 대부분의 면에서 저보다 훨씬 똑똑합니다. 그리고 당신이 그들에게 도구를 주고, 무언가를 가능하게 하면, 그리고 또한 AI 코딩 도구와 같은 것들이 격차를 메우는 데 도움이 되면, 저는 우리가 훨씬 더 많은 제품을 갖게 될 것이라고 생각합니다. 이것이 정말로 저를 동기 부여하는 것입니다. 그렇죠? 그리고 이것이 우리가 지난번에 이야기했던 부분이라고 생각합니다. 몇 년 전 저를 정말 좌절시키고 Modular를 시작하도록 영감을 준 것 중 하나는, 제가 조 단위 달러 기업들이 무엇을 할 수 있는지 봤다는 것입니다. 그렇죠? 모든 똑똑한 사람들이 수직적으로 위에서 아래까지 모든 것을 구축한 가장 큰 연구실들을 보면, 그들은 놀라운 제품과 연구 및 기타 작업을 할 수 있었습니다. 그리고, 아시다시피, 5명 팀이나 스타트업 같은 곳에서는 아무도 그것을 감당할 수 없었습니다. 그리고 여기서 우리는 컴퓨팅에 대해 이야기하는 것이 아니라, 단지 인재에 대해 이야기하는 것입니다. 음, 그리고 그 이유는 단지 모든 복잡성 때문입니다. 예를 들어, 구글에서는 복도를 걸어가서 누군가의 어깨를 두드리며 "이봐, 네 것이 작동하지 않아. 어떻게 작동하게 하지? 나는 정상적인 경로에서 벗어났어. 이 새로운 것을 어떻게 작동하게 하지?"라고 말할 수 있었기 때문에 작동했습니다. 그리고 그들은 "내가 해킹해 줄게"라고 말할 것입니다. 그렇죠? 음, 그것은 대규모로 작동하지 않습니다. 우리는 제대로 구성되고, 간단하며, 이해할 수 있고, 경계를 넘을 수 있는 것들이 필요합니다. 그리고, 아시다시피, AI의 많은 부분은 팀 스포츠입니다. 그렇죠? 그리고 우리는 더 많은 사람들이 참여하고 성장하며 배울 수 있기를 원합니다. 그리고 만약 당신이 그렇게 한다면, 저는 당신이, 다시 말하지만, 더 많은 제품 혁신을 얻게 되고, 단지 "거대한 AI가 모든 문제를 해결할 것이다"와 같은 해결책이 아니라, 더 세분화되고, 목적에 맞게 구축되고, 제품에 통합된 AI를 얻게 될 것이라고 생각합니다.

네. 당신이 하고 있는 일을 표현하는 한 가지 방법은, 당신이 "AI가 가속화되기를 원한다"는 말을 했는데, 그것은 이미 빠르고 사람들이 이미 불편해하기 때문에 역설적이라는 것입니다. 하지만 제 생각에 당신은 더, 당신은 배포를 가속화하고 있습니다.

저는 '민주화'라는 단어에 대해 복잡한 감정을 가지고 있지만, 그것이 바로 당신이 하고 있는 일입니다.

음, 예전에는, 2017년에는 AI를 민주화하는 것이 멋진 일이었습니다.

알아요, 이제는 멋지지 않죠.

네, 알아요. 하지만 예전에는 멋진 일이었습니다. 그리고 그것이 의미했고, 의미하게 된 것은 모델 훈련을 민주화하는 것이었습니다. 그렇죠? 그리고 베테랑으로서, 2017년에는 AI가 연구에 관한 것이었다는 것은 매우 흥미롭습니다. 왜냐하면 아무도 제품 애플리케이션이 무엇인지 몰랐을 뿐만 아니라, 모델을 훈련하는 방법도 몰랐기 때문입니다. 그래서 그런 것들, PyTorch 같은 것들이 등장했습니다. 그리고 저는 PyTorch가 모델 훈련을 민주화한 공로를 모두 인정받아야 한다고 생각합니다. 그렇죠? 그것은 졸업하는 거의 모든 컴퓨터 과학 학생들에게 가르쳐집니다. 그것은 큰일이지만, 아무도 추론을 민주화하지 않았습니다. 추론은 항상 블랙 아트(black art)로 남아 있었습니다. 그렇죠? 그래서 우리가 VLM이나 SG Lang 같은 것들을 가지고 있는 이유입니다. 왜냐하면 그것들은 당신이 그 위에 구축하고, 그 무서운 것들이 어떻게 작동하는지 알 필요가 없는 블랙박스이기 때문입니다. 그것은 우리가 업계에 이런 것들을 하는 방법을 가르치지 않았기 때문입니다. 그리고, 아시다시피, 시간이 걸릴 것입니다. 하지만 저는 그것이 문제가 아니라고 생각합니다. 그것은 내재된 문제가 아닙니다. 저는 단지 우리가 추론을 위한 PyTorch 같은 것이 없기 때문이라고 생각합니다. 그래서 우리가 이런 것들을 더 쉽게 만들고 분해하기 시작하면, 좋은 아이디어의 확산을 훨씬 더 많이 얻을 수 있습니다.

몇 가지 기술적인 것들에 대해 좀 더 자세히 알아보고 싶습니다. 하지만 잠시 옆길로 새서, VLM은 학자들이 이끄는 오픈 소스 프로젝트이고, 다른 추론 팀들도 마찬가지입니다. 사실상 모든 팀이 스타트업과 같죠. 파이어웍스(fireworks)나 투게더(together) 같은 곳들이요. 당신의 비즈니스 모델은 그들과 매우 다릅니다. 그리고 그 점에 대해 잠시 시간을 할애하고 싶습니다.

기꺼이 이야기해 드리죠.

당신은 의도적으로, 음, 당신은 오픈 소스를 믿지만, 단지 그것뿐만이 아닙니다. 당신은 다른 모든 사람들이 하는 일반적인 호스팅 클라우드 서비스로부터 돈을 벌지 않기로 선택했습니다.

네. 철학적인 이유와 차별화, 여러 가지 이유가 있습니다. 네. 그래서 아마도 사람들에게 그것이 무엇인지 상기시켜 주시겠어요? 기본적으로 그들이 당신에게 어떻게 돈을 지불하고, 그 대가로 무엇을 얻으며, 왜 그것을 선택했는지요.

그래서, 다시 말하지만, 우리는 이것을 어려운 모드로 하고 있습니다. 그렇죠. 우리는 제품까지 긴 길을 걸어왔습니다. 우리는 그냥 바로 몇 개의 커널을 얻고, 알파 버전을 만들고, GPU 예약 같은 것을 사서 우리 GPU를 재판매하는 그런 식이 아닙니다. 그 길은 많은 회사들이 선택했고, 그들은 그것을 정말 잘합니다. 그래서 그것은 제가 아주 잘하는 기여가 아닙니다. 그리고 저는 당신을 위해 데이터 센터를 짓지 않을 겁니다. 그것보다 훨씬, 훨씬 더 잘하는 사람들이 있습니다. 좋아요. 그래서 모든 행운을 빕니다. 저는 그 사람들이 맥스를 사용하기를 원합니다. 아시다시피, 저는 꽤 잘합니다.

그게 크루소(Crusoe)군요. 네.

저는 이 소프트웨어에 꽤 능숙합니다. 그래서 당신은 모든 컴퓨팅을 처리할 수 있습니다. 게다가, 스타트업에서 벗어나면, GPU와 클라우드로 고생하는 사람들이 많습니다. 그렇죠. 그래서 GPU와 클라우드는 근본적으로 CPU와 클라우드와는 다른 것입니다. 그리고 많은 사람들이 그것에 다가가서 "그냥 다 클라우드일 뿐이야"라고 말합니다. 그렇죠. 하지만 제가 그것이 사실이 아니라는 것을 설득해 드리겠습니다. 그래서, 우선, CPU와 클라우드. 왜 그것이 굉장했을까요? 음, 모든 워크로드는 상태가 없었습니다(stateless). 모두 수평적으로 자동 확장될 수 있었습니다. CPU는 비교적 저렴합니다. 그래서 탄력성을 얻을 수 있습니다. 그것은 정말 멋집니다.

꽤 빨리 로드할 수 있죠. 네. 기가바이트 단위의 가중치 같은 게 아니고요.

네. 그래서 어떤 사업이 2년 반 후에 무엇을 할지 아는 사람이 있을까요? 아무도 없습니다. 아무도 없죠. 그렇죠. 그래서 CPU를 위한 클라우드는 그렇게 멀리까지 용량 계획을 할 필요가 없기 때문에 엄청나게 가치가 있습니다. 그렇죠. 이제 GPU로 넘어가 봅시다. 음, 이제 3년 약정을 맺어야 합니다. 3년이요. 그렇죠. 그래서 젠슨(Jensen)이 1년 안에 구식으로 만들 하드웨어에 대해 3년 약정을 맺는 겁니다. 그렇죠. 그래서 이 물건을 얻게 됩니다. 그래서 큰 약정을 맺고, 그것으로 무엇을 할까요? 음, 당신의 필요가 어떨지 모르기 때문에 과도하게 약정해야 하고, 이것을 할 준비가 되어 있지 않습니다. 또한, 모든 기술은 매우 복잡하고 무섭습니다. 또한, GPU 워크로드은 상태가 있습니다(stateful). 그래서 당신이 멋진 에이전틱(agentic)한 것들에 대해 이야기하고, 여러분은 이 모든 것을 알죠. 네. 상태가 있습니다. 그래서 이제 수평적 자동 확장을 얻지 못합니다. 상태 없는 탄력성을 얻지 못합니다. 그래서 거대한 관리 문제를 얻게 됩니다. 그래서 우리가 할 수 있고, 사람들을 도울 수 있다고 생각하는 것은 "좋아, 당신의 컴퓨팅에 대한 권한을 주겠다"고 말하는 것입니다. 그리고 많은 사람들이 다른 시스템을 가지고 있고, 이것에 들어가는 매우 간단한 시스템들이 있습니다. 하지만 지능적인 라우팅을 통해 5배의 성능 TCO 이점을 얻을 수 있습니다. 그것은 실제로 플랫폼 팀에게 큰 문제입니다. 그들은 이것을 처리하고 싶어하지 않습니다. 그들은 AMD로 가기 위한 하드웨어 선택권을 원합니다. 그들은 이런 종류의 힘과 기술을 원합니다. 그래서 우리는 그들과 함께 일하게 되어 매우 기쁩니다. 제가 간단하게 설명하는 방식은, 많은 엔드포인트 회사들이 있고, 그들이 많이 있다는 것입니다. 그래서 당신은 그들이 모두 하나라고 말할 수 없습니다. 그들은 분명히 장단점과 트레이드오프가 있습니다. 하지만 일반적으로 엔드포인트의 가치 제안은 "보세요, AI와 AI 소프트웨어, 애플리케이션, 워크로드는 모두 엉망진창입니다. 너무 복잡합니다. 당신의 작은 머리로 걱정하지 마세요. 제가 당신의 접시에서 AI를 치워드릴 테니, 당신은 그것에 대해 걱정할 필요가 없습니다. 우리가 당신을 위해 모든 복잡성을 처리해 드릴 겁니다. 그리고 쉬울 겁니다. 그냥 우리 엔드포인트와 이야기하세요."라고 말하는 것입니다. 우리의 접근 방식은 "좋아, 그래, 모든 것이 엉망진창이야. 맞아, 100%야. 끔찍해. 아마 당신이 아는 것보다 더 심할 거야. 그리고 내일이 되면, 모든 것이 계속 변하기 때문에 더 심해질 거야. 우리가 쉽게 만들어 줄게. 우리가 당신에게 힘을 줄게. 당신의 기업과 팀에 초능력을 줄게."라고 말하는 것입니다. 왜냐하면 제가 이야기하는 모든 CEO는 제품에 AI를 넣고 싶어 할 뿐만 아니라, 팀이 AI 기술을 향상시키기를 원하기 때문입니다. 그래서 우리는 기업에서 AI를 빼앗지 않습니다. 우리는 AI에 대한 권한을 줍니다. 우리는 그들의 팀에 힘을 돌려주고, 시작하기 쉬운 경험을 가질 수 있게 합니다. 왜냐하면 많은 사람들이 표준적인 상용 모델을 실행하고 싶어 하고, 당신은 기본적인 것으로서 그냥 작동하는 것을 원하기 때문입니다. 하지만 그들이 "이봐, 나는 실제로 미세 조정을 하고 싶어"라고 말할 때, 저는 제 독점적인 데이터를 다른 스타트업이나 심지어 거기에 있는 몇몇 큰 스타트업에 주고 싶지 않습니다. 그리고 당신은 이것들이 누구의 것인지 알죠. 그것은 제 독점적인 IP입니다. 그리고 나서 당신은 "이봐, 나는 멋진 데이터 모델을 가지고 있어. 나는 실제로 데이터 과학자들이 있어. 나는 실제로 몇 개의 GPU를 가지고 있어. 나는 내 모델을 훈련할 거야."라고 말하는 사람들을 만나게 됩니다. 멋지네요. 그것은 민주화되었습니다. 이제 어떻게 배포할까요? 그렇죠? 음, 다시, 당신은 VLM의 내부를 해킹하는 것으로 돌아갑니다. 그리고 PyTorch는 KV 캐시 최적화나 모든 현대적인 트랜스포머 기능 같은 것들을 위해 실제로 설계되지 않았습니다. 그래서 갑자기 당신은 그것이 좋기를 원한다면 이 복잡성의 절벽에서 떨어집니다. 그래서 우리는 "좋아, 그래, 이것은 복잡성의 또 다른 단계야. 하지만 당신은 이것을 소유할 수 있고, 이것을 확장할 수 있어."라고 말합니다. 그래서 우리는 그것을 도울 수 있습니다. 그래서 그것은 공간에서 다른 트레이드오프입니다. 하지만 저는 시장 출시 시간과 매출 성장 등이 있다는 것을 인정합니다. 그리고 그들은 CUDA의 전체 대체품을 만들 필요가 없었기 때문에 훨씬 더 빨랐습니다.

**Modular의 비즈니스 모델 및 수익화 전략**

Alessio [00:41:37]: 멋지네요. 그리고 과금에 관해서는, 사람들이 이것을 플랫폼으로 구매하는 건가요? 토큰이나 추론된 것과 같은 것과는 관련이 없고요.

Chris [00:41:45]: 저희는 두 가지를 진행하고 있습니다. Max 프레임워크와 Mojo 언어는 NVIDIA와 CPU에서 어떤 규모로든 무료로 사용할 수 있습니다. 마음껏 사용하세요. 원하는 것은 무엇이든 하세요. 패치를 보내주시면 감사하겠습니다. 무료입니다. 그렇죠. 왜 그럴까요? 음, CUDA는 이미 무료입니다. NVIDIA는 이미 여기서 지배적입니다. 우리는 기술이 널리 퍼지기를 원합니다. 무료로 사용하세요. 패치를 보내주시면 좋겠지만, 그렇게 하지 않아도 됩니다. 그렇죠? 저희 웹페이지에 로고를 사용할 수 있도록 허락해 달라고 요청합니다. 그래서 이메일을 보내서 "사용하고 있고, 10,000개의 GPU에서 스캔하고 있다"고 알려주시면 정말 좋겠습니다. 하지만 그것이 유일한 요구 사항입니다. 만약 클러스터 관리와 엔터프라이즈 지원, 그리고 이런 것들을 원한다면, GPU당 기준으로 비용을 지불하고 저희 영업팀에 연락할 수 있습니다. 그러면 저희가 거래를 성사시키고 직접 협력할 수 있습니다. 그래서 저희는 이렇게 나눕니다. 그리고 또한, 제가 말하겠습니다. 제가 보고 싶은 한 가지는, 그리고 다시 말하지만, 아직 초기 단계이지만, PyTorch가 Max를 채택하는 것을 보고 싶습니다. VLM이 Max를 채택하는 것을 보고 싶습니다. SGLang이 Max를 채택하는 것을 보고 싶습니다. 우리는 우리만의 작은 서빙 시스템을 가지고 있지만, 가서 보세요. 정말 간단합니다. 정말 놀라울 겁니다. 그리고 다시, 우리는 이제 사람들이 실제로 우리 것을 사용하기를 바라는 단계에 있습니다. 그래서 우리는 역사적으로 "아니, 우리 것은 닫혀 있어, 멀리 떨어져 있어"라는 모드에 있었지만, 지금은 국면 전환을 하고 있습니다. 그래서 앞으로 이런 발표가 더 많아질 겁니다.

네. 이걸 어떻게 실현할지는 모르겠지만, 제 생각에 당신은 Mistral, Meta, DeepSeq, Quen이 당신을 채택하고 네이티브로 탑재할 때 이기는 것 같아요. 그렇죠? 어떻게 그런 일이 일어날까요?

저는 그렇게 먼 미래에 대해 이야기하고 싶지 않습니다.

그렇게 멀지 않다고 생각해요.

우리는 곧 업계를 선도하는 최첨단 모델을 Mac에서 처음으로 출시할 수도 있습니다. 그 점에 대해 계속 주목해 주시고, 저희에게도 알려주세요. 하지만 아직 그런 일은 일어나지 않았으니, 일어나지 않는다고 가정합시다.

저는 그때가 정말로 전환점이 될 것이라고 생각합니다. 왜냐하면 그러면 모두가 "좋아, 그들에게 충분히 좋다면, 우리에게도 충분히 좋아"라고 생각할 것이기 때문입니다. 그렇죠? 그리고 나서 나머지 업계를 얻게 됩니다.

네. 하지만 다시 말하지만, 저는 장기전을 하고 있습니다. 그렇죠? 그리고 저는 다시, 제가 작업하는 것들은 사람들이 처리하는 데 시간이 걸린다는 것을 깨닫습니다. 그래서 우리가 해야 할 일, 그리고 제가 우리가 하기를 바라는 일, 그리고 제가 팀에게 요청하는 일은, 계속해서 더 좋고, 더 좋고, 더 좋고, 더 좋게 만드는 것입니다. 그리고 기술 채택에는 S자 곡선이 있습니다. 그래서 저는 2월에 우리 것을 사용했던 소수의 미친 얼리 어답터들이 있다는 것이 훌륭하다고 생각합니다. 오픈 소스화되기 전이었고, 합리적인 의미가 전혀 없었습니다. 거의 작동하지 않았죠. 하지만 놀라웠고, 저는 그 사람들에게 매우 감사합니다. 그리고 나서, 물론, 우리는 그것을 오픈 소스화했고, 사람들을 가르치기 시작했고, 훨씬 더 큰 채택 곡선을 얻게 됩니다. 무료로 만들고, 채택하고, 나아가세요. 그리고 나서, 당신이 말했듯이, 곧 더 많은 검증이 있을 것입니다. 그리고 이것들 각각은 곡선의 변곡점입니다. 하지만 그것이 또한 하는 일은, 우리에게 버그를 수정하고, 것들을 개선하고, 더 많은 기능을 추가하고, 새로운 기능을 출시할 수 있는 능력을 준다는 것입니다.

Swyx: 이것을 출시하는 것이 소프트웨어와 비교했을 때 어떤 느낌인가요?

Chris: 아, 음, 제가 당신의 질문을 다시 해석해 보겠습니다. 과거에 몇 가지 흥미로운 일을 해보셨는데, 무엇을 배우셨고, 다시는 하지 않을 것은 무엇인가요?

그게 제가 물어본 질문보다 더 좋은 질문이네요. 왜냐하면 Swift는 거의 너무 좁거든요.

Swift의 특징은, 제가 대부분의 사람들이 이것에 대해 모른다고 가정하기 때문에, Swift의 특징은 제가 2010년에 주말과 저녁 시간을 이용한 프로젝트로 시작했다는 것입니다. 1년 반 동안 혼자서, 주말과 저녁 시간에 해킹했습니다. 결국 애플의 경영진에게 그것에 대해 말했습니다. 그들의 머리가 터질 뻔했습니다. "왜 우리가 무언가가 필요한가? Objective-C는 충분히 좋은데, 왜 이것이 필요한가?"라고요. 몇 명의 사람들을 더 참여시킬 수 있도록 승인을 받았습니다.

그때 애플에서 펠로우십이나 인턴십을 하고 계셨나요?

아니요, 저는 개발자 도구 팀을 이끌고 있었습니다.

뭔가 하고 계셨던 것 같아요, 네.

네, 저는 거대한 팀을 이끌고 있었습니다. 이것은 제 본업이 아니었다고 해두죠. 하지만 그래서, 2010년에 시작해서, 2014년에 애플에 의해 공개적으로 출시되었습니다. 그리고 2014년에 출시될 때까지, 전 세계에서 약 250명만이 그것에 대해 알고 있었습니다. 그들 대부분은 제 팀에 있었습니다. 약 200명 정도가 제 팀에 있었고, 나머지는 고위 임원, 마케팅, 팀 쿡 등이었습니다. 그리고 이것이 Swift에 대해 아는 사람들의 범주였습니다. 그래서 우리는 그것을 비밀리에 만들었습니다. 말 그대로 NDA(비밀유지계약)가 있었습니다. 애플 내에서. 그것에 대해 알기 위해서요. 우리가 그것을 출시했을 때, 요구 사항 중 하나는 Swift로 앱 스토어에 앱을 제출할 수 있어야 한다는 것이었습니다. 그것이 저에게 주어진 요구 사항이었습니다. 그래서 "좋아, 멋지게 들리네"라고 생각했습니다. 그래서 우리는 그것을 출시하고 1.0이라고 말했습니다. 그래서 당신은 1.0, 완전히 새로운 프로그래밍 언어를 출시하는 것입니다. 아무도 그것을 본 적이 없습니다. 내부 사용자도 없습니다. 데모 앱 하나뿐이었습니다. 정말 악몽이었습니다. 네. 그래서 커뮤니티에게는 악몽이었습니다. 왜냐하면, 다행히도 많은 사람들이 흥분했고 그것을 채택하고 싶어 했고, 많은 사람들이 즉시 그것을 채택했습니다. 하지만 그것은 실전에서 단련되지 않았습니다. 버그가 많았습니다. 우리는 그것을 0.5로 출시했어야 했습니다. 그렇죠? 그래서 그것이 꽤 좋아지는 데 1년이 더 걸렸습니다. 그리고 제 생각에, 아주 좋아지는 데 2년이 걸렸습니다. 또한, 애플의 소프트웨어 엔지니어 중 아무도 그것에 대해 몰랐습니다. 그래서 그들의 머리가 터질 뻔했습니다. 그들은 "잠깐만, 왜 Objective-C를 대체하는 거야? 나는 Objective-C를 사랑해서 애플에 입사했는데. 왜 새로운 프로그래밍 언어에 대해 내 의견을 묻지 않았어?"라고 말했습니다. 그렇죠? 그래서 그런 모든 역학 관계가 있었습니다.

아, 그들이 이제부터 Swift를 작성해야 한다는 회사 방침이 있었나요?

아니요. 하지만 여전히, "잠깐만, 이건 내가 입사했다고 생각했던 회사가 아니야"와 같은 것이죠. 그렇죠? 그리고 이런 것들이요. 그렇죠? 그래서 거기서 나온 엄청난 혼란과 드라마, 그리고 말도 안 되는 일들이 있었습니다. 그래서, 좋아, Mojo로 넘어가 봅시다. 배운 교훈들. 이봐, 첫째, 급작스러운 시작(hot start)을 하지 마라. 그래서 우리는 Mojo를 아주 오래 전에, 심지어 말이 되기 전에도 출시했습니다. 그리고 우리는 그것을 0.1이라고 불렀습니다. 그래서, 광고의 정직함은 어떤가요? 그렇죠? "이것은 0.1입니다. 제발 사용하지 마세요. 하지만 관심이 있다면, 피드백을 주시면 감사하겠습니다." 그렇죠? 그래서 부드러운 시작, 가자. 두 번째로 매우 다른 점은 Swift에서는 데모 앱이 하나뿐이었다는 것입니다. 그래서 당신은 매우, 제 생각에, 강력한 팀이 많은 신뢰할 만한 일을 해온 언어를 만들고 있었지만, iOS 개발자를 위한 언어를 만들고 있었습니다. 그리고 컴파일러는 C++로 작성되었습니다. 그렇죠? 그래서, 네, 사용자에 대한 공감은 있지만, 우리가 출시했을 때 내부적으로 많은 이해나 학습이 없었습니다. Mojo의 경우, Modular는 Mojo의 첫 번째 고객입니다. 우리 저장소에는 다른 어떤 언어보다 더 많은 Mojo 코드가 있습니다. 그렇죠? 그것은 굉장합니다. 그리고 그것은 오픈 소스입니다. 그리고 우리는 약 65만 줄의 Mojo 코드를 오픈 소스화했습니다. 그렇죠? 이것은 많습니다. 그래서 우리는 고통을 겪고, 우리의 필요에 따라 기능과 개선을 추진합니다. 우리는 또한 커뮤니티에 감사합니다. 그리고 우리는 많은 기여를 받고 있습니다. 그리고 누군가가 제 문자열 구현에서 비트 하나를 제거하여 최적화했는데, 그것은 최적이 아니었습니다. 그래서 그것은 정말 굉장했습니다. 하지만 그렇게 추진하는 것은 그것이 진짜임을 확인시켜 줍니다. 그것은 현실에 기반을 두고 있습니다. 그것은 사용 사례에 기반을 두고 있습니다. 우리는 과대 약속을 하지 않으려고 노력하고 있습니다. 심지어 당신이 저에게 그것이 무엇에 유용한지 물었을 때도, 저는 그것이 파이썬의 대체품이라고 말하지 않았습니다. 저는 그것이 빠르게 가는 언어라고 말했습니다. 언젠가는 꽤 신뢰할 만한 파이썬 대안이 될 수도 있습니다. 하지만 지금 당장은 특정 종류의 사용 사례에 좋습니다. 그리고 만약 당신이 그 사용 사례에 관심이 있다면, 예를 들어 GPU를 쌩쌩 돌리는 것과 같은, Mojo는 굉장합니다. 하지만 만약 당신이 Rust의 완전한 대체품을 원한다면, 우리에게 6개월을 주세요. 네. 네.

Swyx: 제 말은, 당신은 자연의 힘과 같아요. 애플의 AI 이니셔티브에 무슨 일이 일어나고 있는지에 대해 많은 미스터리가 있다고 생각합니다. 그리고 결국 소비자들이 고통받습니다. 최종 사용자들은 이것을 기다리고 있는데, 일어나지 않고 있습니다.

Chris: 불행히도, 제가 아는 것은 모두 엄청나게 구식입니다. 그들은 변했고, 재편성되었고, 성장했고, 문화도 바뀌었습니다. 그리고 그것은 매우 성공적인 회사입니다. 그래서 저는 그들이 아마도 성공을 느끼고 있고, 업계의 변화에 적응하는 데 어려움을 겪고 있다고 생각합니다. 그리고 그것은 많은 대기업의 전형적인 모습입니다. 그래서 저는 구체적인 원인에 대해 말할 수 없습니다. 구글에 대해 말하자면, 분명히, 저는 그들이 가장 초기에 있었던 회사 중 하나라고 생각합니다.

우리가 무엇에 대해 이야기하고 있나요?

그들이 트랜스포머를 발명했죠.

다른 많은 것들도요. 텐서플로우, 기억나세요?

네, 맞아요. 엄청났죠. 네. NTP들. 저는 구글이 AI를 오픈 소스로 만든 공로를 인정합니다.

음, 그들은 텐서플로우를 오픈 소스화할 필요가 없었습니다.

네. 그것은 놀라운 결정이었습니다. 제프 딘과 이에 관여했던 많은 다른 사람들에게 전적인 찬사를 보냅니다. 왜냐하면 그들은 "구글에게 실제로 가장 중요한 것은 AI가 더 빨라지는 것이다. 어떻게 그렇게 할 수 있을까? 우리는 텐서플로우를 독점적인 내부적인 것으로 만드는 대신 오픈 소스화한다."고 말했기 때문입니다. 그들은 이전에 Disbelief라는 시스템을 가지고 있었습니다. 그래서 그것은 PyTorch가 오픈 소스화되고, 연구가 공개되고, 이 모든 것들의 무대를 마련한 거대한 순간이었습니다. 왜냐하면 그들은 가치 체계가 AI가 더 빨라지는 것이라고 결정했기 때문입니다입니다. 트랜스포머 논문이 발표되었습니다. 구글로부터 너무 많은 기여가 나왔습니다. 저는 구글이 그것에 대해 충분한 인정을 받지 못한다고 생각합니다.

네. 왜 구글이 AI를 소유하는 것보다 오픈 소스화하는 것이 구글에게 더 좋을까요?

음, 그래서 저는 그 내기가 성공했는지 말할 수는 없습니다. 하지만 저는 그것이 내기였다고 말할 수 있습니다. 하지만 제 외부자 관점에서 보면, 왜냐하면 저는 5년 이상 구글에 있지 않았으니까요, 시간이 참 빠르네요. 그 내기는 당신이 이것을 당신의 제품에 통합할 수 있는 놀라운 연구원 팀과 Swyx를 가지고 있을 때 의미가 있습니다. 그래서 구글은 수십억 명의 사용자를 가지고 있습니다. 모든 제품 서비스를 가지고 있습니다. 모든 다른 애플리케이션을 가지고 있습니다. 그리고 놀라운 인재 밀도를 가지고 있습니다. 그리고 저는 구글의 최근 발표, 즉 구글 I.O. 직후의 발표 같은 것들이, 네, 우리 둘 다 거기 있었죠. 네, 구글이 실제로 작동하고 있는 것 같습니다. 꽤 인상적입니다. 그리고 한동안 그들은 조직적인 드라마와 구글 브레인 대 딥마인드, 그리고 이런 것들을 다루고 있었습니다. 그리고 저는 그들이 무엇을 했는지 말할 수는 없지만, 그들은 훨씬 더 통합된 팀인 것 같습니다. 그들은 잘 실행하고 있습니다. 그들은 연구를 제품에 반영하고 있습니다. 그래서 저에게는 다른 구글처럼 느껴집니다.

네, 완전히 그렇습니다. 예전에는 구글에 모든 것이 두 개씩 있었고, 어느 것을 사용해야 할지 몰랐습니다.

구글에 의해 죽었죠. 그들은 모두 1년 안에 폐기되었습니다.

그래서 네, 제 생각에 그들은 메모를 받은 것 같아요, 뭐든 간에요.

네, 그리고 그들에 대해 저에게 매우 인상적인 또 다른 것은, 이것은 제가 구글을 팬보잉하는 것입니다. 그렇죠? 물론이죠. 조 단위 달러 회사들을 비난한 후에 말이죠. 하지만 그들이 발표한 것들은 실제로 출시되고 있었습니다. 네. AI에서는 너무나 많은 것들이 그렇습니다.

이것은 애플을 더 비꼬는 거네요.

저는 특별히 애플을 말한 것은 아닙니다. 이것은 AI에서 매우 흔한 일입니다. 그리고 Modular도 과거에 이런 일을 했습니다. 이것이 바로 이유입니다. 그래서 제가 이 매우 깊은 기술 강연을 했습니다. 제가 GPU 모드 강연 링크를 보내드렸죠. 그리고 슬라이드 2는 경고였습니다. "당신은 실제로 이것을 사용할 수 있습니다. 이것은 베이퍼웨어(vaporware)가 아닙니다. 여기 있는 모든 것은 당신이 재현할 수 있습니다. 이 주장들은 당신이 다운로드할 수 있습니다. 이것은 실제로 진짜입니다. 여기 소스 코드 링크가 있습니다."

왜 그렇게 강조하셨는지 궁금했어요. 마치, 누가 당신을 상처줬나요?

알아요. 제 말은, 너무 많은 주장들이 있다는 거죠. 아무도 무엇이 진짜인지 더 이상 모릅니다.

알아요. 그렇죠? 그리고 제 말은, 말 그대로 제품 데모가 있었는데, 마치 전기 세미 트럭이 자체 동력으로 작동하는 대신 언덕을 굴러 내려가는 것과 같았죠. 그리고 아무도 무엇이 진짜인지 모릅니다.

Alessio [00:52:18]: 저는 그들이 일하기 시작했다는 것을 알았습니다. 왓츠앱 채팅 같은 것이 있습니다. 우리는 주중에 구글 필드에서 축구를 하곤 했습니다. 그리고 약 6개월 전에, 어떤 관리자가 게시물을 올렸습니다. "이봐, 점심시간에 축구하러 오는 사람이 더 이상 충분하지 않아. 무슨 일이야?" 그리고 제 생각에 그때 사람들이 시작했던 것 같습니다.

그게 당신의 구글 지표군요.

다시 일하기 시작했죠. 네. 여기 있습니다.

Chris [00:52:35]: 제 말은, 세르게이 브린이 IO에 있었습니다. 그리고 그는 확실히. 그는 다시 일하는 것 같습니다. 그리고 그것은 굉장합니다. 네. 그래서 저는 그것에 대해 엄청난 존경심을 가지고 있습니다. 그렇죠. 그리고 제 가치관은 물건을 출시하는 사람들과 일치합니다. 네. 왜냐하면 그것이 세상을 바꾸는 것이기 때문입니다.

Alessio [00:52:47]: 오픈 소스에 대해 좀 더 이야기해 봅시다. 더 최근의 오픈 소스 사례로는 딥시크(DeepSeek)가 있습니다. 그리고 특히 당신의 경우, 그들은 GPU의 PTX 레이어에서 작업했는데, 이는 CUDA보다 훨씬 더 저수준이고 독점적인 것입니다. 네. 저는 그것이 미친 영향과, 사람들이 이 독점적인 것에서 얼마나 벗어나려고 노력해야 하는지에 대한 영향, 두 가지 측면에서 궁금합니다. 왜냐하면 제 이해로는 다음 세대의 칩에서는 모든 코드가 쓸모없어지기 때문입니다.

**DeepSeek의 영향과 저수준 GPU 프로그래밍**

Chris [00:53:17]: 음, 널리 알려지지는 않았지만, Blackwell은 Hopper와 호환되지 않습니다. 그렇죠. Hopper 커널이 항상 Blackwell에서 실행되는 것은 아닙니다, 예를 들어. 그렇죠. 하지만 당신의 질문은, 그것이 업계에 어떤 의미가 있느냐는 것이죠?

Alessio [00:53:27]: 음, 그게 왜 그렇게 중요한가요? 딥시크의 예시가 왜 그렇게 중요한가요? 그들이 작동하게 만들기 위해 이 모든 독점적인 것들을 헤쳐나가야 했다는 점이요. 네.

Chris [00:53:37]: 제가 겪은 경험을 말씀드리죠. 네. 왜냐하면 딥시크는 12월에 나왔는데, 그때 저와 아마 당신도 그것을 알아차렸을 겁니다. 그렇죠. 하지만 그 후 한 달 뒤에 세상은 큰 경각심을 갖게 되었고, 비디오 주가가 하락하는 등 여러 일이 있었습니다. 그렇죠. 그래서 제가 무슨 일이 일어났는지 설명해 드리겠습니다. 좋아요. 딥시크 팀이 한 일은 정말 인상적인 연구였습니다. 그들은 MLA를 발전시켰고, 그것은 어텐션의 한 형태이며, 저정밀도 훈련을 발전시켰습니다. 그들은 많은 것들을 발전시켰습니다. 그들은 당시 잘 알려지지 않았던 일부 PTX 명령어를 리버스 엔지니어링했습니다. 그렇죠. 네. 그래서 많은 사람들이 그냥, 그리고 그것은 중국 팀이었습니다. 그렇죠. 그것이 미국주의를 위협했죠. 그렇죠. 그리고 이런 것들이요. 그래서 제가 정말 흥미롭게 생각했던 것은 그들이 연구를 발전시켰고, 이 놀라운 일들을 해냈다는 것입니다. 그들은 세상에 그것이 가능하다는 것을 보여주었고, 그것을 공개하고, 출판하고, 실제로 세상에 그것에 대해 가르쳤습니다. 왜냐하면 저는 그들이 왜 그렇게 하기로 선택했는지 모르지만, 그것은 그들이 개방성과 AI의 발전을 믿기 때문입니다. 그렇죠. 네. 네. 네. 네. 그래서 제가 인상 깊게 생각한 또 다른 것은, 세상의 반응이 실제 세계보다 저에게 더 인상 깊었다는 것입니다. 아니면 뭐든 간에요. 모르겠네요. 네. 왜냐하면, 우선, 지정학이 제 강점은 아니기 때문에 중국과 미국의 드라마가 있습니다. 그래서 저는 그것을 이해하고 옆으로 밀어놓습니다. 그렇죠. 하지만 제가 정말 흥미롭게 생각한 또 다른 것은 사람들이 "와, 좋아. 딥시크만이 PTX 수준까지 내려갈 수 있구나"라고 말했지만, 그것은 표준이라는 것입니다. 그것은 모든 선도적인 팀들이 하는 일입니다. 모듈러의 경우, 네. 우리는 CUDA를 모두 제거했기 때문에 그 수준에서만 작업합니다. 그렇죠? 그래서 우리는 전체 스택을 교체했습니다. 그래서 우리는 그것만 합니다. 하지만 성능에 신경 쓰는 많은 팀들은 실제로 PTX, TensorCore, Instruction, Foo를 사용하기 위해 내려갈 것입니다. 이것은 실제로 문서화되어 있지 않습니다. 당신은 그것을 알아내고 컷라스(cutlass) 코드를 봐야 합니다. NVIDIA는 이것을 해야 할 만큼 쉽게 만들지 않습니다.

왜 그런지 궁금하네요.

음, 제 생각에는 그들이 Blackwell에서 깨지고 있기 때문이라고 생각합니다. 그래서 그들은 사람들이 실제로 그것을 사용하기를 원하지 않았고, 그래서 그들만의 문제가 있었습니다. 그렇죠? 하지만 행운을 빕니다. 세상에는 똑똑한 사람들이 많이 있습니다. 그래서 저에게, 저는 그것이 정말 흥미롭다고 생각했습니다. 왜냐하면 스택의 그 수준이 어떻게 작동하는지에 대한 인식이 많지 않았기 때문입니다. 저에게, 저는 그것이 사람들이 "오, 와, 만약 당신이 스택의 이 수준에서 일한다면, 제가 수십 년 동안 살아온 스택의 수준에서, 당신은 컴퓨팅에 대한 힘을 갖게 됩니다. 당신은 문제를 이해하고 해결할 수 있습니다. 당신은 다른 누구도 할 수 없는 방식으로 연구를 발전시킬 수 있습니다."라고 말하는 훌륭한 경각심을 불러일으키는 계기가 되었다고 생각했습니다. 그리고 이것이 바로 조 단위 달러 기업들이 하는 일입니다. 단지 딥시크만이 아닙니다. 하지만 저는 딥시크가 거대한 경각심을 불러일으켰고, 그것이 단지 PyTorch나 VLM 위에 레이어를 쌓는 것이 아니라, 그 재미있는 양의 작업을 하는 것이었기 때문에 스택의 그 레이어에 주의를 끌었다고 생각합니다. 그리고 저는 그것이 놀랍다고 생각했습니다. 이제, 그것의 도전 과제와 딥시크가 그것을 한 방식, 그리고 다른 모든 사람들이 이 모든 작업을 하는 방식의 도전 과제는, 그것이 완전히 하나의 GPU에만 특정하다는 것입니다. 당신이 PTX 수준에서 작업하고 있다는 것뿐만이 아닙니다. 당신이 정말로 그 하나의 GPU에서만 작동할 수 있는 코드를 작성하고 있다는 것이고, 그것은 Blackwell이 나오면, 당신은 그것을 버리고 새로운 것을 작성해야 한다는 것을 의미합니다. 그렇죠? 하지만 여기에 공개된 비밀이 있습니다. 그것이 바로 VLM입니다. VLM을 보세요. 그들은 AVLM을 위한 다른 커널을 가지고 있습니다. 그들은 이제 Blackwell을 따라잡으려고 노력하고 있습니다. 그래서, 이러한 시스템의 최첨단 기술은, Gen AI 이후, 그 이전에는 XLA와 같은 멋진 AI 컴파일러와 Trat AI 세계에서 제공하는 일부 확장성이 있었습니다. 하지만 Gen AI에서는, 새로운 하드웨어가 나올 때마다 모든 것을 다시 작성하는 것입니다. 그래서 이것이 바로 Mojo가 해결하고 있는 것입니다. 그렇죠? 그리고 이것이 바로, 다시 말하지만, 우리가 새로운 하드웨어의 증분 비용을 0으로 만들 수는 없지만, 대폭 줄일 수는 있다는 것입니다. 그래서 이것은 정말 흥미로운 시기라고 생각합니다. 우리가 지금 증명한 것이기도 하지만, 미래에 어떤 의미가 있는지도요.

저는 여전히 그들의 채용이나 내부 훈련에 대해서도 궁금합니다. 그들이 당신과 같은 방식으로 이것을 하는 작은 팀을 어떻게 가질 수 있었는지요.

저는 그들이 꽤 상당한 팀을 가지고 있다고 생각합니다. 물론 내부 정보는 없지만, 5명 팀이 아니라 수백 명의 사람들입니다.

좋아요, 네. 그래서...

네, 아시다시피, 천 명은 아니죠. 그렇죠? 놀랍습니다. 특히, 제 말은, 아마도 언어 장벽이 있을 텐데, 그것을 무시하더라도, 한 회사에 그 정도의 인재 밀도를 모으는 것은, 중요한 과제가 아닙니다.

네, 음, 저는 그것에 동의합니다. 회사를 세우는 것은 어렵습니다. 저는 그들이 어떻게 딥시크를 세웠는지에 대한 가시성이 없지만, 제가 말할 수 있는 것은 그들의 작업을 출판해 준 딥시크에게 감사하다는 것뿐입니다. 네. 왜냐하면 그들은 그렇게 할 필요가 없었기 때문입니다. 그리고 저는 그것이 일시적으로 많은 사람들을 당황하게 만들었다고 생각합니다. 그렇죠? 그리고 특정 그룹에게는 좀 창피한 일이었고, 많은 사람들이 멈춰 서서 "오, 젠장, 이것에 대해 어떻게 해야 하지?"라고 생각했다고 생각합니다. 하지만 제 생각에 그것이 한 일은 AI의 진보를 6개월 정도 앞당겼다는 것입니다.

네. 그들은 GPU 수준의 작업만 한 것이 아닙니다. 그들은 파일 시스템도 가지고 있었습니다.

아, 네. 만약 당신이 봤다면... 네, 놀랍습니다.

보셨나요... 분명히, 그것은 모듈러의 주력 분야는 아니지만, 다른 누군가가 그것을 가져가서 발전시킬 가능성이 있다고 보시나요?

저는 몇 년 동안 추론 문제에 매우 집착해왔기 때문에, 훈련을 위한 그 문제를 해결하는 가장 좋은 방법을 모릅니다. 구글 내부에는 훌륭한...

물론이죠. 그렇죠? 그래서 나머지 세상에는 그것이 어디에 있나요?

네. 저는 솔직히 그 질문에 대답할 적임자가 아닙니다. 왜냐하면 저만의 집착이 있기 때문입니다.

네. 음, 추론에 대해 이야기하자면, 추론 모델과 추론 시간 컴퓨팅, 매우 큰 주제입니다. 무언가 변하나요, 아니면 아무것도 변하지 않나요? 왜냐하면 그것은 단지 더 많은 추론일 뿐이니까요.

무엇으로부터의 변화에 따라 다릅니다. 그렇죠? 그래서 우리가 3년 전에 모듈러를 시작했을 때, 우리는 당시에는 터무니없이 이상한 내기를 했습니다. 훈련 대신 추론에 집중하기로 한 것이죠. 네. 그리고 다시, 당시에는, 저는 이것에 익숙합니다. 사람들은 "당신에게 무슨 문제가 있나요? 모두가 분명히 훈련이 중요하고, 훈련, 훈련, 훈련, 그리고 사람들이 이 거대한 클러스터를 구축하고, 모든 지출이 훈련에 있다는 것을 압니다. 등등, 등등, 등등."이라고 말했습니다. 그리고 저는 "음, 네, 왜 그렇게 보는지 이해합니다. 하지만 저는 구글에서 이것을 겪었습니다. 구글은 나머지 업계보다 5년 앞서 있습니다. 가장 확장된 추론, 네."라고 말했습니다. 네. 훈련은 연구팀의 규모에 따라 확장됩니다. 추론은 고객 기반의 규모에 따라 확장됩니다. 그렇죠? 그래서 그 사이에서 일어나는 일은 연구가 생산에 들어가는 것입니다. 그래서 격차는 연구가 생산에 들어가는 것입니다. 일단 그렇게 하면, 갑자기 미친 듯이 확장됩니다. 그래서 저는 Gen AI를 계획하지 않았습니다. 저는 추론 시간 컴퓨팅을 계획하지 않았습니다. 그리고 이런 것들이요. 하지만 생산 사용 사례에 대한 그 내기는, AI의 애플리케이션 수에 따라 확장되기 때문에, 단지 뜨거운 연구팀만이 아니기 때문에, 그렇죠? 아시다시피, 꽤 중요합니다. 단지 제가 지난 몇 년 동안 집중하지 않았을 뿐입니다. 그것은 논란의 여지가 있었습니다. 그래서 저는 이제 온 세상이 뒤집혔고, 세상이 그것을 이해한다고 생각합니다. 그렇죠? 하지만 그것은 정말로 경험에서 비롯된 것이었습니다. 그래서 당신이 이러한 새로운 기술에 도달했을 때, 그렇죠? 또 다른 논란의 여지가 있는 것, CPU 문제로 돌아가서, 왜 CPU로 시작하는가? 당시의 대답은 전처리, 후처리, 전체 시스템 통합, 네트워킹, GPU에 데이터를 공급하기 위해 CPU가 필요하다는 것과 같은 매우 표준적인 것들이었습니다. 하지만 이제 당신은 KV 캐시를 말합니다. 당신의 축출 정책은 CPU에서 실행됩니다. 그 Radix 해싱 알고리즘과 블록 해싱, 그리고 그 모든 것들이 주로 CPU에서 일어납니다. 그것은 성능에 정말 중요합니다. 왜냐하면 만약 당신이 이 단계들에서 지연 시간이 있다면, 당신은 GPU를 활용하지 못하고 있는 것이기 때문입니다. 그렇죠? 그리고 다시, 이것은 Rust로 다시 작성하는 것과 같은 것으로 돌아갑니다. 모든 에이전틱(agentic)한 것들과 이런 것들, 저는 그것을 예측하지 못했지만, 놀라지 않았고, 더 많은 것을 보게 될 것이라고 생각합니다. 그래서 긴밀한 통합, 경계를 넘나드는 최적화, 이런 것들은 제가 믿는 것들입니다. 그리고 저는 이것이 세상을 앞으로 나아가게 하는 방법이라고 생각합니다.

기본적으로 제가 아는 모든 똑똑한 프로그래머들이 항상 병목 현상이 있는 곳에 집중한다는 것이 놀랍습니다. 그리고 그것은 항상 당신을 올바른 답으로 이끌어 줍니다. 만약 당신이 그것에 대해 매우 명확하게 본다면요. 그리고 모르겠네요, 그런 일이 일어나는 것을 보는 것이 좋습니다.

제가 당신을 위해 언급할 또 다른 논점은, 당신이 꺼내지 않았지만, 다른 사람들이 이야기하고 있는 것인데, 실제로 이제 사고의 연쇄(train of thought)와 추론 모델에 대한 요구 사항 때문에, 추론이 이제 훈련의 일부가 되었다는 것입니다.

Swyx [01:01:06]: 좋아요, 네.

Chris [01:01:07]: 왜냐하면 추론이 필요하기 때문입니다.

RL은 항상 그렇게 해왔습니다.

RL에게요, 네. 그래서 그것은 실제로 당신이 어쨌든 하고 있는 일에 플러스가 됩니다.

네, 물론입니다. 왜냐하면 같은 코드이기 때문입니다. 그래서 RL 시스템에 대한 제 경험은, 대규모로, 딥마인드 스타일, 알파고 같은 것들이었습니다. 그래서 몇 년 전이었지만, 그런 것들을 설정하는 것은 엄청나게 복잡했습니다. 왜냐하면 이제 당신은 클러스터 규모의 오케스트레이션을 다루고 있고, 이 모든 에이전트들에 걸쳐 배치 처리를 하고 있습니다. 그리고 다시, 어떤 시스템도 그것을 위해 설정되어 있지 않습니다. 그렇죠? 만약 당신이 모델을 훈련하고 싶다면 PyTorch가 있지만, 이것을 하기 위해 설정된 것은 아무것도 없습니다. 그래서 다시, 저는 모든 RL 시스템에 대해 말할 수는 없지만, 그것들은 결국 덕테이프와 철사, 그리고 매우 미친 것들로 만들어졌습니다. 그리고 그것은 놀라웠습니다. 다시 말하지만, 전체 스택을 알고 있는 전문가 팀과 그들이 달성할 수 있는 것은 놀랍지만, 그렇게 어려워서는 안 됩니다. 그래서 우리는 단지 그것을 해결하는 데 집중하지 않고, 아직 그 문제를 해결하는 데 집중하지 않고 있습니다. 아마도 우리는 거기에 도달할 것입니다.

우리는 빌딩 블록을 가지고 있습니다.

우리는 빌딩 블록을 가지고 있습니다. 그리고 다시, 우리는 아직 훈련을 해결하는 데 집중하지 않고 있습니다. 아마도 우리는 거기에 도달할 것입니다. 저는 그것을 하기 위한 논리적인 단계에 대한 몇 가지 아이디어가 있지만, 우리가 끝까지 모든 것을 해결하고, 사람들을 행복하게 만들고, 사람들이 우리 것에 대해 그들의 목소리로 이야기하는 것을 확인하고 싶습니다. 단지 제가 우리 것에 대해 이야기하는 것이 아니고요. 그래서 우리는 곧 사람들이 우리 것에 대해 이야기하는 것을 듣게 될 단계에 있습니다. 제 생각에 사람들은 이미 그렇지만, 그들은 훨씬 더 그렇게 될 것입니다. 그리고 저는 당신이 그것에 대해 더 이야기하기 위해 팟캐스트에 나와주셔서 감사합니다. 그리고 우리는 몇 가지 개인적인 이야기로 넘어가고 싶습니다.

**Modular를 이끌며 느낀 개인적인 소회**

Alessio [01:02:31]: 그래서 저는 그것이 훌륭한 Modular 이야기였다고 생각합니다. 이제 개인적인 측면에서 몇 가지가 있습니다. 당신이 처음 우리와 함께했을 때, 저는 그것이 2023년 9월이었다고 봤습니다. 그래서 그것은 회사를 세운 지 1년 반 정도 되었을 때였습니다. 이제 4년이 넘는 시간이 지났습니다. 그리고 개인적인 배움은 무엇이었나요? 분명히 회사의 리더로서, 관리하는 팀이 성장하고, 더 이상 기술적이지 않은 많은 책임을 지게 되면서요. 그런 것들에 대해 좀 이야기해 주세요. 네.

Chris [01:02:58]: 저에게는, 저는 많은 것을 만들어왔습니다. 저는 이전에 처음부터 큰 팀을 만들어왔지만, 그것들은 모두 기존 회사에서였습니다. 저는 이전에 스타트업에서 일해봤지만, 그것은 다른 사람의 스타트업이었습니다. 그래서 이것은 제가 창업하고, 상당한 팀을 만들고, 만드는 데 몇 년이 걸리는 제품을 만든 첫 번째 스타트업입니다. 그래서 제가 배운 많은 교훈들은 매우 가치 있었고, 제가 일부 성과를 달성할 수 있게 해주었습니다. 하지만 그것은 또한 매우 다릅니다. 그래서 매우 다른 것 중 하나는, 그것이 매우 개인적이라는 것입니다. 그래서 저는 이전에 우리 팀에서 사람들을 잃어본 적이 있습니다, 여러 번. 저는 사람들을 해고해야 했고, 사람들은 그만두고 애플에서 구글로 가거나 했습니다. 하지만 그것은 Modular에서처럼 개인적이지 않았습니다. 그래서 이것은 제 뇌의 지적인 부분은 누군가 떠나면, 그것이 말이 된다는 것을 아는 것입니다. 그들은 삶의 변화가 있었습니다. 저는 그들의 가족이나 다른 것에 방해가 되고 싶지 않습니다. 제 말은, 저는 지적으로 그것을 압니다. 하지만 다른 한편으로는, 조금 아픕니다. 그래서 저는 그런 종류의 것들을 다루는 데 더 나아지고 있다고 생각합니다. 다른 것은, 당신이 큰 회사에서 0명에서 100명으로 팀을 성장시킬 때, 당신은 모든 인프라를 가지고 있다는 것입니다. 그리고 인프라는 성숙합니다. 그렇죠? 그래서 당신이 100명 팀으로 성장하더라도, 당신은 여전히 애플이나 구글, 또는 이런 회사에 비하면 작습니다. 당신은 여전히 전체 규모의 비율에 비해 작습니다. 그래서 그들은 이미 모든 채용과 다른 모든 것, 그리고 모든 법률 및 재무, 그리고 그런 종류의 모든 것을 가지고 있습니다. 그들은 관리자 교육을 가지고 있습니다. 그들은 이 모든 것을 가지고 있습니다. 그래서 스타트업에서는, 당신은 때때로 "좋아, 나는 재조직을 해야 하고, 이런 것들을 해야 해"와 같은 뜨거운 혼란을 겪게 됩니다. 그래서 그것은 좋은 배움이었습니다. 그것은 잘 확장되었습니다. 그리고 불가능하다고 말하는 사람들에게 돌아가서, 실제로, 아마도 가장 중요한 것은, 저는 불가능하다는 말을 듣는 데 익숙하다는 것입니다. 그리고 저는 꽤 고집이 세고, 공식이 있습니다. 그래서 성공으로 가는 길이 있습니다. 그리고 원하신다면 설명해 드릴 수 있습니다. 하지만 저는 그것이 1년차이고, 완전히 비밀 프로젝트(skunkworks)이고, "어떤 것을 증명하자"는 단계일 때의 느낌에 익숙합니다. 저는 그것에 익숙합니다. 좋아, 멋지네. 이제 우리는 사람들에게 그것에 대해 이야기하고 있지만, 여전히 충분히 좋지 않습니다. 그리고 사람들은 당신의 모든 것이 형편없다고 말합니다. 저는 그것에 익숙합니다. 좋아, 음, 당신은 이 모든 것이 거의 다 된 그 창에 들어갑니다. 사람들은 땀을 흘리고 있습니다. 정말 어렵습니다. 불가능해 보이는 것들이 많이 있습니다. 상당한 팀이지만, 조각들이 아직 맞춰지지 않았습니다. 그래서 우리는 지난 가을에 그런 일을 겪었고, 사람들은 "오 마이 갓, 아마 절대 작동하지 않을 거야"라고 생각했습니다. 그리고 당신은 이런 불안감을 갖게 됩니다. 그리고 제가 그것을 겪으면서 감사하지 못했던 것은, 그리고 이것이 제가 이 단계에 있는 것이 다른 사람들의 사고 과정에 실제로 영향을 미치기 때문에 매우 흥분되는 이유이기도 합니다. 왜냐하면 그들은 그것을 겪어보지 않았고, 그들은 저를 믿고, 우리는 거기에 도달할 것입니다. 음, 정확히 언제, 당신은 모든 것을 이해하고 싶어 하는 매우 분석적인 엔지니어들을 얻게 되고, 그들은 스택의 자기 부분에 정말 전문가이고, 다른 부서와 그 다른 부서, 다른 부서가 모두 줄을 서고 있는 것에 대해 확립된 신뢰가 정말로 없습니다. 그래서 확실히 그로부터 몇 가지 아침이 있었지만, 하지만 이것이 바로, 다시 말하지만, 당신이 그 R&D 단계에서 벗어나 실행 단계로 들어가면, "좋아, 음, 엔지니어들은 끝에서 끝까지 작동하는 불완전한 것을 가져다가 더 좋고, 더 좋고, 더 좋게 만드는 데 정말 능숙하다"와 같습니다. 그래서, 그것은 단지 Modular가 이전의 어떤 단계와도 근본적으로 다르게 느껴집니다. 네.

Alessio [01:06:04]: 당신의 하루 일과는 어떤가요? 회의가 많은가요, 아니면 적은가요?

Chris [01:06:08]: 네, 저는 회의가 많습니다. 제, 제 실제 삶에 대해 이야기하시는군요. 음, 저의 평범한 평일은, 음, 저는 7시 15분쯤에 일어나서, 아내와 함께 아이들을 내보내고, 그녀가 8시쯤에 아이들을 학교에 데려다줍니다. 저는 보통 30분에서 45분 정도 개들과 함께 산책을 하고, 언덕을 오르내리며 격렬하게 운동합니다. 심박수가 올라가죠. 좋은 일입니다. 예를 들어, 당신의 팟캐스트를 듣습니다. 그래서, 제가 다른 사람들이 하는 흥미롭고 멋진 일들을 실제로 따라갈 시간이 있는 이유입니다. 9시에 출근해서 6시나 7시 정도까지 일합니다. 그리고 대부분은 회의입니다. 그래서 그것은 제가 그날의 문제들을 해결하려고 노력하는 것입니다. 집에 와서 아이들과 저녁을 먹습니다. 저는 가족과 함께 식사하는 것을 고집하고, 잠자리에 들 때까지 그들과 함께 시간을 보낸 다음, 제가 쓰러질 때까지 2~3시간 더 일을 합니다. 그리고 그것을 규칙적으로 합니다.

두 번째 근무일이군요. 네. 네. 네. 네.

그리고 주말에는, 놀랍게도, 일할 시간이 많습니다. 하루 종일은 아니지만, 아이들과 함께 무언가를 하기 때문에, 시간이 많고 회의가 없습니다. 그래서 놀랍습니다.

그때가 실제로 일이 처리되는 때죠.

네, 맞아요. 제 생각에, 여기서 핵심은 당신이 잠가두는 어떤 종류의 전략적 검토 시간입니다. 왜냐하면, 제 생각에 사람들은 종종, 당신이 사업 안에서 일할 때가 있고, 사업에 대해 일할 때가 있다고 말합니다. 당신이 잠시 밖으로 나갈 때요. 종종 창업자들에게는 이사회 회의를 할 때입니다. 하지만 어떤 것이 있는지 궁금합니다. 당신에게 매우 의미 있는 것이 있나요? 코치가 있나요? 그런 것이 있나요?

네. 네. 그래서 제 생각에 제가 정말로 많은 빚을 진 두 사람이 있습니다. 음, 또는 두, 두 범주. 그러니까, 하나는 제 공동 창업자인 팀입니다. 네. 그래서 팀과 저는 함께 회사를 설립했습니다. 어, 우리는 매주 금요일마다 걷고, 근황을 나누고, 그것은 마치 줌아웃해서 전술적으로 만들지 않으려고 노력하는 것과 같습니다. 그래서 우리가 미친 아이디어들을 서로에게 던질 수 있도록 하고, 저는 믿거나 말거나, 미친 아이디어들이 많습니다. 그도 그렇습니다. 하지만 그리고 나서 실행에 기반을 두고 나아갑니다. 다른 것은, 네. 제 아내, 그녀는 사운딩 보드이고, 그리고 경영진 사이의 이 조합입니다. 그리고 저는 약간 미쳐서 업계 문제를 해결하고 싶어 하고, 경영진은 그것을 "좋아, 다음 분기, 계획이 있는지 확인하자. 우리가 소통할 수 있는지 확인하자. 실제 우선순위가 무엇인지 결정하자. 좋아. 우리는 전체 팀을 위해 최대 세 가지 우선순위를 가질 수 있어, 50개가 아니라. 그렇지 않으면 그것들은 우선순위가 아니야."로 되돌립니다.

네, 맞아요. 모든 것이 최우선 순위가 될 수는 없습니다. 그렇지 않으면 아무것도 아니죠.

그렇죠. 그리고 이런 것들이요. 그리고 나서 제 아내는 저를 제정신으로 유지시켜 주고, 아시다시피, 저는 모릅니다.

**창업자로서의 일과 및 시간 관리**

Alessio [01:08:27]: 그녀는 놀라운 인생 코치입니다. 아내를 실제 업무에 얼마나 참여시키나요?

Chris [01:08:33]: 그녀가 아나요, 예를 들어, 네, 그녀는 자신만의 일이 있습니다. 어, 제 아내는 LVM 재단을 운영합니다. 그래서 그녀는 아이들과 다른 모든 것들 외에도 많은 일들을 하고 있습니다.

Alessio [01:08:41]: 그녀는 "이 추기경들에 대해 듣고 싶지 않아"라고 말하는 것 같네요.

Chris [01:08:43]: 음, 하지만 그녀는 저를 돕는 데 훌륭합니다. 그래서 저는 EQ보다 IQ가 더 높은 편입니다. 그래서 인간과 함께 일하는 것은, 타고난 기술이 아니라 습득한 기술입니다. 그래서 저는 이것이, 일단, 어, 저는 종종 어떤 이상한 일이 일어나고, 도대체 무슨 일이 일어나고 있는지 모르는 이 장소에 있게 됩니다. "Chris, 분명하잖아, 그들은 이렇게 말하지만, 이것이 그들이 실제로 의미하는 바야." 저는 "오, 나는 그것에 대해 생각해 본 적이 없어."라고 말합니다.

당신은 코딩 에이전트를 언급했습니다. 네. 내부적으로 무엇을 사용하시나요? 무엇을 좋아하시나요?

네. 그래서, 이 녹음 시점에서, 저는 개인적으로 커서(Cursor)를 사용합니다. 그래서 커서는, 제 말은, 제가 본 것 중 최고이고, 저는 이것저것 시도하는 데 많은 시간을 쓰지 않습니다. 그래서, 하지만 커서는, 어, 그래서 저는 C++와 모조 코드를 많이 작성하는데, AI 코딩 도구에서 모조 코드를 작업하는 핵심은 컨텍스트 창(context window)에 많은 코드를 넣는 것입니다. 네. 그래서 커서와 이 도구들은 정말 잘 인덱싱할 수 있습니다.

저는 당신이 모조 코드를 오픈 소스화한 것을 생각하고 있었습니다. 사실, 그것은 꽤 좋습니다.

그것이 우리가 이것을 한 이유 중 하나입니다. 네. 그리고 우리가 이것을 한 많은 이유 중 하나입니다. 그래서 이것이 우리가 해커톤에서 본 것입니다. 사람들은 모조로 제로에서 히어로가 될 수 있었습니다. 왜냐하면 당신은 그냥, 이 전체 거대한 코드베이스를 인덱싱할 수 있고, 그것은 경이롭습니다. 그리고 AI가 많은 기계적인 작업을 해주기 때문에 새로운 언어를 배우는 것은 실제로 쉽습니다. 그리고 또한 파이썬처럼 보이기 때문에 읽을 수 있지만, 그것은 단지 온보딩을 대규모로 확장합니다.

네. 네. 그래서 새로운 언어 채택을 위해, AI는, 제가 설득해 드리겠습니다, AI는 멋집니다.

저는 그냥 가서, 실제로 큰 연구소의 데이터셋 사람들에게 무엇이 필요한지 물어볼 겁니다. 네. 그리고 그냥, 저는 그들 모두에게 물어봤습니다.

그들에게 먹여주세요. 네. 그냥 코드를 가져가세요, 제발 그들을 위해 라벨을 붙여주세요. 아파치 2.0입니다. 그냥 가세요.

네. 네. 우리는 마크다운 파일을 추가하고 있습니다. cloud.md가 있습니다. 그래서 우리는 몇 가지 기본적인 작업을 하고 있습니다. 음, 회사 내 사람들은 클라우드 코드와 몇 가지를 시도하고 있습니다. 그래서 저는 그것에 대한 개인적인 경험은 없지만, 음, 하지만 저에게는, 저는 그것이 대부분, 매우 유용하다는 것을 발견했습니다. 하지만 그것은 정말로 보일러플레이트(boilerplate)에 관한 것입니다. 그래서 새로운 알고리즘을 발명하는 것과 같은 것에 관한 것이 아닙니다. 그리고 그것은 아마도, 제가 리액트 컴포넌트를 만들고 있지 않기 때문일 겁니다.

네. 제 말은, 연구소들은 자신들의 모델을 CUDA 커널 작성용으로 훈련하거나 벤치마킹하고 있다고 선전하고 있습니다. 그렇죠. 모델을 바꿀 때마다 눈에 띄는 성능 향상을 보는지 궁금합니다. 당신이 그것들을 벤치마킹하는지는 모르겠지만요.

저는, 저는 그 특정 사용 사례를 보지 않았습니다. 음, 하지만, 어, 사람들은 종종 저에게 묻습니다. "이봐, Chris, AI가 모든 코드를 작성할 건데 왜 새로운 프로그래밍 언어를 만들고 있나요?" 비슷하게, 만약 당신이 "CUDA 커널을 생성하자"와 같은 것을 많이 본다면, 당신은 묻고 궁금해하기 시작합니다. 또는 적어도 저는 많이 그렇습니다. 코드의 목적은 무엇인가? 제가 그것에 대해 현재 생각하는 방식에 대해 반성해 본 결과, 물론 바뀔 수 있습니다. 왜냐하면 우리 모두 배우고 있으니까요. 저는 한 걸음 물러서서 말합니다. 음, 코드는 정말로 컴퓨터에게 무엇을 하라고 말하는 것에 관한 것이 아닙니다. 코드는 인간이 코드가 무엇을 하는지 이해할 수 있는 것에 관한 것입니다. 그래서 언젠가 우리가 AGI(범용 인공지능)나 ASI(초지능) 같은 것을 얻게 되면, 아마도 그것은 완전히 불투명해질 수 있습니다. 그리고 저는 정말로 알 필요가 없을 것입니다. 우리는 아직 거기에 도달하지 않았습니다. 그래서, 그리고 저는 그것이 언제 일어날지 모릅니다. 하지만 그 동안, 저는 코드가 실제로 무엇을 하는지 볼 수 있기를 원합니다. 그리고 저는 제약의 세계에 살고 있습니다. 저는 이 모든 기능을 가진 제품이 있다는 것을 알아야 합니다. 만약 제가 또 다른 기능을 추가하면, 무슨 일이 일어날까요? 그것은 제 지연 시간 예산을 초과할 것입니다. 메모리 부족으로 충돌할까요? 그것은, 너무 많은 비용이 들까요? 저는 이것에 대해 추론할 수 있어야 합니다. 그래서 저에게, 저는 이러한 많은 코딩 도구들을 봅니다. 아시다시피, 현재 있는 곳을 넘어 확장되었지만, 예측 가능한 미래까지는 "좋아, 음, 그것은 당신의 코드베이스나 팀에 또 다른 엔지니어를 고용하는 것과 같다"고 말하는 것과 같습니다. 그리고 근본적으로 코딩과 소프트웨어 엔지니어링은 팀 스포츠입니다. 그리고 당신은 제품 관리자, 엔지니어, 많은 것들을 가지고 있습니다. 그리고 만약 당신이 코드의 모든 엔지니어링을 자동화한다면, 아마도 당신은 이론적으로 제품 관리자만 있고 마케팅만 있는 곳에 도달할 수 있습니다. 하지만 당신은 여전히 코드가 무엇을 하는지에 대해 추론하고 싶어 합니다. 그래서 그 안에서, 네, 해석 가능성 주장입니다. 그래서 그 세상에서, 실제로 가장 중요한 것은 무엇인가? 가장 중요한 것은 당신이 표현할 수 있다는 것입니다. 하드웨어가 할 수 있는 모든 것을요. 왜냐하면 당신은 어떤 능력, 어떤 비용, 또는 당신이 뚫을 수 없는 어떤 경계를 갖고 싶지 않기 때문입니다. 모조는 그것을 합니다. 두 번째는 당신이 실제로 이해할 수 있는 읽기 쉬운 코드를 원한다는 것입니다. 그렇죠? 그래서 당신은 어셈블리 언어나 그런 것을 원하지 않습니다. 당신은 높은 수준이고 표현력이 풍부하며 이해하기 쉬운 것을 원합니다. 그래서, 이것이 제가 모조가 정말 독특하다고 생각하는 부분입니다. 그리고 나서 AI 코딩 도구들은 제가 채택을 위한 순수한 부가 가치로 봅니다. 왜냐하면 저는 이미 이 모든 것을 전혀 만져본 적 없는 사람들이 무엇을 할 수 있는지 봤기 때문입니다. 그리고 그것은 정말 놀랍습니다. 당신은 지능적인 사람을 데려다 놓습니다. 그들은 사용 사례를 알고 있고, 이제 당신은 이 도구들을 그들의 손에 쥐어줍니다. 그리고 그들은 이미 놀라운 일들을 할 수 있습니다. 그래서 저는 그것이 매우 힘을 실어준다고 생각합니다. 그리고 다시, 저는 인간이 새로운 기술로 힘을 얻고, 기술을 향상시키고, 배울 수 있는 것을 보고 싶다는 것으로 돌아갑니다. 아시다시피, 당신은 오늘 GPU 프로그래머가 아니지만, 아시다시피, 내일, 바라건대 GPU를 프로그래밍하는 사람이 10배 더 많아질 것입니다. 저는 그것이 세상을 더 나은 곳으로 만들 것이라고 생각합니다. 그래서 저는 우리가 CPU의 세계로 돌아가고 있다고 생각하지 않습니다. 저는 GPU가 더 중요해질 것이라고 생각합니다. 그리고 만약 우리가 사람들이 그렇게 하는 것을 도울 수 있다면, 저는 그것이 훌륭하다고 생각합니다.

**AI 코딩 도구 사용 및 최신 연구 동향 파악**

Alessio [01:13:24]: 추론에 대한 연구와 아카이브 논문 중 일부를 언급하셨습니다. 아카이브는 어떻게 따라가시나요?

Chris [01:13:31]: 네, 저희는 슬랙(Slack)을 주로 사용하는 회사입니다. 그래서 논문 채널이 있습니다. 제 생각에, 하루에 3개에서 10개 사이의 논문이 올라오는 것 같습니다. 그리고 저희에게는 그것을 하는 놀랍고 똑똑한 사람들이 있습니다. 저는 또한 레딧(Reddit) 커뮤니티 같은 것들을 팔로우합니다. 저는 여전히 RSS를 사용하는 구식 사람입니다. 그래서 만약 당신이 RSS 피드를 가지고 있다면, 제가 당신을 팔로우하기가 훨씬 쉽습니다.

어떤 리더를 사용하시나요?

네. 그리고, 어, 저는 피들리(Feedly)를 사용합니다.

피들리요.

네. 하지만, 음, 아카이브는 특정 그룹을 팔로우하는 기능이 있습니다. 그래서 저는 여러 그룹에 대해 그렇게 합니다. 그래서 그것이 또 다른 기술입니다.

언급하고 싶은 주목할 만한 논문이나, 그들이 출판할 때마다 "이건 읽어야 해"라고 생각하는 저자가 있나요?

저는 잘 고려된 답변을 드릴 수 없습니다. 음, 바로 오늘 아침에, 마이크로소프트의 한 분이 논문을 발표했습니다. 어, 그의 이름은 지금 기억나지 않지만, 어, 그는 방금 논문을 발표했습니다. 그것은 플래시 어텐션을 자동 생성하고 블로커(blocker) 같은 것을 하는 것에 대한 정말 멋진 논문입니다. 블록(block)이 들어간 귀여운 이름이 있었습니다. 그래서 어쨌든, 제 말은, 많은 일들이 일어나고 있습니다.

좋아요.

Alessio [01:14:33]: 그래서 그런 종류의, 네, 아시다시피, 당신이 무엇에 주의를 기울이는지 보는 것은 흥미롭습니다. 마지막으로, 모두가 답을 원하는 질문입니다. 지난번에 언급했던 아이들을 위한 레고 로보틱스 테이블 만들기를 끝내셨나요? 그리고, 작업 중인 새로운 프로젝트가 있나요?

**개인 프로젝트와 일과 삶의 균형**

Chris [01:14:47]: 그것에 대해 완전히 잊고 있었네요. 그래서 우리는 여전히 레고 로보틱스 테이블을 사용합니다. 이것은 큰 4x8 합판 시트에 가장자리에 2x3 목재를 두른 것입니다. 하지만 4x8 합판 시트는 다루기가 꽤 어려웠습니다. 그래서 그것은 세 개의 분해 가능한 모듈식 섹션으로 나뉩니다. 그래서 정말 좋습니다. 그리고 아이들은 프로그래밍과 레고, 그리고 이런 종류의 모든 것들에 훨씬 더 능숙해지고 있습니다. 음, 맙소사, 제 가장 최근 프로젝트는 무엇이었을까요? 저는 방금 가게에서 아이들과 함께 밴드쏘(bandsaw)로 칼을 만들고 있었습니다. 그래서 나무 조각을 가져다가, 밴드쏘를 가지고, 아이에게 주고, "손가락 자르지 마"라고 말합니다. 알고 보니 그 진보는, 제 말은, 제가 분명히 조금 농담을 하고 있는 것입니다. 그들은 많은 감독을 받습니다. 하지만 밴드쏘는 실제로 매우 안전한 도구입니다. 그래서 그 이유는 밴드쏘, 아마 많은 사람들이 밴드쏘를 본 적이 없을 텐데, 구글 검색을 해보면, 두 개의 바퀴가 있고, 그 바퀴 주위를 도는 날이 있고, 테이블이 있습니다. 그리고 밴드쏘의 멋진 점은, 날 쪽으로 개구부를 조여서 나무 조각만큼만 크게 만들 수 있다는 것입니다. 그리고 또한 나무를 테이블 안으로 끌어당깁니다. 그래서 나무를 테이블 안으로 끌어당기기 때문에, 킥백(kickback)이라고 불리는 것과 같은 위험이 있습니다. 그리고 이런 종류의 다른 많은 것들이 매우 낮습니다. 그래서 당신은 기본적으로 아이에게 "봐, 네 손가락 보이지, 날에서 멀리 떨어뜨려"라고 말할 수 있습니다. 그리고 만약 당신이 잘못된 기술을 사용하면, 정말 곤경에 처할 수 있는 갑작스러운 흔들림이나 다른 것들이 없습니다. 그리고 만약 당신이 가드를 완전히 내리면, 팔 같은 것이 거기에 들어갈 수 없습니다.

Alessio [01:16:11]: 하지만, 어, 차고 전체를 목공소로 만드셨나요?

Chris [01:16:14]: 네, 저는 차는 밖에 세워두는 사람입니다. 그래서 그것이 다시, 제 이상한 행동을 용납해주는 아내에게 감사하는 것입니다. 제 말은, 저는 무언가를 만드는 것을 사랑합니다. 그렇죠? 그래서 이것이 근본적으로, 당신이, 아시다시피, 저를 움직이게 하는 것이 무엇인지 이야기할 때, 저는 발견의 기쁨을 사랑합니다. 그렇죠? 그래서 그것이 놀라운 팀을 만드는 것이든, 새로운 테이블을 만드는 것이든, 아시다시피, 식탁이나 이런 것들을 만들었습니다. 어, 제 웹사이트를 볼 수 있습니다. 저는 웹 디자이너는 별로 잘하지 못합니다. 거기에 몇 가지 목공 프로젝트가 있지만, 저는 소프트웨어를 만드는 것을 사랑합니다. 저는 이것에 따르는 문제들을 만들고 해결하는 것을 사랑합니다. 저는 기계적인 것을 만드는 데는 별로 능숙하지 않습니다. 그래서 아마도 저는 의자 하나를 만드는 데는 능숙할지 모르지만, 식탁 주위에 놓을 여덟 개의 의자를 만들지는 않을 겁니다. 그것은 저를 미치게 할 겁니다.

발견과 배움이 바로 의자를 만드는 기계를 만들 수 있는 것입니다.

바로 그거죠. 멋지게 들리네요. 그렇죠? 10년 동안 만들고, 3주 만에 뚝딱 만들어내죠. 네.

Alessio [01:17:02]: 어, 네. 멋지네요. 네. 행동 촉구 같은 것이 있나요?

**채용, 오픈 소스, 커뮤니티 참여**

Chris [01:17:05]: 예를 들어, 채용 중이신가요? 네, 저희는, 저희는 소수의 최고의 너드(nerd)들을 채용하고 있습니다. 그래서 만약 당신이 GPU 프로그래밍에 관심이 있고, AI 모델에 관심이 있고, 추론에 관심이 있고, 쿠버네티스와 클라우드 규모의 것들에 관심이 있다면, 저희를 확인해 주세요. 저희는 올해 말에 훨씬 더 많이 성장할 것으로 예상합니다. 그, 어, 다른 것들은 저희가 엄청난 양의 오픈 소스 코드를 가지고 있다는 것입니다. 그래서 만약 당신이 Mojo에 대해 들어봤지만, 1년 전에 그것을 봤다면, 글쎄요, 이제 모든 것이 완전히 다릅니다. 그래서 만약 당신이 이러한 많은 것들에 관심이 있다면, 만약 당신이 GPU에 대해 배우는 데 관심이 있다면, 우리는 당신에게 GPU 프로그래밍, GPU 퍼즐, 그리고 이런 것들에 대해 가르쳐 줄 많은 콘텐츠를 가지고 있습니다. 사람들은 이제 Mojo를 집어 들고 많은 최고의 GPU, 어, 오늘 나왔고, 이 물건을 가져다가 내놓는 다른 많은 사람들이 있습니다. 그리고 저는 이것이 정말 흥미로운 시기라고 생각합니다. 왜냐하면 저는 훨씬 더 많은 사람들이 그것을 사용해야 한다고 생각하기 때문입니다. 저는 이것이 정말 흥미로운 시기라고 생각합니다. 왜냐하면 저는 훨씬 더 많은 사람들이 그것을 사용해야 한다고 생각하기 때문입니다. 저는 이것이 정말 흥미로운 시기라고 생각합니다. 왜냐하면 저는 훨씬 더 많은 사람들이 GPU를 프로그래밍해야 한다고 생각하기 때문입니다. 저는 이것이 업계에 큰 기회라고 생각합니다. 그리고 물론, 만약 당신이 기업이고 AI를 확장하는 데 어려움을 겪고 있다면, 아시다시피, 저희에게 알려주세요. 저희가, 저희가 도울 수 있습니다.

멋지네요. 오늘 와주셔서 정말 감사합니다. 언제나처럼 영감을 주시네요.

네. 음, 초대해 주셔서 감사합니다.