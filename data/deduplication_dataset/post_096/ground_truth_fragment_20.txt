## Modular: AI 컴퓨팅의 복잡성을 허물고 미래를 개척하다

YouTube에서 시청하거나, Apple Podcast, Spotify에서 듣거나, 즐겨 사용하는 플레이어에 저희 RSS 피드를 추가하여 최신 AI 기술 트렌드를 만나보세요!

Chris Lattner가 처음 팟캐스트에 출연했을 때, 저희는 에피소드 제목을 '어려운 길을 가다(Doing it The Hard Way)'로 정했습니다. 단순히 추론 플랫폼을 구축하고 GPU가 쌩쌩 돌아가는 차트를 게시하는 대신, 그들은 컴파일러(compiler) 수준까지 내려가 전체 스택(stack)을 재정의했습니다. 이러한 접근 방식은 AI 개발의 근본적인 한계를 극복하려는 Modular의 비전을 명확히 보여줍니다. AI 기술이 점점 더 복잡해지고 다양한 하드웨어 환경을 요구함에 따라, 이러한 풀스택 혁신은 단순한 효율성 개선을 넘어 개발자 경험의 혁명을 가져오고 있습니다.

Modular는 '동심원(concentric circles)' 구조로 구축되고 있습니다. 각 레이어(layer)는 독립적으로 진화하며, 그 아래의 모든 것은 유연한 기반 시설(plumbing)을 제공합니다. 이는 빠르게 변화하는 AI 생태계에서 특정 요구사항에 맞춰 스택의 특정 부분을 교체하거나 업데이트할 수 있는 민첩성을 부여합니다. 개발자는 필요한 추상화 수준에서 작업하면서도, 필요할 경우 언제든 하위 레이어의 세부 사항에 접근하여 깊이 있는 최적화를 수행할 수 있습니다. 이러한 설계 원칙은 Modular 팀 내부의 개발 속도를 높일 뿐만 아니라, 외부 개발자들이 자신들의 특정 문제를 해결하기 위해 플랫폼을 유연하게 활용할 수 있도록 돕습니다.

이전 에피소드에서 Mojo의 설계에 대해 많이 다루었으니, 이번에는 그 발전된 모습을 살펴보겠습니다. Mojo의 독창성 핵심에는 파이썬에 친숙한(Python-familiar) 구문으로 가속기 명령어(텐서 코어(tensor cores), TMA 등)를 노출하는 능력이 있습니다. 이는 AI 개발자들이 익숙한 파이썬 환경을 벗어나지 않으면서도, GPU와 같은 이기종 가속기의 모든 잠재력을 끌어낼 수 있도록 설계되었습니다. Mojo는 단순한 프로그래밍 언어를 넘어, 하드웨어와 소프트웨어 스택 사이의 간극을 메우는 핵심 브릿지 역할을 수행하며, 다음과 같은 혁신적인 이점을 제공합니다.

*   한 번 작성하면 다양한 AI 가속기로 리타겟팅(re-target)할 수 있습니다. 이는 특정 벤더에 종속되지 않는 유연한 개발 환경을 제공하며, 미래의 하드웨어 변화에 대한 대응력을 높입니다.
*   CPython보다 월등히 빠르게 실행되며, 최적화된 Rust 코드에 필적하는 성능을 보여줍니다. 이는 고성능이 요구되는 AI 워크로드에서 병목 현상을 제거하고, 실시간 추론과 같은 까다로운 요구사항을 충족시킵니다.
*   바인딩이 필요 없는(zero-binding) 확장 언어로, 기존 파이썬 프로젝트에 쉽게 통합됩니다. 개발자는 복잡한 인터페이스 코드 없이도 파이썬 애플리케이션의 핵심 성능 부분을 Mojo로 쉽게 마이그레이션하여 성능을 극대화할 수 있습니다.

이를 통해 복잡한 커널(kernel) 및 '글루(glue)' 코드가 필요 없어집니다. 이는 MLOps 파이프라인을 간소화하고, 유지보수 오버헤드를 크게 줄여주며, 개발자들이 핵심적인 AI 모델 개발에 더 집중할 수 있도록 합니다.

동일한 접근 방식이 MAX 추론 플랫폼에도 확장 적용되었습니다. MAX는 대규모 AI 모델의 배포와 관리를 혁신하기 위해 설계되었으며, 다음과 같은 특징을 가집니다.

*   Max의 기본 이미지는 매우 경량화되어, 효율적인 배포를 가능하게 합니다. 1GB 미만의 작은 이미지 크기는 엣지 AI(Edge AI) 환경이나 서버리스(serverless) 함수와 같이 자원 제약이 있는 환경에서도 신속한 배포와 빠른 시작 시간을 보장합니다.
*   플래시어텐션(Flash-Attention), 페이징된 KV(paged KV) 등 첨단 최적화가 포함된 컨테이너(container)로 다양한 모델을 지원합니다. 이는 최신 연구 성과가 빠르게 제품에 반영될 수 있도록 하여, 사용자들이 항상 최첨단 성능을 누릴 수 있게 합니다.
*   가장 중요한 것은 오픈 소스 커뮤니티의 적극적인 참여를 이끌어내기 위해 지속적으로 업데이트를 제공한다는 것입니다. 나이틀리 빌드(nightly builds)를 통해 커뮤니티는 최신 기능을 접하고 기여하며, 플랫폼의 투명성과 신뢰성을 높이는 데 기여합니다.

이번 주, 그들은 AMD와 함께 H200과 MI325의 성능이 거의 일치함을 보여주는 중요한 발표를 했습니다. 이는 GPU 시장의 지배력을 깨는 데 있어 큰 진전입니다. 이러한 멀티-벤더(multi-vendor) 전략은 특정 하드웨어 공급업체에 대한 종속성을 줄이고, 기업들에게 더 넓은 선택권과 유연성을 제공합니다. 이는 장기적으로 AI 인프라 비용을 절감하고, 혁신을 가속화하는 데 기여할 것입니다.

Chris는 또한 그의 'AI 컴퓨팅의 민주화(Democratizing AI Compute)' 시리즈로 폭넓은 인사이트를 제공하고 있습니다. 이 시리즈는 Modular의 혁신적인 접근 방식에 대한 명확한 설명이기도 합니다. AI의 "민주화"는 단순히 기술 접근성을 높이는 것을 넘어, 개발자와 기업이 AI 기술을 자신의 필요에 맞게 제어하고 최적화할 수 있는 능력을 부여하는 것을 의미합니다.

Chris는 이미 여러 기술 스택을 성공적으로 대체했습니다. 다음은 Mojo가 AI 가속기 프로그래밍을 재정의할 차례일까요? 우리는 이를 실현하기 위해 무엇이 필요한지에 대해 깊이 탐구했습니다. 이는 단순한 대체가 아니라, AI 개발 패러다임 자체를 한 단계 끌어올리는 것을 목표로 합니다.

***

Modular는 이제 막 3년이 조금 넘은 회사입니다. 처음 3년은 많은 사람들에게 매우 미스터리한 시간이었습니다. 왜냐하면 저희가 모든 것을 알아가는 과정에 있었기 때문입니다. 저희는 이 정말 어려운 문제, 즉 이기종 컴퓨팅(heterogeneous compute)의 잠재력을 어떻게 열 것인가? AI 스택 전반에 걸친 풀스택(full stack) 혁신을 어떻게 더 간단하게 만들고 복잡성을 몰아냄으로써 가능하게 할 것인가? 와 같은 핵심적인 질문들을 해결하려고 노력하고 있었습니다. 이러한 질문에 대한 해답을 찾는 과정은 단순한 연구를 넘어, AI 개발의 본질적인 복잡성을 제거하고 개발자 생산성을 극대화하는 것을 목표로 했습니다. 이제는 모두가 볼 수 있게 된 거죠. 그래서 저희가 국면 전환을 하면서, 갑자기 "그래, 좋아, 오픈 소스화하자"가 되는 겁니다. 이제 더 많은 사람들이 참여하기를 원하니까요. 사실, 저희는 해커톤(hackathon)을 열었습니다. 하루 만에, 그들은 이전에 Mojo를 사용해 본 적도, GPU를 프로그래밍해 본 적도 없었는데, 훈련 시스템을 만들었습니다. Adam 옵티마이저(Adam Optimizer)와 여러 훈련 커널을 작성하고, 간단한 역전파(backprop) 시스템을 구축해서, 저희가 추론을 위해 만든 모든 것들을 사용해서 모델을 훈련시킬 수 있다는 것을 실제로 보여주었습니다. 이것이 바로 차이점이고, 저희 팀이 겪어온 진화 과정입니다. 이러한 경험은 AI R&D가 단순한 학술 연구 단계를 넘어, 실제 엔지니어링 문제 해결로 전환되고 있음을 보여줍니다.

처음에 뵈었을 때, 사실 CPU에 집중하고 계셨던 것으로 기억합니다. 제가 Modular를 설명하는 방식은, 첫해는 컴파일 철학을 증명하는 것이었습니다. 2년차에는 두 가지 길을 갔습니다. 하나는 Mojo입니다. 프로그래밍 언어 구문, 파이썬 계열의 일원으로서, 커널 작성과 성능 등을 훨씬 더 접근하기 쉽고 쉽게 만드는 것이죠. 그리고 두 번째는 CPU용 AI 프레임워크를 구축하여 인텔 CPU에서 OpenVINO 같은 것들을 이기는 것이었습니다. 2년차 말에 우리는 "휴, 이 놀라운 것을 달성했어. 하지만 멋지군. GPU."라고 생각하게 되었습니다. 그래서 다시 두 가지를 말했습니다. "좋아, GPU를 할 수 있다는 것을 증명하자." LLM 서빙(LLM serving)에 도전해 보자. 그리고 그것이 우리를 3년차로 이끌었습니다. 이 각 단계는 정말 어렵고 흥미로운 기술적 문제들이 많았습니다. 아마도 당신이 마주하는 가장 큰 문제는, 끊임없이 불가능하다고 말하는 사람들을 마주하는 것입니다. 하지만 다시 말하지만, 조금 고집을 부리고 자신을 믿고 열심히 일하며 이정표에 집중해야 합니다. CUDA가 거의 20년이 되었고, NVIDIA에는 수백, 수천 명의 사람들이 작업하고 있다는 것은 상식입니다. 많은 사람들은 스타트업이 이 분야에서 무언가를 하는 것이 불가능하다고 생각합니다. 그래서 변화가 불가능하다는 것이 일반적인 통념이지만, 이봐요, 우리는 AI 시대에 살고 있잖아요. 우리 주변에는 항상 변화가 있죠. 그래서 당신이 해야 할 일은 성공 기준이 무엇인지, 변화가 실제로 작동하게 하는 원인이 무엇인지를 계획하는 것입니다. 그리고 제 경력 전반에 걸쳐, LLVM 때처럼, 모든 GCC 사람들은 저에게 불가능하다고 말했습니다. "LLVM은 실패할 거야." 애플 내부에서 그것에 대해 아는 모든 사람들은 "아니, 아니, Objective-C는 괜찮아. 그냥 Objective-C를 개선해야 해. 세상은 새로운 프로그래밍 언어가 필요 없어. 새로운 프로그래밍 언어는 절대 채택되지 않아."라고 말했습니다. 그리고 "새로운 프로그래밍 언어는 아무 데도 가지 못한다"는 것은 상식입니다. MLIR은 또 다른 컴파일러입니다. LLVM 커뮤니티의 모든 LLVM 권위자들(LLVM Illuminati)은 "아니, 아니, LLVM은 충분히 좋아. 새로운 건 필요 없어. 머신러닝은 그렇게 중요하지 않아."라고 말했습니다. 그래서 다시, 분명히 이런 종류의 도전을 해결하기 위한 몇 가지 기술을 개발했지만, 인간은 변화를 좋아하지 않는다는 현실로 돌아가게 됩니다. 그래서 블로그 포스트 시리즈 같은 것들이 모두 이런 교육 캠페인의 일부인 것입니다. 단지 정말 힘든 작업이고, 엘리트 팀과 좋은 비전, 지도 등이 필요할 뿐입니다. 하지만 이것을 하는 것이 불가능하다는 것이 이해할 만한 일반적인 통념입니다. 이러한 경험은 기술 혁신이 단순히 코드 작성에 그치지 않고, 깊이 있는 교육과 커뮤니티 참여를 통해 새로운 패러다임을 정착시키는 과정임을 보여줍니다.

오늘 MAX를 다운로드할 수 있습니다. 무료로 제공되고요. 원한다면 수천 개의 GPU로 확장할 수도 있습니다. VLLM 같은 것만큼 좋지는 않습니다. 몇 가지 기능이 빠져 있고, 예를 들어 NVIDIA와 AMD 하드웨어만 지원합니다. 하지만 컨테이너가 1기가바이트 정도밖에 안 돼요. 왜 1기가바이트일까요? 음, 완전히 새로운 스택이기 때문입니다. CUDA를 사용할 수도 있고, 임의의 PyTorch 모델을 실행할 수도 있습니다. 하지만 사람들이 정말로 신경 쓰는 일반적인 LLM과 Gen AI 모델을 실행한다면, 완전히 네이티브 스택입니다. 매우 효율적이죠. 즉시 실행 모드 연산 디스패치(eager mode op dispatch) 같은 것을 위해 루프에 파이썬이 없습니다. 서버가 정말 빨리 시작됩니다. 그래서 수평적 자동 확장(horizontal auto scaling)에 관심이 있다면, 그건 정말 멋진 일입니다. 모든 것이 오픈 소스입니다. 그래서 해킹할 수 있죠. 이것은 매우 다른 세상입니다. 저는 여기에 몇 가지 흥미로운 점이 있고, 특정 사람들에게 흥미로운 구체적인 이유가 있다고 생각합니다. MAX의 효율성은 단순히 성능을 넘어, 기업이 AI를 대규모로 배포하고 관리하는 방식을 변화시킵니다. 특히, 경량화된 이미지와 네이티브 스택은 클라우드 환경에서 리소스 사용량을 최적화하고, 운영 비용을 절감하는 데 결정적인 역할을 합니다.

저희 스택의 맨 아래에는 Mojo라는 프로그래밍 언어가 있습니다. "Chris, 왜 또 다른 프로그래밍 언어를 만들어야 했나요?" 음, 대답은 기존 언어 중 어느 것도 실제로 문제를 해결하지 못했기 때문입니다. 문제는 이제 모든 컴퓨팅이 가속화되었다는 것입니다. 그래서 우리는 이 모든 것을 아우를 수 있는 프로그래밍 언어가 필요합니다. C++는 형편없습니다. AI 사람들은 일반적으로 C++를 좋아하지 않는다고 주장하겠습니다. 그들은 파이썬을 좋아합니다. 그래서 저희가 결정한 것은 "좋아, C++의 영역 내에서도 텐서 코어(tensor cores) 같은 것들과 통신할 수 있는 실제로 좋은 통합적인 것이 없다"는 것이었습니다. 그래서 저희는 "나는, Chris가 비합리적이게도, 한 공급업체에서 나온 칩 하나만이 아니라, 어떤 칩의 모든 성능을 드러낼 수 있는 것을 원한다. 그것은 그래프 컴파일러(graph compilers)와 같은 다음 수준의 매우 멋진 컴파일러와 다른 것들을 지원해야 하고, 이식성이 있어야 한다. 공급업체 간에 이식성이 있어야 하고, 이식 가능한 코드를 가능하게 해야 한다."고 말했습니다. H100과 AMD 칩은 실제로는 꽤 다릅니다. 하지만 그 사이에는 재사용할 수 있는 것이 많습니다. 그래서 공통 코드가 많을수록 좋습니다. 다른 부분은 사용성입니다. 그래서 우리는 사람들이 실제로 사용하고 배울 수 있는 것을 원합니다. 성능과 제어, 그리고 다시 말해, 하드웨어의 모든 성능을 원합니다. 그리고 이것이 Mojo가 탄생한 배경입니다. 오늘날 Mojo는 두 가지에 정말 유용합니다. Mojo는 시간이 지남에 따라 성장할 것이지만, 오늘날 저는 성능이 중요한 곳에 사용하기를 권장합니다. 파이썬을 확장하는 가장 좋은 방법이라는 것입니다. 만약 당신이 큰 파이썬 코드 덩어리를 가지고 있고, 성능에 신경을 쓴다면, 파이썬에서 성능 부분을 빼내고 싶을 겁니다. 우리는 그것을 Mojo로 옮기는 것을 매우 쉽게 만듭니다. Mojo는 파이썬보다 약간 더 빠른 것이 아니라, Rust보다 빠릅니다. 파이썬보다 수만 배 빠르죠. 그래서 말 그대로 일부 for 루프를 뜯어내서 Mojo에 넣으면 성능 향상을 얻을 수 있습니다. GPU로 오프로드할 수도 있고, 이런 것들을 할 수 있습니다. 그리고 모든 패키징은 매우 간단하며, 파이썬 코드를 빠르게 만드는 아름다운 방법입니다. 기술적으로는 저희 나이틀리 빌드(nightlies)에 있지만, 아직 공식적으로 발표하지는 않았습니다. 저희는 매우 개발자 중심적입니다. 그래서 저희 Discord나 Discourse에 가입하면, 나이틀리 빌드는 훌륭합니다. 발표되지 않았지만 커뮤니티에서는 잘 알려진 것들이 많이 있습니다. 바인딩이 필요 없습니다(binding-free). 만약 당신이 큰 파이썬 코드 덩어리를 가지고 있다면, 우리 중 많은 사람들이 그렇듯이, 그것을 만들고, 만들고, 만들고, 만들다 보면 성능이 문제가 됩니다. "내 전체 애플리케이션을 Rust 같은 걸로 다시 작성하겠다"고 말할 수 있습니다. 다른 방법은 "좋아, Pybind나 Nanobind 또는 어떤 Rust 도구 같은 것을 사용해서 내 모듈의 일부, 성능이 중요한 부분을 다시 작성하겠다"고 말하는 것입니다. 이제 이 바인딩 로직과 이 빌드 시스템의 복잡함, 그리고 이쪽에 Rust 코드가 있고 저쪽에 파이썬 코드가 있는 이 모든 복잡성을 감당해야 합니다. Mojo는 파이썬이 가진 모든 기능을 가지고 있지는 않습니다. 특히, Mojo에는 클래스가 없습니다. 하지만 함수는 있습니다. 임의의 파이썬 객체를 사용할 수 있습니다. 이 바인딩 없는 경험을 얻을 수 있고, 매우 유사합니다. 그래서 이것을 매우 빠르고, 약간 더 제한적인 파이썬으로 볼 수 있습니다. 그리고 이제 생태계 내에서 응집력이 생깁니다. 저는 이것이 단지 AI 생태계를 넘어서서 유용하다고 생각합니다. 이것은 파이썬 전반에 걸쳐 꽤 멋진 것이라고 생각합니다. 하지만 이제 GPU를 가져와서 "좋아, 당신의 코드를 가져와서 정말 빠르게 만들 수 있다"고 말합니다. 왜냐하면 CPU에는 자체 텐서 코어와 SIMD, 그리고 이 모든 것들과 같은 멋진 기능들이 많이 있기 때문입니다. 그런 다음 그것을 GPU에 올릴 수 있습니다. 그리고 그것을 8개의 GPU에 올릴 수 있습니다. 그리고 이것은 Rust가 할 수 없는 것입니다. 이것은 우리가 세상에 내놓고 있는 새로운 기술의 물결의 일부입니다. 올 가을은 훨씬 더 재미있을 겁니다. AMD와 NVIDIA 외에 더 많은 하드웨어가 있을 수 있습니다. Mojo는 이기종 컴퓨팅 환경에서 개발자 생산성과 성능을 동시에 극대화하는 혁신적인 솔루션으로 자리매김하고 있습니다.

안쪽 원은 프로그래밍 언어입니다. 그리고 그것은 무언가를 빠르게 만드는 좋은 방법입니다. 다음 단계는 Max라고 부르는 Gen AI 추론 중심의 프레임워크입니다. Max는 PyTorch가 아닙니다. 그것이 되고자 하는 것이 아니라, 추론에 정말 집중되어 있습니다. 성능과 제어, 그리고 지연 시간에 정말 집중되어 있죠. 그래서 Mojo와 직접적으로 작동하도록 설계되었습니다. LLM 애플리케이션에는 매우 맞춤화된 GPU 커널이 많이 있습니다. 최근에 나온 딥시크(deep seek) 같은 것들처럼 미친 형태의 어텐션이 많이 있고, 이런 것들은 항상 변합니다. 그래서 그들 중 많은 것들이 커스텀 커널입니다. 하지만 그 밖에는 그래프 레벨이 있습니다. 내부에 CUDA나 Tritonlang 같은 것들이 있고, 외부에 파이썬이 있는 것입니다. 우리는 그 모델을 받아들였습니다. 깨지지 않은 것은 고치지 말자는 거죠. 우리는 모델 레벨에 순수 파이썬을 사용합니다. API는 매우 간단합니다. 매우 간단한 PyTorch처럼 느껴집니다. Mojo와 직접적으로 통합됩니다. 완전한 통합을 얻게 됩니다. 자동 커널 퓨전(automatic kernel fusion) 같은 것을 얻게 된다는 것을 의미합니다. 그것은 "좋아, 플래시 어텐션의 한 버전을 작성하면, 멋지네. 우리가 자동으로 퓨전할 수 있어"라고 말할 수 있게 해주는 매우 멋진 컴파일러 기술입니다. 그래서 당신이 사용하고 싶을 수 있는 다른 활성화 함수들을 자동으로 퓨전할 수 있고, 이 커널들의 모든 순열을 작성할 필요가 없습니다. 그것은 단지 당신이 더 생산적이 된다는 것을 의미합니다. 더 나은 성능을 얻게 된다는 것을 의미합니다. 그것은 단지 시스템의 복잡성을 낮추는 것입니다. 멋진 컴파일러가 있다는 것을 알 필요가 없어야 합니다. 맞춤형 모델을 만들고 기존 모델을 맞춤화하는 것과 같은 매우 멋지고, 매우 인체공학적이며 효율적인 방법처럼 느껴집니다. max를 사용하면, 500~600개의 매우 일반적인 모델 패밀리가 있고, build.modular.com에서 볼 수 있는 구현된 것들이 있습니다. 다음 레이어는 "좋아, 단일 노드에서 서빙을 하는 매우 멋진 방법이 있네. 하지만 실제로 멋진 것은 대규모 배포야."라고 말하는 것입니다. 다음 레벨, 클러스터 레벨이 있습니다. 쿠버네티스 클러스터가 있고, 플랫폼 팀이 있어. 그들은 300개의 GPU에 대해 3년 약정을 맺었어. 그리고 이제 제품 팀이 있어. 이 공유 컴퓨팅 풀에 워크로드를 던지고 싶어. 각 노드별로 매우 멋진 접두사 캐싱(prefix caching)이 있고, 지능적인 라우팅이 있으며, 분리된 프리필(disaggregated pre-fill)과 같은 멋진 기술들이 각 레이어에 많이 있습니다. 그것들이 모두 공동으로 설계되었다는 것입니다. 내부가 이기종이기 때문에, "이봐, AMD도 있고, Nvidia도 있어. 모델을 던져서 최고의 아키텍처에서 실행해."라고 말할 수 있습니다. 이것은 실제로 많은 관리 문제를 단순화합니다. AI에 내재된 것으로 내면화한 복잡성의 상당 부분은 실제로는 함께 설계되고 있는 이러한 시스템의 결과입니다. 저의 최우선 목표는 복잡성을 몰아내는 것입니다. 우리 스택의 복잡성도요. AI 전반의 복잡성을 몰아내는 것이죠. AI 전반에는 그럴 만한 것보다 훨씬 더 많은 기술 부채가 있습니다. VLLM 대 SGLang 그리고 버클리에서 나오는 모든 것들에 대해 어떤 견해나 내부자 정보가 있는지 궁금합니다. SG Lang은 제게 매우 집중된 팀으로 보입니다. 특정 목표와 증명하고 싶은 것들이 있고, Modular 팀처럼 특정 목표를 향해 정말 열심히 실행하고 있습니다. VLM은 훨씬 더 많은 이해관계자와 많은 일들이 벌어지고 있는 거대한 커뮤니티처럼 보이고, 좀 엉망진창인 것 같습니다. 그들은 모두가 벤치마킹하는 기본 추론 플랫폼이 되고 싶어 하죠. 그리고, 제 생각에, 제가 아는 한, 그것은 TRT LLM이나 다른 오래된 시스템들을 압도하고 있습니다. 그들의 야망에 대해 말할 수는 없지만, 구조적으로는 매우 다른 접근 방식인 것 같습니다. 하나는 "정말 중요한 소수의 일에 정말 잘하자"고 말하는 것입니다. 하나는 "많은 것에 '예'라고 말하자. 그러면 많은 것을 갖게 될 것이고, 그중 일부는 작동하고 일부는 작동하지 않을 것이다"라고 말하는 것입니다. VLM에 대해 제가 끊임없이 듣는 도전 과제 중 하나는, 웹페이지에 가보면, "네, 우리는 이 모든 하드웨어를 지원합니다. 구글 TPU, Inferentia, AMD, 그리고 당연히 Nvidia, CPU 등등을 지원합니다."라고 말한다는 것입니다. 그리고 그들이 지원하는 것들의 거대한 목록이 있습니다. 하지만 그리고 나서 VLM으로 무언가를 하는 방법에 대한 어떤 임의의 웹페이지의 데모를 따라 하려고 하면, 비-NVIDIA 하드웨어에서 하면 실패합니다. 그래서 VLM 같은 것의 가치는 무엇일까요? 음, 가치는 그 위에 구축하고 싶다는 것입니다. 만약 당신이 작동한다고 광고하는 것을 가지고 있는데, 그것을 집어 들었을 때 작동하지 않고 디버깅해야 한다면, 그것은 목표에 대한 배신과도 같습니다. 저는 그들이 발명하지 않은, 솔직히 말해서 잘 작동하지 않는, 그들 아래에 있는 많은 것들 위에 구축하려고 하는 근본적인 이유를 압니다. "우리가 할 수 있는 모든 것들이 여기 있습니다"라고 말하고, 실제로 작동하는 것들의 희소 행렬을 갖는 그 접근 방식은, "좋아, 우리는 소수의 일을 정말 잘하고, 당신은 그것에 의존할 수 있다"고 말하는 보수적인 접근 방식과는 매우 다릅니다. 저는 둘 다 감사하고, 둘 다 훌륭한 아이디어를 가지고 있습니다. 그리고 경쟁이 있다는 사실은 업계의 모든 사람들에게 좋습니다. 그들은 이 산업이 진화하는 방식의 벤치마크 전쟁 상태에 있습니다. 하지만, 저는 또한 기업 측면에서 그들이 모두 너무 좋아서 드라마를 따르고 싶어하지 않는다는 말을 듣습니다. 그래서, 이것이 바로 혼란이 적고, 함께 일할 수 있는 누군가가 있다는 것이 요즘 정말 가치 있는 이유입니다. 최첨단 기술과 성능 등이 필요하지만, 잘 실행하고 함께 일할 수 있는 누군가가 있다는 것도 매우 중요합니다. 모듈식 설계에 대한 저의 집착은 LLVM을 만들던 시절로 거슬러 올라갑니다. 그 당시에는 GCC가 있었습니다. GCC는 모놀리스(monolith)입니다. 그것은 오래된 유닉스 방식, 즉 컴파일러는 유닉스 파이프이고, 모든 것이 전역 변수이며, C 코드로 설계되었습니다. 그것은 다른 소프트웨어 시대의 것이었고, LLVM이 와서 "모두가 학교에서 가르치는 것은 프론트엔드, 옵티마이저, 코드 생성기가 있다는 것이다. 그것을 깔끔하게 만들자"고 말했습니다. 그 당시 사람들은 저에게 다시, 우선, GCC를 대체하는 것은 불가능하다고 말했습니다. 하지만 또한 깔끔한 설계를 가질 수 없다고 말했습니다. 그들이 맞을 수도 있습니다. 무한히 완벽한 우주에서는요. 하지만 우리는 무한히 완벽한 우주에 살고 있지 않습니다. 대신, 우리가 사는 우주는 팀이 있는 곳입니다. 파서를 잘 쓰는 사람들, 옵티마이저를 잘 쓰는 사람들, x86용 코드 생성기를 잘 쓰는 사람들 같은 사람들이 있죠. 또한, AI에서 보듯이, 요구 사항은 항상 바뀝니다. 그래서 만약 당신이 오늘 매우 하드코딩되고 해킹된 모놀리스를 작성한다면, 2년 후에는 그것이 관련이 있을까요? 그리고 이것이 우리가 AI에서 많이 보는 것입니다. 우리는 정말 멋지고 매우 유망한 시스템들이 나타나고 매우 빠르게 성장했다가 결국 무너지는 것을 봅니다. 그것은 거의 일회용 프레임워크이기 때문입니다. 언어는 프레임워크입니다. 이 시스템들 각각은 결국 달라집니다. AI에서 우리는 진보가 더 느려지는 것이 아니라 더 빨라지기를 원한다는 것입니다. 그것은 논란의 여지가 있습니다. 왜냐하면 이미 너무 빠르기 때문이죠. 하지만 우리가 일을 가속화할 수 있다면, 우리는 우리 삶에 더 많은 제품 가치를 얻게 됩니다. 우리는 더 많은 영향을 미치게 됩니다. 우리는 AI와 함께 오는 모든 좋은 것들을 얻게 됩니다. 현실은 모든 것이 변하고 깨질 것이라는 것입니다. 그래서 만약 당신이 모듈성을 가지고 있다면, 만약 당신이 깔끔한 아키텍처를 가지고 있다면, 당신은 설계를 진화시키고 변경할 수 있습니다. 그것은 특정 사용 사례에 과도하게 전문화되지 않습니다. 도전 과제는 당신의 기준선과 메트릭을 올바르게 설정해야 한다는 것입니다. 이것이 바로 "업계 최고와 비교하라"고 하는 이유입니다. 그래서 "최고보다 80% 좋은 것을 만들자. 하지만 다른 이점이 있다"고 말하는 것은, 적어도 저에게는 만족스럽지 않습니다. 저는 우리가 신경 쓰는 카테고리에서 최고가 되고 싶습니다.

저는 좋은 아이디어가 어디서 오든 그것을 사용하는 데 전혀 부끄러움이 없습니다. 모든 것은 리믹스(remix)잖아요. 그래서 누군가, 그게 누구든 상관없어요. NVIDIA든, SGLang이든, VLM이든, 누군가 좋은 아이디어를 가지고 있다면, 그것을 함께 모으는 거죠. 하지만 핵심은 그것을 구성 가능하고(composable), 직교적이며(orthogonal), 유연하고(flexible), 표현력이 풍부하게(expressive) 만드는 것입니다. 저는 그것을 VLM에 넣지 않습니다, 예를 들어. 아카이브 논문들의 지속적인 흐름이죠. 추론 연구를 둘러싼 매우 활발한 산업이 있다는 것을 따릅니다. 예전에는 훈련 연구만 있었죠. 그리고 그 중 많은 것들이 이러한 표준 프레임워크에 들어가지 못합니다. 왜냐하면 새로운 것을 위해 대규모로 손으로 코딩된 CUDA 커널과 이 모든 것들을 작성해야 하기 때문입니다. 만약 당신이 이러한 소프트웨어 아키텍처적인 것들을 제대로 한다면, 물론 그것은 당신이 새로운 프로그래밍 언어를 발명해야 한다는 것을 요구합니다. 그것의 멋진 점은 당신이 훨씬 더 빠르게 움직일 수 있다는 것입니다. 이것은 완전히 공개된 것입니다. 왜냐하면 우리는 우리 것을 오픈 소스화했을 뿐만 아니라, 모든 버전 관리 기록을 오픈 소스화했기 때문입니다. 우리는 어떻게 H100을 가져왔는지, 몇 주 만에 처음부터 플래시 어텐션을 구축했는지, 이 모든 것들을 볼 수 있습니다. 우리는 예를 들어, 모두가 사용하는 Tri Dao의 참조 구현을 이기고 있습니다. 완전히 Mojo로 작성되었습니다. 다시 말하지만, 우리의 모든 GPU 커널은 Mojo로 작성되었습니다. 팀이 이것을 구축하는 역사를 볼 수 있고, 그것은 단 몇 주 만에 이루어졌습니다. 우리는 완전히 새로운 GPU 아키텍처인 H100을 가져왔습니다. 그것은 매우 멋진 비동기 기능과 텐서 메모리 가속기 같은 것들을 가지고 있습니다. 그리고 그들이 추가한 이 모든 이상한 것들은 성능에 정말 중요합니다. 우리의 목표는 QDNN과 TRTLM 같은 것들을 만나고 이기는 것입니다. 그래서, 성공으로 가는 빠른 길만 있는 것이 아닙니다. 모든 것을 제대로 하고 모든 것이 맞아떨어져야 합니다. 우리는 그것을, 제 생각에, 두 달도 안 돼서 해냈습니다. 깃허브에 공개적으로요. 그 속도는 정말 놀랍습니다. 플래시 어텐션을 발명하는 데 9개월 또는 12개월이 걸렸고, VLM에 들어가는 데 또 6개월이 걸렸습니다. 그리고 이것은 단지, 후자는 단지 통합 작업일 뿐입니다. 이제 당신은, 다른 아키텍처에 대해 확장되고 이러한 장점을 가진 구성 가능한 방식으로 이 모든 것을 처음부터 구축하는 것에 대해 이야기하고 있습니다. 그것은 그냥 다른 수준입니다. 어쨌든, 우리 것은 여러 면에서 아직 초기 단계입니다. 그래서 기능이 부족합니다. 하지만 만약 당신이 우리가 하는 일에 관심이 있다면, 변경 로그를 완전히 따라갈 수 있습니다. 그리고 당신은, 우리가 모든 멋진 것들을 게시하는 나이틀리 빌드를 따라갈 수 있고, 모든 커널은 공개되어 있습니다. 그리고 만약 당신이 관심이 있다면, 당신도 이것을 할 수 있습니다. 이러한 개방적인 개발 방식은 커뮤니티의 참여를 유도하고, 혁신을 가속화하며, 투명성을 통해 신뢰를 구축합니다.

저희는 작은 팀입니다. 우리는 AI 산업의 크기에 비하면 극히 미미합니다. Turing 지원에 별로 신경 쓰지 않았습니다. 그래서 커뮤니티의 누군가가 "좋아, 나도 새로운 GPU 아키텍처를 활성화할게"라고 했습니다. 그래서 그들이 Turing 지원을 기여했습니다. 이제 Max와 Colab을 무료로 사용할 수 있습니다. 여러 연산자들이 있습니다. 우리는 AI와 Gen AI 같은 것에 매우 집중하고 있습니다. 우리 것은 AI에만 국한되지 않습니다. 레이 트레이서(ray tracer)를 작성한 사람들도 있고, 비행 안전을 연구하는 사람들도 있고, 온갖 이상한 일들을 하는 사람들이 있습니다. 우리 해커톤에서 누군가가, 블랙박스 같은 트래픽을 보고 조종사가 실수를 했을 때를 예측하는 데모를 만들었습니다. 그리고 비행기에 큰 문제가 생길 것이고, 그것을 높은 신뢰도로 예측하는 거죠. 이것이 바로 우리 산업에 거의 무한히 똑똑하다고 느껴지는 사람들이 너무 많다는 것의 힘입니다. 그들은 대부분의 면에서 저보다 훨씬 똑똑합니다. 당신이 그들에게 도구를 주고, 무언가를 가능하게 하면, 그리고 또한 AI 코딩 도구와 같은 것들이 격차를 메우는 데 도움이 되면, 저는 우리가 훨씬 더 많은 제품을 갖게 될 것이라고 생각합니다. 이것이 정말로 저를 동기 부여하는 것입니다. 몇 년 전 저를 정말 좌절시키고 Modular를 시작하도록 영감을 준 것 중 하나는, 제가 조 단위 달러 기업들이 무엇을 할 수 있는지 봤다는 것입니다. 모든 똑똑한 사람들이 수직적으로 위에서 아래까지 모든 것을 구축한 가장 큰 연구실들을 보면, 그들은 놀라운 제품과 연구 및 기타 작업을 할 수 있었습니다. 그리고, 아시다시피, 5명 팀이나 스타트업 같은 곳에서는 아무도 그것을 감당할 수 없었습니다. 그것은 대규모로 작동하지 않습니다. 우리는 제대로 구성되고, 간단하며, 이해할 수 있고, 경계를 넘을 수 있는 것들이 필요합니다. AI의 많은 부분은 팀 스포츠입니다. 그리고 우리는 더 많은 사람들이 참여하고 성장하며 배울 수 있기를 원합니다. 더 많은 제품 혁신을 얻게 되고, 단지 "거대한 AI가 모든 문제를 해결할 것이다"와 같은 해결책이 아니라, 더 세분화되고, 목적에 맞게 구축되고, 제품에 통합된 AI를 얻게 될 것이라고 생각합니다. 당신이 "AI가 가속화되기를 원한다"는 말을 했는데, 그것은 이미 빠르고 사람들이 이미 불편해하기 때문에 역설적이라는 것입니다. 저는 '민주화'라는 단어에 대해 복잡한 감정을 가지고 있지만, 그것이 바로 당신이 하고 있는 일입니다. 예전에는, 2017년에는 AI를 민주화하는 것이 멋진 일이었습니다. 그리고 그것이 의미했고, 의미하게 된 것은 모델 훈련을 민주화하는 것이었습니다. PyTorch가 모델 훈련을 민주화한 공로를 모두 인정받아야 한다고 생각합니다. 하지만 아무도 추론을 민주화하지 않았습니다. 추론은 항상 블랙 아트(black art)로 남아 있었습니다. 그래서 우리가 VLM이나 SG Lang 같은 것들을 가지고 있는 이유입니다. 왜냐하면 그것들은 당신이 그 위에 구축하고, 그 무서운 것들이 어떻게 작동하는지 알 필요가 없는 블랙박스이기 때문입니다. 그것은 우리가 업계에 이런 것들을 하는 방법을 가르치지 않았기 때문입니다. 하지만 저는 그것이 문제가 아니라고 생각합니다. 그것은 내재된 문제가 아닙니다. 저는 단지 우리가 추론을 위한 PyTorch 같은 것이 없기 때문이라고 생각합니다. 그래서 우리가 이런 것들을 더 쉽게 만들고 분해하기 시작하면, 좋은 아이디어의 확산을 훨씬 더 많이 얻을 수 있습니다. VLM은 학자들이 이끄는 오픈 소스 프로젝트이고, 다른 추론 팀들도 마찬가지입니다. 당신의 비즈니스 모델은 그들과 매우 다릅니다. 당신은 오픈 소스를 믿지만, 단지 그것뿐만이 아닙니다. 당신은 다른 모든 사람들이 하는 일반적인 호스팅 클라우드 서비스로부터 돈을 벌지 않기로 선택했습니다. 철학적인 이유와 차별화, 여러 가지 이유가 있습니다. 우리는 이것을 어려운 모드로 하고 있습니다. 우리는 제품까지 긴 길을 걸어왔습니다. 우리는 그냥 바로 몇 개의 커널을 얻고, 알파 버전을 만들고, GPU 예약 같은 것을 사서 우리 GPU를 재판매하는 그런 식이 아닙니다. 그 길은 많은 회사들이 선택했고, 그들은 그것을 정말 잘합니다. 그리고 저는 당신을 위해 데이터 센터를 짓지 않을 겁니다. 그것보다 훨씬, 훨씬 더 잘하는 사람들이 있습니다. 저는 이 소프트웨어에 꽤 능숙합니다. 그래서 당신은 모든 컴퓨팅을 처리할 수 있습니다. 게다가, 스타트업에서 벗어나면, GPU와 클라우드로 고생하는 사람들이 많습니다. GPU와 클라우드는 근본적으로 CPU와 클라우드와는 다른 것입니다. 그리고 많은 사람들이 그것에 다가가서 "그냥 다 클라우드일 뿐이야"라고 말합니다. 모든 워크로드는 상태가 없었습니다(stateless). 모두 수평적으로 자동 확장될 수 있었습니다. CPU는 비교적 저렴합니다. 그래서 탄력성을 얻을 수 있습니다. 꽤 빨리 로드할 수 있죠. 어떤 사업이 2년 반 후에 무엇을 할지 아는 사람이 있을까요? 아무도 없습니다. 그래서 CPU를 위한 클라우드는 그렇게 멀리까지 용량 계획을 할 필요가 없기 때문에 엄청나게 가치가 있습니다. 이제 GPU로 넘어가 봅시다. 이제 3년 약정을 맺어야 합니다. 그래서 젠슨(Jensen)이 1년 안에 구식으로 만들 하드웨어에 대해 3년 약정을 맺는 겁니다. 그래서 큰 약정을 맺고, 그것으로 무엇을 할까요? 당신의 필요가 어떨지 모르기 때문에 과도하게 약정해야 하고, 이것을 할 준비가 되어 있지 않습니다. 모든 기술은 매우 복잡하고 무섭습니다. GPU 워크로드는 상태가 있습니다(stateful). 그래서 이제 수평적 자동 확장을 얻지 못합니다. 상태 없는 탄력성을 얻지 못합니다. 그래서 거대한 관리 문제를 얻게 됩니다. 우리가 할 수 있고, 사람들을 도울 수 있다고 생각하는 것은 "좋아, 당신의 컴퓨팅에 대한 권한을 주겠다"고 말하는 것입니다. 많은 사람들이 다른 시스템을 가지고 있고, 이것에 들어가는 매우 간단한 시스템들이 있습니다. 하지만 지능적인 라우팅을 통해 5배의 성능 TCO 이점을 얻을 수 있습니다. 그것은 실제로 플랫폼 팀에게 큰 문제입니다. 그들은 이것을 처리하고 싶어하지 않습니다. 그들은 AMD로 가기 위한 하드웨어 선택권을 원합니다. 그들은 이런 종류의 힘과 기술을 원합니다. 그래서 우리는 그들과 함께 일하게 되어 매우 기쁩니다. 많은 엔드포인트 회사들이 있고, 그들이 많이 있다는 것입니다. 그들은 분명히 장단점과 트레이드오프가 있습니다. 하지만 일반적으로 엔드포인트의 가치 제안은 "보세요, AI와 AI 소프트웨어, 애플리케이션, 워크로드는 모두 엉망진창입니다. 너무 복잡합니다. 당신의 작은 머리로 걱정하지 마세요. 제가 당신의 접시에서 AI를 치워드릴 테니, 당신은 그것에 대해 걱정할 필요가 없습니다. 우리가 당신을 위해 모든 복잡성을 처리해 드릴 겁니다. 그리고 쉬울 겁니다. 그냥 우리 엔드포인트와 이야기하세요."라고 말하는 것입니다. 우리의 접근 방식은 "좋아, 그래, 모든 것이 엉망진창이야. 맞아, 100%야. 끔찍해. 아마 당신이 아는 것보다 더 심할 거야. 그리고 내일이 되면, 모든 것이 계속 변하기 때문에 더 심할 거야. 우리가 쉽게 만들어 줄게. 우리가 당신에게 힘을 줄게. 당신의 기업과 팀에 초능력을 줄게."라고 말하는 것입니다. 왜냐하면 제가 이야기하는 모든 CEO는 제품에 AI를 넣고 싶어 할 뿐만 아니라, 팀이 AI 기술을 향상시키기를 원하기 때문입니다. 그래서 우리는 기업에서 AI를 빼앗지 않습니다. 우리는 AI에 대한 권한을 줍니다. 우리는 그들의 팀에 힘을 돌려주고, 시작하기 쉬운 경험을 가질 수 있게 합니다. 많은 사람들이 표준적인 상용 모델을 실행하고 싶어 하고, 당신은 기본적인 것으로서 그냥 작동하는 것을 원하기 때문입니다. 하지만 그들이 "이봐, 나는 실제로 미세 조정을 하고 싶어"라고 말할 때, 저는 제 독점적인 데이터를 다른 스타트업이나 심지어 거기에 있는 몇몇 큰 스타트업에 주고 싶지 않습니다. 그것은 제 독점적인 IP입니다. 그리고 나서 당신은 "이봐, 나는 멋진 데이터 모델을 가지고 있어. 나는 실제로 데이터 과학자들이 있어. 나는 실제로 몇 개의 GPU를 가지고 있어. 나는 내 모델을 훈련할 거야."라고 말하는 사람들을 만나게 됩니다. 이제 어떻게 배포할까요? 다시, 당신은 VLM의 내부를 해킹하는 것으로 돌아갑니다. 그리고 PyTorch는 KV 캐시 최적화나 모든 현대적인 트랜스포머 기능 같은 것들을 위해 실제로 설계되지 않았습니다. 그래서 갑자기 당신은 그것이 좋기를 원한다면 이 복잡성의 절벽에서 떨어집니다. 그래서 우리는 "좋아, 그래, 이것은 복잡성의 또 다른 단계야. 하지만 당신은 이것을 소유할 수 있고, 이것을 확장할 수 있어."라고 말합니다. 그래서 우리는 그것을 도울 수 있습니다. 그것은 공간에서 다른 트레이드오프입니다. 하지만 저는 시장 출시 시간과 매출 성장 등이 있다는 것을 인정합니다. 그리고 그들은 CUDA의 전체 대체품을 만들 필요가 없었기 때문에 훨씬 더 빨랐습니다. Modular의 비즈니스 모델은 단순한 호스팅 서비스를 넘어, 기업이 자체 AI 역량을 구축하고 확장할 수 있도록 지원하는 데 중점을 둡니다.

저희는 두 가지를 진행하고 있습니다. Max 프레임워크와 Mojo 언어는 NVIDIA와 CPU에서 어떤 규모로든 무료로 사용할 수 있습니다. 마음껏 사용하세요. 원하는 것은 무엇이든 하세요. 패치를 보내주시면 감사하겠습니다. 무료입니다. 왜 그럴까요? 음, CUDA는 이미 무료입니다. NVIDIA는 이미 여기서 지배적입니다. 우리는 기술이 널리 퍼지기를 원합니다. 무료로 사용하세요. 패치를 보내주시면 좋겠지만, 그렇게 하지 않아도 됩니다. 저희 웹페이지에 로고를 사용할 수 있도록 허락해 달라고 요청합니다. 그래서 이메일을 보내서 "사용하고 있고, 10,000개의 GPU에서 스캔하고 있다"고 알려주시면 정말 좋겠습니다. 하지만 그것이 유일한 요구 사항입니다. 만약 클러스터 관리와 엔터프라이즈 지원, 그리고 이런 것들을 원한다면, GPU당 기준으로 비용을 지불하고 저희 영업팀에 연락할 수 있습니다. 그러면 저희가 거래를 성사시키고 직접 협력할 수 있습니다. 그래서 저희는 이렇게 나눕니다. 그리고 또한, 제가 말하겠습니다. 제가 보고 싶은 한 가지는, 그리고 다시 말하지만, 아직 초기 단계이지만, PyTorch가 Max를 채택하는 것을 보고 싶습니다. VLM이 Max를 채택하는 것을 보고 싶습니다. SGLang이 Max를 채택하는 것을 보고 싶습니다. 우리는 우리만의 작은 서빙 시스템을 가지고 있지만, 가서 보세요. 정말 간단합니다. 정말 놀라울 겁니다. 그리고 다시, 우리는 이제 사람들이 실제로 우리 것을 사용하기를 바라는 단계에 있습니다. 그래서 우리는 역사적으로 "아니, 우리 것은 닫혀 있어, 멀리 떨어져 있어"라는 모드에 있었지만, 지금은 국면 전환을 하고 있습니다. 그래서 앞으로 이런 발표가 더 많아질 겁니다. 우리는 곧 업계를 선도하는 최첨단 모델을 Mac에서 처음으로 출시할 수도 있습니다. 그 점에 대해 계속 주목해 주시고, 저희에게도 알려주세요. 하지만 아직 그런 일은 일어나지 않았으니, 일어나지 않는다고 가정합시다. 저는 그때가 정말로 전환점이 될 것이라고 생각합니다. 왜냐하면 그러면 모두가 "좋아, 그들에게 충분히 좋다면, 우리에게도 충분히 좋아"라고 생각할 것이기 때문입니다. 그리고 나서 나머지 업계를 얻게 됩니다. 네. 하지만 다시 말하지만, 저는 장기전을 하고 있습니다. 그리고 저는 다시, 제가 작업하는 것들은 사람들이 처리하는 데 시간이 걸린다는 것을 깨닫습니다. 그래서 우리가 해야 할 일, 그리고 제가 우리가 하기를 바라는 일, 그리고 제가 팀에게 요청하는 일은, 계속해서 더 좋고, 더 좋고, 더 좋고, 더 좋게 만드는 것입니다. 그리고 기술 채택에는 S자 곡선이 있습니다. 그래서 저는 2월에 우리 것을 사용했던 소수의 미친 얼리 어답터들이 있다는 것이 훌륭하다고 생각합니다. 오픈 소스화되기 전이었고, 합리적인 의미가 전혀 없었습니다. 거의 작동하지 않았죠. 하지만 놀라웠고, 저는 그 사람들에게 매우 감사합니다. 그리고 나서, 물론, 우리는 그것을 오픈 소스화했고, 사람들을 가르치기 시작했고, 훨씬 더 큰 채택 곡선을 얻게 됩니다. 무료로 만들고, 채택하고, 나아가세요. 그리고 나서, 당신이 말했듯이, 곧 더 많은 검증이 있을 것입니다. 그리고 이것들 각각은 곡선의 변곡점입니다. 하지만 그것이 또한 하는 일은, 우리에게 버그를 수정하고, 것들을 개선하고, 더 많은 기능을 추가하고, 새로운 기능을 출시할 수 있는 능력을 준다는 것입니다. Swift의 특징은 제가 2010년에 주말과 저녁 시간을 이용한 프로젝트로 시작했다는 것입니다. 1년 반 동안 혼자서, 주말과 저녁 시간에 해킹했습니다. 결국 애플의 경영진에게 그것에 대해 말했습니다. 그들의 머리가 터질 뻔했습니다. "왜 우리가 무언가가 필요한가? Objective-C는 충분히 좋은데, 왜 이것이 필요한가?"라고요. 몇 명의 사람들을 더 참여시킬 수 있도록 승인을 받았습니다. 저는 거대한 팀을 이끌고 있었습니다. 이것은 제 본업이 아니었다고 해두죠. 하지만 그래서, 2010년에 시작해서, 2014년에 애플에 의해 공개적으로 출시되었습니다. 그리고 2014년에 출시될 때까지, 전 세계에서 약 250명만이 그것에 대해 알고 있었습니다. 그들 대부분은 제 팀에 있었습니다. 약 200명 정도가 제 팀에 있었고, 나머지는 고위 임원, 마케팅, 팀 쿡 등이었습니다. 그리고 이것이 Swift에 대해 아는 사람들의 범주였습니다. 그래서 우리는 그것을 비밀리에 만들었습니다. 말 그대로 NDA(비밀유지계약)가 있었습니다. 애플 내에서. 그것에 대해 알기 위해서요. 우리가 그것을 출시했을 때, 요구 사항 중 하나는 Swift로 앱 스토어에 앱을 제출할 수 있어야 한다는 것이었습니다. 그것이 저에게 주어진 요구 사항이었습니다. 그래서 "좋아, 멋지게 들리네"라고 생각했습니다. 그래서 우리는 그것을 출시하고 1.0이라고 말했습니다. 그래서 당신은 1.0, 완전히 새로운 프로그래밍 언어를 출시하는 것입니다. 아무도 그것을 본 적이 없습니다. 내부 사용자도 없습니다. 데모 앱 하나뿐이었습니다. 정말 악몽이었습니다. 그래서 커뮤니티에게는 악몽이었습니다. 왜냐하면, 다행히도 많은 사람들이 흥분했고 그것을 채택하고 싶어 했고, 많은 사람들이 즉시 그것을 채택했습니다. 하지만 그것은 실전에서 단련되지 않았습니다. 버그가 많았습니다. 우리는 그것을 0.5로 출시했어야 했습니다. 그래서 그것이 꽤 좋아지는 데 1년이 더 걸렸습니다. 그리고 제 생각에, 아주 좋아지는 데 2년이 걸렸습니다. 또한, 애플의 소프트웨어 엔지니어 중 아무도 그것에 대해 몰랐습니다. 그래서 그들의 머리가 터질 뻔했습니다. 그들은 "잠깐만, 왜 Objective-C를 대체하는 거야? 나는 Objective-C를 사랑해서 애플에 입사했는데. 왜 새로운 프로그래밍 언어에 대해 내 의견을 묻지 않았어?"라고 말했습니다. 그래서 그런 모든 역학 관계가 있었습니다. 아니요. 하지만 여전히, "잠깐만, 이건 내가 입사했다고 생각했던 회사가 아니야"와 같은 것이죠. 그리고 이런 것들이요. 그래서 거기서 나온 엄청난 혼란과 드라마, 그리고 말도 안 되는 일들이 있었습니다. 그래서, 좋아, Mojo로 넘어가 봅시다. 배운 교훈들. 이봐, 첫째, 급작스러운 시작(hot start)을 하지 마라. 그래서 우리는 Mojo를 아주 오래 전에, 심지어 말이 되기 전에도 출시했습니다. 그리고 우리는 그것을 0.1이라고 불렀습니다. 그래서, 광고의 정직함은 어떤가요? "이것은 0.1입니다. 제발 사용하지 마세요. 하지만 관심이 있다면, 피드백을 주시면 감사하겠습니다." 그래서 부드러운 시작, 가자. 두 번째로 매우 다른 점은 Swift에서는 데모 앱이 하나뿐이었다는 것입니다. 그래서 당신은 매우, 제 생각에, 강력한 팀이 많은 신뢰할 만한 일을 해온 언어를 만들고 있었지만, iOS 개발자를 위한 언어를 만들고 있었습니다. 그리고 컴파일러는 C++로 작성되었습니다. 그래서, 네, 사용자에 대한 공감은 있지만, 우리가 출시했을 때 내부적으로 많은 이해나 학습이 없었습니다. Mojo의 경우, Modular는 Mojo의 첫 번째 고객입니다. 우리 저장소에는 다른 어떤 언어보다 더 많은 Mojo 코드가 있습니다. 그것은 굉장합니다. 그리고 그것은 오픈 소스입니다. 그리고 우리는 약 65만 줄의 Mojo 코드를 오픈 소스화했습니다. 이것은 많습니다. 그래서 우리는 고통을 겪고, 우리의 필요에 따라 기능과 개선을 추진합니다. 우리는 또한 커뮤니티에 감사합니다. 그리고 우리는 많은 기여를 받고 있습니다. 그리고 누군가가 제 문자열 구현에서 비트 하나를 제거하여 최적화했는데, 그것은 최적이 아니었습니다. 그래서 그것은 정말 굉장했습니다. 하지만 그렇게 추진하는 것은 그것이 진짜임을 확인시켜 줍니다. 그것은 현실에 기반을 두고 있습니다. 그것은 사용 사례에 기반을 두고 있습니다. 우리는 과대 약속을 하지 않으려고 노력하고 있습니다. 심지어 당신이 저에게 그것이 무엇에 유용한지 물었을 때도, 저는 그것이 파이썬의 대체품이라고 말하지 않았습니다. 저는 그것이 빠르게 가는 언어라고 말했습니다. 언젠가는 꽤 신뢰할 만한 파이썬 대안이 될 수도 있습니다. 하지만 지금 당장은 특정 종류의 사용 사례에 좋습니다. 그리고 만약 당신이 그 사용 사례에 관심이 있다면, 예를 들어 GPU를 쌩쌩 돌리는 것과 같은, Mojo는 굉장합니다. 하지만 만약 당신이 Rust의 완전한 대체품을 원한다면, 우리에게 6개월을 주세요. 애플의 AI 이니셔티브에 무슨 일이 일어나고 있는지에 대해 많은 미스터리가 있다고 생각합니다. 그리고 결국 소비자들이 고통받습니다. 최종 사용자들은 이것을 기다리고 있는데, 일어나지 않고 있습니다. 불행히도, 제가 아는 것은 모두 엄청나게 구식입니다. 그들은 변했고, 재편성되었고, 성장했고, 문화도 바뀌었습니다. 그리고 그것은 매우 성공적인 회사입니다. 그래서 저는 그들이 아마도 성공을 느끼고 있고, 업계의 변화에 적응하는 데 어려움을 겪고 있다고 생각합니다. 그리고 그것은 많은 대기업의 전형적인 모습입니다. 구글에 대해 말하자면, 분명히, 저는 그들이 가장 초기에 있었던 회사 중 하나라고 생각합니다. 그들이 트랜스포머를 발명했죠. 다른 많은 것들도요. 텐서플로우, 기억나세요? 네, 맞아요. 엄청났죠. 저는 구글이 AI를 오픈 소스로 만든 공로를 인정합니다. 음, 그들은 텐서플로우를 오픈 소스화할 필요가 없었습니다. 네. 그것은 놀라운 결정이었습니다. 제프 딘과 이에 관여했던 많은 다른 사람들에게 전적인 찬사를 보냅니다. 왜냐하면 그들은 "구글에게 실제로 가장 중요한 것은 AI가 더 빨라지는 것이다. 어떻게 그렇게 할 수 있을까? 우리는 텐서플로우를 독점적인 내부적인 것으로 만드는 대신 오픈 소스화한다."고 말했기 때문입니다. 그들은 이전에 Disbelief라는 시스템을 가지고 있었습니다. 그래서 그것은 PyTorch가 오픈 소스화되고, 연구가 공개되고, 이 모든 것들의 무대를 마련한 거대한 순간이었습니다. 왜냐하면 그들은 가치 체계가 AI가 더 빨라지는 것이라고 결정했기 때문입니다. 트랜스포머 논문이 발표되었습니다. 구글로부터 너무 많은 기여가 나왔습니다. 저는 구글이 그것에 대해 충분한 인정을 받지 못한다고 생각합니다. 왜 구글이 AI를 소유하는 것보다 오픈 소스화하는 것이 구글에게 더 좋을까요? 음, 그래서 저는 그 내기가 성공했는지 말할 수는 없습니다. 하지만 저는 그것이 내기였다고 말할 수 있습니다. 하지만 제 외부자 관점에서 보면, 왜냐하면 저는 5년 이상 구글에 있지 않았으니까요, 시간이 참 빠르네요. 그 내기는 당신이 이것을 당신의 제품에 통합할 수 있는 놀라운 연구원 팀과 Swyx를 가지고 있을 때 의미가 있습니다. 그래서 구글은 수십억 명의 사용자를 가지고 있습니다. 모든 제품 서비스를 가지고 있습니다. 모든 다른 애플리케이션을 가지고 있습니다. 그리고 놀라운 인재 밀도를 가지고 있습니다. 그리고 저는 구글의 최근 발표, 즉 구글 I.O. 직후의 발표 같은 것들이, 네, 우리 둘 다 거기 있었죠. 네, 구글이 실제로 작동하고 있는 것 같습니다. 꽤 인상적입니다. 그리고 한동안 그들은 조직적인 드라마와 구글 브레인 대 딥마인드, 그리고 이런 것들을 다루고 있었습니다. 그리고 저는 그들이 무엇을 했는지 말할 수는 없지만, 그들은 훨씬 더 통합된 팀인 것 같습니다. 그들은 잘 실행하고 있습니다. 그들은 연구를 제품에 반영하고 있습니다. 그래서 저에게는 다른 구글처럼 느껴집니다. 예전에는 구글에 모든 것이 두 개씩 있었고, 어느 것을 사용해야 할지 몰랐습니다. 구글에 의해 죽었죠. 그들은 모두 1년 안에 폐기되었습니다. 네, 제 생각에 그들은 메모를 받은 것 같아요, 뭐든 간에요. 네, 그리고 그들에 대해 저에게 매우 인상적인 또 다른 것은, 이것은 제가 구글을 팬보잉하는 것입니다. 하지만 그들이 발표한 것들은 실제로 출시되고 있었습니다. 네. AI에서는 너무나 많은 것들이 그렇습니다. 이것은 AI에서 매우 흔한 일입니다. 그리고 Modular도 과거에 이런 일을 했습니다. 이것이 바로 이유입니다. 그래서 제가 이 매우 깊은 기술 강연을 했습니다. 제가 GPU 모드 강연 링크를 보내드렸죠. 그리고 슬라이드 2는 경고였습니다. "당신은 실제로 이것을 사용할 수 있습니다. 이것은 베이퍼웨어(vaporware)가 아닙니다. 여기 있는 모든 것은 당신이 재현할 수 있습니다. 이 주장들은 당신이 다운로드할 수 있습니다. 이것은 실제로 진짜입니다. 여기 소스 코드 링크가 있습니다." 왜 그렇게 강조하셨는지 궁금했어요. 알아요. 제 말은, 너무 많은 주장들이 있다는 거죠. 아무도 무엇이 진짜인지 더 이상 모릅니다. 알아요. 그리고 제 말은, 말 그대로 제품 데모가 있었는데, 마치 전기 세미 트럭이 자체 동력으로 작동하는 대신 언덕을 굴러 내려가는 것과 같았죠. 그리고 아무도 무엇이 진짜인지 모릅니다. 저는 그들이 일하기 시작했다는 것을 알았습니다. 왓츠앱 채팅 같은 것이 있습니다. 우리는 주중에 구글 필드에서 축구를 하곤 했습니다. 그리고 약 6개월 전에, 어떤 관리자가 게시물을 올렸습니다. "이봐, 점심시간에 축구하러 오는 사람이 더 이상 충분하지 않아. 무슨 일이야?" 그리고 제 생각에 그때 사람들이 시작했던 것 같습니다. 그게 당신의 구글 지표군요. 다시 일하기 시작했죠. 네. 여기 있습니다. 제 말은, 세르게이 브린이 IO에 있었습니다. 그리고 그는 확실히. 그는 다시 일하는 것 같습니다. 그리고 그것은 굉장합니다. 네. 그래서 저는 그것에 대해 엄청난 존경심을 가지고 있습니다. 그리고 제 가치관은 물건을 출시하는 사람들과 일치합니다. 네. 왜냐하면 그것이 세상을 바꾸는 것이기 때문입니다."

널리 알려지지는 않았지만, Blackwell은 Hopper와 호환되지 않습니다. Hopper 커널이 항상 Blackwell에서 실행되는 것은 아닙니다. 딥시크 팀이 한 일은 정말 인상적인 연구였습니다. 그들은 MLA를 발전시켰고, 저정밀도 훈련을 발전시켰습니다. 그들은 당시 잘 알려지지 않았던 일부 PTX 명령어를 리버스 엔지니어링했습니다. 그들은 세상에 그것이 가능하다는 것을 보여주었고, 그것을 공개하고, 출판하고, 실제로 세상에 그것에 대해 가르쳤습니다. 왜냐하면 저는 그들이 왜 그렇게 하기로 선택했는지 모르지만, 그것은 그들이 개방성과 AI의 발전을 믿기 때문입니다. 세상의 반응이 실제 세계보다 저에게 더 인상 깊었다는 것입니다. 왜냐하면