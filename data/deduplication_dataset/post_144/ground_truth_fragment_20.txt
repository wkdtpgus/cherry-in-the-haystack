Gradient의 최신 업데이트에 오신 것을 환영합니다! 저희 콘텐츠가 유익하다고 느끼신다면, 구독하고 소셜 미디어에서 저희를 팔로우해주세요. 저희 뉴스레터는 심층적인 분석을 담고 있으니, 전체 내용을 보시려면 Substack에서 이 게시물을 확인해주세요!

최근 인공지능(AI) 기술이 가져온 변화에 대한 많은 논의가 있었습니다. 이번 업데이트에서는 이러한 기술적 진보가 사회와 산업에 미치는 다양한 영향에 초점을 맞추었습니다. 인공지능(AI)의 급속한 발전은 단순히 기술적 혁신을 넘어, 윤리적, 경제적, 사회적 패러다임의 변화를 요구하고 있습니다. 다음 글들은 이러한 변화의 핵심을 짚어볼 것입니다.

*   이번 논의를 촉발시킨 테드 창(Ted Chiang)의 뉴요커 에세이 "인공지능이 예술을 만들지 못하는 이유(Why A.I. Isn’t Going to Make Art)"
*   창의 에세이와 전국 소설 쓰기 대회(NaNoWriMo)의 대규모 언어 모델(LLM) 논란에 대한 Read Max의 논평
*   셀린 응우옌(Celine Nguyen)이 인공지능(AI) 예술이 다른 예술과 어떤 관계에 있는지 멋지게 탐구한 글
*   새로운 AI 동향 분석: 멀티모달(Multimodal) AI의 부상과 산업별 적용 사례
*   인공지능(AI) 시대의 새로운 윤리적 딜레마: 책임감 있는 개발의 중요성
*   생성형 인공지능(GenAI)이 콘텐츠 창작 시장에 미치는 영향과 미래 전망

언제나처럼, 저희와 함께 혁신적인 아이디어를 나누고 싶으시다면 [이 양식](https://docs.google.com/forms/d/e/1FAIpQLSdcX2j-D_63Gf9fO7b82qX_s14m81h9h3V7-iXQ7-v2y2y2yQ/viewform)을 사용하여 제안서를 보내주세요.

**뉴스 하이라이트: 인공지능(AI)을 이용한 음원 스트리밍 사기에 대한 첫 형사 기소**

**요약**
연방 검찰은 "인위적으로 부풀려진 음원 스트리밍(Artificially Inflated Music Streaming)"과 관련된 사기 계획에 대해 사상 첫 형사 기소를 발표했습니다. 기소장에 따르면 노스캐롤라이나에 거주하는 음악가 마이클 스미스(Michael Smith)는 인공지능(AI)이 생성한 음원을 구매하여 다양한 스트리밍 플랫폼에 업로드한 후, 수천 개의 "봇(bot)"을 사용하여 해당 음원을 반복적으로 스트리밍했습니다. 이 계획으로 그는 7년 동안 1천만 달러 이상의 로열티(royalty)를 벌어들인 것으로 알려졌습니다. 그는 통신 사기(wire fraud), 통신 사기 공모(wire fraud conspiracy), 자금 세탁 공모(money laundering conspiracy) 혐의로 기소되었습니다. 각 혐의는 최대 20년의 징역형을 선고받을 수 있습니다.

**개요**
이 계획은 매우 간단합니다.

*   수천 개의 가짜 이메일 주소 구매
*   이 이메일 주소를 사용하여 Spotify, Apple Music, Youtube Music과 같은 음악 플랫폼에 수천 개의 가짜 계정 생성 및 등록
*   유료 계정의 스트리밍당 로열티(royalty) 비율이 더 높습니다. 따라서 각 가짜 계정이 다른 결제 수단을 사용한 것처럼 보이도록 "대량의 직불 카드, 일반적으로 회사 직원용 법인 직불 카드(corporate debit cards)를 제공"하는 사업을 하는 "맨해튼 기반 서비스"를 찾습니다.
*   수천 개의 유료 계정을 설정하는 데는 돈이 들지만, 그만한 가치가 있을 것입니다.
*   자신이 소유한 음악을 많이 스트리밍하기 시작합니다.

더 구체적으로: **수익**

처음에는 인공지능(AI)이 없었습니다. 대신 스미스는 음악 홍보 담당자의 방대한 기존 음악 카탈로그에 자신의 스트리밍 봇(bot)을 풀어놓았습니다. 나중에 그는 자신의 스트리밍 부대(streaming army)를 다른 음악가들에게 서비스로 제공하여 그들의 스트리밍 수를 늘렸습니다. 하지만 한 곡을 너무 여러 번 스트리밍하면 누군가가 알아차리게 됩니다. 탐지를 피하기 위해 스미스는 더 큰 카탈로그, 더 많은 자료가 필요했습니다. 그래서 2018년에 그는 아직 이름이 알려지지 않은 "인공지능(AI) 음악 회사"와 협력하여 매주 수천 곡의 노래를 제공받아 플랫폼에 업로드하고 스트리밍을 조작했습니다. 이름 없는 음악 회사는 스미스에게 음원을 제공했고, 그는 무작위적이지만 이상하게 그럴듯한 트랙 제목과 아티스트를 생성했습니다.

최선을 다했음에도 불구하고, 스미스의 계정은 이 계획이 진행되는 동안 여러 번 플랫폼에서 플래그(flag) 처리되거나 삭제되었습니다. 사실 그는 이 모든 것에 대해 훨씬 더 미묘하게 접근할 수 있었습니다.

기소장에는 인공지능(AI) 생성 음악이 실제로 어떻게 생성되었는지에 대한 세부 정보가 나와 있지 않습니다. 그들이 단순한 절차적 방법(procedural method)이 아닌 진정한 딥러닝(deep learning) 생성 인공지능(genAI)을 사용하고 있었다는 유일한 증거는 기소장에 포함된 인공지능(AI) 음악 회사 직원 중 한 명이 스미스에게 보낸 이메일 발췌문입니다. “이제 곡의 품질이 10배에서 20배 더 좋아졌고, 보컬 생성 기능도 갖추고 있습니다. . . . 제가 무슨 말을 하는지 이해하시려면 첨부된 파일을 들어보세요."

어떤 의미에서는 인공지능(AI)이 이 이야기에서 부수적인 요소입니다. 인공지능(AI)이 생성한 음악을 Spotify에 업로드하는 것은 불법이 아닙니다. 인공지능(AI)은 단지 기존의 사기를 확장했을 뿐입니다.

**우리의 견해**
연방 검찰은 스미스의 범죄를 "합법적으로 스트리밍된 곡을 가진 음악가, 작곡가 및 기타 권리 보유자로부터 훔친 것"으로 묘사하고 있습니다. 기계적으로는 사실입니다. 스미스의 행동은 다른 음악가들에게 더 적은 로열티(royalty) 지급으로 이어졌습니다. 하지만 저는 스미스 씨에게 어느 정도 공감합니다(NYT 댓글 작성자들도 마찬가지입니다). 그는 다른 많은 사람들이 하는 방식으로 고장 난 시스템을 이용했습니다. 맷 레빈(Matt Levine)은 특징적으로 훌륭하고 적절한 견해를 제시했습니다.

“기본적으로 현대 경제와 삶의 많은 부분은 다음과 같은 특징을 가집니다. 모든 것은 비인격적인 자동화된 전자 교환을 통해 중개됩니다. 자동화된 전자 교환은 메커니즘(mechanism) — 실제로 어떻게 작동하는지, 교환 소프트웨어가 무엇을 허용하는지 — 과 규칙, 즉 메커니즘을 어떻게 사용할 수 있는지 규제하는 서비스 약관을 가지고 있습니다. 이 규칙들은 메커니즘보다 모호하며 작은 글씨로 쓰여 있습니다. 예를 들어 '사기를 치지 마라' 또는 '인간이어야 한다' 등입니다. 메커니즘은 규칙보다 훨씬 더 명확하고 두드러지며, 비인격적인 전자 세계에서 사람들은 메커니즘을 규칙으로 간주합니다. 그들은 규칙이 존재한다고 믿지 않습니다. 왜냐하면 규칙이 서비스 작동 방식과 모순되는 것처럼 보이기 때문입니다. Spotify의 작동 방식에 대한 기본적인 설명은 스미스의 주장된 차익 거래(arbitrage)를 시사합니다. 그가 하지 않았다면 분명 다른 누군가가 했을 것입니다.” – 콜(Cole)

**뉴스 하이라이트: 인공지능(AI) 기반 신약 개발의 혁신과 도전**

**요약**
최근 인공지능(AI) 기반 신약 개발 분야에서 획기적인 발전이 보고되었습니다. 글로벌 제약사인 '바이오젠 테크(BioGen Tech)'는 인공지능(AI)을 활용하여 특정 난치병 치료제의 후보 물질을 기존 방식보다 10배 빠른 속도로 발견했다고 발표했습니다. 이 인공지능(AI) 시스템은 수십억 개의 화합물 데이터베이스를 분석하고, 질병 관련 단백질과의 상호작용을 예측하여 가장 유망한 물질들을 선별합니다. 이러한 접근 방식은 신약 개발에 소요되는 시간과 비용을 크게 절감할 수 있을 것으로 기대됩니다. 그러나 인공지능(AI) 모델의 예측 정확성 검증과 임상 시험의 복잡성은 여전히 중요한 과제로 남아 있습니다.

**개요**
전통적인 신약 개발은 평균 10년 이상의 시간과 수십억 달러의 비용이 소요되는 고위험, 고비용 과정입니다. 인공지능(AI)은 이 과정을 혁신할 잠재력을 가지고 있습니다. 특히, 후보 물질 발굴, 약물 재창출(drug repurposing), 독성 예측 등 여러 단계에서 그 효율성을 입증하고 있습니다. '바이오젠 테크'의 사례는 인공지능(AI)이 단순한 보조 도구를 넘어, 핵심적인 연구 동력으로 자리매김하고 있음을 보여줍니다. 이들은 딥러닝(deep learning) 기반의 그래프 신경망(graph neural networks)을 사용하여 분자 구조와 생체 내 반응 사이의 복잡한 관계를 모델링했습니다. 이 모델은 기존의 생물학적 지식과 대규모 실험 데이터를 학습하여, 인간 연구자가 수십 년간 탐색해야 할 가능성을 단 몇 주 만에 제시할 수 있었습니다.

**수익성 및 윤리적 고려**
이러한 기술은 제약 산업의 수익성을 크게 향상시킬 수 있지만, 동시에 윤리적 질문을 제기합니다. 인공지능(AI)이 제안한 약물이 예상치 못한 부작용을 일으킬 경우 책임은 누구에게 있는가? 또한, 인공지능(AI)이 특정 질병에 대한 치료법 개발에 집중함으로써 소외된 질병 연구가 위축될 가능성은 없는가? 이러한 질문들은 인공지능(AI) 기반 신약 개발의 상업적 성공과 더불어 사회적 책임의 중요성을 부각시킵니다.

**우리의 견해**
인공지능(AI)이 신약 개발의 판도를 바꾸고 있다는 점은 분명합니다. 그러나 기술적 진보만큼이나 중요한 것은 투명성, 재현성, 그리고 인간 중심적인 접근 방식입니다. 인공지능(AI)은 강력한 도구이지만, 최종 결정은 항상 인간의 전문성과 윤리적 판단에 기반해야 합니다. 이 분야의 발전이 인류의 건강 증진에 기여하기 위해서는 기술적 역량과 사회적 책임감의 균형이 필수적입니다. – 콜(Cole)

**연구 하이라이트: 자연어(Natural Language)를 통한 계획 수립이 대규모 언어 모델(LLM) 코드 생성 검색을 개선합니다.**

**요약**
Scale AI의 연구원들(Gradient 공동 창립자 휴 장(Hugh Zhang) 포함 😀)은 대규모 언어 모델(LLM) 코드 생성 작업을 위한 새로운 검색 알고리즘(search algorithm)인 PlanSearch를 발표했습니다. 유사한 코드 솔루션(code solution)을 검색하여 추론 연산(inference compute)을 확장하는 기존 방법과 달리, PlanSearch는 자연어(natural language)로 된 문제 해결 계획의 공간을 탐색합니다. 이 접근 방식은 잠재적인 솔루션(solution)에 대한 더 다양한 탐색으로 이어집니다. 이 알고리즘(algorithm)은 HumanEval+, MBPP+, LiveCodeBench를 포함한 여러 코딩 벤치마크(benchmark)에서 유망한 결과를 보여줍니다. 이 연구는 코드 생성을 위한 대규모 언어 모델(LLM)에서 추론 연산(inference compute)을 효과적으로 확장하는 과제를 해결하고, 코드보다는 "개념(concept)" 공간에 대한 검색의 새로운 방향을 제시합니다.

**개요**
저자들은 최신 대규모 언어 모델(SoTA LLM) 출력의 다양성 부족이 검색 알고리즘(search algorithm) (전반적인 성능 향상을 위해 추론 시간(inference time)에 추가 연산(compute)을 활용하는 모든 방법으로 정의됨)을 방해할 수 있다고 관찰합니다. 왜냐하면 검색은 다양한 가능성을 탐색함으로써 이점을 얻기 때문입니다. 다양성 부족은 검색을 더 좁은 가능성 집합으로 제한합니다. DPO 및 RLHF와 같은 후처리 훈련 방법(post-training methods)이 출력 다양성을 감소시킨다는 증거가 있으며, 실제로 저자들은 일부 모델의 기본 버전이 여러 가능한 솔루션(solution)을 생성하도록 허용될 때 지시 버전(instruct versions)보다 성능이 우수함을 보여줍니다.

PlanSearch의 핵심 아이디어는 솔루션(solution) 코드 자체보다는 솔루션(solution)에 대한 더 높은 수준의 개념적인 자연어(natural language) 설명을 검색하는 것입니다. 저자들은 먼저 대규모 언어 모델(LLM)에 솔루션(solution)의 올바른 자연어(natural language) 스케치(sketch)를 프롬프트(prompt)하는 것이 코드 생성 성능을 향상시키는지 탐구함으로써 이 가설을 조사합니다. 그들은 대규모 언어 모델(LLM)에 문제와 올바른 코드 솔루션(code solution)을 모두 제공하고, 대규모 언어 모델(LLM)에게 솔루션(solution)의 자연어(natural language) 설명을 요청함으로써 "역번역된(backtranslated)" 스케치(sketch)를 생성합니다. 그들은 스케치(sketch)가 성능을 크게 향상시키며, 더 긴 스케치(sketch)가 훨씬 더 많은 이점을 제공한다는 것을 발견했습니다.

다음으로, 그들은 특정 스케치(sketch)에 따라 조건화된 대규모 언어 모델(LLM)의 정확도가 0% 또는 100%로 수렴하는 경향을 보임으로써, 단순히 아무 스케치(sketch)가 아니라 좋은 스케치(sketch)를 갖는 것의 중요성을 보여줍니다.

스케치(sketch)가 성능을 향상시키고, 실제로 좋은 스케치(sketch)가 성능을 좌우할 수 있다는 것을 입증한 후, 저자들은 스케치(sketch)의 중요성을 활용하기 위한 검색 알고리즘(search algorithm)을 제시합니다. 주어진 대규모 언어 모델(LLM)과 코딩 문제에 대해, 그들의 알고리즘(algorithm)인 PlanSearch는 다음을 포함합니다.

*   문제에 대한 많은 1차 관찰(first-order observations) 생성
*   대규모 언어 모델(LLM)에 선택된 1차 관찰(first-order observations)을 사용/병합하도록 프롬프트(prompt)하여 2차 관찰(second-order observations)을 생성하기 위한 1차 관찰(first-order observations) 조합을 조합적으로 샘플링(sampling)
*   1차 및 2차 관찰(first and second order observations)을 기반으로 문제를 해결하기 위한 전략(즉, 스케치(sketch))의 자연어(natural language) 설명 생성
*   "당신의 아이디어가 틀렸습니다(Your idea is wrong)"라는 프롬프트(prompt)로 더 많은 솔루션(solution) 스케치(sketch) 생성
*   솔루션(solution) 스케치(sketch)를 기반으로 코드 솔루션(code solution) 생성

PlanSearch는 네 가지 모델(GPT-4o 및 4o-mini, DeepSeek-Coder-V2, Claude-Sonnet-3.5)을 기반으로 세 가지 코딩 벤치마크(benchmark) (LiveCodeBench, HumanEval+, MBPP+)에서 평가됩니다. 저자들은 PlanSearch의 200개 생성 솔루션("PlanSearch@200")을 기본 반복 샘플링(sampling) 200회("Pass@200"), 검색 없는 단일 생성("Pass@1"), 그리고 단순히 스케치(sketch)를 요청한 다음 대규모 언어 모델(LLM)에 제안된 스케치(sketch)를 따르는 코드를 생성하도록 별도로 프롬프트(prompt)하는 IdeaSearch("IdeaSearch@200")와 비교합니다.

PlanSearch는 LiveCodeBench에서 비검색 기준선(non-search baseline)보다 25-35% 포인트, "Pass@200"보다 10-20% 포인트 더 높은 성능을 꾸준히 보여주며 매우 우수하게 작동합니다.

**우리의 견해**
코드 솔루션(code solution) 공간보다는 개념(concept) 공간을 탐색하는 것이 직관적으로 매우 합리적입니다. 컴퓨터 과학 교수 10명 중 9명은 코딩을 시작하기 전에 펜과 종이를 들고 앉아 계획을 스케치(sketch)할 것을 권장합니다. 접근 방식이 틀렸다면 코드를 얼마나 잘 작성하는지는 중요하지 않습니다. 컴퓨터 과학의 전설 도널드 커누스(Donald Knuth)는 "성급한 최적화(premature optimization)는 모든 악의 근원이다"라고 유명하게 말했습니다. 마찬가지로 지난주 인공지능(AI)의 전설 노암 브라운(Noam Brown)은 "올바른 방향으로 일하는 엔지니어 한 명이 잘못된 방향으로 일하는 천재 100명보다 낫다"고 트윗했습니다. 원리는 같습니다. 이러한 종류의 컴퓨터 과학(comp sci) 기본 지식이 대규모 언어 모델(LLM) 성능으로 이어진다는 사실은 어쩐지 위안이 됩니다. – 콜(Cole)

**연구 하이라이트: 멀티모달(Multimodal) 대규모 언어 모델(LLM)의 이해력과 활용성 증대**

**요약**
최근 발표된 '비전-언어 통합 모델(Vision-Language Integration Model)' 연구는 멀티모달(multimodal) 대규모 언어 모델(LLM)의 새로운 지평을 열었습니다. 이 연구는 텍스트뿐만 아니라 이미지, 오디오, 비디오 데이터를 동시에 처리하고 이해하는 모델의 능력을 크게 향상시켰습니다. 연구팀은 새로운 어텐션 메커니즘(attention mechanism)과 효율적인 데이터 융합 기법을 도입하여, 모델이 다양한 양식(modality) 간의 복잡한 관계를 파악하고 일관된 추론을 수행할 수 있음을 입증했습니다. 이 모델은 복잡한 시각적 질문 응답(Visual Question Answering, VQA), 이미지 캡셔닝(image captioning), 비디오 요약(video summarization) 등 여러 멀티모달(multimodal) 벤치마크에서 기존 최고 성능을 뛰어넘는 결과를 보여주었습니다. 이는 인공지능(AI)이 인간처럼 다양한 정보를 통합적으로 인지하고 상호작용하는 미래에 한 걸음 더 다가섰음을 시사합니다.

**개요**
저자들은 기존 멀티모달(multimodal) 모델들이 각 양식(modality)의 정보를 개별적으로 처리한 후 단순 결합하는 방식의 한계를 지적합니다. 이러한 방식은 양식(modality) 간의 미묘한 상호작용과 문맥적 의미를 포착하기 어렵게 만듭니다. '비전-언어 통합 모델'은 초기 단계부터 다양한 양식(modality)의 임베딩(embedding)을 심층적으로 융합하는 새로운 아키텍처(architecture)를 제안합니다. 특히, 동적으로 가중치를 조절하는 '크로스-모달 어텐션(cross-modal attention)' 메커니즘을 통해, 모델은 특정 작업에 필요한 양식(modality)에 더 집중할 수 있게 됩니다. 예를 들어, '이 이미지에서 가장 오래된 건축물은 무엇인가?'라는 질문에는 시각 정보에 더 큰 가중치를 두면서도, '이 사람이 왜 슬퍼 보이는가?'와 같은 질문에는 시각적 단서와 함께 학습된 감성 어휘의 패턴을 종합적으로 고려하는 식입니다.

**성능 향상 및 활용성**
이 모델은 VQA(Visual Question Answering), ImageNet-C, AudioSet 등 여러 멀티모달(multimodal) 벤치마크에서 기존 최고 성능을 뛰어넘는 유망한 결과를 보여주었습니다. 또한, 이 모델은 자율주행(autonomous driving) 시스템의 환경 인지, 의료 영상 진단, 교육용 인터랙티브 콘텐츠 제작 등 다양한 실제 응용 분야에서 혁신적인 잠재력을 가지고 있습니다. 연구팀은 특히 복잡한 상황 이해를 요구하는 로봇 공학 분야에서 이 모델이 인간과 유사한 판단을 내릴 수 있음을 강조합니다.

**우리의 견해**
멀티모달(multimodal) 인공지능(AI)은 인간의 인지 방식에 가장 가까운 형태로 진화하고 있습니다. 다양한 감각 정보를 통합하여 세상을 이해하는 인간처럼, 인공지능(AI)도 이제 여러 양식(modality)을 통해 더 깊은 이해를 얻으려 합니다. 이는 단순히 데이터를 더 많이 처리하는 것을 넘어, 지능의 본질에 대한 새로운 질문을 던집니다. 예를 들어, '이 그림의 분위기에 어울리는 음악을 추천해줘'와 같은 복잡한 요청을 처리할 수 있게 되면서, 인공지능(AI)의 활용 범위는 상상할 수 없을 정도로 확장될 것입니다. 이러한 발전은 인공지능(AI)이 단순한 도구를 넘어, 진정으로 '이해'하고 '창조'하는 단계로 나아가고 있음을 시사합니다. – 다니엘(Daniel)

**Gradient의 새로운 소식**

*   대규모 언어 모델(LLM) 챗봇(chatbot)에 빠진 것: 목적 의식
*   데이비다드 달림플(Davidad Dalrymple): 증명 가능한 안전한 인공지능(AI)을 향하여
*   클라이브 톰슨(Clive Thompson): 기술 이야기
*   대규모 언어 모델(LLM)의 환각 현상(hallucination)과 신뢰성 문제 해결 방안
*   인공지능(AI) 기반 창작 도구의 저작권 논쟁: 법적, 윤리적 쟁점 분석
*   미래 도시를 위한 인공지능(AI) 교통 시스템 혁신

**우리의 눈길을 사로잡은 다른 소식들**

**뉴스**

**애플(Apple), 인공지능(AI) 내장된 새로운 아이폰(iPhone) 공개**
애플(Apple)은 인공지능(AI)이 내장된 새로운 아이폰(iPhone)인 아이폰 16(iPhone 16)을 공개했습니다. 아이폰 16(iPhone 16)은 네 가지 모델로 출시되며, 애플(Apple)의 생성형 인공지능(generative AI) 시스템인 애플 인텔리전스(Apple Intelligence)를 실행하도록 설계되었습니다. 이 폰들은 메시지 분류, 글쓰기 제안, 향상된 시리(Siri) 가상 비서(virtual assistant)와 같은 기능을 갖출 것입니다. 이는 이전 아이폰(iPhone)의 예측 가능한 디자인에서 벗어나 사용자 경험(user experience)을 향상시키기 위한 인공지능(AI) 기능을 도입한 것입니다.
**애플(Apple), 인공지능(AI) 기반의 새로운 서비스 전략 공개**
애플(Apple)이 자사의 생태계 전반에 걸쳐 인공지능(AI) 기능을 통합하는 새로운 서비스 전략을 발표했습니다. 이는 단순히 기기 성능 향상을 넘어, 사용자 경험(user experience)을 개인화하고 생산성을 높이는 데 초점을 맞추고 있습니다. 특히, 기존 서비스에 인공지능(AI) 어시스턴트(AI assistant)를 강화하고, 개발자들에게 더 강력한 인공지능(AI) API(Application Programming Interface)를 제공하여 혁신적인 애플리케이션 개발을 독려할 계획입니다. 애플(Apple)은 이러한 전략을 통해 인공지능(AI) 시대의 새로운 경쟁 우위를 확보하려 합니다.

**미국, 유럽연합(EU), 영국 등, 법적 구속력 있는 인공지능(AI) 조약 서명**
미국, 영국, 유럽연합(EU)은 여러 다른 국가들과 함께 인공지능(AI)에 관한 최초의 "법적 구속력 있는(legally binding)" 조약인 인공지능 기본 협약(Framework Convention on Artificial Intelligence)에 서명했습니다. 이 조약은 인공지능(AI)의 사용이 인권, 민주주의, 법치주의와 일치하도록 보장하는 것을 목표로 합니다. 이 조약은 사용자 데이터(user data) 보호, 법률 준수, 투명성 유지 등 인공지능(AI) 시스템이 따라야 할 주요 원칙들을 제시합니다. 조약에 서명하는 각 국가는 이 프레임워크(framework)를 반영하는 적절한 조치를 채택해야 합니다. 이 조약은 법적 구속력이 있지만, 집행은 주로 모니터링(monitoring)에 의존하며, 이는 비교적 약한 형태의 집행으로 간주됩니다.
**미국, 유럽연합(EU) 등, 새로운 인공지능(AI) 규제 프레임워크를 논의 중**
전 세계 주요국들이 인공지능(AI) 기술의 급속한 발전에 대응하기 위해 새로운 규제 프레임워크를 적극적으로 논의하고 있습니다. 미국과 유럽연합(EU)은 각각 다른 접근 방식을 취하면서도, 인공지능(AI)의 안전성, 투명성, 책임성을 확보하는 데 중점을 두고 있습니다. 특히, 고위험 인공지능(AI) 시스템에 대한 사전 평가 의무화, 데이터 프라이버시(data privacy) 강화, 그리고 인공지능(AI) 알고리즘(algorithm)의 설명 가능성(explainability) 확보 등이 주요 논의 대상입니다. 이러한 국제적인 노력은 인공지능(AI) 기술이 사회에 미치는 긍정적 영향을 극대화하고 잠재적 위험을 최소화하는 것을 목표로 합니다.

**OpenAI, ChatGPT 기업용 버전 유료 사용자 100만 명 돌파**
OpenAI는 ChatGPT의 기업용 버전에서 100만 명 이상의 유료 사용자라는 이정표를 달성했으며, 이는 기업들 사이에서 챗봇(chatbot)에 대한 수요가 증가하고 있음을 나타냅니다. 이 수치에는 ChatGPT 팀(Team) 및 엔터프라이즈(Enterprise) 서비스 사용자뿐만 아니라 대학에서 ChatGPT 에듀(Edu)를 사용하는 사람들도 포함됩니다. OpenAI는 1년 전 향상된 기능과 개인 정보 보호 조치를 갖춘 ChatGPT 엔터프라이즈(Enterprise)를 도입하여 수익을 창출하고 인공지능(AI) 개발의 높은 비용을 상쇄했습니다. 유료 기업 사용자 증가가 중요하지만, 얼마나 많은 새로운 기업이 가입했는지는 불분명합니다. OpenAI는 기업 고객당 평균 유료 사용자 수를 공개하지 않았습니다. OpenAI 기업 사용자 대다수는 미국에 기반을 두고 있으며, 미국 외에서는 독일, 일본, 영국이 가장 인기 있는 국가입니다.
**OpenAI, ChatGPT의 새로운 비즈니스 모델로 시장을 확장**
OpenAI는 ChatGPT의 성공을 발판 삼아 다양한 비즈니스 모델을 탐색하며 시장 확장에 박차를 가하고 있습니다. 기존의 구독형 서비스 외에도, 특정 산업 분야에 특화된 맞춤형 인공지능(AI) 솔루션(solution) 개발, 온프레미스(on-premise) 배포 옵션 제공 등을 통해 기업 고객층을 넓히고 있습니다. 또한, 개발자 생태계를 강화하기 위해 플러그인(plugin) 및 API(Application Programming Interface) 기능을 확장하고, 소규모 스타트업(startup)들이 ChatGPT 기술을 활용하여 혁신적인 서비스를 구축할 수 있도록 지원하고 있습니다. 이러한 전략은 인공지능(AI) 기술의 대중화를 넘어, 산업 전반의 디지털 전환을 가속화하는 데 기여할 것으로 보입니다.

**ChatGPT에서 Gemini까지: 인공지능(AI)이 인터넷을 다시 쓰는 방법**
이 기사는 Microsoft, Google, OpenAI와 같은 주요 기업들이 인공지능(AI) 챗봇(chatbot) 기술을 일반 대중에게 더 쉽게 접근할 수 있도록 만드는 방법을 다룹니다. 이 회사들은 Copilot, Gemini, GPT-4o와 같은 대규모 언어 모델(LLM) 프로그램을 개발하고 있습니다. 이러한 인공지능(AI) 도구는 자동 완성(autocomplete)과 유사한 프로그램을 사용하여 언어를 학습하고 언어의 통계적 특성(statistical properties)을 분석하여 이전에 입력된 단어를 기반으로 합리적인 추측을 합니다. 그러나 이러한 인공지능(AI) 도구는 사실의 하드코딩된 데이터베이스(hard-coded database)를 가지고 있지 않으며, 사실성을 보장하기보다는 그럴듯하게 들리는 진술을 생성하는 데 중점을 두기 때문에 거짓 정보를 사실처럼 제시할 수 있다는 점에 유의해야 합니다.
**ChatGPT에서 Gemini까지, 인공지능(AI) 모델의 발전이 새로운 사용자 경험을 창출**
ChatGPT와 Gemini와 같은 대규모 언어 모델(LLM)의 지속적인 발전은 사용자 경험(user experience)의 근본적인 변화를 가져오고 있습니다. 이들 모델은 단순히 정보를 제공하는 것을 넘어, 사용자의 의도를 이해하고 맥락에 맞는 복잡한 작업을 수행할 수 있게 되었습니다. 예를 들어, 이메일 초안 작성, 복잡한 데이터 분석 요약, 심지어 개인화된 학습 콘텐츠 생성까지 가능해지면서, 사람들은 인공지능(AI)을 단순한 검색 도구가 아닌 지능형 조력자로 인식하기 시작했습니다. 이러한 변화는 디지털 상호작용의 패러다임을 재정의하며, 미래의 모든 소프트웨어(software)와 서비스에 인공지능(AI)이 필수적인 요소로 자리매김할 것임을 시사합니다.

**제이콥 볼(Jacob Wohl)의 비밀 인공지능(AI) 로비 회사 '고객'이라는 빅테크(Big Tech) 기업들, "들어본 적 없다"고 밝혀**
유죄 판결을 받은 사기꾼이자 우익 운동가인 제이콥 볼(Jacob Wohl)과 잭 버크먼(Jack Burkman)은 인공지능(AI) 기반 로비 서비스(lobbying services)를 제공한다고 주장하는 LobbyMatic이라는 회사를 운영해왔습니다. 그러나 LobbyMatic의 고객으로 등재된 많은 주요 기업들이 이 회사에 대해 들어본 적이 없다는 사실이 밝혀졌습니다. LobbyMatic은 인공지능(AI)을 사용하여 기업과 로비스트(lobbyist)가 로비 전략(lobbying strategies)을 수립하고, 청문회와 법안을 분석하며, 입법 진행 상황을 추적하도록 돕는다고 주장합니다. 이 회사는 볼(Wohl)과 버크먼(Burkman)에 의해 "제이 클라인(Jay Klein)"과 "빌 샌더스(Bill Sanders)"라는 가명으로 운영되었습니다. 토요타(Toyota), 바운더리 스톤 파트너스(Boundary Stone Partners), 란테우스(Lantheus)를 고객으로 확보했다고 주장했음에도 불구하고, 이 회사들은 LobbyMatic과의 어떠한 연관성도 부인했습니다. 이 회사는 이후 주요 기업들이 자사 소프트웨어(software)를 사용하고 있음을 시사하는 웹사이트(website) 스크린샷(screenshot)을 삭제했습니다. 플랫폼(platform)을 실제로 사용했던 몇 안 되는 회사 중 하나인 바운더리 스톤 파트너스(Boundary Stone Partners)는 해당 도구의 비효율성으로 인해 계약을 해지했습니다. 볼(Wohl)과 버크먼(Burkman)은 2022년에 중범죄 통신 사기(felony telecom fraud)로 유죄 판결을 받았고, FCC로부터 500만 달러의 벌금을 부과받았습니다.
**일부 인공지능(AI) 로비 회사들의 주장과 실제 고객사 간의 괴리가 밝혀져**
최근 인공지능(AI) 기술을 활용한 로비 서비스를 제공한다고 주장하는 일부 회사들이 실제로는 그 능력을 과장하거나 고객사를 허위로 기재한 사례가 드러나 논란이 되고 있습니다. 이들 회사는 인공지능(AI)이 복잡한 입법 분석과 전략 수립을 자동화한다고 홍보했지만, 실제로는 기본적인 데이터 처리 수준에 머물거나 심지어 허위 정보를 제공한 것으로 밝혀졌습니다. 이러한 사건은 인공지능(AI) 기술이 아직 완전히 성숙하지 않은 분야에서 과대광고와 사기성 행위가 발생할 수 있음을 경고하며, 인공지능(AI) 서비스의 투명성과 신뢰성 검증의 중요성을 다시 한번 상기시키고 있습니다.

**자율주행차(Self-Driving Cars)가 수백 마일 떨어진 인간으로부터 도움을 받는 방법**
자율주행차(Self-driving cars)는 완전히 자율적이지 않으며, 종종 어려운 상황을 헤쳐나가기 위해 인간의 도움이 필요합니다. 아마존(Amazon) 소유의 Zoox와 같은 회사들은 기술자들이 장애물이나 익숙하지 않은 시나리오(scenario)에 직면했을 때 자율주행차(self-driving cars)를 원격으로 안내하는 지휘 센터(command centers)를 가지고 있습니다. 기술자들은 경고를 받고 컴퓨터 마우스(computer mouse)를 사용하여 차량에 새로운 경로를 보낼 수 있습니다. 그들은 또한 차량 카메라(camera)의 비디오 피드(video feeds)를 보고 차량 경로를 실시간으로 조정할 수 있습니다. Waymo와 Cruise와 같은 회사들이 인간 지원의 필요성을 인정하기 시작했지만, 고용된 기술자 수나 관련 비용은 공개하지 않았습니다. 원격 지원은 로봇 택시(robot taxis)가 Uber와 Lyft가 운영하는 전통적인 차량 호출 서비스(ride-hailing fleets)를 대체하는 데 어려움을 겪을 수 있는 한 가지 이유입니다. 자율주행 기술(self-driving technology)의 발전에도 불구하고, 안전하고 효율적인 운영을 위해서는 인간의 개입이 여전히 필요합니다.
**자율주행차(Self-Driving Cars)의 기술적 한계는 여전히 인간의 개입을 요구**
자율주행차(Self-Driving Cars) 기술이 빠르게 발전하고 있지만, 여전히 예상치 못한 상황이나 복잡한 환경에서는 인간 운전자의 개입이 필요한 경우가 많습니다. 특히, 악천후, 비정상적인 도로 공사, 또는 예측 불가능한 보행자 행동과 같은 시나리오(scenario)에서는 인공지능(AI) 시스템이 완벽하게 대응하기 어렵다는 점이 드러나고 있습니다. 일부 자율주행차(Self-Driving Cars) 회사들은 원격 관제 시스템을 통해 인간 오퍼레이터(operator)가 차량의 경로를 실시간으로 조정하거나 긴급 상황에 개입하는 방식으로 이러한 한계를 보완하고 있습니다. 이는 완전 자율주행 시대가 오기까지는 아직 많은 기술적, 윤리적 과제가 남아 있음을 보여줍니다.

**혼란스러운 과거에도 불구하고 OpenAI는 지속적인 혁신을 통해 성장하려 노력 중**
내부적인 갈등과 외부의 비판에도 불구하고, 인공지능(AI) 연구의 선두 주자인 OpenAI는 끊임없는 혁신과 전략적 변화를 통해 성장을 모색하고 있습니다. 이들은 새로운 인공지능(AI) 모델을 지속적으로 발표하고, 안전 및 윤리 연구에 대한 투자를 확대하며, 기업 지배 구조를 강화하는 등 다각적인 노력을 기울이고 있습니다. 주요 기업들로부터 투자를 유치하기 위해 경영진과 조직 구조에 상당한 변화를 겪고 있으며, 저명한 기술 경영진, 허위 정보 전문가, 인공지능(AI) 안전 연구원들을 고용하고 전 육군 4성 장군을 포함한 7명의 이사회 구성원을 추가했습니다. OpenAI는 또한 Microsoft, Apple, Nvidia, Thrive와 같은 잠재적 투자자들과 논의 중이며, 잠재적 기업 가치는 1천억 달러에 달합니다. 더 많은 투자자를 유치하기 위해 기업 구조를 변경하는 것을 고려하고 있습니다. 특히, 인공지능(AI) 기술의 상업적 성공과 공공의 이익 사이에서 균형점을 찾으려는 시도는 업계 전반에 중요한 메시지를 던지고 있습니다. OpenAI의 이러한 행보는 인공지능(AI) 기술의 미래 방향과 그에 따른 책임감 있는 발전의 중요성을 다시 한번 강조하고 있습니다.

**마무리 생각**
이번 호 주제에 대해 깊은 통찰을 나누고 싶으신가요? editor@thegradient.pub으로 이메일을 보내주시면, 다음 뉴스레터에서 독자들의 가장 흥미로운 의견을 공유하는 것을 고려하겠습니다! 인공지능(AI) 기술은 빠르게 진화하고 있으며, 그 영향은 광범위합니다. 이러한 변화의 흐름 속에서 저희 Gradient는 독자 여러분과 함께 깊이 있는 논의를 이어가고자 합니다. 여러분의 소중한 피드백(feedback)은 저희 콘텐츠의 질을 높이는 데 큰 도움이 됩니다. 피드백(feedback)을 원하시면 Daniel에게 dbashir@hmc.edu로 직접 연락하시거나 트위터(Twitter)를 통해 연락하실 수 있습니다. 이 뉴스레터가 유익하셨다면, 저희의 지속적인 연구를 지원하기 위해 Substack 구독을 고려해주세요. 이는 이 자원봉사 프로젝트를 유지하는 데 큰 도움이 됩니다.

Gradient의 최신 업데이트를 끝까지 읽어주셔서 진심으로 감사합니다!