Gradient의 88번째 업데이트에 오신 것을 환영합니다! 새로 오셨고 저희 콘텐츠가 마음에 드신다면, 주저하지 마시고 구독하고 트위터에서 저희를 팔로우해주세요. 저희 뉴스레터는 내용이 길기 때문에, 모든 내용을 온전히 보시려면 Substack에서 이 게시물을 확인하셔야 합니다!

최근 인공지능(AI)이 만들어낸 예술이 과연 진정한 예술로 인정받을 수 있는지에 대한 많은 논의가 있었습니다. 이번 업데이트에서 이 복잡한 질문에 대한 최종적인 답을 내릴 용기나 전문 지식은 없었지만, 여전히 깊이 읽어볼 가치가 있는 글들은 다음과 같습니다. 이러한 논의는 여전히 현재 진행형이며, 기술 발전과 함께 그 의미가 더욱 심화되고 있습니다.

*   이번 논의를 촉발시킨 테드 창(Ted Chiang)의 뉴요커 에세이 "인공지능이 예술을 만들지 못하는 이유(Why A.I. Isn’t Going to Make Art)"
*   창의 에세이와 전국 소설 쓰기 대회(NaNoWriMo)의 대규모 언어 모델(LLM) 논란에 대한 Read Max의 논평
*   셀린 응우옌(Celine Nguyen)이 인공지능(AI) 예술이 다른 예술과 어떤 관계에 있는지 멋지게 탐구한 글

언제나처럼, 저희와 함께 글을 쓰고 싶으시다면 [이 양식](https://docs.google.com/forms/d/e/1FAIpQLSdcX2j-D_63Gf9fO7b82qX_s14m81h9h3V7-iXQ7-v2y2y2yQ/viewform)을 사용하여 제안서를 보내주세요.

**뉴스 하이라이트: 인공지능(AI)을 이용한 음원 스트리밍 사기에 대한 첫 형사 기소**

**요약**
연방 검찰은 "인위적으로 부풀려진 음원 스트리밍(Artificially Inflated Music Streaming)"과 관련된 사기 계획에 대해 사상 첫 형사 기소를 발표했습니다. 기소장에 따르면 노스캐롤라이나에 거주하는 음악가 마이클 스미스(Michael Smith)는 인공지능(AI)이 생성한 음원을 구매하여 다양한 스트리밍 플랫폼에 업로드한 후, 수천 개의 "봇(bot)"을 사용하여 해당 음원을 반복적으로 스트리밍했습니다. 이 기소는 디지털 음악 생태계에서 AI 기술의 오용 가능성을 보여주는 중요한 사례로 기록되었습니다. 이 계획으로 그는 7년 동안 1천만 달러 이상의 로열티(royalty)를 벌어들인 것으로 알려졌습니다. 그는 통신 사기(wire fraud), 통신 사기 공모(wire fraud conspiracy), 자금 세탁 공모(money laundering conspiracy) 혐의로 기소되었습니다. 각 혐의는 최대 20년의 징역형을 선고받을 수 있습니다.

**개요**
이 사기 계획은 놀랍도록 간단했습니다.

*   수천 개의 가짜 이메일 주소 구매
*   이 이메일 주소를 사용하여 Spotify, Apple Music, Youtube Music과 같은 음악 플랫폼에 수천 개의 가짜 계정 생성 및 등록
*   유료 계정의 스트리밍당 로열티(royalty) 비율이 더 높습니다. 따라서 각 가짜 계정이 다른 결제 수단을 사용한 것처럼 보이도록 "대량의 직불 카드, 일반적으로 회사 직원용 법인 직불 카드(corporate debit cards)를 제공"하는 사업을 하는 "맨해튼 기반 서비스"를 찾습니다.
*   수천 개의 유료 계정을 설정하는 데는 돈이 들지만, 그만한 가치가 있을 것이라고 판단했습니다.
*   자신이 소유한 음악을 많이 스트리밍하기 시작합니다.

더 구체적으로: **수익 창출 방식**

처음에는 인공지능(AI)이 없었습니다. 대신 스미스는 음악 홍보 담당자의 방대한 기존 음악 카탈로그에 자신의 스트리밍 봇(bot)을 풀어놓았습니다. 나중에 그는 자신의 스트리밍 부대(streaming army)를 다른 음악가들에게 서비스로 제공하여 그들의 스트리밍 수를 늘렸습니다. 하지만 한 곡을 너무 여러 번 스트리밍하면 누군가가 알아차리게 됩니다. 탐지를 피하기 위해 스미스는 더 큰 카탈로그, 더 많은 자료가 필요했습니다. 그래서 2018년에 그는 아직 이름이 알려지지 않은 "인공지능(AI) 음악 회사"와 협력하여 매주 수천 곡의 노래를 제공받아 플랫폼에 업로드하고 스트리밍을 조작했습니다. 이름 없는 음악 회사는 스미스에게 음원을 제공했고, 그는 무작위적이지만 이상하게 그럴듯한 트랙 제목과 아티스트를 생성했습니다.

최선을 다했음에도 불구하고, 스미스의 계정은 이 계획이 진행되는 동안 여러 번 플랫폼에서 플래그(flag) 처리되거나 삭제되었습니다. 사실 그는 이 모든 것에 대해 훨씬 더 미묘하게 접근할 수 있었습니다.

기소장에는 인공지능(AI) 생성 음악이 실제로 어떻게 생성되었는지에 대한 세부 정보가 나와 있지 않습니다. 그들이 단순한 절차적 방법(procedural method)이 아닌 진정한 딥러닝(deep learning) 생성 인공지능(genAI)을 사용하고 있었다는 유일한 증거는 기소장에 포함된 인공지능(AI) 음악 회사 직원 중 한 명이 스미스에게 보낸 이메일 발췌문입니다. “이제 곡의 품질이 10배에서 20배 더 좋아졌고, 보컬 생성 기능도 갖추고 있습니다. . . . 제가 무슨 말을 하는지 이해하시려면 첨부된 파일을 들어보세요."

어떤 의미에서는 인공지능(AI)이 이 이야기에서 부수적인 요소입니다. 인공지능(AI)이 생성한 음악을 Spotify에 업로드하는 것은 불법이 아닙니다. 인공지능(AI)은 단지 기존의 사기를 확장했을 뿐입니다. 이 사건은 AI가 기존 범죄 수법을 더욱 정교하고 대규모로 만들 수 있음을 보여주는 중요한 경고가 되었습니다.

**우리의 견해**
연방 검찰은 스미스의 범죄를 "합법적으로 스트리밍된 곡을 가진 음악가, 작곡가 및 기타 권리 보유자로부터 훔친 것"으로 묘사하고 있습니다. 기계적으로는 사실입니다. 스미스의 행동은 다른 음악가들에게 더 적은 로열티(royalty) 지급으로 이어졌습니다. 하지만 저는 스미스 씨에게 어느 정도 공감합니다(NYT 댓글 작성자들도 마찬가지입니다). 그는 다른 많은 사람들이 하는 방식으로 고장 난 시스템을 이용했습니다. 맷 레빈(Matt Levine)은 특징적으로 훌륭하고 적절한 견해를 제시했습니다.

“기본적으로 현대 경제와 삶의 많은 부분은 다음과 같은 특징을 가집니다. 모든 것은 비인격적인 자동화된 전자 교환을 통해 중개됩니다. 자동화된 전자 교환은 메커니즘(mechanism) — 실제로 어떻게 작동하는지, 교환 소프트웨어가 무엇을 허용하는지 — 과 규칙, 즉 메커니즘을 어떻게 사용할 수 있는지 규제하는 서비스 약관을 가지고 있습니다. 이 규칙들은 메커니즘보다 모호하며 작은 글씨로 쓰여 있습니다. 예를 들어 '사기를 치지 마라' 또는 '인간이어야 한다' 등입니다. 메커니즘은 규칙보다 훨씬 더 명확하고 두드러지며, 비인격적인 전자 세계에서 사람들은 메커니즘을 규칙으로 간주합니다. 그들은 규칙이 존재한다고 믿지 않습니다. 왜냐하면 규칙이 서비스 작동 방식과 모순되는 것처럼 보이기 때문입니다. Spotify의 작동 방식에 대한 기본적인 설명은 스미스의 주장된 차익 거래(arbitrage)를 시사합니다. 그가 하지 않았다면 분명 다른 누군가가 했을 것입니다.” – 콜(Cole)

**연구 하이라이트: 자연어(Natural Language)를 통한 계획 수립이 대규모 언어 모델(LLM) 코드 생성 검색을 개선합니다.**

**요약**
Scale AI의 연구원들(Gradient 공동 창립자 휴 장(Hugh Zhang) 포함 😀)은 대규모 언어 모델(LLM) 코드 생성 작업을 위한 새로운 검색 알고리즘(search algorithm)인 PlanSearch를 발표했습니다. 유사한 코드 솔루션(code solution)을 검색하여 추론 연산(inference compute)을 확장하는 기존 방법과 달리, PlanSearch는 자연어(natural language)로 된 문제 해결 계획의 공간을 탐색합니다. 이 접근 방식은 잠재적인 솔루션(solution)에 대한 더 다양하고 심층적인 탐색으로 이어집니다. 이 알고리즘(algorithm)은 HumanEval+, MBPP+, LiveCodeBench를 포함한 여러 코딩 벤치마크(benchmark)에서 유망한 결과를 보여주며, 코드 생성의 효율성을 크게 향상시킬 잠재력을 입증했습니다. 이 연구는 코드 생성을 위한 대규모 언어 모델(LLM)에서 추론 연산(inference compute)을 효과적으로 확장하는 과제를 해결하고, 코드보다는 "개념(concept)" 공간에 대한 검색의 새로운 방향을 제시합니다.

**개요**
저자들은 최신 대규모 언어 모델(SoTA LLM) 출력의 다양성 부족이 검색 알고리즘(search algorithm) (전반적인 성능 향상을 위해 추론 시간(inference time)에 추가 연산(compute)을 활용하는 모든 방법으로 정의됨)을 방해할 수 있다고 관찰합니다. 왜냐하면 검색은 다양한 가능성을 탐색함으로써 이점을 얻기 때문입니다. 다양성 부족은 검색을 더 좁은 가능성 집합으로 제한합니다. DPO 및 RLHF와 같은 후처리 훈련 방법(post-training methods)이 출력 다양성을 감소시킨다는 증거가 있으며, 실제로 저자들은 일부 모델의 기본 버전이 여러 가능한 솔루션(solution)을 생성하도록 허용될 때 지시 버전(instruct versions)보다 성능이 우수함을 보여줍니다.

PlanSearch의 핵심 아이디어는 솔루션(solution) 코드 자체보다는 솔루션(solution)에 대한 더 높은 수준의 개념적인 자연어(natural language) 설명을 검색하는 것입니다. 저자들은 먼저 대규모 언어 모델(LLM)에 솔루션(solution)의 올바른 자연어(natural language) 스케치(sketch)를 프롬프트(prompt)하는 것이 코드 생성 성능을 향상시키는지 탐구함으로써 이 가설을 조사합니다. 그들은 대규모 언어 모델(LLM)에 문제와 올바른 코드 솔루션(code solution)을 모두 제공하고, 대규모 언어 모델(LLM)에게 솔루션(solution)의 자연어(natural language) 설명을 요청함으로써 "역번역된(backtranslated)" 스케치(sketch)를 생성합니다. 그들은 스케치(sketch)가 성능을 크게 향상시키며, 더 긴 스케치(sketch)가 훨씬 더 많은 이점을 제공한다는 것을 발견했습니다.

다음으로, 그들은 특정 스케치(sketch)에 따라 조건화된 대규모 언어 모델(LLM)의 정확도가 0% 또는 100%로 수렴하는 경향을 보임으로써, 단순히 아무 스케치(sketch)가 아니라 좋은 스케치(sketch)를 갖는 것의 중요성을 보여줍니다. 이는 계획의 품질이 최종 코드의 성공에 결정적인 영향을 미친다는 것을 의미합니다.

스케치(sketch)가 성능을 향상시키고, 실제로 좋은 스케치(sketch)가 성능을 좌우할 수 있다는 것을 입증한 후, 저자들은 스케치(sketch)의 중요성을 활용하기 위한 검색 알고리즘(search algorithm)을 제시합니다. 주어진 대규모 언어 모델(LLM)과 코딩 문제에 대해, 그들의 알고리즘(algorithm)인 PlanSearch는 다음을 포함합니다.

*   문제에 대한 많은 1차 관찰(first-order observations) 생성
*   대규모 언어 모델(LLM)에 선택된 1차 관찰(first-order observations)을 사용/병합하도록 프롬프트(prompt)하여 2차 관찰(second-order observations)을 생성하기 위한 1차 관찰(first-order observations) 조합을 조합적으로 샘플링(sampling)
*   1차 및 2차 관찰(first and second order observations)을 기반으로 문제를 해결하기 위한 전략(즉, 스케치(sketch))의 자연어(natural language) 설명 생성
*   "당신의 아이디어가 틀렸습니다(Your idea is wrong)"라는 프롬프트(prompt)로 더 많은 솔루션(solution) 스케치(sketch) 생성
*   솔루션(solution) 스케치(sketch)를 기반으로 코드 솔루션(code solution) 생성

PlanSearch는 네 가지 모델(GPT-4o 및 4o-mini, DeepSeek-Coder-V2, Claude-Sonnet-3.5)을 기반으로 세 가지 코딩 벤치마크(benchmark) (LiveCodeBench, HumanEval+, MBPP+)에서 평가됩니다. 저자들은 PlanSearch의 200개 생성 솔루션("PlanSearch@200")을 기본 반복 샘플링(sampling) 200회("Pass@200"), 검색 없는 단일 생성("Pass@1"), 그리고 단순히 스케치(sketch)를 요청한 다음 대규모 언어 모델(LLM)에 제안된 스케치(sketch)를 따르는 코드를 생성하도록 별도로 프롬프트(prompt)하는 IdeaSearch("IdeaSearch@200")와 비교합니다.

PlanSearch는 LiveCodeBench에서 비검색 기준선(non-search baseline)보다 25-35% 포인트, "Pass@200"보다 10-20% 포인트 더 높은 성능을 꾸준히 보여주며 매우 우수하게 작동합니다.

**우리의 견해**
코드 솔루션(code solution) 공간보다는 개념(concept) 공간을 탐색하는 것이 직관적으로 매우 합리적입니다. 컴퓨터 과학 교수 10명 중 9명은 코딩을 시작하기 전에 펜과 종이를 들고 앉아 계획을 스케치(sketch)할 것을 권장합니다. 접근 방식이 틀렸다면 코드를 얼마나 잘 작성하는지는 중요하지 않습니다. 컴퓨터 과학의 전설 도널드 커누스(Donald Knuth)는 "성급한 최적화(premature optimization)는 모든 악의 근원이다"라고 유명하게 말했습니다. 마찬가지로 지난주 인공지능(AI)의 전설 노암 브라운(Noam Brown)은 "올바른 방향으로 일하는 엔지니어 한 명이 잘못된 방향으로 일하는 천재 100명보다 낫다"고 트윗했습니다. 원리는 같습니다. 이러한 종류의 컴퓨터 과학(comp sci) 기본 지식이 대규모 언어 모델(LLM) 성능으로 이어진다는 사실은 어쩐지 위안이 됩니다. 이는 LLM이 단순히 코드를 생성하는 도구가 아니라, 문제 해결의 근본적인 사고 과정을 모방하고 있음을 시사합니다. – 콜(Cole)

**Gradient의 새로운 소식**

*   대규모 언어 모델(LLM) 챗봇(chatbot)에 빠진 것: 목적 의식
*   데이비다드 달림플(Davidad Dalrymple): 증명 가능한 안전한 인공지능(AI)을 향하여
*   클라이브 톰슨(Clive Thompson): 기술 이야기

**우리의 눈길을 사로잡은 다른 소식들**

**뉴스**

**애플(Apple), 인공지능(AI) 내장된 새로운 아이폰(iPhone) 공개**
애플(Apple)은 인공지능(AI)이 내장된 새로운 아이폰(iPhone)인 아이폰 16(iPhone 16)을 공개했습니다. 아이폰 16(iPhone 16)은 네 가지 모델로 출시되며, 애플(Apple)의 생성형 인공지능(generative AI) 시스템인 애플 인텔리전스(Apple Intelligence)를 실행하도록 설계되었습니다. 이 폰들은 메시지 분류, 글쓰기 제안, 향상된 시리(Siri) 가상 비서(virtual assistant)와 같은 기능을 갖출 것입니다. 이는 이전 아이폰(iPhone)의 예측 가능한 디자인에서 벗어나 사용자 경험(user experience)을 향상시키기 위한 인공지능(AI) 기능을 도입한 것입니다. 시장에서는 애플의 AI 전략이 사용자층에 어떻게 받아들여질지, 그리고 경쟁사들과의 차별점을 어떻게 부각할지 지속적으로 주목하고 있습니다.

**미국, 유럽연합(EU), 영국 등, 법적 구속력 있는 인공지능(AI) 조약 서명**
미국, 영국, 유럽연합(EU)은 여러 다른 국가들과 함께 인공지능(AI)에 관한 최초의 "법적 구속력 있는(legally binding)" 조약인 인공지능 기본 협약(Framework Convention on Artificial Intelligence)에 서명했습니다. 이 조약은 인공지능(AI)의 사용이 인권, 민주주의, 법치주의와 일치하도록 보장하는 것을 목표로 합니다. 이 조약은 사용자 데이터(user data) 보호, 법률 준수, 투명성 유지 등 인공지능(AI) 시스템이 따라야 할 주요 원칙들을 제시합니다. 조약에 서명하는 각 국가는 이 프레임워크(framework)를 반영하는 적절한 조치를 채택해야 합니다. 이 조약은 법적 구속력이 있지만, 집행은 주로 모니터링(monitoring)에 의존하며, 이는 비교적 약한 형태의 집행으로 간주됩니다. 현재 이 조약의 실제 적용과 국제 협력 강화 방안에 대한 논의가 활발히 진행 중입니다.

**OpenAI, ChatGPT 기업용 버전 유료 사용자 100만 명 돌파**
OpenAI는 ChatGPT의 기업용 버전에서 100만 명 이상의 유료 사용자라는 이정표를 달성했으며, 이는 기업들 사이에서 챗봇(chatbot)에 대한 수요가 증가하고 있음을 나타냅니다. 이 수치에는 ChatGPT 팀(Team) 및 엔터프라이즈(Enterprise) 서비스 사용자뿐만 아니라 대학에서 ChatGPT 에듀(Edu)를 사용하는 사람들도 포함됩니다. OpenAI는 1년 전 향상된 기능과 개인 정보 보호 조치를 갖춘 ChatGPT 엔터프라이즈(Enterprise)를 도입하여 수익을 창출하고 인공지능(AI) 개발의 높은 비용을 상쇄했습니다. 유료 기업 사용자 증가가 중요하지만, 얼마나 많은 새로운 기업이 가입했는지는 불분명합니다. OpenAI는 기업 고객당 평균 유료 사용자 수를 공개하지 않았습니다. OpenAI 기업 사용자 대다수는 미국에 기반을 두고 있으며, 미국 외에서는 독일, 일본, 영국이 가장 인기 있는 국가입니다. 이러한 성장은 기업용 AI 시장의 잠재력을 명확히 보여주며, 경쟁사들의 유사 서비스 출시를 가속화하고 있습니다.

**ChatGPT에서 Gemini까지: 인공지능(AI)이 인터넷을 다시 쓰는 방법**
이 기사는 Microsoft, Google, OpenAI와 같은 주요 기업들이 인공지능(AI) 챗봇(chatbot) 기술을 일반 대중에게 더 쉽게 접근할 수 있도록 만드는 방법을 다룹니다. 이 회사들은 Copilot, Gemini, GPT-4o와 같은 대규모 언어 모델(LLM) 프로그램을 개발하고 있습니다. 이러한 인공지능(AI) 도구는 자동 완성(autocomplete)과 유사한 프로그램을 사용하여 언어를 학습하고 언어의 통계적 특성(statistical properties)을 분석하여 이전에 입력된 단어를 기반으로 합리적인 추측을 합니다. 그러나 이러한 인공지능(AI) 도구는 사실의 하드코딩된 데이터베이스(hard-coded database)를 가지고 있지 않으며, 사실성을 보장하기보다는 그럴듯하게 들리는 진술을 생성하는 데 중점을 두기 때문에 거짓 정보를 사실처럼 제시할 수 있다는 점에 유의해야 합니다. 최근에는 이러한 환각(hallucination) 현상을 줄이기 위한 다양한 기술적 접근 방식과 함께, 사용자에게 AI 생성 정보의 한계를 명확히 알리는 노력이 중요해지고 있습니다.

**제이콥 볼(Jacob Wohl)의 비밀 인공지능(AI) 로비 회사 '고객'이라는 빅테크(Big Tech) 기업들, "들어본 적 없다"고 밝혀**
유죄 판결을 받은 사기꾼이자 우익 운동가인 제이콥 볼(Jacob Wohl)과 잭 버크먼(Jack Burkman)은 인공지능(AI) 기반 로비 서비스(lobbying services)를 제공한다고 주장하는 LobbyMatic이라는 회사를 운영해왔습니다. 그러나 LobbyMatic의 고객으로 등재된 많은 주요 기업들이 이 회사에 대해 들어본 적이 없다는 사실이 밝혀졌습니다. LobbyMatic은 인공지능(AI)을 사용하여 기업과 로비스트(lobbyist)가 로비 전략(lobbying strategies)을 수립하고, 청문회와 법안을 분석하며, 입법 진행 상황을 추적하도록 돕는다고 주장합니다. 이 회사는 볼(Wohl)과 버크먼(Burkman)에 의해 "제이 클라인(Jay Klein)"과 "빌 샌더스(Bill Sanders)"라는 가명으로 운영되었습니다. 토요타(Toyota), 바운더리 스톤 파트너스(Boundary Stone Partners), 란테우스(Lantheus)를 고객으로 확보했다고 주장했음에도 불구하고, 이 회사들은 LobbyMatic과의 어떠한 연관성도 부인했습니다. 이 회사는 이후 주요 기업들이 자사 소프트웨어(software)를 사용하고 있음을 시사하는 웹사이트(website) 스크린샷(screenshot)을 삭제했습니다. 플랫폼(platform)을 실제로 사용했던 몇 안 되는 회사 중 하나인 바운더리 스톤 파트너스(Boundary Stone Partners)는 해당 도구의 비효율성으로 인해 계약을 해지했습니다. 볼(Wohl)과 버크먼(Burkman)은 2022년에 중범죄 통신 사기(felony telecom fraud)로 유죄 판결을 받았고, FCC로부터 500만 달러의 벌금을 부과받았습니다. 이 사건은 AI 기술이 오용될 수 있는 다양한 방식을 보여주며, 특히 정보의 신뢰성과 투명성이 중요한 정치 및 로비 분야에서의 윤리적 문제를 제기합니다.

**자율주행차(Self-Driving Cars)가 수백 마일 떨어진 인간으로부터 도움을 받는 방법**
자율주행차(Self-driving cars)는 아직 완전히 자율적이지 않으며, 종종 어려운 상황을 헤쳐나가기 위해 인간의 도움이 필요합니다. 아마존(Amazon) 소유의 Zoox와 같은 회사들은 기술자들이 장애물이나 익숙하지 않은 시나리오(scenario)에 직면했을 때 자율주행차(self-driving cars)를 원격으로 안내하는 지휘 센터(command centers)를 가지고 있습니다. 기술자들은 경고를 받고 컴퓨터 마우스(computer mouse)를 사용하여 차량에 새로운 경로를 보낼 수 있습니다. 그들은 또한 차량 카메라(camera)의 비디오 피드(video feeds)를 보고 차량 경로를 실시간으로 조정할 수 있습니다. Waymo와 Cruise와 같은 회사들이 인간 지원의 필요성을 인정하기 시작했지만, 고용된 기술자 수나 관련 비용은 공개하지 않았습니다. 원격 지원은 로봇 택시(robot taxis)가 Uber와 Lyft가 운영하는 전통적인 차량 호출 서비스(ride-hailing fleets)를 대체하는 데 어려움을 겪을 수 있는 한 가지 이유입니다. 자율주행 기술(self-driving technology)의 발전에도 불구하고, 안전하고 효율적인 운영을 위해서는 인간의 개입이 여전히 필요합니다. 완전한 자율주행을 위한 기술적, 법적, 사회적 과제는 여전히 남아있으며, 원격 관제 시스템의 역할은 당분간 중요하게 유지될 것입니다.

**혼란스러운 과거에 여전히 시달리는 OpenAI, 성장하려 노력 중**
인공지능(AI) 분야의 주요 기업인 OpenAI는 주요 기업들로부터 투자를 유치하기 위해 경영진과 조직 구조에 상당한 변화를 겪고 있습니다. 이 회사는 저명한 기술 경영진, 허위 정보 전문가, 인공지능(AI) 안전 연구원들을 고용했으며, 전 육군 4성 장군을 포함한 7명의 이사회 구성원을 추가했습니다. OpenAI는 또한 Microsoft, Apple, Nvidia, Thrive와 같은 잠재적 투자자들과 논의 중이며, 잠재적 기업 가치는 1천억 달러에 달합니다. 또한 이 회사는 더 많은 투자자를 유치하기 위해 기업 구조를 변경하는 것을 고려하고 있습니다. 이러한 움직임은 OpenAI가 과거의 갈등을 해결하고 미래 목표에 집중하면서, 인공지능(AI) 산업에서 진지하고 책임감 있는 리더(leader)로서 자신을 보여주려는 노력을 반영합니다. 최근에는 샘 알트만(Sam Altman) CEO의 복귀와 새로운 제품 발표를 통해 내부 안정과 외부 성장을 동시에 추구하고 있으며, AI 안전(AI safety)과 윤리적 개발에 대한 대중의 기대에 부응하기 위한 노력을 강화하고 있습니다.

**마무리 생각**
이번 호 주제에 대해 할 말이 있으신가요? editor@thegradient.pub으로 이메일을 보내주시면, 다음 뉴스레터에서 독자들의 가장 흥미로운 생각을 공유하는 것을 고려하겠습니다! 피드백(feedback)을 원하시면 Daniel에게 dbashir@hmc.edu로 직접 연락하시거나 트위터(Twitter)를 통해 연락하실 수 있습니다. 이 뉴스레터가 마음에 드셨다면, Substack 구독을 통해 The Gradient에 기부하는 것을 고려해주세요. 이는 이 자원봉사 프로젝트를 유지하는 데 도움이 됩니다. 독자 여러분의 관심과 참여는 저희에게 큰 힘이 됩니다.

Gradient의 최신 업데이트를 읽어주셔서 감사합니다!