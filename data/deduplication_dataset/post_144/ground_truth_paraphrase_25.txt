Gradient의 83번째 소식지에 오신 것을 환영합니다! 본 콘텐츠가 유익하다고 생각하시면 구독 버튼을 눌러주시고 트위터에서 저희를 찾아주세요. 본 뉴스레터의 방대한 분량으로 인해, 전체 내용을 확인하시려면 Substack 페이지를 방문해 주시기 바랍니다!

최근 인공지능(AI)으로 제작된 작품들이 과연 참된 예술의 범주에 속하는지에 대한 활발한 논의가 이어지고 있습니다. 저희는 이번 최신호에서 이 복잡한 질문에 대한 명확한 해답을 제시할 역량이나 전문성을 갖추지는 못했지만, 아래의 흥미로운 글들을 살펴보시길 권합니다.

*   이번 논의의 불씨를 지핀 테드 창(Ted Chiang)의 뉴요커 에세이 "인공지능이 예술을 만들지 못하는 이유(Why A.I. Isn’t Going to Make Art)"
*   창의 에세이와 전국 소설 쓰기 대회(NaNoWriMo)의 대규모 언어 모델(LLM) 논란에 대한 Read Max의 해설
*   셀린 응우옌(Celine Nguyen)이 인공지능(AI) 예술이 다른 예술 형식들과 어떻게 상호작용하는지에 대해 심도 있게 탐구한 글

평소와 같이, 저희와 협력하여 글을 기고하고 싶으시다면 [제안서 양식](https://docs.google.com/forms/d/e/1FAIpQLSdcX2j-D_63Gf9fO7b82qX_s14m81h9h3V7-iXQ7-v2y2y2yQ/viewform)을 통해 문의해 주십시오.

**뉴스 하이라이트: 인공지능(AI)을 이용한 음원 스트리밍 사기에 대한 첫 형사 기소**

**요약**
연방 검찰 당국은 '인위적으로 부풀려진 음원 스트리밍(Artificially Inflated Music Streaming)'과 연루된 사기 행각에 대해 역사상 최초의 형사 고발을 공식화했습니다. 기소장에 따르면 노스캐롤라이나에 거주하는 음악가 마이클 스미스(Michael Smith)는 인공지능(AI)이 생성한 음원을 구매하여 다양한 스트리밍 플랫폼에 업로드한 후, 수천 개의 '봇(bot)'을 사용하여 해당 음원을 반복적으로 스트리밍했습니다. 이 계획으로 그는 7년 동안 1천만 달러 이상의 로열티(royalty)를 벌어들인 것으로 알려졌습니다. 그는 통신 사기(wire fraud), 통신 사기 공모(wire fraud conspiracy), 자금 세탁 공모(money laundering conspiracy) 혐의로 기소되었으며, 각 혐의는 최대 20년의 징역형에 처해질 수 있습니다. 이러한 사건은 디지털 음악 생태계의 취약성을 드러내며, 플랫폼들이 봇 활동을 탐지하고 차단하는 기술을 고도화해야 할 필요성을 강조합니다.

**개요**
이 계획은 겉보기에는 매우 단순합니다.

*   수천 개의 가짜 이메일 주소 확보
*   이 이메일 주소를 활용하여 Spotify, Apple Music, YouTube Music과 같은 주요 음악 플랫폼에 수천 개의 허위 계정 생성 및 등록
*   유료 계정의 스트리밍당 로열티(royalty) 비율이 더 높기 때문에, 각 가짜 계정이 서로 다른 결제 수단을 사용하는 것처럼 보이도록 "대량의 직불 카드, 일반적으로 회사 직원용 법인 직불 카드(corporate debit cards)를 제공"하는 서비스를 제공하는 "맨해튼 기반 업체"를 물색합니다.
*   수천 개의 유료 계정을 설정하는 데는 초기 비용이 발생하지만, 장기적으로는 그 이상의 수익을 기대할 수 있습니다.
*   자신이 소유한 음악을 대량으로 스트리밍하여 수익을 창출합니다.

**수익**
초기 단계에서는 인공지능(AI)이 직접적으로 관여하지 않았습니다. 대신 스미스는 음악 홍보 담당자의 방대한 기존 음악 카탈로그에 자신의 스트리밍 봇(bot)을 투입했습니다. 이후 그는 자신의 스트리밍 부대(streaming army)를 다른 음악가들에게 서비스 형태로 제공하여 그들의 스트리밍 수를 인위적으로 증가시켰습니다. 그러나 한 곡을 너무 자주 스트리밍하면 이상 징후로 감지될 위험이 있습니다. 이러한 탐지를 피하기 위해 스미스는 더 큰 카탈로그, 즉 더 많은 음원 자료가 필요했습니다. 그리하여 2018년, 그는 당시 이름이 잘 알려지지 않았던 "인공지능(AI) 음악 회사"와 제휴하여 매주 수천 곡의 노래를 제공받아 플랫폼에 업로드하고 스트리밍을 조작했습니다. 이 익명의 음악 회사는 스미스에게 음원을 공급했고, 그는 무작위적이지만 그럴듯한 트랙 제목과 아티스트 이름을 생성했습니다.

최선을 다했음에도 불구하고, 스미스의 계정은 이 계획이 진행되는 동안 여러 차례 플랫폼에서 플래그(flag) 처리되거나 삭제되었습니다. 사실 그는 이 모든 것에 대해 훨씬 더 미묘하게 접근할 수 있었습니다.

기소장에는 인공지능(AI) 생성 음악이 구체적으로 어떻게 만들어졌는지에 대한 세부 정보가 명시되어 있지 않습니다. 이들이 단순한 절차적 방법(procedural method)이 아닌 진정한 딥러닝(deep learning) 기반의 생성형 인공지능(genAI)을 사용하고 있었다는 유일한 증거는 기소장에 포함된 인공지능(AI) 음악 회사 직원 중 한 명이 스미스에게 보낸 이메일 발췌문입니다. “이제 곡의 품질이 10배에서 20배 더 좋아졌고, 보컬 생성 기능도 갖추고 있습니다. . . . 제가 무슨 말을 하는지 이해하시려면 첨부된 파일을 들어보세요."

어떤 의미에서는 인공지능(AI)이 이 이야기에서 부수적인 요소입니다. 인공지능(AI)이 생성한 음악을 Spotify에 업로드하는 것 자체는 불법이 아닙니다. 인공지능(AI)은 단지 기존의 사기 행위를 더욱 확장하고 자동화하는 도구로 활용되었을 뿐입니다. 이러한 사례는 기술 발전이 기존 범죄 수법과 결합될 때 발생할 수 있는 새로운 유형의 문제들을 시사합니다.

**우리의 견해**
연방 검찰 측은 스미스의 행위를 "정당하게 스트리밍된 음악을 통해 수익을 얻는 음악가, 작곡가, 기타 저작권 소유자들로부터의 도둑질"로 규정합니다. 기술적으로 이 설명은 정확합니다. 스미스의 이러한 조작은 다른 음악인들에게 돌아가야 할 로열티(royalty) 수익을 감소시키는 결과를 초래했습니다. 그러나 저는 (NYT의 일부 독자들과 마찬가지로) 스미스 씨의 상황에 일정 부분 공감하는 바입니다. 그는 기존의 결함 있는 시스템을 다른 많은 이들이 그랬던 방식으로 활용했습니다. 이와 관련하여 맷 레빈(Matt Levine)은 통찰력 있고 적절한 분석을 내놓았습니다.

“기본적으로 현대 경제와 삶의 많은 부분은 다음과 같은 특징을 가집니다. 모든 것은 비인격적인 자동화된 전자 교환을 통해 중개됩니다. 자동화된 전자 교환은 메커니즘(mechanism) — 실제로 어떻게 작동하는지, 교환 소프트웨어가 무엇을 허용하는지 — 과 규칙, 즉 메커니즘을 어떻게 사용할 수 있는지 규제하는 서비스 약관을 가지고 있습니다. 이 규칙들은 메커니즘보다 모호하며 작은 글씨로 쓰여 있습니다. 예를 들어 '사기를 치지 마라' 또는 '인간이어야 한다' 등입니다. 메커니즘은 규칙보다 훨씬 더 명확하고 두드러지며, 비인격적인 전자 세계에서 사람들은 메커니즘을 규칙으로 간주합니다. 그들은 규칙이 존재한다고 믿지 않습니다. 왜냐하면 규칙이 서비스 작동 방식과 모순되는 것처럼 보이기 때문입니다. Spotify의 작동 방식에 대한 기본적인 설명은 스미스의 주장된 차익 거래(arbitrage)를 시사합니다. 그가 하지 않았다면 분명 다른 누군가가 했을 것입니다.” – 콜(Cole)

이 사건은 디지털 플랫폼의 '규칙의 틈새(loophole)'를 악용하는 문제와, 기술이 발전하면서 기존의 규제와 윤리적 기준이 어떻게 재정의되어야 하는지에 대한 중요한 질문을 던집니다.

**연구 하이라이트: 자연어(Natural Language)를 통한 계획 수립이 대규모 언어 모델(LLM) 코드 생성 검색을 개선합니다.**

**요약**
Scale AI 소속 연구진(Gradient 공동 설립자 휴 장(Hugh Zhang) 포함 😀)이 대규모 언어 모델(LLM) 기반 코드 생성 과제를 위한 혁신적인 탐색 알고리즘(search algorithm)인 PlanSearch를 공개했습니다. 유사한 코드 솔루션(code solution)을 검색하여 추론 연산(inference compute)을 확장하는 기존 방법과 달리, PlanSearch는 자연어(natural language)로 된 문제 해결 계획의 공간을 탐색합니다. 이 접근 방식은 잠재적인 솔루션(solution)에 대한 더 다양하고 심층적인 탐색으로 이어집니다. 이 알고리즘(algorithm)은 HumanEval+, MBPP+, LiveCodeBench를 포함한 여러 코딩 벤치마크(benchmark)에서 매우 유망한 결과를 보여주었습니다. 이 연구는 코드 생성을 위한 대규모 언어 모델(LLM)에서 추론 연산(inference compute)을 효과적으로 확장하는 과제를 해결하며, 코드 자체보다는 문제 해결의 "개념(concept)" 공간에 대한 검색이라는 새로운 방향을 제시합니다. 이는 LLM이 단순히 코드를 생성하는 것을 넘어, 문제 해결 과정을 '이해하고 계획하는' 능력을 강화하는 중요한 진전입니다.

**개요**
저자들은 최신 대규모 언어 모델(SoTA LLM) 출력의 다양성 부족이 검색 알고리즘(search algorithm) (전반적인 성능 향상을 위해 추론 시간(inference time)에 추가 연산(compute)을 활용하는 모든 방법으로 정의됨)을 방해할 수 있다고 관찰합니다. 왜냐하면 검색은 다양한 가능성을 탐색함으로써 이점을 얻기 때문입니다. 다양성 부족은 검색을 더 좁은 가능성 집합으로 제한합니다. DPO 및 RLHF와 같은 후처리 훈련 방법(post-training methods)이 출력 다양성을 감소시킨다는 증거가 있으며, 실제로 저자들은 일부 모델의 기본 버전이 여러 가능한 솔루션(solution)을 생성하도록 허용될 때 지시 버전(instruct versions)보다 성능이 우수함을 보여줍니다.

PlanSearch의 핵심 아이디어는 솔루션(solution) 코드 자체보다는 솔루션(solution)에 대한 더 높은 수준의 개념적인 자연어(natural language) 설명을 검색하는 것입니다. 저자들은 먼저 대규모 언어 모델(LLM)에 솔루션(solution)의 올바른 자연어(natural language) 스케치(sketch)를 프롬프트(prompt)하는 것이 코드 생성 성능을 향상시키는지 탐구함으로써 이 가설을 조사합니다. 그들은 대규모 언어 모델(LLM)에 문제와 올바른 코드 솔루션(code solution)을 모두 제공하고, 대규모 언어 모델(LLM)에게 솔루션(solution)의 자연어(natural language) 설명을 요청함으로써 "역번역된(backtranslated)" 스케치(sketch)를 생성합니다. 그들은 스케치(sketch)가 성능을 크게 향상시키며, 더 긴 스케치(sketch)가 훨씬 더 많은 이점을 제공한다는 것을 발견했습니다.

다음으로, 그들은 특정 스케치(sketch)에 따라 조건화된 대규모 언어 모델(LLM)의 정확도가 0% 또는 100%로 수렴하는 경향을 보임으로써, 단순히 아무 스케치(sketch)가 아니라 좋은 스케치(sketch)를 갖는 것의 중요성을 보여줍니다. 이는 LLM이 '올바른' 계획을 받았을 때 얼마나 강력한 성능을 발휘할 수 있는지를 증명하는 대목입니다.

스케치(sketch)가 성능을 향상시키고, 실제로 좋은 스케치(sketch)가 성능을 좌우할 수 있다는 것을 입증한 후, 저자들은 스케치(sketch)의 중요성을 활용하기 위한 검색 알고리즘(search algorithm)을 제시합니다. 주어진 대규모 언어 모델(LLM)과 코딩 문제에 대해, 그들의 알고리즘(algorithm)인 PlanSearch는 다음을 포함합니다.

*   문제에 대한 많은 1차 관찰(first-order observations) 생성
*   대규모 언어 모델(LLM)에 선택된 1차 관찰(first-order observations)을 사용/병합하도록 프롬프트(prompt)하여 2차 관찰(second-order observations)을 생성하기 위한 1차 관찰(first-order observations) 조합을 조합적으로 샘플링(sampling)
*   1차 및 2차 관찰(first and second order observations)을 기반으로 문제를 해결하기 위한 전략(즉, 스케치(sketch))의 자연어(natural language) 설명 생성
*   "당신의 아이디어가 틀렸습니다(Your idea is wrong)"라는 프롬프트(prompt)로 더 많은 솔루션(solution) 스케치(sketch) 생성
*   솔루션(solution) 스케치(sketch)를 기반으로 코드 솔루션(code solution) 생성

PlanSearch는 네 가지 모델(GPT-4o 및 4o-mini, DeepSeek-Coder-V2, Claude-Sonnet-3.5)을 기반으로 세 가지 코딩 벤치마크(benchmark) (LiveCodeBench, HumanEval+, MBPP+)에서 평가됩니다. 저자들은 PlanSearch의 200개 생성 솔루션("PlanSearch@200")을 기본 반복 샘플링(sampling) 200회("Pass@200"), 검색 없는 단일 생성("Pass@1"), 그리고 단순히 스케치(sketch)를 요청한 다음 대규모 언어 모델(LLM)에 제안된 스케치(sketch)를 따르는 코드를 생성하도록 별도로 프롬프트(prompt)하는 IdeaSearch("IdeaSearch@200")와 비교합니다.

PlanSearch는 LiveCodeBench에서 비검색 기준선(non-search baseline)보다 25-35% 포인트, "Pass@200"보다 10-20% 포인트 더 높은 성능을 꾸준히 보여주며 매우 우수하게 작동합니다. 이는 코드 생성의 효율성과 정확성을 획기적으로 개선할 수 있는 잠재력을 시사합니다.

**우리의 견해**
코드 구현 공간보다는 개념적 영역을 탐색하는 것이 매우 직관적이고 타당합니다. 대다수의 컴퓨터 과학 교육자들은 코딩에 앞서 종이와 펜을 사용하여 문제 해결 계획을 구상할 것을 조언합니다. 만약 접근 방식 자체가 잘못되었다면, 아무리 훌륭하게 코드를 작성하더라도 그 가치는 떨어집니다. 컴퓨터 과학계의 거장 도널드 커누스(Donald Knuth)는 "성급한 최적화(premature optimization)는 모든 해악의 근원이다"라는 명언을 남겼습니다. 비슷한 맥락에서, 지난주 인공지능(AI) 분야의 선구자 노암 브라운(Noam Brown)은 "올바른 방향으로 나아가는 한 명의 엔지니어가 잘못된 방향으로 가는 백 명의 천재보다 낫다"고 트윗했습니다. 핵심 원리는 동일합니다. 이러한 컴퓨터 과학(comp sci)의 근본적인 지혜가 대규모 언어 모델(LLM)의 성능 향상으로 이어진다는 점은 어딘가 모르게 안도감을 줍니다. – 콜(Cole)

**Gradient의 새로운 소식**

*   대규모 언어 모델(LLM) 챗봇(chatbot)에 빠진 것: 목적 의식
*   데이비다드 달림플(Davidad Dalrymple): 증명 가능한 안전한 인공지능(AI)을 향하여
*   클라이브 톰슨(Clive Thompson): 기술 이야기

**우리의 눈길을 사로잡은 다른 소식들**

**뉴스**

**애플(Apple), 인공지능(AI) 내장된 새로운 아이폰(iPhone) 공개**
애플(Apple)은 인공지능(AI)이 내장된 새로운 아이폰(iPhone)인 아이폰 16(iPhone 16)을 공개했습니다. 아이폰 16(iPhone 16)은 네 가지 모델로 출시되며, 애플(Apple)의 생성형 인공지능(generative AI) 시스템인 애플 인텔리전스(Apple Intelligence)를 실행하도록 설계되었습니다. 이 폰들은 메시지 분류, 글쓰기 제안, 향상된 시리(Siri) 가상 비서(virtual assistant)와 같은 기능을 갖출 것입니다. 이는 이전 아이폰(iPhone)의 예측 가능한 디자인에서 벗어나 사용자 경험(user experience)을 향상시키기 위한 인공지능(AI) 기능을 도입한 것입니다.

**미국, 유럽연합(EU), 영국 등, 법적 구속력 있는 인공지능(AI) 조약 서명**
미국, 영국, 유럽연합(EU)은 여러 다른 국가들과 함께 인공지능(AI)에 관한 최초의 "법적 구속력 있는(legally binding)" 조약인 인공지능 기본 협약(Framework Convention on Artificial Intelligence)에 서명했습니다. 이 조약은 인공지능(AI)의 사용이 인권, 민주주의, 법치주의와 일치하도록 보장하는 것을 목표로 합니다. 이 조약은 사용자 데이터(user data) 보호, 법률 준수, 투명성 유지 등 인공지능(AI) 시스템이 따라야 할 주요 원칙들을 제시합니다. 조약에 서명하는 각 국가는 이 프레임워크(framework)를 반영하는 적절한 조치를 채택해야 합니다. 이 조약은 법적 구속력이 있지만, 집행은 주로 모니터링(monitoring)에 의존하며, 이는 비교적 약한 형태의 집행으로 간주됩니다.

**OpenAI, ChatGPT 기업용 버전 유료 사용자 100만 명 돌파**
OpenAI는 ChatGPT의 기업용 버전에서 100만 명 이상의 유료 사용자라는 이정표를 달성했으며, 이는 기업들 사이에서 챗봇(chatbot)에 대한 수요가 증가하고 있음을 나타냅니다. 이 수치에는 ChatGPT 팀(Team) 및 엔터프라이즈(Enterprise) 서비스 사용자뿐만 아니라 대학에서 ChatGPT 에듀(Edu)를 사용하는 사람들도 포함됩니다. OpenAI는 1년 전 향상된 기능과 개인 정보 보호 조치를 갖춘 ChatGPT 엔터프라이즈(Enterprise)를 도입하여 수익을 창출하고 인공지능(AI) 개발의 높은 비용을 상쇄했습니다. 유료 기업 사용자 증가가 중요하지만, 얼마나 많은 새로운 기업이 가입했는지는 불분명합니다. OpenAI는 기업 고객당 평균 유료 사용자 수를 공개하지 않았습니다. OpenAI 기업 사용자 대다수는 미국에 기반을 두고 있으며, 미국 외에서는 독일, 일본, 영국이 가장 인기 있는 국가입니다.

**ChatGPT에서 Gemini까지: 인공지능(AI)이 인터넷을 다시 쓰는 방법**
이 기사는 Microsoft, Google, OpenAI와 같은 주요 기업들이 인공지능(AI) 챗봇(chatbot) 기술을 일반 대중에게 더 쉽게 접근할 수 있도록 만드는 방법을 다룹니다. 이 회사들은 Copilot, Gemini, GPT-4o와 같은 대규모 언어 모델(LLM) 프로그램을 개발하고 있습니다. 이러한 인공지능(AI) 도구는 자동 완성(autocomplete)과 유사한 프로그램을 사용하여 언어를 학습하고 언어의 통계적 특성(statistical properties)을 분석하여 이전에 입력된 단어를 기반으로 합리적인 추측을 합니다. 그러나 이러한 인공지능(AI) 도구는 사실의 하드코딩된 데이터베이스(hard-coded database)를 가지고 있지 않으며, 사실성을 보장하기보다는 그럴듯하게 들리는 진술을 생성하는 데 중점을 두기 때문에 거짓 정보를 사실처럼 제시할 수 있다는 점에 유의해야 합니다.

**제이콥 볼(Jacob Wohl)의 비밀 인공지능(AI) 로비 회사 '고객'이라는 빅테크(Big Tech) 기업들, "들어본 적 없다"고 밝혀**
유죄 판결을 받은 사기꾼이자 우익 운동가인 제이콥 볼(Jacob Wohl)과 잭 버크먼(Jack Burkman)은 인공지능(AI) 기반 로비 서비스(lobbying services)를 제공한다고 주장하는 LobbyMatic이라는 회사를 운영해왔습니다. 그러나 LobbyMatic의 고객으로 등재된 많은 주요 기업들이 이 회사에 대해 들어본 적이 없다는 사실이 밝혀졌습니다. LobbyMatic은 인공지능(AI)을 사용하여 기업과 로비스트(lobbyist)가 로비 전략(lobbying strategies)을 수립하고, 청문회와 법안을 분석하며, 입법 진행 상황을 추적하도록 돕는다고 주장합니다. 이 회사는 볼(Wohl)과 버크먼(Burkman)에 의해 "제이 클라인(Jay Klein)"과 "빌 샌더스(Bill Sanders)"라는 가명으로 운영되었습니다. 토요타(Toyota), 바운더리 스톤 파트너스(Boundary Stone Partners), 란테우스(Lantheus)를 고객으로 확보했다고 주장했음에도 불구하고, 이 회사들은 LobbyMatic과의 어떠한 연관성도 부인했습니다. 이 회사는 이후 주요 기업들이 자사 소프트웨어(software)를 사용하고 있음을 시사하는 웹사이트(website) 스크린샷(screenshot)을 삭제했습니다. 플랫폼(platform)을 실제로 사용했던 몇 안 되는 회사 중 하나인 바운더리 스톤 파트너스(Boundary Stone Partners)는 해당 도구의 비효율성으로 인해 계약을 해지했습니다. 볼(Wohl)과 버크먼(Burkman)은 2022년에 중범죄 통신 사기(felony telecom fraud)로 유죄 판결을 받았고, FCC로부터 500만 달러의 벌금을 부과받았습니다.

**자율주행차(Self-Driving Cars)가 수백 마일 떨어진 인간으로부터 도움을 받는 방법**
자율주행차(Self-driving cars)는 완전히 자율적이지 않으며, 종종 어려운 상황을 헤쳐나가기 위해 인간의 도움이 필요합니다. 아마존(Amazon) 소유의 Zoox와 같은 회사들은 기술자들이 장애물이나 익숙하지 않은 시나리오(scenario)에 직면했을 때 자율주행차(self-driving cars)를 원격으로 안내하는 지휘 센터(command centers)를 가지고 있습니다. 기술자들은 경고를 받고 컴퓨터 마우스(computer mouse)를 사용하여 차량에 새로운 경로를 보낼 수 있습니다. 그들은 또한 차량 카메라(camera)의 비디오 피드(video feeds)를 보고 차량 경로를 실시간으로 조정할 수 있습니다. Waymo와 Cruise와 같은 회사들이 인간 지원의 필요성을 인정하기 시작했지만, 고용된 기술자 수나 관련 비용은 공개하지 않았습니다. 원격 지원은 로봇 택시(robot taxis)가 Uber와 Lyft가 운영하는 전통적인 차량 호출 서비스(ride-hailing fleets)를 대체하는 데 어려움을 겪을 수 있는 한 가지 이유입니다. 자율주행 기술(self-driving technology)의 발전에도 불구하고, 안전하고 효율적인 운영을 위해서는 인간의 개입이 여전히 필요합니다.

**혼란스러운 과거에 여전히 시달리는 OpenAI, 성장하려 노력 중**
인공지능(AI) 분야의 주요 기업인 OpenAI는 주요 기업들로부터 투자를 유치하기 위해 경영진과 조직 구조에 상당한 변화를 겪고 있습니다. 이 회사는 저명한 기술 경영진, 허위 정보 전문가, 인공지능(AI) 안전 연구원들을 고용했으며, 전 육군 4성 장군을 포함한 7명의 이사회 구성원을 추가했습니다。OpenAI는 또한 Microsoft, Apple, Nvidia, Thrive와 같은 잠재적 투자자들과 논의 중이며, 잠재적 기업 가치는 1천억 달러에 달합니다. 또한 이 회사는 더 많은 투자자를 유치하기 위해 기업 구조를 변경하는 것을 고려하고 있습니다. 이러한 움직임은 OpenAI가 과거의 갈등을 해결하고 미래 목표에 집중하면서, 인공지능(AI) 산업에서 진지하고 책임감 있는 리더(leader)로서 자신을 보여주려는 노력을 반영합니다.

**구글(Google), 새로운 멀티모달(Multimodal) AI 모델 'Gemini Ultra 1.5' 발표**
구글(Google)은 언어, 이미지, 오디오, 비디오를 동시에 처리할 수 있는 새로운 멀티모달(multimodal) 인공지능(AI) 모델인 'Gemini Ultra 1.5'를 공개했습니다. 이 모델은 특히 장문의 문맥 이해 능력이 뛰어나, 최대 100만 토큰(token)의 데이터를 처리할 수 있습니다. 이는 복잡한 문서 분석, 긴 대화 요약, 대규모 코드베이스(codebase) 이해 등 다양한 분야에서 혁신적인 응용 가능성을 열어줍니다. 구글(Google)은 이 모델이 의료 진단, 교육 콘텐츠 생성, 창의적 스토리텔링(storytelling) 등에서 중요한 역할을 할 것으로 기대하고 있습니다.

**유럽연합(EU) AI 법안, 최종 승인 및 시행 임박**
유럽연합(EU)의 역사적인 인공지능(AI) 법안이 최종 승인 단계를 거쳐 곧 시행될 예정입니다. 이 법안은 인공지능(AI) 시스템을 위험 수준에 따라 분류하고, 고위험 인공지능(AI)에 대해서는 엄격한 규제와 투명성 요건을 부과하는 것을 골자로 합니다. 이는 인공지능(AI) 개발 및 배포에 있어 윤리적이고 안전한 접근 방식을 보장하려는 세계 최초의 포괄적인 법적 프레임워크(framework)로 평가받고 있습니다. 이 법안은 전 세계적으로 인공지능(AI) 규제 논의에 큰 영향을 미칠 것으로 예상됩니다.

**마이크로소프트(Microsoft), AI 기반 코딩 도구 'GitHub Copilot Enterprise' 출시**
마이크로소프트(Microsoft)는 기업용으로 설계된 'GitHub Copilot Enterprise'를 공식 출시했습니다. 이 도구는 개발자들이 코드를 더 빠르고 효율적으로 작성할 수 있도록 돕는 인공지능(AI) 기반의 코드 도우미입니다. 기업 내의 사내 코드 베이스(code base)를 학습하여 맞춤형 제안을 제공하며, 보안 및 데이터 프라이버시(privacy) 기능을 강화하여 기업 환경에 적합하도록 설계되었습니다. 이는 소프트웨어 개발 생산성을 혁신하고, 개발자들이 반복적인 작업 대신 더 창의적인 문제 해결에 집중할 수 있도록 지원하는 것을 목표로 합니다.

**AI 모델의 에너지 소비, 환경 문제로 부상**
최근 인공지능(AI) 모델, 특히 대규모 언어 모델(LLM)의 훈련 및 운영에 필요한 막대한 에너지 소비가 환경 문제로 대두되고 있습니다. 한 연구에 따르면, GPT-3와 같은 대형 모델 하나를 훈련시키는 데 필요한 전력량이 수백 가구의 연간 전력 사용량에 맞먹는 것으로 나타났습니다. 이에 따라 인공지능(AI) 업계는 에너지 효율적인 모델 아키텍처(architecture) 개발, 재생 에너지 사용 확대, 그리고 모델의 탄소 발자국(carbon footprint)을 줄이기 위한 새로운 기술 연구에 박차를 가하고 있습니다.

**보스턴 다이내믹스(Boston Dynamics), 새로운 전기 휴머노이드(Humanoid) 로봇 'Atlas' 공개**
세계적으로 유명한 로봇 회사 보스턴 다이내믹스(Boston Dynamics)가 완전히 전기 구동 방식의 차세대 휴머노이드(humanoid) 로봇 'Atlas'를 선보였습니다. 이전 유압식 모델보다 더 강하고 민첩하며, 다양한 산업 환경에서 복잡한 작업을 수행할 수 있도록 설계되었습니다. 이 새로운 Atlas 로봇은 제조, 물류, 건설 현장 등에서 인간과 협력하거나 위험한 작업을 대체하며 로봇 자동화의 새로운 시대를 열 것으로 기대됩니다.

**AI 기반 의료 진단 시스템, 임상 시험에서 유망한 결과 보여**
인공지능(AI) 기반의 의료 진단 시스템이 초기 임상 시험에서 높은 정확도를 보이며 유망한 결과를 얻고 있습니다. 특히 영상 진단 분야(예: X-ray, MRI)에서 암, 심혈관 질환 등 미세한 이상 징후를 인간 의사보다 더 빠르고 정확하게 찾아내는 능력을 입증했습니다. 이러한 시스템은 의료진의 진단 부담을 줄이고, 조기 진단을 통해 환자의 예후를 개선하는 데 기여할 수 있을 것으로 전망됩니다. 하지만 규제 승인과 광범위한 배포를 위해서는 추가적인 연구와 검증이 필요합니다.

**마무리 생각**
이번 주제와 관련하여 의견이 있으신가요? editor@thegradient.pub으로 이메일을 보내주시면, 다음 소식지에서 독자 여러분의 가장 흥미로운 통찰을 공유하는 것을 검토하겠습니다! 의견을 주시고 싶으시면 Daniel(dbashir@hmc.edu)에게 직접 연락하시거나 트위터(Twitter)를 통해 소통하실 수 있습니다. 본 뉴스레터가 유용하셨다면, Substack 구독을 통해 The Gradient에 후원하는 방안을 고려해 주십시오. 이는 자원봉사로 운영되는 본 프로젝트를 지속하는 데 큰 힘이 됩니다. Gradient의 최신 소식을 읽어주셔서 대단히 감사합니다!