Gradient의 83번째 업데이트에 오신 것을 환영합니다! 새로 오셨고 저희 콘텐츠가 마음에 드신다면, 구독하고 트위터에서 저희를 팔로우해주세요. 저희 뉴스레터는 내용이 길기 때문에, 모든 내용을 보시려면 Substack에서 이 게시물을 확인하셔야 합니다!

최근 인공지능(AI) 예술이 진정한 예술인가에 대한 많은 논의가 있었습니다. 이번 주 업데이트에서 이 질문을 해결할 용기나 전문 지식은 없었지만, 다음 글들은 읽어볼 가치가 있습니다.

*   이번 논의를 촉발시킨 테드 창(Ted Chiang)의 뉴요커 에세이 "인공지능이 예술을 만들지 못하는 이유(Why A.I. Isn’t going to Make Art)"
*   창의 에세이와 전국 소설 쓰기 대회(NaNoWriMo)의 대규모 언어 모델(LLM) 논란에 대한 Read Max의 논평
*   셀린 응우옌(Celine Nguyen)이 인공지능(AI) 예술이 다른 예술과 어떤 관계에 있는지 멋지게 탐구한 글
*   인공지능(AI) 생성 예술의 저작권 문제: 누가 저작권을 소유하는가?
*   프롬프트 엔지니어링(Prompt Engineering)이 예술 창작의 새로운 형태로 부상하는 방식
*   인공지능(AI) 예술이 기존 예술 시장과 예술가들에게 미치는 경제적 영향

언제나처럼, 저희와 함께 글을 쓰고 싶으시다면 [이 양식](https://docs.google.com/forms/d/e/1FAIpQLSdcX2j-D_63Gf9fO7b82qX_s14m81h9h3V7-iXQ7-v2y2y2yQ/viewform)을 사용하여 제안서를 보내주세요.

**뉴스 하이라이트: 인공지능(AI)을 이용한 음원 스트리밍 사기에 대한 첫 형사 기소**

**요약**
연방 검찰은 "인위적으로 부풀려진 음원 스트리밍(Artificially Inflated Music Streaming)"과 관련된 사기 계획에 대해 사상 첫 형사 기소를 발표했습니다. 기소장에 따르면 노스캐롤라이나에 거주하는 음악가 마이클 스미스(Michael Smith)는 인공지능(AI)이 생성한 음원을 구매하여 다양한 스트리밍 플랫폼에 업로드한 후, 수천 개의 "봇(bot)"을 사용하여 해당 음원을 반복적으로 스트리밍했습니다. 이 계획으로 그는 7년 동안 1천만 달러 이상의 로열티(royalty)를 벌어들인 것으로 알려졌습니다. 그는 통신 사기(wire fraud), 통신 사기 공모(wire fraud conspiracy), 자금 세탁 공모(money laundering conspiracy) 혐의로 기소되었습니다. 각 혐의는 최대 20년의 징역형을 선고받을 수 있습니다.

**개요**
이 계획은 매우 간단합니다.

*   수천 개의 가짜 이메일 주소 구매
*   이 이메일 주소를 사용하여 Spotify, Apple Music, Youtube Music과 같은 음악 플랫폼에 수천 개의 가짜 계정 생성 및 등록
*   유료 계정의 스트리밍당 로열티(royalty) 비율이 더 높습니다. 따라서 각 가짜 계정이 다른 결제 수단을 사용한 것처럼 보이도록 "대량의 직불 카드, 일반적으로 회사 직원용 법인 직불 카드(corporate debit cards)를 제공"하는 사업을 하는 "맨해튼 기반 서비스"를 찾습니다.
*   수천 개의 유료 계정을 설정하는 데는 돈이 들지만, 그만한 가치가 있을 것입니다.
*   자신이 소유한 음악을 많이 스트리밍하기 시작합니다.

더 구체적으로: **수익**

처음에는 인공지능(AI)이 없었습니다. 대신 스미스는 음악 홍보 담당자의 방대한 기존 음악 카탈로그에 자신의 스트리밍 봇(bot)을 풀어놓았습니다. 나중에 그는 자신의 스트리밍 부대(streaming army)를 다른 음악가들에게 서비스로 제공하여 그들의 스트리밍 수를 늘렸습니다. 하지만 한 곡을 너무 여러 번 스트리밍하면 누군가가 알아차리게 됩니다. 탐지를 피하기 위해 스미스는 더 큰 카탈로그, 더 많은 자료가 필요했습니다. 그래서 2018년에 그는 아직 이름이 알려지지 않은 "인공지능(AI) 음악 회사"와 협력하여 매주 수천 곡의 노래를 제공받아 플랫폼에 업로드하고 스트리밍을 조작했습니다. 이름 없는 음악 회사는 스미스에게 음원을 제공했고, 그는 무작위적이지만 이상하게 그럴듯한 트랙 제목과 아티스트를 생성했습니다.

최선을 다했음에도 불구하고, 스미스의 계정은 이 계획이 진행되는 동안 여러 번 플랫폼에서 플래그(flag) 처리되거나 삭제되었습니다. 사실 그는 이 모든 것에 대해 훨씬 더 미묘하게 접근할 수 있었습니다.

기소장에는 인공지능(AI) 생성 음악이 실제로 어떻게 생성되었는지에 대한 세부 정보가 나와 있지 않습니다. 그들이 단순한 절차적 방법(procedural method)이 아닌 진정한 딥러닝(deep learning) 생성 인공지능(genAI)을 사용하고 있었다는 유일한 증거는 기소장에 포함된 인공지능(AI) 음악 회사 직원 중 한 명이 스미스에게 보낸 이메일 발췌문입니다. “이제 곡의 품질이 10배에서 20배 더 좋아졌고, 보컬 생성 기능도 갖추고 있습니다. . . . 제가 무슨 말을 하는지 이해하시려면 첨부된 파일을 들어보세요."

어떤 의미에서는 인공지능(AI)이 이 이야기에서 부수적인 요소입니다. 인공지능(AI)이 생성한 음악을 Spotify에 업로드하는 것은 불법이 아닙니다. 인공지능(AI)은 단지 기존의 사기를 확장했을 뿐입니다.

마이클 스미스(Michael Smith) 사건은 디지털 음악 스트리밍 생태계에서 사기가 얼마나 광범위하게 발생할 수 있는지 보여주는 대표적인 사례입니다. 이 계획은 단순히 봇(bot)을 사용하여 스트리밍 수를 조작하는 것을 넘어, 인공지능(AI) 생성 음악을 활용하여 탐지를 회피하고 사기 규모를 확장했다는 점에서 주목할 만합니다. 스트리밍 플랫폼은 수십억 달러 규모의 산업이며, 로열티(royalty) 분배는 스트리밍 횟수를 기반으로 이루어지기 때문에, 이러한 조작은 합법적인 아티스트와 권리 보유자에게 직접적인 재정적 피해를 줍니다.

오늘날 스트리밍 사기는 더욱 정교해지고 있습니다. 초기에는 단순한 봇(bot) 네트워크가 주를 이루었지만, 이제는 인공지능(AI) 기술이 사기 탐지와 동시에 사기 행위 자체를 고도화하는 데 사용되고 있습니다. 예를 들어, 인공지능(AI)은 수많은 "새로운" 아티스트 이름과 "독창적인" 곡을 생성하여 콘텐츠 라이브러리를 빠르게 채울 수 있습니다. 이러한 곡들은 인간이 작곡한 것처럼 들리도록 미묘하게 변형될 수 있으며, 플랫폼의 자동화된 탐지 시스템을 우회하기 위해 다양한 장르와 스타일을 모방할 수 있습니다. 또한, 사기꾼들은 봇(bot)의 행동 패턴을 실제 사용자와 유사하게 만들어서, 계정 활동이 더 자연스럽게 보이도록 인공지능(AI)을 활용하기도 합니다. 이는 플랫폼이 사기 계정을 식별하고 제거하는 것을 훨씬 더 어렵게 만듭니다.

이러한 사기 행위는 스트리밍 플랫폼의 신뢰성을 훼손하고, 음악 산업 전반에 걸쳐 불공정한 경쟁 환경을 조성합니다. 플랫폼들은 인공지능(AI) 기반의 사기 탐지 시스템을 강화하고 있지만, 사기꾼들 역시 끊임없이 새로운 방법을 찾아내면서 기술적 군비 경쟁이 심화되고 있습니다. 궁극적으로, 이러한 사기는 합법적인 음악가들이 마땅히 받아야 할 로열티(royalty)를 빼앗고, 팬들이 진정한 예술을 발견하기 어렵게 만듭니다.

**우리의 견해**
연방 검찰은 스미스의 범죄를 "합법적으로 스트리밍된 곡을 가진 음악가, 작곡가 및 기타 권리 보유자로부터 훔친 것"으로 묘사하고 있습니다. 기계적으로는 사실입니다. 스미스의 행동은 다른 음악가들에게 더 적은 로열티(royalty) 지급으로 이어졌습니다. 하지만 저는 스미스 씨에게 어느 정도 공감합니다(NYT 댓글 작성자들도 마찬가지입니다). 그는 다른 많은 사람들이 하는 방식으로 고장 난 시스템을 이용했습니다. 맷 레빈(Matt Levine)은 특징적으로 훌륭하고 적절한 견해를 제시했습니다.

“기본적으로 현대 경제와 삶의 많은 부분은 다음과 같은 특징을 가집니다. 모든 것은 비인격적인 자동화된 전자 교환을 통해 중개됩니다. 자동화된 전자 교환은 메커니즘(mechanism) — 실제로 어떻게 작동하는지, 교환 소프트웨어가 무엇을 허용하는지 — 과 규칙, 즉 메커니즘을 어떻게 사용할 수 있는지 규제하는 서비스 약관을 가지고 있습니다. 이 규칙들은 메커니즘보다 모호하며 작은 글씨로 쓰여 있습니다. 예를 들어 '사기를 치지 마라' 또는 '인간이어야 한다' 등입니다. 메커니즘은 규칙보다 훨씬 더 명확하고 두드러지며, 비인격적인 전자 세계에서 사람들은 메커니즘을 규칙으로 간주합니다. 그들은 규칙이 존재한다고 믿지 않습니다. 왜냐하면 규칙이 서비스 작동 방식과 모순되는 것처럼 보이기 때문입니다. Spotify의 작동 방식에 대한 기본적인 설명은 스미스의 주장된 차익 거래(arbitrage)를 시사합니다. 그가 하지 않았다면 분명 다른 누군가가 했을 것입니다.” – 콜(Cole)

**연구 하이라이트: 자연어(Natural Language)를 통한 계획 수립이 대규모 언어 모델(LLM) 코드 생성 검색을 개선합니다.**

**요약**
Scale AI의 연구원들(Gradient 공동 창립자 휴 장(Hugh Zhang) 포함 😀)은 대규모 언어 모델(LLM) 코드 생성 작업을 위한 새로운 검색 알고리즘(search algorithm)인 PlanSearch를 발표했습니다. 유사한 코드 솔루션(code solution)을 검색하여 추론 연산(inference compute)을 확장하는 기존 방법과 달리, PlanSearch는 자연어(natural language)로 된 문제 해결 계획의 공간을 탐색합니다. 이 접근 방식은 잠재적인 솔루션(solution)에 대한 더 다양한 탐색으로 이어집니다. 이 알고리즘(algorithm)은 HumanEval+, MBPP+, LiveCodeBench를 포함한 여러 코딩 벤치마크(benchmark)에서 유망한 결과를 보여줍니다. 이 연구는 코드 생성을 위한 대규모 언어 모델(LLM)에서 추론 연산(inference compute)을 효과적으로 확장하는 과제를 해결하고, 코드보다는 "개념(concept)" 공간에 대한 검색의 새로운 방향을 제시합니다.

**개요**
저자들은 최신 대규모 언어 모델(SoTA LLM) 출력의 다양성 부족이 검색 알고리즘(search algorithm) (전반적인 성능 향상을 위해 추론 시간(inference time)에 추가 연산(compute)을 활용하는 모든 방법으로 정의됨)을 방해할 수 있다고 관찰합니다. 왜냐하면 검색은 다양한 가능성을 탐색함으로써 이점을 얻기 때문입니다. 다양성 부족은 검색을 더 좁은 가능성 집합으로 제한합니다. DPO 및 RLHF와 같은 후처리 훈련 방법(post-training methods)이 출력 다양성을 감소시킨다는 증거가 있으며, 실제로 저자들은 일부 모델의 기본 버전이 여러 가능한 솔루션(solution)을 생성하도록 허용될 때 지시 버전(instruct versions)보다 성능이 우수함을 보여줍니다.

PlanSearch의 핵심 아이디어는 솔루션(solution) 코드 자체보다는 솔루션(solution)에 대한 더 높은 수준의 개념적인 자연어(natural language) 설명을 검색하는 것입니다. 저자들은 먼저 대규모 언어 모델(LLM)에 솔루션(solution)의 올바른 자연어(natural language) 스케치(sketch)를 프롬프트(prompt)하는 것이 코드 생성 성능을 향상시키는지 탐구함으로써 이 가설을 조사합니다. 그들은 대규모 언어 모델(LLM)에 문제와 올바른 코드 솔루션(code solution)을 모두 제공하고, 대규모 언어 모델(LLM)에게 솔루션(solution)의 자연어(natural language) 설명을 요청함으로써 "역번역된(backtranslated)" 스케치(sketch)를 생성합니다. 그들은 스케치(sketch)가 성능을 크게 향상시키며, 더 긴 스케치(sketch)가 훨씬 더 많은 이점을 제공한다는 것을 발견했습니다.

다음으로, 그들은 특정 스케치(sketch)에 따라 조건화된 대규모 언어 모델(LLM)의 정확도가 0% 또는 100%로 수렴하는 경향을 보임으로써, 단순히 아무 스케치(sketch)가 아니라 좋은 스케치(sketch)를 갖는 것의 중요성을 보여줍니다.

스케치(sketch)가 성능을 향상시키고, 실제로 좋은 스케치(sketch)가 성능을 좌우할 수 있다는 것을 입증한 후, 저자들은 스케치(sketch)의 중요성을 활용하기 위한 검색 알고리즘(search algorithm)을 제시합니다. 주어진 대규모 언어 모델(LLM)과 코딩 문제에 대해, 그들의 알고리즘(algorithm)인 PlanSearch는 다음을 포함합니다.

*   문제에 대한 많은 1차 관찰(first-order observations) 생성
*   대규모 언어 모델(LLM)에 선택된 1차 관찰(first-order observations)을 사용/병합하도록 프롬프트(prompt)하여 2차 관찰(second-order observations)을 생성하기 위한 1차 관찰(first-order observations) 조합을 조합적으로 샘플링(sampling)
*   1차 및 2차 관찰(first and second order observations)을 기반으로 문제를 해결하기 위한 전략(즉, 스케치(sketch))의 자연어(natural language) 설명 생성
*   "당신의 아이디어가 틀렸습니다(Your idea is wrong)"라는 프롬프트(prompt)로 더 많은 솔루션(solution) 스케치(sketch) 생성
*   솔루션(solution) 스케치(sketch)를 기반으로 코드 솔루션(code solution) 생성

PlanSearch는 네 가지 모델(GPT-4o 및 4o-mini, DeepSeek-Coder-V2, Claude-Sonnet-3.5)을 기반으로 세 가지 코딩 벤치마크(benchmark) (LiveCodeBench, HumanEval+, MBPP+)에서 평가됩니다. 저자들은 PlanSearch의 200개 생성 솔루션("PlanSearch@200")을 기본 반복 샘플링(sampling) 200회("Pass@200"), 검색 없는 단일 생성("Pass@1"), 그리고 단순히 스케치(sketch)를 요청한 다음 대규모 언어 모델(LLM)에 제안된 스케치(sketch)를 따르는 코드를 생성하도록 별도로 프롬프트(prompt)하는 IdeaSearch("IdeaSearch@200")와 비교합니다.

PlanSearch는 LiveCodeBench에서 비검색 기준선(non-search baseline)보다 25-35% 포인트, "Pass@200"보다 10-20% 포인트 더 높은 성능을 꾸준히 보여주며 매우 우수하게 작동합니다.

PlanSearch의 핵심은 대규모 언어 모델(LLM)이 코드 자체를 직접 생성하기 전에 문제 해결에 대한 고수준의 "계획" 또는 "개념"을 자연어로 수립하도록 유도하는 것입니다. 기존의 LLM 코드 생성 방식은 종종 토큰(token) 단위로 코드를 생성하며, 이는 문법적으로는 올바르더라도 전체적인 문제 해결 논리나 효율성 측면에서 부족할 수 있습니다. 마치 숙련된 개발자가 코드를 작성하기 전에 설계 문서나 의사 코드를 작성하는 것처럼, PlanSearch는 LLM에게도 이러한 '사전 계획' 과정을 거치게 합니다.

이러한 접근 방식은 여러 가지 중요한 이점을 제공합니다. 첫째, LLM이 문제의 본질을 더 깊이 이해하고 다양한 해결 전략을 탐색할 수 있도록 돕습니다. 코드 공간에서의 검색은 무한대에 가깝고 비효율적일 수 있지만, 자연어로 된 개념 공간에서의 검색은 훨씬 더 의미 있고 효율적입니다. 둘째, 생성된 코드의 견고성과 정확성을 향상시킵니다. LLM이 명확한 계획을 가지고 코드를 작성하면, 단순한 문법적 오류를 넘어선 논리적 오류를 줄일 수 있습니다. 셋째, 복잡한 문제에 대한 LLM의 코드 생성 능력을 크게 확장시킵니다. 복잡한 문제는 여러 단계의 추론과 전략적 사고를 요구하는데, PlanSearch는 이러한 과정을 LLM 내부에 내재화하는 데 기여합니다.

이러한 "개념 중심" 접근 방식은 미래의 소프트웨어 개발 환경에도 큰 영향을 미칠 수 있습니다. 개발자는 LLM에게 단순히 "이 코드를 작성해줘"라고 요청하는 대신, "이 문제를 해결하기 위한 전략을 제안해줘"라고 요청하고, 그 전략을 기반으로 코드를 생성하도록 지시할 수 있게 됩니다. 이는 LLM이 단순한 코드 작성 도구를 넘어, 설계 단계에서부터 개발자를 지원하는 진정한 지능형 조력자로 발전할 수 있음을 시사합니다.

**우리의 견해**
코드 솔루션(code solution) 공간보다는 개념(concept) 공간을 탐색하는 것이 직관적으로 매우 합리적입니다. 컴퓨터 과학 교수 10명 중 9명은 코딩을 시작하기 전에 펜과 종이를 들고 앉아 계획을 스케치(sketch)할 것을 권장합니다. 접근 방식이 틀렸다면 코드를 얼마나 잘 작성하는지는 중요하지 않습니다. 컴퓨터 과학의 전설 도널드 커누스(Donald Knuth)는 "성급한 최적화(premature optimization)는 모든 악의 근원이다"라고 유명하게 말했습니다. 마찬가지로 지난주 인공지능(AI)의 전설 노암 브라운(Noam Brown)은 "올바른 방향으로 일하는 엔지니어 한 명이 잘못된 방향으로 일하는 천재 100명보다 낫다"고 트윗했습니다. 원리는 같습니다. 이러한 종류의 컴퓨터 과학(comp sci) 기본 지식이 대규모 언어 모델(LLM) 성능으로 이어진다는 사실은 어쩐지 위안이 됩니다. – 콜(Cole)

**Gradient의 새로운 소식**

*   대규모 언어 모델(LLM) 챗봇(chatbot)에 빠진 것: 목적 의식
*   데이비다드 달림플(Davidad Dalrymple): 증명 가능한 안전한 인공지능(AI)을 향하여
*   클라이브 톰슨(Clive Thompson): 기술 이야기
*   차세대 멀티모달(Multimodal) AI: 텍스트, 이미지, 오디오의 통합이 가져올 혁신
*   소형 언어 모델(SLM)의 부상: 엣지(Edge) 디바이스에서 AI의 새로운 가능성
*   AI 윤리 거버넌스: 책임감 있는 AI 개발을 위한 글로벌 프레임워크(Framework) 구축

**우리의 눈길을 사로잡은 다른 소식들**

**뉴스**

**애플(Apple), 인공지능(AI) 내장된 새로운 아이폰(iPhone) 공개**
애플(Apple)은 인공지능(AI)이 내장된 새로운 아이폰(iPhone)인 아이폰 16(iPhone 16)을 공개했습니다. 아이폰 16(iPhone 16)은 네 가지 모델로 출시되며, 애플(Apple)의 생성형 인공지능(generative AI) 시스템인 애플 인텔리전스(Apple Intelligence)를 실행하도록 설계되었습니다. 이 폰들은 메시지 분류, 글쓰기 제안, 향상된 시리(Siri) 가상 비서(virtual assistant)와 같은 기능을 갖출 것입니다. 이는 이전 아이폰(iPhone)의 예측 가능한 디자인에서 벗어나 사용자 경험(user experience)을 향상시키기 위한 인공지능(AI) 기능을 도입한 것입니다.

**미국, 유럽연합(EU), 영국 등, 법적 구속력 있는 인공지능(AI) 조약 서명**
미국, 영국, 유럽연합(EU)은 여러 다른 국가들과 함께 인공지능(AI)에 관한 최초의 "법적 구속력 있는(legally binding)" 조약인 인공지능 기본 협약(Framework Convention on Artificial Intelligence)에 서명했습니다. 이 조약은 인공지능(AI)의 사용이 인권, 민주주의, 법치주의와 일치하도록 보장하는 것을 목표로 합니다. 이 조약은 사용자 데이터(user data) 보호, 법률 준수, 투명성 유지 등 인공지능(AI) 시스템이 따라야 할 주요 원칙들을 제시합니다. 조약에 서명하는 각 국가는 이 프레임워크(framework)를 반영하는 적절한 조치를 채택해야 합니다. 이 조약은 법적 구속력이 있지만, 집행은 주로 모니터링(monitoring)에 의존하며, 이는 비교적 약한 형태의 집행으로 간주됩니다.

**OpenAI, ChatGPT 기업용 버전 유료 사용자 100만 명 돌파**
OpenAI는 ChatGPT의 기업용 버전에서 100만 명 이상의 유료 사용자라는 이정표를 달성했으며, 이는 기업들 사이에서 챗봇(chatbot)에 대한 수요가 증가하고 있음을 나타냅니다. 이 수치에는 ChatGPT 팀(Team) 및 엔터프라이즈(Enterprise) 서비스 사용자뿐만 아니라 대학에서 ChatGPT 에듀(Edu)를 사용하는 사람들도 포함됩니다. OpenAI는 1년 전 향상된 기능과 개인 정보 보호 조치를 갖춘 ChatGPT 엔터프라이즈(Enterprise)를 도입하여 수익을 창출하고 인공지능(AI) 개발의 높은 비용을 상쇄했습니다. 유료 기업 사용자 증가가 중요하지만, 얼마나 많은 새로운 기업이 가입했는지는 불분명합니다. OpenAI는 기업 고객당 평균 유료 사용자 수를 공개하지 않았습니다. OpenAI 기업 사용자 대다수는 미국에 기반을 두고 있으며, 미국 외에서는 독일, 일본, 영국이 가장 인기 있는 국가입니다.

**ChatGPT에서 Gemini까지: 인공지능(AI)이 인터넷을 다시 쓰는 방법**
이 기사는 Microsoft, Google, OpenAI와 같은 주요 기업들이 인공지능(AI) 챗봇(chatbot) 기술을 일반 대중에게 더 쉽게 접근할 수 있도록 만드는 방법을 다룹니다. 이 회사들은 Copilot, Gemini, GPT-4o와 같은 대규모 언어 모델(LLM) 프로그램을 개발하고 있습니다. 이러한 인공지능(AI) 도구는 자동 완성(autocomplete)과 유사한 프로그램을 사용하여 언어를 학습하고 언어의 통계적 특성(statistical properties)을 분석하여 이전에 입력된 단어를 기반으로 합리적인 추측을 합니다. 그러나 이러한 인공지능(AI) 도구는 사실의 하드코딩된 데이터베이스(hard-coded database)를 가지고 있지 않으며, 사실성을 보장하기보다는 그럴듯하게 들리는 진술을 생성하는 데 중점을 두기 때문에 거짓 정보를 사실처럼 제시할 수 있다는 점에 유의해야 합니다.

**제이콥 볼(Jacob Wohl)의 비밀 인공지능(AI) 로비 회사 '고객'이라는 빅테크(Big Tech) 기업들, "들어본 적 없다"고 밝혀**
유죄 판결을 받은 사기꾼이자 우익 운동가인 제이콥 볼(Jacob Wohl)과 잭 버크먼(Jack Burkman)은 인공지능(AI) 기반 로비 서비스(lobbying services)를 제공한다고 주장하는 LobbyMatic이라는 회사를 운영해왔습니다. 그러나 LobbyMatic의 고객으로 등재된 많은 주요 기업들이 이 회사에 대해 들어본 적이 없다는 사실이 밝혀졌습니다. LobbyMatic은 인공지능(AI)을 사용하여 기업과 로비스트(lobbyist)가 로비 전략(lobbying strategies)을 수립하고, 청문회와 법안을 분석하며, 입법 진행 상황을 추적하도록 돕는다고 주장합니다. 이 회사는 볼(Wohl)과 버크먼(Burkman)에 의해 "제이 클라인(Jay Klein)"과 "빌 샌더스(Bill Sanders)"라는 가명으로 운영되었습니다. 토요타(Toyota), 바운더리 스톤 파트너스(Boundary Stone Partners), 란테우스(Lantheus)를 고객으로 확보했다고 주장했음에도 불구하고, 이 회사들은 LobbyMatic과의 어떠한 연관성도 부인했습니다. 이 회사는 이후 주요 기업들이 자사 소프트웨어(software)를 사용하고 있음을 시사하는 웹사이트(website) 스크린샷(screenshot)을 삭제했습니다. 플랫폼(platform)을 실제로 사용했던 몇 안 되는 회사 중 하나인 바운더리 스톤 파트너스(Boundary Stone Partners)는 해당 도구의 비효율성으로 인해 계약을 해지했습니다. 볼(Wohl)과 버크먼(Burkman)은 2022년에 중범죄 통신 사기(felony telecom fraud)로 유죄 판결을 받았고, FCC로부터 500만 달러의 벌금을 부과받았습니다.

**자율주행차(Self-Driving Cars)가 수백 마일 떨어진 인간으로부터 도움을 받는 방법**
자율주행차(Self-driving cars)는 완전히 자율적이지 않으며, 종종 어려운 상황을 헤쳐나가기 위해 인간의 도움이 필요합니다. 아마존(Amazon) 소유의 Zoox와 같은 회사들은 기술자들이 장애물이나 익숙하지 않은 시나리오(scenario)에 직면했을 때 자율주행차(self-driving cars)를 원격으로 안내하는 지휘 센터(command centers)를 가지고 있습니다. 기술자들은 경고를 받고 컴퓨터 마우스(computer mouse)를 사용하여 차량에 새로운 경로를 보낼 수 있습니다. 그들은 또한 차량 카메라(camera)의 비디오 피드(video feeds)를 보고 차량 경로를 실시간으로 조정할 수 있습니다. Waymo와 Cruise와 같은 회사들이 인간 지원의 필요성을 인정하기 시작했지만, 고용된 기술자 수나 관련 비용은 공개하지 않았습니다. 원격 지원은 로봇 택시(robot taxis)가 Uber와 Lyft가 운영하는 전통적인 차량 호출 서비스(ride-hailing fleets)를 대체하는 데 어려움을 겪을 수 있는 한 가지 이유입니다. 자율주행 기술(self-driving technology)의 발전에도 불구하고, 안전하고 효율적인 운영을 위해서는 인간의 개입이 여전히 필요합니다.

**혼란스러운 과거에 여전히 시달리는 OpenAI, 성장하려 노력 중**
인공지능(AI) 분야의 주요 기업인 OpenAI는 주요 기업들로부터 투자를 유치하기 위해 경영진과 조직 구조에 상당한 변화를 겪고 있습니다. 이 회사는 저명한 기술 경영진, 허위 정보 전문가, 인공지능(AI) 안전 연구원들을 고용했으며, 전 육군 4성 장군을 포함한 7명의 이사회 구성원을 추가했습니다. OpenAI는 또한 Microsoft, Apple, Nvidia, Thrive와 같은 잠재적 투자자들과 논의 중이며, 잠재적 기업 가치는 1천억 달러에 달합니다. 또한 이 회사는 더 많은 투자자를 유치하기 위해 기업 구조를 변경하는 것을 고려하고 있습니다. 이러한 움직임은 OpenAI가 과거의 갈등을 해결하고 미래 목표에 집중하면서, 인공지능(AI) 산업에서 진지하고 책임감 있는 리더(leader)로서 자신을 보여주려는 노력을 반영합니다.

**구글(Google), 새로운 멀티모달(multimodal) AI 모델 '제미니 울트라 1.5(Gemini 1.5 Ultra)' 발표**
구글(Google)은 텍스트, 이미지, 오디오, 비디오를 동시에 이해하고 추론할 수 있는 최신 멀티모달(multimodal) AI 모델인 '제미니 울트라 1.5(Gemini 1.5 Ultra)'를 공개했습니다. 이 모델은 특히 긴 컨텍스트(context) 창을 지원하여 방대한 양의 정보를 한 번에 처리할 수 있는 능력을 자랑합니다. 이는 복잡한 문서 분석, 긴 비디오 콘텐츠 요약, 여러 모달리티(modality)에 걸친 복합적인 질의응답 등에서 혁신적인 성능을 보여줄 것으로 기대됩니다. 구글(Google)은 이 모델이 의료 진단, 교육 콘텐츠 생성, 복잡한 법률 문서 검토 등 다양한 산업 분야에 적용될 수 있다고 밝혔습니다.

**EU AI 법안 최종 승인, 글로벌 AI 규제 표준화에 영향**
유럽연합(EU)은 인공지능(AI)의 개발 및 사용을 규제하는 포괄적인 법안인 'EU AI 법안'을 최종 승인했습니다. 이 법안은 위험 수준에 따라 AI 시스템을 분류하고, 고위험 AI 시스템에 대해 엄격한 투명성, 안전성, 인권 보호 의무를 부과합니다. 이 법안은 개인 정보 보호, 차별 방지, 알고리즘(algorithm) 투명성 등 AI 윤리적 사용에 대한 글로벌 표준을 제시하며, 다른 국가들의 AI 규제 움직임에도 상당한 영향을 미칠 것으로 예상됩니다. 특히, 생체 인식 시스템 사용 제한, 감성 인식 AI 규제 등 구체적인 조항들이 포함되어 있습니다.

**온디바이스(On-Device) AI의 발전, 스마트폰 및 엣지(Edge) 기기 성능 향상**
최근 몇 년간 온디바이스(on-device) AI 기술이 빠르게 발전하면서, 클라우드(cloud) 기반 처리 없이도 스마트폰, 웨어러블(wearable) 기기, 자율주행차(self-driving car) 등 엣지(edge) 기기에서 복잡한 AI 기능을 수행할 수 있게 되었습니다. 퀄컴(Qualcomm), 애플(Apple) 등 주요 반도체 회사들은 AI 가속기(accelerator)를 내장한 새로운 칩(chip)을 출시하며 이러한 추세를 주도하고 있습니다. 온디바이스(on-device) AI는 데이터 프라이버시(privacy) 강화, 지연 시간(latency) 감소, 네트워크(network) 의존도 저하 등의 이점을 제공하며, 개인화된 AI 비서, 실시간 번역, 고급 이미지 처리 등 다양한 애플리케이션(application)의 가능성을 열고 있습니다.

**AI 기반 신약 개발, 제약 산업의 패러다임 변화 가속화**
인공지능(AI)은 신약 개발 과정을 혁신하며 제약 산업의 판도를 바꾸고 있습니다. AI는 수많은 화합물 데이터(data)를 분석하여 잠재적인 약물 후보 물질을 식별하고, 질병 메커니즘을 예측하며, 임상 시험의 성공률을 높이는 데 기여하고 있습니다. 특히, 복잡한 단백질 구조 예측, 약물 재창출, 환자 맞춤형 치료법 개발 등에서 AI의 역할이 커지고 있습니다. 이러한 기술 발전은 신약 개발에 드는 시간과 비용을 획기적으로 줄이고, 난치병 치료를 위한 새로운 돌파구를 마련할 것으로 기대됩니다. 많은 제약 회사들이 AI 스타트업(startup)과의 협력을 강화하며 이 분야에 대한 투자를 확대하고 있습니다.

**AI 안전성 연구, 초지능(Superintelligence) 정렬(Alignment) 문제에 대한 새로운 접근 모색**
인공지능(AI) 기술이 빠르게 발전함에 따라, 미래의 초지능(superintelligence) 시스템이 인류의 가치와 목표에 부합하도록 정렬(alignment)하는 것에 대한 연구가 중요해지고 있습니다. 최근 연구자들은 AI 시스템이 인간의 의도를 정확하게 이해하고, 예상치 못한 부작용을 최소화하며, 안전하게 행동하도록 설계하는 새로운 방법론을 모색하고 있습니다. 여기에는 AI의 불확실성(uncertainty)을 관리하고, AI의 행동을 설명 가능하게 만들며, 인간의 피드백(feedback)을 효과적으로 통합하는 기술들이 포함됩니다. 이러한 연구는 AI의 잠재적 위험을 완화하고, AI가 인류에게 긍정적인 영향을 미치도록 보장하는 데 필수적입니다.

**국제 AI 거버넌스(Governance) 논의 활발, 유엔(UN) 주도 협력 강화**
인공지능(AI) 기술의 글로벌(global) 영향력이 증대됨에 따라, 국제 사회는 AI 거버넌스(governance) 및 규제에 대한 논의를 더욱 활발히 진행하고 있습니다. 유엔(UN)은 AI의 윤리적 개발과 책임감 있는 사용을 위한 국제적 협력을 강화하기 위해 다양한 이니셔티브(initiative)를 주도하고 있습니다. 여기에는 AI의 군사적 사용 제한, 개발도상국의 AI 접근성 및 역량 강화, AI로 인한 사회적 불평등 해소 등이 포함됩니다. 각국 정부, 민간 기업, 시민 사회 단체들이 참여하는 다자간 포럼(forum)을 통해 AI의 잠재력을 최대한 활용하면서도 위험을 최소화하기 위한 전 세계적인 합의를 도출하려는 노력이 계속되고 있습니다.

**마무리 생각**
이번 호 주제에 대해 할 말이 있으신가요? editor@thegradient.pub으로 이메일을 보내주시면, 다음 뉴스레터에서 독자들의 가장 흥미로운 생각을 공유하는 것을 고려하겠습니다! 피드백(feedback)을 원하시면 Daniel에게 dbashir@hmc.edu로 직접 연락하시거나 트위터(Twitter)를 통해 연락하실 수 있습니다. 이 뉴스레터가 마음에 드셨다면, Substack 구독을 통해 The Gradient에 기부하는 것을 고려해주세요. 이는 이 자원봉사 프로젝트를 유지하는 데 도움이 됩니다.

Gradient의 최신 업데이트를 읽어주셔서 감사합니다!