**LLM-book.com: 1주년을 맞이하며, 더 깊어진 LLM 여정**

이 흥미로운 프로젝트를 시작한 지 약 18개월 만에, 이제 LLM-book.com을 여러분께 선보이게 되어 기쁩니다. 지난 1년여간 많은 독자분의 관심과 성원에 깊이 감사드립니다. 이 책은 아마존(Amazon)과 오라일리(O’Reilly)에서 구매할 수 있으며, 인도에서는 슈로프(Shroff)를 통해서도 만나볼 수 있습니다. 총 425페이지 분량의 이 책은 LLM 구축 및 사용의 주요 직관(intuition)을 설명하는 300개의 독창적인 풀컬러 삽화가 포함되어 있습니다.

모든 코드 예제는 깃허브(Github)에서 확인할 수 있으며, 현재 2.5K 이상의 스타를 기록하며 큰 관심을 받았습니다. 마르텐(Maarten)과 저는 무료 코랩(Colab) 인스턴스에서 모든 예제를 손쉽게 실행할 수 있도록 작은 모델을 선택했습니다.

우리는 초기 반응에 압도되었습니다. 앤드류 응(Andrew Ng)은 이 책을 "대규모 언어 모델(large language model)이 어떻게 구축되는지에 대한 주요 기술을 이해하고자 하는 모든 사람에게 귀중한 자료"라고 평했습니다. 스탯퀘스트(StatQuest)의 제작자 조쉬 스타머(Josh Starmer)는 "지금 당장 읽어야 할 더 중요한 책은 생각할 수 없습니다. 모든 페이지에서 저는 언어 모델(language model) 시대의 성공에 필수적인 것을 배웠습니다"라고 극찬했습니다. 지난 한 해 LLM 생태계의 급격한 변화 속에서도 이 책의 기본 원리는 여전히 강력한 길잡이가 됩니다.

**내용 개요**
이 책은 세 부분으로 나뉩니다. 1부에서는 대규모 언어 모델(large language model)이 어떻게 작동하는지 설명합니다. 특히, 2025년 최신 동향을 반영해 '일러스트레이티드 트랜스포머(The Illustrated Transformer)'의 내용이 더욱 확장되고 현대화되었습니다. 2부는 응용 프로그램(application)에 중점을 두며, 각 장은 특정 유형의 사용 사례(use case)를 다룹니다. 3부는 모델(model)을 미세 조정(fine-tune)하려는 고급 사용자(표현(representation) 또는 생성(generation))를 위한 내용을 다룹니다.

**1장 개요**
1장은 LLM 이해를 위한 길을 닦기 위해 관련 개념의 역사와 개요를 제공합니다. 핵심은 LLM이 단순한 텍스트 생성기(text generator)를 넘어 임베딩(embedding)이나 분류(classification) 등 다양한 문제 해결 시스템을 형성할 수 있다는 점입니다. 임베딩(embedding)은 문서, 문장, 단어 또는 토큰(token) 수준에서 텍스트의 의미를 포착하는 숫자 표현(numeric representation)입니다. 트랜스포머(Transformer) 이전에는 인코더-디코더 RNN(Encoder-Decoder RNN)이 텍스트 생성(text generation) 및 번역(translation) 분야를 선도했습니다. 이 책 전체에서 우리는 언어 모델(language model)을 표현 모델(representation model, 오른쪽 상단에 벡터 아이콘이 있는 녹색) 또는 생성 모델(generative model, 말풍선 아이콘이 있는 분홍색)로 색상 코드를 지정합니다. 최근 멀티모달(multimodal) LLM의 등장으로 임베딩의 중요성이 더욱 커지고 있으며, 1장에서 이 확장 가능성을 조명합니다.

**2장 개요**
2장: 토큰(Tokens)과 임베딩(Embeddings)은 LLM의 두 가지 기본 개념을 분석하여 LLM 이해의 토대를 마련합니다. 특히, 다양한 LLM이 특정 문자열(string)을 토큰화(tokenize)하는 방식과 그 미묘한 차이를 깊이 있게 다룹니다. 이는 유니코드(unicode), 다국어(multi-linguality), 코드(code), 숫자 등 LLM 성능에 영향을 미치는 요인에 대한 민감도를 보여줍니다. 토큰화(tokenization) 시각화 코드는 2장 노트북(notebook)에서 직접 실행 가능합니다. 토크나이저(tokenizer)가 허깅페이스 허브(HuggingFace hub)에 있는 한, 이 코드를 사용하여 다른 모델(model)을 시각화할 수 있습니다.

이 두 개념은 텍스트 LLM을 넘어선 수많은 혁신적인 솔루션(solution)의 문을 엽니다. 이 장에서는 음악 추천 시스템(music recommendation system)에 이 개념들을 사용하는 예시 중 하나를 다룹니다 (노래를 토큰(token)으로, 재생 목록(playlist)을 문장(sentence)으로 취급). 최근 멀티모달 임베딩(multimodal embedding)을 활용한 이미지-텍스트 검색(image-text retrieval) 같은 새로운 응용 분야가 급부상하고 있으며, 2장에서 이 최신 트렌드를 간략히 다룹니다.

이후 장별 개요는 이미 블로그에 게시되었으니, 전체 내용을 확인해 보시길 추천합니다. 이 책을 접하시고 경험이 어떠했는지 알려주시기를 바랍니다! 아, 그리고 다 읽으신 후에는 구매하신 플랫폼이나 굿리즈(Goodreads)에 리뷰를 남겨주시면 정말 감사하겠습니다. 즐거운 독서 되세요!

Language Models & Co.를 읽어주셔서 감사합니다! 새로운 게시물을 무료로 받아보고 제 작업을 지원하려면 구독하세요. 구독