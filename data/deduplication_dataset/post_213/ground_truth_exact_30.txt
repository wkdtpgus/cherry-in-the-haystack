우리는 모두 방대한 양의 텍스트로 훈련된 대규모 언어 모델(large language model)인 GPT 모델을 기반으로 구축된 애플리케이션인 챗GPT(ChatGPT)에 익숙합니다. 챗GPT의 핵심적인 주요 기술은 주어진 입력 시퀀스(sequence)를 기반으로 다음 토큰(token) (단어 또는 단어의 일부)을 예측하는 것입니다. 이러한 토큰(token)의 연속적인 흐름을 생성함으로써 모델은 텍스트를 생성합니다. 이것이 우리가 챗GPT를 생성형 AI(generative AI)라고 부르는 이유입니다.

챗GPT와 같은 대규모 언어 모델(LLM)이 인간 언어의 복잡성을 이해하고 생성하는 능력을 보여주면서, AI의 적용 범위가 단순히 텍스트를 넘어 다양한 데이터 유형으로 확장될 수 있음을 시사했습니다. 이는 생물학적 데이터, 특히 DNA와 같은 "생명의 언어"에도 적용될 수 있다는 기대를 낳았습니다.

한 번에 한 단어씩 텍스트를 생성하는 것이 본질적으로 어려운 것은 아닙니다. 진정한 도전은 단순히 의미가 통할 뿐만 아니라 입력에 적절한 응답을 형성하는 방식으로 텍스트를 생성하는 것입니다. 그리고 물론, 그것은 결코 사소한 일이 아닙니다. 이를 위해서는 모델이 개별 단어뿐만 아니라 단어들이 멀리 떨어져 있을 때에도 그 관계를 고려해야 합니다. 또한 모델은 단어들이 일반적으로 서로 어떻게 관련되는지 파악해야 합니다. 이것이 바로 GPT의 T를 구성하는 "트랜스포머(transformer)" 아키텍처(architecture)를 그토록 강력하게 만든 이유입니다. 트랜스포머는 텍스트 생성의 세계를 영원히 바꾸어 놓았습니다.

트랜스포머 아키텍처의 성공은 단순히 단어 간의 관계를 파악하는 것을 넘어, 복잡한 패턴과 장거리 의존성을 모델링하는 데 탁월한 능력을 보여주었습니다. 이러한 능력은 유전체 데이터와 같이 길고 복잡한 서열에서도 유사한 잠재력을 가질 것으로 예상되며, 생물학적 시스템의 심층적인 이해를 가능하게 합니다.

## 생명의 언어

이제 이 혁신적인 기술을 다른 언어, 어쩌면 가장 중요한 언어인 생명 자체의 언어에 적용한다고 상상해 보세요. DNA는 뉴클레오타이드(nucleotide) (A, C, G, T)로 구성되어 있으며, 이들은 (A는 T와, G는 C와) 짝을 이루어 익숙한 이중 나선(double-helix) 구조를 형성합니다. 이 뉴클레오타이드(nucleotide)는 유전자(gene)와 조절 서열(regulatory sequence)을 형성하며, 염색체(chromosome)에 포장되어 전체적으로 게놈(genome)을 구성합니다. 지구상의 모든 종은 고유한 게놈 서열(genomic sequence)을 가지고 있으며, 사실 각 개체도 고유한 서열을 가지고 있습니다. 그러나 종 내의 차이는 종 간의 차이에 비해 작습니다.

그러나 인간 언어와 달리, DNA는 그 자체로 단순한 문자열이 아닙니다. 이 염기 서열은 유전자 발현을 조절하고, 단백질을 합성하며, 세포의 모든 기능을 지시하는 복잡한 지침서입니다. 게놈의 방대한 양과 그 안에 숨겨진 미묘한 변이들이 생명체의 다양성과 질병 발생에 어떻게 기여하는지 이해하는 것은 여전히 인류의 가장 큰 도전 중 하나입니다. 코딩 영역(coding region)을 넘어 비코딩 영역(non-coding region)의 기능과 상호작용을 파악하는 것은 더욱 복잡합니다. 수십 년간의 연구에도 불구하고, 우리는 여전히 게놈의 상당 부분을 '암흑 물질(dark matter)'로 여기고 있습니다. AI는 이러한 복잡한 생물학적 언어의 문법과 의미를 해독하여, 유전적 변이가 질병에 미치는 영향, 약물 반응성, 진화 과정 등에 대한 새로운 통찰력을 제공할 잠재력을 가지고 있습니다. 개인 맞춤형 의학(personalized medicine)의 시대가 열리면서, 각 개인의 게놈 데이터를 정확하게 해석하는 능력은 더욱 중요해지고 있습니다.

예를 들어 제 게놈(genome)은 대략 30억 개의 염기쌍(base pair)으로 구성되어 있습니다. 만약 이를 지구상의 무작위로 선택된 인간의 게놈(genome)과 비교한다면, 약 300만 개의 염기쌍(base pair) 차이를 발견할 수 있을 것입니다. 이는 단 0.1%에 불과합니다. 제 게놈(genome)을 가장 가까운 친척인 침팬지의 게놈(genome)과 비교하면, 그 차이는 약 3천만 개의 염기쌍(base pair), 즉 약 1%로 증가합니다. 전체적으로 보면 작아 보일 수 있습니다. 만약 두 권의 책이 단 1%만 다르다면 우리는 아마도 그것을 표절이라고 생각할 것입니다. 하지만 이러한 미미한 변화들이 인간의 모든 놀라운 유전적 다양성(genetic diversity)을 설명하며, 심지어 우리를 다른 종과 구분 짓습니다.

최근 몇 년 동안 과학자들은 수천 종의 종을 시퀀싱(sequencing)했습니다. 우리는 우리의 유전적 다양성(genetic diversity)을 점점 더 잘 이해하고 있습니다. 하지만 우리는 여전히 이 언어의 표면만 긁고 있을 뿐입니다.

## Evo 2: DNA를 위한 챗GPT

이러한 비전이 최근 Arc Institute의 Evo 2 모델을 통해 현실로 한 걸음 더 다가섰습니다. Evo 2는 대규모 언어 모델의 성공 원리를 DNA 서열에 적용하여, 생명의 언어를 이해하고 나아가 생성하는 새로운 패러다임을 제시합니다. GPT 모델이 방대한 텍스트를 통해 자연어의 패턴을 학습하듯이, Evo 2는 광범위한 생명체의 유전체 데이터를 학습하여 DNA 서열의 "문법"과 "의미"를 파악합니다.

이 모델은 모든 생명 영역을 아우르는 큐레이션된 게놈 아틀라스(genomic atlas)에서 가져온 9.3조 개의 DNA 염기쌍으로 훈련되었습니다. 비교하자면, GPT-4는 약 6.5조 개의 토큰(token)으로 훈련된 것으로 추정됩니다(OpenAI가 정확한 수치를 공개하지는 않았지만). Meta의 LLaMA 3와 DeepSeek V3는 모두 약 15조 개의 토큰(token)으로 훈련되었습니다. 따라서 훈련 규모 면에서 Evo 2는 선도적인 언어 모델(language model)들과 어깨를 나란히 합니다. 특히 주목할 점은 Evo 2가 광범위한 생물학적 패턴을 포착하기 위해 컨텍스트 윈도우(context window)를 최대 100만 염기쌍까지 확장한다는 것입니다. 이는 DNA 서열 내의 장거리 상호작용과 복잡한 조절 패턴을 포착하는 데 필수적이며, 기존의 짧은 컨텍스트 모델로는 불가능했던 생물학적 통찰력을 제공할 수 있습니다. 아래 패널은 데이터 증강(data augmentation) 및 가중치 부여(weighting) 접근 방식을 보여줍니다.
출처: https://arcinstitute.org/manuscripts/Evo2

그렇다면 Evo 2는 무엇을 할 수 있을까요? 핵심 기능 중 하나는 돌연변이(mutation)의 영향을 예측하는 것입니다. 여러분의 유전자(gene) 중 하나를 예로 들어 봅시다. 대부분의 유전자(gene)는 세포가 생명의 근본적인 구성 요소인 단백질(protein)을 만드는 데 사용하는 지침을 포함하고 있습니다. (이 단백질(protein)이 기능적 구조로 접히는 방식은 DeepMind의 AlphaFold가 성공적으로 다룬 또 다른 어려운 예측 작업입니다.) 이제 그 서열을 변경하면 결과가 어떻게 달라질까요? 일부 변이(variant)는 치명적이고, 다른 일부는 해로우며, 많은 변이(variant)는 중립적이고, 드물게는 유익한 변이(variant)도 있습니다. 문제는 어떤 것이 어떤 것인지 알아내는 것입니다.

이것이 바로 Evo 2가 빛을 발하는 지점입니다. 다양한 변이 예측 작업에서 Evo 2는 다른 고도로 전문화된 모델의 기존 기준선(baseline)과 일치하거나 이를 능가합니다. Evo 2의 이러한 예측 능력은 놀랍게도 인간의 변이 데이터로 명시적으로 훈련되지 않았음에도 발휘됩니다. 대신, Evo 2는 다양한 종과 컨텍스트에 걸쳐 "정상적인" DNA 서열이 어떻게 생겼는지에 대한 진화적 제약(evolutionary constraint)을 학습합니다. 이는 마치 언어 모델이 전 세계의 다양한 텍스트를 읽고 '올바른' 문장의 패턴을 배우는 것과 유사합니다. 모델은 대규모 비지도 학습(unsupervised learning)을 통해 게놈 서열 내의 미묘한 통계적 규칙과 보존된 영역을 파악하며, 이를 통해 특정 변이가 생물학적 기능에 미칠 영향을 추론할 수 있게 됩니다. 이는 생물학적 "적합성 지형(fitness landscape)"을 탐색하여 최적의 경로를 찾아내는 데 중요한 역할을 합니다.

코딩 영역(coding region) 내 변이 병원성(variant pathogenicity)의 제로샷(zero-shot) 평가.
출처: https://arcinstitute.org/manuscripts/Evo2

## 생물학을 이해하는 것에서 창조하는 것으로

Evo 2를 놀랍게 만드는 것은 특정 서열을 이전에 본 적이 없더라도 DNA 서열이 "이상하다"고 느껴질 때를 알 수 있는 능력입니다. 마치 챗GPT(ChatGPT)가 자연스러운 영어가 어떻게 들리는지 아는 것과 같습니다. 하지만 더 나아가, Evo 2는 원본 훈련 데이터로부터 이동성 유전 요소(mobile genetic element), 조절 모티프(regulatory motif), 단백질 2차 구조(protein secondary structure) 등과 같은 생물학적 특징(biological feature)을 직접 학습했습니다. 이는 놀라운 일입니다. 왜냐하면 단순히 DNA 서열을 읽는 것을 넘어, 해당 정보가 훈련 데이터의 일부가 아니었음에도 불구하고 고차 구조 정보를 포착하기 때문입니다.

다시 한번, 챗GPT(ChatGPT)와의 비교가 도움이 됩니다. 챗GPT(ChatGPT)는 문법 규칙을 명시적으로 배운 적이 없더라도 올바른 문법으로 문장을 완성할 수 있습니다. 마찬가지로, Evo 2는 유전자(gene)나 단백질(protein)이 무엇인지 배운 적이 없더라도 유효한 생물학적 구조로 게놈(genome)의 한 부분을 완성할 수 있습니다.

마지막으로, GPT 모델이 새로운 콘텐츠를 생성할 수 있는 것처럼 (그래서 "생성형 AI(generative AI)"라는 이름이 붙었습니다), Evo 2는 새로운 DNA 서열을 생성할 수 있습니다. 여기에서 우리는 생물학을 이해하는 것에서 생물학을 창조하는 것으로 나아갑니다. Evo 2는 미토콘드리아 게놈(mitochondrial genome), 박테리아 게놈(bacterial genome), 그리고 효모 게놈(yeast genome)의 일부를 생성하는 데 사용되었습니다. 이는 바이오 제조(biomanufacturing), 탄소 포집(carbon capture), 또는 약물 합성(drug synthesis)을 위한 유기체 설계를 가능하게 하여 합성 생물학(synthetic biology)에서 매우 유용할 수 있습니다.

이러한 생성 능력은 합성 생물학(synthetic biology) 분야에 혁명적인 변화를 가져올 수 있습니다. 기존의 생물학적 시스템 설계는 시행착오(trial-and-error) 방식에 크게 의존했지만, Evo 2와 같은 모델은 기능적일 가능성이 높은 DNA 서열을 예측하고 생성함으로써 '설계-구축-테스트-학습(design-build-test-learn)' 사이클의 첫 단계를 비약적으로 가속화할 수 있습니다. 예를 들어, 특정 단백질을 과발현시키거나, 특정 대사 경로를 최적화하여 바이오 연료 생산 효율을 높이는 등, 산업용 미생물 균주(industrial microbial strain)를 설계하는 데 활용될 수 있습니다.

하지만 강력한 기술에는 책임이 따릅니다. 생성형 생물학의 발전은 생물학적 무기 개발과 같은 잠재적 오용(misuse)에 대한 윤리적, 보안적 우려를 낳습니다. 따라서 Evo 2와 같은 모델의 개발 및 배포에는 엄격한 윤리적 가이드라인과 규제 프레임워크가 필수적입니다. 안전장치와 책임 있는 연구 개발이 병행되어야만, 이 기술이 인류에게 진정한 이점을 가져올 수 있을 것입니다.

Evo 2는 아직 초기 단계에 있으며, 생성된 DNA 서열이 실험적으로 검증되어야 한다는 한계는 여전합니다. 그러나 불과 몇 년 만에 GPT-3에서 GPT-4, 그리고 더욱 발전된 모델로 진화한 언어 모델의 역사를 볼 때, 생성형 생물학 분야의 발전 속도 또한 상상 이상일 것입니다. 이는 DNA 언어 모델이 단순히 서열을 예측하는 것을 넘어, 생명 현상의 근본적인 원리를 이해하고 조작하는 데 핵심적인 역할을 할 것임을 시사합니다.

Evo 2가 생성한 원핵생물 게놈 서열(prokaryotic genomic sequence)에서 발견된 예시 단백질의 AlphaFold 3 구조 예측.
출처: https://arcinstitute.org/manuscripts/Evo2

이 모든 것이 충분하지 않다면: Evo 2는 오픈소스(open-source), 오픈웨이트(open-weight) 모델입니다. 모델 매개변수(model parameter), 사전 훈련 코드, 추론 코드, 그리고 훈련에 사용된 전체 데이터셋(dataset)을 다운로드할 수 있습니다. 그리고 속도를 고려해 보세요. Evo 1은 불과 몇 달 전인 2024년 11월에 출시되었습니다. 이미 놀라운 성과였습니다. 하지만 Evo 1은 약 3천억 개의 토큰(token)으로 원핵생물 게놈(prokaryotic genome)만으로 훈련되었고, 131,000 염기쌍(base pair)의 컨텍스트 윈도우(context window)를 가졌으며, 기능도 비교적 제한적이었습니다. 이제 불과 몇 달 후, 훈련 규모를 30배 확장하고, 컨텍스트 윈도우(context window)를 8배 늘리고, 완전히 새로운 기능을 도입한 새로운 모델이 탄생했습니다! Evo 1에서 Evo 2로의 빠른 진화는 언어 모델(language model)에서 우리가 목격한 놀랍도록 빠른 개선을 반영합니다. 언어 모델(language model)은 불과 몇 년 만에 잦은 환각(hallucination) 현상에서 인간 수준의 능숙도로 복잡한 작업을 처리하는 수준으로 발전했습니다. GPT가 언어 생성에 혁명을 일으킨 것처럼, 이러한 DNA 언어 모델(DNA language model)은 생명 자체의 코드를 이해하는 방식을 변화시키고 있습니다. 생물학의 미래는 그 어느 때보다 흥미진진해 보입니다.

Evo 2의 등장은 생물학 연구의 새로운 시대를 예고합니다. 우리는 이제 게놈 서열뿐만 아니라 단백질 구조, 대사체 데이터, 표현형 정보 등 다양한 생물학적 데이터를 통합하는 다중 모달(multi-modal) AI 모델의 등장을 기대할 수 있습니다. 이러한 통합적 접근 방식은 질병 진단 및 치료, 신약 개발, 지속 가능한 농업, 환경 보호 등 전례 없는 혁신을 가능하게 할 것입니다. 생명의 코드를 해독하고 재설계하는 여정은 이제 막 시작되었으며, AI는 이 여정의 가장 강력한 동반자가 될 것입니다.

## CODA

이것은 두 가지 구독 유형을 가진 뉴스레터입니다. 유료 버전으로 전환하는 것을 강력히 추천합니다. 모든 콘텐츠는 무료로 유지되지만, 모든 재정적 지원은 EPFL AI 센터 활동에 직접적으로 자금을 지원합니다.

연락을 유지하려면 다음 방법으로 저를 찾을 수 있습니다.
소셜 미디어: 저는 주로 LinkedIn을 사용하지만, Mastodon, Bluesky, X에서도 활동합니다.
팟캐스트: 저는 EPFL AI 센터에서 "Inside AI"라는 AI 팟캐스트(Apple Podcasts, Spotify)를 진행하고 있으며, 저보다 훨씬 똑똑한 분들과 이야기할 수 있는 특권을 누리고 있습니다.

Engineering Prompts는 독자 지원 출판물입니다. 새로운 게시물을 받고 제 작업을 지원하려면 무료 또는 유료 구독자가 되는 것을 고려해 보세요.

구독하기