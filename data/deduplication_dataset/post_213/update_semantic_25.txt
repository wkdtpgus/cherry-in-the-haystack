우리는 방대한 양의 텍스트로 훈련된 대규모 언어 모델(large language model)인 GPT 모델을 기반으로 구축된 챗GPT(ChatGPT) 애플리케이션에 매우 익숙합니다. 이 인공지능은 출시 이후 전 세계적으로 폭발적인 관심을 불러일으키며, 일상생활과 업무 환경에 깊숙이 파고들어 우리의 소통 방식과 정보 접근 방식을 근본적으로 변화시켰습니다. 챗GPT의 능력은 단순한 정보 검색을 넘어, 창의적인 글쓰기, 복잡한 문제 해결, 심지어 코딩에 이르기까지 다양한 분야에서 새로운 가능성을 제시하고 있습니다. 이 시스템의 근본적인 작동 원리는 제공된 문자열(string)을 바탕으로 뒤따를 개별 요소(element) (글자 또는 글자 묶음)를 추론하는 데 있습니다. 이러한 요소들의 연속적인 생성을 통해 모델은 의미 있는 텍스트를 구성하며, 이러한 작동 방식 때문에 해당 인공지능은 '생성적 인공지능(generative artificial intelligence)'으로 분류됩니다.

텍스트를 한 단어씩 순차적으로 만들어내는 과정 자체가 본질적으로 복잡한 작업은 아닙니다. 진정한 난관은 단순히 문맥에 맞을 뿐만 아니라, 주어진 정보에 정확히 부합하는 답변을 구성하는 방식으로 글을 만들어내는 데 있습니다. 그리고 물론, 이러한 역량은 결코 쉽게 달성되는 것이 아닙니다. 이를 위해 시스템은 개별 어휘뿐만 아니라, 서로 상당히 떨어져 위치한 어휘들 사이의 상호 연관성까지 파악해야 합니다. 또한, 모델은 단어들이 일반적으로 어떻게 연결되고 의미를 형성하는지에 대한 깊은 이해를 구축해야 합니다. 이러한 복잡한 요구사항을 해결하며 GPT의 'T'를 구성하는 "트랜스포머(transformer)" 아키텍처(architecture)가 그토록 강력한 혁신을 가져온 배경입니다. 트랜스포머는 텍스트 생성의 패러다임을 영원히 바꾸어 놓았으며, 인공지능 언어 처리 분야에 새로운 지평을 열었습니다. 특히 어텐션 메커니즘(attention mechanism)을 통해 입력 시퀀스 내의 모든 요소 간의 중요도와 관계를 효율적으로 계산함으로써, 기존 모델들이 해결하기 어려웠던 장거리 의존성(long-range dependencies) 문제를 극복하고 훨씬 더 일관성 있고 맥락에 맞는 텍스트를 생성할 수 있게 되었습니다.

Engineering Prompts는 독자 지원 출판물입니다. 새로운 게시물을 받고 제 작업을 지원하려면 무료 또는 유료 구독자가 되는 것을 고려해 보세요.

구독하기

## 생명의 언어: 유전체 암호의 이해

이제 이러한 혁신적인 기술을 또 다른 언어, 어쩌면 가장 근원적인 언어인 생명 자체의 언어에 적용하는 상상을 해봅시다. 유전 물질인 DNA는 아데닌(A), 시토신(C), 구아닌(G), 티민(T)이라는 염기 단위로 이루어져 있으며, 이들은 각각 특정 쌍(A-T, G-C)을 형성하여 우리가 잘 아는 나선형 이중 가닥 구조를 이룹니다. 이러한 염기 단위들은 유전 암호(genetic code)와 특정 기능 제어 영역을 형성하며, 이들이 염색체 내에 압축되어 생명체의 전체 유전체(hereditary material)를 이룹니다. 지구상의 모든 종은 고유한 유전체 서열(genomic sequence)을 가지고 있으며, 사실 각 개체 또한 그들만의 독특한 서열을 지닙니다. 그러나 종 내의 개체 간 차이는 종 간의 차이에 비해 상대적으로 미미합니다.

예를 들어, 제 유전체(genome)는 대략 30억 개의 염기쌍(base pair)으로 구성되어 있습니다. 만약 이를 지구상의 무작위로 선택된 다른 인간의 유전체와 비교한다면, 약 300만 개의 염기쌍 차이를 발견할 수 있을 것입니다. 이는 전체의 단 0.1%에 불과합니다. 제 유전체를 가장 가까운 친척인 침팬지의 유전체와 비교하면, 그 차이는 약 3천만 개의 염기쌍, 즉 약 1%로 증가합니다. 전체적으로 보면 작아 보일 수 있습니다. 만약 두 권의 책이 단 1%만 다르다면 우리는 아마도 그것을 표절이라고 생각할 것입니다. 하지만 이러한 미미한 변화들이 인간의 모든 놀라운 유전적 다양성(genetic diversity)을 설명하며, 심지어 우리를 다른 종과 구분 짓는 결정적인 역할을 합니다. DNA는 단순히 정보를 저장하는 매체를 넘어, 생명체의 설계도이자 운영 체제이며, 진화의 역사를 담고 있는 거대한 도서관과 같습니다. 유전체의 각 부분은 복잡한 상호작용을 통해 생명 현상을 조절하며, '유전체 암흑 물질(genomic dark matter)'이라고 불리는 비코딩 DNA(non-coding DNA) 영역조차도 유전자 발현 조절이나 염색체 구조 유지에 중요한 역할을 하는 것으로 밝혀지고 있습니다. 이처럼 방대한 유전체 정보를 해독하고 이해하는 것은 생물학의 궁극적인 목표 중 하나입니다.

최근 몇 년 동안 과학자들은 수천 종의 유전체를 시퀀싱(sequencing)했습니다. 우리는 유전적 다양성에 대한 이해를 꾸준히 넓혀가고 있지만, 여전히 이 생명의 언어는 우리가 그 표면만을 훑고 있을 뿐입니다. 유전체 데이터가 폭발적으로 증가하면서, 이를 효과적으로 분석하고 의미 있는 패턴을 추출할 수 있는 새로운 도구의 필요성이 절실해졌습니다.

## Evo 2: DNA를 위한 거대 언어 모델의 등장

DNA를 위한 챗GPT(ChatGPT)라는 이 비전은 Arc Institute의 Evo 2 모델로 현실이 되었습니다. 불과 한 달 전 출시된 이 모델은 생명 공학 분야의 놀라운 업적입니다. 해당 모델은 모든 생물학적 범주를 포괄하는 정제된 유전체 지도에서 추출된 9.3조 개에 달하는 DNA 염기쌍 쌍으로 학습되었습니다. 이는 GPT-4가 약 6.5조 개의 토큰(token)으로 훈련된 것으로 추정되는(OpenAI가 정확한 수치를 공개하지는 않았지만) 것과 비교할 때, Meta의 LLaMA 3와 DeepSeek V3가 약 15조 개의 토큰으로 훈련된 것과 유사한 규모입니다. 따라서 훈련 규모 면에서 Evo 2는 선도적인 언어 모델들과 어깨를 나란히 하며, 유전체 데이터 처리 분야에서 전례 없는 규모의 학습을 수행했습니다. 이 모델은 넓은 범위의 생명 현상 패턴을 인지하기 위해, 문맥 처리 범위(context processing range)를 최대 백만 개의 염기쌍까지 늘렸습니다. 이러한 광범위한 컨텍스트 윈도우는 복잡한 유전체 조절 네트워크나 멀리 떨어진 유전자 간의 상호작용을 이해하는 데 필수적입니다.

아래 패널은 데이터 증강(data augmentation) 및 가중치 부여(weighting) 접근 방식을 보여줍니다.
출처: https://arcinstitute.org/manuscripts/Evo2

그렇다면 Evo 2는 구체적으로 무엇을 할 수 있을까요? 주요 역량 중 하나는 유전자 변형(genetic alteration)이 미치는 결과를 미리 알아내는 것입니다. 여러분의 유전자 중 하나를 예로 들어 봅시다. 대부분의 유전자는 세포가 생명의 근본적인 구성 요소인 단백질(protein)을 만드는 데 사용하는 지침을 포함하고 있습니다. (이 단백질이 기능적 구조로 접히는 방식은 DeepMind의 AlphaFold가 성공적으로 다룬 또 다른 어려운 예측 작업입니다.) 이제 그 서열을 변경하면 결과가 어떻게 달라질까요? 일부 변이(variant)는 생명에 치명적이고, 다른 일부는 해로우며, 많은 변이는 중립적이고, 드물게는 유익한 변이도 있습니다. 문제는 어떤 것이 어떤 것인지 정확히 알아내는 것입니다.

이것이 바로 Evo 2가 탁월한 성능을 발휘하는 지점입니다. 다양한 유전 변이 예측 과업에서 Evo 2는 기존의 고도로 특화된 시스템들이 제시하는 표준 성능과 동등하거나 그 이상을 보입니다. 다시 말해, 어떤 돌연변이(mutation)가 병원성(pathogenic)일 가능성이 있는지, 또는 잘 알려진 암 유전자(cancer gene) (유방암과 관련된 BRCA1과 같은)의 어떤 변이가 임상적으로 중요한지 예측할 수 있습니다. 놀랍게도 Evo 2는 인간 변이 데이터로 훈련되지 않았습니다. 표준 인간 참조 게놈(reference genome)으로만 훈련되었습니다. 그러나 게놈 서열에 대한 진화적 제약(evolutionary constraint)을 학습한 것으로 보이기 때문에 인간에게 어떤 돌연변이가 해로운지 추론할 수 있습니다. Evo 2는 종과 컨텍스트(context)에 걸쳐 "정상적인" DNA가 어떻게 생겼는지 이해하는 능력을 갖추고 있습니다. 이는 개인 맞춤형 의학(personalized medicine) 분야에 혁명적인 잠재력을 제공합니다. 특정 환자의 유전체 정보와 Evo 2의 예측 능력을 결합하면, 질병 위험도를 보다 정확하게 평가하고, 최적의 치료법을 선택하는 데 중요한 정보를 제공할 수 있을 것입니다.

코딩 영역(coding region) 내 변이 병원성(variant pathogenicity)의 제로샷(zero-shot) 평가.
출처: https://arcinstitute.org/manuscripts/Evo2

## 생물학을 이해하는 것을 넘어 창조의 영역으로

Evo 2의 경이로운 점은 특정 유전 부위를 이전에 접한 적이 없더라도, 해당 DNA 배열이 '비정상적'이라고 감지할 수 있는 능력에 있습니다. 이는 마치 챗GPT가 자연스러운 영어가 어떻게 들리는지 아는 것과 같은 이치입니다. 하지만 더 나아가, Evo 2는 원본 훈련 데이터로부터 이동성 유전 요소(mobile genetic element), 조절 모티프(regulatory motif), 단백질 2차 구조(protein secondary structure) 등과 같은 생물학적 특징(biological feature)을 직접 학습했습니다. 이는 놀라운 일입니다. 왜냐하면 단순히 DNA 서열을 읽는 것을 넘어, 해당 정보가 훈련 데이터의 일부가 아니었음에도 불구하고 고차 구조 정보를 포착하기 때문입니다. 이러한 능력은 생명체가 작동하는 복잡한 원리를 모델이 스스로 발견하고 내재화했음을 의미하며, 이는 생물학적 시스템에 대한 우리의 이해를 한 차원 높이는 중요한 진전입니다.

이와 유사하게, Evo 2는 유전자나 단백질의 개념을 명시적으로 학습하지 않았음에도 불구하고, 유효한 생체 구조를 갖춘 유전체의 일부를 구성할 수 있습니다. 이는 마치 챗GPT가 문법 규칙을 명시적으로 배우지 않고도 올바른 문법으로 문장을 완성할 수 있는 것과 같은 맥락입니다. 마지막으로, GPT 모델이 새로운 콘텐츠를 생성할 수 있는 것처럼 (그래서 "생성형 AI"라는 이름이 붙었습니다), 이 모델은 이전에 존재하지 않던 DNA 염기 배열을 만들어낼 수 있습니다. 여기에서 우리는 생물학을 이해하는 것에서 생물학을 창조하는 것으로 나아갑니다. Evo 2는 미토콘드리아 게놈(mitochondrial genome), 박테리아 게놈(bacterial genome), 그리고 효모 게놈(yeast genome)의 일부를 생성하는 데 사용되었습니다. 이는 바이오 제조(biomanufacturing), 탄소 포집(carbon capture), 또는 약물 합성(drug synthesis)을 위한 유기체 설계를 가능하게 하여 합성 생물학(synthetic biology)에서 매우 유용할 수 있습니다. 예를 들어, 특정 대사 경로를 최적화하여 바이오 연료 생산 효율을 높이거나, 환경 오염 물질을 분해하는 미생물을 설계하는 등 다양한 응용 가능성을 가집니다.

그러나 챗GPT와 마찬가지로 Evo 2도 주요한 한계점을 가지고 있습니다. 생체 내에서 가능성이 있는 DNA 배열을 만들어낸다고 해서, 실험적인 확인 과정 없이 그 배열이 생물학적으로 실제 작동할 것이라고 단언할 수는 없습니다. 생성된 DNA 서열이 세포 내에서 예상대로 기능하고, 독성 반응을 일으키지 않으며, 안정적으로 유지되는지 확인하는 것은 여전히 복잡하고 시간 소모적인 실험 과정이 필요합니다. DNA 생성은 여전히 Evo 2의 비교적 제한된 측면으로 보입니다. 하지만 언어 모델이 불과 몇 년 만에 GPT-3에서 LLaMA 3 또는 DeepSeek으로 어떻게 진화했는지 고려한다면, 생성형 생물학(generative biology)에 무엇이 기다리고 있을지 쉽게 상상할 수 있습니다. AI 기반의 설계-구축-테스트(design-build-test) 사이클이 가속화됨에 따라, 생물학적 시스템의 예측 및 조작 능력이 기하급수적으로 발전할 것입니다.

Evo 2가 생성한 원핵생물 게놈 서열(prokaryotic genomic sequence)에서 발견된 예시 단백질의 AlphaFold 3 구조 예측.
출처: https://arcinstitute.org/manuscripts/Evo2

이 모든 것이 충분하지 않다면, Evo 2는 오픈소스(open-source), 오픈웨이트(open-weight) 모델이라는 점에 주목해야 합니다. 모델 매개변수(model parameter), 사전 훈련 코드, 추론 코드, 그리고 훈련에 사용된 전체 데이터셋(dataset)을 다운로드할 수 있습니다. 이는 과학적 투명성과 협력을 촉진하고, 전 세계 연구자들이 이 강력한 도구를 활용하여 새로운 발견을 할 수 있도록 문을 열어준다는 점에서 매우 중요합니다. 그리고 속도를 고려해 보세요. Evo 1은 불과 몇 달 전인 2024년 11월에 출시되었습니다. 이미 놀라운 성과였지만, Evo 1은 약 3천억 개의 토큰으로 원핵생물 게놈(prokaryotic genome)만으로 훈련되었고, 131,000 염기쌍의 컨텍스트 윈도우를 가졌으며, 기능도 비교적 제한적이었습니다. 이제 불과 몇 달 후, 훈련 규모를 30배 확장하고, 컨텍스트 윈도우를 8배 늘리고, 완전히 새로운 기능을 도입한 새로운 모델이 탄생했습니다! Evo 1에서 Evo 2로의 빠른 진화는 언어 모델에서 우리가 목격한 놀랍도록 빠른 개선을 반영합니다. 언어 모델은 불과 몇 년 만에 잦은 환각(hallucination) 현상에서 인간 수준의 능숙도로 복잡한 작업을 처리하는 수준으로 발전했습니다. 마치 GPT 계열 모델이 인간 언어 생성 분야에 지각 변동을 가져왔듯이, 이러한 유전체 언어 모델(genomic language model)들은 생명의 근본적인 암호를 해독하는 방식을 혁신하고 있습니다. 생물학 연구의 미래는 과거 어느 때보다도 밝고 기대됩니다. 이러한 발전 속도는 마치 컴퓨터 산업의 무어의 법칙(Moore's Law)처럼 생물학 분야에 적용될 수 있음을 시사하며, AI와 생명 과학의 융합은 바이오 기술의 민주화를 가속화하고 인류가 직면한 다양한 난제 해결에 기여할 것입니다.

## CODA

이것은 두 가지 구독 유형을 가진 뉴스레터입니다. 유료 버전으로 전환하는 것을 강력히 추천합니다. 모든 콘텐츠는 무료로 유지되지만, 모든 재정적 지원은 EPFL AI 센터 활동에 직접적으로 자금을 지원합니다.

연락을 유지하려면 다음 방법으로 저를 찾을 수 있습니다.
소셜 미디어: 저는 주로 LinkedIn을 사용하지만, Mastodon, Bluesky, X에서도 활동합니다.
팟캐스트: 저는 EPFL AI 센터에서 "Inside AI"라는 AI 팟캐스트(Apple Podcasts, Spotify)를 진행하고 있으며, 저보다 훨씬 똑똑한 분들과 이야기할 수 있는 특권을 누리고 있습니다.

Engineering Prompts는 독자 지원 출판물입니다. 새로운 게시물을 받고 제 작업을 지원하려면 무료 또는 유료 구독자가 되는 것을 고려해 보세요.

구독하기