우리는 모두 방대한 양의 텍스트로 훈련된 대규모 언어 모델(large language model)인 GPT 모델을 기반으로 구축된 애플리케이션인 챗GPT(ChatGPT)에 익숙합니다. 챗GPT의 핵심적인 주요 기술은 주어진 입력 시퀀스(sequence)를 기반으로 다음 토큰(token) (단어 또는 단어의 일부)을 예측하는 것입니다. 이러한 토큰(token)의 연속적인 흐름을 생성함으로써 모델은 텍스트를 생성합니다. 이것이 우리가 챗GPT를 생성형 AI(generative AI)라고 부르는 이유입니다.

물론, 텍스트를 한 번에 한 단어씩 만들어내는 것 자체가 근본적으로 어려운 일은 아닙니다. 진정한 난제는 단순히 문법적으로 맞는 것을 넘어, 주어진 입력에 대한 적절한 응답을 구성하고 의미론적으로 일관된 텍스트를 생성하는 것입니다. 이러한 작업은 결코 간단하지 않습니다. 이를 위해서는 모델이 개별 단어의 의미뿐만 아니라, 서로 멀리 떨어져 있는 단어들 사이의 복잡한 관계까지도 이해해야 합니다. 또한 모델은 단어들이 일반적으로 어떻게 연결되고 상호작용하는지에 대한 깊은 통찰력을 가져야 합니다. 이 지점에서 GPT의 'T'를 의미하는 "트랜스포머(transformer)" 아키텍처(architecture)가 엄청난 위력을 발휘합니다. 트랜스포머는 자연어 처리(natural language processing) 분야, 특히 텍스트 생성 방식에 혁명적인 변화를 가져왔습니다. 최근에는 트랜스포머 기반의 모델들이 단순한 텍스트 생성을 넘어 이미지, 오디오, 비디오 등 다양한 형태의 데이터를 이해하고 생성하는 멀티모달(multimodal) 능력까지 선보이며 그 활용 범위를 더욱 넓히고 있습니다.

Engineering Prompts는 독자 여러분의 지원으로 운영되는 출판물입니다. 최신 소식을 받아보고 저의 작업을 격려해 주시려면, 무료 또는 유료 구독자가 되어주시면 감사하겠습니다.

구독하기

## 생명의 언어, 그 심층적인 구조

이제 이러한 혁신적인 기술을 또 다른 언어, 즉 생명 자체의 근원적인 언어에 적용하는 시나리오를 상상해 봅시다. DNA는 아데닌(A), 시토신(C), 구아닌(G), 티민(T)이라는 네 가지 핵산 염기로 이루어져 있으며, 이들은 특정 규칙(A-T, G-C)에 따라 결합하여 전형적인 이중 나선(double-helix) 형태를 이룹니다. 이 핵산 염기(nucleotide)들은 유전자(gene)와 유전자 발현 조절 서열(regulatory sequence)을 구성하며, 이들이 염색체(chromosome) 내에 응축되어 전체 생명체의 게놈(genome)을 형성합니다. 지구상의 모든 생물 종은 물론, 각 개체 또한 고유한 게놈 서열(genomic sequence)을 보유하고 있습니다. 다만, 같은 종 내에서의 차이는 종 간의 차이에 비해 상대적으로 미미한 수준입니다.

예시를 들어 설명하자면, 저의 게놈(genome)은 약 30억 개의 염기쌍(base pair)으로 구성되어 있습니다. 만약 이를 전 세계 임의의 한 인간의 게놈(genome)과 비교한다면, 대략 300만 개의 염기쌍(base pair)에서 차이를 발견할 수 있을 것입니다. 이는 전체의 단 0.1%에 해당합니다. 반면, 저의 게놈(genome)을 가장 가까운 유전적 친척인 침팬지의 게놈(genome)과 비교하면, 그 차이는 약 3천만 개의 염기쌍(base pair)으로 증가하며, 이는 전체의 약 1%를 차지합니다. 이러한 수치들은 전체적으로는 작게 느껴질 수 있습니다. 만약 두 권의 책이 단 1%만 다르다면 우리는 아마도 이를 표절로 간주할 것입니다. 그러나 생물학적 관점에서 이러한 미세한 변화들은 인간의 놀라운 유전적 다양성(genetic diversity)을 설명할 뿐만 아니라, 우리를 다른 종과 명확하게 구분 짓는 결정적인 요소가 됩니다.

최근 수년간 과학계는 수천 종에 달하는 생명체의 게놈을 시퀀싱(sequencing)하며 유전적 다양성에 대한 이해를 심화시켜 왔습니다. 그러나 우리가 DNA라는 언어의 심층적인 의미를 완전히 파악하기까지는 아직 갈 길이 멀며, 아직 표면적인 부분만을 탐색하고 있을 뿐입니다. 특히, 유전자 정보를 직접적으로 담지 않는 비암호화 DNA(non-coding DNA) 영역의 중요성과 후성유전학(epigenetics)적 변형이 유전자 발현에 미치는 영향 등은 여전히 활발히 연구되고 있는 분야이며, 이 분야의 깊은 이해는 정밀 의학(precision medicine)과 개인 맞춤형 치료법 개발에 필수적입니다.

## Evo 2: DNA를 위한 챗GPT, 생명 코드를 해독하다

DNA를 위한 챗GPT(ChatGPT)라는 원대한 비전은 Arc Institute가 개발한 Evo 2 모델을 통해 구체적인 현실이 되었습니다. 불과 한 달 전 공개된 이 모델은 경이로운 공학적 성과를 대표합니다. 이 모델은 모든 생명체 영역을 포괄하는 엄선된 게놈 아틀라스(genomic atlas)에서 수집된 9.3조 개의 DNA 염기쌍(base pair) 데이터를 활용하여 학습되었습니다. 이 훈련 규모를 비교해 보면, GPT-4가 약 6.5조 개의 토큰(token)으로 훈련된 것으로 추정되며(OpenAI는 정확한 수치를 공개하지 않았습니다), Meta의 LLaMA 3와 DeepSeek V3는 모두 약 15조 개의 토큰(token)으로 훈련되었습니다. 이처럼 Evo 2는 훈련 데이터의 양적인 측면에서 선도적인 언어 모델(language model)들과 견줄 만한 수준에 도달했습니다.

Evo 2는 광범위한 생물학적 패턴을 파악하기 위해 컨텍스트 윈도우(context window)를 최대 100만 염기쌍(base pair)까지 확장했습니다. 이는 장거리 유전자 조절(long-range gene regulation)이나 복잡한 유전적 상호작용을 이해하는 데 필수적인 요소입니다. 아래 패널은 모델의 데이터 증강(data augmentation) 및 가중치 부여(weighting) 전략을 보여줍니다.
출처: https://arcinstitute.org/manuscripts/Evo2

그렇다면 Evo 2는 구체적으로 어떤 능력을 발휘할 수 있을까요? 핵심 기능 중 하나는 DNA 서열의 미세한 변화, 즉 돌연변이(mutation)가 생물학적 기능에 미치는 영향을 예측하는 것입니다. 예를 들어, 우리 몸의 유전자(gene) 중 하나를 생각해 봅시다. 대부분의 유전자는 세포가 생명의 필수 구성 요소인 단백질(protein)을 합성하는 데 필요한 설계도를 담고 있습니다. (이 단백질이 올바른 3차원 구조로 접히는 방식은 DeepMind의 AlphaFold가 성공적으로 해결한 또 다른 복잡한 예측 과제입니다.) 이제 이 유전자 서열에 작은 변화가 생기면 어떤 결과가 초래될까요? 어떤 변이(variant)는 치명적일 수 있고, 어떤 변이는 해로운 영향을 미 미치며, 대다수는 중립적이지만, 드물게는 생존에 유리한 유익한 변이도 존재합니다. 관건은 이들 중 어떤 변이가 어떤 결과를 가져올지 정확히 식별하는 것입니다.

이러한 맥락에서 Evo 2의 진가는 명확하게 드러납니다. 다양한 변이 예측 작업에서 Evo 2는 기존의 고도로 전문화된 모델들의 성능과 동등하거나 그 이상을 달성합니다. 이는 어떤 돌연변이(mutation)가 질병을 유발하는 병원성(pathogenic)일 가능성이 높은지, 또는 유방암과 밀접하게 관련된 BRCA1과 같은 잘 알려진 암 유전자(cancer gene) 내의 특정 변이(variant)가 임상적으로 중요한 의미를 가지는지 예측할 수 있다는 것을 의미합니다. 더욱 놀라운 점은 Evo 2가 인간의 변이 데이터로 직접 훈련되지 않았다는 사실입니다. 오직 표준 인간 참조 게놈(reference genome)만을 가지고 학습했음에도 불구하고, 게놈 서열(genomic sequence)에 내재된 진화적 제약(evolutionary constraint)을 스스로 터득하여 인간에게 해로운 돌연변이를 추론할 수 있게 된 것입니다. Evo 2는 여러 종과 다양한 생물학적 상황(context) 전반에 걸쳐 "정상적인" DNA의 형태와 기능을 깊이 이해하고 있습니다. 이러한 제로샷(zero-shot) 예측 능력은 희귀 질환 진단, 신약 개발을 위한 새로운 치료 표적 발굴 등 의료 분야에 혁신적인 영향을 미칠 잠재력을 가지고 있습니다.

코딩 영역(coding region) 내 변이 병원성(variant pathogenicity)의 제로샷(zero-shot) 평가.
출처: https://arcinstitute.org/manuscripts/Evo2

## 생물학을 이해하는 것을 넘어 창조의 영역으로

Evo 2의 놀라운 능력은 이전에 접한 적 없는 서열이라 할지라도 DNA 서열이 "정상적이지 않다"고 감지할 수 있다는 점입니다. 이는 마치 챗GPT(ChatGPT)가 자연스러운 언어의 흐름을 본능적으로 아는 것과 유사합니다. 그러나 여기서 그치지 않고, Evo 2는 초기 학습 과정에서 이동성 유전 요소(mobile genetic element), 유전자 발현 조절 모티프(regulatory motif), 단백질 2차 구조(protein secondary structure)와 같은 다양한 생물학적 특성(biological feature)을 직접적으로 파악했습니다. 이는 단순한 DNA 서열 판독을 넘어서, 해당 정보가 훈련 데이터에 명시적으로 주어지지 않았음에도 불구하고 고차원적인 구조 정보를 포착했다는 점에서 매우 인상적인 성과입니다.

다시 한번 챗GPT(ChatGPT)와의 비교를 통해 이를 명확히 이해할 수 있습니다. 챗GPT(ChatGPT)는 문법 규칙을 명시적으로 학습한 적이 없더라도 문법적으로 올바른 문장을 자연스럽게 완성할 수 있습니다. 이와 마찬가지로, Evo 2는 유전자(gene)나 단백질(protein)이 무엇인지에 대한 사전 지식 없이도, 생물학적으로 유효한 구조를 갖춘 게놈(genome)의 특정 부분을 완성해낼 수 있습니다.

궁극적으로, GPT 모델이 새로운 콘텐츠를 창조하는 능력(이 때문에 "생성형 AI(generative AI)"라 불립니다)을 지닌 것처럼, Evo 2 역시 독창적인 DNA 서열을 생성할 수 있습니다. 이 지점에서 우리는 생물학을 단순히 '이해하는' 단계를 넘어 '창조하는' 영역으로 발을 내딛게 됩니다. Evo 2는 미토콘드리아 게놈(mitochondrial genome), 박테리아 게놈(bacterial genome), 심지어 효모 게놈(yeast genome)의 일부를 성공적으로 생성하는 데 활용되었습니다. 이러한 능력은 바이오 제조(biomanufacturing), 탄소 포집(carbon capture)을 위한 미생물 설계, 또는 특정 약물 합성(drug synthesis)을 위한 유기체 맞춤 제작 등 합성 생물학(synthetic biology) 분야에서 엄청난 잠재력을 가집니다. 예를 들어, 특정 오염 물질을 분해하는 능력을 가진 미생물을 설계하거나, 고효율 바이오 연료를 생산하는 효모를 개발하는 등의 응용이 가능해집니다.

그러나 챗GPT(ChatGPT)와 마찬가지로 Evo 2 역시 중요한 한계점을 안고 있습니다. 생물학적으로 그럴듯해 보이는 DNA 서열을 생성하는 것이 곧 그 서열이 실험적 검증(experimental validation) 없이도 생물학적으로 기능적임을 보장하지는 않습니다. 현재 DNA 생성 능력은 Evo 2의 여러 측면 중 비교적 초기 단계에 머물러 있습니다. 하지만 불과 몇 년 만에 언어 모델(language model)이 GPT-3에서 o3 또는 DeepSeek과 같은 고도화된 모델로 어떻게 진화했는지 상기해 본다면, 생성형 생물학(generative biology)의 미래에 어떤 놀라운 발전이 기다리고 있을지 쉽게 예측할 수 있습니다. 이러한 기술의 발전은 생명 공학(biotechnology) 분야에 새로운 지평을 열 것이며, 인류가 직면한 다양한 문제 해결에 기여할 것으로 기대됩니다.

Evo 2가 생성한 원핵생물 게놈 서열(prokaryotic genomic sequence)에서 발견된 예시 단백질의 AlphaFold 3 구조 예측.
출처: https://arcinstitute.org/manuscripts/Evo2

이 모든 놀라운 기능 외에도, Evo 2는 오픈소스(open-source)이자 오픈웨이트(open-weight) 모델로 공개되었습니다. 이는 모델 매개변수(model parameter), 사전 훈련 코드, 추론 코드, 그리고 모델 훈련에 활용된 전체 데이터셋(dataset)을 누구나 다운로드하여 사용할 수 있음을 의미합니다. 이러한 개방성은 전 세계 연구자와 개발자들이 Evo 2를 기반으로 새로운 연구를 수행하고 혁신적인 애플리케이션을 개발하는 데 크게 기여할 것입니다. 과학 발전의 속도를 가속화하고, 더 많은 이들이 생명 과학 연구에 참여할 수 있는 기회를 제공한다는 점에서 매우 중요한 의미를 가집니다.

그리고 기술 발전의 속도를 한번 되짚어 봅시다. Evo 1은 불과 몇 달 전인 2024년 11월에 공개되었으며, 당시에도 이미 놀라운 성과로 평가받았습니다. 하지만 Evo 1은 약 3천억 개의 토큰(token)으로 주로 원핵생물 게놈(prokaryotic genome)만을 대상으로 훈련되었고, 131,000 염기쌍(base pair)의 컨텍스트 윈도우(context window)를 가졌으며, 기능적 범위도 상대적으로 한정적이었습니다. 그런데 불과 몇 달 만에, 훈련 규모를 30배 확장하고, 컨텍스트 윈도우(context window)를 8배나 늘리며, 완전히 새로운 기능을 도입한 Evo 2가 탄생했습니다! Evo 1에서 Evo 2로의 이러한 급속한 진화는 우리가 언어 모델(language model) 분야에서 목격했던 경이로운 속도의 개선을 그대로 반영합니다. 언어 모델(language model)은 불과 몇 년 사이에 잦은 환각(hallucination) 현상을 보이던 초기 단계에서, 이제는 인간 수준의 능숙도로 복잡한 작업을 처리하는 수준까지 발전했습니다. GPT가 언어 생성 분야에 혁명적인 변화를 가져온 것처럼, 이러한 DNA 언어 모델(DNA language model)들은 생명 자체의 코드를 이해하고 조작하는 방식을 근본적으로 변화시키고 있습니다. 생물학의 미래는 그 어느 때보다 밝고 흥미진진하며, 이러한 기술이 가져올 잠재적 영향에 대한 윤리적, 사회적 논의 또한 중요하게 다루어져야 할 것입니다.

## CODA

이 뉴스레터는 두 가지 구독 옵션을 제공합니다. 모든 콘텐츠는 무료로 이용 가능하지만, 유료 구독으로 전환하시면 EPFL AI 센터의 활동을 직접적으로 후원하는 데 큰 도움이 됩니다. 여러분의 재정적 지원은 저의 작업에 큰 힘이 됩니다.

저와 소통하고 싶으시다면 다음 채널들을 이용해 주세요.
*   **소셜 미디어:** 주로 LinkedIn에서 활동하며, Mastodon, Bluesky, X에서도 저를 찾을 수 있습니다.
*   **팟캐스트:** EPFL AI 센터에서 진행하는 AI 팟캐스트 "Inside AI"(Apple Podcasts, Spotify)를 통해 저보다 훨씬 뛰어난 전문가들과 대화하는 기회를 가지고 있습니다.

Engineering Prompts는 독자 여러분의 성원에 힘입어 운영되는 출판물입니다. 최신 소식을 받아보고 저의 작업을 지속적으로 지원해 주시려면, 지금 바로 구독을 고려해 주세요.

구독하기