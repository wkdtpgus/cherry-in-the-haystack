# **금주의 AI 에이전트: 알아두어야 할 논문들**

Author: Pascal Biese
URL: https://www.llmwatch.com/p/ai-agent-of-the-week-papers-you-should

============================================================

**요약**
**학습 도구로서의 기억 및 자기 성찰**
새로운 기술을 통해 대규모 언어 모델(LLM) 에이전트는 경험과 비판을 장기 기억에 저장하여 즉석에서 학습할 수 있게 되었습니다. 한 프레임워크는 에피소드(개별 사례별) 기억과 의미(일반화된) 기억을 결합하여 재훈련 없이 적응하도록 했으며, 이는 표준 검색 방식 대비 정확도를 24.8% 향상시켰습니다. 이러한 기억 기반의 성찰적 학습 접근 방식은 에이전트를 더욱 적응력 있고 해석 가능하게 만들며, 지속적인 자기 피드백이 값비싼 미세 조정(fine-tuning)을 대체할 수 있음을 시사합니다.

**다중 에이전트 시스템(Multi-Agent Systems) 및 '사고' 공유**
자율 에이전트(Autonomous agents)는 점점 더 팀으로 작업을 처리하고 있습니다. 주목할 만한 다중 에이전트 시스템(EDR)은 전문 하위 에이전트(계획, 웹 검색, 코드 분석 등)를 조정하고 성찰 루프(reflection loop)를 활용하여 기업 보고서를 생성했으며, 개방형 벤치마크(open-ended benchmarks)에서 이전 에이전트 시스템보다 뛰어난 성능을 보였습니다. 이와 동시에 연구자들은 에이전트가 자연어(natural language)를 넘어 소통하도록 제안했습니다. 이는 본질적으로 잠재된 사고의 '텔레파시' 공유입니다. 그들은 에이전트가 식별 가능한 공유 '아이디어'를 통해 은닉 상태(hidden state)를 직접 교환할 수 있음을 입증했으며, 이러한 사고 통신이 협업을 현저히 개선한다는 것을 보여주었습니다.

**향상된 장기적 추론(Long-Horizon Reasoning)**
몇 가지 발전은 장기적인 작업에 대한 계획 및 학습의 과제를 해결했습니다. SALT라고 불리는 새로운 신용 할당(credit assignment) 방식은 궤적 그래프(trajectory graphs)를 구성하여 단계별 보상을 할당함으로써 다단계 작업에 대한 강화 학습(reinforcement learning)을 안정화합니다. 긴 시퀀스(sequences)에서 좋고 나쁜 행동을 분리함으로써 SALT는 WebShop 및 ALFWorld와 같은 복잡한 벤치마크에서 성능을 향상시켰습니다. 한편, 월드 모델 평가 프로토콜(WorldTest)은 탐색(exploration)과 테스트(testing)를 분리하여 에이전트가 보상 해킹(reward-hacking)을 넘어 환경 역학(environment dynamics)을 얼마나 잘 이해하는지 측정합니다. 43개 환경 스위트(AutumnBench)를 사용하여 연구자들은 인간이 결과 예측 및 계획에서 에이전트를 여전히 훨씬 능가한다는 것을 발견했으며, 진정으로 일반화 가능한 월드 모델(world models)을 위한 큰 발전 가능성을 보여주었습니다.

**평생 및 효율적인 학습**
지속적인 학습(continual learning)을 향해 나아가며, NeurIPS에 제출된 한 논문은 지속적 지식 적응(Continual Knowledge Adaptation, CKA-RL)을 소개했는데, 이는 과거 작업의 핵심 지식 벡터(knowledge vectors)를 저장하고 새로운 작업에 재사용합니다. 이는 치명적인 망각(catastrophic forgetting)을 방지하고 순방향 전이(forward transfer)를 8% 향상시켰는데, 에이전트가 시간이 지남에 따라 기술을 축적할 수 있었기 때문입니다. 유사하게, 메모(Memo) 아키텍처(architecture)는 과거 관찰 내용을 주기적으로 압축된 임베딩(embeddings)으로 요약함으로써 체화된 에이전트(embodied agents)의 장기 기억 사용을 개선했습니다. 이러한 요약은 트랜스포머 정책(transformer policy)이 훨씬 적은 연산량으로 매우 긴 시간 프레임(timeframes)을 처리할 수 있게 하며, 컨텍스트 윈도우(context windows)가 잘려야 할 때에도 견고함을 유지합니다. 두 접근 방식 모두 무기한으로 학습할 수 있는 더욱 메모리 효율적인 에이전트를 지향합니다.

**도구 사용 및 모듈식 추론(Modular Reasoning)**
하나의 거대한 모델에 의존하는 대신, 에이전트는 전문화된 도구를 사용하는 방법을 배우고 있습니다. 비전-LLM(vision-LLM) 모델에 대한 분석 결과, 이들이 종종 환각(hallucinate)을 일으키거나 텍스트 단서에 과도하게 의존하는 것으로 나타났습니다. 제안된 해결책은 LLM 추론과 경량 시각 모듈(객체 인식, 공간 확인 등)을 교차시키는 에이전트 기반 아키텍처(architecture)입니다. 올바른 도구를 반복적으로 호출하고 사고의 사슬(chain-of-thought)을 정제함으로써, 70억 매개변수(parameter) 에이전트는 시각적 추론 벤치마크에서 +10.3 및 +6.0점의 향상을 달성했으며, 이는 훨씬 더 큰 모델들과 동등하거나 그들을 능가하는 수준입니다. 이는 미래의 자율 에이전트(autonomous agents)가 정확성과 효율성을 높이기 위해 데이터베이스(databases)부터 비전 API(vision APIs)에 이르기까지 도구 사용과 모듈식 서브루틴(modular sub-routines)을 대거 통합할 것임을 강조합니다.

이 요약에 이어, 우리는 각 기여에 대해 더 자세히 살펴보고, 핵심 혁신, 자율 AI(autonomous AI)에 왜 중요한지, 해결하는 문제점, 그리고 미래적 함의를 검토할 것입니다.