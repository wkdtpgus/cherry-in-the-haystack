**현실에 뿌리내린 AI: 기술로서의 진화**

저희가 **정상 기술로서의 AI(AI as Normal Technology)**를 출간했을 때, 그 반향은 AI 기술의 복잡한 사회적 통합 과정에 대한 깊은 성찰을 불러일으켰습니다. 이 글은 AI의 윤리적 사용과 책임 있는 개발에 대한 새로운 논의의 장을 열었습니다. 저희는 이를 AI가 단순한 도구를 넘어, 인간 사회와 상호작용하며 진화하는 과정에 대한 이해를 심화하는 중요한 계기로 받아들였습니다. 이는 단순히 기술적 진보를 넘어, 인류의 가치와 어떻게 조화를 이룰 수 있을지에 대한 질문을 던지는 것입니다. 이러한 변화를 반영하여 저희는 이 뉴스레터의 초점을 확장했습니다. 저희는 이미 AI 거버넌스와 데이터 주권에 대한 후속 연구를 진행했으며, 2025년 말에 완성하여 2026년에 출판할 계획인 보고서를 통해 저희의 프레임워크(framework)를 현실 세계의 적용 사례에 맞게 확장하면서 더 정기적으로 통찰을 공유할 예정입니다. 오늘 저희는 AI의 지속 가능한 발전과 포용적 미래를 위한 실질적인 과제들을 다루고, 기존의 기술 중심적 관점을 넘어, 인간 중심적 접근 방식의 중요성을 강조해보고자 합니다.

**목차**
*   정상적이라는 것이 평범하거나 예측 가능하다는 의미는 아닙니다
*   저희 논지의 재정의
*   최근의 AI 모델 업데이트가 AI의 본질에 대한 오해를 심화시킬 수도 있습니다
*   생성형 AI와 인간 창의성 사이의 새로운 협력 모델
*   인간 중심 AI 디자인의 중요성
*   AI의 이점을 얻으려면 많은 노력과 고통스러운 선택이 필요할 것입니다
*   확산 속도에 대한 초현실적인 논쟁
*   AI 채택이 다르게 느껴지는 이유
*   결론

**정상적이라는 것이 평범하거나 예측 가능하다는 의미는 아닙니다**

에세이에서 저희가 정상적이라는 것의 정의를 탐구했지만, 그 의미가 단순히 기술적 특성에 국한되지 않음을 분명히 할 필요가 있었습니다. 예측 불가능한 사회적 영향은 강력한 기술의 특징이었으며, AI 역시 예외는 아닙니다. 이는 기술과 사회 시스템 간의 복잡한 상호작용에서 발생하는 비예측적 효과(emergent effects)이기 때문입니다. 기술 자체의 논리만으로는 사회적 가치나 윤리적 함의를 완전히 예측하기 어렵습니다. 이것이 기술 결정론(technological determinism)을 거부하고, 대신 인간의 역할과 선택에 주목하는 것이 이 글의 핵심 전제 중 하나인 이유입니다. AI, 특히 대규모 언어 모델(large language models)의 경우, 저희는 이미 비예측적 사회적 효과를 목격하고 있습니다. AI 기반 콘텐츠의 확산과 “딥페이크(deepfake)”와 같은 새로운 형태의 정보 왜곡은 대부분의 관찰자들을 당황하게 했습니다. 반면에 AI가 특정 산업의 생산성을 혁신적으로 개선하는 것과 같이 임박했다고 널리 예측되었던 많은 이점은 아직 초기 단계에 있습니다. 3~5년 후 AI의 사회적 영향의 지형이 어떻게 보일지는 — 미래 역량이 아닌 현재 역량의 확산에 기반하더라도 — 누구도 예측할 수 없습니다. 기술적 역량의 개발은 AI의 사회적 영향보다 더 예측 가능합니다. 과거의 기술적 예측은 종종 기술 자체의 발전 속도에 초점을 맞췄지만, 실제 사회적 파급 효과는 복잡한 인간의 적응 과정과 제도적 변화에 의해 좌우됩니다. 이 모든 것은 AI를 기관과 정책 입안자들에게 더 심각한 도전 과제로 만듭니다. 왜냐하면 그들은 예측의 잘못된 안도감에 의존하거나 모든 해악을 방지하려 노력하는 대신 예측 불가능한 영향에 민첩하게 대응해야 할 것이기 때문입니다. 광범위하게 말해서, 이러한 적응성을 가능하게 하는 정책 수립 접근 방식은 회복탄력성(resilience)이라고 불리며, 이는 저희 에세이가 옹호했던 바입니다. 그러나 저희가 잠재적으로 치명적인 위험을 다루는 접근 방식으로 회복탄력성을 강조했지만, 회복탄력성이 더 광범위하게 퍼져 있는 위험을 다루는 데도 중요한 역할을 한다는 점을 더 명확히 했어야 했습니다. 아마도 일부 독자들이 예측 가능성에 대한 저희의 견해를 오해한 이유는 “정상”이라는 단어 때문일 것입니다. 다시 말하지만, 저희의 목표는 개별적으로 그리고 집단적으로 AI에 적응하는 과제를 사소하게 만들려는 것이 아닙니다. 이상적인 세상에서는 단순히 “기술로서의 AI(AI as Technology)”가 더 나은 제목이었겠지만, 저희는 그것이 저희의 목표가 현재 담론을 지배하고 있는 기술 만능주의적 세계관을 특징짓는 예외주의(exceptionalism)에 대한 대안을 제공하는 것임을 효과적으로 전달할 것이라고 생각하지 않았습니다.

**저희 논지의 재정의**

저희 논지의 핵심을 추출하고 단순화한다면 다음과 같을 것입니다: AI 역량 증가와 사회적 영향 사이에는 역동적인 상호작용이 있습니다. 이점과 위험은 AI가 개발될 때가 아니라 배포될 때, 그리고 사용자의 맥락 속에서 실현됩니다. 이는 저희(개인, 조직, 기관, 정책 입안자)에게 그러한 영향을 형성하는 데 많은 영향력을 행사할 수 있는 지점들을 제공합니다. 따라서 저희는 역량 개발 속도에 대해 그렇게 많이 걱정할 필요가 없습니다. 저희의 노력은 AI의 이점을 실현하고 위험에 대응하는 관점에서 배포 단계(deployment stage)에 더 집중해야 합니다. 이 모든 것은 오늘날의 AI에만 해당되는 것이 아니라, AI 역량의 자기 개선(self-improvement)과 같은 가설적인 발전에도 해당됩니다. AI 시스템의 힘에 대한 많은 한계는 해당 시스템 외부에 존재하며 (또한 그래야만 합니다), 따라서 AI가 스스로 기술 설계를 개선하는 것만으로는 극복될 수 없습니다. 이 프레임워크(framework)의 측면들은 결국 수정되어야 할 수도 있지만, 그것은 저희가 의미 있게 예측하거나 준비할 수 있는 지평 너머에 있습니다: 저희가 2부에서 설명하는 세상은 오늘날보다 AI가 훨씬 더 발전한 세상입니다. 저희는 AI 발전—또는 인간의 발전—이 그 지점에서 멈출 것이라고 주장하는 것이 아닙니다. 그 이후에는 무엇이 올까요? 저희는 모릅니다. 이 비유를 생각해 보십시오: 1차 산업혁명(Industrial Revolution)의 여명기에 산업 세계가 어떻게 보일지 생각하고 준비하는 것은 유용했을 것이지만, 전기나 컴퓨터를 예측하려 시도하는 것은 헛된 일이었을 것입니다. 여기서 저희의 작업도 비슷합니다. 저희는 “급속한 발전(fast takeoff)” 시나리오(scenario)를 거부하기 때문에, 저희가 시도한 것보다 더 먼 미래의 세상을 상상하는 것을 필요하거나 유용하다고 보지 않습니다. 저희가 2부에서 설명하는 시나리오가 구체화된다면, 저희는 다음에 올 것이 무엇이든 더 잘 예측하고 준비할 수 있을 것입니다. 어쨌든, 다시 말하지만, 논지의 핵심은 AI와 사회 간의 관계를 이해하기 위한 근본적인 인과 프레임워크(causal framework)이며, AI가 가질 수도 있고 가지지 않을 수도 있는 특정 영향이 아닙니다. 저희의 견해로는, 이 인과적 이해를 공유한다면, 여러분은 정상 기술 논지(normal technology thesis)에 동의하는 것입니다. 저희는 이 프레임워크(framework)가 암묵적으로나마 실제로 널리 공유되고 있음을 발견했습니다. 이는 많은 독자들의 마음속에서 이 논지를 거의 동어반복적(tautological)으로 만듭니다. 저희는 저희가 보기에 — 그리고 독자들이 보기에 — 매우 약한 주장을 하고 있는 것입니다! 이를 인식하지 못하면 독자들은 저희가 “정상”이라는 말로 의미했을지도 모르는 훨씬 더 구체적인 것을 찾으려 합니다. 하지만 저희는 그렇지 않았습니다. 저희는 기술을 “정상”과 “비정상”으로 분류한 다음 AI를 “정상” 범주에 넣는 것이 아닙니다. 저희는 단지 AI를 다른 강력한 범용 기술(general-purpose technologies)처럼 다루어야 한다고 말하는 것입니다. 이는 대규모 언어 모델(large language models)이나 특정 종류의 AI에만 국한된 것이 아닙니다. 덧붙여 말하자면, 이것이 제목이 “정상 기술로서의 AI(AI as normal technology)”이지 “하나의 정상 기술로서의 AI(AI as a normal technology)”가 아닌 이유입니다. 저희의 견해는 총체적으로 AI라고 불리는 모든 기술과, AI라고 불리지 않더라도 유사한 다른 기술에 적용됩니다. 저희의 세계관이 거의 동어반복적이라면, 굳이 그것을 언급할 필요가 있을까요? 왜냐하면 그것은 초지능(superintelligence) 세계관과 대조되기 때문입니다. 세계관의 특징은 이렇습니다: 서로 모순되는 세계관이 존재할 수 있으며, 각 세계관은 그것을 신봉하는 사람들에게는 동어반복적으로 보일 수 있습니다.

**최근의 AI 모델 업데이트가 AI의 본질에 대한 오해를 심화시킬 수도 있습니다**

최근 새로운 AI 모델 출시 이후 저희 에세이에 대한 관심이 급증했으며, 그 중 적어도 일부는 출시에 대한 기대와 현실 사이의 괴리에서 비롯된 것으로 보입니다. 이것은 이상합니다! 이런 일이 처음은 아닙니다 — 저희는 이전에 거의 새로운 정보 없이 발생한 확장(scaling)에 대한 큰 서사적 변화에 회의적인 시각을 표명했습니다. 만약 단일 제품 업데이트가 AI의 궤적에 대한 사람들의 견해를 바꾼다면, 애초에 사람들의 증거 기반(evidence base)은 얼마나 신뢰할 수 있을까요? 정상 기술 프레임워크(normal technology framework)가 느린 시간표를 예측하는 이유는 역량이 한계에 부딪힐 것이기 때문이 아니라, 역량이 계속 빠르게 발전하더라도 영향은 느리고 점진적일 것이기 때문입니다. 따라서 저희는 새로운 출시에 대한 실망이 여러분을 AI를 정상 기술로 보는 것에 더 공감하게 만들어서는 안 된다고 생각합니다. 마찬가지로, 내일 발표될 새로운 돌파구도 저희의 견해에 대해 더 회의적으로 만들어서는 안 됩니다. GPT-5를 이해하는 가장 좋은 방법은, 이는 AI 개발자들이 모델에서 제품으로 강조점을 전환하는 특히 좋은 예시라는 것입니다. 저희는 이에 대해 1년 전에 글을 썼습니다. 자동 모델 전환기(automatic model switcher)는 ChatGPT의 일상 사용자들에게 큰 의미가 있습니다. 출시된 지 거의 1년이 지나도 “사고(thinking)” 모델을 사용하는 사람이 거의 없었지만, GPT-5는 그 사용량을 극적으로 증가시켰습니다. 일부 통신에서 알트만(Altman)은 GPT-5의 강조점이 역량의 도약이 아니라 유용성이었음을 분명히 밝혔지만, 이 메시지는 불행히도 끊임없는 과대광고(hype)로 인해 약화되어 실망으로 이어졌습니다. 업계의 이러한 광범위한 변화는 사실 기업들 스스로 (마지못해) 성공으로 가는 길이 AGI(인공 일반 지능) 또는 초지능(superintelligence)을 구축하기 위해 경쟁하고 그것이 모든 확산 장벽을 쓸어버릴 것이라고 기대하는 대신, 제품을 만들고 채택을 촉진하는 힘든 작업을 하는 것임을 인정하게 되는 것과 매우 일치합니다. 아이러니하게도, 이 서사에서 GPT-5는 실패가 아니라 성공의 예시입니다. 사실, 모델 개발자들은 더 유용한 제품을 개발하는 것(저희 기술 개발 및 채택 프레임워크(technology development & adoption framework)의 두 번째 단계)을 넘어 배포자(deployer)와 협력하여 초기 채택의 어려움을 완화하는 것(세 번째 단계)으로 나아가기 시작했습니다. 예를 들어, OpenAI의 선행 배포 엔지니어(Forward Deployed Engineers)는 존 디어(John Deere)와 같은 고객 및 농부들과 직접 협력하여 살충제 적용을 위한 맞춤형 권장 사항 제공과 같은 역량을 통합하고 배포하고 있습니다.

**생성형 AI와 인간 창의성 사이의 새로운 협력 모델**

생성형 AI의 발전은 인간의 창의성에 대한 새로운 질문을 던지고 있습니다. 많은 사람들이 AI가 인간의 예술적, 지적 영역을 침범할 것이라고 우려하지만, 저희는 오히려 새로운 협력 모델이 나타나고 있다고 생각합니다. AI는 아이디어 생성, 초안 작성, 반복 작업 처리 등에서 강력한 보조 도구가 될 수 있습니다. 이는 예술가, 작가, 디자이너, 연구자들이 보다 고차원적인 창의적 문제 해결에 집중할 수 있도록 돕습니다. 예를 들어, AI 기반 디자인 도구는 제품 개발 과정에서 수많은 시안을 빠르게 생성하여 디자이너가 최적의 솔루션을 찾는 시간을 단축시킵니다. 음악 분야에서는 AI가 새로운 멜로디나 화음 패턴을 제안하여 작곡가의 영감을 자극하고, 문학 분야에서는 AI가 줄거리 아이디어를 제공하거나 문체 교정을 도와 작가의 생산성을 향상시킵니다. 이러한 협력은 AI가 단순히 작업을 자동화하는 것을 넘어, 인간의 잠재력을 증폭시키는 역할을 할 수 있음을 보여줍니다. 중요한 것은 AI를 맹목적으로 따르는 것이 아니라, AI가 생성한 결과물을 비판적으로 평가하고, 인간의 통찰력과 윤리적 판단을 결합하여 최종 결과물을 만들어내는 것입니다. 이러한 인간-AI 협력은 미래 사회에서 필수적인 역량이 될 것이며, 교육 시스템 또한 이러한 변화에 발맞춰 창의적 사고와 비판적 판단력을 강조하는 방향으로 진화해야 할 것입니다.

**인간 중심 AI 디자인의 중요성**

세계관 간의 소통을 어렵게 만듭니다. 하지만 AI의 성공적인 통합을 위해서는 이러한 장벽을 넘어 공동의 이해를 구축하는 것이 필수적입니다. 저희는 AI 개발의 초기 단계부터 인간 중심 디자인(Human-Centered Design) 원칙을 적용하는 것이 중요하다고 강조합니다. 이는 기술이 사용자에게 어떻게 영향을 미치고, 어떤 가치를 제공하며, 잠재적인 위험은 무엇인지 깊이 이해하는 것에서 시작됩니다. 예를 들어, AI 시스템이 의사 결정을 내릴 때, 그 과정이 투명하고 설명 가능해야 합니다. 사용자는 AI가 왜 특정 결론에 도달했는지 이해할 수 있어야 하며, 필요한 경우 이의를 제기하거나 수정할 수 있는 메커니즘이 마련되어야 합니다. 이는 AI의 신뢰성을 높이고, 사용자의 수용도를 증가시키는 데 기여합니다. 또한, AI 디자인 과정에는 다양한 배경과 관점을 가진 이해관계자들이 참여해야 합니다. 이는 AI 시스템이 특정 집단에게 편향되거나 불공정한 결과를 초래하는 것을 방지하고, 모든 사용자에게 공평하고 포용적인 경험을 제공할 수 있도록 돕습니다. AI의 이점은 기술 자체의 능력뿐만 아니라, 그 기술이 인간의 필요와 가치에 얼마나 잘 부합하도록 설계되었는지에 달려있습니다. 따라서 기술적 우수성만큼이나 윤리적 고려와 사회적 책임이 AI 개발의 핵심 요소가 되어야 합니다.

**AI의 이점을 얻으려면 많은 노력과 고통스러운 선택이 필요할 것입니다**

저희 프레임워크(framework)에는 두 가지 광범위한 함의가 있습니다: 하나는 경제와 노동에 대한 것이고, 다른 하나는 안전에 대한 것입니다. 몇 가지 기본 전제(특히, 초지능(superintelligence)은 정의에 따라 비일관적이거나 불가능하다는 것)를 넘어서면, 이 두 가지 함의 뒤에 있는 저희의 주장은 대체로 다릅니다. 경제적 영향에 대해, 저희의 주장은 광범위하게 확산 장벽이 역량 개선을 통해 극복되지 않을 것이라는 것입니다. 안전에 대해서는, 저희의 주장은 주로 정렬(alignment) 없이 AI 제어가 가능할 뿐만 아니라, 특별히 어렵게 보이지도 않으며, 과학적 돌파구도 필요하지 않다는 것입니다. 이 두 가지 주장이 크게 겹치지 않기 때문에, 한 가지 주장은 받아들이고 다른 주장은 받아들이지 않거나 (또는 양가적인 태도를 취하는 것이) 일관성이 있습니다. 실제로 경제적 영향에 대한 저희의 견해는 독자들에게 특히 강하게 공감대를 형성한 것 같습니다. 에세이 출간 이후, 저희는 다양한 산업 분야에서 AI 전략을 담당하는 사람들과 많은 논의를 가졌습니다. 저희는 그들이 AI에 대해 생각했던 방식이 저희와 일치했지만, 모든 과대광고(hype) 때문에 자신들의 접근 방식에 대해 재고하기 시작했다는 것을 발견했습니다. 저희 에세이는 현장에서의 관찰뿐만 아니라 그들의 직관을 뒷받침하는 일관된 프레임워크(framework)를 제공했습니다. AI를 배포하는 사람들은 기술 개발과 확산의 차이를 예리하게 이해하고 있지만, 저희 프레임워크(framework)는 각각을 두 단계로 더 나눕니다. 개발 측면에서는 모델과 제품, 또는 역량과 애플리케이션(application) 사이의 간극을 강조합니다. 확산 측면에서는 사용자 학습 곡선(user learning curves)과 개인의 적응의 다른 측면, 그리고 종종 집단 행동을 요구하는 구조적, 조직적, 또는 법적 변화를 구별합니다. 저희는 각 4단계에서 작용하는 속도 제한의 종류를 설명합니다. 사용자 행동은 적어도 느리지만 예측 가능하게 변하는 경향이 있지만, 조정 문제를 해결하거나 경직된 제도(sclerotic institutions)를 개혁하는 것 — 이는 효과적인 기술 채택을 위한 전제 조건이기도 합니다 — 은 훨씬 더 불확실합니다. 예를 들어, 현대화 부족으로 인한 막대한 비용이 명확해지고 있음에도 불구하고 항공 교통 관제(Air Traffic Control)가 20세기 중반 기술에 갇혀 있는 방식을 생각해 보십시오. 저희 에세이는 AI의 경우에도 유사한 확산 장벽이 존재한다는 점을 지적했지만, 저희는 이제야 그러한 장벽을 명확히 설명하고 필요한 특정 개혁을 식별하는 작업을 하고 있습니다. 저희는 이 분야에 대해 더 많은 글을 쓸 것이며, 그 중 일부는 저스틴 컬(Justin Curl)과 협력할 것입니다. 첨단 AI가 이미 고도로 기술적이고 고도로 규제된 세상으로 진입하고 있다는 점을 염두에 둘 가치가 있습니다. 저희는 AI가 다루는 워크플로우(workflow)의 부분들이 병목 현상이 될 가능성이 낮다는 것을 반복적으로 발견합니다. 왜냐하면 사용 가능한 생산성 향상의 대부분은 이미 이전 기술의 물결을 통해 달성되었기 때문입니다. 한편 실제 병목 현상은 규제나 다른 외부 제약으로 인해 저항력을 보입니다. 법률 서비스와 과학 연구를 포함한 많은 특정 영역에서 경쟁 역학(competitive dynamics)이 너무 강해서 AI로 인한 생산성 향상이 궁극적으로 사회적 가치로 이어지지 않는 군비 경쟁의 심화로 이어집니다.

**확산 속도에 대한 초현실적인 논쟁**

저희는 서로 다른 진영들이 현재 AI의 영향력을 어떻게 특징짓는지에 대해 이견을 보이고 있다는 점을 여러 번 언급했습니다. 확산 속도보다 더 명확하게 드러나는 곳은 없습니다. AI 지지자들은 AI가 전례 없이 빠르게 채택되고 있다고 믿습니다. 저희는 전적으로 동의하지 않습니다. 더 나쁜 것은, 더 많은 증거가 나올수록 각 측은 자신들의 해석에 대해 더 확신하는 것처럼 보인다는 것입니다. 저희는 확산 속도에 대한 심층 분석을 진행 중입니다. 현재로서는, “빠른 채택” 해석을 정당화하기 위해 제시되는 일반적인 주장과 통계에서 몇 가지 기본적인 오류를 지적합니다. 첫째, 배포(deployment)는 확산(diffusion)이 아닙니다. 종종 사람들은 빠른 채택에 대해 이야기할 때, 역량이 개발되면 수억 명의 사용자가 사용하는 제품(예: 챗봇(chatbot))에 거의 즉시 배포될 수 있다는 것을 의미합니다. 그러나 이것은 확산이 의미하는 바가 아닙니다. 얼마나 많은 사람들이 역량에 접근할 수 있는지 아는 것만으로는 충분하지 않습니다: 중요한 것은 얼마나 많은 사람들이 실제로 그것을 사용하고 있는지, 얼마나 오랫동안 사용하고 있는지, 그리고 무엇을 위해 사용하고 있는지입니다. 그러한 세부 사항들을 깊이 파고들면, 그림은 매우 다르게 보입니다. 예를 들어, ChatGPT에서 자랑스럽게 출시된 “사고(thinking)” 모델이 출시된 지 거의 1년이 지나도, 사용자의 1% 미만이 매일 그것을 사용했습니다! 이것이 저희 논지를 뒷받침함에도 불구하고, 저희는 이 점을 지적하는 데 즐거움을 느끼지 않습니다. AI의 열렬한 얼리 어답터(early adopters)로서, 이러한 숫자는 너무 낮아서 저희가 직관적으로 이해하기 어렵고, 솔직히 꽤나 우울합니다. 오해의 소지가 있는 또 다른 통계는 특정 고위험 영역의 근로자 중 AI를 사용하는 비율과 관련이 있습니다. 이러한 통계는 AI가 위험한 방식으로 빠르게 채택되고 있다는 주장을 뒷받침하기 위해 제시되는 경향이 있습니다. 그러나 고위험 영역에서도 대부분의 작업은 실제로는 평범하며, 특정 용도를 깊이 파고들면 전혀 위험해 보이지 않습니다. 예를 들어, 미국 의사 협회(American Medical Association)의 설문조사에 따르면 대다수의 의사가 AI를 사용하고 있다고 보고했습니다. 그러나 여기에는 구술된 메모의 전사(transcription)와 같은 것들이 포함됩니다. 또한 진단에 대한 두 번째 의견을 챗봇(chatbot)에 묻는 것과 같은 것들도 포함됩니다 (2024년에는 약 12%가 이 사용 사례(use case)를 보고했는데, 이는 2023년 11%에서 1%포인트 증가한 엄청난 수치입니다). 이것은 전사(transcription)보다 확실히 더 심각한 사용이지만, 여전히 충분히 근거 있는 것입니다. 저희가 이전에 지적했듯이, 신뢰할 수 없는 AI조차도 오류 감지(error detection)에 매우 유용합니다. 이러한 작업에 대한 AI 채택 증가는 의사들이 무모하게 행동하고(YOLOing it) ChatGPT에 결정을 위임함으로써 환자에 대한 책임을 포기하려 한다는 것을 의미하지 않습니다. 대다수의 의사들은 이 두 가지 유형의 사용 간의 차이를 이해하고 있으며, 의료 과실 책임, 직업 윤리 강령, 의료 기기 규제를 포함하여 의료 전문가 내에서 광범위한 무책임한 사용을 방지하는 많은 중첩되는 안전장치(guardrails)가 있습니다. 가장 오해의 소지가 있는 “빠른 채택” 밈(meme)은 아마도 ChatGPT가 약 두 달 만에 1억 명의 사용자에게 도달했음을 보여주는 이 널리 공유된 차트일 것입니다: 이 차트는 ChatGPT 사용자 증가를 (1) 네트워크 효과(network effects)에 따라 유용성이 달라지므로 첫날부터 유용한 앱보다 훨씬 느리게 성장하는 특징이 있는 소셜 미디어(social media) 앱인 인스타그램(Instagram), 페이스북(Facebook), 트위터(Twitter)와 비교하고, (2) 처음에는 초대 전용이었던 앱인 스포티파이(Spotify)와 (3) 제한된 재고로 출시되었고 사용하려면 구독이 필요했던 서비스인 넷플릭스(Netflix)와 비교합니다. 이 차트에 반영된 것은 앱에 대한 소문이 돌면 확인해 보는 얼리 어답터(early adopters)이며, ChatGPT에 대한 엄청난 소문이 있었습니다. 이러한 호기심 많은 초기 사용자들을 소진하면, 성장 곡선은 매우 다르게 보입니다. 사실, 1년 후 ChatGPT는 1억 명에서 2억 명의 사용자로만 성장한 것으로 보이며, 이는 곡선이 오른쪽으로 급격히 꺾였다는 것을 분명히 보여줍니다. 이는 처음 두 달만을 반영하는 이 그래프에는 편리하게도 포착되지 않았습니다. 이 차트는 확산에 대한 일반적인 장벽이 약화되거나 제거되었다는 증거를 제공한다면 유용할 것입니다. 하지만 그렇지 않습니다. 두 달은 사용자들이 AI를 생산적으로 통합하기 위해 워크플로우(workflow)를 조정하는 것과 같이 확산의 어려운 부분이 시작되기에도 충분한 시간이 아닙니다. 따라서 이 차트는 확산 속도에 대한 어떤 의미 있는 논의와도 무관합니다. 이 차트에는 다른 많은 문제점들이 있지만, 여기에서 멈추겠습니다. 다시 말하지만, 이것은 AI 확산 속도에 대한 완전한 분석과는 거리가 멀며 — 그것은 곧 나올 것입니다. 현재로서는, 이 주제에 대한 대부분의 논평이 단순히 진지하지 않다는 점을 지적하는 것뿐입니다. 그리고 저희가 데이터를 가지고 있는 질문에 대한 담론이 이렇다면, 서로 다른 진영의 미래 예측이 서로 전혀 닮지 않았다는 것은 놀라운 일이 아닙니다.

**AI 채택이 다르게 느껴지는 이유**

만약 “빠른 확산” 밈(meme)이 그렇게 잘못되었다면, 왜 그렇게 널리 퍼져 있고 지속적일까요? 왜냐하면 AI 채택은 PC나 인터넷, 소셜 미디어(social media)가 결코 그러지 않았던 방식으로 쓰나미처럼 느껴지기 때문입니다. 사람들이 어떤 것에 대해 직관적으로 확신할 때, 그들은 그러한 느낌을 확인시켜준다고 주장하는 데이터나 차트에 훨씬 덜 회의적일 것입니다. 물론 저희도 그 느낌을 압니다. AI에 대한 저희의 실제 경험은 과거 기술의 물결과는 다릅니다. 처음에는 저희는 이것을 인지 편향(cognitive bias)으로 치부했습니다. 저희가 현재 겪고 있는 어떤 변화든 과거에 성공적으로 적응했던 것보다 훨씬 더 큰 변화처럼 느껴질 것입니다. 저희는 이제 저희가 틀렸다는 것을 깨달았습니다. 인지 편향(cognitive bias)이 설명의 작은 부분일 수 있지만, AI 채택이 훨씬 더 빠르고 무섭게 느껴지는 진짜 이유가 있습니다. 요컨대, 배포(deployment)가 확산(diffusion)이 아니라는 것은 사실이지만, 과거에는 점진적인 배포(deployment)가 사용자들이 채택에 대한 결정을 끊임없이 내려야 하는 부담으로부터 어느 정도 보호받았다는 것을 의미했지만, 이제 그 완충 장치가 사라졌습니다. 인터넷 채택과의 비교를 통해 설명해 보겠습니다. 90년대에 다이얼업 인터넷(dial-up internet)을 채택했던 사람들은 다음과 같은 이야기를 기억할 것입니다. 처음 기술에 대해 들었을 때, 저희는 PC의 높은 가격 때문에 망설였습니다. 점차 가격이 내려갔습니다. 그동안 저희는 직장이나 친구 집에서 인터넷을 사용하는 경험을 얻었습니다. 그래서 몇 년 후 PC와 다이얼업 인터넷(dial-up internet)을 구입했을 때, 저희는 이미 어느 정도 훈련이 되어 있었습니다. 처음에는 다이얼업이 느리고 비쌌으며 웹사이트도 그렇게 많지 않았기 때문에 인터넷을 많이 사용하지 않았습니다. 점차 가격이 내려가고, 대역폭(bandwidth)이 개선되었고, 더 많은 콘텐츠가 온라인에 등장했으며, 저희는 사용량 증가와 함께 인터넷을 생산적이고 안전하게 사용하는 방법을 배웠습니다. 2020년대에 범용 AI 도구(general-purpose AI tools)를 채택하는 것은 새로운 역량의 배포(deployment)가 즉각적이기 때문에 근본적으로 다른 경험입니다. 사람들은 특정 사용 사례(use case)에 AI를 채택할지 여부를 평가하는 데 훨씬 더 많은 시간을 할애해야 하며, 채택하지 않으면 뒤처질 것이라는 말을 끊임없이 듣습니다. 저희의 이전 모든 요점은 여전히 유효합니다 — 학습 곡선(learning curves)이 존재하며, 인간 행동은 변화하는 데 오랜 시간이 걸리고, 조직 변화는 훨씬 더 오래 걸립니다. 그러나 AI를 사용하지 않는 것은 어느 정도 능동적인 선택이며, 사람들은 더 이상 접근할 수 없기 때문에 그것에 대해 생각하지 않아도 된다는 변명을 할 수 없습니다. 요컨대, 배포(deployment)는 확산(diffusion)의 여러 단계 중 하나일 뿐이며, 그 병목 현상을 제거하는 것이 확산을 약간 더 빠르게 만들었을 것입니다. 그러나 특정 AI 사용 사례(use case)에 대해 듣자마자, 궁극적으로는 합리적이거나 비합리적일 수 있는 다양한 이유로 대다수의 사람들이 채택하지 않기로 결정하는 경우라 할지라도, 채택할지 말지를 결정해야 하기 때문에 극적으로 더 빠르게 느껴집니다.

**결론**

저희가 AI 지지자들과 분명히 동의하는 한 가지는 AI가 사라지지 않을 것이며, 대부분의 사람들이 무시할 수 있는 암호화폐(crypto)와 같은 틈새시장이 되지 않을 것이라는 점입니다. 생성형 AI(generative AI)에 대한 집단적인 초기 충격이 가라앉았으므로, 각각의 새로운 기술적 역량이나 비예측적 사회적 효과(emergent social effect)에 (과도하게) 반응하는 대신, AI의 영향이 어떻게 전개될지 생각하는 구조화된 방법이 필요합니다. 저희가 이 뉴스레터에서 계속해서 상세히 설명하고 있는 정상 기술로서의 AI(AI-as-normal-technology) 프레임워크(framework)는 그러한 접근 방식 중 하나입니다. 이는 적어도 기술의 사회적 영향에 대해 역사적으로 근거한 기본적 사고방식을 명확히 표현한 것으로서, 더 예외주의적인 설명과 비교될 수 있다는 점에서 익숙해질 가치가 있습니다. 이 프레임워크(framework)는 기업 리더, 근로자, 학생, AI 안전 또는 AI 윤리(AI ethics)에 관심 있는 사람들, 그리고 정책 입안자 등에게 어느 정도 실행 가능한 지침을 제공합니다. 여러분이 계속해서 저희와 함께하고 논의에 기여해 주시기를 바랍니다. 초고에 대한 피드백을 제공해 준 스티브 뉴먼(Steve Newman)과 펠릭스 첸(Felix Chen)에게 감사드립니다.

**AI 시대의 새로운 도전과 기회**

AI 기술의 발전은 단순히 생산성 향상을 넘어, 사회 구조와 인간의 삶의 방식 자체에 근본적인 변화를 가져오고 있습니다. 이러한 변화의 물결 속에서, 우리는 AI가 제공하는 무한한 기회를 활용하는 동시에, 발생할 수 있는 잠재적 위험을 최소화하기 위한 지혜를 모아야 합니다. AI 기술은 의료, 교육, 환경 보호 등 다양한 분야에서 혁신적인 해결책을 제시할 수 있습니다. 예를 들어, 맞춤형 학습 경험을 제공하거나, 복잡한 질병을 조기에 진단하며, 기후 변화에 대응하는 새로운 방법을 모색하는 데 기여할 수 있습니다. 그러나 이러한 긍정적인 측면만큼이나, 데이터 프라이버시(data privacy) 침해, 알고리즘 편향(algorithmic bias), 노동 시장의 변화와 같은 새로운 도전 과제들도 함께 등장하고 있습니다. 우리는 이러한 도전에 수동적으로 반응하기보다는, 선제적이고 협력적인 접근 방식을 통해 AI의 혜택이 모두에게 공정하게 분배되고, 그 위험은 효과적으로 관리될 수 있도록 노력해야 합니다.

AI 시대를 성공적으로 헤쳐나가기 위해서는 기술 개발자, 정책 입안자, 시민 사회 단체, 그리고 일반 대중을 포함한 모든 이해관계자들의 지속적인 대화와 협력이 필수적입니다. 기술의 발전 속도에 발맞춰 윤리적 가이드라인과 규제 프레임워크를 마련하고, AI 리터러시(AI literacy) 교육을 강화하여 모든 사람이 AI를 이해하고 책임감 있게 사용할 수 있도록 지원해야 합니다. AI는 더 이상 미래의 기술이 아니라, 현재 우리의 삶 속에 깊이 뿌리내린 현실입니다. 이 현실을 어떻게 만들어갈지는 우리 모두의 손에 달려 있습니다. 우리는 AI를 통해 더 나은 세상을 만들 수 있다는 희망을 가지고, 동시에 그 과정에서 발생할 수 있는 어려움에 대한 현실적인 인식을 바탕으로 끊임없이 배우고 적응해야 할 것입니다.