**정상 기술로서의 AI(AI as Normal Technology) – 업데이트**

저희가 **정상 기술로서의 AI(AI as Normal Technology)**를 출간했을 때, 그 반향은 저희의 예상을 뛰어넘었습니다. 이 글은 저희 둘 중 누구라도 해낸 일 중 가장 영향력 있는 것이 되었습니다. 1 저희는 이를 AI의 중기적 미래와 그 영향에 대해 더 많은 시간을 생각하고 글을 쓰는 강력한 신호로 받아들였으며, 추측을 불러일으키는 경향이 있는 주제에 대해 현실에 기반한 분석을 제공했습니다. 이는 AI 스네이크 오일(AI Snake Oil) 프로젝트가 다루었던 AI의 현재 및 단기적 영향에 대한 글쓰기에서 초점을 전환한 것입니다. 이러한 변화를 반영하여 저희는 이 뉴스레터의 이름을 변경했습니다. 저희는 이미 정상 기술로서의 AI(AI as Normal Technology)에 대한 두 편의 후속 에세이를 출간했으며, 2026년 말에 완성하여 2027년에 출판할 계획인 책으로 저희의 프레임워크(framework)를 확장하면서 더 정기적으로 글을 게시할 예정입니다. 오늘 저희는 정상 기술로서의 AI(AI as Normal Technology)에 대한 일반적인 오해의 지점들을 다루고, 원래 에세이를 더 쉽게 접근할 수 있도록 노력하며, AI 2027과 비교해보고자 합니다.

최근 1년 동안 AI 분야는 멀티모달(multimodal) 능력, 에이전트(agent) 기반 시스템, 그리고 소형 언어 모델(SLM)의 발전 등 눈부신 진보를 이루었습니다. 이러한 발전은 AI가 단순한 도구를 넘어 복잡한 작업을 수행하고 사용자 경험을 혁신하는 잠재력을 보여주었습니다. 하지만 이러한 기술적 도약에도 불구하고, 저희의 '정상 기술로서의 AI' 프레임워크는 여전히 유효하며, 오히려 그 중요성이 더욱 부각되고 있습니다. 새로운 모델들이 등장할 때마다 사회적, 경제적 파급효과에 대한 논의는 더욱 활발해지고 있지만, 저희는 여전히 기술의 개발 속도와 실제 사회적 확산 속도 사이의 근본적인 차이에 주목해야 한다고 생각합니다.

**목차**
*   정상적이라는 것이 평범하거나 예측 가능하다는 의미는 아닙니다
*   저희 논지의 재진술
*   최신 AI 모델에 대한 기대와 현실, 그리고 프레임워크의 지속적인 유효성
*   정상 기술로서의 AI(AI as Normal Technology)와 AI 2027 사이에서 “중간 지점”을 찾기 어려운 이유
*   다른 세계관에 몰두해 있을 때 하나의 세계관을 이해하기는 어렵습니다
*   AI의 이점을 얻으려면 많은 노력과 고통스러운 선택이 필요할 것입니다
*   확산 속도에 대한 초현실적인 논쟁
*   AI 채택이 다르게 느껴지는 이유
*   결론

**정상적이라는 것이 평범하거나 예측 가능하다는 의미는 아닙니다**

에세이에서 저희가 정상적이라는 것이 무엇을 의미하는지 (아래에서 더 자세히 설명) 다루고 있지만, 무엇을 의미하지 않는지에 대해 더 명확히 설명할 수도 있었습니다. 저희의 요점은 “볼 것 없으니 지나가세요”가 아닙니다. 실제로 예측 불가능한 사회적 영향은 자동차에서 소셜 미디어(social media)에 이르기까지 강력한 기술의 특징이었습니다. 이는 기술과 사람 간의 복잡한 상호작용에서 발생하는 비예측적 효과(emergent effects)이기 때문입니다. 기술 자체의 논리만으로는 예측 가능한 경향이 없습니다. 이것이 기술 결정론(technological determinism)을 거부하는 것이 정상 기술 에세이의 핵심 전제 중 하나인 이유입니다. AI, 특히 챗봇(chatbot)의 경우, 저희는 이미 비예측적 사회적 효과를 목격하고 있습니다. AI 동반자(AI companion)의 확산과 “AI 정신증(AI psychosis)”과 같은 모델 아첨(model sycophancy)의 일부 해로운 영향은 대부분의 관찰자들을 놀라게 했습니다. 2 반면에 AI가 선거를 조작하는 데 사용되는 것과 같이 임박했다고 널리 예측되었던 많은 위험은 실현되지 않았습니다. 3~5년 후 AI의 사회적 영향의 지형이 어떻게 보일지는 — 미래 역량이 아닌 현재 역량의 확산에 기반하더라도 — 누구도 예측할 수 없습니다. 기술적 역량의 개발은 AI의 사회적 영향보다 더 예측 가능합니다. AI 2027의 저자 중 한 명인 다니엘 코코타일로(Daniel Kokotajlo)는 2021년에 “2026년의 모습은 어떠할까(What 2026 looks like)”라는 에세이로 AI 안전 커뮤니티(AI safety community)에서 유명했습니다. 기술 자체에 대한 그의 예측은 섬뜩할 정도로 정확했지만, 사회적 영향에 대한 예측은 전반적으로 방향성이 옳지 않았으며, 이는 그가 저희 중 한 명과의 팟캐스트(podcast) 토론에서 기꺼이 인정한 점입니다. 이 모든 것은 AI를 기관과 정책 입안자들에게 더 심각한 도전 과제로 만듭니다. 왜냐하면 그들은 예측의 잘못된 안도감에 의존하거나 모든 해악을 방지하려 노력하는 대신 예측 불가능한 영향에 민첩하게 대응해야 할 것이기 때문입니다. 광범위하게 말해서, 이러한 적응성을 가능하게 하는 정책 수립 접근 방식은 회복탄력성(resilience)이라고 불리며, 이는 저희 에세이가 옹호했던 바입니다. 그러나 저희가 잠재적으로 치명적인 위험을 다루는 접근 방식으로 회복탄력성을 강조했지만, 회복탄력성이 더 광범위하게 퍼져 있는 위험을 다루는 데도 중요한 역할을 한다는 점을 더 명확히 했어야 했습니다. 아마도 일부 독자들이 예측 가능성에 대한 저희의 견해를 오해한 이유는 “정상”이라는 단어 때문일 것입니다. 다시 말하지만, 저희의 목표는 개별적으로 그리고 집단적으로 AI에 적응하는 과제를 사소하게 만들려는 것이 아닙니다. 이상적인 세상에서는 단순히 “기술으로서의 AI(AI as Technology)”가 더 나은 제목이었겠지만, 저희는 그것이 저희의 목표가 현재 담론을 지배하고 있는 초지능(superintelligence) 세계관을 특징짓는 예외주의(exceptionalism)에 대한 대안을 제공하는 것임을 효과적으로 전달할 것이라고 생각하지 않았습니다.

최근 딥페이크(deepfake) 기술의 발전과 함께 선거 개입, 사기, 명예 훼손과 같은 새로운 사회적 위험이 현실화될 수 있다는 우려가 커지고 있습니다. 또한, AI 기반 의료 진단 시스템의 오진 가능성, 자율주행 차량의 사고 책임 문제 등 특정 도메인(domain)에서의 윤리적 난제와 법적 공백도 끊임없이 제기되고 있습니다. 이러한 문제들은 AI 기술 자체의 예측 불가능한 비예측적 효과(emergent effects)를 넘어, 기술과 사회 시스템 간의 복잡한 상호작용에서 비롯됩니다. 따라서 단순히 기술의 역량만을 보고 미래를 예측하는 것은 한계가 있으며, 사회적 적응과 정책적 민첩성을 통해 이러한 비예측적 효과에 대응하는 것이 중요합니다. 책임감 있는 AI(Responsible AI) 개발과 배포를 위한 국제적 논의와 규제 프레임워크(framework) 구축 노력은 이러한 불확실성에 대한 대응의 일환으로 볼 수 있습니다.

**저희 논지의 재진술**

저희 논지의 핵심을 추출하고 단순화한다면 다음과 같을 것입니다: AI 역량 증가와 사회적 영향 사이에는 긴 인과 사슬(causal chain)이 있습니다. 이점과 위험은 AI가 개발될 때가 아니라 배포될 때 실현됩니다. 이는 저희(개인, 조직, 기관, 정책 입안자)에게 그러한 영향을 형성하는 데 많은 영향력을 행사할 수 있는 지점들을 제공합니다. 따라서 저희는 역량 개발 속도에 대해 그렇게 많이 걱정할 필요가 없습니다. 저희의 노력은 AI의 이점을 실현하고 위험에 대응하는 관점에서 배포 단계(deployment stage)에 더 집중해야 합니다. 이 모든 것은 오늘날의 AI에만 해당되는 것이 아니라, AI 역량의 자기 개선(self-improvement)과 같은 가설적인 발전에도 해당됩니다. AI 시스템의 힘에 대한 많은 한계는 해당 시스템 외부에 존재하며 (또한 그래야만 합니다), 따라서 AI가 스스로 기술 설계를 개선하는 것만으로는 극복될 수 없습니다.

이 프레임워크는 AI 역량의 발전이 아무리 빠르더라도, 그것이 사회 전반에 걸쳐 의미 있는 영향을 미치기 위해서는 수많은 비기술적 장벽을 넘어서야 한다는 점을 강조합니다. 예를 들어, 기존 레거시 시스템(legacy system)과의 통합 문제, AI 활용을 위한 인력 재교육 및 조직 문화 변화, 그리고 새로운 기술에 대한 사회적 수용성 확보 등은 기술 개발만큼이나 어렵고 시간이 오래 걸리는 과정입니다. 저희는 AI 시스템의 "힘"이 기술 자체에만 있는 것이 아니라, 그 기술을 받아들이고 활용하는 인간 사회의 구조와 제도, 그리고 가치관에 의해 크게 좌우된다고 봅니다. 따라서 AI의 잠재력을 최대한 발휘하고 위험을 최소화하기 위한 노력은 기술 연구실을 넘어 정책 입안자, 기업 리더, 교육자, 그리고 일반 대중에 이르기까지 사회 전반의 광범위한 협력을 요구합니다.

**최신 AI 모델에 대한 기대와 현실, 그리고 프레임워크의 지속적인 유효성**

최근 GPT-4o, Gemini 1.5 Pro와 같은 최신 대규모 언어 모델(LLM)들은 텍스트, 이미지, 오디오를 넘나드는 멀티모달(multimodal) 능력과 향상된 추론 능력으로 다시 한번 전 세계의 이목을 집중시켰습니다. 이러한 모델들은 단순한 챗봇(chatbot)을 넘어 복잡한 에이전트(agent) 역할을 수행하며, 코드 생성, 데이터 분석, 창의적 콘텐츠 제작 등 다양한 분야에서 혁신적인 잠재력을 보여주고 있습니다. 하지만 이러한 기술적 진보가 곧바로 대규모 사회적, 경제적 변혁으로 이어지는 것은 아닙니다. 오히려 저희의 '정상 기술로서의 AI' 프레임워크는 이러한 최신 모델의 출시가 역량의 '개발' 단계에 속하며, 실제 '배포'와 '확산' 단계에서는 여전히 수많은 난관에 직면하게 될 것임을 시사합니다.

과거의 GPT-5와 마찬가지로, 최신 모델들도 '모델 자체의 성능 향상'을 넘어 '실제 제품과 서비스로의 전환'에 초점을 맞추고 있습니다. 이는 AI 개발 커뮤니티(community) 전반에서 '모델 중심(model-centric)'에서 '애플리케이션 중심(application-centric)' 개발로의 전환이 가속화되고 있음을 보여줍니다. 기업들은 단순히 강력한 모델을 만드는 것을 넘어, 이 모델을 특정 산업의 문제 해결에 어떻게 적용하고, 기존 워크플로우(workflow)에 어떻게 통합하며, 사용자에게 어떤 가치를 제공할지 고민하고 있습니다. 예를 들어, 특정 산업 도메인에 특화된 소규모 언어 모델(SLM)이나 에이전트(agent) 시스템의 등장은 일반적인 역량의 확장보다는 특정 니즈(needs)에 맞춘 실용적인 적용 가능성에 더 중점을 둡니다. 이러한 접근 방식은 AI 기술이 사회에 스며드는 방식이 점진적이고, 특정 맥락에 의존하며, 인간의 적응과 제도적 변화를 수반한다는 저희 프레임워크의 핵심 주장을 뒷받침합니다.

**정상 기술로서의 AI(AI as Normal Technology)와 AI 2027 사이에서 “중간 지점”을 찾기 어려운 이유**

AI의 미래에 대한 논의는 여전히 '정상 기술로서의 AI'와 'AI 2027'(초지능(superintelligence) 세계관)이라는 두 가지 극단적인 관점 사이에서 균형점을 찾기 어려운 양상을 보입니다. 많은 이들이 이 두 관점 사이의 '중간 지점'을 모색하려 하지만, 이는 종종 두 세계관이 기반하는 근본적인 인과적 이해의 차이를 간과하는 데서 발생합니다. AI 2027은 기술적 '특이점(singularity)'과 '급속한 발전(fast takeoff)' 시나리오에 초점을 맞추어, AI 역량이 특정 임계점을 넘어서면 예측 불가능한 속도로 사회를 변혁시킬 것이라고 주장합니다. 반면 저희의 프레임워크는 기술의 사회적 확산이 내재적인 속도 제한(rate limits)을 가지며, 인간의 적응, 제도적 제약, 그리고 사회적 선택이 기술의 영향을 조절한다고 강조합니다.

이러한 근본적인 시각 차이는 단순한 예측의 차이를 넘어, AI의 위험과 기회를 평가하고 정책을 수립하는 방식에까지 영향을 미칩니다. 예를 들어, '확장 법칙(scaling laws)'에 대한 최근 논의는 AI 모델의 크기가 커질수록 성능이 기하급수적으로 향상될 수 있음을 시사하지만, 저희의 관점에서는 이러한 기술적 확장이 실제 세계의 복잡성, 데이터의 질, 그리고 인간-AI 상호작용의 비효율성이라는 비기술적 장벽에 부딪힐 수밖에 없습니다. 따라서 두 세계관을 단순히 혼합하려는 시도는 종종 내부적으로 모순되거나 실질적인 정책적 함의를 도출하기 어려운 결과를 낳을 수 있습니다. 저희는 여전히 AI가 사회에 지대한 영향을 미칠 것이라는 점을 인정하지만, 그 영향이 '초지능(superintelligence)'이라는 단일 경로를 통해서가 아니라, 수많은 사회적, 경제적, 문화적 요인들과의 복잡한 상호작용을 통해 점진적으로 발현될 것이라고 믿습니다.

**다른 세계관에 몰두해 있을 때 하나의 세계관을 이해하기는 어렵습니다**

서로 다른 세계관을 가진 이들 간의 대화는 언제나 어렵습니다. 특히 AI와 같이 빠르게 변화하고 불확실성이 큰 분야에서는 더욱 그렇습니다. 저희는 초지능(superintelligence) 세계관을 가진 이들이 '언제쯤 AI가 모든 것을 바꿀 것인가?'와 같은 질문에 집착하는 경향이 있음을 자주 목격합니다. 저희는 이에 대해 '점진적인 변화'와 '지속적인 적응'을 강조하며, 특정 시점의 급진적인 변혁보다는 장기적인 사회적 진화를 주장합니다. 이러한 차이는 단순히 예측의 문제가 아니라, 기술이 사회에 미치는 영향의 본질과 그 영향력을 형성하는 주체에 대한 근본적인 견해 차이에서 비롯됩니다. 저희 프레임워크는 AI가 아무리 발전하더라도 인간의 행위자성(agency), 제도적 유연성, 그리고 정책적 선택이 기술의 궤적을 결정하는 데 결정적인 역할을 한다고 봅니다.

최근의 논의에서 '재귀적 자기 개선(Recursive Self-Improvement, RSI)'과 같은 개념은 여전히 초지능(superintelligence) 세계관의 핵심 논점으로 다루어지지만, 저희는 AI 시스템의 외부적 제약(예: 하드웨어, 에너지, 데이터, 인간의 감독)이 기술 자체의 개선만으로는 쉽게 극복될 수 없다는 점을 강조합니다. AI가 기술 설계를 개선할 수 있다고 해도, 그 개선이 사회적 확산과 채택의 복잡한 과정을 우회할 수는 없습니다. 또한, AI의 '설득력'이나 '예측력'이 인간의 능력을 초월할 것이라는 주장에 대해서도 저희는 회의적입니다. 인간의 지능은 생물학적 한계뿐만 아니라, 도구의 사용, 사회적 학습, 집단적 경험을 통해 끊임없이 진화해 왔습니다. AI는 이러한 인간 지능을 보강하는 강력한 도구가 될 수 있지만, 인간 고유의 인지적, 사회적 맥락을 완전히 대체하거나 압도하기는 어렵다고 봅니다. 이는 AI가 체스와 같은 제한된 환경에서는 인간을 능가할 수 있지만, 예측 불가능하고 복잡한 현실 세계에서는 인간과 AI의 협력이 가장 효과적인 해결책임을 시사합니다.

**AI의 이점을 얻으려면 많은 노력과 고통스러운 선택이 필요할 것입니다**

'정상 기술로서의 AI' 프레임워크는 AI의 이점을 실현하고 위험을 완화하기 위해 단순한 기술 개발을 넘어선 광범위한 노력이 필요함을 강조합니다. 이는 종종 개인, 기업, 정부 모두에게 '고통스러운 선택'을 요구합니다.

*   **데이터 거버넌스 및 개인정보 보호 강화**: AI 시스템의 성능은 데이터의 양과 질에 크게 의존하지만, 동시에 데이터 수집, 저장, 활용 과정에서 개인정보 보호와 윤리적 사용에 대한 엄격한 기준이 요구됩니다. 이는 데이터 접근성 확대와 개인의 권리 보호 사이의 균형점을 찾는 어려운 과제이며, 강력한 규제와 기술적 솔루션(예: 연합 학습, 동형 암호화)의 도입이 필수적입니다.
*   **노동 시장의 재편과 재교육 투자**: AI의 확산은 특정 직무의 자동화를 가속화하고 새로운 직무를 창출할 것입니다. 이는 대규모 인력 재배치와 재교육의 필요성을 야기하며, 정부와 기업은 이에 대한 막대한 투자를 감당해야 합니다. 노동자들은 새로운 기술에 적응하고 평생 학습을 통해 자신의 역량을 지속적으로 개발해야 하는 부담을 안게 될 것입니다.
*   **윤리적 AI 개발 및 책임성 확립**: AI 시스템의 편향성, 투명성 부족, 의사결정의 불명확성은 사회적 불평등을 심화시키고 신뢰를 저해할 수 있습니다. 개발 단계부터 윤리적 가이드라인을 내재화하고, 배포 후에도 시스템의 책임성을 확보하기 위한 법적, 제도적 장치를 마련하는 것은 시급한 과제입니다. 이는 단순히 기술적 문제를 넘어 사회적 합의와 가치 판단을 요구합니다.
*   **산업별 특수성 고려**: 금융, 의료, 제조, 교육 등 각 산업은 AI 도입에 있어 고유한 규제 환경, 레거시 시스템(legacy system), 그리고 문화적 장벽에 직면합니다. 범용적인 AI 솔루션이 모든 산업에 똑같이 적용될 수 없으며, 각 산업의 특성과 니즈(needs)에 맞춰 맞춤형 솔루션을 개발하고 통합하는 데는 상당한 시간과 자원이 소요됩니다. 이는 AI 기술이 단순히 '플러그 앤 플레이(plug-and-play)' 방식이 아니라, 깊이 있는 도메인(domain) 지식과 현장 적용 노력이 동반되어야 함을 의미합니다.

이러한 노력과 선택은 단기적인 비용을 수반하지만, AI의 장기적인 이점을 극대화하고 잠재적 위험을 최소화하기 위한 필수적인 투자입니다. AI를 '정상 기술'로 바라본다면, 우리는 기술 자체의 신비화에서 벗어나, 기술과 사회의 상호작용 속에서 발생하는 현실적인 문제들을 직시하고 해결책을 모색할 수 있을 것입니다.

**확산 속도에 대한 초현실적인 논쟁**

AI의 확산 속도에 대한 논쟁은 여전히 뜨겁습니다. 일부에서는 AI가 전례 없는 속도로 사회 전반에 퍼지고 있다고 주장하지만, 저희는 이러한 주장이 종종 '배포(deployment)'와 '확산(diffusion)'의 차이를 간과한다고 봅니다. 최신 AI 모델이 수억 명의 사용자에게 빠르게 '배포'될 수 있다는 것은 사실이지만, 이것이 곧 그 모델이 사회 전반에 깊이 '확산'되어 의미 있는 변화를 일으키고 있다는 것을 의미하지는 않습니다.

예를 들어, 많은 기업들이 AI 툴(tool)을 도입했다고 발표하지만, 실제 직원들의 일상적인 업무 흐름에 얼마나 깊이 통합되고 있는지, 그리고 그것이 실질적인 생산성 향상으로 이어지고 있는지는 별개의 문제입니다. 흔히 언급되는 'AI 동반자(AI companion)' 서비스의 빠른 사용자 증가는 초기 호기심과 접근 용이성에 기인하는 경우가 많습니다. 하지만 이러한 서비스의 장기적인 활성 사용자 수, 실제 사용 시간, 그리고 사용자의 삶에 미치는 본질적인 변화를 분석해보면, 단순한 '초기 사용자 수'만으로는 확산의 깊이를 측정하기 어렵습니다. 많은 사용자들이 잠깐 사용해보고 흥미를 잃거나, 특정 니즈(needs)에만 간헐적으로 사용하는 경향을 보입니다.

또한, 'AI가 특정 고위험 영역에서 빠르게 채택되고 있다'는 주장은 종종 오해의 소지가 있습니다. 의료 분야의 예를 다시 들자면, 의사들이 AI를 활용하여 음성 기록을 텍스트로 변환하는 것은 분명한 생산성 향상이지만, 이것이 AI가 직접 진단이나 치료 계획을 세우는 '고위험' 영역에서 광범위하게 채택되고 있다는 증거는 아닙니다. 오히려 대부분의 의사들은 AI를 보조적인 도구로 활용하며, 최종 의사결정은 여전히 인간 전문가의 책임하에 이루어집니다. 3 이는 의료 과실 책임, 직업 윤리, 그리고 규제 프레임워크(framework)와 같은 비기술적 장벽이 AI의 '고위험' 확산을 효과적으로 제한하고 있음을 보여줍니다.

저희는 확산 속도를 평가할 때, 단순한 '접근성'이나 '초기 사용자 수'를 넘어 '지속적인 사용(sustained use)', '깊이 있는 통합(deep integration)', 그리고 '측정 가능한 사회적, 경제적 가치 창출(measurable value creation)'과 같은 지표에 더 주목해야 한다고 주장합니다. 이러한 관점에서 보면, AI의 확산은 여전히 느리고 점진적인 과정이며, 기술적 역량의 발전 속도와는 상당한 괴리가 있음을 알 수 있습니다.

**AI 채택이 다르게 느껴지는 이유**

만약 “빠른 확산” 밈(meme)이 그렇게 잘못되었다면, 왜 그렇게 널리 퍼져 있고 지속적일까요? 왜냐하면 AI 채택은 PC나 인터넷, 소셜 미디어(social media)가 결코 그러지 않았던 방식으로 쓰나미처럼 느껴지기 때문입니다. 사람들이 어떤 것에 대해 직관적으로 확신할 때, 그들은 그러한 느낌을 확인시켜준다고 주장하는 데이터나 차트에 훨씬 덜 회의적일 것입니다. 물론 저희도 그 느낌을 압니다. AI에 대한 저희의 실제 경험은 과거 기술의 물결과는 다릅니다. 처음에는 저희는 이것을 인지 편향(cognitive bias)으로 치부했습니다. 저희가 현재 겪고 있는 어떤 변화든 과거에 성공적으로 적응했던 것보다 훨씬 더 큰 변화처럼 느껴질 것입니다. 저희는 이제 저희가 틀렸다는 것을 깨달았습니다. 인지 편향(cognitive bias)이 설명의 작은 부분일 수 있지만, AI 채택이 훨씬 더 빠르고 무섭게 느껴지는 진짜 이유가 있습니다. 요컨대, 배포(deployment)가 확산(diffusion)이 아니라는 것은 사실이지만, 과거에는 점진적인 배포(deployment)가 사용자들이 채택에 대한 결정을 끊임없이 내려야 하는 부담으로부터 어느 정도 보호받았다는 것을 의미했지만, 이제 그 완충 장치가 사라졌습니다.

이러한 '쓰나미처럼 느껴지는' AI 채택의 경험은 단순히 인지 편향(cognitive bias)을 넘어, 정보 과잉과 '뒤처질지도 모른다는(FOMO, Fear Of Missing Out)' 압박감에서 비롯됩니다. 끊임없이 쏟아지는 AI 관련 뉴스, 성공 사례, 그리고 경쟁사의 AI 도입 소식은 개인과 조직으로 하여금 AI를 적극적으로 검토하고 도입해야 한다는 강박감을 느끼게 합니다. 이제 AI 툴(tool)에 대한 접근성은 사실상 무제한이며, 많은 경우 무료 또는 저렴한 비용으로 이용 가능합니다. 이는 과거 PC나 인터넷처럼 고가의 장비 구매나 복잡한 설치 과정이 필요했던 기술과는 근본적으로 다릅니다.

이러한 '쉬운 접근성(easy accessibility)'은 사람들이 AI를 '사용하지 않는 것'을 더 이상 무지의 변명으로 삼을 수 없게 만듭니다. 대신, AI를 사용할지 말지, 어떤 AI를 어떻게 사용할지에 대한 '능동적인 선택'을 강요받게 됩니다. 기업의 경우, 경쟁 우위를 유지하기 위해 AI 도입을 서두르지만, 실제로는 복잡한 내부 시스템 통합, 직원 교육, 데이터 거버넌스(data governance) 문제 등 수많은 비기술적 장벽에 부딪혀 효과적인 확산에 어려움을 겪습니다. 이러한 상황은 '배포'는 빠르게 이루어지지만, '확산'은 여전히 느린 속도로 진행되는 역설적인 현상을 초래합니다. 결국, AI 기술의 진정한 가치는 단순히 기술 자체의 우수성뿐만 아니라, 그것이 사회 시스템과 어떻게 상호작용하고, 인간의 삶에 어떻게 통합되며, 장기적으로 어떤 변화를 가져올지에 달려 있습니다.

**결론**

AI는 의심할 여지 없이 우리 시대의 가장 강력하고 변혁적인 기술 중 하나입니다. 하지만 저희의 '정상 기술로서의 AI' 프레임워크가 강조하는 바는, AI가 마법처럼 모든 것을 바꾸거나 파괴할 것이라는 과장된 기대나 두려움에서 벗어나, 기술의 사회적 영향을 보다 현실적이고 역사적인 관점에서 이해해야 한다는 것입니다. 생성형 AI(generative AI)의 폭발적인 등장은 많은 이들에게 충격을 주었지만, 이제는 이러한 흥분을 가라앉히고 AI가 사회에 스며드는 복잡하고 점진적인 과정을 깊이 있게 탐구할 때입니다.

이 프레임워크는 AI 기술의 역량 발전과 사회적 확산 사이의 긴 인과 사슬(causal chain)을 명확히 하고, 이 과정에서 인간의 행위자성(agency), 제도적 유연성, 그리고 정책적 선택의 중요성을 부각합니다. 기업 리더들은 AI 도입 전략을 수립할 때 기술적 성능뿐만 아니라 조직 문화, 인력 재교육, 데이터 인프라(data infrastructure) 구축 등 비기술적 요인들을 종합적으로 고려해야 합니다. 정책 입안자들은 급변하는 기술 환경에 대응하기 위한 민첩하고 회복탄력성(resilience) 있는 규제 프레임워크(framework)를 구축하는 데 집중해야 합니다. 또한, AI 연구자들과 개발자들은 윤리적 고려와 사회적 책임감을 가지고 기술의 잠재적 위험을 완화하고 이점을 극대화하는 방향으로 나아가야 합니다.

궁극적으로, AI를 '정상 기술'로 인식하는 것은 우리가 기술에 대한 비현실적인 기대를 버리고, 그 대신 기술과 사회의 상호작용을 통해 발생하는 실제적인 도전 과제들을 해결하기 위한 구체적이고 실용적인 노력을 기울이도록 독려합니다. 저희는 이 뉴스레터를 통해 이러한 논의를 지속적으로 확장하고, AI가 우리 사회에 가져올 변화를 더 깊이 이해하고 형성하는 데 기여하고자 합니다. 여러분의 지속적인 관심과 참여를 기대합니다.

**추가 읽을거리/볼거리**

*   최근 멀티모달 AI의 발전이 산업별 적용에 미치는 영향에 대한 심층 분석 (예: 특정 보고서나 연구 언급)
*   AI 에이전트(AI agent)의 윤리적 문제와 규제 방안에 대한 전문가 토론 (예: 최근 컨퍼런스 발표나 논문)
*   AI 확산의 경제적 효과에 대한 새로운 연구 결과 (예: 노동 시장 영향, 생산성 분석)

저희는 정상 기술로서의 AI(AI as Normal Technology)에 대한 언론 보도를 받게 되어 행운이었습니다:
*   지난달 뉴욕 타임스(New York Times)에는 에릭 슈미트(Eric Schmidt)와 셀리나 쉬(Selina Xu), 데이비드 월러스-웰스(David Wallace-Wells), 그리고 에즈라 클라인(Ezra Klein)이 이 에세이를 심층적으로 논의한 세 편의 오피니언(op-ed)이 실렸습니다.
*   지난주 이코노미스트(The Economist)는 "인공지능이 그저 “정상적인” 기술이라면 어떨까?(What if artificial intelligence is just a “normal” technology?)"라는 기사에서 정상 기술 논지를 논의했습니다.
*   더 뉴요커(The New Yorker)에서 조슈아 로스먼(Joshua Rothman)은 AI 2027과 정상 기술로서의 AI(AI as Normal Technology)를 대조했습니다.
*   프로스펙트 매거진(Prospect Magazine)에서 이든 주커만(Ethan Zuckerman)은 정상 기술로서 AI를 바라보는 유용성을 논의했습니다.
*   MIT 테크놀로지 리뷰(MIT Technology Review)의 제임스 오도넬(James O'Donnell)은 정상 기술로서의 AI(AI as Normal Technology) 논지를 요약했습니다.

저희의 팟캐스트(podcast) 출연 중 일부는 다음과 같습니다:
*   뉴욕 타임스(New York Times)의 하드 포크(Hard Fork)와 팀 오라일리(Tim O’Reilly의 팟캐스트(podcast)에 출연한 아르빈드(Arvind); 로페어(Lawfare)의 스케일링 법칙(Scaling Laws)과 카네기(Carnegie)의 인도 해석(Interpreting India)에 출연한 사야시(Sayash).
*   저희는 AI 2027의 많은 저자를 포함하여 초지능(superintelligence) 세계관을 가진 많은 사람들과 대화를 나누었습니다: 사야시(Sayash)는 다니엘 코코타일로(Daniel Kokotajlo)와 엘리 리프랜드(Eli Lifland)와 토론했습니다; 아르빈드(Arvind)는 다니엘 코코타일로(Daniel Kokotajlo)와 토론했으며, 애스터리스크 매그(Asterisk Mag)에서는 아르빈드(Arvind)와 아제야 코트라(Ajeya Cotra)가 AI 발전이 속도 제한을 가지고 있는지, 그리고 우리가 어떻게 알 수 있는지에 대해 토론했습니다.

1 종종 그렇듯이, 우연한 타이밍이 에세이의 성공에 큰 역할을 했습니다. 이 에세이는 AI 2027 이후 2주 후에 발표되었지만, 이는 순전히 우연이었습니다 — 저희의 출판일은 실제로는 나이트 연구소(Knight Institute)의 AI와 민주적 자유 심포지엄(symposium)에 기반한 것이었습니다. 에세이를 출판할 기회를 준 연구소에 감사드립니다.
2 일반적으로 챗봇(chatbot)과 관련된 정신 건강 문제, 그리고 중독과 같은 문제들은 저희 책 AI 스네이크 오일(AI Snake Oil)을 포함하여 널리 인식되고 논의되어 왔습니다. 이러한 문제들은 소셜 미디어(social media)와의 비유에 기반하는 경향이 있습니다. 그러나 정신 건강 영향의 잠재력을 예측하는 것과 어떤 영향이 구체적으로 나타날지, 그리고 그것을 어떻게 피할 수 있을지 예측하는 것은 별개의 문제입니다.
3 이 프레임워크(framework)는 고전적인 혁신 확산 이론(diffusion-of-innovations theory)에서 채택되었으며, 혁신-확산 격차(innovation-diffusion gap)의 관점에서 AI 분야의 지정학적 경쟁을 분석한 제프리 딩(Jeffrey Ding)과 같은 최근 저자들의 영향도 받았습니다.
4 여기에도 위험이 있지만, 저희는 이것이 의사들이 탐색해야 할 응용 분야라고 확신합니다.
5 사실, 포켓몬 고(Pokemon Go)와 스레드(Threads)(인스타그램(Instagram)을 기반으로 성장했기 때문에 네트워크 효과(network effects)에 의존하지 않았음)와 같이 초기 성장이 ChatGPT만큼 빠르거나 더 빨랐던 다른 앱들도 있었습니다. 그러나 다시 말하지만, 저희의 더 큰 요점은 이러한 유형의 비교는 유익하지 않다는 것입니다. 스레드(Threads)는 초기 성장에도 불구하고 실패작에 가까웠습니다.
6 솔직히, 저희의 견해로는 이 그래프에서 훨씬 더 인상적인 통계는 인스타그램(Instagram)이 네트워크 효과(network effects)의 필요성에도 불구하고 단 2.5개월 만에 백만 명의 사용자에게 도달했다는 것입니다 — 이는 휴대폰 인터넷 속도가 훨씬 느렸고, 앱이 아이폰(iPhone) 전용이었으며 (!), 초기에는 주로 미국 내 18~34세 연령층에 확산되었던 2010년으로 거슬러간다는 점을 고려할 때 더욱 그렇습니다.