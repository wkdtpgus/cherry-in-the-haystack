**정상 기술로서의 AI(AI as Normal Technology)**

저희가 **정상 기술로서의 AI(AI as Normal Technology)**를 출간했을 때, 그 반향은 저희의 예상을 뛰어넘었습니다. 이 글은 저희 둘 중 누구라도 해낸 일 중 가장 영향력 있는 것이 되었습니다. 1 저희는 이를 AI의 중기적 미래와 그 영향에 대해 더 많은 시간을 생각하고 글을 쓰는 강력한 신호로 받아들였습니다. 기존 AI 스네이크 오일(AI Snake Oil) 프로젝트가 AI의 현재와 단기적 영향에 집중했던 것과 달리, 이제는 AI의 중장기적 미래와 그 파급 효과에 대한 심층적인 분석을 제공하는 데 주력하고 있습니다. 이러한 변화를 반영하여 저희는 이 뉴스레터의 이름을 변경했습니다. 저희는 이미 정상 기술로서의 AI(AI as Normal Technology) 관련 후속 에세이들을 공개했으며, 2026년 말에 완성하여 2027년 출판을 목표로 하는 책을 통해 이 프레임워크(framework)를 더욱 확장할 계획입니다. 최근 AI 기술의 발전 속도와 사회적 수용 양상에 대한 논의가 활발해지면서, 저희의 관점이 더욱 중요하게 다뤄지고 있습니다. 오늘 저희는 정상 기술로서의 AI(AI as Normal Technology)에 대한 일반적인 오해의 지점들을 다루고, 원래 에세이를 더 쉽게 접근할 수 있도록 노력하며, AI 2027과 비교해보고자 합니다.

**목차**
*   정상적이라는 것이 평범하거나 예측 가능하다는 의미는 아닙니다
*   저희 논지의 재진술
*   GPT-5에 대한 실망이 여러분을 정상 기술로서의 AI(AI as normal technology)로 이끌었다면, 여러분은 이 논지를 제대로 이해하지 못했을 수도 있습니다
*   정상 기술로서의 AI(AI as Normal Technology)와 AI 2027 사이에서 “중간 지점”을 찾기 어려운 이유
*   다른 세계관에 몰두해 있을 때 하나의 세계관을 이해하기는 어렵습니다
*   AI의 이점을 얻으려면 많은 노력과 고통스러운 선택이 필요할 것입니다
*   확산 속도에 대한 초현실적인 논쟁
*   AI 채택이 다르게 느껴지는 이유
*   AI 규제 환경의 변화와 정상 기술로서의 AI
*   결론

**정상적이라는 것이 평범하거나 예측 가능하다는 의미는 아닙니다**

에세이에서 저희가 정상적이라는 것이 무엇을 의미하는지 (아래에서 더 자세히 설명) 다루고 있지만, 무엇을 의미하지 않는지에 대해 더 명확히 설명할 수도 있었습니다. 저희의 요점은 “볼 것 없으니 지나가세요”가 아닙니다. 자동차나 소셜 미디어와 같은 강력한 기술들이 그래왔듯이, AI 또한 예측 불가능한 사회적 파급 효과를 수반합니다. 이는 기술 자체의 발전 경로만으로는 온전히 예측하기 어려운, 기술과 인간 사회의 복합적인 상호작용에서 비롯되는 비예측적 현상(emergent phenomena)입니다. 이것이 기술 결정론(technological determinism)을 거부하는 것이 정상 기술 에세이의 핵심 전제 중 하나인 이유입니다. 챗봇을 포함한 AI 기술의 경우, 이미 비예측적 사회적 효과를 경험하고 있습니다. AI 동반자의 확산이나 'AI 정신증(AI psychosis)' 같은 모델 아첨(model sycophancy)의 부작용은 많은 이들을 놀라게 했지만, 반대로 선거 조작과 같이 널리 예측되었던 위협 중 일부는 아직 현실화되지 않았습니다. 2 최근 몇몇 국가에서 AI 기반의 허위 정보가 선거에 미칠 영향에 대한 우려가 있었으나, 실제 선거 결과에 미친 결정적인 영향은 미미했다는 분석이 나오기도 했습니다. 3~5년 후 AI의 사회적 영향의 지형이 어떻게 보일지는 — 미래 역량이 아닌 현재 역량의 확산에 기반하더라도 — 누구도 예측할 수 없습니다. AI 기술 자체의 발전 속도는 비교적 예측 가능하지만, 사회적 파급 효과는 훨씬 예측하기 어렵습니다. 예를 들어, AI 2027의 공동 저자인 다니엘 코코타일로(Daniel Kokotajlo)가 2021년 에세이에서 예측했던 2026년의 기술적 역량은 놀랍도록 정확했으나, 그 사회적 영향에 대한 예측은 예상과 달랐다는 점을 그 스스로도 인정했습니다. 이 모든 것은 AI를 기관과 정책 입안자들에게 더 심각한 도전 과제로 만듭니다. 왜냐하면 그들은 예측의 잘못된 안도감에 의존하거나 모든 해악을 방지하려 노력하는 대신 예측 불가능한 영향에 민첩하게 대응해야 할 것이기 때문입니다. 광범위하게 말해서, 이러한 적응성을 가능하게 하는 정책 수립 접근 방식은 회복탄력성(resilience)이라고 불리며, 이는 저희 에세이가 옹호했던 바입니다. 그러나 저희가 잠재적으로 치명적인 위험을 다루는 접근 방식으로 회복탄력성을 강조했지만, 회복탄력성이 더 광범위하게 퍼져 있는 위험을 다루는 데도 중요한 역할을 한다는 점을 더 명확히 했어야 했습니다. 일부 독자들이 '정상'이라는 단어로 인해 저희의 예측 가능성 견해를 오해했을 수 있습니다. 저희는 AI에 적응하는 것이 결코 사소한 문제가 아님을 다시 한번 강조합니다. 이상적인 세상에서는 단순히 “기술로서의 AI(AI as Technology)”가 더 나은 제목이었겠지만, 저희는 그것이 저희의 목표가 현재 담론을 지배하고 있는 초지능(superintelligence) 세계관을 특징짓는 예외주의(exceptionalism)에 대한 대안을 제공하는 것임을 효과적으로 전달할 것이라고 생각하지 않았습니다.

**저희 논지의 재진술**

저희 논지의 핵심을 추출하고 단순화한다면 다음과 같을 것입니다: AI 역량 증가와 사회적 영향 사이에는 긴 인과 사슬(causal chain)이 있습니다. 이점과 위험은 AI가 개발될 때가 아니라 배포될 때 실현됩니다. 이는 저희(개인, 조직, 기관, 정책 입안자)에게 그러한 영향을 형성하는 데 많은 영향력을 행사할 수 있는 지점들을 제공합니다. 따라서 저희는 역량 개발 속도에 대해 그렇게 많이 걱정할 필요가 없습니다. 저희의 노력은 AI의 이점을 실현하고 위험에 대응하는 관점에서 배포 단계(deployment stage)에 더 집중해야 합니다. 이러한 관점은 현재의 AI뿐만 아니라, AI의 자기 개선(self-improvement)과 같은 가설적인 미래 발전에도 적용됩니다. AI 시스템의 영향력에는 기술 내부적인 요인 외에도 외부적인 사회적, 제도적 한계가 존재하며, 이는 AI 자체의 기술적 설계 개선만으로는 극복하기 어렵습니다. 이 프레임워크(framework)의 측면들은 결국 수정되어야 할 수도 있지만, 그것은 저희가 의미 있게 예측하거나 준비할 수 있는 지평 너머에 있습니다: 저희가 2부에서 설명하는 세상은 오늘날보다 AI가 훨씬 더 발전한 세상입니다. 저희는 AI 발전—또는 인간의 발전—이 그 지점에서 멈출 것이라고 주장하는 것이 아닙니다. 그 이후에는 무엇이 올까요? 저희는 모릅니다. 이 비유를 생각해 보십시오: 1차 산업혁명(Industrial Revolution)의 여명기에 산업 세계가 어떻게 보일지 생각하고 준비하는 것은 유용했을 것이지만, 전기나 컴퓨터를 예측하려 시도하는 것은 헛된 일이었을 것입니다. 여기서 저희의 작업도 비슷합니다. 오늘날의 AI는 마치 초기 인터넷처럼, 그 잠재력은 무궁무진하지만 그 최종 형태와 사회적 통합 방식은 아직 미지수입니다. 저희는 “급속한 발전(fast takeoff)” 시나리오(scenario)를 거부하기 때문에, 저희가 시도한 것보다 더 먼 미래의 세상을 상상하는 것을 필요하거나 유용하다고 보지 않습니다. 저희가 제시하는 시나리오가 현실화된다면, 그 다음 단계의 변화에 더 효과적으로 대비할 수 있을 것입니다. 어쨌든, 다시 말하지만, 논지의 핵심은 AI와 사회 간의 관계를 이해하기 위한 근본적인 인과 프레임워크(causal framework)이며, AI가 가질 수도 있고 가지지 않을 수도 있는 특정 영향이 아닙니다. 저희의 견해로는, 이 인과적 이해를 공유한다면, 여러분은 정상 기술 논지(normal technology thesis)에 동의하는 것입니다. 저희는 이 프레임워크(framework)가 암묵적으로나마 실제로 널리 공유되고 있음을 발견했습니다. 이는 많은 독자들의 마음속에서 이 논지를 거의 동어반복적(tautological)으로 만듭니다. 저희는 저희가 보기에 — 그리고 독자들이 보기에 — 매우 약한 주장을 하고 있는 것입니다! 이를 인식하지 못하면 독자들은 저희가 “정상”이라는 말로 의미했을지도 모르는 훨씬 더 구체적인 것을 찾으려 합니다. 하지만 저희는 그렇지 않았습니다. 저희는 기술을 “정상”과 “비정상”으로 분류한 다음 AI를 “정상” 범주에 넣는 것이 아닙니다. 저희는 단지 AI를 다른 강력한 범용 기술(general-purpose technologies)처럼 다루어야 한다고 말하는 것입니다. 이는 대규모 언어 모델(large language models)이나 특정 종류의 AI에만 국한된 것이 아닙니다. 덧붙여 말하자면, 이것이 제목이 “정상 기술로서의 AI(AI as normal technology)”이지 “하나의 정상 기술로서의 AI(AI as a normal technology)”가 아닌 이유입니다. 저희의 견해는 총체적으로 AI라고 불리는 모든 기술과, AI라고 불리지 않더라도 유사한 다른 기술에 적용됩니다. 저희의 관점이 동어반복적으로 느껴진다면, 굳이 이를 강조하는 이유는 무엇일까요? 이는 초지능(superintelligence) 세계관과 명확히 대비되기 때문입니다. 서로 다른 세계관들은 각기 고유한 전제와 논리를 가지며, 이를 신봉하는 이들에게는 각자의 관점이 너무나 당연하게 받아들여질 수 있습니다.

**GPT-5에 대한 실망이 여러분을 정상 기술로서의 AI(AI as normal technology)로 이끌었다면, 여러분은 이 논지를 제대로 이해하지 못했을 수도 있습니다**

GPT-5 출시 이후 저희 에세이에 대한 관심이 급증했으며, 그 중 적어도 일부는 출시에 실망한 후 사람들이 관점을 약간 바꾼 때문이라고 추측하는 것이 합리적입니다. 이것은 이상합니다! 이런 일이 처음은 아닙니다 — 저희는 이전에 거의 새로운 정보 없이 발생한 확장(scaling)에 대한 큰 서사적 변화에 회의적인 시각을 표명했습니다. 단 하나의 제품 업데이트가 AI의 미래 궤적에 대한 사람들의 인식을 변화시킨다면, 과연 그들의 기존 판단 근거는 얼마나 견고했던 것일까요? 정상 기술 프레임워크는 AI 역량의 발전이 지속되더라도 그 사회적 영향은 점진적으로 나타날 것이라는 예측을 합니다. 따라서 저희는 새로운 출시에 대한 실망이 여러분을 AI를 정상 기술로 보는 것에 더 공감하게 만들어서는 안 된다고 생각합니다. 마찬가지로, 내일 발표될 새로운 돌파구도 저희의 견해에 대해 더 회의적으로 만들어서는 안 됩니다. GPT-5를 이해하는 가장 좋은 방법은, 이는 AI 개발자들이 모델에서 제품으로 강조점을 전환하는 특히 좋은 예시라는 것입니다. 저희는 이에 대해 1년 전에 글을 썼습니다. 자동 모델 전환기(automatic model switcher)는 ChatGPT의 일상 사용자들에게 큰 의미가 있습니다. 출시된 지 거의 1년이 지나도 “사고(thinking)” 모델을 사용하는 사람이 거의 없었지만, GPT-5는 그 사용량을 극적으로 증가시켰습니다. 최근에는 멀티모달(multimodal) 기능의 강화나 모델 효율성 개선 등 사용자 경험을 향상시키는 방향으로 LLM 개발의 초점이 이동하고 있습니다. 일부 통신에서 알트만(Altman)은 GPT-5의 강조점이 역량의 도약이 아니라 유용성이었음을 분명히 밝혔지만, 이 메시지는 불행히도 끊임없는 과대광고(hype)로 인해 약화되어 실망으로 이어졌습니다. 이는 AGI나 초지능 개발 경쟁보다는, 실질적인 제품 개발과 시장 채택 촉진이라는 현실적인 노력이 성공의 열쇠임을 업계가 점차 인식하고 있다는 증거입니다. 아이러니하게도, 이 서사에서 GPT-5는 실패가 아니라 성공의 예시입니다. 사실, 모델 개발자들은 더 유용한 제품을 개발하는 것(저희 기술 개발 및 채택 프레임워크(technology development & adoption framework)의 두 번째 단계)을 넘어 배포자(deployer)와 협력하여 초기 채택의 어려움을 완화하는 것(세 번째 단계)으로 나아가기 시작했습니다. 예를 들어, OpenAI의 선행 배포 엔지니어(Forward Deployed Engineers)는 존 디어(John Deere)와 같은 고객 및 농부들과 직접 협력하여 살충제 적용을 위한 맞춤형 권장 사항 제공과 같은 역량을 통합하고 배포하고 있습니다.

**정상 기술로서의 AI(AI as Normal Technology)와 AI 2027 사이에서 “중간 지점”을 찾기 어려운 이유**

많은 사람들이 AI 2027과 정상 기술로서의 AI(AI as Normal Technology) 사이에서 중간 지점의 입장을 명확히 표현하려 노력했으며, 아마도 이들을 견해 스펙트럼(spectrum)의 양극단으로 보았을 것입니다. 이는 놀랍게도 어려운 일입니다. AI 2027과 정상 기술로서의 AI(AI as Normal Technology)는 모두 일관된 세계관입니다. 이들은 기술이 사회에 어떻게 영향을 미칠지에 대한 매우 다른 인과적 이해를 나타냅니다. 만약 여러분이 섞어서 맞추려 한다면, 내부적으로 일관성 없는 잡동사니로 끝날 위험이 있습니다. (덧붙여 말하자면, 이는 저희가 결국 틀렸다면, 조금 틀리기보다는 완전히 틀릴 가능성이 더 높다는 것을 의미합니다.) 게다가, 실리콘 밸리(Silicon Valley)의 특정 환경에서만 정상 기술로서의 AI가 회의적인 시각으로 비칠 수 있습니다! 저희는 에세이에서 AI를 전기에 비유하며, 그 파급력이 매우 심대할 것임을 일관되게 강조했습니다. AI가 노동 시장에 미칠 영향에 대한 저희의 예상은 해당 분야 경제학자들의 예측 중에서도 상당히 적극적인 편에 속합니다. 요컨대, 온건한 입장을 찾고 있다면, 저희 에세이 전체를 읽어보시기를 권합니다. 제목 때문에 저희가 AI 회의론자라고 생각하게 하지 마십시오. 아마도 여러분은 정상 기술로서의 AI(AI as Normal Technology)가 이미 여러분이 찾고 있는 중간 지점이라고 결론 내릴 것입니다. 저희는 AI의 미래에 대해 생각하는 가장 널리 논의되는 두 가지 프레임워크(framework)가 그렇게 근본적으로 다르다는 것이 불편할 수 있다는 것을 알고 있습니다. (저희 에세이 자체는 4부에서 정책에 관한 이 상황에 대해 많은 논평을 제공합니다.) 저희는 몇 가지 위로가 되는 생각을 제공할 수 있습니다: 저희는 AI 2027 저자들과 많은 합의점을 가지고 있습니다. 저희는 그러한 분야를 설명하는 공동 성명을 작성 중입니다. 이 노력을 조직해 준 니콜라스 칼리니(Nicholas Carlini)에게 감사드립니다. 최근에는 양측의 건설적인 대화를 통해 공통의 정책 권고안을 도출하려는 움직임도 활발해지고 있습니다. 저희의 견해로는, 신념의 일치보다 더 중요한 것은 신념의 차이에도 불구하고 정책에서의 공통점입니다. 서로 다른 측이 동의할 수 있는 비교적 “쉬운” 정책 개입조차도 실제로는 엄청난 도전이 될 것입니다. 만약 저희가 이것들을 달성할 수 없다면, 임박한 초지능(superintelligence)을 걱정하는 사람들이 선호하는 훨씬 더 급진적인 조치에 대한 희망은 거의 없습니다. 의견 불일치의 핵심(cruxes)을 식별하고 두 세계관 사이를 판단하는 데 도움이 될 수 있는 지표에 동의하기 위한 몇 가지 지속적인 노력이 있었습니다. 저희는 이러한 노력 중 일부에 참여했으며 앞으로도 계속 참여하기를 기대합니다. 이 분야에서의 골든 게이트 AI 연구소(Golden Gate Institute for AI)의 노력에 감사드립니다. 지표 개발과 관련하여, 저희는 프로젝트 HAL, 즉 총체적 에이전트 리더보드(Holistic Agent Leaderboard)에 대한 비전을 확장하고 있습니다. 현재는 AI 에이전트(AI agent)를 위한 더 나은 벤치마크 오케스트레이션 시스템(benchmark orchestration system)이 되려고 노력하고 있지만, 새로운 계획은 AI 커뮤니티(AI community)가 AI 에이전트(AI agent)가 다양한 영역에서 변혁적인 실제 세계 영향(transformative real-world impacts)을 위한 역량 임계값(capability thresholds)을 언제 넘어섰는지 식별하는 데 도움이 되는 조기 경보 시스템(early warning system)으로 개발하는 것입니다. 저희는 이러한 역량 임계값(capability thresholds)을 영향에 대한 필수적이지만 항상 충분한 조건은 아니라고 보며, 이러한 임계값에 도달하면 이점과 위험 모두에 대한 비기술적 장벽에 대한 저희의 논지를 훨씬 더 날카롭게 압박할 것입니다. HAL은 예측에 관한 것이 아니라 현재 상황 인식(situational awareness)에 관한 것임을 주목하십시오. 이것이 저희 작업의 주제입니다. 일반적으로 AI 담론에서, 특히 저희와 AI 2027 사이에서 놀라운 점은 미래뿐만 아니라 확산 속도(아래에서 더 자세히 설명)와 같이 저희가 관찰할 수 있는 것들에 대한 견해의 폭이 넓다는 것입니다. 저희가 커뮤니티(community)로서 현재에 대한 측정과 진보에 대한 경쟁적인 인과적 설명(causal explanations)을 테스트하는 데 훨씬 더 능숙해지지 않는 한, 예측에 투입되는 에너지 수준이 잘못된 방향으로 흐를 것입니다. 왜냐하면 그러한 예측을 해결할 방법이 부족하기 때문입니다. 예를 들어, 저희는 “AGI(인공 일반 지능)”가 사후적으로(post facto) 구축되었는지조차 반드시 알 수 없을 것이라고 주장했습니다. 어느 정도 이러한 한계는 AGI와 같은 개념의 개념적 정밀성(conceptual precision) 부족으로 인해 본질적이지만, 동시에 저희가 측정에서 훨씬 더 잘할 수 있다는 것도 사실입니다.

**다른 세계관에 몰두해 있을 때 하나의 세계관을 이해하기는 어렵습니다**

저희는 다음과 같이 썼습니다: 정상 기술로서의 AI(AI as normal technology)는 임박한 초지능(superintelligence)으로서의 AI 세계관과 대조되는 세계관입니다. 세계관은 가정, 어휘, 증거 해석, 인식론적 도구(epistemic tools), 예측, 그리고 (가능성 있는) 가치로 구성됩니다. 이러한 요소들은 서로를 강화하고 각 세계관 내에서 긴밀한 묶음을 형성합니다. 이는 세계관 간의 소통을 어렵게 만듭니다. 예를 들어, AI 2027 지지자들로부터 자주 받는 질문 중 하나는 '2027년 세상이 어떻게 변할 것인가'입니다. 저희는 현재(2025년)와 크게 다르지 않을 것이라고 답변합니다. 그들은 2035년이나 2045년과 같은 변혁적인 미래를 예측하지 못하는 것을 저희 프레임워크의 한계로 지적하지만, 이러한 시나리오 예측은 그들의 세계관에서만 유의미합니다. 저희는 저희가 실질적으로 다룰 수 있는 범위 내에서 구체적인 논의를 전개합니다. 동시에, 저희는 AI 2027이 상정하는 미래를 포함하여, 인간, 제도, 정치적 주체(agency)가 미래를 형성하는 데 중요한 역할을 한다고 강조합니다. 따라서 정상 기술로서의 AI(AI as normal technology)는 단순한 예측을 넘어선 처방적 성격을 가집니다. 이러한 소통의 어려움은 AI 2027 저자 중 한 명인 스콧 알렉산더(Scott Alexander)가 정상 기술로서의 AI(AI as Normal Technology)에 대해 내놓은 반응을 고려할 때 중요하게 염두에 두어야 합니다. 저희는 그의 대화 노력이 선의의 노력이라는 점을 의심하지 않으며, 그가 시간을 할애해 준 것에 감사하지만, 유감스럽게도 그의 반응은 저희의 말을 제대로 이해하지 못하고 엇나간 대화를 한다고 느낍니다. 그가 의견 불일치의 핵심(cruxes)으로 식별하는 것들은 저희가 핵심으로 여기는 것들과는 상당히 다릅니다! 이러한 이유로, 저희는 항목별 답변을 하지 않을 것입니다. 왜냐하면 저희도 결국 그와 엇나간 대화를 하게 될 것이기 때문입니다. 하지만 저희는 조정된 대화에 기꺼이 참여할 것이며, 이는 지난 1년 동안 8~10회 성공적으로 참여했던 형식입니다. 동시적인 특성은 서로를 이해하는 것을 훨씬 더 쉽게 만듭니다. 그리고 비공개 대화가 공개되기 전에 편집될 것이라는 사실은 각 측이 상대방의 관점을 이해하기 위해 어리석은 질문을 하는 것을 더 쉽게 만듭니다. 이러한 대화는 서로의 관점을 심화하고, 궁극적으로 AI의 건전한 발전에 기여하는 중요한 과정이라고 생각합니다. 어쨌든, 알렉산더(Alexander)의 반응에서 저희의 의도를 오해한 몇 가지 중요한 지점이 있습니다. 예를 들어, 재귀적 자기 개선(Recursive Self-Improvement, RSI)은 그의 관점에서 핵심적인 불일치 지점이지만, 저희는 에세이에서 RSI를 거의 언급하지 않아 그를 놀라게 했습니다. 저희는 RSI에 대한 우리의 입장을 더 명확히 설명할 수도 있었을 것입니다. 요컨대, 저희는 RSI가 초지능(superintelligence)으로 이어질 것이라고 생각하지 않습니다. 왜냐하면 강력한 AI 시스템을 구축하고 배포하는 데 대한 외부 병목 현상은 기술 설계를 개선하는 것만으로는 극복될 수 없기 때문입니다. 이것이 저희가 그것을 많이 논의하지 않는 이유입니다. 3 비록 저희에게 핵심(crux)은 아니지만, 저희는 AI 커뮤니티(AI community)가 RSI에 전혀 근접하지 못했다고 생각하는 이유를 에세이에서 설명합니다. 최근에는 해결해야 할 근본적인 연구 과제에 대해 생각하고 있는데, 저희가 깨달았던 것보다 훨씬 더 많습니다. 그리고 AI 커뮤니티(AI community)가 다른 과학 커뮤니티(community)에 비해 진보를 위한 새로운 패러다임(paradigm)을 찾는 데 특히 서툴 수 있다는 점을 염두에 둘 가치가 있습니다. 다시 말하지만, 이것은 저희 프로젝트 HAL이 진보를 측정하는 데 역할을 할 수 있기를 바라는 분야입니다. 알렉산더의 반응 중 또 다른 오해의 지점은 확산 속도에 대한 논의였습니다. 이 부분은 아래에서 다시 다루겠지만, 향후 에세이에서 더욱 심층적으로 다룰 예정입니다. 세계관 간의 담론의 어려움을 가장 잘 보여주는 것은 예측이나 설득과 같은 작업에서 인간 초월적인 AI 능력이 가능한지 여부에 대한 저희의 가설에 대한 알렉산더(Alexander)의 논의입니다. 그의 반응을 여러 번 읽은 후에도 저희는 정확히 어디에서 동의하고 어디에서 동의하지 않는지 파악하기 어렵습니다. 저희는 다음과 같이 썼습니다: 저희는 인간의 한계가 너무나 명확하여 AI가 인간의 성능을 훨씬 뛰어넘을 수 있는 (AI가 체스에서 그러하듯이) 실제 세계의 인지 작업은 상대적으로 거의 없다고 생각합니다. ... 구체적으로, 저희는 두 가지 영역을 제안합니다: 예측과 설득. 저희는 AI가 지정학적 사건(예: 선거)을 예측하는 데 훈련된 인간(특히 인간 팀, 그리고 간단한 자동화 도구로 보강된 경우)을 의미 있게 능가할 수 없을 것이라고 예측합니다. 저희는 사람들이 자신의 이익에 반하여 행동하도록 설득하는 작업에 대해서도 동일한 예측을 합니다. 알렉산더(Alexander)는 그의 에세이 3B 섹션에서 인간의 생물학적 한계에 초점을 맞춰 반박합니다. 그는 수천 년간 아프리카 사바나에서 진화한 인간이 '예측 대회에서 최고 점수를 얻는 것'과 같은 특정한 압력에 노출되지 않았으므로, 이를 달성했다고 볼 근거가 없다고 주장합니다. 또한, 농업 혁명 이후 1만 년간의 진화가 인간 지능에 미친 영향을 고려할 때, 인간이 생물학적 최대치에 도달했다고 단정할 수 없다는 논리를 펼칩니다. 그러나 인간 능력에 대한 생물학적 개념을 거부하는 것은 저희에게 핵심 출발점이며, 저희는 “인간의 능력은 생물학에 의해 제약받지 않는다(Human Ability Is Not Constrained by Biology)” 섹션에서 이를 자세히 설명하기 위해 노력합니다. 이것이 세계관 간의 논의의 문제입니다: 만약 여러분이 특정 진술을 취하고, 그 진술에 이르는 전제와 용어적 명확화(terminological clarifications)를 무시하고, 그것을 여러분의 세계관으로 해석한다면, 상대방이 무지하다고 생각할 것입니다. 알렉산더는 저희가 과거의 인간이 현재의 선거를 예측할 수 있다고 주장하는 것으로 오해하는 듯합니다. 그는 인간의 능력이 고정되어 있지 않음을 강조하면서도, 이를 저희 논지의 핵심이 아닌 반박으로 해석하는 경향이 있습니다. 아마도 예측에서 인간 성능의 '환원 불가능한 오류(irreducible error)'에 대한 저희의 가설 때문에 혼란이 있었을 것입니다. 저희는 이 오류가 고정된 값이 아니라, 사용 가능한 데이터와 훈련에 따라 달라질 수 있다고 봅니다. 이 훈련에는 AI 기반 예측 연구의 결과도 포함될 수 있습니다. 저희는 원래 에세이에서 인간 지능이 저희의 생물학 때문이 아니라 AI를 포함한 저희 도구에 대한 (우발적인) 숙달 때문에 특별하다고 강조합니다. 따라서 AI의 발전은 종종 인간 지능(능력)을 향상시킬 것이며, 저희가 제안하는 인간-AI 비교의 양측 성능을 향상시킬 잠재력을 가지고 있습니다. 저희 가설의 핵심은 예측이 체스와는 다르다는 것입니다. 체스에서는 AI의 방대한 계산 능력이 결정적인 우위를 제공하지만, 예측의 계산 구조는 훈련과 데이터에 따라 성능이 크게 향상될 수 있음에도 불구하고 비교적 단순합니다. 숙련된 전문가 예측가 팀이 간단한 계산 도구를 활용한다면, 거의 모든 가능한 정보를 추출할 수 있습니다. 저희는 알렉산더(Alexander)의 반응이 “상호 협력 가능성에 대해 말뿐이 아니라 실제로 행동한다”는 점을 저희에게 인정해 준 것에 기쁩니다. 그 감정은 상호적입니다. 저희는 서브스택(Substack) 반박과 재반박보다 더 생산적이라고 생각하는 그 협력을 계속하기를 기대합니다.

**AI의 이점을 얻으려면 많은 노력과 고통스러운 선택이 필요할 것입니다**

저희 프레임워크(framework)에는 두 가지 광범위한 함의가 있습니다: 하나는 경제와 노동에 대한 것이고, 다른 하나는 안전에 대한 것입니다. 몇 가지 기본 전제(특히, 초지능(superintelligence)은 정의에 따라 비일관적이거나 불가능하다는 것)를 넘어서면, 이 두 가지 함의 뒤에 있는 저희의 주장은 대체로 다릅니다. 경제적 측면에서, 저희는 AI의 역량 개선만으로는 확산 장벽이 쉽게 극복되지 않을 것이라고 주장합니다. 안전 측면에서는, 정렬(alignment)이 없더라도 AI 제어가 가능하며, 이는 특별히 어렵거나 과학적 돌파구가 필요한 과제가 아니라고 봅니다. 이 두 주장은 서로 크게 독립적이므로, 한쪽만 수용하거나 양가적인 태도를 취하는 것이 모순되지 않습니다. 특히 경제적 영향에 대한 저희의 견해는 많은 독자들의 공감을 얻고 있습니다. 에세이 출간 이후, 저희는 다양한 산업 분야에서 AI 전략을 담당하는 사람들과 많은 논의를 가졌습니다. 저희는 그들이 AI에 대해 생각했던 방식이 저희와 일치했지만, 모든 과대광고(hype) 때문에 자신들의 접근 방식에 대해 재고하기 시작했다는 것을 발견했습니다. 저희 에세이는 현장에서의 관찰뿐만 아니라 그들의 직관을 뒷받침하는 일관된 프레임워크(framework)를 제공했습니다. 4 최근 많은 기업들이 AI 도입을 서두르면서 예상치 못한 복잡성과 통합의 어려움에 직면하고 있으며, 이는 저희의 주장을 뒷받침합니다. AI 배포자들은 기술 개발과 확산의 차이를 명확히 인지하고 있지만, 저희 프레임워크는 이를 더 세분화합니다. 개발 단계에서는 모델과 제품, 즉 역량과 실제 애플리케이션(application) 사이의 간극을 중요하게 보며, 확산 단계에서는 사용자 학습 곡선(user learning curves) 및 개인의 적응, 그리고 구조적, 조직적, 법적 변화와 같은 집단적 노력이 필요한 요소들을 구분합니다. 각 단계에서 발생하는 속도 제한 요인을 설명합니다. 사용자 행동은 적어도 느리지만 예측 가능하게 변하는 경향이 있지만, 경직된 제도(sclerotic institutions)를 개혁하거나 조정 문제를 해결하는 것은 훨씬 불확실합니다. 이는 효과적인 기술 채택의 필수 전제 조건임에도 불구하고, 항공 교통 관제(Air Traffic Control)와 같이 현대화되지 못한 채 막대한 비용을 초래하는 사례가 많습니다. 저희 에세이는 AI의 경우에도 유사한 확산 장벽이 존재한다는 점을 지적했지만, 저희는 이제야 그러한 장벽을 명확히 설명하고 필요한 특정 개혁을 식별하는 작업을 하고 있습니다. 저희는 이 분야에 대해 더 많은 글을 쓸 것이며, 그 중 일부는 저스틴 컬(Justin Curl)과 협력할 것입니다. 첨단 AI가 이미 고도로 기술적이고 고도로 규제된 세상으로 진입하고 있다는 점을 염두에 둘 가치가 있습니다. AI가 적용되는 워크플로우(workflow)의 많은 부분은 이미 이전 기술 혁신을 통해 생산성 향상이 이루어졌기 때문에 병목 현상이 될 가능성이 적습니다. 오히려 실제 병목 현상은 규제나 기타 외부 제약으로 인해 발생하는 경우가 많습니다. 법률 서비스와 과학 연구를 포함한 많은 특정 영역에서 경쟁 역학(competitive dynamics)이 너무 강해서 AI로 인한 생산성 향상이 궁극적으로 사회적 가치로 이어지지 않는 군비 경쟁의 심화로 이어집니다.

**확산 속도에 대한 초현실적인 논쟁**

저희는 서로 다른 진영들이 현재 AI의 영향력을 어떻게 특징짓는지에 대해 이견을 보이고 있다는 점을 여러 번 언급했습니다. 확산 속도보다 더 명확하게 드러나는 곳은 없습니다. AI 지지자들은 AI가 전례 없이 빠르게 채택되고 있다고 믿습니다. 저희는 전적으로 동의하지 않습니다. 더 나쁜 것은, 더 많은 증거가 나올수록 각 측은 자신들의 해석에 대해 더 확신하는 것처럼 보인다는 것입니다. 저희는 AI 확산 속도에 대한 심층적인 분석을 계속하고 있습니다. 현재 시점에서, '빠른 채택'이라는 주장을 뒷받침하기 위해 제시되는 일반적인 논거와 통계에 몇 가지 근본적인 오류가 있음을 지적하고자 합니다. 첫째, 배포(deployment)가 곧 확산(diffusion)을 의미하지는 않습니다. 흔히 '빠른 채택'을 언급할 때, 수억 명의 사용자가 챗봇(chatbot)과 같은 제품에 즉시 접근할 수 있다는 점을 드는데, 이는 확산의 진정한 의미와 다릅니다. 중요한 것은 단순히 접근 가능성이 아니라, 얼마나 많은 사람들이 실제로 AI를 사용하고, 얼마나 지속적으로, 그리고 어떤 목적으로 사용하는지입니다. 그러한 세부 사항들을 깊이 파고들면, 그림은 매우 다르게 보입니다. 예를 들어, ChatGPT에서 자랑스럽게 출시된 “사고(thinking)” 모델이 출시된 지 거의 1년이 지나도, 사용자의 1% 미만이 매일 그것을 사용했습니다! 이것이 저희 논지를 뒷받침함에도 불구하고, 저희는 이 점을 지적하는 데 즐거움을 느끼지 않습니다. AI의 열렬한 얼리 어답터(early adopters)로서, 이러한 숫자는 너무 낮아서 저희가 직관적으로 이해하기 어렵고, 솔직히 꽤나 우울합니다. 이러한 현상은 최근 'AI 피로감(AI fatigue)'이라는 용어로도 설명되며, 초기 기대감이 실질적인 효용으로 전환되는 데 시간이 걸린다는 것을 보여줍니다. 오해의 소지가 있는 또 다른 통계는 특정 고위험 직종에서 AI를 사용하는 근로자의 비율에 관한 것입니다. 이 수치는 AI가 위험한 방식으로 빠르게 확산되고 있다는 주장을 뒷받침하는 데 사용되곤 합니다. 그러나 고위험 직종 내에서도 대부분의 업무는 일상적이며, AI의 특정 용례를 자세히 살펴보면 위험성이 크지 않음을 알 수 있습니다. 예를 들어, 미국 의사 협회(American Medical Association) 설문조사에서 대다수 의사가 AI를 사용한다고 응답했습니다. 그러나 이는 구술 메모 전사(transcription)와 같은 간단한 용도뿐 아니라, 챗봇(chatbot)을 통한 진단 보조(2024년 12%, 2023년 11%에서 1%p 증가)와 같은 사례도 포함됩니다. 진단 보조는 전사보다 복잡하지만, 여전히 합리적인 범위 내의 사용이며, 신뢰도가 낮은 AI도 오류 감지(error detection)에 유용할 수 있습니다. 이러한 작업에 대한 AI 채택 증가는 의사들이 무모하게 행동하고(YOLOing it) ChatGPT에 결정을 위임함으로써 환자에 대한 책임을 포기하려 한다는 것을 의미하지 않습니다. 대다수의 의사들은 이 두 가지 유형의 사용 간의 차이를 이해하고 있으며, 의료 과실 책임, 직업 윤리 강령, 의료 기기 규제를 포함하여 의료 전문가 내에서 광범위한 무책임한 사용을 방지하는 많은 중첩되는 안전장치(guardrails)가 있습니다. 가장 오해의 소지가 있는 “빠른 채택” 밈(meme)은 아마도 ChatGPT가 약 두 달 만에 1억 명의 사용자에게 도달했음을 보여주는 이 널리 공유된 차트일 것입니다: 이 차트는 ChatGPT 사용자 증가를 (1) 네트워크 효과(network effects)에 따라 유용성이 달라지므로 첫날부터 유용한 앱보다 훨씬 느리게 성장하는 특징이 있는 소셜 미디어(social media) 앱인 인스타그램(Instagram), 페이스북(Facebook), 트위터(Twitter)와 비교하고, (2) 처음에는 초대 전용이었던 앱인 스포티파이(Spotify)와 (3) 제한된 재고로 출시되었고 사용하려면 구독이 필요했던 서비스인 넷플릭스(Netflix)와 비교합니다. 6 이 차트에 반영된 것은 앱에 대한 소문이 돌면 확인해 보는 얼리 어답터(early adopters)이며, ChatGPT에 대한 엄청난 소문이 있었습니다. 이러한 호기심 많은 초기 사용자들을 소진하면, 성장 곡선은 매우 다르게 보입니다. 사실, 1년 후 ChatGPT는 1억 명에서 2억 명의 사용자로만 성장한 것으로 보이며, 이는 곡선이 오른쪽으로 급격히 꺾였다는 것을 분명히 보여줍니다. 이는 처음 두 달만을 반영하는 이 그래프에는 편리하게도 포착되지 않았습니다. 이 차트는 확산 장벽이 약화되거나 제거되었다는 증거를 제공하지 못합니다. 단 두 달은 사용자가 AI를 워크플로우(workflow)에 생산적으로 통합하는 등 확산의 핵심 단계가 시작되기에도 턱없이 부족한 시간입니다. 따라서 이 차트는 확산 속도 논의에 유의미한 정보를 제공하지 못합니다. 이 차트에는 다른 많은 문제점들이 있지만, 여기에서 멈추겠습니다. 7 다시 말하지만, 이것은 AI 확산 속도에 대한 완전한 분석과는 거리가 멀며 — 그것은 곧 나올 것입니다. 현재로서는, 이 주제에 대한 대부분의 논평이 단순히 진지하지 않다는 점을 지적하는 것뿐입니다. 그리고 저희가 데이터를 가지고 있는 질문에 대한 담론이 이렇다면, 서로 다른 진영의 미래 예측이 서로 전혀 닮지 않았다는 것은 놀라운 일이 아닙니다.

**AI 채택이 다르게 느껴지는 이유**

만약 “빠른 확산” 밈(meme)이 그렇게 잘못되었다면, 왜 그렇게 널리 퍼져 있고 지속적일까요? 왜냐하면 AI 채택은 PC나 인터넷, 소셜 미디어(social media)가 결코 그러지 않았던 방식으로 쓰나미처럼 느껴지기 때문입니다. 사람들이 어떤 것에 대해 직관적으로 확신할 때, 그들은 그러한 느낌을 확인시켜준다고 주장하는 데이터나 차트에 훨씬 덜 회의적일 것입니다. 물론 저희도 그 느낌을 압니다. AI에 대한 저희의 실제 경험은 과거 기술의 물결과는 다릅니다. 처음에는 저희는 이것을 인지 편향(cognitive bias)으로 치부했습니다. 저희가 현재 겪고 있는 어떤 변화든 과거에 성공적으로 적응했던 것보다 훨씬 더 큰 변화처럼 느껴질 것입니다. 하지만 이제 저희는 생각이 바뀌었습니다. 인지 편향(cognitive bias)이 부분적인 설명이 될 수는 있지만, AI 채택이 훨씬 더 빠르고 위협적으로 느껴지는 실제적인 이유가 있습니다. 요컨대, 배포(deployment)가 확산(diffusion)과 동일하지 않다는 것은 사실입니다. 과거에는 점진적인 배포를 통해 사용자들이 채택 결정의 부담에서 어느 정도 벗어날 수 있었지만, 이제는 그러한 완충 장치가 사라졌습니다. 인터넷 채택과의 비교를 통해 설명해 보겠습니다. 90년대에 다이얼업 인터넷(dial-up internet)을 채택했던 사람들은 다음과 같은 이야기를 기억할 것입니다. 처음 기술에 대해 들었을 때, 저희는 PC의 높은 가격 때문에 망설였습니다. 점차 가격이 내려갔습니다. 그동안 저희는 직장이나 친구 집에서 인터넷을 사용하는 경험을 얻었습니다. 그래서 몇 년 후 PC와 다이얼업 인터넷(dial-up internet)을 구입했을 때, 저희는 이미 어느 정도 훈련이 되어 있었습니다. 처음에는 다이얼업이 느리고 비쌌으며 웹사이트도 그렇게 많지 않았기 때문에 인터넷을 많이 사용하지 않았습니다. 점차 가격이 내려가고, 대역폭(bandwidth)이 개선되었고, 더 많은 콘텐츠가 온라인에 등장했으며, 저희는 사용량 증가와 함께 인터넷을 생산적이고 안전하게 사용하는 방법을 배웠습니다. 오늘날 AI 도구는 웹 브라우저나 스마트폰 앱만 있으면 바로 접근할 수 있어, 인터넷 초창기처럼 고가의 장비나 복잡한 설치 과정이 필요하지 않습니다. 2020년대에 범용 AI 도구(general-purpose AI tools)를 채택하는 것은 근본적으로 다른 경험입니다. 새로운 AI 역량이 즉각적으로 배포(deployment)되기 때문입니다. 사람들은 특정 사용 사례(use case)에 AI를 도입할지 여부를 끊임없이 평가해야 하며, 도입하지 않으면 뒤처질 것이라는 압박을 받습니다. 학습 곡선(learning curves)이 존재하고, 인간 행동 및 조직 변화가 오래 걸린다는 저희의 주장은 여전히 유효합니다. 그러나 AI를 사용하지 않는 것은 이제 능동적인 선택이 되었고, 접근성 부족을 핑계로 AI를 고려하지 않을 수 없습니다. 요컨대, 배포(deployment)는 확산(diffusion)의 여러 단계 중 하나일 뿐이며, 그 병목 현상을 제거하는 것이 확산을 약간 더 빠르게 만들었을 것입니다. 그러나 특정 AI 사용 사례(use case)에 대해 듣자마자, 궁극적으로는 합리적이거나 비합리적일 수 있는 다양한 이유로 대다수의 사람들이 채택하지 않기로 결정하는 경우라 할지라도, 채택할지 말지를 결정해야 하기 때문에 극적으로 더 빠르게 느껴집니다.

**AI 규제 환경의 변화와 정상 기술로서의 AI**

최근 몇 년간 AI 기술의 발전과 함께 전 세계적으로 AI 규제에 대한 논의가 급물살을 타고 있습니다. 유럽연합의 AI 법(EU AI Act) 통과, 미국 행정부의 AI 관련 행정명령 발표, 그리고 한국을 비롯한 여러 국가에서의 자율적인 AI 윤리 가이드라인 및 법제화 움직임은 AI가 더 이상 '예외적인' 기술이 아니라 '정상적인' 기술로서 사회 시스템에 통합되고 있음을 보여주는 명확한 증거입니다. 이러한 규제들은 단순한 기술 통제를 넘어, AI가 사회에 미칠 긍정적 영향은 극대화하고 부정적 영향은 최소화하기 위한 사회적 합의 및 제도적 장치 마련의 과정입니다. 저희는 이러한 규제 환경의 변화가 AI 확산의 비기술적 장벽 중 하나로 작용할 수 있지만, 동시에 AI의 책임감 있는 개발과 배포를 위한 필수적인 조건이라고 봅니다. 이는 저희 프레임워크가 강조하는 '배포 단계(deployment stage)'에서의 노력과 고통스러운 선택이 필요한 영역과 정확히 일치합니다. 규제 준수를 위한 기업의 노력, 새로운 법적 프레임워크에 대한 사회적 적응, 그리고 국제적인 규제 조화 노력 등은 AI가 진정으로 사회에 스며들기 위해 넘어야 할 중요한 산들입니다.

**결론**

저희가 AI 지지자들과 분명히 동의하는 한 가지는 AI가 사라지지 않을 것이며, 대부분의 사람들이 무시할 수 있는 암호화폐(crypto)와 같은 틈새시장이 되지 않을 것이라는 점입니다. 생성형 AI(generative AI)에 대한 집단적인 초기 충격이 가라앉았으므로, 각각의 새로운 기술적 역량이나 비예측적 사회적 효과(emergent social effect)에 (과도하게) 반응하는 대신, AI의 영향이 어떻게 전개될지 생각하는 구조화된 방법이 필요합니다. 저희 뉴스레터에서 꾸준히 강조하는 정상 기술로서의 AI(AI-as-normal-technology) 프레임워크(framework)는 이러한 구조화된 접근 방식의 한 예시입니다. 이 프레임워크는 기술의 사회적 영향에 대한 역사적 맥락을 바탕으로 한 기본적인 사고방식을 제시하며, 예외주의적 관점과 대비되는 점에서 충분히 탐구할 가치가 있습니다. 이 프레임워크(framework)는 기업 리더, 근로자, 학생, AI 안전 또는 AI 윤리(AI ethics)에 관심 있는 사람들, 그리고 정책 입안자 등에게 어느 정도 실행 가능한 지침을 제공합니다. 앞으로도 저희와 함께 이 논의에 참여해 주시기를 기대합니다. 초고에 대한 피드백을 제공해 준 스티브 뉴먼(Steve Newman)과 펠릭스 첸(Felix Chen)에게 감사드립니다.

**추가 읽을거리/볼거리**

아르빈드(Arvind)는 세계은행 개발 회의(World Bank Development Conference)에서 경제 및 노동 관련 함의에 초점을 맞춰 이 논문을 발표했습니다.
아르빈드(Arvind)의 새로운 유튜브 채널(YouTube channel)은 정상 기술 관점에서 AI 개발을 논의합니다.

저희는 정상 기술로서의 AI(AI as Normal Technology)에 대한 언론 보도를 받게 되어 행운이었습니다:
최근 뉴욕 타임스(New York Times)에서는 에릭 슈미트(Eric Schmidt)와 데이비드 월러스-웰스(David Wallace-Wells) 등 저명한 인사들이 저희 에세이를 심층적으로 다룬 여러 칼럼을 통해 AI 논의에 기여했습니다.
지난주 이코노미스트(The Economist)는 "인공지능이 그저 “정상적인” 기술이라면 어떨까?(What if artificial intelligence is just a “normal” technology?)"라는 기사에서 정상 기술 논지를 논의했습니다.
더 뉴요커(The New Yorker)에서 조슈아 로스먼(Joshua Rothman)은 AI 2027과 정상 기술로서의 AI(AI as Normal Technology)를 대조했습니다.
프로스펙트 매거진(Prospect Magazine)에서 이든 주커만(Ethan Zuckerman)은 정상 기술로서 AI를 바라보는 유용성을 논의했습니다.
MIT 테크놀로지 리뷰(MIT Technology Review)의 제임스 오도넬(James O'Donnell)은 정상 기술로서의 AI(AI as Normal Technology) 논지를 요약했습니다.

저희의 팟캐스트(podcast) 출연 중 일부는 다음과 같습니다:
뉴욕 타임스(New York Times)의 하드 포크(Hard Fork)와 팀 오라일리(Tim O’Reilly)의 팟캐스트(podcast)에 출연한 아르빈드(Arvind); 로페어(Lawfare)의 스케일링 법칙(Scaling Laws)과 카네기(Carnegie)의 인도 해석(Interpreting India)에 출연한 사야시(Sayash).
저희는 AI 2027의 많은 저자를 포함하여 초지능(superintelligence) 세계관을 가진 많은 사람들과 대화를 나누었습니다: 사야시(Sayash)는 다니엘 코코타일로(Daniel Kokotajlo)와 엘리 리프랜드(Eli Lifland)와 토론했습니다; 아르빈드(Arvind)는 다니엘 코코타일로(Daniel Kokotajlo)와 토론했으며, 애스터리스크 매그(Asterisk Mag)에서는 아르빈드(Arvind)와 아제야 코트라(Ajeya Cotra)가 AI 발전이 속도 제한을 가지고 있는지, 그리고 우리가 어떻게 알 수 있는지에 대해 토론했습니다.

1 종종 그렇듯이, 우연한 타이밍이 에세이의 성공에 큰 역할을 했습니다. 이 에세이는 AI 2027 이후 2주 후에 발표되었지만, 이는 순전히 우연이었습니다 — 저희의 출판일은 실제로는 나이트 연구소(Knight Institute)의 AI와 민주적 자유 심포지엄(symposium)에 기반한 것이었습니다. 에세이를 출판할 기회를 준 연구소에 감사드립니다.
2 일반적으로 챗봇(chatbot)과 관련된 정신 건강 문제, 그리고 중독과 같은 문제들은 저희 책 AI 스네이크 오일(AI Snake Oil)을 포함하여 널리 인식되고 논의되어 왔습니다. 이러한 문제들은 소셜 미디어(social media)와의 비유에 기반하는 경향이 있습니다. 그러나 정신 건강 영향의 잠재력을 예측하는 것과 어떤 영향이 구체적으로 나타날지, 그리고 그것을 어떻게 피할 수 있을지 예측하는 것은 별개의 문제입니다.
3 그렇긴 하지만, 저희는 저희의 전체 논지가 틀릴 수도 있다는 것을 인정하며, RSI가 달성된다면 저희가 틀릴 가능성이 더 높습니다.
4 이 프레임워크(framework)는 고전적인 혁신 확산 이론(diffusion-of-innovations theory)에서 채택되었으며, 혁신-확산 격차(innovation-diffusion gap)의 관점에서 AI 분야의 지정학적 경쟁을 분석한 제프리 딩(Jeffrey Ding)과 같은 최근 저자들의 영향도 받았습니다.
5 여기에도 위험이 있지만, 저희는 이것이 의사들이 탐색해야 할 응용 분야라고 확신합니다.
6 사실, 포켓몬 고(Pokemon Go)와 스레드(Threads)(인스타그램(Instagram)을 기반으로 성장했기 때문에 네트워크 효과(network effects)에 의존하지 않았음)와 같이 초기 성장이 ChatGPT만큼 빠르거나 더 빨랐던 다른 앱들도 있었습니다. 그러나 다시 말하지만, 저희의 더 큰 요점은 이러한 유형의 비교는 유익하지 않다는 것입니다. 스레드(Threads)는 초기 성장에도 불구하고 실패작에 가까웠습니다.
7 솔직히, 저희의 견해로는 이 그래프에서 훨씬 더 인상적인 통계는 인스타그램(Instagram)이 네트워크 효과(network effects)의 필요성에도 불구하고 단 2.5개월 만에 백만 명의 사용자에게 도달했다는 것입니다 — 이는 휴대폰 인터넷 속도가 훨씬 느렸고, 앱이 아이폰(iPhone) 전용이었으며 (!), 초기에는 주로 미국 내 18~34세 연령층에 확산되었던 2010년으로 거슬러 올라간다는 점을 고려할 때 더욱 그렇습니다.