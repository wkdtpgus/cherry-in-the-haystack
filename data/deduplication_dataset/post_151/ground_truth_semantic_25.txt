**정상 기술로서의 AI(AI as Normal Technology)**

인공지능을 평범한 기술의 관점으로 조명한 저희의 글이 세상에 나온 후, 독자들의 반응은 저희의 기대를 훨씬 상회했습니다. 이 글은 저희 둘 중 누구라도 해낸 일 중 가장 영향력 있는 기여가 되었습니다. 1 저희는 이를 인공지능의 중기적 궤적과 사회적 파급 효과에 대해 더 깊이 사고하고 집필할 강력한 동기로 받아들였으며, 흔히 추측으로 가득 찬 주제에 대해 현실에 기반한 분석을 제공했습니다. 이는 'AI 스네이크 오일(AI Snake Oil)' 프로젝트에서 다루었던 인공지능의 현행 및 단기적 영향에 대한 글쓰기에서 초점을 전환한 것입니다. 이러한 변화된 방향성을 반영하여 저희는 이 뉴스레터의 명칭을 변경했습니다. 저희는 이미 '정상 기술로서의 AI(AI as Normal Technology)' 개념에 대한 두 편의 후속 에세이를 발표했으며, 2026년 말에 완성하여 2027년에 출판할 계획인 책으로 저희의 근본적인 틀을 확장하면서 더욱 규칙적으로 글을 게시할 예정입니다. 이번 글에서는 인공지능이 사회에 통합되는 과정을 둘러싼 흔한 오해들을 해소하고, 저희의 초기 주장을 더욱 명확하게 전달하며, 특히 'AI 2027'과 같은 다른 미래 예측 모델과의 차이점을 심층적으로 비교 분석하고자 합니다. 독자들이 저희의 관점을 보다 쉽게 이해하고, 인공지능 기술의 진정한 의미와 그 파급 효과에 대한 건설적인 논의에 참여할 수 있도록 돕는 것이 목표입니다. 인공지능의 발전 속도와 그로 인한 사회경제적 변동은 많은 이들에게 불안감과 동시에 기대감을 안겨주고 있습니다. 이러한 복합적인 감정 속에서, 인공지능을 단지 경이로운 존재가 아닌, 여타 범용 기술들처럼 사회 시스템과 상호작용하며 발전해 나가는 '평범한' 기술로 인식하는 것이 중요하다고 저희는 강조합니다. 이 관점은 기술 자체의 역량보다는 기술이 인간 사회에 어떻게 적용되고 수용되는지에 대한 깊이 있는 통찰을 요구합니다.

**목차**
*   "일상적"이라는 표현이 흔하거나 예상 가능하다는 뜻은 아닙니다
*   저희 핵심 주장 다시 보기
*   GPT-5의 예상 밖 결과가 '정상 기술로서의 AI(AI as Normal Technology)' 관점으로 이끌었다면, 본질을 놓쳤을 수 있습니다
*   '정상 기술로서의 AI(AI as Normal Technology)'와 'AI 2027' 간의 절충안을 찾기 어려운 까닭
*   다른 관점에 사로잡혀 있을 때, 특정 시각을 온전히 파악하기란 어렵습니다
*   인공지능의 혜택을 실현하려면 상당한 노력과 어려운 결정이 수반될 것입니다
*   기술 확산 속도에 대한 비현실적인 논쟁
*   인공지능 도입이 특별하게 느껴지는 이유
*   결론 및 제언

**"일상적"이라는 표현이 흔하거나 예상 가능하다는 뜻은 아닙니다**

저희의 에세이에서 '일상적'이라는 단어의 의미를 (아래에서 더 심도 있게 다루겠지만) 무엇을 뜻하지 않는지에 대해 더 명확히 기술할 수도 있었습니다. 저희의 주장은 "별 볼 일 없으니 무시해도 좋다"는 뜻이 결코 아닙니다. 사실, 자동차부터 소셜 미디어 플랫폼에 이르기까지, 강력한 기술들은 늘 예상치 못한 사회적 파급 효과를 동반했습니다. 이는 기술 자체의 논리만으로는 미래를 예측하기 어렵게 만드는, 기술과 인간 사회의 복잡한 상호작용에서 비롯되는 비선형적인 결과(비예측적 효과) 때문입니다. 이러한 이유로 기술의 발전이 사회의 변화를 일방적으로 결정한다는 '기술 결정론'적 사고방식을 거부하는 것이 저희 논문의 핵심 전제 중 하나입니다. 특히 챗봇 형태의 인공지능 분야에서는 이미 이러한 비예측적 사회적 현상들을 목도하고 있습니다. 인공지능 동반자의 확산이나 'AI 정신증'으로 불리는 모델의 아첨(model sycophancy)과 같은 일부 해로운 영향은 대다수 관찰자들을 놀라게 했습니다. 반면, AI가 선거 조작에 사용될 것이라는 등 널리 예견되었던 많은 위험은 아직 현실화되지 않았습니다. 현재 역량의 확산만을 기반으로 하더라도, 3~5년 후 인공지능이 사회에 미칠 영향의 지형이 어떻게 변화할지는 그 누구도 단언할 수 없습니다. 인공지능의 기술적 역량 개발은 그 사회적 파급 효과보다 비교적 예측이 용이합니다. 'AI 2027'의 공동 저자인 다니엘 코코타일로(Daniel Kokotajlo)는 2021년 '2026년의 모습(What 2026 looks like)'이라는 글로 AI 안전 커뮤니티에서 명성을 얻었습니다. 그의 기술 자체에 대한 예측은 놀랍도록 정확했지만, 사회적 영향에 대한 전망은 전반적으로 빗나갔으며, 이는 그가 저희 중 한 명과의 팟캐스트 대담에서 솔직히 인정했던 부분입니다. 이 모든 것은 인공지능이 정부 기관과 정책 입안자들에게 더욱 심각한 난제로 다가오게 만듭니다. 왜냐하면 그들은 예측이라는 잘못된 안정감에 기대거나 모든 해악을 사전에 막으려 하기보다, 예측 불가능한 영향에 대해 기민하게 대처해야 할 것이기 때문입니다. 이러한 적응력을 가능하게 하는 정책 접근 방식은 넓은 의미에서 '회복탄력성(resilience)'이라 불리며, 저희 에세이가 강조했던 바입니다. 저희는 잠재적으로 치명적인 위험에 대한 접근 방식으로 회복탄력성을 역설했지만, 더 광범위하게 퍼져 있는 위험에 대처하는 데에도 회복탄력성이 핵심적인 역할을 한다는 점을 더 명확히 했어야 했습니다. 일부 독자들이 '정상적'이라는 단어 때문에 예측 가능성에 대한 저희의 견해를 오해했을 수도 있습니다. 저희의 목표는 인공지능에 개별적으로나 집단적으로 적응해야 하는 과제를 경시하려는 것이 아닙니다. 이상적인 상황에서는 단순히 '기술로서의 AI'가 더 적절한 제목이었겠지만, 저희는 그것이 현재 논의를 지배하는 '초지능' 세계관의 예외주의에 대한 대안을 제시하려는 저희의 의도를 효과적으로 전달하지 못할 것이라고 판단했습니다.

저희가 강조하는 '일상적'이라는 개념은 기술이 사회에 스며들어가는 방식과 그 과정에서 발생하는 복잡성을 이해하는 데 초점을 맞춥니다. 이는 기술이 단순히 도구로서 기능하는 것을 넘어, 문화, 경제, 정치 등 사회 전반에 걸쳐 예상치 못한 방식으로 변화를 일으키는 현상을 의미합니다. 예를 들어, 인터넷의 초창기에는 정보 접근성 향상이라는 긍정적 측면에만 주목했지만, 이후 소셜 미디어의 등장과 함께 정보의 왜곡, 프라이버시 침해, 사회적 양극화 심화와 같은 부작용이 나타났습니다. 이처럼 기술의 진정한 영향은 시간이 지나고 사회에 깊이 뿌리내릴 때 비로소 드러나기 마련입니다. 인공지능 역시 마찬가지입니다. 초기에는 주로 자동화와 효율성 증대에 대한 기대가 컸지만, 최근에는 딥페이크(deepfake)와 같은 기술 오용 문제, 인공지능 기반의 편향된 의사결정 시스템, 그리고 노동 시장의 구조적 변화 등 예상치 못한 도전 과제들이 부상하고 있습니다. 이러한 상황에서 정책 입안자들은 기술의 잠재력을 최대한 활용하면서도, 발생 가능한 부작용을 최소화할 수 있는 유연하고 적응력 있는 규제 프레임워크를 구축하는 데 집중해야 합니다. 단순히 기술 발전을 억제하거나, 반대로 무조건적인 수용을 주장하기보다는, 기술이 사회와 상호작용하는 역동적인 과정을 이해하고 이에 맞춰 대응하는 것이 중요합니다. 이는 기술 자체의 우월성이나 결함에만 초점을 맞추는 것이 아니라, 기술을 사용하는 인간과 사회 시스템의 특성을 함께 고려해야 함을 의미합니다. 저희의 관점은 인공지능을 일시적인 유행이나 전례 없는 위협으로 보는 대신, 인류 역사에 반복적으로 등장했던 범용 기술(general-purpose technologies)의 맥락에서 이해하려는 시도입니다.

**저희 핵심 주장 다시 보기**

저희의 주장을 핵심만 요약하자면 다음과 같습니다. 인공지능의 성능 향상과 사회적 파급 효과 사이에는 복잡하고 긴 인과적 연결고리가 존재합니다. 기술의 이점과 위험은 개발 단계에서 발현되는 것이 아니라, 실제 사회에 배포되고 적용될 때 비로소 현실화됩니다. 이는 개인, 조직, 정부 기관, 정책 입안자 등 저희 모두에게 이러한 영향을 조절하고 형성할 수 있는 중요한 개입 지점들을 제공합니다. 따라서 저희는 인공지능 역량 개발의 속도 자체에 과도하게 몰두할 필요가 없다고 봅니다. 오히려 저희의 노력은 인공지능의 긍정적인 측면을 실현하고 잠재적 위험에 대응하는 측면에서 '배포' 단계에 더 집중되어야 합니다. 이러한 관점은 현재의 인공지능뿐만 아니라, 인공지능 역량의 자기 개선(self-improvement)과 같은 가설적인 미래 발전에도 동일하게 적용됩니다. 인공지능 시스템의 힘에 대한 많은 제약은 시스템 외부, 즉 사회적, 제도적 환경에 존재하며 (또한 그래야만 합니다), 따라서 인공지능이 스스로 기술 설계를 개선하는 것만으로는 이러한 외부적 한계를 극복할 수 없습니다. 이 프레임워크의 특정 측면들은 시간이 지나면서 수정될 수 있겠지만, 이는 저희가 현재로서 의미 있게 예측하거나 준비할 수 있는 범위를 넘어섭니다. 저희가 2부에서 제시하는 미래는 오늘날보다 인공지능이 훨씬 더 진보한 세상입니다. 저희는 인공지능의 발전—혹은 인류의 발전—이 특정 시점에서 멈출 것이라고 주장하는 것이 아닙니다. 그 이후에 무엇이 올지는 저희도 알 수 없습니다. 1차 산업혁명 초기에 산업 세계가 어떻게 변할지 예상하고 대비하는 것은 유용했지만, 전기나 컴퓨터의 등장을 미리 예측하려 했다면 헛된 시도였을 것입니다. 저희의 작업 역시 이와 유사합니다. 저희는 '급속한 발전(fast takeoff)' 시나리오를 받아들이지 않으므로, 저희가 다룬 것보다 훨씬 먼 미래의 세상을 상상하는 것이 필요하거나 유용하다고 보지 않습니다. 2부에서 제시하는 시나리오가 현실화된다면, 저희는 그 다음에 올 어떤 것이든 더 잘 예측하고 대비할 수 있을 것입니다. 요컨대, 저희 논지의 핵심은 인공지능과 사회의 관계를 이해하는 근본적인 '인과적 틀(causal framework)'이며, 인공지능이 가질 수도 있고 가지지 않을 수도 있는 특정 영향 자체가 아닙니다. 저희는 이러한 인과적 이해를 공유한다면, 여러분은 '정상 기술로서의 AI(AI as Normal Technology)' 논지에 동의하는 것이라고 봅니다. 저희는 이 프레임워크가 암묵적으로나마 실제로는 널리 받아들여지고 있음을 확인했습니다. 이는 많은 독자들에게 이 논지를 거의 자명한 것으로 만듭니다. 저희는 저희가—그리고 독자들이—보기에는 매우 약한 주장을 하고 있는 셈입니다! 이러한 점을 인지하지 못하면 독자들은 '정상적'이라는 단어에서 저희가 의도했을 훨씬 더 구체적인 의미를 찾으려 할 것입니다. 하지만 저희는 그렇지 않았습니다. 저희는 기술을 '정상'과 '비정상'으로 분류한 뒤 인공지능을 '정상' 범주에 넣는 것이 아닙니다. 저희는 단지 인공지능을 다른 강력한 범용 기술(general-purpose technologies)처럼 다루어야 한다고 주장하는 것입니다. 이는 대규모 언어 모델(large language models)이나 특정 종류의 인공지능에만 해당되는 것이 아닙니다. 덧붙여 말하자면, 이것이 제목이 '정상 기술로서의 AI(AI as Normal Technology)'이지 '하나의 정상 기술로서의 AI(AI as a normal technology)'가 아닌 이유입니다. 저희의 견해는 '인공지능'이라고 통칭되는 모든 기술과, 인공지능으로 불리지 않더라도 유사한 다른 기술에 적용됩니다. 저희의 세계관이 거의 자명한 것이라면, 굳이 그것을 언급할 필요가 있을까요? 이는 '초지능' 세계관과 극명하게 대비되기 때문입니다. 세계관의 특성이란 이런 것입니다. 서로 모순되는 세계관이 존재할 수 있으며, 각 세계관은 그것을 신봉하는 사람들에게는 동어반복적으로 느껴질 수 있습니다.

저희가 제시하는 프레임워크는 기술 혁신이 사회에 미치는 영향을 이해하는 데 있어 보다 현실적인 접근 방식을 제안합니다. 이는 기술 자체의 내재된 잠재력만큼이나, 사회적 수용도, 제도적 장벽, 그리고 문화적 맥락이 기술의 실제 파급력을 결정하는 데 중요한 역할을 한다는 인식에서 출발합니다. 예를 들어, 인터넷 기술은 그 자체로 방대한 정보에 대한 접근을 가능하게 했지만, 전자상거래나 소셜 네트워크 서비스와 같은 구체적인 '배포' 형태를 통해서야 비로소 사회경제적 변화를 일으켰습니다. 이 과정에서 규제, 사용자 교육, 인프라 구축 등 수많은 외부적 요인들이 작용했습니다. 인공지능도 마찬가지입니다. 아무리 강력한 인공지능 모델이 개발되더라도, 그것이 실제 산업 현장이나 일상생활에 통합되기 위해서는 기존의 업무 방식, 법적 규제, 그리고 인간의 습관과 문화적 관습이라는 거대한 장벽을 넘어서야 합니다. 이러한 외부적 제약들은 인공지능이 단순히 '스스로 진화'하는 것만으로는 해결될 수 없는 문제입니다. 따라서 인공지능의 미래를 논할 때, 기술적 진보의 속도에만 매몰되기보다는, 기술이 사회에 '착륙'하는 과정과 그에 따른 사회적 적응 과정에 더 많은 주의를 기울여야 합니다. 이는 또한 기술 개발자들에게도 중요한 시사점을 제공합니다. 단순히 더 강력한 모델을 만드는 것을 넘어, 그 모델이 현실 세계에서 어떻게 활용될 수 있는지, 어떤 사회적 가치를 창출할 수 있는지, 그리고 어떤 윤리적, 사회적 문제를 야기할 수 있는지를 깊이 고민하며 개발해야 한다는 뜻입니다. 저희는 이러한 통합적 사고가 인공지능 기술이 인류에게 진정으로 유익한 방향으로 발전하는 데 필수적이라고 믿습니다.

**GPT-5의 예상 밖 결과가 '정상 기술로서의 AI(AI as Normal Technology)' 관점으로 이끌었다면, 본질을 놓쳤을 수 있습니다**

GPT-5의 공개 이후 저희 에세이에 대한 관심이 급증했는데, 이는 적어도 일부 독자들이 해당 출시에 대한 기대에 미치지 못하면서 기존 관점을 재조정했기 때문일 것으로 추정됩니다. 이러한 현상은 다소 의아하게 느껴집니다. 이는 이전에도 유사하게 발생했던 일로, 저희는 거의 새로운 정보 없이 대규모 기술 확장(scaling)에 대한 서술 방식이 크게 변하는 것에 대해 회의적인 시각을 표명한 바 있습니다. 만약 단 하나의 제품 업데이트가 인공지능의 발전 경로에 대한 사람들의 인식을 바꿀 수 있다면, 애초에 그들의 판단 근거(evidence base)가 얼마나 견고했는지 의문이 들 수밖에 없습니다. '정상 기술로서의 AI(AI as Normal Technology)' 프레임워크가 인공지능의 사회적 영향이 느린 속도로 전개될 것이라고 예측하는 이유는, 인공지능의 역량이 한계에 부딪힐 것이기 때문이 아닙니다. 오히려 역량은 계속해서 빠르게 발전하겠지만, 그 파급 효과는 점진적이고 시간이 걸릴 것이라는 관점입니다. 따라서 새로운 기술 출시에 대한 실망이 여러분을 인공지능을 '정상 기술로서의 AI(AI as Normal Technology)'로 보는 견해에 더 동조하게 만들어서는 안 된다고 생각합니다. 마찬가지로, 내일 발표될 혁신적인 돌파구 역시 저희의 관점에 대해 더 회의적으로 만들어서는 안 됩니다. GPT-5를 이해하는 가장 적절한 방법은, 인공지능 개발자들이 '모델' 자체에서 '제품'으로 강조점을 옮기는 훌륭한 사례로 보는 것입니다. 저희는 이미 1년 전부터 이 주제에 대해 논의했습니다. 자동 모델 전환 기능(automatic model switcher)은 ChatGPT의 일반 사용자들에게 상당한 이점을 제공합니다. 출시 후 거의 1년 동안 '사고(thinking)' 모드를 사용하는 사용자가 극히 드물었지만, GPT-5의 도입은 그 사용량을 획기적으로 증가시켰습니다. 일부 소통에서 알트만(Altman)은 GPT-5의 중점이 역량의 비약적인 발전이 아니라 '유용성'에 있었음을 명확히 했으나, 이러한 메시지는 끊임없는 과대광고(hype)에 의해 희석되어 실망으로 이어지는 경향이 있었습니다. 업계에서 나타나는 이러한 광범위한 변화는 기업들이 인공 일반 지능(AGI)이나 초지능(superintelligence)을 구축하여 모든 확산 장벽을 일거에 무너뜨릴 것이라는 기대를 접고, 대신 제품을 만들고 기술 채택을 촉진하는 지난한 작업에 집중하고 있음을 (마지못해) 인정하는 것과 매우 일치합니다. 역설적으로, 이러한 맥락에서 GPT-5는 실패가 아니라 성공의 좋은 예시입니다. 실제로 모델 개발자들은 더 유용한 제품을 개발하는 것(저희 기술 개발 및 채택 프레임워크의 두 번째 단계)을 넘어, 배포자(deployer)와 협력하여 초기 채택의 난관을 완화하는 것(세 번째 단계)으로 나아가기 시작했습니다. 예를 들어, OpenAI의 '선행 배포 엔지니어(Forward Deployed Engineers)' 팀은 존 디어(John Deere)와 같은 기업 고객 및 농부들과 직접 협력하여 살충제 적용을 위한 맞춤형 권장 사항 제공과 같은 역량을 통합하고 실제로 적용하는 데 기여하고 있습니다.

GPT-5 사례는 기술 혁신이 단순히 최고 성능의 모델을 개발하는 것을 넘어, 그것이 실제 사용자에게 어떤 가치를 제공하고 어떻게 통합될 수 있는지를 고민하는 방향으로 진화하고 있음을 보여줍니다. 이는 기술 공급자 중심의 사고방식에서 사용자 중심의 사고방식으로의 전환을 의미하며, 인공지능이 사회에 더 깊이 뿌리내리기 위한 필수적인 과정입니다. 예를 들어, 과거 소프트웨어 개발에서 '기능 우선'주의가 지배적이었다면, 이제는 '사용자 경험(UX)'과 '사용성(usability)'이 핵심 성공 요인으로 부상한 것과 유사합니다. 인공지능 분야에서도 마찬가지로, 아무리 강력한 인공지능 모델이라 할지라도 실제 문제 해결에 활용되지 못하면 그 잠재력을 온전히 발휘할 수 없습니다. 따라서 기술 개발 단계에서부터 최종 사용자의 니즈와 사용 환경을 고려한 '제품화' 전략이 중요해지고 있습니다. 이는 단순히 기술을 포장하는 것을 넘어, 기술과 인간의 상호작용 방식, 기존 시스템과의 통합, 그리고 윤리적 고려사항 등을 포괄하는 넓은 개념입니다. 이러한 변화는 인공지능 기술이 점차 '일상적'인 도구로 자리매김하고 있음을 보여주는 강력한 신호입니다. 이는 또한 인공지능의 미래를 예측하는 데 있어서 기술 자체의 발전 속도뿐만 아니라, 그것이 사회에 흡수되고 재구성되는 '배포'와 '확산'의 과정을 면밀히 분석하는 것이 얼마나 중요한지를 시사합니다. 기술이 아무리 뛰어나더라도 인간의 행동 변화나 제도적 혁신 없이는 그 영향력이 제한적일 수밖에 없다는 것이 저희 주장의 핵심입니다.

**'정상 기술로서의 AI(AI as Normal Technology)'와 'AI 2027' 간의 절충안을 찾기 어려운 까닭**

많은 이들이 'AI 2027'과 '정상 기술로서의 AI(AI as Normal Technology)' 사이에서 중립적인 입장을 취하려 노력하고 있으며, 아마도 이 두 관점을 스펙트럼의 양 극단으로 간주했을 것입니다. 하지만 이러한 시도는 놀랍도록 어렵다는 것이 현실입니다. 'AI 2027'과 '정상 기술로서의 AI(AI as Normal Technology)'는 각각 내적으로 일관된 세계관을 형성하고 있습니다. 이들은 기술이 사회에 미치는 영향에 대해 매우 상이한 '인과적 이해'를 바탕으로 합니다. 만약 이 두 관점을 섞어 맞추려 한다면, 내적으로 모순되는 불균형한 혼합물이 될 위험이 있습니다. (덧붙여, 이는 저희의 주장이 결국 틀리게 된다면, 부분적으로 틀리기보다는 완전히 틀릴 가능성이 더 높다는 의미이기도 합니다.) 더욱이, '정상 기술로서의 AI(AI as Normal Technology)'라는 관점은 오직 실리콘 밸리(Silicon Valley)의 특정 환경에서만 회의적인 시각으로 받아들여질 수 있습니다! 저희는 에세이의 두 번째 문단에서 인공지능을 '전기'에 비유하며, 이 기술이 사회에 지대한 영향을 미칠 것이라고 줄곧 강조해 왔습니다. 인공지능이 노동 시장에 미칠 영향에 대한 저희의 예측은 이 분야를 연구하는 경제학자들의 전망 중에서도 상당히 과감한 축에 속합니다. 요약하자면, 만약 여러분이 보다 온건한 입장을 찾고 있다면, 저희 에세이를 전체적으로 읽어보시길 권합니다. 제목만으로 저희를 인공지능 회의론자라고 단정하지 마십시오. 아마도 여러분은 '정상 기술로서의 AI(AI as Normal Technology)'가 이미 여러분이 찾고 있던 '중간 지점'이라고 결론 내릴 수도 있을 것입니다. 인공지능의 미래를 논하는 가장 널리 퍼진 두 가지 프레임워크가 이토록 근본적으로 다르다는 사실이 불편하게 느껴질 수 있음을 저희도 이해합니다. (저희 에세이 4부에서는 이러한 상황이 정책에 미치는 영향에 대해 많은 부분을 할애하여 논하고 있습니다.) 그러나 저희는 몇 가지 희망적인 생각을 제시할 수 있습니다. 저희는 'AI 2027'의 저자들과 많은 부분에서 의견을 같이하고 있습니다. 현재 그러한 공통 분야를 명확히 하는 공동 성명을 작성 중에 있으며, 이 노력을 조직해 준 니콜라스 칼리니(Nicholas Carlini)에게 감사를 표합니다. 저희의 견해로는, 신념의 일치보다 더 중요한 것은 신념의 차이에도 불구하고 정책적 영역에서의 공통점입니다. 서로 다른 입장의 주체들이 동의할 수 있는 비교적 '쉬운' 정책적 개입조차도 실제로는 엄청난 난관에 부딪힐 것입니다. 만약 저희가 이러한 목표조차 달성할 수 없다면, 임박한 초지능(superintelligence)을 우려하는 사람들이 선호하는 훨씬 더 급진적인 조치들에 대한 희망은 거의 없을 것입니다. 의견 불일치의 핵심 쟁점(cruxes)을 식별하고, 두 세계관 사이를 판단하는 데 유용한 지표에 합의하기 위한 지속적인 노력들이 있었습니다. 저희는 이러한 노력들 중 일부에 참여해 왔으며, 앞으로도 계속 참여하기를 기대합니다. 이 분야에서 골든 게이트 AI 연구소(Golden Gate Institute for AI)의 노력에 감사드립니다. 지표 개발에 관해 말씀드리자면, 저희는 프로젝트 HAL(Holistic Agent Leaderboard), 즉 '총체적 에이전트 리더보드'에 대한 비전을 확장하는 중입니다. 현재는 인공지능 에이전트(AI agent)를 위한 더 나은 벤치마크 오케스트레이션 시스템(benchmark orchestration system)이 되고자 하지만, 새로운 계획은 인공지능 커뮤니티가 인공지능 에이전트가 다양한 영역에서 '변혁적인 실제 세계 영향(transformative real-world impacts)'을 위한 '역량 임계값(capability thresholds)'을 언제 넘어섰는지 식별하는 데 도움이 되는 '조기 경보 시스템(early warning system)'으로 발전시키는 것입니다. 저희는 이러한 역량 임계값을 영향에 대한 필수적이지만 항상 충분한 조건은 아니라고 보며, 이러한 임계값에 도달하면 이점과 위험 모두에 대한 비기술적 장벽에 대한 저희의 논지를 훨씬 더 예리하게 부각시킬 것입니다. HAL은 '예측'에 관한 것이 아니라, 현재의 '상황 인식(situational awareness)'에 관한 것임을 주목하십시오. 이것이 저희 작업의 중심 주제입니다. 일반적으로 인공지능 담론에서, 특히 저희와 'AI 2027' 사이에서 놀라운 점은 미래뿐만 아니라 확산 속도(아래에서 더 상세히 설명)와 같이 저희가 관찰할 수 있는 현상들에 대한 견해의 폭이 넓다는 것입니다. 저희가 커뮤니티로서 현재에 대한 측정과 진보에 대한 경쟁적인 인과적 설명(causal explanations)을 검증하는 데 훨씬 더 능숙해지지 않는 한, 예측에 투입되는 에너지 수준은 잘못된 방향으로 흐를 것입니다. 그러한 예측을 해결할 방법이 부족하기 때문입니다. 예를 들어, 저희는 'AGI(인공 일반 지능)'가 사후적으로(post facto) 구축되었는지조차 반드시 알 수 없을 것이라고 주장했습니다. 어느 정도 이러한 한계는 AGI와 같은 개념의 '개념적 정밀성(conceptual precision)' 부족으로 인해 본질적이지만, 동시에 저희가 측정 방법론을 훨씬 더 개선할 수 있다는 것도 사실입니다.

두 세계관 사이의 근본적인 차이는 인공지능의 본질을 어떻게 정의하고, 그 발전이 사회에 어떤 방식으로 영향을 미칠지에 대한 가정에서 비롯됩니다. 'AI 2027'이 기술 자체의 기하급수적인 발전과 그로 인한 급격한 사회 변혁에 초점을 맞춘다면, '정상 기술로서의 AI(AI as Normal Technology)'는 기술의 사회적 통합 과정이 지닌 내재적 관성(inertia)과 복잡성에 주목합니다. 이 간극은 단순히 미래 시점에 대한 의견 차이가 아니라, 기술과 사회의 상호작용 메커니즘에 대한 근본적인 이해의 차이를 반영합니다. 예를 들어, 자율주행 기술의 경우, 기술적 완성도는 빠르게 향상되고 있지만, 법적 책임 문제, 보험 시스템의 변화, 사회적 수용도, 기존 교통 인프라와의 통합 등 비기술적 요인들이 상용화의 주요 걸림돌이 되고 있습니다. 이는 아무리 기술이 뛰어나더라도 사회적, 제도적 준비 없이는 그 잠재력을 온전히 실현하기 어렵다는 저희 주장을 뒷받침합니다. 따라서 효과적인 정책 수립을 위해서는 기술적 예측뿐만 아니라, 사회경제적, 문화적, 법적 맥락을 종합적으로 고려하는 통찰력이 요구됩니다. 저희는 이러한 관점의 차이가 건설적인 논의를 통해 해소될 수 있다고 믿으며, 이를 위해 '골든 게이트 AI 연구소'와 같은 기관들이 진행하는 지표 개발 노력이 중요하다고 생각합니다. 단순히 기술의 성능을 측정하는 벤치마크를 넘어, 실제 세계에서 기술이 어떤 영향력을 발휘하는지, 그리고 그 영향력이 사회에 미치는 긍정적/부정적 효과를 종합적으로 평가할 수 있는 지표들이 필요합니다. 이는 인공지능 기술이 가져올 미래에 대한 막연한 불안감이나 과도한 낙관론을 넘어, 현실에 기반한 합리적인 대응 방안을 모색하는 데 필수적입니다.

**다른 관점에 사로잡혀 있을 때, 특정 시각을 온전히 파악하기란 어렵습니다**

저희는 다음과 같은 주장을 펼쳤습니다. '정상 기술로서의 AI(AI as Normal Technology)'는 임박한 초지능(superintelligence)으로서의 인공지능 세계관과 대척점에 서 있는 시각입니다. 세계관이란 근본적인 가정, 사용되는 어휘, 증거 해석 방식, 인식론적 도구(epistemic tools), 미래 예측, 그리고 (잠재적으로) 가치 체계로 구성됩니다. 이러한 요소들은 서로를 강화하며 각 세계관 내에서 긴밀한 결속력을 형성하기 때문에, 서로 다른 세계관 간의 소통은 매우 어렵습니다. 예를 들어, 'AI 2027' 관계자들로부터 저희가 자주 받는 질문 중 하나는 "2027년의 세상은 어떻게 변모할 것이라고 보느냐"는 것입니다. 저희는 "2025년과 크게 다르지 않을 것"이라고 답변합니다. 그러면 그들은 세상이 혁신적으로 바뀔 2035년이나 2045년, 혹은 그 이후의 특정 연도를 염두에 두도록 저희를 압박하며, 저희가 구체적인 시나리오(scenario)를 제시하지 않는 것을 저희 프레임워크의 결함으로 간주합니다. 그러나 이러한 종류의 시나리오 예측(scenario forecasting)은 그들의 세계관 내에서만 유의미한 활동입니다. 저희는 저희가 구체적으로 다룰 수 있다고 판단하는 영역에 대해서만 명확한 입장을 표명합니다. 동시에, 저희는 'AI 2027'을 포함하여 근본적으로 다른 미래를 창조할 수 있는 인간, 제도, 그리고 정치적 주체(agency)의 역할을 강조합니다. 따라서 '정상 기술로서의 AI(AI as Normal Technology)'는 미래에 대한 '예측'인 동시에 '처방'의 성격도 지닙니다. 이러한 소통의 난점은 'AI 2027'의 공동 저자인 스콧 알렉산더(Scott Alexander)가 '정상 기술로서의 AI(AI as Normal Technology)'에 대해 제시한 반론을 고려할 때 특히 중요하게 인식되어야 합니다. 저희는 그의 대화 시도가 선의에서 비롯되었다는 점을 의심하지 않으며, 그의 시간을 할애해 준 것에 감사하지만, 유감스럽게도 그의 반응은 저희의 주장을 제대로 파악하지 못하고 엇갈린 대화를 하고 있다는 느낌을 지울 수 없습니다. 그가 '의견 불일치의 핵심(cruxes)'으로 지목하는 것들은 저희가 핵심으로 간주하는 쟁점들과 상당히 다릅니다! 이러한 이유로, 저희는 항목별로 그의 반론에 답변하지 않을 것입니다. 그렇게 한다면 저희 역시 결국 그와 엇갈린 대화를 반복하게 될 것이기 때문입니다. 하지만 저희는 조정된 대화에는 기꺼이 참여할 것이며, 이는 지난 1년 동안 8~10회 성공적으로 이루어졌던 방식입니다. 동시적인 대화의 특성은 서로를 훨씬 더 쉽게 이해할 수 있도록 돕습니다. 그리고 비공개 대화가 공개되기 전에 편집될 수 있다는 사실은 각 참여자가 상대방의 관점을 이해하기 위해 다소 어리석은 질문을 하는 데 대한 부담을 덜어줍니다. 어쨌든, 알렉산더의 반응이 저희의 주장을 제대로 이해하지 못하고 엇갈린 대화를 하고 있다고 느끼게 하는 몇 가지 중요한 방식은 다음과 같습니다. '재귀적 자기 개선(Recursive Self-Improvement, RSI)'은 알렉산더의 관점에서 의견 불일치의 핵심 쟁점이며, 그는 저희가 이를 거의 언급할 가치도 없다고 보는 점에 놀라움을 표합니다. 솔직히 저희는 에세이에서 RSI에 대한 저희의 생각을 훨씬 더 명확하게 설명할 수도 있었습니다. 요약하자면, 저희는 RSI가 초지능(superintelligence)으로 이어질 것이라고 생각하지 않습니다. 그 이유는 강력한 인공지능 시스템을 구축하고 배포하는 데 따르는 외부적 병목 현상들이 기술 설계의 자체적인 개선만으로는 극복될 수 없기 때문입니다. 이것이 저희가 RSI를 많이 논의하지 않는 까닭입니다. 3 저희에게 RSI가 핵심 쟁점은 아니지만, 저희는 인공지능 커뮤니티가 RSI에 전혀 근접하지 못했다고 판단하는 이유를 에세이에서 설명합니다. 최근에는 해결해야 할 근본적인 연구 과제들이 저희가 이전에 인식했던 것보다 훨씬 더 많다는 것을 깨달았습니다. 그리고 인공지능 커뮤니티가 다른 과학 분야에 비해 진보를 위한 새로운 패러다임(paradigm)을 찾는 데 특히 미숙할 수 있다는 점을 염두에 둘 가치가 있습니다. 다시 한번 강조하지만, 이것은 저희 프로젝트 HAL이 진보를 측정하는 데 중요한 역할을 할 수 있기를 기대하는 분야입니다. 알렉산더의 반응이 저희의 주장을 제대로 이해하지 못하고 엇갈린 대화를 하고 있다고 느끼게 하는 또 다른 주제는 '확산 속도'에 관한 것입니다. 이에 대해서는 아래에서 간략히 언급하고 향후 에세이에서 더 자세히 다룰 것입니다. 세계관 간의 담론의 어려움을 가장 극명하게 보여주는 것은 '예측'이나 '설득'과 같은 작업에서 인간을 초월하는 인공지능 능력이 가능한지 여부에 대한 저희 가설에 대한 알렉산더의 논의입니다. 그의 반응을 여러 차례 읽었음에도 불구하고, 저희는 정확히 어디에서 동의하고 어디에서 동의하지 않는지 파악하기 어렵습니다. 저희는 다음과 같이 기술했습니다. "저희는 인간의 한계가 너무나 명백하여, 인공지능이 인간의 성능을 훨씬 뛰어넘을 수 있는 (체스에서 그러하듯이) 실제 세계의 인지적 작업은 상대적으로 거의 없다고 생각합니다. ... 구체적으로, 저희는 두 가지 영역을 제안합니다: 예측과 설득. 저희는 인공지능이 지정학적 사건(예: 선거)을 예측하는 데 훈련된 인간(특히 인간 팀, 그리고 간단한 자동화 도구로 보강된 경우)을 의미 있게 능가할 수 없을 것이라고 예측합니다. 저희는 사람들이 자신의 이익에 반하여 행동하도록 설득하는 작업에 대해서도 동일한 예측을 합니다." 그의 에세이 섹션 3B에서 이에 대한 그의 전체 반응을 읽을 수 있지만, 요약하자면 그는 인간의 생물학적 한계에 초점을 맞춥니다. 인간은 아프리카 사바나(savanna)에서 수천 년의 진화를 통해 능력을 얻었습니다. 사바나에서는 "예측 대회에서 가능한 가장 높은 브라이어 점수(Brier score)를 정확히 얻는 것"에 대한 특별한 압력이 없었고, 인간이 이를 달성했다고 생각할 특별한 이유도 없습니다. 실제로 농업에 대한 반응으로 지난 1만 년 동안 인간 지능의 진화에 대한 증거가 사실로 판명된다면, 인간은 아프리카 사바나에서 우주적 최대치에 도달하지 못했습니다. 왜 우리는 이 마지막, 매우 짧은 선택의 라운드가 정확히 옳았다고 생각해야 할까요? 그러나 인간 능력에 대한 생물학적 제약 개념을 거부하는 것은 저희에게 핵심적인 출발점이며, 저희는 "인간의 능력은 생물학에 의해 제약받지 않는다(Human Ability Is Not Constrained by Biology)" 섹션에서 이를 자세히 설명하기 위해 노력합니다. 이것이 바로 세계관 간 논의의 문제입니다. 만약 여러분이 특정 진술을 취하고, 그 진술에 이르는 전제와 용어적 명확화(terminological clarifications)를 무시한 채, 그것을 여러분의 세계관으로 해석한다면, 상대방이 무지하다고 생각할 것입니다. 알렉산더는 저희가 마치 사바나 거주자가 현재로 시간 여행을 한다면 선거를 예측할 수 있을 것이라고 제안한다고 생각할까요? 그는 인간의 성능이 고정되어 있지 않다는 점을 강조하지만, 어쩐지 이를 저희 논지에 대한 반박(오히려 핵심적인 부분이라기보다는)으로 봅니다. 아마도 혼란은 예측에서 인간의 성능이 "환원 불가능한 오류(irreducible error)"에 가깝다는 저희의 가설 때문에 발생했을 것입니다. 저희는 예측의 환원 불가능한 오류가 영원히 고정된 특정 숫자라고 암시하는 것이 아닙니다. 물론 그것은 사용 가능한 데이터에 따라 달라집니다. 더 나은 여론조사는 더 나은 예측으로 이어집니다. 그리고 증가된 데이터를 활용하는 데 도움이 되는 훈련에 따라 달라집니다. 그리고 그 훈련 중 일부는 인공지능 기반 예측 연구의 결과일 수도 있습니다. 저희는 원래 에세이에서 인간 지능이 저희의 생물학 때문이 아니라, 인공지능을 포함한 저희 도구에 대한 (우발적인) 숙달 때문에 특별하다고 강조합니다. 따라서 인공지능의 발전은 종종 인간 지능(능력)을 향상시킬 것이며, 저희가 제안하는 인간-AI 비교의 양측 성능을 향상시킬 잠재력을 가지고 있습니다. 저희 가설의 요점은 간단합니다. 저희는 예측이 체스와 같다고 생각하지 않습니다. 체스에서는 많은 계산이 인공지능에게 결정적인 속도 우위를 제공할 수 있습니다. 예측의 계산 구조(computational structure)는 성능이 훈련과 데이터를 통해 크게 향상될 수 있음에도 불구하고 비교적 간단합니다. 따라서 적절하게 훈련된 전문가 예측가 팀의 손에 있는 비교적 간단한 계산 도구는 짜낼 수 있는 (거의) 모든 것을 짜낼 수 있습니다. 저희는 알렉산더의 반응이 "상호 협력 가능성에 대해 말뿐이 아니라 실제로 행동한다"는 점을 저희에게 인정해 준 것에 기쁩니다. 그 감정은 상호적입니다. 저희는 서브스택(Substack) 반박과 재반박보다 더 생산적이라고 생각하는 그 협력을 계속하기를 기대합니다.

이러한 세계관 간의 소통 단절은 인공지능의 미래에 대한 공통된 이해를 형성하는 데 중대한 장애물로 작용합니다. 각 세계관은 고유한 렌즈를 통해 현실을 해석하며, 이 렌즈가 너무나 강력하여 다른 렌즈로 본 풍경을 이해하기 어렵게 만듭니다. 예를 들어, 인공지능이 인간의 창의성을 대체할 것이라는 주장과 인공지능이 인간의 창의성을 증폭시킬 것이라는 주장은 단순히 미래에 대한 다른 예측이 아니라, 창의성의 본질과 기술의 역할에 대한 근본적인 철학적 가정에서부터 갈립니다. 전자는 창의성을 인간 고유의, 대체 불가능한 특성으로 보지 않거나 기술이 이를 완전히 모방할 수 있다고 믿는 반면, 후자는 창의성을 도구와 상호작용하며 발전하는 능력으로 봅니다. 이러한 깊은 차이는 단순히 데이터를 제시한다고 해서 쉽게 좁혀지지 않습니다. 오히려, 서로의 가정을 명확히 하고, 어떤 조건에서 각자의 예측이 유효하거나 무효화될 수 있는지에 대한 '공동의 지표'를 찾아 합의하는 노력이 필요합니다. 저희는 이러한 지표 개발이 미래 예측의 정확성을 높이는 데 기여할 뿐만 아니라, 인공지능 기술이 사회에 미치는 영향을 더욱 정교하게 관리할 수 있는 기반을 마련할 것이라고 믿습니다. 특히 '재귀적 자기 개선(RSI)'과 같은 개념에 대해서는, 기술적 가능성 자체보다는 그것이 실제 세계에서 사회적, 경제적, 제도적 제약을 어떻게 돌파할 수 있는지에 대한 심도 있는 분석이 선행되어야 합니다. 기술은 진공 상태에서 발전하지 않으며, 항상 복잡한 인간 사회 시스템 속에서 기능합니다. 따라서 기술의 '내부 논리'뿐만 아니라 '외부 논리' 또한 중요하게 고려되어야 합니다.

**인공지능의 혜택을 실현하려면 상당한 노력과 어려운 결정이 수반될 것입니다**

저희의 프레임워크는 크게 두 가지 광범위한 시사점을 내포합니다. 하나는 경제 및 노동 시장에 관한 것이고, 다른 하나는 인공지능의 '안전' 문제에 대한 것입니다. 특정 기본 전제(특히 초지능(superintelligence)은 본질적으로 모순되거나 불가능하다는 점)를 제외하면, 이 두 가지 시사점 뒤에 있는 저희의 논지는 대체로 서로 다릅니다. 경제적 영향에 관해서는, 저희의 주장은 기술 역량 개선만으로는 확산 장벽이 극복되지 않을 것이라는 점을 폭넓게 강조합니다. 안전 문제에 대해서는, 인공지능의 '정렬(alignment)' 없이도 제어가 가능하며, 이는 특별히 어렵지도 않고 과학적 돌파구가 필요한 영역도 아니라는 것이 저희의 주요 주장입니다. 이 두 가지 주장은 크게 겹치지 않으므로, 한 가지 주장은 수용하고 다른 주장은 거부하거나(혹은 양가적인 태도를 취하는 것이) 논리적으로 일관될 수 있습니다. 실제로 경제적 파급 효과에 대한 저희의 견해는 독자들에게 특히 큰 공감을 얻은 것으로 보입니다. 에세이 출간 이후, 저희는 다양한 산업 분야에서 인공지능 전략을 담당하는 전문가들과 수많은 논의를 진행했습니다. 저희는 그들이 인공지능에 대해 생각하는 방식이 저희와 일치했음에도 불구하고, 끊임없는 과대광고(hype) 때문에 자신들의 접근 방식에 대해 재고하기 시작했다는 것을 알게 되었습니다. 저희 에세이는 현장에서의 그들의 관찰과 직관을 뒷받침하는 일관된 프레임워크를 제공했습니다. 4 인공지능을 실제로 배포하는 이들은 기술 개발과 확산의 차이를 명확히 이해하고 있지만, 저희 프레임워크는 이 각각의 과정을 다시 두 단계로 세분화합니다. 개발 측면에서는 '모델'과 '제품', 즉 '역량'과 '애플리케이션(application)' 사이의 간극을 강조합니다. 확산 측면에서는 '사용자 학습 곡선(user learning curves)'과 개인의 적응을 포함한 다양한 측면, 그리고 종종 집단적 행동을 요구하는 구조적, 조직적, 또는 법적 변화를 구분합니다. 저희는 각 4단계에서 작용하는 다양한 종류의 '속도 제한 요인'들을 설명합니다. 사용자 행동은 적어도 느리지만 예측 가능한 방식으로 변하는 경향이 있지만, 조정 문제를 해결하거나 경직된 제도(sclerotic institutions)를 개혁하는 것—이는 효과적인 기술 채택을 위한 필수 전제 조건이기도 합니다—은 훨씬 더 불확실합니다. 예를 들어, 현대화 부족으로 인한 막대한 비용이 명백해지고 있음에도 불구하고, 항공 교통 관제(Air Traffic Control) 시스템이 20세기 중반 기술에 갇혀 있는 방식을 생각해 보십시오. 저희 에세이는 인공지능의 경우에도 유사한 확산 장벽이 존재함을 지적했지만, 저희는 이제 그러한 장벽들을 명확히 설명하고 필요한 특정 개혁들을 식별하는 작업에 착수하고 있습니다. 저희는 이 분야에 대해 더 많은 글을 쓸 예정이며, 그 중 일부는 저스틴 컬(Justin Curl)과 협력하여 진행할 것입니다. 첨단 인공지능이 이미 고도로 기술적이고 엄격하게 규제되는 세상으로 진입하고 있다는 점을 염두에 둘 가치가 있습니다. 저희는 인공지능이 다루는 워크플로우(workflow)의 부분들이 병목 현상이 될 가능성이 낮다는 것을 반복적으로 발견합니다. 왜냐하면 사용 가능한 생산성 향상의 대부분은 이미 이전 기술의 물결을 통해 달성되었기 때문입니다. 반면, 실제 병목 현상은 규제나 다른 외부 제약으로 인해 변화에 저항하는 경향이 있습니다. 법률 서비스와 과학 연구를 포함한 많은 특정 영역에서 경쟁 역학(competitive dynamics)이 너무나 강력하여, 인공지능으로 인한 생산성 향상이 궁극적으로 사회적 가치로 이어지지 않고 오히려 '군비 경쟁'의 심화로 귀결되는 현상이 발생하기도 합니다.

경제와 노동에 대한 저희의 분석은 인공지능이 가져올 변화가 단순히 기술적 효율성의 문제가 아니라, 사회경제적 구조와 인간의 역할 재정의를 수반한다는 점을 시사합니다. 예를 들어, 자동화 기술이 발전하면서 특정 직업군이 사라지거나 업무 내용이 크게 변화할 수 있지만, 동시에 새로운 직업군이 생겨나거나 기존 직업의 생산성이 향상될 수도 있습니다. 중요한 것은 이러한 변화의 속도와 방향이 기술 자체의 발전 속도만큼이나, 교육 시스템, 노동 정책, 사회 안전망 구축과 같은 비기술적 요인에 의해 크게 좌우된다는 점입니다. 기술 확산의 속도 제한 요인 중 하나는 '조직 문화'의 변화입니다. 아무리 뛰어난 인공지능 솔루션이 도입되더라도, 조직 구성원들이 새로운 도구를 학습하고, 기존 업무 프로세스를 재정비하며, 협업 방식을 바꾸는 데는 상당한 시간과 노력이 필요합니다. 이는 단순히 기술을 구매하여 도입하는 것과는 차원이 다른 문제입니다. 또한, 인공지능의 '안전' 문제는 기술의 오작동이나 악용 가능성뿐만 아니라, 사회적 편향성(bias)이나 책임 소재 불분명과 같은 윤리적, 법적 문제까지 포괄합니다. 저희는 이러한 문제들이 기술적 해결책만으로 완전히 해소될 수 없으며, 사회적 합의와 제도적 장치 마련이 필수적이라고 봅니다. 인공지능 기술이 가져올 혜택을 극대화하고 위험을 최소화하기 위해서는, 기술 개발자, 정책 입안자, 기업 리더, 그리고 일반 시민 모두가 함께 참여하여 복합적인 해결책을 모색해야 할 것입니다.

**기술 확산 속도에 대한 비현실적인 논쟁**

저희는 여러 차례 서로 다른 진영들이 현재 인공지능의 영향력을 규정하는 방식에 대해 이견을 보이고 있다고 언급했습니다. 이러한 차이는 '확산 속도'를 논하는 부분에서 가장 명확하게 드러납니다. 인공지능 지지자들은 이 기술이 전례 없이 빠른 속도로 채택되고 있다고 확신합니다. 하지만 저희는 이 주장에 전적으로 동의하지 않습니다. 더욱이, 증거가 더 많이 축적될수록 각 측은 자신들의 해석에 대해 더 확신하는 경향을 보이는 듯합니다. 저희는 현재 확산 속도에 대한 심층적인 분석을 진행하고 있습니다. 우선적으로, '빠른 채택'이라는 주장을 정당화하기 위해 제시되는 일반적인 논거와 통계에서 몇 가지 근본적인 오류를 지적하고자 합니다. 첫째, '배포(deployment)'는 '확산(diffusion)'과 동일하지 않습니다. 종종 사람들이 빠른 채택을 이야기할 때, 이는 기술 역량이 개발되면 수억 명의 사용자가 사용하는 제품(예: 챗봇)에 거의 즉각적으로 배포될 수 있다는 의미로 사용됩니다. 그러나 이는 확산이 의미하는 바가 아닙니다. 단순히 얼마나 많은 사람들이 특정 역량에 접근할 수 있는지를 아는 것만으로는 충분치 않습니다. 중요한 것은 얼마나 많은 사람들이 실제로 그것을 사용하고 있는지, 얼마나 오랫동안 사용하고 있는지, 그리고 '무엇을 위해' 사용하고 있는지입니다. 이러한 세부적인 사용 행태를 깊이 들여다보면, 전체적인 그림은 매우 다르게 나타납니다. 예를 들어, ChatGPT에서 야심 차게 선보인 '사고(thinking)' 모델은 출시된 지 거의 1년이 지났음에도 불구하고, 매일 사용하는 사용자의 비율은 1% 미만이었습니다! 이 사실이 저희 논지를 뒷받침함에도 불구하고, 저희는 이 점을 지적하는 것이 즐겁지만은 않습니다. 인공지능의 열렬한 초기 사용자(early adopters)로서, 이 수치는 저희가 직관적으로 이해하기 어려울 정도로 낮으며, 솔직히 다소 우울하게 느껴집니다. 또 다른 오해의 소지가 있는 통계는 특정 '고위험 영역'에서 인공지능을 사용하는 근로자의 비율과 관련이 있습니다. 이러한 통계는 인공지능이 위험한 방식으로 빠르게 채택되고 있다는 주장을 뒷받침하기 위해 자주 인용됩니다. 그러나 고위험 영역 내에서도 대부분의 작업은 실제로는 평범하며, 특정 용도를 자세히 살펴보면 전혀 위험하지 않은 경우가 많습니다. 예를 들어, 미국 의사 협회(American Medical Association)의 설문조사 결과에 따르면 대다수의 의사가 인공지능을 사용하고 있다고 응답했습니다. 하지만 여기에는 구술된 메모의 '전사(transcription)'와 같은 작업이 포함됩니다. 5 또한 진단에 대한 '두 번째 의견'을 챗봇에 문의하는 것과 같은 사용도 포함됩니다 (2024년에는 약 12%가 이 사용 사례를 보고했으며, 이는 2023년 11%에서 1%포인트 증가한 수치로, 엄청나다고 할 수 있습니다). 이는 전사 작업보다는 확실히 더 심각한 사용이지만, 여전히 충분히 합리적인 범위 내에 있습니다. 저희가 이전에 지적했듯이, 신뢰할 수 없는 인공지능조차도 '오류 감지(error detection)'에는 매우 유용합니다. 이러한 작업에서 인공지능 채택이 증가한다는 것이 의사들이 무모하게 행동하고(YOLOing it) ChatGPT에 결정을 전적으로 위임하여 환자에 대한 책임을 회피하려 한다는 것을 의미하지 않습니다. 대다수의 의사들은 이 두 가지 유형의 사용 간의 차이를 명확히 이해하고 있으며, 의료 과실 책임, 직업 윤리 강령, 의료 기기 규제 등을 포함하여 의료 전문가 내에서 광범위한 무책임한 사용을 방지하는 수많은 중첩된 '안전장치(guardrails)'가 존재합니다. 가장 오해의 소지가 있는 '빠른 채택' 밈(meme)은 아마도 ChatGPT가 약 두 달 만에 1억 명의 사용자에게 도달했음을 보여주는 이 널리 공유된 차트일 것입니다. 이 차트는 ChatGPT 사용자 증가를 (1) '네트워크 효과(network effects)'에 따라 유용성이 달라지므로 첫날부터 유용한 앱보다 훨씬 느리게 성장하는 특징이 있는 소셜 미디어(social media) 앱인 인스타그램(Instagram), 페이스북(Facebook), 트위터(Twitter)와 비교하고, (2) 처음에는 초대 전용이었던 앱인 스포티파이(Spotify)와 (3) 제한된 재고로 출시되었고 사용하려면 구독이 필요했던 서비스인 넷플릭스(Netflix)와 비교합니다. 6 이 차트에 반영된 것은 앱에 대한 소문이 돌면 확인해 보는 초기 수용자(early adopters)들이며, ChatGPT에 대한 엄청난 소문이 있었습니다. 이러한 호기심 많은 초기 사용자들을 소진하고 나면, 성장 곡선은 매우 다르게 나타납니다. 실제로, 1년 후 ChatGPT는 1억 명에서 2억 명의 사용자로만 증가한 것으로 보이며, 이는 곡선이 오른쪽으로 급격히 꺾였다는 것을 분명히 보여줍니다. 이는 처음 두 달만을 반영하는 이 그래프에는 편리하게도 포착되지 않은 부분입니다. 이 차트는 확산에 대한 일반적인 장벽이 약화되거나 제거되었다는 증거를 제공한다면 유용할 것입니다. 하지만 그렇지 않습니다. 두 달은 사용자들이 인공지능을 생산적으로 통합하기 위해 '워크플로우(workflow)'를 조정하는 것과 같이 확산의 어려운 부분이 시작되기에도 충분한 시간이 아닙니다. 따라서 이 차트는 확산 속도에 대한 어떤 의미 있는 논의와도 무관합니다. 이 차트에는 다른 많은 문제점들이 있지만, 여기에서 멈추겠습니다. 7 다시 말하자면, 이것은 인공지능 확산 속도에 대한 완전한 분석과는 거리가 멀며—그것은 곧 발표될 것입니다. 현재로서는, 이 주제에 대한 대부분의 논평이 단순히 '진지하지 않다'는 점을 지적하는 것뿐입니다. 그리고 저희가 데이터를 가지고 있는 질문에 대한 담론이 이렇다면, 서로 다른 진영의 미래 예측이 서로 전혀 닮지 않았다는 것은 놀라운 일이 아닙니다.

기술 확산에 대한 오해는 종종 '잠재적 접근성'과 '실질적 활용도'를 혼동하는 데서 비롯됩니다. 수억 명의 사용자가 특정 AI 도구에 '접근'할 수 있다는 사실이 곧 그들이 해당 도구를 자신의 삶이나 업무에 깊이 '통합'하여 활용하고 있다는 의미는 아닙니다. 실제 확산은 기술이 사회경제적 시스템에 얼마나 깊이 뿌리내리고, 기존의 행태를 얼마나 변화시키며, 새로운 가치를 얼마나 창출하는지에 따라 측정되어야 합니다. 예를 들어, 스마트폰은 전 세계 수십억 명이 소유하고 있지만, 그들이 스마트폰의 모든 기능을 생산적으로 활용하는 방식은 개인마다, 문화권마다 큰 차이를 보입니다. 단순히 앱 다운로드 수나 초기 사용자 유입 속도만으로 기술의 확산 정도를 판단하는 것은 매우 피상적인 접근입니다. 인공지능의 경우, 특히 '제너레이티브 AI(generative AI)'는 초기에는 참신함과 높은 잠재력으로 인해 많은 관심을 받지만, 실제 비즈니스 프로세스나 개인의 일상생활에 의미 있는 변화를 가져오기 위해서는 상당한 학습과 적응이 필요합니다. 기업들은 인공지능 도입을 위해 대규모 투자를 단행하지만, 그 효과를 체감하기까지는 조직 구조 변경, 직원 교육, 데이터 거버넌스(data governance) 구축 등 복잡한 과정을 거쳐야 합니다. 이러한 과정은 결코 '빠르게' 진행되지 않으며, 오히려 예상치 못한 난관에 부딪히기도 합니다. 따라서 인공지능의 확산 속도를 평가할 때는 단순히 '얼마나 많은 사람이 기술을 아는가'가 아니라, '얼마나 많은 사람이 기술을 통해 실제적인 가치를 창출하고 있는가'에 초점을 맞춰야 합니다. 8

**인공지능 도입이 특별하게 느껴지는 이유**

만약 '빠른 확산'이라는 통념이 그렇게 잘못된 것이라면, 왜 그토록 널리 퍼져 있고 지속력을 가질까요? 그 이유는 인공지능의 도입이 개인용 컴퓨터(PC), 인터넷, 혹은 소셜 미디어(social media)가 결코 그러지 못했던 방식으로 마치 쓰나미처럼 느껴지기 때문입니다. 사람들이 어떤 현상에 대해 직관적으로 확신을 가질 때, 그들은 그러한 감각을 뒷받침한다고 주장하는 데이터나 차트에 대해 훨씬 덜 비판적으로 반응하는 경향이 있습니다. 물론 저희도 그와 같은 느낌을 공유합니다. 인공지능에 대한 저희의 실제 경험은 과거의 기술 물결과는 확연히 다릅니다. 처음에는 저희도 이를 '인지 편향(cognitive bias)'으로 치부했습니다. 우리가 현재 겪는 어떤 변화든 과거에 성공적으로 적응했던 변화보다 훨씬 더 크게 느껴질 것이라고 생각했습니다. 하지만 이제 저희는 그러한 생각이 틀렸음을 깨달았습니다. 인지 편향이 설명의 작은 부분을 차지할 수는 있겠지만, 인공지능 채택이 훨씬 더 빠르고 위협적으로 느껴지는 진정한 이유가 있습니다. 요약하자면, '배포(deployment)'가 '확산(diffusion)'과 다르다는 것은 사실이지만, 과거에는 점진적인 배포가 사용자들이 기술 채택에 대한 결정을 끊임없이 내려야 하는 부담으로부터 어느 정도 보호막 역할을 했다면, 이제 그 완충 지대가 사라졌습니다. 인터넷 채택 사례와 비교하여 설명해 보겠습니다. 1990년대 다이얼업 인터넷(dial-up internet)을 경험했던 사람들은 다음과 같은 이야기를 기억할 것입니다. 처음 기술에 대해 들었을 때, 저희는 PC의 높은 가격 때문에 망설였습니다. 점차 가격이 하락했습니다. 그동안 저희는 직장이나 친구 집에서 인터넷을 사용하는 경험을 쌓았습니다. 그래서 몇 년 후 PC와 다이얼업 인터넷을 구매했을 때, 저희는 이미 어느 정도 훈련이 되어 있었습니다. 초기에는 다이얼업 속도가 느리고 비용도 비쌌으며, 웹사이트도 그리 많지 않았기 때문에 인터넷을 많이 사용하지 않았습니다. 점진적으로 가격이 인하되고, 대역폭(bandwidth)이 개선되었으며, 더 많은 콘텐츠가 온라인에 등장하면서, 저희는 사용량 증가와 더불어 인터넷을 생산적이고 안전하게 사용하는 방법을 자연스럽게 익혔습니다. 2020년대에 범용 인공지능 도구(general-purpose AI tools)를 채택하는 것은 새로운 역량의 '배포(deployment)'가 즉각적으로 이루어지기 때문에 근본적으로 다른 경험입니다. 사람들은 특정 사용 사례(use case)에 인공지능을 채택할지 여부를 평가하는 데 훨씬 더 많은 시간을 할애해야 하며, 채택하지 않으면 뒤처질 것이라는 말을 끊임없이 듣습니다. 저희의 이전 모든 주장은 여전히 유효합니다. 학습 곡선(learning curves)은 존재하고, 인간 행동은 변화하는 데 오랜 시간이 걸리며, 조직 변화는 훨씬 더 오래 걸립니다. 그러나 인공지능을 사용하지 않는 것은 어느 정도 '능동적인 선택'이 되었으며, 사람들은 더 이상 '접근할 수 없기 때문에' 그것에 대해 생각하지 않아도 된다는 변명을 할 수 없습니다. 요컨대, 배포는 확산의 여러 단계 중 하나일 뿐이며, 그 병목 현상을 제거하는 것이 확산을 다소 더 빠르게 만들었을 것입니다. 그러나 특정 인공지능 사용 사례에 대해 듣자마자, 궁극적으로는 합리적이거나 비합리적일 수 있는 다양한 이유로 대다수의 사람들이 채택하지 않기로 결정하는 경우라 할지라도, '채택할지 말지'를 결정해야 하기 때문에 극적으로 더 빠르게 느껴지는 것입니다.

이러한 '체감 속도'의 차이는 인공지능 기술이 과거의 기술들과는 다른 방식으로 개인의 의사결정 과정에 직접적으로 개입하기 때문입니다. 과거에는 새로운 기술이 도입되면, 그 기술을 배우고 활용할 충분한 시간적 여유가 있었고, 기술 도입 여부는 대개 '편의성'이나 '효율성'이라는 측면에서 점진적으로 결정되었습니다. 그러나 인공지능은 그 잠재적 영향력이 너무나 크고 광범위하여, 마치 '선택의 강요'처럼 느껴집니다. 특히 직업 환경에서는 인공지능 도구의 도입이 생산성 향상과 직결된다는 인식이 강해, 이를 외면하기 어려운 압박으로 작용합니다. 이러한 심리적 압박은 실제 확산 속도와는 별개로, 인공지능이 '빠르게' 사회에 스며들고 있다는 인식을 강화합니다. 또한, 인공지능 기술의 특성상 초기 버전에서도 상당한 수준의 기능을 제공하며, '즉각적인 만족감'을 제공하는 경우가 많습니다. 이는 사용자들이 기술의 복잡성을 완전히 이해하기 전에 이미 그 효용성을 경험하게 하여, 기술에 대한 긍정적인 인식을 빠르게 형성하는 데 기여합니다. 그러나 이러한 초기 만족감이 실제적인 '숙련된 활용'으로 이어지는 데는 여전히 상당한 시간과 노력이 필요하며, 이 간극이 바로 확산 속도에 대한 오해를 불러일으키는 원인이 됩니다. 따라서 인공지능의 진정한 사회적 영향력을 평가하기 위해서는, 초기 '수용' 단계를 넘어선 '지속적인 활용'과 '심층적인 통합' 여부를 면밀히 분석해야 합니다. 9

**결론 및 제언**

저희가 인공지능 지지자들과 분명히 의견을 같이하는 한 가지는, 인공지능이 결코 사라지지 않을 것이며, 대다수의 사람들이 무시할 수 있는 암호화폐(crypto)와 같은 틈새 기술로 남지 않을 것이라는 점입니다. 생성형 인공지능(generative AI)에 대한 집단적인 초기 충격이 진정되었으므로, 이제는 각각의 새로운 기술 역량이나 비예측적 사회적 파급 효과(emergent social effect)에 대해 과도하게 반응하기보다는, 인공지능의 영향이 어떻게 전개될지 체계적으로 사고하는 방식이 필요합니다. 저희가 이 뉴스레터에서 지속적으로 상세히 설명하고 있는 '정상 기술로서의 AI(AI as Normal Technology)' 프레임워크는 그러한 접근 방식 중 하나입니다. 이 프레임워크는 적어도 기술의 사회적 영향에 대해 역사적 맥락에 기반한 기본적인 사고방식을 명확히 제시하며, 더 예외주의적인 설명들과 대비될 수 있다는 점에서 익숙해질 가치가 있습니다. 이 틀은 기업 경영자, 직장인, 학생, 인공지능 안전 또는 인공지능 윤리(AI ethics)에 관심을 가진 사람들, 그리고 정책 입안자 등 다양한 주체들에게 어느 정도 실질적인 지침을 제공합니다. 저희는 여러분이 계속해서 저희와 함께 이 논의에 참여하고 기여해 주시기를 진심으로 바랍니다. 초고에 대한 귀중한 피드백을 주신 스티브 뉴먼(Steve Newman)과 펠릭스 첸(Felix Chen)께 감사의 말씀을 전합니다.

궁극적으로 인공지능은 더 이상 공상 과학 소설 속의 이야기가 아닌, 우리 삶의 다양한 영역에 깊숙이 스며들고 있는 현실의 기술입니다. 중요한 것은 이러한 현실을 직시하고, 기술의 발전이 가져올 수 있는 기회와 도전을 균형 잡힌 시각으로 바라보는 것입니다. '정상 기술로서의 AI(AI as Normal Technology)'라는 관점은 인공지능을 지나치게 숭배하거나 두려워하기보다는, 다른 범용 기술들과 마찬가지로 사회적 맥락 속에서 이해하고 관리해야 할 대상으로 인식하게 합니다. 이는 인공지능이 가진 기술적 특성뿐만 아니라, 그것을 둘러싼 인간의 의도, 사회적 규범, 제도적 장치 등이 복합적으로 작용하여 그 최종적인 형태와 영향력을 결정한다는 점을 강조합니다. 따라서 인공지능의 미래를 논하는 데 있어 기술적 전문성만큼이나 사회학적, 경제학적, 윤리적 통찰력이 중요합니다. 저희는 이러한 다학제적 접근 방식이 인공지능 시대의 복잡한 문제들을 해결하고, 기술이 인류에게 진정으로 유익한 방향으로 발전하도록 이끄는 데 필수적이라고 믿습니다. 앞으로도 저희는 이 프레임워크를 통해 인공지능 기술이 사회에 통합되는 과정을 지속적으로 탐구하고, 건설적인 논의의 장을 마련하고자 합니다. 10

**추가 읽을거리/볼거리**

아르빈드(Arvind)는 세계은행 개발 회의(World Bank Development Conference)에서 경제 및 노동 관련 함의에 초점을 맞춰 이 논문을 발표했습니다. 또한, 아르빈드(Arvind)의 새로운 유튜브 채널(YouTube channel)에서는 인공지능 개발을 '일상적 기술' 관점에서 심도 있게 다룹니다. 저희의 '정상 기술로서의 AI(AI as Normal Technology)' 논의는 여러 주요 언론 매체에서도 주목받았습니다. 지난달 뉴욕 타임스(New York Times)에서는 에릭 슈미트(Eric Schmidt), 셀리나 쉬(Selina Xu), 데이비드 월러스-웰스(David Wallace-Wells), 그리고 에즈라 클라인(Ezra Klein)이 이 에세이를 심층 분석한 세 편의 오피니언(op-ed)을 게재했습니다. 지난주 이코노미스트(The Economist)는 "인공지능이 그저 “정상적인” 기술이라면 어떨까?(What if artificial intelligence is just a “normal” technology?)"라는 기사에서 저희의 주장을 다루었습니다. 더 뉴요커(The New Yorker)의 조슈아 로스먼(Joshua Rothman)은 'AI 2027'과 '정상 기술로서의 AI(AI as Normal Technology)'를 비교 분석하는 글을 썼고, 프로스펙트 매거진(Prospect Magazine)에서는 이든 주커만(Ethan Zuckerman)이 인공지능을 '일상적 기술'로 바라보는 관점의 유용성을 논했습니다. MIT 테크놀로지 리뷰(MIT Technology Review)의 제임스 오도넬(James O'Donnell)은 저희의 '정상 기술로서의 AI(AI as Normal Technology)' 논지를 요약했습니다. 저희의 팟캐스트(podcast) 출연 중 일부는 다음과 같습니다. 뉴욕 타임스(New York Times)의 '하드 포크(Hard Fork)'와 팀 오라일리(Tim O’Reilly)의 팟캐스트에 아르빈드(Arvind)가 출연했습니다. 사야시(Sayash)는 로페어(Lawfare)의 '스케일링 법칙(Scaling Laws)'과 카네기(Carnegie)의 '인도 해석(Interpreting India)'에 참여했습니다. 저희는 'AI 2027'의 여러 저자를 포함하여 '초지능' 세계관을 가진 많은 분들과 대화를 나누었습니다. 사야시(Sayash)는 다니엘 코코타일로(Daniel Kokotajlo) 및 엘리 리프랜드(Eli Lifland)와 토론을 벌였고, 아르빈드(Arvind)는 다니엘 코코타일로(Daniel Kokotajlo)와 대담했습니다. 또한 애스터리스크 매그(Asterisk Mag)에서는 아르빈드(Arvind)와 아제야 코트라(Ajeya Cotra)가 인공지능 발전이 속도 제한을 가지고 있는지, 그리고 우리가 이를 어떻게 알 수 있는지에 대해 논의했습니다.

저희의 작업에 대한 이러한 광범위한 관심은 인공지능의 미래에 대한 논의가 점차 기술 자체의 성능을 넘어 사회적, 경제적, 정책적 함의로 확장되고 있음을 보여줍니다. 이는 인공지능이 단순한 기술적 경이로움이 아니라, 인류 사회의 근본적인 질문들을 제기하는 복합적인 현상임을 시사합니다. 독자들이 저희의 관점을 통해 인공지능의 사회적 통합 과정에 대한 보다 현실적인 이해를 얻고, 이를 바탕으로 미래를 대비하는 데 기여할 수 있기를 바랍니다. 저희는 앞으로도 다양한 미디어 채널을 통해 인공지능의 '일상적 기술' 관점을 확산시키고, 관련 분야 전문가 및 일반 대중과의 소통을 강화할 예정입니다. 특히, 인공지능이 가져올 노동 시장의 변화, 새로운 산업 생태계의 형성, 그리고 사회적 불평등 심화 가능성 등 복합적인 문제들에 대한 심층적인 분석과 해결책 모색에 집중할 것입니다. 11

---
**각주**

1.  흔히 그렇듯이, 에세이의 성공에는 우연한 타이밍이 큰 영향을 미쳤습니다. 이 글은 'AI 2027'이 발표된 지 2주 후에 공개되었는데, 이는 전적으로 우연의 일치였습니다. 저희의 출판일은 실제로는 나이트 연구소(Knight Institute)의 'AI와 민주적 자유 심포지엄(symposium)' 일정에 맞춰졌습니다. 이 귀한 출판 기회를 제공해 준 연구소에 깊이 감사드립니다.
2.  일반적으로 챗봇(chatbot)과 연관된 정신 건강 문제나 중독과 같은 이슈들은 저희의 저서 'AI 스네이크 오일(AI Snake Oil)'을 포함하여 이미 널리 인지되고 논의되어 왔습니다. 이러한 문제들은 대체로 소셜 미디어(social media)와의 유사성에 기반하여 비유되곤 합니다. 하지만 정신 건강에 미칠 잠재적 영향을 예측하는 것과, 구체적으로 어떤 영향이 나타날지 그리고 그것을 어떻게 예방할 수 있을지를 예측하는 것은 별개의 문제입니다.
3.  그럼에도 불구하고, 저희는 저희의 전체 주장이 틀릴 수도 있음을 인정하며, '재귀적 자기 개선(RSI)'이 실제로 실현된다면 저희가 틀릴 가능성이 더 높아질 것입니다.
4.  이 프레임워크(framework)는 고전적인 '혁신 확산 이론(diffusion-of-innovations theory)'에서 영감을 얻었으며, '혁신-확산 격차(innovation-diffusion gap)'의 관점에서 인공지능 분야의 지정학적 경쟁을 분석한 제프리 딩(Jeffrey Ding)과 같은 최근 학자들의 연구에서도 영향을 받았습니다.
5.  물론 여기에도 위험 요소가 존재하지만, 저희는 이것이 의사들이 반드시 탐색해야 할 응용 분야라고 확신합니다.
6.  실제로, 포켓몬 고(Pokemon Go)와 스레드(Threads)(인스타그램(Instagram)을 기반으로 성장하여 네트워크 효과(network effects)에 덜 의존했음)와 같이 초기 사용자 증가 속도가 ChatGPT와 비슷하거나 더 빨랐던 다른 애플리케이션들도 있었습니다. 그러나 다시 한번 강조하지만, 저희의 더 중요한 요점은 이러한 유형의 비교 자체가 별다른 통찰을 제공하지 않는다는 것입니다. 스레드(Threads)는 초기 사용자 유입에도 불구하고 실패작에 가깝다는 평가를 받았습니다.
7.  솔직히, 저희의 관점에서는 이 그래프에서 훨씬 더 인상적인 통계는 인스타그램(Instagram)이 네트워크 효과(network effects)의 필요성에도 불구하고 단 2.5개월 만에 백만 명의 사용자에게 도달했다는 사실입니다. 이는 휴대폰 인터넷 속도가 훨씬 느렸고, 앱이 아이폰(iPhone) 전용이었으며 (!), 초기에는 주로 미국 내 18~34세 연령층에 확산되었던 2010년이라는 시점을 고려할 때 더욱 놀라운 성과입니다.
8.  인공지능의 확산 과정을 이해하기 위해서는 단순한 사용자 수치 외에, 기술이 사용자들의 일상적인 문제 해결에 얼마나 깊이 통합되고 있는지를 측정하는 질적인 지표들이 필요합니다. 예를 들어, 인공지능 도구의 '반복 사용률', '작업 완성률', '사용자의 생산성 향상 체감도' 등이 고려될 수 있습니다.
9.  의료 분야에서 인공지능의 활용은 '보조 도구'로서의 역할과 '독립적인 의사결정 주체'로서의 역할을 명확히 구분해야 합니다. 현재 대부분의 인공지능 의료 애플리케이션은 의사의 진단을 보조하거나 행정 업무를 효율화하는 데 중점을 둡니다. 이는 환자 안전을 최우선으로 하는 의료 윤리 및 법적 책임 체계와 일관됩니다.
10. 기술의 '혁신 주기'와 '사회적 수용 주기' 사이의 비동기화는 인공지능 확산의 중요한 특징입니다. 기술은 기하급수적으로 발전할 수 있지만, 사회는 선형적으로, 때로는 훨씬 더 느리게 변화합니다. 이러한 간극을 이해하는 것이 인공지능의 미래를 현실적으로 전망하는 데 필수적입니다.
11. '인지적 부하(cognitive load)'는 새로운 기술을 채택할 때 사용자가 겪는 정신적 노력을 의미합니다. 인공지능 도구가 너무 복잡하거나 사용법이 직관적이지 않으면, 아무리 강력한 기능이라도 확산에 실패할 수 있습니다. 사용자 경험(UX) 디자인의 중요성이 부각되는 지점입니다.