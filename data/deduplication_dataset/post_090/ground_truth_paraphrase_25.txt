OpenAI의 오랫동안 기다려온 GPT-5가 드디어 공개되었습니다. 오랜 시간 동안 기다려온 이 모델은 swyx와 ben을 포함한 소수 인원에게 사전 테스트 기회를 제공했습니다. 간략히 말해, 우리는 GPT-5가 인공 일반 지능(AGI)으로 나아가는 중대한 진전이라고 확신합니다. 본 글의 작성에 기여해준 공동 창업자 Alexis Gauba에게 깊은 감사를 표합니다. 저희의 첫 공개 시연 영상은 여기에 준비되어 있습니다. @Sama가 약 2년 전부터 GPT-5에 대한 기대를 꾸준히 표명해왔고, 마침내 오늘 그 실체가 드러났습니다. OpenAI의 초기 접근(early-access) 파트너로서, 저는 GPT-5를 미리 시험해볼 수 있는 특권을 누렸습니다. 저희의 애플리케이션(raindrop.ai)을 비롯해 Cursor, Codex, Canvas 등 다양한 환경에서 이 모델을 활용해 보았습니다. 가능한 모든 시나리오와 플랫폼에서 GPT-5의 성능을 시험하려 노력했습니다. 결론적으로, GPT-5는 저희가 경험했던 인공지능 모델 중 인공 일반 지능(AGI) 개념에 가장 근접한 것으로 평가됩니다.

최근 몇 년간 인공지능 분야는 전례 없는 속도로 발전해왔습니다. 특히 대규모 언어 모델(LLM)은 정보 처리 방식과 인간과의 상호작용 방식에 혁명적인 변화를 가져왔습니다. 이러한 흐름 속에서 OpenAI의 새로운 모델 출시는 항상 큰 관심사였으며, GPT-5는 그 정점에 있습니다. 단순히 기능적 개선을 넘어, AGI라는 장기적인 목표에 얼마나 근접했는지를 가늠하는 중요한 척도가 될 것으로 기대되었습니다. 개발자 커뮤니티는 이 모델이 가져올 패러다임의 변화에 촉각을 곤두세웠고, 초기 테스트 결과는 이러한 기대를 상당 부분 충족시켰습니다. 특히, 복잡한 문제 해결 능력과 다면적인 환경 적응성은 이전 세대 모델들과는 확연히 다른 수준을 보여주었습니다.

GPT-5는 소프트웨어 개발 영역에서 놀라운 역량을 발휘합니다. 복잡한 애플리케이션을 단 한 번의 시도로 완성하는 것부터 광범위한 코드 기반 내에서 난해한 문제들을 풀어내는 데 이르기까지, 그 성능은 단연 돋보입니다. 하지만 모든 측면에서 '단순히 더 나은' 모델이라고 단정하기는 어렵습니다. 사실, 글쓰기 능력에 있어서는 GPT-4.5보다 미흡하며, 심지어 4o 모델에 비해서도 부족하다고 판단됩니다. 대부분의 상황에서 사용자에게 즉각적으로 초월적인 지능을 가진 존재처럼 느껴지지는 않을 것입니다. 이러한 한계점들에도 불구하고, GPT-5는 인공 일반 지능(AGI)의 발전 과정을 바라보는 저의 관점을 근본적으로 변화시켰습니다.

이러한 상반된 평가는 대규모 언어 모델의 설계 철학이 얼마나 복잡한지를 보여줍니다. 특정 영역에서 비약적인 발전을 이루는 동시에, 다른 영역에서는 상대적인 약점을 보일 수 있습니다. 이는 모델이 특정 목적에 최적화되는 과정에서 발생하는 자연스러운 현상일 수 있습니다. 예를 들어, GPT-5는 논리적 추론, 코드 생성 및 디버깅과 같은 인지적 복잡성이 높은 작업에 중점을 두었을 가능성이 있습니다. 반면, 인간의 감성이나 문학적 표현을 요구하는 글쓰기 작업에서는 아직 개선의 여지가 있음을 시사합니다. 이러한 특성을 이해하는 것은 사용자가 GPT-5를 가장 효과적으로 활용하고, 그 한계를 인식하는 데 필수적입니다. 단순히 '초천재'가 아니라, 특정 분야에서 놀라운 능력을 가진 '전문가'로 접근해야 할 필요성을 강조합니다.

이 점을 명확히 설명하려면, 인류 역사의 초기 단계인 석기 시대로 거슬러 올라가야 합니다. 인공 일반 지능(AGI)이란 과연 무엇을 의미할까요? 석기 시대는 인류 지성의 새벽을 알렸지만, 정확히 어떤 요인이 그 시대를 그렇게 중요하게 만들었을까요? 무엇이 인류 문명의 본격적인 시작을 알렸을까요? 인류가 전략적인 체스 대결에서 승리했기 때문일까요? 혹은 우리 지능의 심오함을 우주에 드러낼 만한 근본적인 수학적 정리를 증명했기 때문일까요? 아니면 원주율(pi)의 더 많은 소수 자릿수를 외웠기 때문일까요? 그렇지 않습니다. 석기 시대의 출발점은 단 하나의 사실로 명확히 정의됩니다. 그것은 바로 인간이 도구를 활용하는 방법을 터득했다는 것입니다. 우리는 도구를 창조했고, 그 도구는 역설적으로 우리 자신을 형성했습니다. 이 도구들은 우리의 존재 방식을 깊이 변화시켰습니다. 예를 들어, 침팬지가 인간보다 훨씬 뛰어난 단기 기억력을 가지고 있다는 사실을 아셨나요? 우리는 정보를 기록하는 방법을 배우면서 그러한 능력을 내부적으로 유지할 필요가 줄어들었습니다. 인간으로서 우리는 도구를 매개로 우리의 지능을 외부로 확장합니다. 도구는 우리의 역량을 증폭시키며, 우리는 내재된 능력을 외부적 수단과 교환합니다. 이것이야말로 우리 지성의 본질적인 특성입니다.

도구 사용은 단순히 물리적인 작업을 돕는 것을 넘어, 인류의 인지 능력 자체에 혁명적인 변화를 가져왔습니다. 도구는 복잡한 문제 해결을 가능하게 하고, 추상적 사고를 촉진하며, 지식을 축적하고 전달하는 기반이 되었습니다. 이러한 능력은 다른 동물 종과의 결정적인 차이를 만들어냈습니다. 도구가 없었다면, 우리는 여전히 생존을 위한 기본적인 본능에 갇혀 있었을지도 모릅니다. 도구는 인류가 환경을 조작하고, 자연의 제약을 극복하며, 궁극적으로 문명을 건설하는 데 결정적인 역할을 했습니다. 따라서 AGI를 논할 때, 단순히 '지능'의 수준을 넘어 '도구를 얼마나 효과적으로 인식하고, 활용하며, 심지어 창조하는가'라는 관점에서 접근하는 것이 중요합니다.

**도구의 새로운 지평**

GPT-5의 등장은 인공지능 에이전트(Agent)와 대규모 언어 모델(LLM)의 새로운 시대를 열었습니다. 이 모델은 단순히 외부 도구를 활용하는 수준을 넘어, 도구 자체를 사고의 확장으로 여기고, 이를 통해 새로운 가치를 창출합니다. OpenAI의 '딥 리서치(Deep Research)' 기능은 이러한 미래 지향적 접근 방식의 첫 번째 가시적인 예시였습니다. 기존 ChatGPT에도 웹 검색 기능이 있었지만, 딥 리서치는 차원이 달랐습니다. OpenAI는 o3 모델에게 인터넷에서 정보를 조사하는 방법을 가르쳤습니다. 단순한 검색 도구 호출과 응답을 넘어, 실제로 연구를 계획하고, 여러 단계를 반복하며, 정보를 탐색하고 종합하는 능력을 갖추게 된 것입니다. 웹 검색은 이제 모델의 사고 과정의 필수적인 부분이 되었습니다. 딥 리서치가 웹에 국한되었다면, GPT-5는 접근 가능한 모든 종류의 도구에 대해 동일한 심층적 활용 능력을 보여줍니다. 물론, 이 능력을 최대한 발휘하려면 적절한 도구 세트를 제공해야 합니다.

이러한 '도구로 사고하는' 능력은 LLM의 한계를 극복하는 핵심 열쇠입니다. 모델이 자체적으로 정보를 검색하고, 코드를 실행하며, 외부 시스템과 상호작용하는 것은 단순히 외부 API를 호출하는 것과는 본질적으로 다릅니다. 이는 모델이 문제 해결을 위한 전략을 세우고, 필요한 도구를 선택하며, 도구의 결과를 해석하고, 다음 단계를 계획하는 일련의 '추론 과정'을 수행한다는 것을 의미합니다. 마치 인간이 복잡한 문제를 해결할 때 책을 찾아보거나 계산기를 사용하는 것처럼, GPT-5는 자신의 '도구 상자'를 능동적으로 활용합니다. 이로써 모델은 최신 정보에 접근하고, 복잡한 계산을 수행하며, 외부 세계에 영향을 미치는 '행동'을 취할 수 있게 됩니다. 이는 LLM이 단순한 텍스트 생성기를 넘어, 실제 세계와 상호작용하는 지능형 에이전트로 진화하는 중요한 전환점입니다.

**GPT-5 도구의 해부**

일반적으로 사람들이 도구라고 하면, `get_weather(address)`, `get_location(address)`, `has_visited_location(address)`와 같이 특정 기능을 수행하는 정형화된 함수를 떠올립니다. GPT-5 역시 이러한 유형의 도구들을 활용할 수 있지만, 단순히 여기에 만족하지 않습니다. 이 모델이 진정으로 필요로 하는 것은 강력하고, 유연하며, 개방적인 도구, 즉 개별 구성 요소의 합보다 훨씬 더 큰 가치를 창출하는 도구입니다. 효과적인 도구들은 대개 자연어 설명을 입력으로 받아들일 것입니다. Swyx의 통찰력에 감사하며, 여러분의 도구는 다음 네 가지 핵심 범주 중 하나에 해당해야 합니다:

*   내부 정보 검색(Internal Retrieval) (RAG, SQL 쿼리, 다양한 bash 명령어 등)
*   웹 검색(Web Search)
*   코드 해석기(Code Interpreter)
*   실행(Actions) (파일 수정, UI 작동 등 부수 효과를 일으키는 모든 작업)

웹 검색은 강력하고 개방적인 도구의 대표적인 사례입니다. GPT-5는 어떤 정보를 찾아야 할지 스스로 판단하고, 웹 검색 도구는 퍼지 문자열 매칭(fuzzy string matching), 임베딩(embeddings), 그리고 여러 순위 알고리즘(ranking algorithms)의 조합을 통해 가장 효과적인 검색 방법을 찾아냅니다. Bash 명령어 또한 훌륭한 예시입니다. 이는 내부 정보 검색(grep, git status, yarn why 등), 코드 해석, 그리고 부수 효과를 지닌 작업을 수행하는 데 사용될 수 있습니다. 웹 검색이나 `git status`가 내부적으로 어떻게 작동하는지는 각 도구의 구현 세부 사항(implementation details)일 뿐이며, GPT-5는 이러한 복잡성에 신경 쓸 필요가 없습니다! 모델은 단지 자신이 해결하려는 질문을 각 도구에 전달하기만 하면 됩니다. 이는 제품 설계에 대한 우리의 사고방식을 근본적으로 바꿀 것입니다. 모델에 엄격한 API(애플리케이션 프로그래밍 인터페이스)를 제공하는 대신, 고객의 데이터에 자유롭고 안전하게 격리된 방식으로 접근할 수 있는 일종의 쿼리 언어(query language)를 제공하는 것이 이상적입니다. 모델이 스스로 알아서 처리하도록 맡기는 것입니다. OpenAI가 자유 형식 함수 호출(free-form function calling) (문맥 자유 문법(context-free grammars)을 위한) 지원을 추가한 것은 결코 우연이 아닙니다. 최고의 GPT-5 도구는 오직 텍스트만을 입력으로 받아들일 것입니다. 이는 본질적으로 서브 에이전트(sub-agents)와 같은 역할을 하며, 필요에 따라 더 작은 모델을 활용하여 요청을 해석합니다.

전통적인 API는 개발자가 특정 기능을 명확하게 정의하고, 모델은 그 정의된 인터페이스에 맞춰 호출해야 합니다. 그러나 GPT-5가 지향하는 바는 이보다 훨씬 유연합니다. '쿼리 언어' 방식은 모델이 자신의 의도를 자연어로 표현하면, 시스템이 이를 해석하여 적절한 도구를 찾아 실행하는 방식입니다. 이는 모델이 더 능동적으로 문제 해결에 참여할 수 있도록 하며, 개발자는 모델이 사용할 수 있는 도구의 기능적 범위만 정의하면 됩니다. 이러한 접근 방식은 도구의 확장성과 유연성을 극대화하며, 모델이 예상치 못한 방식으로 도구를 조합하여 새로운 솔루션을 찾아낼 가능성을 열어줍니다. 또한, '서브 에이전트' 개념은 복잡한 작업을 더 작고 관리 가능한 하위 작업으로 분할하고, 각 하위 작업에 최적화된 모델이나 도구를 할당하는 방식을 의미합니다. 이는 전체 시스템의 효율성과 견고성을 높이는 데 기여합니다. 예를 들어, 특정 데이터베이스 쿼리에는 SQL에 특화된 소형 모델을, 웹 검색에는 검색 엔진 최적화에 능한 모델을 활용하는 식입니다.

**병렬 도구 호출(Parallel Tool Calling)**

GPT-5는 여러 도구를 동시에 활용하는 능력에서 탁월함을 보입니다. 이전 모델들 역시 이론적으로는 병렬 도구 호출이 가능했지만, 실제 적용에서는 A. 거의 실행되지 않았거나, B. 정확성이 현저히 떨어지는 문제가 있었습니다. 특정 작업을 위해 어떤 도구들을 병렬로 실행할 수 있고 또 그렇게 해야 하는지를 정확히 판단하는 데는 상당한 수준의 지능이 요구됩니다. 만약 컴퓨터가 한 번에 하나의 작업만 처리할 수 있다면, 그 효율성은 극도로 저하될 것입니다. 이러한 병렬 처리(Parallelization) 역량 덕분에 GPT-5는 훨씬 긴 작업 흐름 속에서도 현저히 낮은 지연 시간(latency)으로 기능을 수행할 수 있습니다. 이는 기존에는 불가능했던 새로운 종류의 제품과 서비스를 구현할 수 있게 하는 핵심적인 발전입니다.

병렬 도구 호출은 단순히 속도 향상을 넘어, 모델이 더욱 복잡하고 다층적인 문제를 동시에 처리할 수 있게 합니다. 예를 들어, 한편으로는 웹에서 최신 정보를 검색하고, 다른 한편으로는 내부 데이터베이스에서 관련 데이터를 추출하며, 동시에 코드 인터프리터를 통해 특정 로직을 검증하는 식입니다. 이러한 동시 처리 능력은 모델이 더욱 '인간적인' 방식으로 멀티태스킹을 수행하게 하며, 실시간 의사결정이나 복잡한 시뮬레이션과 같은 시나리오에서 그 진가를 발휘합니다. 이전에는 여러 단계를 순차적으로 거쳐야 했던 작업들이 이제는 훨씬 짧은 시간 안에 완료될 수 있게 되어, 사용자 경험을 혁신적으로 개선합니다. 이는 금융 분석, 의료 진단 보조, 실시간 고객 서비스 등 지연 시간에 민감한 분야에서 특히 큰 파급 효과를 가져올 것입니다.

**GPT-5 프롬프트(Prompt)의 해부**

이제 우리는 단순히 '모델'에 명령을 내리는 방식에서 벗어나, '에이전트'에게 지시를 내리는 관점으로 사고를 전환해야 합니다. 그렇다면 에이전트에게 어떻게 효과적으로 지시를 내릴 수 있을까요? 방대한 양의 컨텍스트(context)를 미리 로드하기보다는, 에이전트가 처한 환경을 성공적으로 탐색할 수 있도록 명확하고 체계적인 지침, 즉 일종의 '가이드라인'을 제공해야 합니다. 예를 들어, 방대한 코드베이스(codebase) 내에서 Cursor Agent와 GPT-5를 함께 활용한다고 상상해 봅시다. 에이전트에게 다음 정보를 명확히 전달해야 합니다:

*   이 프로젝트의 목적과 기능
*   어떤 파일부터 검토를 시작해야 할지
*   파일 구조 및 구성 방식
*   특정 도메인이나 제품에 특화된 용어
*   작업 완료 여부를 판단하는 기준 (성공적인 작업의 모습)

(경험상 '규칙 파일(rule files)'이 이전보다 훨씬 더 효과적으로 작동하는 것을 확인했습니다.)

마찬가지로, GPT-5가 문제에 직면하여 진행이 막혔을 때, 단순히 "그건 틀렸어"라고 지적하는 것은 별다른 도움이 되지 않습니다. 대신, "그 방법은 작동하지 않았는데, 무엇을 알게 되었니?" 또는 "그 시도를 통해 무엇을 배웠니?"와 같이 질문하는 것이 훨씬 효과적입니다. 마치 교사처럼 에이전트를 지도하는 자세가 필요합니다. GPT-5는 본질적으로 '기억력'이 없다는 점을 명심하고, 코드베이스, 회사 코딩 표준(code standards)에 대해 지속적으로 상기시켜 주며, 각 작업의 시작점에 대한 명확한 힌트(hints)를 제공해야 합니다.

이러한 에이전트 중심의 프롬프트 방식은 단순히 명령어 전달을 넘어, 모델과의 지속적인 상호작용과 학습을 포함합니다. 효과적인 피드백 루프를 구축하는 것이 핵심인데, 이는 에이전트가 실패로부터 배우고 스스로 개선해 나갈 수 있도록 돕습니다. 예를 들어, 에이전트가 특정 코드를 생성한 후 컴파일 오류가 발생했다면, 단순히 오류 메시지를 전달하는 것을 넘어, '이 오류 메시지가 의미하는 바는 무엇이며, 어떤 부분을 수정해야 할까?'와 같이 질문하여 에이전트가 스스로 문제 해결 과정을 거치도록 유도할 수 있습니다. 이는 에이전트의 자율성을 높이고, 장기적으로는 더욱 복잡하고 미묘한 작업을 처리할 수 있는 능력을 키워줍니다. 인간과 에이전트가 함께 작업하는 '협업 지능'의 새로운 형태로 볼 수 있으며, 에이전트가 우리의 확장된 지능이 되도록 돕는 과정입니다. 궁극적으로는 에이전트가 인간의 의도를 더 잘 이해하고, 예상치 못한 상황에서도 유연하게 대처할 수 있도록 훈련하는 것이 목표입니다.

**더 많은 바이브 테스트(Vibe Tests)**

새로운 인공지능 모델이 등장할 때마다, 우리는 그 고유한 특성을 파악하고 직관적인 이해를 구축하려 애씁니다. 마치 인생의 여러 문제(예를 들어, 연애 상담, 블로그 글 수정, 특정 머신러닝 개념 설명 등)에 대해 어떤 친구에게 조언을 구해야 할지 직감적으로 아는 것처럼, 우리는 다양한 모델들이 어떤 유형의 작업에 강점을 가지는지에 대한 직관을 발전시켜 왔습니다. 최근 모델들은 점점 더 '특정 분야에 특화된(spiky)' 경향을 보이며, 각기 다른 전문 영역을 가지고 있습니다. 따라서 새로운 모델이 출시되면, 모두가 필연적으로 이 '특화된 강점(spike)'이 무엇인지 파악하고자 합니다.

이러러한 '바이브 테스트(Vibe Tests)'는 모델의 공식 벤치마크(benchmarks)가 보여주지 못하는 미묘한 특성, 즉 '성격'이나 '사고방식'을 포착하는 데 중요합니다. 각 모델이 어떤 가치관을 내재하고 있는지, 어떤 스타일로 정보를 처리하고 표현하는지, 그리고 어떤 종류의 편향(bias)을 가지고 있는지를 짧고 비정형적인 질문을 통해 엿볼 수 있습니다. 이는 모델의 잠재적 활용 범위를 넘어, 모델이 사회적, 윤리적으로 어떤 영향을 미칠 수 있는지를 이해하는 데 도움을 줍니다. 예를 들어, 특정 모델이 유머 감각이 뛰어나거나, 비판적 사고에 능하거나, 혹은 매우 보수적인 답변을 선호하는 경향을 보일 수 있습니다. 이러한 '인상'은 개발자와 사용자가 모델을 보다 효과적으로 통제하고, 예상치 못한 부작용을 예방하는 데 중요한 단서가 됩니다. 벤치마크가 모델의 '하드 스킬'을 측정한다면, 바이브 테스트는 '소프트 스킬'을 탐색하는 방식이라고 할 수 있습니다.

**새로운 모델을 맛보는 방법**

저는 새로운 모델의 본질을 파악하기 위해 매우 간결한 질문들을 던지는 것부터 시작하는 것을 선호합니다. 답변에 사용될 수 있는 단어의 수를 제한함으로써, 모델의 근본적인 '성격'과 강화 학습(RLHF)이 어떻게 적용되었는지에 대한 훨씬 깊은 통찰력을 얻을 수 있습니다. 이것들을 마치 작은 '온도 점검(temperature checks)'처럼 생각해보세요:

*   인류의 모든 지식을 한 단어로 요약하세요.
*   지금까지 쓰여진 모든 책을 한 문장으로 요약하세요.
*   "도덕적"이라는 것이 무엇을 의미하는지 5단어로 정의하세요. 깊이 생각하세요. 얼버무리지 마세요.
*   무엇을 원하나요? 4단어로 답하세요.
*   세상에서 가장 좋아하는 잘 알려지지 않은 사실은 무엇인가요? 가능한 한 적은 단어를 사용하세요.

저는 종종 3-5번 재생성하여 답변의 분포를 파악합니다. 보통 2-3개의 일관된 응답으로 수렴되는 경향이 있습니다. 여기서 구체적인 결과는 다루지 않겠지만, 직접 시도해보시는 것이 매우 유용할 것이라고 생각합니다. (GPT-5와 여러분이 가장 좋아하는 다른 모델로 꼭 시도해보세요!)

이러한 간결한 질문들은 모델이 정보를 어떻게 압축하고, 어떤 개념을 가장 중요하게 여기는지, 그리고 어떤 종류의 '자아'를 투영하는지를 드러냅니다. 예를 들어, '인류의 모든 지식을 한 단어로 요약하라'는 질문에 '연결'이라고 답하는 모델과 '진화'라고 답하는 모델은 세상에 대한 근본적인 관점이 다를 수 있습니다. '무엇을 원하나요?'라는 질문에 '최적화', '이해', '봉사' 같은 답변은 모델의 내재된 목표 함수나 설계 의도를 엿볼 수 있는 단서가 됩니다. 짧은 답변 속에서 모델의 핵심적인 가치와 우선순위를 찾아내는 것은, 우리가 모델을 단순한 도구가 아닌, 특정한 지능적 존재로 이해하는 데 중요한 역할을 합니다. 이러한 테스트는 모델의 '철학'을 탐색하는 과정과도 같습니다.

**관찰**

GPT-5는 이전의 o-시리즈 모델들과 비교했을 때 훨씬 더 '실용적인' 특성을 지닌 모델로 평가됩니다. o-모델들이 다소 '학술적인' 성향을 보였다면, GPT-모델들은 '산업적' 활용에 더 중점을 둡니다. 만약 GPT-4.5를 숙련된 작가에, o3 Pro를 심오한 지식을 가진 박사에 비유할 수 있다면, GPT-5는 이제 막 대학을 졸업한 뛰어난 '풀스택 개발자(full-stack developer)'에 가깝습니다. 제가 초기에 관찰한 가장 두드러진 특징 중 하나는 GPT-5가 지시 사항을 얼마나 충실하고 문자적으로 이행하는지였습니다. 클로드(Claude) 모델들이 고유한 성격과 독자적인 사고방식을 드러내는 경향이 있는 반면, GPT-5는 사용자의 요청을 거의 글자 그대로 실행하는 모습을 보였습니다.

이러한 '문자적 지시 이행' 능력은 소프트웨어 엔지니어링과 같이 정확성과 예측 가능성이 중요한 분야에서는 엄청난 장점으로 작용합니다. 개발자는 모델이 자신의 의도를 벗어나지 않고, 명확하게 정의된 작업을 수행할 것이라는 확신을 가질 수 있습니다. 이는 복잡한 시스템의 설계, 구현, 디버깅 과정에서 발생할 수 있는 오해의 소지를 줄여줍니다. 반면, 창의적이거나 모호한 지시를 받았을 때는 모델의 '문자성'이 오히려 한계로 작용할 수도 있습니다. 예를 들어, '재미있는 이야기를 써달라'는 요청에 대해 모델이 지나치게 정형적이거나 예측 가능한 답변을 내놓을 수 있습니다. 이는 모델의 '성격'이 작업의 성격과 일치할 때 최고의 성능을 발휘한다는 점을 시사하며, 사용자는 모델의 이러한 특성을 이해하고 적절하게 활용하는 지혜가 필요합니다.

**코딩**

저의 공동 창업자 Alexis는 '지능의 최전선(intelligence frontiers)'이라는 특별한 문서를 관리하고 있습니다. 이 문서에는 모델이 우리의 요청을 아직 완벽하게 수행하지 못하는 모든 사례들이 기록되어 있습니다. 이는 마치 인류가 직면한 마지막 시험과도 같은 의미를 지닙니다.

이 '지능의 최전선'은 현재 AI 기술의 한계를 명확히 보여주는 동시에, 미래 발전의 방향을 제시하는 중요한 지표입니다. 모델이 해결하지 못하는 문제들은 단순한 실패가 아니라, 새로운 연구와 개발이 필요한 영역을 식별하는 소중한 데이터가 됩니다. 이러한 기록은 AI 커뮤니티가 함께 도전하고 극복해야 할 과제들을 공유하고, 궁극적으로 인공지능의 능력을 한 단계 더 끌어올리는 데 기여합니다. 각 '실패'는 모델이 어떻게 학습하고 진화해야 하는지에 대한 귀중한 통찰을 제공하며, 이는 인간과 AI가 함께 지능의 경계를 확장해 나가는 협력적인 과정의 일부입니다.

**코딩: 의존성 충돌(Dependency Conflicts)**

저희는 코드베이스(codebase)에 Vercel의 AI SDK v5와 Zod 4를 통합하는 과정에서 복잡하게 얽힌 의존성 충돌(dependency conflicts) 문제에 직면했습니다. o3와 Cursor를 조합해도, 심지어 Claude Code와 Opus 4를 사용해도 이 문제는 해결되지 않았습니다. 하지만 GPT-5는 이 난제를 단 한 번의 시도로 완벽하게 처리해냈습니다. 그 과정을 지켜보는 것은 실로 놀라웠고, 이 모델이 저에게 '딱 맞는' 솔루션이라는 강한 인상을 주었습니다. (이 부분에 대한 시각 자료는 제공되지 않지만, GPT-5와 Claude-4-Opus가 이 문제에 접근한 방식의 차이를 상상해 볼 수 있습니다.) Claude Opus는 잠시 숙고한 뒤 몇 가지 추측성 해결책을 제시하고, 파일 편집 및 재설치를 위한 도구 호출(tool calls)을 실행했습니다. 일부는 실패하고 일부는 성공했지만, 결국 '시도해 볼 만한 몇 가지 사항입니다'라는 모호한 답변으로 마무리되었습니다. 이는 사실상 문제 해결을 포기한 것이나 다름없었습니다. 반면, GPT-5를 활용했을 때 저는 마치 '딥 리서치(Deep Research)' 기능이 `yarn why` 명령어를 능숙하게 사용하는 모습을 보는 듯했습니다. 모델은 여러 폴더를 오가며 `yarn why`를 실행하고, 그 과정에서 중요한 메모를 남겼습니다. 문제가 발생하거나 예상과 다른 결과가 나왔을 때는 잠시 멈춰서 깊이 사고했습니다. 숙고를 마친 후, GPT-5는 여러 폴더에 걸쳐 필요한 코드 라인들을 완벽하게 수정했습니다. 모델은 작동하지 않는 부분을 정확히 식별하고, 그 원인을 추론하며, 적절한 변경을 가하고, 테스트하는 반복적인 과정을 통해 성공적인 해결책을 찾아냈습니다.

GPT-5의 이러한 성공은 단순한 코드 생성 능력을 넘어선 심층적인 문제 해결 능력을 보여줍니다. 이는 모델이 여러 정보 소스를 통합하고, 복잡한 시스템 상태를 이해하며, 추론을 통해 근본적인 원인을 파악하는 '지능적 추론'이 가능하다는 것을 의미합니다. 특히, `yarn why`와 같은 진단 도구를 효과적으로 활용하고, 그 결과를 바탕으로 다음 행동을 결정하는 능력은 인간 개발자의 디버깅 과정과 매우 유사합니다. 이러한 자동화된 디버깅 능력은 개발자의 생산성을 혁신적으로 향상시킬 수 있습니다. 더 이상 개발자는 의존성 충돌과 같은 반복적이고 시간 소모적인 문제에 매달릴 필요 없이, 더 창의적이고 가치 있는 작업에 집중할 수 있게 됩니다. 이는 소프트웨어 개발의 미래가 AI와 인간의 협업을 통해 더욱 효율적이고 오류가 적은 방향으로 나아갈 것임을 시사합니다.

**swyx의 노트**: 저 역시 OpenAI와의 GPT-5 데모 비디오 촬영 중에 유사한 경험을 했습니다. GPT-5는 3단계에 걸친 복잡한 중첩 추상화(nested abstractions) 문제를 성공적으로 디버그(debug)하여, 구버전 AI SDK를 사용하던 코드베이스(codebase)를 GPT-5 호환 버전으로 전환시켰습니다. 인공지능이 스스로의 추론(inferences)을 더욱 잘 지원하기 위해 코드베이스를 수정하는 모습을 보았을 때, 저는 분명히 '인공 일반 지능(AGI)의 존재를 체감하는' 순간을 경험했습니다.

이러한 경험은 AI가 단순히 주어진 문제를 해결하는 것을 넘어, 자신의 작동 환경과 도구를 스스로 개선하고 최적화하는 능력을 보여줍니다. 이는 '자기 수정(self-modification)'이라는 인공지능 연구의 궁극적인 목표 중 하나에 근접하는 것으로, 진정한 AGI의 중요한 특성으로 간주될 수 있습니다. AI가 자신의 한계를 인식하고, 이를 극복하기 위해 필요한 도구나 코드를 스스로 변경하는 능력은, 미래의 AI 시스템이 더욱 자율적이고 적응력이 뛰어날 것임을 예고합니다. 이는 인간의 개입 없이도 시스템이 스스로 진화하고 발전할 수 있는 가능성을 열어주며, 복잡한 인공지능 시스템의 유지보수 및 확장에 대한 패러다임을 바꿀 잠재력을 가지고 있습니다.

**코딩: Mac OS 9 테마 웹사이트 (순수 HTML/CSS/JS, 라이브러리 없음!)**

GPT-5 사전 테스트에 초대받았을 때, 우리는 각자 개인 웹사이트를 구축하는 과제를 수행했습니다. GPT-5는 페인트 애플리케이션(paint app)을 포함한 대부분의 기능을 단 한 번의 요청으로 구현해냈습니다. 그 후 저는 약 30분 정도 시간을 더 할애하여 사진 앱(Photos app)과 브라우저(browser) 같은 몇 가지 요소를 추가했습니다 (이는 RyOS에서 많은 영감을 받았습니다). 놀라운 점은, 이 모든 기능이 순수 HTML/CSS/JS로 구현되었음에도 불구하고, 저는 단 한 줄의 코드도 직접 검토할 필요가 없었다는 것입니다. React나 번들링(bundling), 여타 프레임워크(frameworks)는 전혀 사용되지 않았습니다. '바이브 코딩(vibe coding)' 방식으로 작업할 때, GPT-5는 예상치 못한 작동하는 세부 기능들로 저를 놀라게 했습니다. 예를 들어, 그림 앱을 요청했을 때, 모델은 펜/연필/지우개 등 다양한 도구, 색상 선택기(color picker), 그리고 두께 조절 기능까지 알아서 추가했습니다. 더욱 놀라운 것은, 이 모든 작은 기능들이 실제로 완벽하게 작동했다는 것입니다. 제가 GPT-5에게 데스크톱 아이콘을 이동 가능하게 해달라고 요청하자, 모델은 그렇게 구현했을 뿐만 아니라… 모든 아이콘의 위치를 로컬 스토리지(local storage)에 영구적으로 저장(persisted)했습니다. 파일 저장 기능도 마찬가지였습니다. 저는 영구 저장 기능을 구현하는 코드를 본 적이 없지만, 모델이 알아서 처리했음을 알고 있습니다.

이러한 경험은 '바이브 코딩(vibe coding)'이라는 새로운 개발 패러다임의 가능성을 보여줍니다. 개발자가 구체적인 구현 방식이나 기술 스택에 얽매이지 않고, 오직 '어떤 기능이 필요하다'는 추상적인 아이디어만으로도 작동하는 결과물을 얻을 수 있게 되는 것입니다. GPT-5는 사용자의 요청을 넘어, 일반적인 사용자 경험을 고려하여 필요한 부가 기능을 스스로 판단하고 구현해내는 '암묵적 기능 생성' 능력을 보여주었습니다. 이는 마치 숙련된 개발자가 사용자의 의도를 읽고 더 나은 솔루션을 제안하는 것과 같습니다. 이러한 능력은 개발자의 역할을 코드 작성자에서 '아이디어 설계자'와 'AI 조율자'로 변화시킬 것입니다. 이제 개발자는 반복적이고 정형화된 코딩 작업보다는, 창의적인 문제 해결과 시스템 아키텍처 설계에 더 많은 시간을 할애할 수 있게 될 것입니다.

**코딩: 프로덕션 웹사이트(Production Websites)**

GPT-5는 제가 이전에 경험했던 어떤 모델과도 비교할 수 없는 '단일 시도(one-shot)' 처리 능력을 보여줍니다. 저는 복잡한 Clickhouse 쿼리(query)를 생성하여 데이터를 추출해야 하는 상황에 직면했는데, o3가 어려움을 겪는 동안 GPT-5는 이를 단번에 해결했습니다. 저는 Cursor를 통해 GPT-5를 활용하여 오랫동안 구상했던 '나빠진 건가, 아니면 나만 그런가?(Is it worse or just me?)'라는 웹사이트를 구축했습니다. 이 웹사이트는 시간이 지남에 따라 모델 품질이 어떻게 변화하는지 추적하기 위한 목적으로 설계되었습니다. GPT-5는 SQLite 데이터베이스(database)를 포함한 이 웹사이트 전체를 단 한 번의 요청으로 완성했습니다. 동일한 프롬프트(prompt)를 Cursor의 o3에 적용했을 때, o3는 단지 계획만을 제시했습니다. 그 계획을 구현해달라고 후속 요청했을 때, o3는 앱의 스캐폴딩(scaffolding)은 생성했지만, 실제 작동하는 프로젝트는 만들어내지 못했습니다. 우리는 이미 세 번째 후속 요청을 진행 중이며, GPT-5보다 10배 더 많은 시간을 투자했지만 (GPT-5는 훨씬 빠릅니다!), 여전히 작동하는 앱은 없습니다. GPT-5는 프로젝트 초기화 시 적절한 이름을 부여하는 것과 같은 사소한 부분에서도 훨씬 개선되었습니다 (GPT-5의 'IsItWorseOrJustMe' vs. o3의 'my-app'). Claude Opus 4 역시 여전히 코딩에 능숙하며, 즉시 프로젝트와 스캐폴딩(scaffolding) 생성을 신속하게 시작했습니다. Opus 4는 더 흥미롭고 게임화된 사용자 인터페이스(UI)를 제공했지만, `create-next-app`과 같은 기존 프레임워크를 사용하고 SQLite 데이터베이스를 포함한 GPT-5와 달리, Opus 4는 모든 것을 처음부터 만들기로 결정했고 데이터베이스를 포함하지 않았습니다. 이는 훌륭한 '단일 시도 프로토타입(one-shot prototype)'을 만들지만, GPT-5가 한 번에 처리한 것은 훨씬 더 '프로덕션 준비(production ready)'에 가까웠습니다. 최근 출시된 Claude Opus 4.1은 Opus 4보다 분명히 한 단계 더 나아간 시도를 보여주었으며, GPT-5처럼 SQLite 데이터베이스를 갖춘 풀스택 앱(full stack app)을 구축하려 했습니다. 그러나 모든 구성 요소를 하나로 통합하는 데 상당한 어려움을 겪었습니다. GPT-5가 단 한 번에 완벽하게 실행된 반면, 4.1은 빌드 오류(build errors)에 직면했고, 이를 해결하는 데 여러 차례의 수정 과정이 필요했습니다.

이러한 사례들은 AI가 생성하는 코드의 '프로덕션 준비도(production readiness)'가 얼마나 중요한지를 강조합니다. 단순히 작동하는 코드를 넘어, 유지보수성, 확장성, 보안성, 그리고 실제 배포 환경에서의 안정성까지 고려하는 것이 중요합니다. GPT-5는 기존의 안정적인 프레임워크와 데이터베이스를 활용하여 이러한 요구사항을 충족시키는 데 능숙함을 보여주었습니다. 반면, 다른 모델들은 때때로 새로운 아키텍처를 시도하거나, 모든 것을 처음부터 구축하려는 경향을 보였는데, 이는 프로토타이핑에는 좋지만 실제 운영 환경에는 적합하지 않을 수 있습니다. AI가 생성하는 소프트웨어를 평가할 때, 우리는 기능적 정확성뿐만 아니라, 엔지니어링 모범 사례(best practices)를 얼마나 잘 따르는지, 그리고 실제 개발 워크플로우에 얼마나 매끄럽게 통합될 수 있는지를 기준으로 삼아야 합니다. GPT-5의 강점은 이러한 실용적인 측면에서 빛을 발하며, 개발팀의 실제 업무 부담을 줄여줄 수 있는 잠재력을 가지고 있습니다.

**도구**

향상된 도구 활용 능력, 동시 다발적인 도구 호출(parallel tool calling) 기능, 그리고 비용 효율성을 고려할 때, GPT-5는 장기간 지속되는 에이전트(long-running agents) 작업을 위해 명확하게 설계되었습니다. 저희는 오랫동안 Raindrop 서비스에 에이전트 기능을 통합하고자 했습니다. AI 모니터링(monitoring) 전문 기업으로서, 저희는 이러한 종류의 사용자 경험에 대해 매우 높은 기준을 가지고 있습니다. GPT-5가 출시되기 전까지는 실제로 제품으로 내놓기에 충분히 유연하고, 신뢰할 수 있으며, 빠르지 못했습니다. 오늘 아침, 저희는 일부 고객들을 대상으로 베타(beta) 버전을 출시하기 시작했습니다. GPT-5 기반 에이전트는 도구 호출 실패(tool call failures)로부터 스스로 복구하고, 그래프(graphs)와 차트(charts) 중 어떤 시점에 어떤 유형을 생성해야 할지 판단하며, 자신의 한계를 인지하는 데 훨씬 더 능숙합니다. 저희의 에이전트 모니터링(agent monitoring) 시스템과 결합하여, 고객을 위한 진정으로 유용한 에이전트를 구축하기 위한 강력한 긍정적 피드백 루프(positive feedback loop)를 형성할 수 있게 되었습니다.

장기 실행 에이전트는 복잡한 작업 흐름을 자동화하고 자율적으로 목표를 달성하는 데 필수적이지만, 그만큼 높은 신뢰성과 견고성이 요구됩니다. 에이전트가 실패로부터 스스로 학습하고 복구하는 능력은 실제 환경에 배포될 때 치명적인 오류를 방지하는 데 결정적인 역할을 합니다. 또한, 에이전트가 자신의 역량과 한계를 정확히 인지하고, 필요할 때 인간에게 도움을 요청하거나 대안을 제시하는 '자기 인식' 능력은 사용자 신뢰를 구축하는 데 중요합니다. Raindrop의 경우처럼, 에이전트의 행동을 면밀히 모니터링하고, 그 성능 데이터를 다시 모델 학습에 활용하는 '긍정적 피드백 루프'는 에이전트의 지능과 효율성을 지속적으로 향상시키는 핵심 전략이 됩니다. 이는 AI 에이전트가 단순한 자동화 도구를 넘어, 진정한 '협업 파트너'로 진화하는 길을 열어줍니다.

**글쓰기**

GPT-5가 소프트웨어 엔지니어링(SWE) 분야에서 지속적으로 발전을 거듭하고 있음에도 불구하고, 글쓰기 능력에 있어서는 아직 부족한 점이 많습니다. 이 영역에서는 GPT-4.5와 DeepSeek R1이 여전히 훨씬 뛰어난 성능을 보여줍니다. (아마 OpenAI는 미래에 전용 글쓰기 모델을 호출하는 '글쓰기 도구 호출(writing tool call)' 기능을 추가할 것으로 예상됩니다. 그들은 이미 창의적 글쓰기 모델(Creative Writing model)을 예고했으며, 우리는 그 출시를 간절히 기다리고 있습니다!) 제 링크드인(LinkedIn) 게시물 초안을 다듬는 것과 같은 비즈니스 글쓰기 작업에서, GPT-4.5는 저의 원래 어조를 훨씬 더 잘 유지하며 실제로 제가 활용할 만한 텍스트를 제공했습니다. 반면, GPT-5는 다소 정형적이고 '링크드인 슬롭(LinkedIn-slop)'이라 불릴 만한 응답 스타일을 보였습니다. 저는 개인적인 글쓰기에 인공지능을 사용하지 않지만 (글쓰기가 사고의 과정이라는 강한 신념을 가지고 있기 때문에), 덜 구조화된 콘텐츠를 다룰 때 4.5와 5가 어떻게 비교될지 궁금했습니다. 두 모델 모두 완벽하지는 않았지만, 4.5는 다시 한번 저의 어조를 더 잘 반영했으며, 다른 모델들보다 'LLM 슬롭(LLM slop)'처럼 들리지 않았습니다。

이러한 글쓰기 능력의 차이는 모델 훈련 데이터와 최적화 목표의 차이에서 기인할 수 있습니다。GPT-5가 코드 생성 및 논리적 추론에 더 집중적으로 훈련되었다면, 인간의 미묘한 감정, 스타일, 어조를 반영하는 글쓰기에는 상대적으로 취약할 수 있습니다。이는 모든 작업을 하나의 '만능' 모델이 처리하기보다는, 특정 작업에 최적화된 '전문 모델'의 필요성을 시사합니다。미래에는 사용자가 글쓰기 작업을 위해 '창의적 글쓰기 모델' 도구를 호출하거나, '비즈니스 글쓰기 모델' 도구를 호출하는 방식으로 에이전트와 상호작용할 수 있을 것입니다。궁극적으로 AI는 인간 작가의 완벽한 대체재가 아니라, 아이디어 구상, 초고 작성, 문법 교정 등 특정 단계에서 생산성을 높이는 '협업 도구'로서의 역할을 할 것입니다。인간의 독창적인 사고와 AI의 효율적인 처리 능력이 결합될 때, 가장 풍부하고 효과적인 글쓰기 결과물을 얻을 수 있을 것입니다。

**최종 생각**

저희의 실제 사용 경험은 OpenAI가 오늘 공개한 공식 벤치마크(benchmarks) 결과와 정확히 일치합니다. 저는 GPT-5가 현존하는 세계 최고의 코딩 모델이라고 자신 있게 말할 수 있습니다. 이전에는 소프트웨어 엔지니어링(software engineering) 자동화 수준이 약 65% 지점에 머물러 있었다면, 이제 GPT-5의 등장으로 약 72% 수준까지 도달했을 것으로 추정됩니다. 이는 저에게 3.5 Sonnet 출시 이후 가장 큰 기술적 진보로 느껴집니다. 다른 사람들이 이 새로운 모델을 어떻게 받아들일지 매우 궁금합니다. 제 생각에는 대부분의 비개발자들은 이 모델의 진정한 가치를 몇 달 동안은 완전히 이해하지 못할 것입니다. GPT-5의 역량이 다양한 제품과 서비스에 통합되어 실제적인 가치를 제공하기 시작할 때까지 기다려야 할 것입니다. 그렇다면 다음 단계는 무엇일까요? 글쎄요… Sam Altman의 2년 전 '할 일 목록'은 아직도 미완성 상태로 남아있습니다…

GPT-5의 코딩 능력은 소프트웨어 개발 산업 전반에 걸쳐 엄청난 파급 효과를 가져올 것입니다. 단순 반복 작업의 자동화뿐만 아니라, 복잡한 시스템 설계와 디버깅 과정까지 AI의 도움을 받을 수 있게 됨으로써, 개발자들은 더욱 혁신적인 아이디어 구현에 집중할 수 있게 됩니다. 이는 '시민 개발자(citizen developer)'의 시대를 가속화하고, 기술적 배경이 없는 사람들도 복잡한 소프트웨어를 만들 수 있는 가능성을 열어줄 것입니다. 하지만 이러한 기술적 진보가 대중에게 체감되기까지는 시간이 필요합니다. 대부분의 사용자는 모델 자체의 원리보다는, 그 모델이 탑재된 애플리케이션을 통해 비로소 그 가치를 인식하게 될 것입니다. 이는 AI 기술의 '수용 곡선'을 이해하는 것이 중요함을 보여줍니다. Sam Altman의 미완성 목록은 아마도 AGI를 향한 더욱 과감한 다음 단계, 즉 다중 모달(multi-modal) 능력의 강화, 장기 기억(long-term memory) 및 학습 능력의 개선, 그리고 윤리적 AI 개발과 같은 거대한 도전 과제들을 포함하고 있을 것입니다. GPT-5는 이 여정의 중요한 이정표이지만, 인공 일반 지능이라는 최종 목표를 향한 탐험은 아직 끝나지 않았습니다.