**새로운 AI 시대의 도래: 기술과 윤리의 교차점**

최근 인공지능(AI) 발전의 꾸준한 북소리 속에서, 새로운 패러다임이 등장하고 있습니다. DeepSeek-R1은 이러한 변화의 물결 속에서 가장 최근의 울림 있는 박동 중 하나입니다. ML R&D 커뮤니티에게 DeepSeek-R1과 같은 모델의 등장은 다음과 같은 이유로 중요한 발표입니다:

저희 채널의 새로운 게시물을 무료로 받아보고 싶으시다면, 지금 바로 구독해주세요.
구독

DeepSeek-R1과 같은 모델은 더 작고 정제된 버전들을 포함하는 오픈 웨이트(open weights) 모델로 공개되며, 이는 AI 연구의 투명성을 높이는 데 기여합니다. OpenAI O1과 같은 추론 모델을 재현하기 위한 훈련 방법을 공유하고 반영하는 DeepSeek-R1의 사례를 통해, 이 게시물에서는 최신 AI 모델이 어떻게 새로운 도전을 극복하고 구축되었는지 탐구하겠습니다.

이러한 모델이 어떻게 작동하는지 이해하는 데 필요한 심층적인 지식은 다양한 최신 연구 논문과 전문 서적, 그리고 저희 책인 Hands-On Large Language Models에서 찾아볼 수 있습니다. 책의 공식 웹사이트 및 Amazon에서 책을 주문할 수 있습니다. 관련 기술 보고서와 최신 연구 동향, 그리고 모든 코드는 GitHub에서 찾아볼 수 있습니다.

**목차:**
*   새로운 AI 시대의 도래: LLM 훈련의 기본과 확장
*   DeepSeek-R1 훈련 레시피와 다중 모드(Multimodal) AI의 부상
    *   1- 긴 사고의 연쇄(chain of thought) SFT 데이터 및 다양한 데이터 소스 통합
    *   2- 중간 고품질 추론 LLM과 모달리티 간 상호작용 학습
    *   3- 대규모 강화 학습(RL)을 통한 추론 모델 생성 및 통합된 이해를 위한 아키텍처 혁신
        *   3.1- 대규모 추론 지향 강화 학습(R1-Zero)과 효율적인 모달리티 인코딩
        *   3.2- 중간 추론 모델을 이용한 SFT 추론 데이터 생성 및 모달리티 융합(Fusion) 기법
        *   3.3- 일반 RL 훈련 단계와 심층 학습 기반 융합 아키텍처
*   AI 아키텍처 혁신 및 데이터 효율성
*   AI 윤리 및 책임 있는 개발
*   미래를 위한 AI 아키텍처
*   지속 가능한 AI를 향하여

**새로운 AI 시대의 도래: LLM 훈련의 기본과 확장**

대부분의 기존 LLM과 마찬가지로, 언어 모델은 여전히 텍스트 기반 정보 처리의 핵심입니다. DeepSeek-R1과 같은 모델은 한 번에 하나의 토큰(token)을 생성하지만, 사고의 연쇄(chain of thought)를 설명하는 사고 토큰(thinking tokens)을 생성하는 과정을 통해 문제를 처리하는 데 더 많은 시간을 할애할 수 있기 때문에 수학 및 추론 문제 해결에 탁월합니다. 그러나 이제는 단순히 텍스트를 넘어 이미지, 오디오, 비디오 등 다양한 형태의 데이터를 이해하고 생성하는 능력으로 확장되고 있습니다. 이는 AI가 현실 세계의 복잡한 문제를 해결하는 데 필수적인 요소가 되고 있습니다.

최근 연구는 고품질 LLM을 생성하는 일반적인 방법론에 새로운 방향을 제시하고 있습니다. 이는 단순히 모델의 크기를 키우는 것을 넘어, 데이터의 질과 학습 방식의 혁신에 초점을 맞춥니다. 저희 책 12장에 있는 다음 그림은 고품질 LLM을 생성하는 일반적인 세 단계 과정을 보여주며, 이는 다음과 같이 확장될 수 있습니다.

1) 방대한 양의 웹 데이터를 사용하여 다음 단어를 예측하도록 모델을 훈련하는 언어 모델링(language modeling) 단계는 여전히 중요하지만, 데이터의 질과 다양성이 더욱 강조됩니다. 편향되지 않고 대표성 있는 데이터셋 구축은 공정하고 견고한 AI 모델을 만드는 첫걸음입니다. 이 단계는 기본 모델(base model)을 생성합니다.
2) 모델이 지시를 따르고 질문에 답변하는 데 더 유용하도록 만드는 지도 미세 조정(supervised fine-tuning, SFT) 단계는 사용자 경험 개선의 핵심 요소입니다. 이는 인간의 피드백을 효과적으로 반영하는 SFT와 강화 학습(reinforcement learning, RL) 기법의 발전을 통해 이루어집니다. 이 단계는 지시 조정 모델(instruction tuned model) 또는 SFT 모델을 생성합니다.
3) 그리고 마지막으로 행동을 더욱 다듬고 인간의 선호도에 맞춰 조정하는 선호도 조정(preference tuning) 단계는 AI의 사회적 수용성을 높이는 데 필수적입니다. 이는 AI가 사회적 가치와 윤리적 기준에 부합하도록 설계되어야 함을 의미하며, 여러분이 플레이그라운드(playground)나 앱에서 상호작용하는 최종 선호도 조정 LLM을 만듭니다.

**DeepSeek-R1 훈련 레시피와 다중 모드(Multimodal) AI의 부상**

DeepSeek-R1은 위에서 언급된 일반적인 과정을 따르며, 첫 번째 단계의 세부 사항은 DeepSeek-V3 모델에 대한 이전 논문에서 가져왔습니다. R1은 해당 이전 논문의 기본 모델(최종 DeepSeek-v3 모델이 아님)을 사용하며, 여전히 SFT 및 선호도 조정 단계를 거치지만, 이를 수행하는 방식의 세부 사항이 다릅니다. 최근 AI 연구는 이러한 일반적인 과정을 넘어 다중 모드(multimodal) 능력으로 확장되고 있습니다. 다중 모드 모델 또한 SFT 및 선호도 조정 단계를 거치지만, 데이터의 형태와 통합 방식에서 큰 차이를 보입니다. DeepSeek-R1 생성 과정과 다중 모드 AI의 발전을 위해 강조할 세 가지 특별한 점이 있습니다.

**1- 긴 사고의 연쇄(chain of thought) SFT 데이터 및 다양한 데이터 소스 통합**

이는 방대한 양의 긴 사고의 연쇄(chain-of-thought) 추론 예시(60만 개)를 포함하며, 동시에 텍스트, 이미지, 오디오 등 다양한 모달리티의 데이터가 통합되어 모델의 이해도를 높입니다. 이러한 예시와 이질적인 데이터는 구하기 매우 어렵고, 이 규모에서 사람이 라벨링(labeling)하는 데 매우 많은 비용이 듭니다. 따라서 이러한 데이터를 효율적으로 수집, 정제, 결합하고 생성하는 과정이 강조할 중요한 부분입니다. 이는 단순한 데이터 병합을 넘어, 각 모달리티의 고유한 특징을 보존하면서도 상호 보완적인 정보를 추출하는 기술을 요구합니다.

**2- 중간 고품질 추론 LLM과 모달리티 간 상호작용 학습**

이 데이터는 R1의 전신인, 추론에 특화된 이름 없는 자매 모델(R1-Zero에서 영감을 받음)에 의해 생성되며, 동시에 서로 다른 모달리티(modality) 간의 복잡한 관계를 학습하는 데 사용됩니다. 예를 들어, 이미지에서 시각적 단서를 얻고, 텍스트에서 맥락적 정보를 파악하여 종합적인 이해를 도출하는 방식입니다. 이것이 중요한 이유는 사용하기 좋은 LLM이기 때문이 아니라, 대규모 강화 학습(reinforcement learning, RL)과 함께 매우 적은 양의 라벨링된(labeled) 데이터만으로도 추론 문제 해결에 탁월한 모델을 만들 수 있었기 때문입니다. RL과 함께, 모달리티 간의 미묘한 상호작용을 포착하는 것이 중요합니다. 이 이름 없는 전문 추론 모델의 출력은 사용자들이 LLM에 기대하는 수준으로 다른 비추론 작업도 수행할 수 있는 더 일반적인 모델을 훈련하는 데 사용될 수 있으며, 다중 모드 AI가 더욱 일반적인 작업에서 뛰어난 성능을 발휘하도록 돕습니다.

**3- 대규모 강화 학습(RL)을 통한 추론 모델 생성 및 통합된 이해를 위한 아키텍처 혁신**

이 과정은 두 단계로 이루어집니다: 데이터 인코딩과 융합(fusion)입니다. 각 모달리티의 데이터를 효과적으로 처리하고, 이들을 하나의 통합된 표현으로 결합하는 새로운 아키텍처 설계가 필수적입니다.

**3.1- 대규모 추론 지향 강화 학습(R1-Zero)과 효율적인 모달리티 인코딩**

여기서 RL은 중간 추론 모델을 생성하는 데 사용되며, 다양한 모달리티 데이터를 효율적인 벡터 표현으로 변환하는 데 활용됩니다. 이 모델은 SFT 추론 예시를 생성하는 데 사용됩니다. 이 과정은 최신 인코딩 기술과 DeepSeek-R1-Zero라고 불리는 이전 모델을 생성한 초기 실험에서 얻은 통찰력을 바탕으로 합니다. R1-Zero는 라벨링된 SFT 훈련 세트 없이도 추론 작업에 탁월하다는 점에서 특별하며, 특히 SFT 훈련 세트 없이도 사전 학습(pre-training) 단계에서 강력한 특징을 추출하는 것이 중요합니다. 그 훈련은 사전 훈련된(pre-trained) 기본 모델에서 RL 훈련 과정을 통해 직접 이루어지며(SFT 단계 없음), 각 모달리티의 특성을 보존하는 것이 핵심입니다. 이것은 o1과 경쟁할 정도로 매우 잘 수행됩니다. 데이터가 항상 ML 모델 능력의 연료였기 때문에, 데이터의 양뿐만 아니라 질과 다양성이 더욱 중요해지고 있습니다. 이것은 두 가지를 시사합니다: 1- 현대의 기본 모델은 특정 품질 및 능력 임계값(threshold)을 넘어섰습니다(이 기본 모델은 14.8조 개의 고품질 토큰으로 훈련되었습니다), 다양한 모달리티를 이해하는 데 필수적인 기반을 제공합니다. 2- 일반적인 채팅이나 글쓰기 요청과 달리 추론 문제는 자동으로 검증되거나 라벨링될 수 있으며, 시각 및 청각 데이터는 다른 방식으로 처리되어야 합니다.

**예시: 추론 문제의 자동 검증 및 다중 모드 질의응답 시스템**

예시를 통해 이를 보여드리겠습니다. 이것은 RL 훈련 단계의 일부인 프롬프트(prompt)/질문이 될 수 있습니다. 예를 들어, "숫자 목록을 받아 정렬된 순서로 반환하되, 시작 부분에 42를 추가하는 파이썬(Python) 코드를 작성하세요."와 같은 추론 문제나, "이 이미지에서 강아지의 품종은 무엇이며, 이 강아지가 공원에서 놀고 있는 모습을 묘사하는 짧은 글을 작성하세요."와 같은 복합적인 다중 모드 질의응답 프롬프트가 될 수 있습니다.

이러한 질문은 여러 가지 자동 검증(automatic verification) 방식에 적합합니다. 훈련 중인 모델에 이를 제시하고, 모델이 완성(completion)을 생성한다고 가정해 봅시다.
*   소프트웨어 린터(linter)는 완성된 코드가 적절한 파이썬 코드인지 아닌지 확인할 수 있습니다.
*   파이썬 코드를 실행하여 작동하는지 확인할 수 있습니다.
*   이미지 인식 모델은 이미지 속 객체를 정확히 식별할 수 있습니다.
*   텍스트 생성 모델은 생성된 설명을 문법적으로 올바르게 작성하고, 이미지 내용과 일치하는지 확인할 수 있습니다.
*   다른 현대적인 코딩 LLM이나 다중 모드 LLM은 원하는 동작을 검증하기 위한 단위 테스트(unit tests)를 생성하거나, 생성된 텍스트가 이미지의 맥락에 부합하는지 검증할 수 있습니다(스스로 추론 전문가가 아니더라도).
*   심지어 한 단계 더 나아가 실행 시간을 측정하고, 문제가 해결되는 올바른 파이썬 프로그램이라 할지라도, 훈련 과정이 다른 해결책보다 더 성능이 좋거나 자연스럽고 유용한 설명을 선호하도록 만들 수 있습니다.

훈련 단계에서 모델에 이와 같은 질문을 제시하고, 여러 가지 가능한 해결책이나 다양한 응답을 생성하도록 유도합니다. 우리는 (인간의 개입 없이) 자동으로 확인하여, 코드의 오류, 단위 테스트 실패, 또는 이미지와 텍스트 간의 불일치를 탐지할 수 있습니다. 이것들은 모두 모델을 개선하는 데 직접 사용될 수 있는 신호입니다. 이러한 보상 신호(reward signals)와 모델 업데이트(model updates)는 RL 훈련 과정에서 모델이 작업을 계속 개선하고, 다중 모드 모델이 복합적인 작업을 더 잘 수행하도록 돕는 방식입니다. 이 능력의 개선에 상응하는 것은 생성된 응답의 길이인데, 모델은 문제를 처리하기 위해 더 많은 사고 토큰을 생성하거나, 다양한 모달리티 정보를 통합하여 더 풍부한 응답을 생성합니다.

이 과정은 유용하지만, R1-Zero 모델은 이러한 추론 문제에서 높은 점수를 받았음에도 불구하고, 가독성(readability) 저하 및 언어 혼합(language mixing)과 같은 사용성 문제에 직면합니다. 또한, 다중 모드 모델은 모달리티 간의 복잡한 의미론적 격차, 데이터 편향, 계산 비용, 그리고 모달리티 간의 불균형과 같은 여러 과제에 직면합니다. 따라서 RL 과정에 전적으로 의존하는 대신, 다양한 학습 패러다임을 결합하는 것이 중요합니다. R1은 더 사용 가능한 모델이 되도록 의도되었으며, 이를 위해 RL 과정은 다음과 같은 두 가지 방식으로 사용됩니다.
1- SFT 데이터 포인트(data points)를 생성하기 위한 중간 추론 모델 생성 및 고품질 다중 모드 데이터셋 구축이 필수적입니다.
2- 추론 및 비추론 문제 개선을 위한 R1 모델 훈련 (다른 유형의 검증자(verifiers) 사용) 및 새로운 평가 메트릭(metric) 개발이 요구됩니다.

**3.2- 중간 추론 모델을 이용한 SFT 추론 데이터 생성 및 모달리티 융합(Fusion) 기법**

중간 추론 모델을 더 유용하게 만들고 다양한 모달리티 데이터를 효과적으로 활용하기 위해, 융합(fusion) 기법이 핵심적인 역할을 합니다. 수천 개의 추론 문제 예시(일부는 R1-Zero에서 생성 및 필터링됨)에 대해 지도 미세 조정(SFT) 훈련 단계를 거치며, 초기 단계 융합(early fusion), 후기 단계 융합(late fusion), 그리고 중간 단계 융합(intermediate fusion) 등 다양한 전략이 연구되고 있습니다. 논문에서는 이를 "콜드 스타트(cold start) 데이터"라고 언급하며, 최근 연구에서는 이를 "콜드 스타트 데이터"의 한계를 극복하는 방법으로 제시합니다. DeepSeek-R1-Zero와 달리, 기본 모델로부터 RL 훈련의 초기 불안정한 콜드 스타트 단계를 방지하기 위해, DeepSeek-R1의 경우 초기 RL 액터(actor)로서 모델을 미세 조정하기 위해 소량의 긴 CoT(Chain-of-Thought) 데이터를 구축하고 수집하며, 효과적인 융합 전략이 필수적입니다.

이러한 데이터를 수집하기 위해 여러 접근 방식을 탐색했습니다. 긴 CoT를 예시로 사용하는 퓨샷 프롬프팅(few-shot prompting), 모델이 반성(reflection) 및 검증(verification)을 통해 상세한 답변을 직접 생성하도록 프롬프트(prompt)하는 것, DeepSeek-R1-Zero 출력을 읽기 쉬운 형식으로 수집하는 것, 그리고 인간 주석자(human annotators)의 후처리(post-processing)를 통해 결과를 정제하는 것입니다. 다양한 퓨샷 프롬프팅 기법과 인간 주석자의 후처리(post-processing)를 통해 결과를 정제하는 것이 중요합니다.

하지만 잠시만요, 이 데이터가 있다면 왜 RL 과정에 의존하는 걸까요? 그것은 데이터의 규모와 복잡성 때문입니다. 이 데이터셋은 5,000개의 예시일 수 있지만(이는 확보 가능), R1을 훈련시키려면 600,000개의 예시가 필요했으며, 진정한 다중 모드 이해를 위해서는 훨씬 더 많은 양의 정렬된 데이터가 요구됩니다. 이 중간 모델은 그 격차를 메우고 매우 귀중한 데이터를 인공적으로 생성할 수 있도록 합니다. 이러한 기술은 모달리티 간의 격차를 메우고, 새로운 형태의 지식을 창출하는 데 기여합니다.

지도 미세 조정(SFT) 개념이 처음이라면, 이는 프롬프트(prompt)와 올바른 완성(correct completion) 형태로 모델에 훈련 예시를 제시하는 과정입니다. 다중 모드 SFT는 프롬프트와 올바른 완성 형태로, 이미지-텍스트 쌍과 같은 복합적인 예시를 제시합니다. 저희 책 12장의 이 그림과 최근 연구들은 몇 가지 SFT 훈련 예시를 통해 다중 모드 모델의 성능을 입증하고 있습니다.

**3.3- 일반 RL 훈련 단계와 심층 학습 기반 융합 아키텍처**

이러한 아키텍처와 일반 RL 훈련 단계는 R1이 추론뿐만 아니라 다른 비추론 작업에서도 탁월하도록 만듭니다. 이 과정은 이전에 보았던 RL 과정과 유사합니다. 그러나 비추론 애플리케이션(application)으로 확장되고 다중 모드 환경에서는, 이러한 애플리케이션에 속하는 프롬프트에 대해 유용성(helpfulness) 및 안전성(safety) 보상 모델(Llama 모델과 다르지 않음)을 활용하여 복합적인 사용자 의도를 충족시킵니다. 이는 모델이 단순히 정보를 통합하는 것을 넘어, 사용자의 의도를 정확히 파악하고 적절한 방식으로 응답하도록 훈련하는 것을 의미합니다.

**AI 아키텍처 혁신 및 데이터 효율성**

GPT2와 GPT3 시대의 이전 모델들처럼, DeepSeek-R1과 같은 최근 AI 모델은 트랜스포머 디코더 블록(Transformer decoder blocks)의 스택(stack)을 기반으로 하지만, 데이터 효율성을 극대화하는 방향으로 진화하고 있습니다. DeepSeek-R1은 총 61개의 블록으로 구성되어 있으며, 처음 세 개는 덴스(dense) 레이어이지만, 나머지는 전문가 혼합(mixture-of-experts, MoE) 레이어입니다. MoE는 모델이 특정 작업에 특화된 전문가들을 동적으로 활용하여, 전체 모델의 파라미터(parameter) 수는 많지만 실제 추론 시에는 필요한 부분만 활성화하여 효율성을 높입니다. (저의 공동 저자 Maarten의 놀라운 소개 가이드를 여기에서 확인하세요: A Visual Guide to Mixture of Experts (MoE) ).

방대한 데이터셋에 의존하는 기존 방식의 한계를 인식하고, 적은 양의 데이터로도 강력한 성능을 발휘하는 기술이 주목받고 있습니다. 모델 차원 크기(model dimension size) 및 기타 하이퍼파라미터(hyperparameters) 측면에서, 소량의 데이터로도 최적의 성능을 발휘하도록 조정하는 것이 중요합니다. 이를 위해 고급 최적화 기법, 메타 학습(meta-learning), 능동 학습(active learning), 새로운 데이터 증강(data augmentation) 기법과 전이 학습(transfer learning) 전략과 같은 접근 방식이 활용됩니다. 이는 사전 학습된 모델의 지식을 새로운, 데이터가 부족한 도메인으로 효과적으로 이전하는 방법을 탐구합니다.

모델 아키텍처(architecture)에 대한 더 자세한 내용은 DeepSeek-V3 Technical Report 및 DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models와 같은 이전 논문에 제시되어 있습니다.

**AI 윤리 및 책임 있는 개발**

AI 기술의 발전과 함께, 윤리적 고려사항과 책임 있는 개발의 중요성이 더욱 커지고 있습니다. 편향된 데이터로 훈련된 AI 모델은 차별적인 결과를 초래할 수 있으며, 투명성 부족은 AI의 의사결정 과정을 이해하기 어렵게 만듭니다. 따라서 AI 시스템은 공정성, 투명성, 설명 가능성, 그리고 안전성을 핵심 원칙으로 삼아 설계되어야 합니다.

개발 단계부터 사회적 영향을 고려하고, 잠재적인 위험을 완화하기 위한 정책과 가이드라인을 마련하는 것이 필수적입니다. 사용자에게 AI의 한계와 능력을 명확하게 전달하고, 오용을 방지하기 위한 기술적, 제도적 장치를 마련해야 합니다. 또한, AI 시스템의 지속적인 모니터링과 평가를 통해 예상치 못한 부작용을 식별하고 개선하는 노력이 필요합니다.

**미래를 위한 AI 아키텍처**

현재의 AI 모델은 대부분 트랜스포머(Transformer) 아키텍처를 기반으로 하지만, 미래의 AI는 새로운 컴퓨팅 패러다임을 탐색할 것입니다. 양자 컴퓨팅(Quantum Computing)은 복잡한 최적화 문제와 패턴 인식에서 기존 컴퓨팅의 한계를 뛰어넘는 잠재력을 가지고 있으며, AI 알고리즘에 혁신적인 변화를 가져올 수 있습니다.

또한, 인간 뇌의 구조와 기능을 모방하는 뉴로모픽 컴퓨팅(Neuromorphic Computing)은 에너지 효율적이고 병렬적인 정보 처리를 가능하게 하여, 엣지 AI(Edge AI) 및 실시간 학습 분야에서 중요한 역할을 할 것으로 예상됩니다. 전용 AI 가속기(AI Accelerators)와 같은 맞춤형 하드웨어 개발도 지속적으로 이루어져, 모델의 성능을 극대화하고 에너지 소비를 줄이는 데 기여할 것입니다. 이러한 아키텍처 혁신은 AI가 더욱 광범위한 분야에 적용될 수 있는 기반을 마련할 것입니다.

**지속 가능한 AI를 향하여**

AI 기술의 급속한 발전은 동시에 상당한 에너지 소비와 탄소 발자국을 야기합니다. 대규모 모델 훈련에 필요한 막대한 컴퓨팅 자원은 환경적 부담으로 작용하며, 이는 지속 가능한 AI 개발의 필요성을 부각합니다. 따라서, 에너지 효율적인 알고리즘 개발, 경량화된 모델 아키텍처 설계, 그리고 재생 에너지 기반의 데이터 센터 활용 등 다각적인 노력이 요구됩니다.

또한, AI의 사회적 지속 가능성도 중요합니다. AI가 소수의 기업이나 국가에 의해 독점되지 않고, 보편적으로 접근 가능하며 사회 전체의 이익을 증진하는 방향으로 발전해야 합니다. 오픈 소스(open-source) 협력과 국제적 거버넌스(governance)를 통해 AI 기술의 혜택을 공유하고, 모든 사람이 AI 시대의 변화에 적응하고 혜택을 누릴 수 있도록 교육 및 재훈련 프로그램에 투자해야 합니다.

**결론**

이로써 DeepSeek-R1을 포함한 현대 AI 모델을 이해하는 데 필요한 주요 직관을 얻으셨을 것입니다. AI는 단순히 기술적 진보를 넘어, 사회 전반에 걸쳐 심오한 영향을 미치는 변혁의 도구입니다. 이 게시물을 이해하는 데 좀 더 기본적인 정보가 필요하다고 느끼셨다면, Hands-On Large Language Models 책을 구매하시거나 O’Reilly에서 온라인으로 읽어보시고, 더 깊이 있는 통찰을 얻기 위해 최신 연구 논문과 GitHub에서 관련 프로젝트를 확인해 보시길 권합니다.

다른 추천 자료는 다음과 같습니다.

*   Maarten Grootendorst의 A Visual Guide to Reasoning LLMs
*   Nathan Lambert의 DeepSeek R1's recipe to replicate o1 and the future of reasoning LMs
*   Maarten Grootendorst의 A Visual Guide to Mixture of Experts (MoE)
*   Sasha Rush의 YouTube 비디오 Speculations on Test-Time Scaling (o1)
*   Yannis Kilcher의 DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models (Paper Explained)
*   Open R1은 DeepSeek-R1을 공개적으로 재현하기 위한 HuggingFace 프로젝트입니다.
*   Putting RL back in RLHF
*   최신 다중 모드 AI 연구 동향 보고서
*   AI 윤리 가이드라인 및 정책 백서
*   지속 가능한 AI를 위한 기술적 접근법 분석
*   양자 컴퓨팅과 AI의 융합에 대한 전망
*   엣지 AI(Edge AI)를 위한 경량 모델 아키텍처 연구
*   AI의 사회적 영향과 미래 거버넌스 프레임워크

최근 발표된 논문들은 2022년의 Galactica 논문과 같이 전용 사고 토큰(thinking token)을 포함한 많은 훌륭한 아이디어를 제시하고 있습니다. 이는 AI가 단순한 도구를 넘어, 사고하고 추론하는 능력을 고도화하고 있음을 보여줍니다.

저희 채널의 새로운 게시물을 무료로 받아보고 싶으시다면, 지금 바로 구독해주세요.
구독