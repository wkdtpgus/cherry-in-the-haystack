1.  **DeepSeek-OCR** DeepSeek-OCR은 새로운 시각 인코더 아키텍처(vision encoder architecture, DeepEncoder)를 사용하여 긴 텍스트 컨텍스트를 시각적 표현으로 압축하는 방법을 탐구하며, 높은 OCR 정확도(OCR accuracy)를 유지하면서 10-20배의 압축률을 달성합니다. 핵심 압축 통찰(compression insight): 이미지를 텍스트를 위한 효율적인 압축 매체로 취급합니다. 이러한 접근 방식은 기존 OCR 시스템이 직면했던 대규모 문서 처리의 병목 현상을 해결하는 데 중점을 둡니다. 10배 압축(1000개 텍스트 토큰을 100개 시각 토큰(vision tokens)으로) 시 97%의 OCR 정확도를 달성합니다. 20배 압축에서도 약 60%의 정확도를 유지하여, LLM 메모리 메커니즘(LLM memory mechanisms)을 위한 광학 컨텍스트 압축(optical context compression)의 실현 가능성을 보여줍니다. DeepEncoder 아키텍처는 SAM-base(80M, 윈도우 어텐션(window attention))와 CLIP-large(300M, 전역 어텐션(global attention)) 모델의 강점을 16배 컨볼루션 압축기(convolutional compressor)를 통해 결합합니다. 순차적 설계는 윈도우 어텐션이 높은 토큰 수 이미지를 처리하도록 보장하며, 밀집 전역 어텐션 이전에 압축이 이루어져 고해상도(1024x1024에서 256개 시각 토큰만 생성)에서도 낮은 활성화 메모리(activation memory)를 유지하면서 복잡한 문서 구조를 효과적으로 포착합니다. 다중 해상도 유연성(Multi-resolution flexibility)을 통해 기본 해상도(native resolutions, Tiny: 64개 토큰, Small: 100개, Base: 256개, Large: 400개) 및 동적 타일링(dynamic tiling, Gundam mode: n×100+256개 토큰)을 지원합니다. 단일 모델이 모든 해상도 모드에서 동시 훈련을 통해 여러 압축률을 처리하여 사용자가 압축-품질 절충(compression-quality trade-offs)을 유연하게 조절할 수 있도록 합니다. 이러한 상용화 준비 성능(Production-ready performance)은 GOT-OCR2.0을 256개 시각 토큰 대신 100개 시각 토큰만 사용하여 능가하며, MinerU2.0(페이지당 6000개 이상 토큰)을 800개 미만 토큰으로 능가합니다. 단일 A100-40G GPU에서 하루 20만 페이지 이상을 처리하며, 엔드투엔드 모델(end-to-end models) 중 가장 적은 시각 토큰으로 OmniDocBench에서 SOTA(State-Of-The-Art)를 달성합니다. 확장된 기능(Extended capabilities)으로 순수 OCR 외에도 심층 파싱(deep parsing, 차트-HTML 테이블(chart-to-HTML table), 화학식-SMILES(chemical formula-to-SMILES), 기하학 파싱(geometry parsing)), 약 100개 언어를 지원하는 다국어 인식(multilingual recognition), 그리고 70% OCR 데이터 + 20% 일반 시각 + 10% 텍스트 전용 훈련 혼합(text-only training mix)을 통한 일반 시각 이해(general vision understanding)를 지원하여 범용 문서 이해 플랫폼으로서의 잠재력을 보여줍니다. Paper | Tweet
2.  **희소 메모리 미세 조정을 통한 지속 학습(Continual Learning via Sparse Memory Finetuning)** Meta AI 연구원들은 희소 메모리 미세 조정(sparse memory finetuning)을 통해 언어 모델의 치명적 망각(catastrophic forgetting) 문제를 해결하며, 새로운 지식에 의해 가장 많이 활성화된 메모리 슬롯만 업데이트하여 표준 미세 조정(standard finetuning)보다 89% 적은 성능 저하(performance degradation)를 달성합니다. 핵심 문제(Core problem): 언어 모델은 새로운 정보로 업데이트할 때 치명적 망각을 겪으며, 이전에 습득한 능력을 잃습니다. 표준 미세 조정은 89%의 성능 저하를 유발하고, LoRA는 보류된 작업(held-out tasks)에서 71%의 저하를 초래하여, 고비용 데이터 재생 전략(expensive data replay strategies) 없이는 지속 학습(continual learning)을 비실용적으로 만듭니다. 이 연구는 언어 모델이 새로운 지식을 효율적으로 통합하면서 이전 지식을 보존하는 방법을 제시합니다. 메모리 계층 아키텍처(Memory layer architecture)는 피드포워드 계층(feedforward layers)을 희소 매개변수 메모리 풀(sparse parametric memory pools, 1-10M 슬롯)로 대체하며, 각 순방향 전달(forward pass)은 작은 하위 집합(예: 1만 개 매개변수)에만 접근합니다. 이는 전체 용량과 지식 조각당 최소 매개변수 사이의 균형을 제공하여 정보 저장에 대한 세분화된 제어(granular control)를 가능하게 합니다. 희소성을 위한 TF-IDF 순위(TF-IDF ranking for sparsity)는 배경 코퍼스(background corpus, 사전 훈련 데이터)에 대한 용어 빈도-역 문서 빈도 점수(term frequency-inverse document frequency scores)를 계산하여 새 입력에 특정한 메모리 슬롯을 식별합니다. 새 배치에서 많이 접근되지만 일반 지식에서는 드물게 사용되는 상위 t개 슬롯(예: 100만 개 중 500개)만 업데이트하여 간섭 최소화(minimizing interference)를 달성합니다. 경험적 검증(Empirical validation): TriviaQA 사실 학습(TriviaQA fact learning)에서 희소 메모리 미세 조정은 NaturalQuestions에서 11%의 성능 저하만 달성(전체 미세 조정의 경우 89%, LoRA의 경우 71%)하면서 동등한 새 지식(equivalent new knowledge)을 학습합니다. 사실 학습과 문서 QA 작업(document QA tasks) 모두에서 학습-망각 절충 경계(learning-forgetting tradeoff frontier)를 따라 기준선을 파레토 지배(Pareto dominates)합니다. 핵심 세트 분석(Core set analysis): 사실은 일반적으로 엔티티 경계(entity boundaries)와 일치하는 "핵심 세트(core sets)"를 형성하는 100-500개의 메모리 인덱스(memory indices)에 분산됩니다. TF-IDF 순위는 테스트 시 쿼리(test-time queries)에 접근하지 않고도 이러한 의미론적 콘텐츠 인덱스(semantic content indices)를 성공적으로 식별하여 모델이 지속적인 경험(continual experience)을 통해 지식을 축적(accumulate knowledge)할 수 있도록 합니다. Paper | Tweet
3.  **모델이 매니폴드(Manifolds)를 조작할 때(When Models Manipulate Manifolds)** Anthropic 연구원들은 Claude 3.5 Haiku가 고정 폭 텍스트(fixed-width text)에서 줄 바꿈(line break)을 예측하는 방법을 조사하여, 생물학적 뇌의 생물학적 장소 세포(biological place cells) 및 경계 세포(boundary cells)와 유사한 기하학적 표현(geometric representations)을 밝혀냈습니다. 이 연구는 언어 모델이 텍스트 공간 내에서 시각적/공간적 추론을 어떻게 수행하는지에 대한 깊은 통찰을 제공합니다. 텍스트 공간에서의 지각 작업(Perceptual task in text space): 모델은 현재 줄의 문자 수를 세고, 줄 너비 제약(line width constraints)과 비교하여 새 줄을 삽입할 시기를 예측해야 합니다. 언어 모델은 토큰 시퀀스(token sequences, 정수)만 받으므로, 명시적 위치 정보(explicit position information) 없이 시각/공간 추론(visual/spatial reasoning)을 처음부터 학습해야 합니다. 표현의 이중 해석(Dual interpretation of representations): 문자 위치는 이산 특징(discrete features, 활성화 강도(activation strength)가 위치를 결정)과 1차원 특징 매니폴드(one-dimensional feature manifolds, 매니폴드 상의 각도 움직임(angular movement on the manifold)이 위치를 나타냄)로 인코딩됩니다. 계산은 이산 회로(discrete circuits) 또는 잔차 스트림(residual stream)에 대한 기하학적 변환(geometric transformations)으로 이중적으로 볼 수 있습니다. 생물학적 유사점(Biological parallels): 포유류 장소 세포(mammalian place cells, 환경 내 위치 인코딩(encoding location)) 및 경계 세포(boundary cells, 공간 경계 감지(detecting spatial boundaries))와 유사한 학습된 위치 표현(learned position representations)이 발견되었습니다. 이들은 줄 너비 제약이 있는 소스 코드, 채팅 로그, 이메일 아카이브, 사법 판결에 대한 훈련에서 자연스럽게 나타납니다. 분산 계수 알고리즘(Distributed counting algorithm): 모델은 누적 위치(cumulative position)를 추적하고, 학습된 경계 표현(learned boundary representations)과 비교하며, 새 줄 예측 트리거(trigger newline predictions)를 하는 어텐션 헤드(attention heads)를 통해 문자 계수를 구현합니다. 다른 계층은 문자 누적(character accumulation), 경계 감지(boundary sensing), 최종 새 줄 예측(final newline prediction)을 순차적으로 처리합니다. 모델의 시각적 착시(Visual illusions in models): 인간이 시각적 착시를 경험하는 것처럼, 모델도 엣지 케이스(edge cases)에서 "지각 오류(perceptual errors)"를 보입니다. 이는 잔차 스트림의 추상적인 기하학적 구조(abstract geometric structures)가 인간이 무의식적으로(subconsciously) 수행하는 복잡한 공간 추론 작업(complex spatial reasoning tasks)을 어떻게 가능하게 하는지에 대한 프레임워크를 제공합니다. Paper | Tweet
4.  **헤세 행렬 없는 데이터 기여도 분석을 위한 베이즈 영향 함수(Bayesian Influence Functions for Hessian-Free Data Attribution)** 고전적인 영향 함수(Classical influence functions)는 비가역 헤세 행렬(non-invertible Hessians)과 고차원 매개변수 공간(high-dimensional parameter spaces)으로 인해 심층 신경망(deep neural networks)에서 어려움을 겪습니다. 이 연구는 확률적 경사 MCMC 샘플링(stochastic-gradient MCMC sampling)을 통해 추정된 손실 지형 통계(loss landscape statistics)로 헤세 행렬 역산(Hessian inversion)을 대체하는 지역 베이즈 영향 함수(local Bayesian influence function, BIF)를 소개합니다. 핵심 혁신(Core innovation): BIF는 문제성 있는 헤세 행렬 역행렬(problematic Hessian inverse)을 계산하는 대신 지역 사후 분포(local posterior distribution)에 대한 공분산 추정(covariance estimation)을 사용합니다. 이 분포적 접근 방식(distributional approach)은 DNNs(Deep Neural Networks)의 퇴화된 손실 지형(degenerate loss landscapes)을 자연스럽게 처리하며, 비특이 모델(non-singular models)의 경우 고전적인 영향 함수로 축소됩니다. SGLD 기반 추정(SGLD-based estimation): 확률적 경사 랑주뱅 동역학(stochastic gradient Langevin dynamics)을 구현하여 지역화된 베이즈 사후 분포(localized Bayesian posterior)에서 샘플링하고, 훈련 샘플 손실(training sample losses)과 쿼리 관측값(query observables) 간의 공분산(covariances)을 계산합니다. 이 방법은 아키텍처 불가지론적(architecture-agnostic)이며 구조적 근사(structural approximations) 없이 수십억 개의 매개변수로 확장됩니다. 계산상의 절충(Computational trade-offs): EK-FAC과 같은 고비용 적합 단계(expensive fit phase)는 없지만, 비용은 사후 표본 추출(posterior draws) 횟수에 비례합니다. 세분화된 기여도(fine-grained attribution, 토큰별 영향(per-token influences)은 병렬로 계산)에 더 효율적입니다. 고전적인 방법은 많은 쿼리가 높은 설정 비용 상각(amortize high setup costs)을 할 때 탁월합니다. 실험적 검증(Experimental validation): 재훈련 실험(retraining experiments, 선형 데이터 모델링 점수(Linear Datamodeling Score))에서 최첨단(state-of-the-art, SOTA)을 달성하며, EK-FAC 기준선 능가(outperforming EK-FAC baseline)하거나 동등한 성능을 보입니다. 가장 큰 Pythia 모델(2.8B 매개변수)에서 동일한 GPU 메모리를 사용하면서 2배 빠른 평가 속도를 보여줍니다. 해석 가능한 토큰별 분석(Interpretable per-token analysis): 언어 모델의 의미론적 관계(semantic relationships)를 포착합니다. 상관관계(correlations)는 번역, 대체 철자, 동의어에서 극대화됩니다. 비전 모델(vision models)에서 유사한 범주가 긍정적 영향(positive influence)을 보이는 계층적 구조(hierarchical structure)를 밝혀냅니다. Paper | Tweet
5.  **샘플링을 통한 추론(Reasoning with Sampling)** 기본 언어 모델은 훈련, 데이터셋 또는 검증자(verifiers)가 필요 없는 MCMC 기법(MCMC techniques)을 사용하여 추론 시간 전력 분포 샘플링(inference-time power distribution sampling)을 통해 RL 사후 훈련(RL-posttraining)과 같거나 그 이상의 추론 성능(Reasoning performance)을 달성합니다. 핵심 통찰(Core insight): RL 사후 훈련은 근본적으로 새로운 행동(fundamentally new behaviors)을 학습하기보다는 기본 모델 분포(base model distributions)를 선명하게 합니다. 전력 분포(Power distribution, p^α) 샘플링은 기본 모델 가능도 지수화(exponentiating base model likelihoods)를 통해 이러한 선명화를 명시적으로 목표로 하며, 붕괴된 RL 분포(collapsed RL distributions)와 달리 다양성 유지(maintaining diversity)하면서 고확률 시퀀스 가중치 부여(upweighting high-probability sequences)를 합니다. 전력 샘플링 대 저온 샘플링(Power vs low-temperature sampling): 저온 샘플링(low-temperature sampling)은 조건부 다음 토큰 분포(conditional next-token distributions)를 지수화(합의 지수(exponent of sums))하는 반면, 전력 샘플링(power sampling)은 지수화된 미래 경로 가능도 합(sums exponentiated future path likelihoods, 지수의 합(sum of exponents))을 계산합니다. 이 중요한 차이는 전력 샘플링이 미래 완성(future completions)을 고려하여, 많은 저확률 완성(low-likelihood completions)을 가진 토큰보다 적지만 고확률 경로(high-likelihood paths)를 가진 토큰에 더 높은 가중치를 부여한다는 것을 의미합니다. MCMC 구현(MCMC implementation): 자기회귀 알고리즘(Autoregressive algorithm)은 무작위 재샘플링을 사용한 메트로폴리스-해스팅스(Metropolis-Hastings with random resampling)를 통해 중간 분포를 점진적으로 샘플링(progressively samples intermediate distributions)합니다. 인덱스를 균일하게 선택하고, 제안 LLM(proposal LLM)을 사용하여 해당 지점에서 재샘플링하며, 상대적 전력 분포 가능도(relative power distribution likelihoods)를 기반으로 수락/거부합니다. 블록 크기 B=192, α=4.0, 추론 비용(inference cost)은 표준 샘플링의 약 8.84배입니다. 경험적 결과(Empirical results): Qwen2.5-Math-7B에서 MATH500에서 74.8%를 달성(GRPO는 78.5%)하지만, 도메인 외 작업(out-of-domain tasks)에서는 더 나은 성능을 보입니다. HumanEval에서 57.3%(GRPO는 53.7%), AlpacaEval 점수(AlpacaEval score)에서 2.88점(GRPO는 2.38점)을 기록합니다. RL의 모드 붕괴(RL’s mode collapse)를 피하면서 k>1에서 우수한 pass@k 성능(superior pass@k performance)으로 생성 다양성(generation diversity)을 유지합니다. 훈련 없는 이점(Training-free advantage): 하이퍼파라미터 탐색(hyperparameter sweeps), 선별된 데이터셋(curated datasets), 보상 검증자(reward verifiers)가 필요 없습니다. 검증 가능한 도메인(verifiable domains)을 넘어 광범위하게 적용 가능합니다. 679개 토큰의 평균 응답 길이를 유지하면서 최고 기본 모델 가능도/신뢰 영역(highest base model likelihood/confidence regions)에서 샘플링(GRPO와 유사)하며, 이는 기본 모델에 잠재적 추론 능력(latent reasoning capabilities)이 존재함을 시사합니다. Paper | Tweet
6.  **LLM을 위한 미리 보기 라우팅(Lookahead Routing for LLMs)** 미리 보기 라우팅(Lookahead Routing)은 잠재적 모델 출력의 잠재 표현(latent representations)을 예측하여 전체 추론(full inference) 없이 더 정보에 입각한 라우팅 결정(informed routing decisions)을 가능하게 하는 응답 인식 LLM 라우팅 프레임워크(response-aware LLM routing framework)입니다. 쿼리 전용 라우팅의 핵심 한계(Core limitation of query-only routing): 전통적인 라우터(Traditional routers)는 입력 쿼리(input queries)에만 의존하여 결정을 내리므로, 생성 중에 나타나는 실제 응답 품질(response quality) 및 의미론적 의도(semantic intent)에 대한 중요한 정보를 놓칩니다. 이는 복잡하거나 모호한 쿼리(complex or ambiguous queries)에 대해 최적이 아닌 라우팅(suboptimal routing)으로 이어집니다. 이중 구현 아키텍처(Dual implementation architecture): 시퀀스 수준 변형(Sequence-level variant)은 인과 언어 모델(causal language models, CLM)을 사용하여 쿼리를 모델 식별자(model identifier, MID) 토큰과 연결하고, MID 위치에서 은닉 상태 추출(extracting hidden states)하여 응답 표현(response representations)으로 사용합니다. 토큰 수준 변형(Token-level variant)은 마스크드 언어 모델(masked language models, MLM)을 사용하여 반복되는 MID 토큰 블록(repeated MID token blocks)을 통해 모든 후보 응답을 공동으로 재구성하고, [CLS] 토큰 어텐션(attention)을 통해 정보 집계(aggregating information)를 합니다. 커리큘럼 마스킹 전략(Curriculum masking strategy): MLM 변형은 응답 끝에서 시작으로 점진적으로 마스크(progressively masks)하며, 훈련의 처음 40% 동안 마스킹 비율(masking ratio)을 선형적으로 100%까지 증가시킵니다. 부분 마스킹에서 전체 마스킹으로의 이 부드러운 전환(smooth transition)은 균일 무작위 마스킹(uniform random masking)보다 견고한 표현(robust representations)과 더 나은 일반화(better generalization)를 가능하게 합니다. 공동 훈련 목표(Joint training objective): 라우팅 손실(routing loss, 모델 선택(model selection)에 대한 이진 교차 엔트로피(binary cross-entropy))과 응답 재구성 손실(response reconstruction loss, CLM의 다음 토큰 예측(next-token prediction), MLM의 마스크된 토큰 복구(masked token recovery))을 결합합니다. 보조 응답 모델링(Auxiliary response modeling)은 샘플 효율성(sample efficiency)을 6.3배 향상시키고 오라클 응답(oracle responses)과의 상호 정보(mutual information)를 높여 더 풍부한 의미론적 정보(richer semantic information)를 포착합니다. 성능(Performance): 7개 벤치마크(benchmarks, AlpacaEval-2, Arena-Hard, MT-Bench, GSM8K, MATH, HumanEval, MBPP)에서 SOTA RouterDC 대비 평균 정규화 점수 이득(average normalized score gain) 7.7%를 달성합니다. MLM 변형은 공동 의미 공간 인코딩(joint semantic-space encoding)이 세분화된 모델 간 비교(fine-grained cross-model comparisons)를 가능하게 하는 개방형 지시 따르기 작업(open-ended instruction-following tasks)에서 탁월합니다. 거의 100%의 코드 쿼리를 전문화된 Qwen2.5-Coder 모델(specialized Qwen2.5-Coder model)로 라우팅하여 강력한 전문화 인식(strong specialization awareness)을 보여줍니다. Paper | Tweet
7.  **Ring-1T** Ring-1T는 1조 개의 매개변수(토큰당 약 500억 개 활성(active per token))를 가진 최초의 오픈 소스 사고 모델(open-source thinking model)이며, 조 단위 RL 훈련(trillion-scale RL training)을 위한 세 가지 혁신을 통해 획기적인 결과(breakthrough results)를 달성합니다. 벤치마크 성능(Benchmark performance): AIME-2025에서 93.4점(최고 오픈 가중치(top open-weights)), HMMT-2025에서 86.72점, CodeForces 등급(CodeForces rating) 2088점(전체 최고), 순수 자연어 추론(pure natural language reasoning)을 통해 IMO-2025 은메달을 획득했습니다. IcePop은 훈련-추론 불일치(training-inference misalignment)를 해결합니다: 별도의 훈련/추론 엔진(separate training/inference engines)을 사용하면 MoE 모델(MoE models)에서 복합화(compound)되는 확률 불일치(probability discrepancies)가 발생합니다. IcePop은 경계(α, β) 내에서 토큰 수준 기울기 보정(token-level gradient calibration)을 적용하고 과도한 편차 토큰(excessive-deviation tokens)을 마스킹합니다. 1-2‰만 클리핑(clipping)이 필요하여 안정성 유지(maintaining stability)를 합니다. C3PO++는 롤아웃(rollouts) 속도를 향상시킵니다: 예산 제어 파티셔닝(Budget-controlled partitioning)은 토큰 제한에서 생성을 중단하여 유휴 리소스(idle resources)를 방지합니다. 완료된 궤적(Completed trajectories)은 훈련으로 이동하고, 미완성된 것은 버퍼링 및 재개됩니다. 2.5배 롤아웃 속도 향상(rollout speedup)과 1.5배 엔드투엔드 속도 향상(end-to-end speedup)을 제공합니다. ASystem 인프라(ASystem infrastructure): 하이브리드 런타임(Hybrid Runtime, 통합 훈련-추론), AMem(GPU 메모리 관리), AState(초 미만 가중치 동기화), ASandbox(100ms 시작)를 포함합니다. SingleController + SPMD 아키텍처(architecture)는 데이터 흐름 병목 현상(data flow bottlenecks)을 방지합니다. 훈련 파이프라인(Training pipeline): 다중 도메인 데이터(multi-domain data, 수학 46%, STEM 26%, 코드 20%)에 대한 Long-CoT SFT, 검증 가능한 보상을 통한 추론 RL(Reasoning RL with verifiable rewards), 정렬 및 안전을 위한 일반 RL(General RL for alignment and safety)을 포함합니다. Paper | Tweet
8.  **ColorAgent** ColorAgent는 단계별 RL(step-wise RL)과 자체 진화 훈련(self-evolving training)을 다중 에이전트 프레임워크(multi-agent framework)와 결합하여 개인화된 사용자 참여(personalized user engagement)를 제공하는 모바일 OS 에이전트(mobile OS agent)입니다. AndroidWorld에서 77.2%, AndroidLab에서 50.7%의 성공률(오픈 모델 중 SOTA)을 달성하며, 개인화된 의도 정렬(personalized intent alignment)을 위한 MobileIAR에서 58.66%, 신뢰성(trustworthiness)을 위한 VeriOS-Bench에서 68.98%를 기록했습니다. 모바일 운영체제 환경은 복잡하고 다양한 사용자 상호작용을 포함하기 때문에, 에이전트가 사용자의 의도를 정확히 파악하고 적절한 작업을 수행하는 것이 중요합니다. ColorAgent는 이러한 맥락에서 사용자의 개별적인 행동 패턴과 선호도를 학습하여 최적의 개인화된 경험을 제공합니다. 다중 에이전트 프레임워크는 서로 다른 역할을 수행하는 에이전트들이 협력하여 복잡한 작업을 처리할 수 있도록 하며, 자체 진화 훈련은 에이전트가 새로운 환경이나 사용자 피드백에 따라 지속적으로 능력을 개선할 수 있게 합니다. 이 에이전트의 높은 성공률은 모바일 환경에서의 실제 적용 가능성을 강력하게 시사하며, 특히 개인화된 의도 정렬 및 신뢰성 측면에서 뛰어난 성능을 보여주어 사용자 경험을 혁신할 잠재력을 가지고 있습니다. Paper | Tweet
9.  **Prompt-MII** CMU 연구원들은 3,000개 이상의 HuggingFace 데이터셋(datasets)에서 지시 유도(instruction induction)를 메타 학습(meta-learns)하는 RL 프레임워크(RL framework)인 Prompt-MII를 제안하며, 90개의 보지 못한 작업(unseen tasks)에서 4-9 F1 점수 개선(F1 point improvements)을 달성하는 동시에 인컨텍스트 학습(in-context learning)보다 3-13배 적은 토큰을 필요로 합니다. Prompt-MII는 기존 프롬프트 엔지니어링의 한계를 극복하고, 모델이 스스로 최적의 지시를 생성하도록 돕는 혁신적인 접근 방식입니다. APE(2000 LLM 호출(LLM calls)) 및 GEPA(150 호출)와 달리, Prompt-MII는 단일 순방향 전달(single forward pass)로 간결한 지시(compact instructions)를 생성하며 테스트 시 훈련 불필요(training-free at test time)합니다. 이는 프롬프트 최적화에 필요한 계산 비용과 시간을 크게 줄여줍니다. 메타 학습을 통해 다양한 데이터셋에서 지시 유도 능력을 학습함으로써, Prompt-MII는 새로운, 보지 못한 작업에 대해서도 뛰어난 일반화 성능을 보여줍니다. 즉, 특정 작업에 대한 수동 프롬프트 튜닝 없이도 높은 성능을 달성할 수 있게 되는 것입니다. 이러한 효율성과 범용성은 대규모 언어 모델을 활용하는 다양한 애플리케이션에서 프롬프트 생성 과정을 자동화하고 최적화하는 데 중요한 역할을 할 것으로 기대됩니다. Paper | Tweet
10. **기업 심층 연구(Enterprise Deep Research)** Salesforce AI 연구원들은 할 일 기반 작업 관리(todo-driven task management) 및 조종 가능한 컨텍스트 엔지니어링(steerable context engineering)을 통한 휴먼 인 더 루프(human-in-the-loop) 조종으로 기업 심층 연구(enterprise deep research)를 위한 투명한 다중 에이전트 프레임워크(multi-agent framework)인 EDR을 제시합니다. DeepResearch Bench에서 SOTA(49.86), DeepConsult에서 71.57%의 승률, ResearchQA에서 68.5%를 달성하며 LangChain의 오픈 심층 연구(open deep research)보다 4배 적은 토큰을 소비합니다. EDR은 복잡한 기업 환경에서 심층적인 연구 작업을 효율적으로 수행하기 위해 설계되었습니다. 이 프레임워크의 핵심은 인간의 개입(human-in-the-loop)을 통해 에이전트의 의사결정을 조종하고 피드백을 제공하여 연구의 정확성과 관련성을 높이는 것입니다. 할 일 기반 작업 관리는 연구 프로세스를 명확한 단계로 나누어 진행 상황을 추적하고, 조종 가능한 컨텍스트 엔지니어링은 에이전트가 특정 연구 목표에 맞춰 정보를 수집하고 분석하도록 유도합니다. 이러한 투명한 다중 에이전트 구조는 각 에이전트가 특정 역할(정보 수집, 분석, 요약 등)을 수행하며 협력하도록 하여, 복잡한 질문에 대한 심층적인 답변을 생성할 수 있습니다. LangChain 기반의 기존 심층 연구 방식보다 훨씬 적은 토큰을 소비하면서도 우수한 성능을 보여주는 것은 EDR의 경제성과 효율성을 입증합니다. 이는 기업들이 방대한 데이터를 기반으로 신속하고 정확한 의사결정을 내리는 데 필수적인 도구가 될 것입니다. Paper | Tweet