다음은 업데이트된 블로그 게시물입니다.

1.  **DeepSeek-OCR** DeepSeek-OCR은 새로운 시각 인코더 아키텍처(vision encoder architecture, DeepEncoder)를 사용하여 긴 텍스트 컨텍스트를 시각적 표현으로 압축하는 방법을 탐구하며, 높은 OCR 정확도(OCR accuracy)를 유지하면서 10-20배의 압축률을 달성합니다. 핵심 압축 통찰(compression insight): 이미지를 텍스트를 위한 효율적인 압축 매체로 취급합니다.
    이러한 접근 방식은 기존 OCR 시스템이 직면했던 대규모 문서 처리의 병목 현상을 해결하는 데 중점을 둡니다. DeepEncoder 아키텍처는 SAM-base(80M)와 CLIP-large(300M) 모델의 강점을 결합하여 16배 컨볼루션 압축기를 통해 효율적인 시각적 토큰 생성을 가능하게 합니다. 특히, 고해상도 이미지(1024x1024)에서도 낮은 활성화 메모리를 유지하면서 256개 시각 토큰만 생성하여, 복잡한 문서 구조를 효과적으로 포착합니다. DeepSeek-OCR은 다양한 해상도 모드를 지원하며, 단일 모델로 여러 압축률을 처리하여 사용자가 압축률과 품질 간의 균형을 유연하게 조절할 수 있도록 합니다. 이는 상업적 활용에 있어 중요한 장점으로, GOT-OCR2.0 및 MinerU2.0과 같은 기존 SOTA 모델을 능가하는 성능을 보여주며, 단일 A100-40G GPU에서 하루 20만 페이지 이상을 처리할 수 있는 높은 처리량을 자랑합니다. 순수 OCR을 넘어, 차트-HTML 테이블 변환, 화학식-SMILES 변환, 기하학 파싱 등 심층 파싱 기능과 약 100개 언어를 지원하는 다국어 인식 기능을 제공하여 범용 문서 이해 플랫폼으로서의 잠재력을 보여줍니다.

2.  **희소 메모리 미세 조정을 통한 지속 학습(Continual Learning via Sparse Memory Finetuning)** 핵심 문제(Core problem): 언어 모델은 새로운 정보로 업데이트할 때 치명적 망각을 겪으며, 이전에 습득한 능력을 잃습니다. 표준 미세 조정은 89%의 성능 저하를 유발하고, LoRA는 보류된 작업(held-out tasks)에서 71%의 저하를 초래하여, 고비용 데이터 재생 전략(expensive data replay strategies) 없이는 지속 학습(continual learning)을 비실용적으로 만듭니다.
    이 연구는 언어 모델이 새로운 지식을 효율적으로 통합하면서 이전 지식을 보존하는 방법을 제시합니다. 피드포워드 계층을 희소 매개변수 메모리 풀(1-10M 슬롯)로 대체하는 메모리 계층 아키텍처는 각 순방향 전달에서 작은 하위 집합(예: 1만 개 매개변수)에만 접근하여 전체 용량과 지식 조각당 최소 매개변수 사이의 균형을 제공합니다. 이는 정보 저장에 대한 세분화된 제어(granular control)를 가능하게 합니다. 희소성 유지를 위해 TF-IDF 순위(TF-IDF ranking)를 활용하여 새 입력에 특정한 메모리 슬롯을 식별하고, 새 배치에서 많이 접근되지만 일반 지식에서는 드물게 사용되는 상위 t개 슬롯(예: 100만 개 중 500개)만 업데이트함으로써 간섭을 최소화합니다. 경험적 검증에서, 희소 메모리 미세 조정은 TriviaQA 사실 학습(TriviaQA fact learning)에서 NaturalQuestions에 대한 11%의 성능 저하만을 보이며 동등한 새 지식을 학습했습니다. 이는 전체 미세 조정의 89%, LoRA의 71% 저하와 비교할 때 획기적인 개선입니다.

3.  **모델이 매니폴드(Manifolds)를 조작할 때(When Models Manipulate Manifolds)** Anthropic 연구원들은 Claude 3.5 Haiku가 고정 폭 텍스트(fixed-width text)에서 줄 바꿈(line break)을 예측하는 방법을 조사하여, 생물학적 뇌의 생물학적 장소 세포(biological place cells) 및 경계 세포(boundary cells)와 유사한 기하학적 표현(geometric representations)을 밝혀냈습니다.
    이 연구는 언어 모델이 텍스트 공간 내에서 시각적/공간적 추론을 어떻게 수행하는지에 대한 깊은 통찰을 제공합니다. 모델은 명시적인 위치 정보 없이도 현재 줄의 문자 수를 세고, 줄 너비 제약과 비교하여 새 줄 삽입 시점을 예측하는 복잡한 지각 작업을 수행합니다. 이는 문자 위치가 이산 특징과 1차원 특징 매니폴드로 이중적으로 인코딩되는 표현 방식 덕분입니다. 특히, 포유류의 장소 세포와 경계 세포에 비견되는 학습된 위치 표현이 발견되었는데, 이는 줄 너비 제약이 있는 소스 코드, 채팅 로그, 이메일 아카이브 등의 훈련 데이터에서 자연스럽게 나타났습니다. 모델은 분산 계수 알고리즘을 통해 누적 위치를 추적하고, 학습된 경계 표현과 비교하여 새 줄 예측을 트리거합니다. 이러한 작동 방식은 인간이 시각적 착시를 경험하듯이, 모델도 엣지 케이스에서 "지각 오류"를 보일 수 있음을 시사하며, 잔차 스트림의 추상적인 기하학적 구조가 복잡한 공간 추론 작업을 가능하게 하는 프레임워크를 제공합니다.

4.  **헤세 행렬 없는 데이터 기여도 분석을 위한 베이즈 영향 함수(Bayesian Influence Functions for Hessian-Free Data Attribution)** 고전적인 영향 함수(Classical influence functions)는 비가역 헤세 행렬(non-invertible Hessians)과 고차원 매개변수 공간(high-dimensional parameter spaces)으로 인해 심층 신경망(deep neural networks)에서 어려움을 겪습니다. 이 연구는 확률적 경사 MCMC 샘플링(stochastic-gradient MCMC sampling)을 통해 추정된 손실 지형 통계(loss landscape statistics)로 헤세 행렬 역산(Hessian inversion)을 대체하는 지역 베이즈 영향 함수(local Bayesian influence function, BIF)를 소개합니다.
    BIF의 핵심 혁신은 문제성 있는 헤세 행렬 역행렬 계산 대신 지역 사후 분포(local posterior distribution)에 대한 공분산 추정(covariance estimation)을 사용한다는 점입니다. 이 분포적 접근 방식은 심층 신경망(DNNs)의 퇴화된 손실 지형을 자연스럽게 처리하며, 비특이 모델의 경우 고전적인 영향 함수로 축소됩니다. SGLD(확률적 경사 랑주뱅 동역학) 기반 추정은 지역화된 베이즈 사후 분포에서 샘플링하고, 훈련 샘플 손실과 쿼리 관측값 간의 공분산을 계산하여 데이터 기여도를 분석합니다. 이 방법은 아키텍처 불가지론적(architecture-agnostic)이며 구조적 근사 없이 수십억 개의 매개변수로 확장됩니다. 계산상의 절충점은 존재하지만, EK-FAC과 같은 고비용 적합 단계가 없으며, 세분화된 기여도(예: 토큰별 영향) 분석에 더 효율적입니다. 재훈련 실험에서 SOTA 성능을 달성하며, 가장 큰 Pythia 모델(2.8B 매개변수)에서 2배 빠른 평가 속도를 보여주었습니다. 특히 언어 모델의 의미론적 관계를 포착하는 해석 가능한 토큰별 분석은 번역, 대체 철자, 동의어에서 상관관계를 극대화하고, 비전 모델에서는 유사한 범주가 긍정적 영향을 보이는 계층적 구조를 밝혀냈습니다.

5.  **샘플링을 통한 추론(Reasoning with Sampling)** 핵심 통찰(Core insight): RL 사후 훈련은 근본적으로 새로운 행동(fundamentally new behaviors)을 학습하기보다는 기본 모델 분포(base model distributions)를 선명하게 합니다. 전력 분포(Power distribution, p^α) 샘플링은 기본 모델 가능도 지수화(exponentiating base model likelihoods)를 통해 이러한 선명화를 명시적으로 목표로 하며, 붕괴된 RL 분포(collapsed RL distributions)와 달리 다양성 유지(maintaining diversity)하면서 고확률 시퀀스 가중치 부여(upweighting high-probability sequences)를 합니다.
    이 연구는 기본 언어 모델이 별도의 훈련, 데이터셋 또는 검증자 없이 MCMC(Markov Chain Monte Carlo) 기법을 사용하여 RL 사후 훈련과 같거나 그 이상의 추론 성능을 달성할 수 있음을 보여줍니다. 전력 샘플링은 단순히 조건부 다음 토큰 분포를 지수화하는 저온 샘플링과 달리, 지수화된 미래 경로 가능도 합을 계산하여 미래 완성을 고려합니다. 이는 적지만 고확률 경로를 가진 토큰에 더 높은 가중치를 부여하여 추론의 정확성을 높입니다. MCMC 구현은 무작위 재샘플링을 사용한 메트로폴리스-해스팅스(Metropolis-Hastings)를 통해 중간 분포를 점진적으로 샘플링하며, 블록 크기 B=192, α=4.0에서 표준 샘플링의 약 8.84배의 추론 비용을 가집니다. 경험적 결과로 Qwen2.5-Math-7B에서 MATH500 벤치마크에서 74.8%를 달성하여 GRPO(78.5%)에 근접하며, HumanEval에서 57.3%(GRPO 53.7%) 및 AlpacaEval 점수에서 2.88점(GRPO 2.38점)으로 도메인 외 작업에서 더 나은 성능을 보였습니다. 훈련 없이도 RL의 모드 붕괴를 피하고 생성 다양성을 유지하면서 우수한 pass@k 성능을 보여, 기본 모델에 잠재된 추론 능력이 있음을 시사합니다.

6.  **LLM을 위한 미리 보기 라우팅(Lookahead Routing for LLMs)** 쿼리 전용 라우팅의 핵심 한계(Core limitation of query-only routing): 전통적인 라우터(Traditional routers)는 입력 쿼리(input queries)에만 의존하여 결정을 내리므로, 생성 중에 나타나는 실제 응답 품질(response quality) 및 의미론적 의도(semantic intent)에 대한 중요한 정보를 놓칩니다. 이는 복잡하거나 모호한 쿼리(complex or ambiguous queries)에 대해 최적이 아닌 라우팅(suboptimal routing)으로 이어집니다.
    미리 보기 라우팅(Lookahead Routing)은 이러한 한계를 극복하기 위해 잠재적 모델 출력의 잠재 표현(latent representations)을 예측하여, 전체 추론 없이 더 정보에 입각한 라우팅 결정을 가능하게 하는 응답 인식 LLM 라우팅 프레임워크입니다. 이중 구현 아키텍처는 시퀀스 수준 변형과 토큰 수준 변형으로 나뉩니다. 시퀀스 수준 변형은 인과 언어 모델(CLM)을 사용하여 쿼리를 모델 식별자(MID) 토큰과 연결하고, MID 위치에서 은닉 상태를 추출하여 응답 표현으로 사용합니다. 토큰 수준 변형은 마스크드 언어 모델(MLM)을 사용하여 반복되는 MID 토큰 블록을 통해 모든 후보 응답을 공동으로 재구성하고, [CLS] 토큰 어텐션을 통해 정보를 집계합니다. 커리큘럼 마스킹 전략은 MLM 변형에서 응답 끝에서 시작으로 마스킹 비율을 점진적으로 증가시켜 견고한 표현과 더 나은 일반화를 가능하게 합니다. 라우팅 손실과 응답 재구성 손실을 결합한 공동 훈련 목표는 샘플 효율성을 6.3배 향상시키고 오라클 응답과의 상호 정보를 높여 더 풍부한 의미론적 정보를 포착합니다. 7개 벤치마크에서 SOTA RouterDC 대비 평균 정규화 점수 이득 7.7%를 달성했으며, 특히 MLM 변형은 개방형 지시 따르기 작업에서 탁월한 성능을 보여 코드 쿼리의 거의 100%를 전문화된 Qwen2.5-Coder 모델로 라우팅하는 등 강력한 전문화 인식을 입증했습니다.

7.  **Ring-1T** Ring-1T는 1조 개의 매개변수(토큰당 약 500억 개 활성(active per token))를 가진 최초의 오픈 소스 사고 모델(open-source thinking model)이며, 조 단위 RL 훈련(trillion-scale RL training)을 위한 세 가지 혁신을 통해 획기적인 결과(breakthrough results)를 달성합니다.
    이 모델은 AIME-2025에서 93.4점(최고 오픈 가중치), HMMT-2025에서 86.72점, CodeForces 등급 2088점(전체 최고)을 기록하며 순수 자연어 추론을 통해 IMO-2025 은메달을 획득하는 등 놀라운 벤치마크 성능을 보여주었습니다. Ring-1T의 핵심 기술 중 하나인 IcePop은 훈련-추론 불일치 문제를 해결합니다. 이는 MoE 모델에서 발생하는 확률 불일치를 경계 내에서 토큰 수준 기울기 보정을 적용하고 과도한 편차 토큰을 마스킹함으로써 안정성을 유지합니다. 또한, C3PO++는 예산 제어 파티셔닝을 통해 롤아웃 속도를 2.5배 향상시키고 엔드투엔드 속도를 1.5배 개선하여 효율적인 RL 훈련을 가능하게 합니다. ASystem 인프라는 통합 훈련-추론을 위한 하이브리드 런타임, GPU 메모리 관리(AMem), 초 미만 가중치 동기화(AState), 100ms 시작(ASandbox)을 포함하여 데이터 흐름 병목 현상을 방지하는 SingleController + SPMD 아키텍처를 제공합니다. 훈련 파이프라인은 수학, STEM, 코드 등 다중 도메인 데이터에 대한 Long-CoT SFT, 검증 가능한 보상을 통한 추론 RL, 그리고 정렬 및 안전을 위한 일반 RL을 포함하여 포괄적인 학습을 수행합니다.

8.  **ColorAgent** ColorAgent는 단계별 RL(step-wise RL)과 자체 진화 훈련(self-evolving training)을 다중 에이전트 프레임워크(multi-agent framework)와 결합하여 개인화된 사용자 참여(personalized user engagement)를 제공하는 모바일 OS 에이전트(mobile OS agent)입니다. AndroidWorld에서 77.2%, AndroidLab에서 50.7%의 성공률(오픈 모델 중 SOTA)을 달성하며, 개인화된 의도 정렬(personalized intent alignment)을 위한 MobileIAR에서 58.66%, 신뢰성(trustworthiness)을 위한 VeriOS-Bench에서 68.98%를 기록했습니다.
    모바일 운영체제 환경은 복잡하고 다양한 사용자 상호작용을 포함하기 때문에, 에이전트가 사용자의 의도를 정확히 파악하고 적절한 작업을 수행하는 것이 중요합니다. ColorAgent는 이러한 맥락에서 사용자의 개별적인 행동 패턴과 선호도를 학습하여 최적의 개인화된 경험을 제공합니다. 다중 에이전트 프레임워크는 서로 다른 역할을 수행하는 에이전트들이 협력하여 복잡한 작업을 처리할 수 있도록 하며, 자체 진화 훈련은 에이전트가 새로운 환경이나 사용자 피드백에 따라 지속적으로 능력을 개선할 수 있게 합니다. 이 에이전트의 높은 성공률은 모바일 환경에서의 실제 적용 가능성을 강력하게 시사하며, 특히 개인화된 의도 정렬 및 신뢰성 측면에서 뛰어난 성능을 보여주어 사용자 경험을 혁신할 잠재력을 가지고 있습니다.

9.  **Prompt-MII** CMU 연구원들은 3,000개 이상의 HuggingFace 데이터셋(datasets)에서 지시 유도(instruction induction)를 메타 학습(meta-learns)하는 RL 프레임워크(RL framework)인 Prompt-MII를 제안하며, 90개의 보지 못한 작업(unseen tasks)에서 4-9 F1 점수 개선(F1 point improvements)을 달성하는 동시에 인컨텍스트 학습(in-context learning)보다 3-13배 적은 토큰을 필요로 합니다.
    Prompt-MII는 기존 프롬프트 엔지니어링의 한계를 극복하고, 모델이 스스로 최적의 지시를 생성하도록 돕는 혁신적인 접근 방식입니다. APE(2000 LLM 호출) 및 GEPA(150 호출)와 달리, Prompt-MII는 단일 순방향 전달로 간결한 지시를 생성하며 테스트 시 훈련이 필요 없습니다. 이는 프롬프트 최적화에 필요한 계산 비용과 시간을 크게 줄여줍니다. 메타 학습을 통해 다양한 데이터셋에서 지시 유도 능력을 학습함으로써, Prompt-MII는 새로운, 보지 못한 작업에 대해서도 뛰어난 일반화 성능을 보여줍니다. 즉, 특정 작업에 대한 수동 프롬프트 튜닝 없이도 높은 성능을 달성할 수 있게 되는 것입니다. 이러한 효율성과 범용성은 대규모 언어 모델을 활용하는 다양한 애플리케이션에서 프롬프트 생성 과정을 자동화하고 최적화하는 데 중요한 역할을 할 것으로 기대됩니다.

10. **기업 심층 연구(Enterprise Deep Research)** Salesforce AI 연구원들은 할 일 기반 작업 관리(todo-driven task management) 및 조종 가능한 컨텍스트 엔지니어링(steerable context engineering)을 통한 휴먼 인 더 루프(human-in-the-loop) 조종으로 기업 심층 연구(enterprise deep research)를 위한 투명한 다중 에이전트 프레임워크(multi-agent framework)인 EDR을 제시합니다. DeepResearch Bench에서 SOTA(49.86), DeepConsult에서 71.57%의 승률, ResearchQA에서 68.5%를 달성하며 LangChain의 오픈 심층 연구(open deep research)보다 4배 적은 토큰을 소비합니다.
    EDR은 복잡한 기업 환경에서 심층적인 연구 작업을 효율적으로 수행하기 위해 설계되었습니다. 이 프레임워크의 핵심은 인간의 개입(human-in-the-loop)을 통해 에이전트의 의사결정을 조종하고 피드백을 제공하여 연구의 정확성과 관련성을 높이는 것입니다. 할 일 기반 작업 관리는 연구 프로세스를 명확한 단계로 나누어 진행 상황을 추적하고, 조종 가능한 컨텍스트 엔지니어링은 에이전트가 특정 연구 목표에 맞춰 정보를 수집하고 분석하도록 유도합니다. 이러한 투명한 다중 에이전트 구조는 각 에이전트가 특정 역할(정보 수집, 분석, 요약 등)을 수행하며 협력하도록 하여, 복잡한 질문에 대한 심층적인 답변을 생성할 수 있습니다. LangChain 기반의 기존 심층 연구 방식보다 훨씬 적은 토큰을 소비하면서도 우수한 성능을 보여주는 것은 EDR의 경제성과 효율성을 입증합니다. 이는 기업들이 방대한 데이터를 기반으로 신속하고 정확한 의사결정을 내리는 데 필수적인 도구가 될 것입니다.