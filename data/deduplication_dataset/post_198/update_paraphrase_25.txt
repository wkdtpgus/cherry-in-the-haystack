**구독자 2만 명 특별 할인**

Pandas DataFrame(데이터프레임)을 다루는 작업은 특히 반복 처리를 활용할 때 번거롭고 많은 시간을 요구할 수 있습니다. 대부분의 파이썬(Python) 개발자들이 그렇듯이, 여러분도 DataFrame을 효율적으로 반복 처리하는 최적의 방안을 찾기 위해 상당한 노력을 기울였을 것입니다. 하지만 더 간결하고 빠른 방법이 있다면 어떨까요? 본 게시물에서는 반복문 없이 판다스 데이터프레임을 처리하는 더욱 효과적인 기법들을 소개할 예정입니다. 이러한 접근 방식의 장점을 심층적으로 논하고, 실제 적용에 도움이 될 몇 가지 실용적인 예시도 제공할 것입니다. 이제 판다스 데이터프레임 반복 처리의 비효율성에서 벗어나 더 나은 방법을 시도할 준비가 되었다면, 계속해서 읽어주십시오!

**목차:**
*   왜 효율적인 코딩이 필수적인가?
*   .iterrows() 활용법과 적절한 사용 시점
*   .apply()를 통한 유연한 데이터 처리
*   벡터화(vectorization) 기법으로 속도 향상
*   `df.eval()` 및 `df.query()`로 표현식 처리
*   `swifter` 라이브러리를 이용한 자동 최적화
*   성능 최적화를 위한 추가 고려사항
*   모범 사례 요약 및 결론

이 글 전체에서 우리는 포커(Poker) 카드 게임 데이터셋(dataset)을 활용할 것입니다. 먼저 데이터를 불러오고(load) 그 구조를 탐색해 봅시다:

```python
import pandas as pd
import time
import numpy as np

poker_data = pd.read_csv('/kaggle/input/poker-hand/poker_hand.csv')
poker_data.head()
```

각 포커 라운드에서 플레이어는 다섯 장의 카드를 받으며, 각 카드는 하트(hearts), 다이아몬드(diamonds), 클로버(clubs), 스페이드(spades) 중 하나의 문양(symbol)과 1부터 13까지의 순위(rank)로 정의됩니다. 이 데이터셋은 한 사람이 가질 수 있는 다섯 장의 카드에 대한 모든 가능한 조합으로 구성되어 있습니다.

Sn: n번째 카드의 문양 (1: 하트, 2: 다이아몬드, 3: 클로버, 4: 스페이드)
Rn: n번째 카드의 순위 (1: 에이스(Ace), 2–10, 11: 잭(Jack), 12: 퀸(Queen), 13: 킹(King))

**제 모든 책들을 클릭 한 번으로 40% 할인된 가격에 만나보세요.**
유세프 호스니(Youssef Hosni) · 6월 17일

저의 모든 책과 로드맵(roadmap)을 번들(bundle)로 구성했습니다. 한 번의 클릭으로 모든 것을 원가보다 40% 저렴하게 구매하실 수 있습니다. 이 번들에는 다음을 포함한 8권의 전자책(eBook)이 포함되어 있습니다:
전체 이야기 읽기

### 1. 왜 효율적인 코딩이 필수적인가?

데이터 분석 및 머신러닝(machine learning) 분야에서 효율적인 코딩은 단순한 선택 사항이 아니라 필수적인 요소입니다. 특히 대규모 데이터셋을 다룰 때, 비효율적인 코드는 엄청난 시간 낭비와 자원 소모를 초래할 수 있습니다. 몇 가지 주요 이유를 살펴보겠습니다:

*   **시간 절약:** 데이터의 규모가 커질수록 코드 실행 시간은 기하급수적으로 증가할 수 있습니다. 최적화된 코드는 몇 시간 또는 며칠이 걸릴 작업을 몇 분 만에 완료하여 개발 및 분석 시간을 단축시킵니다.
*   **자원 효율성:** 비효율적인 코드는 CPU, 메모리(memory)와 같은 컴퓨팅 자원을 과도하게 사용합니다. 이는 특히 클라우드(cloud) 환경에서 불필요한 비용을 발생시키고, 다른 작업의 성능에도 영향을 미칠 수 있습니다.
*   **확장성:** 프로토타입(prototype) 단계에서는 작은 데이터셋으로 작업할 수 있지만, 실제 서비스나 대규모 프로젝트에서는 데이터의 양이 기하급수적으로 늘어납니다. 효율적으로 작성된 코드는 데이터 규모가 커져도 안정적으로 작동하며 확장이 용이합니다.
*   **개발자 생산성:** 코드가 느리게 실행되면 개발자는 결과를 기다리는 데 많은 시간을 소요하게 됩니다. 이는 개발 흐름을 방해하고 전반적인 생산성을 저하시킵니다. 빠른 피드백(feedback)은 더 많은 실험과 개선을 가능하게 합니다.

따라서 데이터프레임을 다룰 때 반복문을 피하고, 판다스(Pandas)와 넘파이(NumPy)의 내장 기능을 최대한 활용하는 것은 데이터 과학자의 핵심 역량 중 하나입니다.

### 2. .iterrows() 활용법과 적절한 사용 시점

.iterrows() 메서드는 모든 판다스 데이터프레임이 지닌 고유한 기능입니다. 이 메서드를 호출하면, 각 행을 순회하며 두 부분으로 구성된 튜플(tuple)을 생성하는 제너레이터(generator) 객체를 반환합니다. 이 제너레이터를 활용해 포커 데이터프레임의 각 행을 처리할 수 있습니다. 튜플의 첫 번째 부분은 해당 행의 색인(index)이고, 두 번째 부분은 각 행이 담고 있는 특성(feature), 즉 다섯 장의 카드별 문양과 순위 정보를 포함하는 판다스 시리즈(Series) 객체입니다. 이는 파이썬(Python)의 `enumerate()` 함수가 리스트(list)의 각 요소와 해당 인덱스를 반환하는 방식과 매우 유사합니다.

먼저, 제너레이터 함수의 개념을 다시 한번 살펴보겠습니다. 제너레이터는 이터레이터(iterator)를 생성하는 간단한 도구이며, 그 본문 안에는 `return` 문 대신 `yield()` 문만 있습니다. `yield()` 문은 하나만 있을 수도 있고 여러 개 있을 수도 있습니다.

여기서는 네 개의 도시 이름을 생성하는 제너레이터인 `city_name_generator()`를 볼 수 있습니다. 간단한 설명을 위해 이 제너레이터를 `city_names` 변수에 할당했습니다.

```python
def city_name_generator():
    yield('New York')
    yield('London')
    yield('Tokyo')
    yield('Sao Paolo')

city_names = city_name_generator()
```

제너레이터가 생성하는 요소에 접근하기 위해 파이썬(Python)의 `next()` 함수를 사용할 수 있습니다. `next()` 명령이 사용될 때마다 제너레이터는 더 이상 생성할 값이 없을 때까지 다음 값을 생성합니다. 우리는 4개의 도시를 가지고 있습니다. `next` 명령을 네 번 실행하여 무엇을 반환하는지 봅시다:

```python
next(city_names)
next(city_names)
next(city_names)
```

보시다시피 `next()` 함수를 실행할 때마다 새로운 도시 이름이 출력됩니다.

판다스 데이터프레임을 반복 처리하는 가장 직관적인 방법은 `range()` 함수를 사용하는 것인데, 이는 종종 '조잡한 반복(crude looping)'이라고 불립니다. 아래 코드에서 이를 보여줍니다:

```python
start_time = time.time()
for index in range(poker_data.shape[0]):
    _ = poker_data.loc[index] # 실제 값 접근을 추가하여 루프가 의미 있도록 함
print("Time using range(): {} sec".format(time.time() - start_time))
```

판다스 데이터프레임을 반복 처리하는 더 현명한 방법은 이 작업에 최적화된 `.iterrows()` 함수를 사용하는 것입니다. 우리는 단순히 각 행의 번호에 대한 이터레이터 하나와 모든 값에 대한 이터레이터 하나, 이렇게 두 개의 이터레이터로 `for` 루프(loop)를 정의합니다.

```python
data_generator = poker_data.iterrows()
start_time = time.time()
for index, values in data_generator:
    _ = values # 실제 값 접근을 추가하여 루프가 의미 있도록 함
print("Time using .iterrows(): {} sec".format(time.time() - start_time))
```

두 계산 시간을 비교해 보면, `.iterrows()`를 사용하는 것이 Pandas DataFrame을 반복 처리하는 속도를 향상시키지 않는다는 것을 알 수 있습니다. 그럼에도 불구하고, `.iterrows()`는 각 행에 대해 복잡한 조건부 논리나 외부 시스템과의 상호작용이 필요한 경우와 같이, 벡터화나 `.apply()`로 처리하기 어려운 특정 상황에서 유용합니다. 예를 들어, 포커 핸드의 복잡한 점수를 계산하는 경우처럼, 각 행의 여러 값을 기반으로 하는 복잡한 규칙을 적용할 때 코드의 가독성을 높일 수 있습니다.

### 3. .apply()를 통한 유연한 데이터 처리

.apply() 메서드는 그 명칭이 시사하는 바와 같이 동작합니다. 즉, 특정 함수를 데이터프레임 전체나 지정된 축(axis)에 걸쳐 적용하는 역할을 합니다. `.apply()` 함수의 문법(syntax)은 간단합니다. 이 경우 람다(lambda) 함수를 사용하여 매핑(mapping)을 생성한 다음, 각 셀(cell)에 적용할 함수를 선언합니다. 여기서는 DataFrame의 모든 셀에 제곱근 함수를 적용하고 있습니다. 속도 면에서는 전체 DataFrame에 NumPy의 `sqrt()` 함수를 직접 사용하는 것과 유사한 효율성을 보입니다.

```python
data_sqrt = poker_data.apply(lambda x: np.sqrt(x))
data_sqrt.head()
```

이것은 이 함수를 DataFrame에 적용하고자 하는 간단한 예시입니다. 하지만 관심 있는 함수가 하나 이상의 셀을 입력으로 받을 때는 어떻게 될까요? 예를 들어, 각 손에 있는 모든 카드의 순위 합계를 계산하고 싶다면 어떨까요? 이 경우, 이전과 동일한 방식으로 `.apply()` 함수를 사용하겠지만, 함수를 각 행에 적용하고 있음을 지정하기 위해 줄 끝에 `‘axis=1’`을 추가해야 합니다.

```python
apply_start_time = time.time()
poker_data[['R1', 'R2', 'R3', 'R4', 'R5']].apply(lambda x: sum(x), axis=1)
apply_end_time = time.time()
apply_time = apply_end_time - apply_start_time
print("Time using .apply(): {} sec".format(apply_time))
```

그런 다음, 이전에 보았던 `.iterrows()` 함수를 사용하여 효율성을 비교할 것입니다.

**제 모든 책들을 40% 할인된 가격에 만나보세요.**

```python
for_loop_start_time = time.time()
for ind, value in poker_data.iterrows():
    _ = sum([value['R1'], value['R2'], value['R3'], value['R4'], value['R5']]) # 컬럼명으로 접근
for_loop_end_time = time.time()
for_loop_time = for_loop_end_time - for_loop_start_time
print("Time using .iterrows(): {} sec".format(for_loop_time))
```

.apply() 함수를 사용하는 것이 .iterrows() 함수보다 약 400% 정도 훨씬 더 빠르며, 이는 엄청난 개선입니다!

```python
print('The difference: {:.2f} %'.format((for_loop_time - apply_time) / apply_time * 100))
```

행에 대해 했던 것처럼 열에 대해서도 동일한 작업을 할 수 있습니다. 즉, 각 열에 하나의 함수를 적용할 수 있습니다. `axis=1`을 `axis=0`으로 바꾸면 모든 열에 합계 함수를 적용할 수 있습니다.

```python
apply_start_time = time.time()
poker_data[['R1', 'R2', 'R3', 'R4', 'R5']].apply(lambda x: sum(x), axis=0)
apply_end_time = time.time()
apply_time = apply_end_time - apply_start_time
print("Time using .apply(): {} sec".format(apply_time))
```

.apply() 함수를 열에 대한 Pandas의 기본 함수와 비교하면, Pandas의 기본 `.sum()` 함수가 동일한 작업을 더 빠르게 수행한다는 것을 알 수 있습니다.

```python
pandas_start_time = time.time()
poker_data[['R1', 'R2', 'R3', 'R4', 'R5']].sum(axis=0) # R1이 두 번 들어가 있던 오타 수정
pandas_end_time = time.time()
pandas_time = pandas_end_time - pandas_start_time
print("Time using pandas native sum(): {} sec".format(pandas_time))
print('The difference: {:.2f} %'.format((apply_time - pandas_time) / pandas_time * 100))
```

결론적으로, `.apply()` 함수는 Pandas DataFrame의 모든 행을 반복 처리할 때 더 빠르게 작동하지만, 동일한 작업을 열을 통해 수행할 때는 Pandas의 내장 벡터화 함수보다 느리다는 것을 알 수 있습니다. 즉, `.apply()`는 벡터화가 어려운 복잡한 로직이나 외부 라이브러리 함수를 적용할 때 유용하며, 특히 행 단위 연산에 강점을 보입니다.

### 4. 벡터화(vectorization) 기법으로 속도 향상

함수가 수행하는 반복 처리의 양을 줄이는 방법을 이해하기 위해, Pandas의 기본 단위인 DataFrame과 Series가 모두 배열(array)을 기반으로 한다는 점을 상기해 봅시다. Pandas는 각 값을 개별적으로 또는 순차적으로 처리하는 것보다 전체 배열에 대해 연산이 수행될 때 더 효율적으로 작동합니다. 벡터화는 전체 배열 단위로 연산을 수행하여 효율성을 극대화하는 기법입니다.

아래 코드에서는 각 손에 있는 모든 카드의 순위 합계를 계산하고자 합니다. 이를 위해 포커 데이터셋을 슬라이싱(slice)하여 각 카드의 순위를 포함하는 열만 유지합니다. 그런 다음, 각 행에 대한 합계를 원한다는 것을 나타내기 위해 `axis = 1` 매개변수(parameter)를 사용하여 DataFrame의 내장 `.sum()` 속성을 호출합니다. 마지막으로, 데이터의 첫 다섯 행의 합계를 출력합니다.

```python
start_time_vectorization = time.time()
poker_data[['R1', 'R2', 'R3', 'R4', 'R5']].sum(axis=1)
end_time_vectorization = time.time()
vectorization_time = end_time_vectorization - start_time_vectorization
print("Time using pandas vectorization: {} sec".format(vectorization_time))
```

이전에 DataFrame의 모든 행을 단순히 반복 처리하는 것보다 DataFrame에 적용된 함수를 더 빠르게 수행하는 다양한 방법들을 살펴보았습니다. 우리의 목표는 이 작업을 수행하는 가장 효율적인 방법을 찾는 것입니다.

.iterrows()를 사용하여 DataFrame 반복 처리하기:

```python
data_generator = poker_data.iterrows()
start_time_iterrows = time.time()
for index, value in data_generator:
    _ = sum([value['R1'], value['R2'], value['R3'], value['R4'], value['R5']])
end_time_iterrows = time.time()
iterrows_time = end_time_iterrows - start_time_iterrows
print("Time using .iterrows() {} seconds " .format(iterrows_time))
```

.apply() 메서드(method) 사용하기:

```python
start_time_apply = time.time()
poker_data[['R1', 'R2', 'R3', 'R4', 'R5']].apply(lambda x: sum(x),axis=1)
end_time_apply = time.time()
apply_time = end_time_apply - start_time_apply
print("Time using apply() {} seconds" .format(apply_time))
```

벡터화, `.iterrows()` 함수, 그리고 `.apply()` 함수를 사용하여 각 손에 있는 모든 카드의 순위를 합산하는 데 걸리는 시간을 비교해 보면, 벡터화 방법이 훨씬 더 나은 성능을 보인다는 것을 알 수 있습니다. 벡터화된 연산은 C(C)나 포트란(Fortran)과 같은 저수준 언어로 구현되어 있어 파이썬(Python) 루프의 오버헤드(overhead) 없이 매우 빠르게 실행됩니다.

DataFrame을 효율적으로 반복 처리하기 위해 NumPy 배열을 사용하여 DataFrame을 벡터화하는 또 다른 벡터화 방법을 사용할 수도 있습니다. 자신을 "파이썬(Python) 과학 계산을 위한 기본 패키지(fundamental package)"라고 정의하는 NumPy 라이브러리(library)는 최적화되고 미리 컴파일(pre-compiled)된 C 코드(code)로 내부적으로 연산을 수행합니다. 배열을 다루는 Pandas와 유사하게, NumPy는 `ndarray`라고 불리는 배열에서 작동합니다. Series와 `ndarray`의 주요 차이점은 `ndarray`가 인덱싱(indexing), 데이터 타입(data type) 확인 등 많은 연산을 생략한다는 것입니다. 결과적으로 NumPy 배열에 대한 연산은 Pandas Series에 대한 연산보다 훨씬 빠를 수 있습니다. Pandas Series가 제공하는 추가 기능이 중요하지 않을 때는 Pandas Series 대신 NumPy 배열을 사용할 수 있습니다. 이 글에서 다루는 문제의 경우, Pandas Series 대신 NumPy `ndarray`를 사용할 수 있습니다. 문제는 이것이 더 효율적인지 아닌지입니다.

다시 한번, 각 손에 있는 모든 카드의 순위 합계를 계산할 것입니다. 우리는 Pandas Series의 `.values` 메서드를 사용하여 순위 배열을 Pandas Series에서 NumPy 배열로 간단히 변환하는데, 이 메서드는 Pandas Series를 NumPy `ndarray`로 반환합니다. Series에 대한 벡터화와 마찬가지로, NumPy 배열을 함수에 직접 전달하면 Pandas는 함수를 전체 벡터(vector)에 적용하게 됩니다.

**제 모든 책들을 40% 할인된 가격에 만나보세요.**

```python
start_time_numpy_vectorization = time.time()
poker_data[['R1', 'R2', 'R3', 'R4', 'R5']].values.sum(axis=1)
end_time_numpy_vectorization = time.time()
numpy_vectorization_time = end_time_numpy_vectorization - start_time_numpy_vectorization
print("Time using NumPy vectorization: {} sec" .format(numpy_vectorization_time))

start_time_pandas_vectorization_again = time.time()
poker_data[['R1', 'R2', 'R3', 'R4', 'R5']].sum(axis=1)
end_time_pandas_vectorization_again = time.time()
pandas_vectorization_time_again = end_time_pandas_vectorization_again - start_time_pandas_vectorization_again
print("Time using Pandas Series vectorization: {} sec" .format(pandas_vectorization_time_again))

print('NumPy vs Pandas Series vectorization difference: {:.2f} %'.format((pandas_vectorization_time_again - numpy_vectorization_time) / numpy_vectorization_time * 100))
```

이 시점에서, Pandas Series에 대한 벡터화가 일상적인 계산에 필요한 최적화 요구 사항의 압도적인 대부분을 충족시킨다는 것을 알 수 있습니다. 하지만 속도가 최우선이라면, NumPy 파이썬(Python) 라이브러리(library)의 형태로 지원을 요청할 수 있습니다. 이전의 최첨단 방법인 Pandas의 최적화와 비교했을 때도, 여전히 작동 시간에서 개선을 얻을 수 있습니다.

### 5. `df.eval()` 및 `df.query()`로 표현식 처리

Pandas는 복잡한 수치 또는 불리언(boolean) 표현식을 효율적으로 처리하기 위한 `df.eval()` 및 `df.query()` 메서드를 제공합니다. 이들은 문자열(string) 기반의 표현식을 사용하여 내부적으로 최적화된 엔진(engine)으로 연산을 수행하므로, 일반적인 파이썬(Python) 연산보다 훨씬 빠를 수 있습니다. 특히 대규모 데이터프레임에서 여러 열에 걸친 연산이나 조건부 필터링(filtering)에 매우 효과적입니다.

`df.eval()`은 새 열을 생성하거나 기존 열을 수정할 때 유용합니다.

```python
eval_start_time = time.time()
poker_data.eval('R_sum = R1 + R2 + R3 + R4 + R5', inplace=True)
eval_end_time = time.time()
print("Time using df.eval(): {} sec".format(eval_end_time - eval_start_time))
poker_data.head()
```

`df.query()`는 특정 조건에 맞는 행을 빠르게 필터링하는 데 사용됩니다.

```python
query_start_time = time.time()
high_rank_hands = poker_data.query('R1 > 10 and R5 > 10')
query_end_time = time.time()
print("Time using df.query(): {} sec".format(query_end_time - query_start_time))
high_rank_hands.head()
```

이 메서드들은 가독성을 높이고 중간 변수를 생성할 필요 없이 복잡한 연산을 수행할 수 있게 해줍니다.

### 6. `swifter` 라이브러리를 이용한 자동 최적화

때로는 `.apply()`가 필요하지만, 그 성능이 아쉬울 때가 있습니다. 이때 `swifter` 라이브러리가 유용합니다. `swifter`는 사용자가 `df.apply()`를 호출할 때, 내부적으로 해당 연산을 벡터화할 수 있는지 자동으로 분석하고, 가능하다면 넘파이(NumPy) 또는 Dask(대규모 데이터 처리 라이브러리)를 사용하여 병렬(parallel) 처리로 전환하여 실행 속도를 최적화합니다. 벡터화가 어렵거나 데이터가 너무 작으면 일반 `.apply()`를 사용합니다.

`swifter`를 사용하려면 먼저 설치해야 합니다: `pip install swifter`

```python
import swifter

swifter_start_time = time.time()
poker_data[['R1', 'R2', 'R3', 'R4', 'R5']].swifter.apply(lambda x: sum(x), axis=1)
swifter_end_time = time.time()
swifter_time = swifter_end_time - swifter_start_time
print("Time using swifter.apply(): {} sec".format(swifter_time))
print(f"swifter.apply() vs pandas.apply() speedup: {apply_time / swifter_time:.2f}x")
```

`swifter`는 `.apply()`의 유연성을 유지하면서도, 가능한 한 최적의 성능을 자동으로 찾아주므로, 복잡한 커스텀(custom) 함수를 적용할 때 매우 강력한 도구가 될 수 있습니다.

### 7. 성능 최적화를 위한 추가 고려사항

데이터프레임 처리 성능을 더욱 향상시키기 위한 몇 가지 추가적인 팁(tip)들이 있습니다.

*   **적절한 데이터 타입(Data Types) 사용:** Pandas는 기본적으로 `int64`나 `float64`와 같은 넓은 범위의 데이터 타입을 사용합니다. 하지만 실제 데이터의 범위가 작다면 `int8`, `float32` 등으로 데이터 타입을 명시적으로 변경하면 메모리 사용량을 줄이고 연산 속도를 높일 수 있습니다. 예를 들어, 포커 카드의 순위는 1에서 13 사이이므로 `int8`로 충분합니다.

    ```python
    # 데이터 타입 변경 예시
    for col in ['R1', 'R2', 'R3', 'R4', 'R5']:
        poker_data[col] = poker_data[col].astype(np.int8)
    print(poker_data.dtypes)
    ```

*   **메서드 체이닝(Method Chaining) 활용:** 여러 연산을 순차적으로 수행할 때, 각 단계마다 새로운 데이터프레임을 생성하는 대신 메서드 체이닝을 사용하면 중간 객체 생성을 줄여 메모리 사용량과 실행 시간을 최적화할 수 있습니다.

    ```python
    # 체이닝 예시
    optimized_data = poker_data.copy().query('S1 == 1').assign(R_avg = lambda df: df[['R1','R2','R3','R4','R5']].mean(axis=1))
    ```

*   **Numba 또는 Cython(사이썬) 고려:** 극단적인 성능 요구 사항이 있는 경우, Numba나 Cython과 같은 라이브러리를 사용하여 파이썬(Python) 코드를 저수준 언어로 컴파일(compile)하여 실행 속도를 대폭 향상시킬 수 있습니다. 이는 복잡한 계산이나 반복적인 작업이 병목 현상(bottleneck)을 일으킬 때 특히 유용합니다.

### 8. DataFrame 반복 처리를 위한 모범 사례 요약 및 결론

**구독자 2만 명 특별 할인**

데이터프레임의 효율적인 반복 처리는 현대 데이터 과학에서 매우 중요한 기술입니다. 지금까지 살펴본 방법들을 통해 다음의 모범 사례들을 정리할 수 있습니다.

*   **.iterrows()**: 데이터프레임 반복 처리의 속도를 직접적으로 높이지는 않으나, 각 행에 대해 복잡한 조건부 논리나 외부 시스템과의 상호작용이 필요한 경우와 같이, 벡터화나 `.apply()`로 처리하기 어려운 특정 상황에서 코드의 가독성을 높이고 디버깅(debugging)에 유용합니다.
*   **.apply()**: 데이터프레임의 행별 처리에 있어 뛰어난 속도를 보이지만, 열별 작업에서는 기본 판다스 함수보다 느릴 수 있습니다. 벡터화가 어려운 복잡한 커스텀 함수나 외부 라이브러리 함수를 적용할 때 유연하게 사용할 수 있습니다.
*   **벡터화(Pandas/NumPy)**: 대부분의 일반적인 연산에 필요한 최적화는 판다스 시리즈의 벡터화만으로 충분합니다. 그러나 최고 수준의 속도 향상이 필요할 때는 파이썬 NumPy 라이브러리의 강력한 기능을 활용하여 `ndarray`로 직접 연산하는 것이 권장됩니다. 이는 저수준 언어로 구현된 최적화된 연산을 활용하기 때문입니다.
*   **`df.eval()` 및 `df.query()`**: 문자열 기반의 복잡한 수치 또는 불리언 표현식을 처리할 때 매우 효율적입니다. 대규모 데이터프레임에서 필터링 및 새 열 생성 시 성능과 가독성을 동시에 잡을 수 있습니다.
*   **`swifter`**: `df.apply()`의 유연성을 유지하면서 자동으로 벡터화 또는 병렬 처리 가능성을 탐색하여 최적의 성능을 제공하는 편리한 도구입니다. 커스텀 함수 적용 시 성능 향상을 시도할 때 좋은 출발점이 됩니다.
*   **추가 고려사항**: 데이터 타입을 적절히 설정하고, 메서드 체이닝을 통해 중간 객체 생성을 줄이며, 필요한 경우 Numba나 Cython을 고려하는 것은 전반적인 코드의 효율성을 극대화하는 데 기여합니다.

이 뉴스레터(newsletter)는 개인적인 열정 프로젝트(project)이며, 여러분의 지원이 이를 유지하는 데 도움이 됩니다. 기여하고 싶으시다면 몇 가지 좋은 방법이 있습니다: 구독하기. 유료 구독은 제 글쓰기를 지속 가능하게 하고 추가 콘텐츠(content)에 대한 접근 권한을 제공합니다.* 제 책 번들(bundle)을 구매하세요. 제 7권의 실용서와 로드맵(roadmap)을 40% 할인된 가격으로 만나보세요.

읽어주셔서 감사드리며, 독립적인 글쓰기와 연구를 지원해 주셔서 감사합니다!