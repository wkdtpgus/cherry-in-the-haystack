안녕하세요 여러분! 신규 구독자 또는 청취자이시라면 다시 한번 환영합니다. 기존 구독자/청취자이시라면 최근 저희 활동에 약간의 변화가 있었음을 눈치채셨을 겁니다. 휴 장(Hugh Zhang), 안드레이 쿠렌코프(Andrey Kurenkov)와 저는 함께 앉아 더 그레디언트(The Gradient)의 지난 여정, 현재 위치, 그리고 앞으로 나아갈 방향에 대해 논의하는 시간을 가졌습니다.

그 배경을 간략히 설명드리자면: 더 그레디언트는 이제 약 7년 전 온라인 매거진으로 첫걸음을 떼었으며, 약 5년 전부터 자체 뉴스레터와 팟캐스트를 제작하기 시작했습니다. 자원봉사자 팀과 함께 — 저희는 필요한 도구 구독료로 사용하고 저희 자신에게도 약간의 보수를 지급하기 위해 서브스택(Substack)을 통해 약간의 수익을 얻고 있습니다 — 꽤 오랫동안 이 활동을 지속할 수 있었습니다. 하지만 현재 저희 팀은 원하는 만큼의 여력이 부족하며, 솔직히 말씀드리자면 저희 중 일부는 거의 한계에 다다랐습니다. 이러한 상황 속에서 몇 가지 중요한 변경 사항을 적용하게 되었습니다.

**매거진**: 매거진 편집 작업을 축소할 예정입니다. 현재로서는 미작성된 초고에 대한 제안(pitch)은 받지 않겠지만, 완성된 글을 저희에게 제안하고 싶으시다면 게재를 고려하겠습니다. 지난 한 해 동안 글쓰기와 관련하여 저희에게 연락하셨음에도 불구하고 답을 받지 못하셨다면 진심으로 사과드립니다. 저희는 들어오는 기사들을 관리하기 위해 몇 가지 새로운 방식을 시도했지만, 이를 효과적으로 운영하기는 쉽지 않았습니다. 저희는 여전히 이곳이 ML 커뮤니티(ML community)의 훌륭한 작업과 글을 홍보하는 중요한 플랫폼이 되기를 바라며, 따라서 이 서브스택(Substack)을 그 목적으로 계속 사용할 계획입니다. 앞으로 저희 팀에 편집 역량이 더 확보된다면, 해당 작업을 다시 활성화할 수 있기를 기대합니다.

**뉴스레터**: 뉴스레터는 이전과 같이 계속 발행될 예정입니다. 특히 지난 업데이트에서 예고했던 "커뮤니티 베스트(Best from the Community)" 섹션은 성공적으로 자리매김하여, ML 커뮤니티 내의 뛰어난 게시물들을 꾸준히 조명하고 있습니다. 여러분이 소개되기를 원하는 기사를 보내는 방법은 이제 명확히 안내되어 있지만, 여전히 editor@thegradient.pub으로 연락 주시면 됩니다. 이 섹션은 독자들에게 다양한 관점을 제공하는 데 크게 기여하고 있습니다.

**팟캐스트**: 저는 이 팟캐스트를 계속 진행할 예정이지만 (더 느린 속도로), 확장된 범위를 고려하여 궁극적으로 더 그레디언트(The Gradient)와는 분리될 것입니다. 지난 해부터 팟캐스트는 '더 그레디언트 인사이트(The Gradient Insights)'라는 새로운 이름으로 독립적인 채널을 운영하며 더욱 심층적인 AI 및 ML 동향 분석을 제공하고 있습니다. 계속해서 시청/청취하고 싶으시다면, 애플 팟캐스트(Apple Podcasts), 스포티파이(Spotify)와 같은 주요 플랫폼이나 RSS 피드(RSS feed)를 통해 구독하는 것이 가장 좋습니다.

**시그모이드 소셜(Sigmoid Social)**: 재정적 지원이 있는 한 이 활동을 계속 유지할 것입니다. 지난 한 해 동안 보내주신 많은 관심과 지원에 깊이 감사드립니다. 저희의 활동이 마음에 드시거나 어떤 방식으로든 저희를 돕고 싶으시다면, 언제든지 editor@thegradient.pub으로 연락 주십시오. 여러분의 소중한 의견을 듣는 것을 언제나 환영합니다.

**타임스탬프** (이전 논의 요약)
(0:00) 소개
(01:55) 더 그레디언트(The Gradient)의 시작
(03:23) 변경 사항 및 공지
(10:10) 더 그레디언트(The Gradient)의 더 많은 역사! 저희의 참여, 좋아하는 기사, 그리고 몇 가지 홍보

저희가 가장 좋아하는 기사들! (이 목록은 너무 많아 모든 것을 담지 못합니다):
*   NLP의 이미지넷(ImageNet) 순간이 도래했다
*   2019년 머신러닝 프레임워크(Machine Learning Frameworks)의 현황
*   변혁적 인공지능(artificial intelligence)이 정말, 정말 달성하기 어려운 이유
*   AI 스토리 생성(AI Story Generation) 입문
*   정렬의 인위성(Artificiality of Alignment) (에피소드에서는 언급하지 않았지만 여기에 포함되어야 합니다)
*   최신 LLM 추론 능력 분석: 새로운 평가 지표와 접근법

저희를 찾을 수 있는 곳!
**휴(Hugh)**:
*   트위터(Twitter)
*   개인 웹사이트

**안드레이(Andrey)**:
*   트위터(Twitter)
*   개인 웹사이트
*   지난주 AI 팟캐스트(Last Week in AI Podcast)

**다니엘(Daniel)**:
*   트위터(Twitter)
*   서브스택 블로그(Substack blog)
*   개인 웹사이트 (업데이트 완료)

**더 그레디언트 공식 채널:**
*   공식 웹사이트: thegradient.pub
*   링크드인(LinkedIn) 페이지

언급된 논문/자료!
*   초등학교 산수(Grade School Arithmetic, GSM1k)에서 LLM(LLM) 성능에 대한 면밀한 조사
*   자연어(Natural Language)를 통한 계획이 코드 생성(Code Generation)을 위한 LLM(LLM) 검색을 개선한다
*   인류의 마지막 시험
*   2024년 최신 대규모 언어 모델(LLM)의 윤리적 고려사항