카라바조의 <나르키소스>, 약 1600년

최근 몇 년간 인공지능(AI) 기술의 발전은 눈부십니다. 매일같이 새로운 모델과 기능이 발표되고, 인류의 삶을 송두리째 바꿀 것이라는 장밋빛 전망부터 인류의 종말을 초래할 것이라는 비관적인 경고까지, 수많은 담론이 쏟아져 나옵니다. 이러한 정보의 홍수 속에서 우리는 종종 기술 자체의 본질보다는 과장되거나 왜곡된 서사에 더 쉽게 노출되곤 합니다. 특히 소셜 미디어와 일부 언론 매체는 조회수와 영향력을 위해 복잡한 기술적 함의를 단순화하거나 극단적인 시각으로 포장하는 경향이 있습니다. 이는 AI에 대한 건전한 이해를 방해하고, 불필요한 기대감이나 근거 없는 공포를 조장하는 결과를 낳습니다. 기술 발전의 속도가 빨라질수록, 우리는 이러한 정보의 파고를 헤쳐나갈 비판적 사고 능력을 더욱 절실히 요구받고 있습니다. AI 기술이 가진 진정한 잠재력과 한계를 정확히 파악하는 것이야말로 이 기술을 현명하게 활용하고 미래를 준비하는 첫걸음일 것입니다.

그럼에도 불구하고, 저는 AI 산업이 잘못된 특성 부여(mischaracterization)로 인해 약화되고 있다는 점에 대해 두 가지 이유로 기쁩니다. 1) ChatGPT가 출시된 이후로 단 하루도 AI 과장 선전 기계(AI Hype Machine)를 끄지 않았기 때문에 이러한 대우를 받을 자격이 있습니다. 2) 이것이 과장된 약속의 기계에 대한 유일한 가능한 대응책이기 때문입니다. 모든 정보 시장은 결국 그에 상응하는 반대편을 찾게 됩니다. 친(親)AI 전도사들로 포화되자, 이제는 반대 진영의 차례가 된 것입니다. 흑과 백, 음과 양. 저는 균형 잡힌 우주를 좋아하며, 앵무새들의 아수라장 같은 **퓨처리즘(Futurism)**은 겸손하고 자기희생적이며 혼란스러운 균형 잡기 행위를 수행합니다. 그것은 필요악입니다. (하지만 저는 특정 뉴스 사이트 하나만을 지목하고 싶지는 않습니다. 전통적으로 기술 친화적인 출판물들을 포함하여 많은 곳들이 이 반물질 파이(anti-matter pie)의 한 조각을 차지하기 위해 경쟁하고 있으며, 증오의 물결이 돈벌이 없이 지나가도록 내버려두려 하지 않습니다.)

이러한 정보 시장의 양극화는 AI 기술의 복잡성과 파급력 때문에 더욱 두드러집니다. 기술 기업들은 투자 유치와 시장 선점을 위해 자신들의 비전(vision)을 과감하게 제시하며, 때로는 실현 가능성보다 잠재적 파급력에 초점을 맞춥니다. '인공 일반 지능(AGI)이 임박했다'는 식의 주장은 기술 개발자들에게는 동기 부여가 될 수 있지만, 대중에게는 불필요한 공포나 비현실적인 기대를 심어줄 수 있습니다. 이러한 과장된 약속은 단순한 마케팅을 넘어, 때로는 특정 기술의 한계를 의도적으로 가리거나, 경쟁사 대비 우위를 점하기 위한 전략적 도구로 활용되기도 합니다. 반대편에서는 이러한 과장된 선전에 대한 반작용으로, AI의 한계나 부작용만을 부각하며 기술 전체를 폄하하는 경향이 나타납니다. 예를 들어, 특정 AI 모델이 보인 사소한 오류나 윤리적 편향(bias)이 전체 AI 기술의 실패를 의미하는 것처럼 확대 해석되기도 하며, AI의 발전이 일자리 감소나 사회적 불평등 심화로 이어질 것이라는 극단적인 예측이 쏟아져 나오기도 합니다. 이러한 상황은 마치 거울상처럼 서로를 반영하며, AI에 대한 건전한 논의를 방해하는 주요 요인이 됩니다. 대중은 어디까지가 사실이고 어디부터가 과장인지 구분하기 어려운 정보의 미로 속에서 혼란스러워하며, 결국 AI에 대한 피상적인 이해만을 갖게 됩니다. 이는 기술 발전을 올바른 방향으로 이끌고 사회적 합의를 형성하는 데 큰 걸림돌이 됩니다.

참고로, OpenAI뿐만 아니라 전체 산업이 이렇습니다. 그들은 마케팅(marketing)의 신들이 항상 그들의 몫을 요구한다는 것을 깨닫지 못한 채 능수능란한 사기꾼(trickster)처럼 행동합니다. 인식이 시장을 지배한다면, 일반 대중이 설파하는 것은 근본적인 현실과 전혀 닮지 않았더라도 복음이 됩니다. 그리고 이 복음이 업계 리더(leader)들에게 좋든 나쁘든, 그들에게는 오직 한 가지 선택만이 있습니다. 바로 합창에 동조하는 것입니다. 알트만은 더 버지(The Verge)에 GPT-5 출시를 “망쳤다”고 말하고 싶지 않았을 것입니다 (아마도 그는 그것이 사실이라고 생각하지도 않았을 것입니다. 그들이 망친 것은 GPT-5 제품 자체가 아니라 얼마나 많은 사용자들이 GPT-4o를 사랑하는지 깨닫지 못한 것이었습니다). 그는 자신의 말이 특정 이야기를 밀어붙이는 데 사용될 것임을 알았지만, 벗어날 방법이 없었습니다. 말이 아닌 내용만이 중요하다고 생각하며 게임을 한다면, 세상이 당신에게 똑같은 기준을 적용할 때 놀라지 마십시오.

이처럼 '인식이 시장을 지배한다'는 원칙은 AI 기술의 현실과 대중의 이해 사이에 깊은 괴리를 만듭니다. 학계나 연구 기관에서 발표되는 연구 결과조차도 종종 이러한 인식의 틀 안에서 재해석되거나 오용되곤 합니다. 예를 들어, 'AI 사용이 인지 능력 저하를 초래한다'는 연구가 특정 조건 하의 제한적인 결과를 일반화하여 보도되거나, 'AI 프로젝트의 높은 실패율'이라는 통계가 표본의 대표성이나 방법론의 한계는 간과된 채 선정적으로 유통되는 경우가 흔합니다. 심지어 'AI가 인간보다 느리다'는 식의 결론은 오래된 모델이나 특정 작업 환경에만 국한될 수 있음에도 불구하고, 모든 AI 기술의 무용론으로 이어지기도 합니다. 이는 AI가 가진 실제 가치를 제대로 평가하지 못하게 할 뿐만 아니라, 중요한 정책 결정이나 산업 투자 방향에도 부정적인 영향을 미칠 수 있습니다. 기업들은 과장된 약속에 기반한 솔루션(solution)을 도입하려다 실망하고, 정부는 잘못된 정보에 근거하여 규제를 만들거나 투자를 집행할 위험에 처하게 됩니다. AI 기술이 사회 전반에 미치는 영향이 커질수록, 정확하고 균형 잡힌 정보의 중요성은 더욱 강조되어야 합니다. 기술 개발자들은 자신들의 연구와 제품에 대해 더 큰 책임감을 가지고 투명하게 소통해야 하며, 언론은 단편적인 소식보다는 깊이 있는 분석과 비판적 검증을 통해 대중의 이해를 도와야 합니다. 또한, 우리 각자는 AI에 대한 정보를 접할 때, 그 출처와 맥락을 꼼꼼히 살피고 스스로 판단하는 능력을 길러야 합니다. AI 시대의 진정한 성숙은 기술적 진보와 더불어 정보의 투명성, 그리고 비판적 사고의 함양에서 비롯될 것입니다. 극단적인 주장보다는 실용적이고 현실적인 접근이 필요한 시점입니다.

구독하기