카라바조의 <나르키소스>, 약 1600년

최근 몇 년간 인공지능(AI) 기술의 발전은 눈부십니다. 매일같이 새로운 모델과 기능이 발표되고, 인류의 삶을 송두리째 바꿀 것이라는 장밋빛 전망부터 인류의 종말을 초래할 것이라는 비관적인 경고까지, 수많은 담론이 쏟아져 나옵니다. 이러한 정보의 홍수 속에서 우리는 종종 기술 자체의 본질보다는 과장되거나 왜곡된 서사에 더 쉽게 노출되곤 합니다. 특히 소셜 미디어와 일부 언론 매체는 조회수와 영향력을 위해 복잡한 기술적 함의를 단순화하거나 극단적인 시각으로 포장하는 경향이 있습니다. 이는 AI에 대한 건전한 이해를 방해하고, 불필요한 기대감이나 근거 없는 공포를 조장하는 결과를 낳습니다. 기술 발전의 속도가 빨라질수록, 우리는 이러한 정보의 파고를 헤쳐나갈 비판적 사고 능력을 더욱 절실히 요구받고 있습니다. AI 기술이 가진 진정한 잠재력과 한계를 정확히 파악하는 것이야말로 이 기술을 현명하게 활용하고 미래를 준비하는 첫걸음일 것입니다.

저는 **퓨처리즘(Futurism)**을 좋아합니다. 이 매체가 다루는 이야기들이 질이 낮다는 것을 쉽게 알아챌 수 있기 때문에 (종종 나쁘지만 왜 나쁜지 정확히 짚어내기 어려운 AI가 작성한 산문과는 다르게) 훌륭한 배출구입니다. 또한, AI를 잠재적으로 유익한 기술로 여기는 데는 관심이 적지만, AI에 대한 과장된 선전을 반박하여 영향력을 얻는 데는 관심이 많은 모든 사람들이 이 매체를 끊임없이 인용할 것이기 때문에 훌륭합니다. 하지만 제가 이 잡지를 좋아하는 주된 이유는 새로운 종류의 AI 인플루언서(influencer)가 등장하는 데 기여했기 때문입니다. 이들은 업계의 발전을 끊임없이 잘못 전달하는 유형입니다 (때로는 의도치 않게).

“ 저는 AI 산업에 대한 모든 신뢰를 잃고 있습니다 ”와 같은 기사를 쓴 저자로서, 저는 공모 혐의를 받기 어렵습니다. 하지만 무엇보다 저는 진실에 충실해야 하므로 말씀드리겠습니다. 이 산업은 자신들이 만드는 모든 것을 여러분에게 팔기 위해 온갖 노력을 다할 것이지만, 그 중 상당 부분은 어쨌든 합법적입니다. 제 말은, 여러분은 ChatGPT에 로그인하여 해결하지 못하는 극단적인 사례(edge cases)에 집중할 수도 있고, 2022년 이전에는 어떤 다른 기술도 할 수 없었던 많은 일들에 집중할 수도 있다는 것입니다. 그것은 여러분의 선택입니다. 저의 선택은 양쪽 모두를 보는 것입니다.

그럼에도 불구하고, 저는 AI 산업이 잘못된 특성 부여(mischaracterization)로 인해 약화되고 있다는 점에 대해 두 가지 이유로 기쁩니다. 1) ChatGPT가 출시된 이후로 단 하루도 AI 과장 선전 기계(AI Hype Machine)를 끄지 않았기 때문에 이러한 대우를 받을 자격이 있습니다. 2) 이것이 과장된 약속의 기계에 대한 유일한 가능한 대응책이기 때문입니다. 모든 정보 시장은 결국 그에 상응하는 반대편을 찾게 됩니다. 친(親)AI 전도사들로 포화되자, 이제는 반대 진영의 차례가 된 것입니다. 흑과 백, 음과 양. 저는 균형 잡힌 우주를 좋아하며, 앵무새들의 아수라장 같은 **퓨처리즘(Futurism)**은 겸손하고 자기희생적이며 혼란스러운 균형 잡기 행위를 수행합니다. 그것은 필요악입니다. (하지만 저는 특정 뉴스 사이트 하나만을 지목하고 싶지는 않습니다. 전통적으로 기술 친화적인 출판물들을 포함하여 많은 곳들이 이 반물질 파이(anti-matter pie)의 한 조각을 차지하기 위해 경쟁하고 있으며, 증오의 물결이 돈벌이 없이 지나가도록 내버려두려 하지 않습니다.)

이러한 정보 시장의 양극화는 AI 기술의 복잡성과 파급력 때문에 더욱 두드러집니다. 기술 기업들은 투자 유치와 시장 선점을 위해 자신들의 비전(vision)을 과감하게 제시하며, 때로는 실현 가능성보다 잠재적 파급력에 초점을 맞춥니다. '인공 일반 지능(AGI)이 임박했다'는 식의 주장은 기술 개발자들에게는 동기 부여가 될 수 있지만, 대중에게는 불필요한 공포나 비현실적인 기대를 심어줄 수 있습니다. 이러한 과장된 약속은 단순한 마케팅을 넘어, 때로는 특정 기술의 한계를 의도적으로 가리거나, 경쟁사 대비 우위를 점하기 위한 전략적 도구로 활용되기도 합니다. 반대편에서는 이러한 과장된 선전에 대한 반작용으로, AI의 한계나 부작용만을 부각하며 기술 전체를 폄하하는 경향이 나타납니다. 예를 들어, 특정 AI 모델이 보인 사소한 오류나 윤리적 편향(bias)이 전체 AI 기술의 실패를 의미하는 것처럼 확대 해석되기도 하며, AI의 발전이 일자리 감소나 사회적 불평등 심화로 이어질 것이라는 극단적인 예측이 쏟아져 나오기도 합니다. 이러한 상황은 마치 거울상처럼 서로를 반영하며, AI에 대한 건전한 논의를 방해하는 주요 요인이 됩니다. 대중은 어디까지가 사실이고 어디부터가 과장인지 구분하기 어려운 정보의 미로 속에서 혼란스러워하며, 결국 AI에 대한 피상적인 이해만을 갖게 됩니다. 이는 기술 발전을 올바른 방향으로 이끌고 사회적 합의를 형성하는 데 큰 걸림돌이 됩니다.

하지만 상황은 기자들이 시대정신(zeitgeist)을 시의적절하게 읽어내어 자신들의 영역을 개척하는 것보다 더 심각합니다. 어쨌든, 그들이 대중을 지휘하는 능력은 칭찬받을 만합니다. 아마도 결국 일반 대중에게까지 미칠 더 광범위한 패러다임 전환(paradigm shift)이 있다는 가장 분명한 징후는, 한때 업계의 가장 큰 비평가로 선전되었던 게리 마커스(Gary Marcus)가 이제는 동료 회의론자들에 비해 온건해졌다는 점일 것입니다. 뉴요커(The New Yorker)는 8월 12일, “GPT-5 출시 이후, AI에 대한 과장된 예측을 액면 그대로 받아들이기가 더욱 어려워졌으며, 마커스와 같은 비평가들의 견해는 점점 더 온건해지는 것처럼 보인다”고 썼습니다. 한 번의 출시 실패로 그들은 당신을 끝장냅니다. 실제로, GPT-5 출시가 왜 “실패”했는지 검토해 봅시다. 왜냐하면 이는 업계가 잘못된 특성 부여(mischaracterization)를 받을 자격이 있는 이유와 그러한 잘못된 특성 부여가 애초에 어떻게 발생하는지를 보여주는 훌륭한 예시이기 때문입니다.

데모 이후 몇 주 동안 몇 가지 주제가 대화를 지배했습니다. 잘못된 라벨이 붙은 두 개의 차트가 트위터(Twitter)에서 조롱당하고 밈(meme)화되었습니다. r/ChatGPT 서브레딧(subreddit)은 GPT-5의 성격이 충분히 매력적이지 않다는 이유로 OpenAI에 GPT-4o를 다시 가져오라고 집단적으로 요구했습니다. 벤치마크(benchmark) 점수는 좋았지만, 언론 보도와 샘 알트만(Sam Altman) CEO의 거창한 발언을 고려할 때 예상했던 것만큼 강력하지는 않았습니다. 알트만은 더 버지(The Verge)와의 인터뷰에서 “출시 과정에서 몇 가지를 완전히 망쳤다”고 인정했습니다. 그래서 기본적으로, 슬라이드(slide) 실수, 소프트웨어(software) 업데이트(절대 그런 일은 없지만)로 인한 화난 고객들, 그리고 투자자들의 귀에 속삭이는 CEO의 발언이 맥락에서 벗어나 인용된 것 등이 있었습니다. 다른 어떤 AI 모델도 부러워할 것이 없는 (오히려 다른 대부분의 모델들이 GPT-5를 부러워할 만한) AI 모델이 대중의 여론에서 그렇게 부정적인 평가(negative valence)를 받게 되었다는 것은 (OpenAI에게는 아니지만 저에게는) 흥미로운 일입니다. 제가 온라인에서 교류하는 놀랍도록 많은 사람들이 GPT-5가 실패작이었다고 생각합니다 (소수의 기술 전문가들은 그렇지 않다는 것을 알고 있고, 대부분의 사람들은 단순히 신경 쓰지 않습니다). 하지만 저는 예측했습니다. 이런 일이 일어날 줄 알았습니다. 출시 4일 전, 저는 GPT-5가 “ 불공정한 실망 ”으로 취급될 것이라고 썼습니다. 불공정한 이유는 그것이 좋을 것이고(그리고 저렴할 것이라고) 알았기 때문이고, 실망스러운 이유는 불가능한 기대를 마주했기 때문입니다. 그것이 핵심이죠? 모든 것은 기대치에 비해서만 좋거나 나쁩니다. 그렇다면 GPT-5에 대한 이러한 노골적인 오해(misrepresentation)에 대해 누구를 비난해야 할까요? 슬라이드(slide)를 만든 인턴(intern)? 이전 버전을 원했던 중독된 레디터(redditors)들? 벤치마크(benchmark)를 최고치로 만들도록 허용한 디자이너(designer)들? 뻔한 질문을 한 인터뷰어(interviewer)들? 아니면 샘 알트만(Sam Altman)과 그의 측근들이 자신들이 하는 모든 것을 과장하는 것(그것이 진정한 열정이든 과시적인 부족주의이든 중요하지 않다고 생각합니다)에 잘못이 있을까요?

참고로, OpenAI뿐만 아니라 전체 산업이 이렇습니다. 그들은 마케팅(marketing)의 신들이 항상 그들의 몫을 요구한다는 것을 깨닫지 못한 채 능수능란한 사기꾼(trickster)처럼 행동합니다. 인식이 시장을 지배한다면, 일반 대중이 설파하는 것은 근본적인 현실과 전혀 닮지 않았더라도 복음이 됩니다. 그리고 이 복음이 업계 리더(leader)들에게 좋든 나쁘든, 그들에게는 오직 한 가지 선택만이 있습니다. 바로 합창에 동조하는 것입니다. 알트만은 더 버지(The Verge)에 GPT-5 출시를 “망쳤다”고 말하고 싶지 않았을 것입니다 (아마도 그는 그것이 사실이라고 생각하지도 않았을 것입니다. 그들이 망친 것은 GPT-5 제품 자체가 아니라 얼마나 많은 사용자들이 GPT-4o를 사랑하는지 깨닫지 못한 것이었습니다). 그는 자신의 말이 특정 이야기를 밀어붙이는 데 사용될 것임을 알았지만, 벗어날 방법이 없었습니다. 말이 아닌 내용만이 중요하다고 생각하며 게임을 한다면, 세상이 당신에게 똑같은 기준을 적용할 때 놀라지 마십시오.

이러한 현상은 지난 몇 달 동안 너무나 만연하여, AI 산업에 대한 피상적인 비판을 반박하는 것만큼이나 AI 산업의 피상적인 과장 선전을 반박하는 많은 기사 아이디어(article ideas)의 원천이 되었습니다. 여러분은 제 일을 쉽게 만들고 있습니다. 그리고 사실, 여러분은 제가 오래전에 썼던, 방어하기 더 어려울 것이라고 생각했던 것을 입증하고 있습니다. 극단적인 과장론자(hypers)와 반과장론자(anti-hypers)는 종종 같은 부류이며, 둘 다 소셜 미디어(social media)의 영향력(clout)을 위해 진실의 어떤 씨앗이라도 터무니없이 과장하는 것을 좋아합니다. 처음부터 끝까지 슬픈 상황입니다. 하지만 저는 우는 것보다 웃는 것을 선호합니다.

MIT 연구에서 ChatGPT를 사용하는 사람들이 필연적으로 더 멍청해지고 있다고 말하고 사람들이 뇌 손상(brain rot)에 대해 비관적인 예측을 할 때, 저는 그 연구 전체를 직접 읽고 다른 결론이 있을 수 없다는 것을 알면서도 웃습니다. 그 결론은 AI가 인지 능력을 저하시킬 수 있지만, 특정 조건 하에서만 그렇다는 것입니다. 즉, 뇌를 사용하기 전에 문제 해결을 위해 AI에 과도하게 의존할 때 말입니다. 또 다른 MIT 연구에서 생성형 AI(generative AI) 파일럿(pilot) 프로젝트의 95%가 실패하고 있다고 말하고 사람들이 95라는 숫자가 크다는 이유로 이 소식을 사방에 공유할 때, 저는 표본이 작고(52개 인터뷰), 방법론이 취약하며, 주 저자(lead author) 자신이 실패의 원인이 기술의 낮은 품질이 아니라 현재 모델(model)들이 맥락적이고 지속적으로 학습하지 않을 때 워크플로우(workflow) 통합이 어렵기 때문이라고 주장했다는 것을 알면서도 웃습니다. METR 무작위 대조 시험(randomized controlled trial, 금본위제)이 “개발자들이 AI 도구(tool)를 사용할 때, 사용하지 않을 때보다 19% 더 오래 걸린다—AI가 그들을 더 느리게 만든다”고 결론 내리고 사람들이 생성형 AI(generative AI)를 “킬러 앱(killer app)”조차도 쓸모없다고 미친 듯이 비난할 때, 저는 그 연구가 오래된 모델(model)들을 대상으로 했고, 자신들의 저장소(repository)에 익숙한 프로그래머(programmer)들을 대상으로 했으며, 인간의 실패(예: AI가 더 오래 걸린다고 생각하는 것)를 고려하지 않았다는 구체적인 사실들이 결과를 올바르게 해석하는 데 필수적이라는 것을 알면서도 웃습니다. 애플(Apple) 논문이 AI 사고가 “환상(illusion)”이라고 말하고 사람들이 권위 있는 주장(애플이잖아!)을 사용하여 이를 옹호할 때, 저는 그 결과가 다양한 오해에 기반하고 있다는 것을 알면서도 웃습니다. 명시적인 추론 흔적(explicit reasoning traces)은 모델(model)의 실제 사고를 반영하지 않으며, 스크래치패드(scratchpad) 없이는 “정확도 붕괴(accuracy collapse)” 현상이 예상됩니다—심지어 인간에게서도 말입니다! 이번 주 초 하버드 비즈니스 리뷰(Harvard Business Review)가 “직원들이 AI 도구(tool)를 사용하여 적은 노력으로 그럴듯해 보이는 작업을 만들고, 이는 결국 동료들에게 더 많은 작업을 초래한다”—그들이 **워크슬롭(workslop)**이라고 명명한 현상—고 보도하고 이 새로운 유행어(buzzword)가 입소문을 탈 때, 저는 이 결과가 AI가 나쁘다는 것이 아니라 사람들이 게으르고, 창의적이지 않으며, 인지적 부담 경감(cognitive offloading)을 추구한다는 것을 강조함에도 불구하고 웃습니다.

이처럼 '인식이 시장을 지배한다'는 원칙은 AI 기술의 현실과 대중의 이해 사이에 깊은 괴리를 만듭니다. 학계나 연구 기관에서 발표되는 연구 결과조차도 종종 이러한 인식의 틀 안에서 재해석되거나 오용되곤 합니다. 예를 들어, 'AI 사용이 인지 능력 저하를 초래한다'는 연구가 특정 조건 하의 제한적인 결과를 일반화하여 보도되거나, 'AI 프로젝트의 높은 실패율'이라는 통계가 표본의 대표성이나 방법론의 한계는 간과된 채 선정적으로 유통되는 경우가 흔합니다. 심지어 'AI가 인간보다 느리다'는 식의 결론은 오래된 모델이나 특정 작업 환경에만 국한될 수 있음에도 불구하고, 모든 AI 기술의 무용론으로 이어지기도 합니다. 이는 AI가 가진 실제 가치를 제대로 평가하지 못하게 할 뿐만 아니라, 중요한 정책 결정이나 산업 투자 방향에도 부정적인 영향을 미칠 수 있습니다. 기업들은 과장된 약속에 기반한 솔루션(solution)을 도입하려다 실망하고, 정부는 잘못된 정보에 근거하여 규제를 만들거나 투자를 집행할 위험에 처하게 됩니다. 기술 개발자들은 자신들의 연구와 제품에 대해 더 큰 책임감을 가지고 투명하게 소통해야 하며, 언론은 단편적인 소식보다는 깊이 있는 분석과 비판적 검증을 통해 대중의 이해를 도와야 합니다. 또한, 우리 각자는 AI에 대한 정보를 접할 때, 그 출처와 맥락을 꼼꼼히 살피고 스스로 판단하는 능력을 길러야 합니다. AI 시대의 진정한 성숙은 기술적 진보와 더불어 정보의 투명성, 그리고 비판적 사고의 함양에서 비롯될 것입니다. 극단적인 주장보다는 실용적이고 현실적인 접근이 필요한 시점입니다.

저는 AI 산업이 이러한 대우를 받을 자격이 있기 때문에 계속해서 웃습니다. 이것은 기술에 대한 잘못된 평가라는 점에서 불공평하지만, 다른 의미에서는 그들이 자초한 일입니다. 그들은 과장된 약속과 끊임없는 마케팅(marketing) 과장 선전으로 이 모든 것을 얻었습니다. 그들이 먼저 정보 환경을 왜곡했기 때문에, 이제 일부 회의론자(skeptics)와 비평가(critics)들이 똑같은 일을 하는 것을 볼 때 저는 우는 대신 웃습니다 (불행히도, 두 가지 잘못이 하나의 옳음을 만들지는 않습니다). 만약 허튼소리가 그들의 통화이고 헛된 말이 그들의 무기라면, 그들은 그에 상응하는 대가를 받아도 마땅합니다.

구독하기