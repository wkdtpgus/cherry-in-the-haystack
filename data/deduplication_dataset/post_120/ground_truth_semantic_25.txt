카라바조의 <나르키소스>, 약 1600년

저는 **퓨처리즘(Futurism)**이라는 간행물을 즐겨 읽습니다. 이곳에 실리는 이야기들이 질적으로 미흡하다는 점을 쉽게 파악할 수 있어 (어떤 면이 부족한지 명확히 설명하기 어려운 인공지능 생성 글과는 달리) 훌륭한 스트레스 해소처가 됩니다. 또한, AI를 잠재적으로 유익한 기술로 여기는 데는 관심이 적지만, AI에 대한 과장된 선전을 반박하여 영향력을 얻는 데는 관심이 많은 모든 사람들이 이 매체를 끊임없이 인용할 것이기 때문에 훌륭합니다. 하지만 제가 이 잡지에 매료되는 핵심적인 까닭은, 업계 동향을 꾸준히 왜곡하여 전달하는 새로운 부류의 인공지능 영향력 행사자(AI influencer)들이 출현하는 데 일조했기 때문입니다 (때로는 의도치 않은 경우도 있습니다). 이러한 현상은 단순한 정보 전달을 넘어, 대중의 인공지능에 대한 인식 자체를 형성하는 데 결정적인 역할을 합니다.

'인공지능 산업에 대한 모든 신뢰를 잃고 있다'는 식의 글을 썼던 작가로서, 제가 어떤 음모에 가담했다고 비난받기는 어려울 것입니다. 그렇지만 저는 사실에 근거하여 이야기해야 하므로 밝히건대, 이 분야는 자신들이 개발하는 모든 것을 판매하기 위해 총력을 기울일 테지만, 그 중 상당수는 어쨌든 정당성을 지닙니다. 다시 말해, 여러분은 **ChatGPT**에 접속하여 해결하지 못하는 아주 예외적인 경우(edge cases)에만 몰두할 수도 있고, 2022년 이전에는 그 어떤 다른 기술도 해내지 못했던 수많은 성과에 주목할 수도 있습니다. 이는 전적으로 여러분의 판단에 달린 문제입니다. 저의 태도는 양면을 모두 살펴보는 것입니다. 이러한 양가적 시각은 기술 발전에 대한 건전한 비판과 현실적인 기대 사이의 균형을 찾는 데 필수적입니다.

그럼에도 불구하고, 저는 인공지능 분야가 부정확한 특징 부여(mischaracterization)로 인해 그 힘을 잃어가는 현상에 대해 만족감을 느낍니다. 이는 **ChatGPT** 출시 이후 단 한 순간도 인공지능 과장 광고 장치(AI Hype Machine)를 멈추지 않았으므로, 이러한 취급을 받아 마땅하며, 부풀려진 약속을 쏟아내는 시스템에 맞설 수 있는 유일한 대안이기 때문입니다. 모든 정보 교환의 장은 결국 자신과 대립하는 세력을 찾아내기 마련입니다. 이러한 현상은 기술 산업 전반에서 반복되는 패턴입니다. 초기에는 혁신에 대한 과도한 낙관론이 지배하고, 이는 막대한 투자와 기대를 불러일으킵니다. 그러나 현실적인 한계와 예상치 못한 문제가 드러나면서 비판론이 고개를 들기 시작하고, 이내 이전의 과장된 주장만큼이나 극단적인 비난으로 전환됩니다. 이 과정에서 기술의 실제적인 가치나 발전 가능성에 대한 객관적인 평가는 뒷전으로 밀려나기 쉽습니다.

최근 인공지능 기술의 발전 속도는 전례 없이 빠르지만, 이에 대한 대중적 인식은 종종 과장된 환상과 냉소적인 비판 사이를 오갑니다. 마치 거울에 비친 자신의 모습에 매료된 나르키소스처럼, 산업은 스스로 만들어낸 이미지에 도취되거나, 혹은 그 이미지가 깨질 때의 실망감에 빠져들곤 합니다. 이러한 인식의 왜곡은 단순히 흥미로운 현상을 넘어, 기술 개발의 방향성, 투자 결정, 그리고 궁극적으로는 사회적 수용도에 심각한 영향을 미칩니다. 예를 들어, 특정 대규모 언어 모델(LLM)의 출시가 '실패'로 규정되는 과정은 기술적 성능의 문제를 넘어, 기대 관리의 실패와 대중 심리의 복합적인 작용으로 설명될 수 있습니다.

데모 이후 몇 주 동안 몇 가지 주제가 대화를 지배했습니다. 잘못된 라벨이 붙은 두 개의 차트가 트위터(Twitter)에서 조롱당하고 밈(meme)화되었습니다. r/ChatGPT 서브레딧(subreddit)은 GPT-5의 성격이 충분히 매력적이지 않다는 이유로 OpenAI에 GPT-4o를 다시 가져오라고 집단적으로 요구했습니다. 벤치마크(benchmark) 점수는 좋았지만, 언론 보도와 샘 알트만(Sam Altman) CEO의 거창한 발언을 고려할 때 예상했던 것만큼 강력하지는 않았습니다. 알트만은 더 버지(The Verge)와의 인터뷰에서 “출시 과정에서 몇 가지를 완전히 망쳤다”고 인정했습니다. 그래서 기본적으로, 슬라이드(slide) 실수, 소프트웨어(software) 업데이트(절대 그런 일은 없지만)로 인한 화난 고객들, 그리고 투자자들의 귀에 속삭이는 CEO의 발언이 맥락에서 벗어나 인용된 것 등이 있었습니다.
대중의 여론에서 그렇게 부정적인 반응(negative valence)을 얻게 되었다는 점은 (OpenAI에게는 아니겠지만 저에게는) 흥미로운 현상입니다. 제가 온라인에서 소통하는 놀랍도록 많은 이들이 **GPT-5**가 실패작이었다고 여깁니다 (소수의 기술 전문가는 그렇지 않음을 인지하고 있으며, 대다수는 단순히 무관심합니다). 그러나 저는 이미 예견했습니다. 이러한 일이 벌어질 것을 알고 있었습니다. 출시 나흘 전, 저는 **GPT-5**가 “부당한 실망”으로 취급될 것이라고 기술했습니다. 부당하다고 한 것은 그것이 훌륭할 것이고 (그리고 저렴할 것이라고) 예측했기 때문이며, 실망스럽다고 한 것은 불가능한 기대에 직면했기 때문입니다. 핵심은 바로 이것이죠? 모든 것은 오직 기대치에 비례하여 좋거나 나쁩니다. 이러한 기대치는 종종 기술의 실제 역량보다는 마케팅(marketing) 전략이나 언론의 과장된 헤드라인에 의해 부풀려집니다. 사용자들은 막연한 기대감을 가지고 새로운 기술을 접하지만, 사소한 결점이나 불편함에도 쉽게 실망하며, 이는 곧 "실패"라는 낙인으로 이어집니다. 그렇다면 GPT-5에 대한 이러한 노골적인 오해(misrepresentation)에 대해 누구를 비난해야 할까요? 슬라이드(slide)를 만든 인턴(intern)? 이전 버전을 원했던 중독된 레디터(redditors)들? 벤치마크(benchmark)를 최고치로 만들도록 허용한 디자이너(designer)들? 뻔한 질문을 한 인터뷰어(interviewer)들? 아니면 샘 알트만(Sam Altman)과 그의 측근들이 자신들이 하는 모든 것을 과장하는 것(그것이 진정한 열정이든 과시적인 부족주의이든 중요하지 않다고 생각합니다)에 잘못이 있을까요?

이러한 경향은 비단 **OpenAI**만의 문제가 아니라, 전체 인공지능 산업 전반에 걸쳐 나타나는 현상입니다. 이들은 마치 교활한 속임수꾼(trickster)처럼 행동하며, 홍보(marketing)의 신들이 언제나 그 대가를 요구한다는 사실을 간과하고 있습니다. 알트만은 더 버지(The Verge)에 GPT-5 출시를 “망쳤다”고 말하고 싶지 않았을 것입니다 (아마도 그는 그것이 사실이라고 생각하지도 않았을 것입니다. 그들이 망친 것은 GPT-5 제품 자체가 아니라 얼마나 많은 사용자들이 GPT-4o를 사랑하는지 깨닫지 못한 것이었습니다). 그는 자신의 말이 특정 이야기를 밀어붙이는 데 사용될 것임을 알았지만, 벗어날 방법이 없었습니다. 대중의 인식이 시장을 좌우한다면, 일반 대중이 믿는 바는 근본적인 현실과 동떨어져 있더라도 결국 진실로 받아들여집니다. 그리고 이러한 ‘진실’이 업계의 선두 주자(leader)들에게 유리하든 불리하든, 그들에게는 단 하나의 선택지밖에 없습니다. 바로 대중의 목소리에 동참하는 것입니다. 이러한 현상은 특히 소셜 미디어와 즉각적인 뉴스 소비가 지배하는 오늘날의 정보 생태계에서 더욱 두드러집니다. 기술 혁신에 대한 기대는 종종 현실을 뛰어넘어 과도한 낙관주의를 낳고, 이는 다시 사소한 결점도 거대한 실패로 부풀리는 반동으로 이어집니다. 업계는 이러한 기대와 실망의 순환 고리 속에서 헤어나오지 못하고 있습니다. 중요한 것은, 이 과정에서 객관적인 사실보다는 감성적인 서사가 더 큰 영향력을 발휘한다는 점입니다. 말이 아닌 내용만이 중요하다고 생각하며 게임을 한다면, 세상이 당신에게 똑같은 기준을 적용할 때 놀라지 마십시오.

지난 몇 달간 이러한 양극화된 현상은 너무나 보편화되어, 인공지능 산업에 대한 겉핥기식 비판을 논박하는 글만큼이나, 인공지능 산업의 표면적인 과장 선전을 반박하는 수많은 글감(article ideas)의 원천이 되고 있습니다. 이로 인해 저의 작업은 훨씬 수월해지고 있습니다. 그리고 사실, 여러분은 제가 오래전 작성했던, 논리적으로 반박하기 더 까다로울 것이라고 여겼던 명제를 증명하고 있습니다. 극단적인 옹호론자(hypers)와 극단적인 비판론자(anti-hypers)는 종종 본질적으로 동일한 부류에 속하며, 이들 모두 **소셜 미디어(social media)**에서 영향력(clout)을 얻기 위해 진실의 미약한 단서조차도 터무니없이 확대 해석하는 경향이 있습니다. 이 모든 상황은 처음부터 끝까지 안타까움을 자아냅니다. 하지만 저는 슬퍼하기보다는 차라리 웃음을 택합니다. 이러한 대립 구도는 인공지능 기술이 실제로 어디로 향하고 있는지, 그리고 우리 사회에 어떤 실질적인 영향을 미치는지에 대한 건설적인 논의를 가로막습니다. 양측 모두 자신들의 주장을 뒷받침하기 위해 통계와 사례를 취사선택하며, 그 과정에서 미묘한 차이나 복잡성은 사라지고 단순화된 메시지만이 남습니다.

MIT 연구에서 ChatGPT를 사용하는 사람들이 필연적으로 더 멍청해지고 있다고 말하고 사람들이 뇌 손상(brain rot)에 대해 비관적인 예측을 할 때, 저는 그 연구 전체를 직접 읽고 다른 결론이 있을 수 없다는 것을 알면서도 웃습니다. 그 결론은 AI가 인지 능력을 저하시킬 수 있지만, 특정 조건 하에서만 그렇다는 것입니다. 즉, 뇌를 사용하기 전에 문제 해결을 위해 AI에 과도하게 의존할 때 말입니다. 또 다른 MIT 연구에서 생성형 AI(generative AI) 파일럿(pilot) 프로젝트의 95%가 실패하고 있다고 말하고 사람들이 95라는 숫자가 크다는 이유로 이 소식을 사방에 공유할 때, 저는 표본이 작고(52개 인터뷰), 방법론이 취약하며, 주 저자(lead author) 자신이 실패의 원인이 기술의 낮은 품질이 아니라 현재 모델(model)들이 맥락적이고 지속적으로 학습하지 않을 때 워크플로우(workflow) 통합이 어렵기 때문이라고 주장했다는 것을 알면서도 웃습니다. METR 무작위 대조 시험(randomized controlled trial, 금본위제)이 “개발자들이 AI 도구(tool)를 사용할 때, 사용하지 않을 때보다 19% 더 오래 걸린다—AI가 그들을 더 느리게 만든다”고 결론 내리고 사람들이 생성형 AI(generative AI)를 “킬러 앱(killer app)”조차도 쓸모없다고 미친 듯이 비난할 때, 저는 그 연구가 오래된 모델(model)들을 대상으로 했고, 자신들의 저장소(repository)에 익숙한 프로그래머(programmer)들을 대상으로 했으며, 인간의 실패(예: AI가 더 오래 걸린다고 생각하는 것)를 고려하지 않았다는 구체적인 사실들이 결과를 올바르게 해석하는 데 필수적이라는 것을 알면서도 웃습니다. 애플(Apple) 논문이 AI 사고가 “환상(illusion)”이라고 말하고 사람들이 권위 있는 주장(애플이잖아!)을 사용하여 이를 옹호할 때, 저는 그 결과가 다양한 오해에 기반하고 있다는 것을 알면서도 웃습니다. 명시적인 추론 흔적(explicit reasoning traces)은 모델(model)의 실제 사고를 반영하지 않으며, 스크래치패드(scratchpad) 없이는 “정확도 붕괴(accuracy collapse)” 현상이 예상됩니다—심지어 인간에게서도 말입니다! 이번 주 초 하버드 비즈니스 리뷰(Harvard Business Review)가 “직원들이 AI 도구(tool)를 사용하여 적은 노력으로 그럴듯해 보이는 작업을 만들고, 이는 결국 동료들에게 더 많은 작업을 초래한다”—그들이 **워크슬롭(workslop)**이라고 명명한 현상—고 보도하고 이 새로운 유행어(buzzword)가 입소문을 탈 때, 저는 이 결과가 AI가 나쁘다는 것이 아니라 사람들이 게으르고, 창의적이지 않으며, 인지적 부담 경감(cognitive offloading)을 추구한다는 것을 강조함에도 불구하고 웃습니다.

저는 인공지능 분야가 이와 같은 취급을 받는 것이 합당하다고 생각하기에 계속해서 미소 짓습니다. 이는 기술 자체에 대한 부정확한 평가라는 점에서 공정하지 못하지만, 다른 한편으로는 그들 스스로 초래한 결과입니다. 그들은 과도한 약속과 쉴 새 없는 홍보(marketing) 활동으로 이러한 상황을 자초했습니다. 그들이 먼저 정보의 장을 왜곡했으므로, 이제 일부 비판적 시각을 가진 이들(skeptics)과 평론가(critics)들이 동일한 방식으로 행동하는 것을 목격할 때, 저는 슬퍼하기보다는 웃음을 택합니다 (불행히도, 두 가지 잘못이 하나의 옳음을 만들지는 않습니다). 궁극적으로, 이러한 정보 전쟁은 기술 발전에 대한 대중의 신뢰를 저하시키고, 진정한 혁신의 가치를 모호하게 만듭니다. 우리는 과장된 기대와 무조건적인 비난을 넘어, 인공지능의 현실적인 잠재력과 한계를 이해하려는 노력이 필요합니다.

구독하기