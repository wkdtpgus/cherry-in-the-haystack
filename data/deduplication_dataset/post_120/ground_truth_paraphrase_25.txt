카라바조의 <나르키소스>, 약 1600년

저는 **퓨처리즘(Futurism)** 매체를 선호합니다. 이 매체가 다루는 내용의 수준이 낮음을 명확히 인지할 수 있어 (인공지능이 작성한 글처럼 모호하게 나쁘지 않고 그 이유를 정확히 파악하기 어려운 것과는 달리) 훌륭한 스트레스 해소 창구 역할을 합니다. 또한, 인공지능을 잠재적으로 유익한 기술로 여기는 데는 관심이 적고, 오히려 AI에 대한 과도한 선전을 반박함으로써 영향력을 얻으려는 이들이 이 매체를 끊임없이 언급한다는 점도 흥미롭습니다. 그러나 제가 이 잡지를 좋아하는 가장 큰 이유는 AI 분야에서 새로운 유형의 영향력 있는 인물들이 나타나는 데 일조했기 때문입니다. 이들은 때로는 의도치 않게, 때로는 고의적으로 업계의 진척 상황을 지속적으로 오도하는 경향이 있습니다. 이러한 미디어 환경은 인공지능에 대한 대중의 인식을 형성하는 데 지대한 영향을 미칩니다. 특정 서사가 반복적으로 재생산되면서, 대중은 인공지능 기술의 실제 발전보다 미디어에 의해 가공된 이미지를 더 신뢰하게 되는 경우가 많습니다.

“저는 AI 산업에 대한 모든 신뢰를 잃고 있습니다”와 같은 글을 쓴 필자로서, 어떤 특정 집단과 공모했다는 의심을 받기는 어렵습니다. 하지만 무엇보다 진실에 충실해야 하기에 말씀드립니다. 이 산업은 자신들이 만들어내는 모든 것을 여러분에게 판매하기 위해 총력을 기울일 것이지만, 그 중 상당수는 어쨌든 합법적이고 가치 있는 것입니다. 독자 여러분은 ChatGPT와 같은 도구가 해결하지 못하는 특정 예외적인 상황(edge cases)에만 주목할 수도 있고, 2022년 이전에는 불가능했던 수많은 성과에 초점을 맞출 수도 있습니다. 이는 전적으로 여러분의 선택입니다. 저의 선택은 양쪽 측면을 모두 균형 있게 살펴보는 것입니다. 새로운 기술을 평가할 때 이러한 양면성을 인지하는 것은 매우 중요합니다. 대중은 종종 기술의 잠재력과 현재의 한계를 극단적으로 이분화하여 바라보는 경향이 있습니다. 이러한 인지 편향(cognitive bias)은 기술에 대한 합리적인 판단을 방해하고, 불필요한 과장이나 과도한 비난으로 이어질 수 있습니다.

그럼에도 불구하고, 필자는 AI 분야가 오해와 잘못된 정보(mischaracterization)로 인해 다소 힘을 잃고 있다는 사실에 대해 두 가지 관점에서 긍정적으로 생각합니다. 첫째, AI 과장 선전이 ChatGPT 출시 이후 단 하루도 멈추지 않고 이어져 왔기에, 이러한 상황은 어느 정도 자업자득이라는 것입니다. 둘째, 이는 과도한 약속을 남발하는 기계에 맞서는 유일한 효과적인 방어 수단이기 때문입니다. 모든 정보 교환의 장은 결국 그에 상응하는 반대 의견을 형성하게 마련입니다. 친(親)AI 전도사들로 정보 시장이 포화되자, 이제는 반대 진영의 차례가 된 것입니다. 흑과 백, 음과 양의 조화처럼, 저는 균형 잡힌 우주를 선호하며, 앵무새처럼 떠들어대는 혼란스러운 **퓨처리즘(Futurism)**은 겸손하고 자기희생적이며 혼란스러운 균형 잡기 행위를 수행합니다. 그것은 필요악입니다. 이러한 기술 과장 선전의 주기(hype cycle)는 새로운 기술이 등장할 때마다 반복되는 현상입니다. 극단적인 낙관론에서 시작하여 과도한 비관론으로 기울어지는 이 주기는 미디어의 역할에 따라 그 속도와 강도가 달라지기도 합니다. 비판적인 미디어는 이러한 주기를 조절하고 건강한 정보 생태계를 유지하는 데 필수적인 기능을 합니다. (물론, 저는 특정 뉴스 사이트 하나만을 지목하고 싶지는 않습니다. 전통적으로 기술 친화적인 출판물들을 포함하여 많은 곳들이 이 반(反)물질 파이(anti-matter pie)의 한 조각을 차지하기 위해 경쟁하고 있으며, 혐오의 물결이 돈벌이 없이 그냥 지나가도록 내버려두려 하지 않습니다.)

그러나 현재의 상황은 단순히 언론인들이 시대의 흐름(zeitgeist)을 빠르게 파악하여 자신들의 입지를 다지는 것보다 훨씬 복잡합니다. 그들이 대중의 인식을 조종하는 능력은 칭찬할 만하지만, 그 이면에는 더 깊은 변화가 있습니다. 아마도 결국 일반 대중에게까지 영향을 미칠 더 큰 인식의 전환(paradigm shift)이 일어나고 있다는 가장 분명한 신호는, 한때 AI 산업의 가장 강력한 비판자로 알려졌던 게리 마커스(Gary Marcus)조차 이제는 다른 회의론자들에 비해 상대적으로 온건한 입장을 취하는 것처럼 보인다는 점일 것입니다. 뉴요커(The New Yorker)는 8월 12일, “GPT-5 출시 이후, AI에 대한 과장된 예측을 액면 그대로 받아들이기가 더욱 어려워졌으며, 마커스와 같은 비평가들의 견해는 점점 더 온건해지는 것처럼 보인다”고 보도했습니다. 단 한 번의 출시 실패로 그들은 당신을 완전히 끝장냅니다. 실제로, GPT-5 출시가 왜 “실패”로 간주되었는지 자세히 살펴보겠습니다. 이는 업계가 잘못된 정보(mischaracterization)를 받을 자격이 있는 이유와 그러한 잘못된 정보가 애초에 어떻게 발생하는지를 보여주는 훌륭한 사례이기 때문입니다. 이러한 대중적 인식의 변화는 기술 기업들이 끊임없이 혁신하고 기대 이상의 성과를 내야 한다는 압박감을 가중시키며, 한 번의 실수가 전체 기술 분야에 대한 신뢰 하락으로 이어질 수 있음을 시사합니다.

데모 이후 몇 주 동안, 잘못된 라벨이 붙은 두 개의 차트가 트위터(Twitter)에서 조롱의 대상이 되고 밈(meme)으로 확산되는 등 몇 가지 이슈가 논의를 지배했습니다. r/ChatGPT 서브레딧(subreddit)은 GPT-5의 특성이 충분히 매력적이지 않다는 이유로 OpenAI에 GPT-4o를 다시 가져오라고 집단적으로 요구했습니다. 벤치마크(benchmark) 점수는 좋았지만, 언론 보도와 샘 알트만(Sam Altman) CEO의 거창한 발언을 고려할 때 예상했던 것만큼 강력하지는 않았습니다. 알트만은 더 버지(The Verge)와의 인터뷰에서 “출시 과정에서 몇 가지를 완전히 망쳤다”고 인정했습니다. 그래서 기본적으로, 슬라이드(slide) 실수, 소프트웨어(software) 업데이트(절대 그런 일은 없겠지만)로 인한 화난 고객들, 그리고 투자자들의 귀에 속삭이는 CEO의 발언이 맥락에서 벗어나 인용된 것 등이 있었습니다. 다른 어떤 AI 모델도 부러워할 것이 없는 (오히려 다른 대부분의 모델들이 GPT-5를 부러워할 만한) AI 모델이 대중의 여론에서 그렇게 부정적인 평가(negative valence)를 받게 되었다는 것은 (OpenAI에게는 아니지만 저에게는) 흥미로운 일입니다. 제가 온라인에서 교류하는 놀랍도록 많은 사람들이 GPT-5가 실패작이었다고 생각합니다 (소수의 기술 전문가들은 그렇지 않다는 것을 알고 있고, 대부분의 사람들은 단순히 신경 쓰지 않습니다). 하지만 저는 예측했습니다. 이런 일이 일어날 줄 알았습니다. 출시 4일 전, 저는 GPT-5가 “ 불공정한 실망 ”으로 취급될 것이라고 썼습니다. 불공정한 이유는 그것이 좋을 것이고(그리고 저렴할 것이라고) 알았기 때문이고, 실망스러운 이유는 불가능한 기대를 마주했기 때문입니다. 그것이 핵심이죠? 모든 것은 기대치에 비해서만 좋거나 나쁩니다. 그렇다면 GPT-5에 대한 이러한 노골적인 오해(misrepresentation)에 대해 누구를 비난해야 할까요? 슬라이드(slide)를 만든 인턴(intern)? 이전 버전을 원했던 중독된 레디터(redditors)들? 벤치마크(benchmark)를 최고치로 만들도록 허용한 디자이너(designer)들? 뻔한 질문을 한 인터뷰어(interviewer)들? 아니면 샘 알트만(Sam Altman)과 그의 측근들이 자신들이 하는 모든 것을 과장하는 것(그것이 진정한 열정이든 과시적인 부족주의이든 중요하지 않다고 생각합니다)에 잘못이 있을까요? 이러한 현상은 소셜 미디어가 기술 서사를 형성하는 데 얼마나 큰 역할을 하는지 보여줍니다. 사소한 결함조차도 빠르게 증폭되어 제품에 대한 부정적인 인식을 확산시킬 수 있으며, 이는 기업이 제품 출시 시 기대치 관리(expectation management)를 얼마나 신중하게 해야 하는지를 강조합니다.

참고로, OpenAI뿐만 아니라 전체 산업이 이렇습니다. 인식이 시장을 좌우하는 상황에서는, 대중에게 전파되는 정보가 실제와 크게 다를지라도 그것이 곧 진리처럼 받아들여집니다. 이처럼 업계는 마케팅의 보이지 않는 힘이 언제든 대가를 요구한다는 사실을 간과한 채, 능숙한 사기꾼(trickster)처럼 행동하는 경향이 있습니다. 그리고 이 복음이 업계 리더(leader)들에게 좋든 나쁘든, 그들에게는 오직 한 가지 선택만이 있습니다. 바로 합창에 동조하는 것입니다. 알트만은 더 버지(The Verge)에 GPT-5 출시를 “망쳤다”고 말하고 싶지 않았을 것입니다 (아마도 그는 그것이 사실이라고 생각하지도 않았을 것입니다. 그들이 망친 것은 GPT-5 제품 자체가 아니라 얼마나 많은 사용자들이 GPT-4o를 사랑하는지 깨닫지 못한 것이었습니다). 그는 자신의 말이 특정 이야기를 밀어붙이는 데 사용될 것임을 알았지만, 벗어날 방법이 없었습니다. 말이 아닌 내용만이 중요하다고 생각하며 게임을 한다면, 세상이 당신에게 똑같은 기준을 적용할 때 놀라지 마십시오. 이러한 현상은 기술 산업의 윤리적 마케팅과 대중 인식 관리의 중요성을 부각합니다. 과도한 과장과 허위 정보는 단기적인 이익을 가져올 수 있지만, 장기적으로는 공중의 신뢰를 훼손하고 산업 전반에 대한 회의감을 증폭시킬 수 있습니다.

이러한 현상이 지난 몇 달간 워낙 흔해져서, AI 산업의 겉핥기식 비판을 논파하는 것만큼이나 AI 산업의 피상적인 과장 선전을 반박하는 수많은 글감의 원천이 되고 있습니다. 여러분은 제 일을 쉽게 만들고 있습니다. 그리고 사실, 여러분은 제가 오래전에 썼던, 방어하기 더 어려울 것이라고 생각했던 것을 입증하고 있습니다. 극단적인 과장론자(hypers)들과 그에 반대하는 이들(anti-hypers)은 종종 본질적으로 유사하며, 둘 다 소셜 미디어(social media)에서의 영향력(clout)을 얻기 위해 미미한 진실의 조각조차도 과도하게 부풀리는 경향이 있습니다. 처음부터 끝까지 슬픈 상황입니다. 하지만 저는 우는 것보다 웃는 것을 선호합니다. 온라인 담론에서 AI에 대한 "메아리 방(echo chamber)" 효과는 이러한 양극화를 더욱 심화시킵니다. 상충되는 서사 속에서 일반 대중이 진실을 가려내기란 매우 어려운 일이며, 이는 건전한 기술 논의를 방해하는 요소로 작용합니다. 필자가 웃음을 택하는 것은 이러한 혼란 속에서도 개인적인 균형 감각을 유지하려는 노력의 일환일 것입니다.

MIT 연구가 ChatGPT 사용자들이 필연적으로 인지 능력이 저하되어 '뇌 손상(brain rot)'에 대한 비관적 예측을 낳는다고 주장할 때, 필자는 직접 해당 연구를 면밀히 검토하고 다른 결론이 나올 수 없음을 알기에 웃음이 나옵니다. 그 결론은 AI가 인지 능력을 저하시킬 수 있지만, 특정 조건 하에서만 그렇다는 것입니다. 즉, 뇌를 사용하기 전에 문제 해결을 위해 AI에 과도하게 의존할 때 말입니다. 또 다른 MIT 연구에서 생성형 AI(generative AI) 파일럿(pilot) 프로젝트의 95%가 실패하고 있다고 말하고 사람들이 95라는 숫자가 크다는 이유로 이 소식을 사방에 공유할 때, 필자는 표본이 작고(52개 인터뷰), 방법론이 취약하며, 주 저자(lead author) 자신이 실패의 원인이 기술의 낮은 품질이 아니라 현재 모델(model)들이 맥락적이고 지속적으로 학습하지 않을 때 워크플로우(workflow) 통합이 어렵기 때문이라고 주장했다는 것을 알면서도 웃습니다. METR 무작위 대조 시험(randomized controlled trial, 금본위제)이 “개발자들이 AI 도구(tool)를 사용할 때, 사용하지 않을 때보다 19% 더 오래 걸린다—AI가 그들을 더 느리게 만든다”고 결론 내리자 사람들이 생성형 AI(generative AI)를 “킬러 앱(killer app)”조차 될 수 없는 무용지물이라고 맹렬히 비난할 때, 필자는 해당 연구가 구형 모델(model)들을 대상으로 했고, 자신의 코드 저장소(repository)에 익숙한 프로그래머(programmer)들을 대상으로 했으며, 인간의 주관적 인지 오류(예: AI가 더 오래 걸린다고 생각하는 것)를 간과했다는 핵심적인 사실들을 인지하고 있기에 웃습니다. 애플(Apple) 논문이 AI 사고가 “환상(illusion)”이라고 말하고 사람들이 권위 있는 주장(애플이잖아!)을 사용하여 이를 옹호할 때, 필자는 그 결과가 다양한 오해에 기반하고 있다는 것을 알면서도 웃습니다. 명시적인 추론 흔적(explicit reasoning traces)은 모델(model)의 실제 사고를 반영하지 않으며, 스크래치패드(scratchpad) 없이는 “정확도 붕괴(accuracy collapse)” 현상이 예상됩니다—심지어 인간에게서도 말입니다! 이번 주 초 하버드 비즈니스 리뷰(Harvard Business Review)가 “직원들이 AI 도구(tool)를 사용하여 적은 노력으로 그럴듯해 보이는 작업을 만들고, 이는 결국 동료들에게 더 많은 작업을 초래한다”—그들이 **워크슬롭(workslop)**이라고 명명한 현상—고 보도하고 이 새로운 유행어(buzzword)가 입소문을 탈 때, 필자는 이 결과가 AI가 나쁘다는 것이 아니라 사람들이 게으르고, 창의적이지 않으며, 인지적 부담 경감(cognitive offloading)을 추구한다는 것을 강조함에도 불구하고 웃습니다. 이러한 사례들은 과학적 연구 결과를 해석할 때 방법론, 표본 크기, 그리고 맥락을 이해하는 것이 얼마나 중요한지 보여줍니다. 언론은 종종 헤드라인을 자극적으로 만들고 미묘한 차이를 간과하여 대중에게 왜곡된 정보를 전달하는 경향이 있습니다. 연구자와 언론인 모두 정확한 정보 전달에 대한 책임감을 가져야 합니다.

AI 산업이 현재와 같은 취급을 받는 것이 마땅하다고 생각하기에, 필자는 계속해서 웃음을 멈출 수 없습니다. 이는 기술 자체에 대한 평가가 잘못되었다는 점에서는 부당할 수 있지만, 다른 한편으로는 그들 스스로가 자초한 결과입니다. 그들은 과장된 약속과 끊임없는 마케팅(marketing) 과장 선전으로 이 모든 상황을 초래했습니다. 그들이 먼저 정보 환경을 왜곡했기 때문에, 이제 일부 회의론자(skeptics)와 비평가(critics)들이 그와 동일한 방식으로 행동하는 것을 보면서 필자는 슬퍼하기보다는 웃음을 택합니다 (불행히도, 두 가지 잘못이 하나의 옳음을 만들지는 않습니다). 만약 허튼소리가 그들의 통화이고 헛된 말이 그들의 무기라면, 그들은 그에 상응하는 대가를 받아도 마땅합니다. 이러한 기술 과장 선전과 그에 대한 반동의 순환은 혁신과 대중의 신뢰에 장기적인 영향을 미칩니다. 기술 기업들은 보다 책임감 있는 소통 전략을 채택하고, 비판적 분석을 통해 건강한 기술 생태계를 유지하는 것이 중요합니다.

구독하기