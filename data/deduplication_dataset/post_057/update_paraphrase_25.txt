(출처: [1, 2, 8, 9, 10, 12, 15]) 머신러닝 모델의 성능을 향상시키기 위한 한 가지 방법으로, 여러 개의 모델을 개별적으로 학습시킨 후 추론 단계에서 그 예측값을 통합하여 앙상블(ensemble)을 구성할 수 있습니다. 앙상블 기법은 머신러닝 분야에서 수십 년간 활용되어 온 강력한 전략이지만, 여러 모델의 출력을 계산해야 하는 특성 때문에 추론 비용이 증가한다는 명확한 제약이 따릅니다. 1 이러한 제약을 극복하기 위해, 연구자들은 모델을 통합하는 다양한 대안적 방법론을 탐색해 왔습니다. 이러한 탐색은 최종적으로 예측값의 평균을 내는 대신, 앙상블을 구성하는 모델들의 가중치를 평균하여 하나의 통합된 모델을 생성하는 가중치 공간 앙상블(weight-space ensembles)의 광범위한 채택으로 이어졌습니다. 이 방식은 많은 경우에 일반적인 출력 공간 앙상블(output-space ensembles)에 필적하거나 심지어 더 뛰어난 성능을 보이며 상당한 효율성을 입증했습니다.

“우리는 언어 모델(LM)이 재훈련이나 GPU 없이도 동종 모델의 매개변수를 동화하여 새로운 기능을 습득할 수 있음을 밝힙니다.” - 출처: [3]

현재 모델 병합(model merging)은 활발한 연구 주제로 부상하고 있지만, 그 개념 자체는 결코 새로운 것이 아닙니다. 이 아이디어는 1990년대 [7]까지 거슬러 올라가는 깊은 역사를 가지고 있습니다! 딥러닝 시대 2 에 들어서면서, 모델 병합과 관련된 기술들은 모드 연결성(mode connectivity), 일반화(generalization), 연속 학습(continual learning)과 같은 핵심 연구 영역에서 반복적으로 나타났습니다. 특히 지난 몇 년 동안 대규모 언어 모델(LLM) 애플리케이션에서의 그 효과성이 입증되면서 모델 병합에 대한 관심은 폭발적으로 증가했습니다. 우리는 모델 병합이 여러 파운데이션 모델(foundation model)의 역량을 결합하고, 모델에 새로운 기능을 주입하며, 심지어 정렬(alignment) 프로세스를 개선하는 데 활용되는 것을 목격했습니다. 이 글에서는 모델 병합의 초기 개념부터 LLM을 활용한 현대적인 적용 사례에 이르기까지, 이 모든 연구의 흐름을 심층적으로 탐구할 것입니다.

**기반 및 배경 정보**
모델 병합에 관한 최신 연구들을 살펴보기에 앞서, 이 분야의 초창기 작업들을 먼저 조명해 볼 필요가 있습니다. 또한, 모델 병합의 근간을 이루는 몇 가지 상이하지만 밀접하게 연관된 연구 주제들을 탐색할 것입니다. 이러한 기술들과 그 기원을 더 깊이 이해함으로써, 우리는 모델 병합 기술에 대한 보다 미묘한 관점(nuanced perspective)을 얻게 될 것이며, 이 분야의 핵심 아이디어, 그 기원, 그리고 왜 그렇게 효과적인지에 대해 더 깊이 이해할 수 있게 될 것입니다.

**모델 병합의 기원 (출처: [7])**
모델 병합은 최근 학계와 산업계에서 큰 주목을 받고 있는 연구 영역이지만, 이 기술의 뿌리는 1990년대 중반 [7]까지 거슬러 올라갈 정도로 그 역사가 상당히 깊습니다! [7]의 저자들은 실제 환경에서 실무자들이 특정 문제 해결을 위해 종종 여러 머신러닝 모델을 훈련시키는데, 이 모델들은 아키텍처(architecture), 훈련 데이터 구성 방식 및/또는 하이퍼파라미터(hyperparameter) 설정에서 서로 다른 경우가 많다는 점을 관찰했습니다. 이러한 개별 모델들은 각 모델의 예측값을 평균하거나, 각 모델의 예측값에 가중치를 부여하여 학습하는 방식으로 결합되어 앙상블을 형성하는 데 사용됩니다.

“우리는 … 특정 조건에서 모든 네트워크를 유지하고 그 출력값을 결합하는 대신 모델 매개변수를 직접 평균할 수 있다고 제안합니다.” - 출처: [7]

(단순한) 신경망(neural network)의 경우, [7]에서는 모델의 출력값을 평균하는 대신 모델 매개변수를 직접 평균하는 방식이 가능하다는 점을 제안합니다. 이 접근 방식은 각 모델의 출력값을 평균하는 것과 유사한 수준의 성능을 제공하면서도, 모델 저장 공간 및 계산 비용을 모두 절감하는 이점을 가집니다. 이 글에서 다루게 될 대부분의 연구는 [7] 이후에 발표되었지만, 이 초기 작업은 모델 병합 연구의 중요한 촉매제 역할을 했으며, 이후 이 분야가 유익하고 중요한 탐구 주제로 자리매김하는 데 결정적인 기여를 했습니다.

**(선형) 모드 연결성((Linear) Mode Connectivity)**
경사 기반 최적화 기법(gradient-based optimization techniques)(예: 확률적 경사 하강법(stochastic gradient descent))을 통해 머신러닝 모델을 훈련하는 방법을 처음 배울 때, 우리는 보통 최소화하려는 손실 함수(loss function)를 매우 단순한 1차원적 관점으로 접하게 됩니다. 실제 신경망의 손실 지형(loss landscape)은 아래 이미지에서 볼 수 있듯이 비볼록(non-convex)하고 복잡합니다. 그러나 이러한 손실 지형에는 우리가 경험적으로 관찰한 몇 가지 예측 가능한 특성과 거동이 존재하며, 이는 이 복잡한 지형을 덜 위협적으로 보이게 만듭니다. 이러한 흥미로운 특성 중 하나가 바로 모드 연결성(mode connectivity)입니다.

(출처)

모드 연결성은 [11]에서 처음으로 발견되고 명명된 개념입니다. 위 시각화에서 나타나듯이, 신경망의 훈련 역학(training dynamics)은 매우 복잡합니다. 이러한 복잡성 때문에, 독립적으로 훈련된 두 개의 신경망 3 이 최적화 지형(optimization landscape)의 완전히 다른 영역에 수렴할 것이라고 예상하기 쉽습니다. 그러나 [11]의 연구는 이것이 항상 사실이 아니라는 것을 보여줍니다. 신경망의 훈련 궤적(training trajectory)은 일정 횟수의 반복(iteration)이 지나면 비교적 예측 가능해집니다.

“우리는 이러한 복잡한 손실 함수의 최적점(optima)이 훈련 및 테스트 정확도(accuracy)가 거의 일정한 단순한 곡선으로 실제로 연결되어 있음을 보여줍니다.” - 출처: [11]

특히, [11]의 연구자들은 독립적으로 훈련된 신경망의 가중치(weights)들이 손실 지형 내에서 일정한 훈련 및 테스트 정확도 4 를 유지하는 경로를 통해 서로 연결될 수 있음을 관찰했으며, 이는 그들의 새로운 훈련 절차를 통해 밝혀졌습니다. 흥미롭게도, 이러한 “모드(modes)”(즉, 손실 지형에서 훈련된 네트워크의 가중치 위치)는 아래 그림에서 볼 수 있듯이 일반적으로 단순한 곡선으로 이어져 있습니다. 이러한 속성은 일정한 성능을 유지하면서 네트워크의 모드를 연결할 수 있다는 점에서 모드 연결성(mode connectivity)이라고 명명되었습니다. 이 특성은 [11]에서 여러 인기 있는 데이터셋으로 훈련된 수많은 컴퓨터 비전 아키텍처(computer vision architectures)(주로 ResNet 계열)에 대해 유효함이 입증되었습니다.

(출처: [11])

선형 모드 연결성(Linear mode connectivity)은 [12]에서 관찰 및 분석된 모드 연결성의 보다 구체적인 형태입니다. 이 논문의 저자들은 서로 다른 무작위 노이즈(random noise)로 훈련된 비전 모델(vision model)들의 특성을 연구하고 비교합니다. 특히, 훈련 과정에서 적용되는 데이터 순서 지정 및 증강(augmentation) 방식은 [12]에서 SGD 노이즈(SGD noise)로 지칭되며 다양하게 변경됩니다. 이후, 다양한 수준의 SGD 노이즈를 적용하여 훈련된 결과 모델들 간의 모드 연결성이 심층적으로 연구됩니다.

(출처: [12])

두 네트워크가 선형적으로 모드 연결되어 있는지 확인하려면, 단순히 그들의 가중치 사이를 (선형적으로) 보간(interpolate)하고, 이 선형 보간 경로를 따라 얻어지는 모델들의 훈련 및 테스트 손실이 일정한 수준을 유지하는지 확인합니다. 선형 모드 연결성을 검증하는 과정은 일반적인 모드 연결성을 확인하는 것보다 훨씬 간편합니다. 이는 임의의 모드 연결 경로를 찾기 위해 더 복잡한 훈련 알고리즘을 사용하는 대신, 모델 가중치 사이의 직선 경로만 확인하면 되기 때문입니다. 더 나아가, [12]의 저자들은 k번의 훈련 반복(training iterations)이 수행된 후에만 SGD 노이즈를 변경하여 이 분석을 확장합니다; 위를 참조하십시오.

(출처: [12])

[12]의 연구를 통해 우리는 신경망이 훈련 초기 단계에서 SGD 노이즈에 대해 안정화된다는 사실을 알 수 있습니다. 이는 다양한 수준의 SGD 노이즈로 훈련된 모델들이 훈련 완료 후에도 여전히 선형적으로 모드 연결되어 있음을 의미합니다. 즉, 일정량의 (합리적인) 훈련이 진행된 후에는, 동일한 기본 모델(base model)에서 파생된 모든 네트워크가 선형적으로 모드 연결됩니다. 이 발견은 우리가 앞으로 살펴보게 될 모델 병합 기술과 매우 밀접한 관련이 있습니다. 일반적으로 모델 병합은 모델의 가중치를 평균하거나 보간하는 방식으로 이루어지기 때문입니다. 따라서 선형 모드 연결성은 이러한 보간된 가중치가 왜 효과적으로 작동하는지에 대한 경험적인 직관을 제공합니다!

(출처: [13])

이 개념을 더욱 구체화하기 위해, [13]의 후속 연구는 동일한 사전 훈련된 가중치(pretrained weights)에서 미세 조정(finetuned)된 모델들이 손실 지형의 동일한 분지(basin)(또는 영역)에 도달한다는 것을 보여줍니다. 다시 말해, 동일한 기본 모델에서 시작하여 독립적으로 미세 조정된 모델들은 매개변수 공간(parameter space) 내에서 서로 가까운 위치에 자리 잡게 됩니다. 이러한 관찰은 임계 학습 기간(critical learning periods)에 대한 연구와 깊이 연관되어 있습니다. 손실 지형의 이 영역에는 발견될 수 있는 여러 실행 가능한 모델 매개변수 설정이 포함되어 있으며, 이는 이 글에서 탐구될 병합 및 보간 기술의 효과성에 대한 추가적인 설명을 제공합니다.

**모드 연결성(Mode connectivity)과 LLM.**
[14]에서 저자들은 대규모 언어 모델(LLM)에 대한 선형 모드 연결성의 유사한 분석을 수행합니다. 이러한 실험을 통해 우리는 미세 조정된 LLM이 선형적으로 모드 연결되는 경향이 있지만, 모드 연결성이 유지되려면 이 모델들이 반드시 동일한 사전 훈련된 가중치에서부터 미세 조정되어야 한다는 것을 알게 됩니다! 위에서 볼 수 있듯이, [14]에서는 GPT 스타일 LLM, 특히 GPT-2를 활용하여 수많은 보간 전략(interpolation strategies)이 탐구됩니다. 이 연구는 선형 모드 연결성 개념이 현대 언어 모델에도 성공적으로 적용될 수 있음을 입증했습니다.

**언어 모델을 위한 가지치기(Pruning) 및 희소성(Sparsity) (출처: [15])**
이 개요 전반에 걸쳐, 우리는 모델 병합을 가능하게 하는 메커니즘을 설명하는 다양한 연구들을 살펴볼 것입니다. 높은 수준에서 볼 때, 모델 병합이 매우 효과적인 경향이 있는 한 가지 중요한 이유는 대규모 신경망, 특히 LLM이 일반적으로 높은 수준의 희소성(sparsity)을 나타내기 때문입니다. 이러한 모델 내의 가중치(weights)와 활성화(activations) 중 일부만이 중요한 값을 가지며, 다른 값들은 중복되거나 영향력이 미미합니다; 위를 참조하십시오. 결과적으로, 우리는 가지치기(pruning)와 같은 기술을 통해 모델 매개변수의 상당 부분을 성능에 유의미한 영향을 주지 않으면서 제거할 수 있으며, 이는 두 개의 중요한 가중치나 활성화가 서로 충돌할 가능성이 높지 않게 매개변수를 병합할 수 있음을 의미합니다.

**신경망 가지치기(neural network pruning)의 주요 구성 요소**
신경망 가지치기는 대규모 신경망에서 시작하여, 원래 네트워크와 유사한 성능을 유지하면서 더 작은 하위 네트워크를 추출하는 것을 목표로 합니다. 이를 위해 우리는 일반적으로 (위에 표시된) 다단계 프로세스를 따릅니다:
*   모델을 수렴(convergence)할 때까지 훈련합니다.
*   모델의 가중치를 가지치기합니다 (예: 각 계층에서 가장 낮은 크기의 가중치를 제거하는 휴리스틱(heuristic)을 통해).
*   (선택적으로) 모델의 남은 가중치를 원래 값으로 되돌립니다.
*   하위 네트워크(subnetwork)(즉, 가지치기된 모델)를 수렴할 때까지 훈련합니다.

단계 2부터 4까지를 반복적으로 적용함으로써 반복적인 가지치기 전략(iterative pruning strategy)을 구현할 수 있습니다. 이는 한 번에 많은 가중치를 가지치기하는 대신 모델에서 가중치를 점진적으로 제거함으로써 더 높은 성능을 유지할 수 있도록 합니다. 이 전략을 따르면, 원래의 더 큰 모델과 비교할 만하거나 심지어 더 나은 성능을 달성하는 놀랍도록 작은 네트워크를 도출할 수 있습니다. 이러한 이유로 가지치기는 2010년대 후반에 인기 있는 연구 주제가 되었고 오늘날에도 활발한 연구 방향으로 남아 있습니다.

“우리는 로또 티켓 가설(lottery ticket hypothesis)을 명확히 합니다: 밀집되고 무작위로 초기화된 피드포워드 네트워크(feed-forward networks)는 독립적으로 훈련될 때 원래 네트워크와 유사한 반복 횟수에서 유사한 테스트 정확도에 도달하는 하위 네트워크(winning tickets)를 포함합니다.” - 출처: [16]

이전 개요 5 에서 우리는 신경망 가지치기 주제에 대해 깊이 있게 배웠습니다; 여기를 참조하십시오. 더 자세히 알고 싶은 분들을 위해 제가 가장 좋아하는 가지치기 논문들을 아래에 나열했습니다:

*   **심층 신경망에서 구조화된 희소성 학습(Learning Structured Sparsity in Deep Neural Networks)** : 이 논문은 L1-노름 휴리스틱(L1-norm heuristic)(즉, 낮은 크기의 가중치 제거)을 통한 가지치기를 탐구한 최초의 논문이며, 이는 가장 일반적으로 사용되는 가지치기 전략입니다.
*   **효율적인 컨브넷을 위한 필터 가지치기(Pruning Filters for Efficient ConvNets)** : 이 논문은 모델 계층에서 낮은 L1-노름을 가진 필터를 제거함으로써 성능 저하 없이 신경망의 계산 비용을 크게 줄일 수 있음을 보여줍니다.
*   **네트워크 가지치기의 가치 재고(Rethinking the Value of Network Pruning)** : 이 연구는 고성능 하위 네트워크를 얻기 위한 최적의 방법을 결정하기 위해 다양한 가지치기 기술 및 설정에 대한 광범위한 경험적 분석을 수행합니다.
*   **로또 티켓 가설(The Lottery Ticket Hypothesis)** : 이 논문은 신경망의 무작위로 초기화된 가중치 내에 고성능 하위 네트워크가 존재함을 보여주는 로또 티켓 가설(LTH)을 발견하고 분석합니다.

최근 몇 년 동안 매우 인기 있는 연구 주제가 되었음에도 불구하고, 가지치기 아이디어는 신경망에 대한 초기 연구에 깊은 뿌리를 두고 있습니다. 이 아이디어를 탐구한 최초의 연구 중 일부는 1990년대 초 [17, 18]에 작성되었습니다; 아래를 참조하십시오.

(출처: [17, 18])

**LLM 시대의 가지치기(Pruning).**
최근에는 대규모 언어 모델(LLM) 시대에 신경망 가지치기 연구가 현대화되고 재조명되었습니다. [19]에서 저자들은 SparseGPT라고 불리는 가지치기 알고리즘을 제안합니다. 이 알고리즘은 비구조화된 접근 방식(unstructured approach)을 사용하여 GPT 스타일 언어 모델을 한 번에 50% 이상의 희소성(sparsity)으로 가지치기할 수 있으며, 이는 가지치기 후 재훈련이 필요 없음을 의미합니다. 가지치기 절차에서 재훈련 단계를 제거하는 것은 계산 비용을 획기적으로 줄이는 결과를 가져옵니다. 아래에 표시된 SparseGPT 알고리즘은 가지치기 프로세스를 효율적으로 근사화할 수 있는 일련의 희소 회귀 문제(sparse regression problems)로 축소하여 작동합니다.

(출처: [19])

얼마 지나지 않아, [19]의 저자들은 가지치기를 위한 인기 있고 널리 사용되는 기술인 크기 기반 가지치기(magnitude-based pruning)가 LLM에서는 기대만큼 효과적이지 않다는 분석을 수행했습니다. SparseGPT가 이 기술을 개선했지만, 저자들은 이 가지치기 알고리즘이 단일 GPU에서 실행될 때 약 1000억 개 매개변수 LLM에 대해 실행하는 데 약 4-5시간이 걸린다고 언급합니다. 다시 말해, SparseGPT 알고리즘은 재훈련이 필요 없더라도 여전히 상당한 계산 비용을 수반합니다.

“더 작은 네트워크에서 크기 가지치기의 과거 성공을 고려할 때, 이 결과는 LLM이 100배에서 1000배 더 많은 매개변수를 가지고 있음에도 불구하고 직접 가지치기하기가 훨씬 더 어렵다는 것을 시사합니다.” - 출처: [20]

이러한 문제에 대한 해결책으로, Wanda (W eights AND A ctivations에 의한 가지치기) — LLM을 위한 매우 간단하면서도 효과적인 가지치기 접근 방식 — 가 [20]에서 제안되고 분석됩니다. 이 접근 방식은 각 모델의 가중치에 해당 입력 활성화(input activations)를 출력 단위로 곱하여 어떤 가중치를 가지치기할지 결정합니다; 정확한 공식은 아래를 참조하십시오. SparseGPT와 유사하게, 이 기술은 재훈련을 요구하지 않습니다. 또한 Wanda는 전반적으로 더 효율적이며, 가지치기된 모델의 성능을 손상시키지 않으면서 더 높은 수준의 희소성을 달성할 수 있습니다. 이 연구를 통해 우리는 LLM을 효과적으로 가지치기하는 것이 도전적이지만 충분히 가능하다는 결론을 얻게 됩니다.

(출처: [20])

Wanda 내에서 가지치기에 사용된 기술이 무작위적으로 보일 수 있지만, [20]의 알고리즘은 LLM이 각 은닉 계층(hidden layers) 내에 매우 큰 크기의 활성화(activations)를 소수만 가지는 경향이 있다는 최근 관찰에서 영감을 받았습니다. 흥미롭게도, 이러한 큰 크기의 특징(high magnitude features)(또는 이상치(outliers))은 더 큰 모델(예: 약 70억 개 매개변수 이상)의 새로운 속성(emergent property)인 것으로 보입니다.

“약 67억 개 매개변수에서 상전이(phase shift)가 발생하며, 모든 트랜스포머 계층(transformer layers)과 전체 시퀀스 차원(sequence dimensions)의 75%가 극단적인 크기 특징(extreme magnitude features)의 영향을 받습니다.” - 출처: [21]

이 속성은 양자화(quantization) 맥락 [21]에서 처음 관찰되었는데, 여기서 저자들은 이러한 이상치 특징을 적절히 처리하기 위한 트릭을 채택하여 LLM 추론을 위한 더 성능 좋은 8비트 양자화 기술(8-bit quantization technique)을 개발했습니다; 아래를 참조하십시오.

(출처: [21])

그러나 또 다른 연구 [15]는 이 속성을 심층적으로 탐구하여, 이러한 대규모 활성화가 다양한 모델과 훈련 설정 전반에 걸쳐 존재한다는 것을 발견했습니다. 간단히 말해, [15]와 [21]의 연구는 LLM이 놀랍도록 희소한 활성화(sparse activations)를 가지는 경향이 있으며, 이는 더 나은 가지치기를 위해 활용될 수 있음을 보여줍니다.

**왜 이것이 중요할까요?**
가지치기와 모델 병합은 본질적으로 별개의 연구 주제이지만, 동일한 근본적인 아이디어인 희소성(sparsity)에 대한 공동 의존성 때문에 밀접하게 연관되어 있습니다. 가지치기가 풍부한 아이디어를 가진 광범위하게 연구된 주제임을 고려할 때, 가지치기 알고리즘과 관련 연구를 이해하는 것은 모델 병합에 대해 배울 때 매우 유익합니다. 특히, LLM의 방대한 크기와 복잡성을 고려할 때, 희소성 기반 접근 방식은 자원 효율적인 모델 배포와 혁신적인 모델 결합 전략의 핵심 동력이 됩니다. 이러한 기술들은 모델의 핵심 역량을 유지하면서 불필요한 부분을 제거하여, 여러 모델의 지식을 효율적으로 통합하는 길을 열어줍니다.

**모델 병합에 대한 초기 연구**
이제 모델 병합 개념의 근간을 이루는 기본 개념들을 이해했으니, 심층 신경망(deep neural networks)을 위한 모델 병합 개념을 처음 탐구한 주목할 만한 논문들을 살펴보겠습니다. 이 논문들 대부분은 LLM이 대중화되기 전에 발표되었지만, 많은 기술들이 오늘날 우리가 보는 모델 병합 연구에서 재활용되고 있습니다.

**모델 수프(Model soups): 여러 미세 조정된 모델의 가중치를 평균하면 추론 시간 증가 없이 정확도가 향상됩니다 [5]**
(출처: [5])

어떤 다운스트림 작업(downstream task)에 대해 사전 훈련된 모델을 미세 조정할 때, 최적의 훈련 하이퍼파라미터 설정은 종종 사전에 알려져 있지 않습니다. 결과적으로, 우리는 일반적으로 i) 다양한 하이퍼파라미터 조합으로 여러 번의 훈련 시도(training trials)를 수행하고, ii) 별도의 검증 세트(held-out validation set)에서 가장 우수한 성능을 보인 모델을 선택하며, iii) 나머지 모델들은 폐기하는 과정을 거칩니다. 하지만 폐기되는 모델들을 활용하여 앙상블을 구성할 경우, 일반적으로 성능 향상을 기대할 수 있습니다 [6]. 그러나 이 접근 방식은 추론 비용을 급격히 증가시키는 단점을 가집니다. [5]에서 저자들은 이 문제를 해결하기 위한 대안적인 전략, 즉 이 모델들의 가중치를 병합하는 방식을 탐구합니다. 이는 두 가지 장점(성능 향상과 비용 절감)을 동시에 얻을 수 있는 방법입니다!

“모델 수프(Model soups)는 추론 시 단일 모델에 비해 추가적인 계산 비용이나 메모리 없이 앙상블의 성능에 근접할 수 있습니다.” - 출처: [5]

**모델 수프(Model soups).** [5]에서 제안된 핵심 아이디어는 놀랍도록 간단합니다. 우리는 서로 다른 하이퍼파라미터 설정으로 여러 개의 동일한 모델을 미세 조정하고, 이 모델들의 가중치를 통합합니다. 하이퍼파라미터 튜닝(hyperparameter tuning)을 수행할 때 일반적으로 최상의 모델을 제외한 모든 모델을 폐기하지만, 이 접근 방식은 모델 앙상블 연구에서 여러 모델의 예측값을 평균하는 것이 가져다주는 이점에서 영감을 받았습니다. 모델의 가중치를 병합하는 몇 가지 다른 방법이 있습니다! [5]에서 고려되는 기술은 다음과 같습니다:

*   **평균(Average)** : 단순히 모델 가중치들의 균일 평균을 취합니다.
*   **탐욕(Greedy)** : 특정 임계값(threshold)(예: 평균 모델 성능) 이상의 성능을 가진 모델만을 선택하고, 선택된 모델 가중치들의 평균을 취합니다.

이렇게 병합된 모델은 “모델 수프(model soup)”라고 불립니다. [5]의 저자들은 모델 가중치 간의 최적 병합 계수(merging coefficients)를 학습하기 위한 더 정교한 기술도 제안합니다. 그러나 이 접근 방식은 모든 모델을 동시에 메모리에 로드해야 하므로 비실용적입니다. 평균 병합과 탐욕 병합을 비교할 때, [5]에서 탐욕 병합이 일반적으로 더 나은 성능을 달성한다는 것을 알 수 있습니다. 평균 병합의 문제는 특정 하이퍼파라미터 설정이 결과 모델의 일부가 다른 모델에 비해 성능이 저조하게 만들 수 있다는 것입니다. 탐욕 병합은 간단한 성능 필터(performance filter)를 통해 이러한 모델들을 고려 대상에서 제외합니다; 위를 참조하십시오. 더 구체적으로, 탐욕 수프(greedy soups)는 홀드아웃 검증 세트에서의 성능이 향상될 경우에만 각 모델을 수프에 순차적으로 추가하여 구성됩니다. 고려되는 모델 목록은 사전에 검증 세트 성능의 내림차순으로 정렬되어, 탐욕 수프가 최상의 개별 모델보다 나쁘지 않도록 보장합니다.

**이것은 얼마나 잘 작동할까요?**
[5]의 실험은 주로 ImageNet에서의 이미지 분류(image classification) 작업을 고려하지만, CLIP, ALIGN, BASIC, 그리고 여러 비전 트랜스포머(vision transformer)(ViT) 변형을 포함한 다양한 모델이 고려됩니다. 이 모델들은 모두 별도의 대규모 데이터셋(예: WIT 또는 JFT-3B)에서 사전 훈련되고, ImageNet에서 미세 조정되며, ImageNet 6 에서 평가됩니다.

(출처: [5])

이러한 실험의 높은 수준의 결과는 위 표에 요약되어 있습니다. 모델 수에 관계없이 탐욕 수프는 모든 하이퍼파라미터 탐색(hyperparameter sweep)의 최상의 단일 모델보다 일관되게 우수한 성능을 보이며, 대부분의 경우 모델 앙상블의 성능과 거의 일치합니다. 그러나 앙상블과 달리, 모델 수프는 단일 모델에 비해 추가적인 추론 또는 메모리 비용을 발생시키지 않습니다!

(출처: [5])

[5]의 저자들은 ViT-G 모델 수프를 사용하여 90.94% 7 의 테스트 정확도를 달성하며 ImageNet에서 새로운 최첨단 성능에 도달했습니다. 모델 수프는 또한 제로샷(zero-shot) 환경과 ImageNet 테스트 세트의 분포를 넘어서는 새로운 작업에서 더 나은 성능을 보입니다. 또한, 모델 수프는 트랜스포머(transformer)를 사용한 텍스트 분류(text classification) 작업에서 유용한 결과를 산출하는 것으로 나타났습니다; 위를 참조하십시오.

(출처: [5])

**왜 이것이 작동할까요?**
[5]의 저자들은 모델 수프의 효과성을 동기 부여하고 설명하기 위해 광범위한 분석을 제공합니다. 이 분석의 대부분은 선형 모드 연결성에 대한 이전 연구와 유사점을 찾습니다. 위 그림에서 보듯이, 미세 조정된 모델들은 손실 지형의 유사한 분지 내에 위치하는 경향이 있으며, 이는 이 미세 조정된 모델들의 가중치 사이를 보간할 때 손실이 비교적 안정적이며 심지어 감소할 수도 있음을 의미합니다! 최고 성능 모델은 개별 미세 조정된 모델 중 어느 것도 아닙니다. 오히려, 이 모든 모델들 사이의 손실 지형 어딘가에 존재합니다. 따라서 모델 수프를 통해 이 모델들 사이를 보간하는 것은 우리가 더 고성능의 모델을 발견할 수 있도록 합니다!

(출처: [36])

모델 라따뚜이(Model Ratatouille) [36]는 온라인에서 이용 가능한 다양한 미세 조정된 파운데이션 모델을 재활용하는 것을 목표로 하는 모델 수프의 흥미로운 확장 개념입니다. 우리의 목표는 특정 다운스트림 작업에 대해 모델을 미세 조정하는 것입니다. 그러나 단일 모델을 직접 미세 조정하는 대신, 우리는 다음 단계를 수행합니다 (위에 표시됨):

*   다양한 보조 작업(auxiliary tasks)에 대해 미세 조정된 여러 공개 모델을 확보합니다.
*   이 모델들 각각을 우리의 다운스트림 작업에 대해 별도로 미세 조정합니다.
*   모든 미세 조정된 모델의 가중치를 (평균을 통해) 병합합니다.

[36]의 연구는 이러한 기술이 이전 병합 기술보다 우수한 성능을 보이며, 다양한 보조 작업에 대해 미세 조정될 때 이 모델들이 학습한 추가 정보가 모델 수프를 형성하는 데 유용하다는 것을 입증합니다. 이는 특정 작업에 특화된 지식을 가진 모델들을 결합하여 더욱 강력하고 다재다능한 모델을 구축할 수 있음을 시사합니다.

**제로샷 모델의 강건한 미세 조정 [8]**
“제로샷 [파운데이션] 모델이 분포 변화(distribution shift) 하에서 정확도를 감소시키지 않고 미세 조정될 수 있을까요?” - 출처: [8]

파운데이션 모델을 훈련할 때, 우리는 이 모델이 광범위한 데이터 분포에서 잘 작동하기를 기대합니다. 자기 지도 사전 훈련(self-supervised pretraining)의 등장은 이 문제를 크게 해결했습니다. 사전 훈련된 LLM은 모델이 사전 훈련된 방대한 텍스트 코퍼스(text corpus)에서 파생된 상당한 지식 기반 덕분에 다양한 문제를 제로샷 방식으로 해결할 수 있습니다. 여전히, 우리는 특정 대상 도메인(target domain)의 데이터셋에 모델을 미세 조정함으로써 사전 훈련된 모델의 성능을 향상시킬 수 있습니다 8 ; 아래를 참조하십시오.

사전 훈련 및 미세 조정의 묘사

미세 조정의 유용성에도 불구하고, 우리가 알아야 할 단점들이 있습니다! 도메인 특정 데이터셋에 사전 훈련된 모델을 미세 조정하는 것은:

*   해당 특정 도메인의 데이터에 대한 모델 성능을 향상시킵니다.
*   해당 특정 도메인 이외의 데이터에 대한 모델 성능을 저하시킵니다.

간단히 말해, 미세 조정은 모델을 덜 일반적(less generic)으로 만들며, 이는 미세 조정 데이터셋과 다른 데이터에 대한 성능을 저하시킬 수 있습니다. [8]에서 저자들은 간단한 모델 병합 접근 방식을 채택하여 이 문제를 완화하려고 합니다.

**미세 조정과 강건성(robustness).** 미세 조정이 사전 훈련된 모델의 강건성(robustness)에 미치는 부정적인 영향은 직관적으로 이해됩니다. 사전 훈련된 모델을 미세 조정하는 것은 이 모델을 대상 도메인의 데이터 속성에 특화시키며, 이는 더 넓은 의미에서 모델 성능 저하를 초래합니다. 미세 조정이 모델 강건성에 미치는 영향이 직관적으로 이해되지만, [8]의 저자들은 이 관계를 더 자세히 분석합니다. 특히, 모델 성능에 대한 미세 조정의 영향과 관련하여 몇 가지 흥미로운 발견이 요약되어 있습니다:

*   모델의 성능은 대상 분포(target distribution)에서 향상됩니다.
*   모델의 성능은 다양한 분포 변화(distribution shifts)(즉, 대상 분포를 넘어서는 데이터) 하에서 저하됩니다.
*   하이퍼파라미터 설정은 강건성에 매우 큰 영향을 미칩니다.
*   더 “공격적인” 미세 조정(예: 더 큰 학습률(learning rate) 사용)은 이러한 발견을 악화시킵니다. 대상 도메인 성능은 더 많이 향상되지만, 분포 변화 하에서는 성능이 훨씬 더 나빠집니다.

분포 변화 하에서의 정확도를 측정하기 위해, 우리는 단순히 분포 외(out-of-distribution, OOD) 일반화 연구에서 기존 데이터셋을 채택할 수 있습니다. 예를 들어, ImageNet 데이터셋에는 여러 종류의 분포 변화를 연구하는 데 사용될 수 있는 수많은 대체 테스트 세트가 있습니다; 몇 가지 예시는 아래를 참조하십시오.

(출처: [8])

**미세 조정을 위한 가중치 공간 앙상블(Weight-Space Ensembles for Fine-Tuning, WiSE-FT).** [8]에서 제안된 핵심 기술은 매우 간단합니다. 우리는 i) 사전 훈련된 모델에서 시작하여, ii) 특정 대상 데이터셋에 모델을 미세 조정하고, iii) 마지막으로 사전 훈련된 모델과 미세 조정된 모델의 가중치 사이를 보간(interpolate)합니다; 아래를 참조하십시오. 사전 훈련된 모델과 미세 조정된 모델의 가중치 사이를 임의로 보간할 수도 있지만, [8]의 연구에 따르면 단순히 이 가중치들의 평균을 취하는 것이 대부분의 시나리오에서 효과적으로 작동합니다.

WiSE-FT에서 모델 가중치 병합

(출처: [8])

선형 모드 연결성에 대한 연구를 확장하여, [8]의 저자들은 미세 조정된 모델이 일반적으로 관련 기본 모델에 모드 연결되어 있음을 관찰합니다. 더 일반적으로, 우리는 훈련 궤적의 상당 부분을 공유하는 모델들(예: 사전 훈련된 모델과 이 사전 훈련된 모델에서 파생된 모든 미세 조정된 모델)이 모드 연결되는 경향이 있으며, 이는 성능에 치명적인 영향을 주지 않고 이 모델들을 병합할 수 있게 한다는 것을 알게 됩니다.

(출처: [8])

**이것은 잘 작동할까요?**
WiSE-FT의 영향은 주로 ImageNet 데이터셋의 사전 훈련된 CLIP 모델을 사용하여 연구되며, 여기서 사전 훈련된 모델과 미세 조정된 모델을 병합하는 것이 두 모델의 성능 사이에서 만족스러운 중간 지점을 제공한다는 것을 알 수 있습니다. [8]의 분석 결과는 위 그림에 요약되어 있습니다.

(출처: [8])

요컨대, WiSE-FT는 표준 미세 조정을 통해 얻은 모델에 비해 다음과 같은 이점을 제공합니다 (자세한 내용은 위 표 참조):

*   분포 변화 하에서 향상된 정확도.
*   대상 도메인에서 비교할 만한 (또는 향상된) 정확도.

또한 WiSE-FT는 하이퍼파라미터 설정에 대한 모델 강건성의 민감도를 완화할 수 있습니다. 보간 계수(interpolation coefficient) 9 만 변경함으로써 거의 모든 경우에 최상의 하이퍼파라미터 설정 성능을 복구할 수 있습니다. WiSE-FT는 미세 조정 또는 추론 중에 추가적인 계산 비용이 없습니다.

**왜 이것이 잘 작동할까요?**
WiSE-FT의 성능 이점을 관찰하는 것 외에도, 저자들은 사전 훈련된 모델, 미세 조정된 모델, 병합된 모델이 생성한 예측값 사이의 관계를 연구함으로써 이 기술의 메커니즘을 좀 더 깊이 파고듭니다. 흥미롭게도, 이 분석을 통해 미세 조정된 모델이 미세 조정 데이터셋과 유사한 도메인 내 데이터(in-domain data)를 평가할 때 사전 훈련된 모델의 예측값을 자주 무시한다는 것을 알 수 있습니다. 대조적으로, 분포 외 모델(out-of-distribution model)에 대한 예측값은 일반적으로 사전 훈련된 모델에 의해 처리됩니다! 간단히 말해, 병합된 모델은 주어진 입력 예시가 고려하는 데이터(및 작업)에 따라 더 적절한 모델에 자연스럽게 의존합니다.

“전반적으로 WiSE-FT는 간단하고, 우리가 연구한 문제에 보편적으로 적용 가능하며, 몇 줄의 코드로 구현할 수 있습니다. 따라서 우리는 제로샷 모델의 미세 조정을 위해 이를 채택할 것을 권장합니다.” - 출처: [8]

**구현 세부 사항.**
WiSE-FT가 단순히 모델 매개변수의 가중 평균(weighted average)을 취한다는 점을 고려할 때, 이 기술은 실제로 구현하기 매우 쉽습니다! PyTorch 구문(syntax)을 사용한 예시는 아래 알고리즘에 제공됩니다.

(출처: [8])

**추가 연구.**
WiSE-FT는 [42]에서 추가로 분석되며, 이 방법이 “FalseFalseTrue” 현상을 통해 일반화(generalization)를 향상시킨다는 것을 알 수 있습니다. 더 구체적으로, WiSE-FT는 각 모델이 잘못된 예측을 하는 수많은 경우를 수정하는 것으로 관찰됩니다. 병합된 모델은 올바르지만, 두 원본 모델은 모두 틀렸습니다! 이 속성을 이론적으로 분석한 후, 저자들은 이 속성이 OOD 일반화에 대한 다양한 특징 세트(feature sets)의 영향 때문이라고 결론지으며, 따라서 가중치 공간 앙상블이 출력 공간 앙상블보다 우수한 성능을 보이는 능력에 대한 이론적 직관을 (처음으로!) 제공합니다.

(출처: [49])

LLM을 위한 WiSE-FT의 확장인 LM-칵테일(LM-Cocktail)이 [49]에서 제안됩니다. 이 접근 방식은 미세 조정된 언어 모델을 사전 훈련된 기본 모델과 병합하며, 이는 WiSE-FT에서 사용된 전략을 모방합니다. 그러나 이 기술은 다른 도메인의 데이터(즉, 피어 모델(peer models))로 미세 조정된 모델과 같은 추가 모델도 병합에 포함될 수 있으므로 약간 더 일반적입니다; 위를 참조하십시오. LM-칵테일은 특히 여러 전문 모델의 지식을 한데 모아 더욱 강력하고 다재다능한 LLM을 구축하려는 시나리오에서 유용합니다. 이는 다양한 전문 지식을 가진 모델들을 마치 칵테일처럼 혼합하여 시너지를 창출하는 개념입니다.

**모델 스톡(Model Stock): 필요한 것은 단 몇 개의 미세 조정된 모델뿐입니다 [9]**
(출처: [9])

[8]의 저자들은 모델 수프 [5]와 WiSE-FT [8] 논문의 더 최근 확장을 제시하며, 다음 사이의 더 나은 절충점(tradeoff)을 찾는 것을 목표로 합니다:

*   병합된 모델의 성능.
*   훈련(및 병합)해야 하는 미세 조정된 모델의 수.

사전 훈련된 모델로 시작하여, [5]에서 제안된 모델 수프 기술은 여러 독립적인 미세 조정 실행(finetuning runs)을 수행한 다음, 결과 모델 가중치의 평균을 취하도록 요구합니다. 불행히도, 이 기술은 일반적으로 수십 개의 모델을 미세 조정해야 하므로 계산 비용이 많이 듭니다! 대신, WiSE-FT는 단일 모델을 미세 조정하고 이 모델과 사전 훈련된 모델의 가중치 사이를 보간할 것을 제안하지만, 성능이 부족합니다.

“이 전략은 모델 스톡(Model Stock)이라고 적절하게 명명될 수 있으며, 이는 더 최적화된 평균 모델을 도출하기 위해 최소한의 모델을 선택하는 것에 의존함을 강조합니다.” - 출처: [9]

이러한 문제들을 해결하기 위해, [9]의 저자들은 사전 훈련된 모델에 대한 미세 조정된 가중치의 기하학적 속성(geometric properties)을 심층적으로 분석합니다. 이 분석을 통해 그들은 모델 “스톡(stock)”이라고 불리는 효율적인 병합 전략을 고안할 수 있었는데, 이는 단 두 번의 미세 조정 실행만으로 모델 수프와 유사한 성능을 달성하여 총 훈련 비용 측면에서 엄청난 양의 계산을 절약합니다.

(출처: [9])

**기하학적 분석(Geometric analysis).** 이 효율적인 병합 전략에 도달하려면, 미세 조정된 가중치의 속성을 이해해야 합니다. 모델 수프와 WiSE-FT는 실제로 무엇을 하고 있으며, 왜 잘 작동할까요? 이 질문들에 답하기 위해, [9]의 저자들은 50개 이상의 사전 훈련된 CLIP 모델을 미세 조정하고 미세 조정된 가중치들이 서로 어떻게 관련되는지 10 를 연구하여 흥미로운 관찰(위에 묘사됨)에 도달했습니다:

*   모든 미세 조정된 가중치는 중심점(즉, 미세 조정된 가중치의 평균)을 중심으로 하는 얇은 껍질(shell)(또는 구(sphere)) 위에 놓여 있으며, 이는 미세 조정된 가중치와 이 중심점 사이의 거리가 (대략) 일정하다는 것을 의미합니다.
*   중심점은 사전 훈련된 가중치에 비해 공간에서 다른 위치에 있지만, 이 위치들은 여전히 예측 가능한 기하학적 속성을 만족합니다.

이 관찰은 [9]에서 여러 다른 미세 조정 설정, 모델 및 데이터셋을 사용하여 경험적으로 검증됩니다. 더 나아가, [9]의 분석을 통해 이 “중심” 가중치(모든 미세 조정된 가중치의 중심에 위치하는 가중치)가 모든 미세 조정된 모델과 사전 훈련된 모델의 성능을 능가하며 일관되게 최적의 성능을 달성한다는 것을 알 수 있습니다. 이 발견은 모델 수프의 유용성을 설명합니다. 모델 수프는 미세 조정된 모델들의 평균이며, 따라서 잘 작동하는 것으로 밝혀진 이 중심 가중치들의 근사치입니다.

“우리는 성능과 가중치 공간(weight space) 중심과의 근접성 사이에 강한 연관성을 밝히고, 단 두 개의 미세 조정된 모델만을 사용하여 중심에 가까운 가중치를 근사화하는 방법을 소개합니다.” - 출처: [9]

이 분석을 염두에 두고, WiSE-FT는 미세 조정된 모델과 사전 훈련된 모델의 가중치 사이를 단순히 보간하는 것으로 볼 수 있으며, 이는 고성능 중심에 더 가까운 공간의 한 지점을 발견하는 데 사용될 수 있습니다; 아래를 참조하십시오.

(출처: [9])

**이것을 어떻게 사용할 수 있을까요?**
[9]에서 수행된 분석은 놀랍도록 철저하고 흥미롭지만, 세부 사항은 복잡하며 이 게시물의 범위를 벗어납니다. 관심 있는 독자들은 자세한 내용을 위해 논문의 2장과 3장을 확인해 보시기를 강력히 권합니다. 여기서 우리가 답하고자 하는 주요 질문은 다음과 같습니다: 이 정보를 실질적으로 활용하여 더 나은 모델 병합 기술을 어떻게 만들 수 있을까요?

(출처: [9])

높은 수준의 답변은 간단합니다. 사전 훈련된 모델 가중치와 미세 조정된 모델 가중치 사이의 기하학적 관계를 사용하여 중심점(center point)을 효율적으로 근사화할 수 있습니다. [9]에서 발견된 속성을 사용하여 중심점을 직접 해결하는 이 근사화는 단 두 개의 미세 조정된 모델만 생성하면 됩니다; 위를 참조하십시오. 사전 훈련된 모델은 “기준점(anchor point)” 역할을 하며, 우리는 세 모델의 가중치로 형성된 평면(plane)에 투영(projecting)함으로써 중심점을 근사화할 수 있습니다.

모델 스톡(model stock) 생성

(출처: [9])

여기에는 이해하기 다소 어려울 수 있는 많은 복잡한 수학이 있지만, 이 광범위한 분석의 실질적인 결과는 미세 조정된 가중치 사이의 최적 보간 계수를 찾는 다른 방정식(위에 표시됨)일 뿐입니다! 따라서 이 접근 방식은 결국 WiSE-FT와 크게 다르지 않습니다. 우리는 단지 i) 하나의 모델 대신 두 개의 미세 조정된 모델을 훈련하고 ii) [9]의 기하학적 분석에 기반한 더 복잡한 기술을 사용하여 모델을 최적으로 병합합니다. 그러나 WiSE-FT는 그 단순성 때문에 문헌에서 더 널리 채택되고 있습니다.

(출처: [9])

**경험적 결과.**
[9]에서 우리는 미세 조정된 모델 가중치의 평균으로 형성된 중심점(충분히 많은 수의 미세 조정된 모델에 대해 평균이 취해진다고 가정)에 더 가까울수록 대상 도메인과 분포 변화 하에서 모두 더 나은 성능을 제공한다는 것을 알 수 있습니다. [9]의 대부분의 실험은 ImageNet에서 미세 조정된 사전 훈련된 CLIP 모델을 사용하여 수행되었으며, 이는 WiSE-FT [8]의 실험 설정과 일치합니다. 단 두 개의 미세 조정된 모델을 가진 모델 스톡은 ImageNet에서 최첨단 성능에 도달하고, 이 환경에서 수십 개의 미세 조정된 모델을 사용하여 얻은 모델 수프 [5]의 성능과 일치하여 훈련 비용을 크게 절감하는 것으로 나타났습니다; 위를 참조하십시오. 흥미롭게도, 모델 스톡에 더 많은 모델(즉, 세 개 또는 네 개의 미세 조정된 모델)을 추가해도 상당한 성능 이점은 발생하지 않습니다; 아래를 참조하십시오.

**가중치 평균화 기술(Weight Averaging Techniques)**
“우리는 SGD가 일반적으로 최적점의 넓고 평평한 영역 경계 근처의 한 지점으로 수렴한다는 것을 보여줍니다. SWA는 이 영역의 중심에 위치한 지점을 찾을 수 있으며, 종종 훈련 손실은 약간 더 나쁘지만 테스트 오류(test error)는 훨씬 더 좋습니다.” - 출처: [22]

모델 병합의 한 가지 일반적인 변형은 모델의 훈련 궤적 전반에 걸쳐 여러 지점에서 모델 가중치의 평균을 취하는 것입니다. 더 구체적으로, 우리는 i) 훈련 전반에 걸쳐 모델 가중치의 여러 체크포인트(checkpoints)를 기록하고, ii) 여러 체크포인트에서 모델 가중치의 평균을 취하며, iii) 이 평균 가중치를 최종 모델로 사용합니다. 이 기술은 원래 [22] 11 에서 제안되었으며 확률적 가중치 평균화(stochastic weight averaging, SWA) 라고 불립니다; 아래를 참조하십시오.

(출처: [22])

표준 훈련(확률적 경사 하강법 사용)과 비교할 때, SWA는 [22]에서 결과 모델이 더 잘 일반화(generalize)하도록 돕는 것으로 나타났습니다. 게다가 이 기술은 구현하기 쉽고 계산 오버헤드(computational overhead)가 없지만, 대안적인 기술(예: 모델 앙상블 생성)은 추론 시점에 계산량이 크게 증가합니다. 우리는 사전 훈련된 네트워크로 시작하여 미세 조정 프로세스 중에 SWA를 적용하며, 이는 체크포인트가 모드 연결되도록 보장합니다 [13].

수많은 다른 가중치 평균화 기술들도 탐구되었습니다:

*   **DiWA** [35]는 평균화되는 모델의 다양성을 개선함으로써 이전 가중치 평균화 기술을 확장합니다. 이는 특히 다양한 관점을 가진 모델을 통합할 때 유용하며, 결과 모델의 강건성을 높일 수 있습니다.
*   **SWAD** [41]는 손실 지형에서 더 나은 일반화 속성을 가진 더 평평한 최소점(flatter minima)을 찾는 확률적 가중치 샘플링 전략(stochastic weight sampling strategy)을 통해 SWA를 확장합니다. 평평한 최소점은 일반적으로 더 넓은 영역에서 낮은 손실을 유지하므로, 새로운 데이터에 대한 일반화 성능이 우수하다고 알려져 있습니다.
*   **잊기 위한 융합(Fuse to Forget)** [43]은 평균화된 모델 내 지식의 속성을 연구하며, 결과 모델이 i) 공유되지 않은 지식을 잃고 ii) 공유된 지식이 강화되는 경향이 있음을 발견합니다. 이 현상은 모델 병합이 어떻게 지식 증류(knowledge distillation) 효과를 가질 수 있는지를 보여줍니다.
*   [44]의 저자들은 가중치 평균화가 자동 음성 인식(automatic speech recognition, ASR) 모델이 새로운 작업에 적응할 때 오래된 작업의 치명적 망각(catastrophic forgetting)을 완화하는 메커니즘으로 사용될 수 있음을 보여줍니다. 이는 연속 학습(continual learning) 문제에서 모델의 안정성을 유지하는 데 중요한 역할을 합니다.
*   [45]에서 우리는 가중치 평균화가 강화 학습(reinforcement learning, RL) 내 이동(locomotion)을 위한 학습된 정책(learned policies)을 병합하는 데 유용하다는 것을 알 수 있으며(이는 “결정” 트랜스포머(decision transformer)로 구현됨), [46]은 가중치 평균화가 심층 신경망을 사용한 RL의 훈련 안정성(training stability)을 개선하는 데 일반적으로 유용하다는 것을 보여줍니다.

**가중치의 EMA.**
유한하고 이산적인 수의 모델 체크포인트에 대해 평균을 취하는 대신, 훈련 프로세스 전반에 걸쳐 모델 가중치의 지수 이동 평균(exponentially moving average, EMA)을 취할 수 있습니다. SWA의 확장인 이 기술은 2010년대 후반에 비전 모델(예: InceptionNet, EfficientNet, MnasNet 등)에 의해 많이 채택되었지만, 논문에서는 일반적으로 다루어지지 않습니다. 이는 이 모델들의 코드 저장소에서 찾을 수 있는 실용적인 구현 세부 사항에 가깝습니다. 그러나 훈련 중 EMA 사용 개념은 원래 Adam 옵티마이저(optimizer) 논문 [24]에 언급되어 있습니다; 여기 7.2절을 참조하십시오.

(출처: [26])

EMA를 통해 얻은 모델 또는 예측값을 자기 지도 학습(self-supervised learning) 또는 준 지도 학습(semi-supervised learning)의 목표로 사용하는 아이디어도 많이 탐구되었습니다 [25, 26]; 위를 참조하십시오. EMA는 특히 불안정한 훈련 과정에서 모델의 가중치를 부드럽게(smooth) 만들어 일반화 성능을 향상시키는 데 기여합니다. 이는 최근 LLM의 대규모 훈련에서도 중요한 안정화 기법으로 활용되고 있습니다.

**LLM으로의 확장.**
[27]에서 저자들은 LLM 사전 훈련을 위한 SWA의 확장을 탐구하며, 이는 더 빠른 수렴과 향상된 일반화로 이어집니다. [27]에서 제안된 기술은 두 가지 주요 관찰에서 영감을 받았습니다:

*   더 큰 학습률로 훈련된 모델은 훈련 궤적을 따라 모델 체크포인트를 평균하는 것에서 더 많은 이점을 얻습니다.
*   훈련 프로세스에서 더 멀리 떨어진 모델 궤적을 평균하는 것은 더 큰 이득으로 이어집니다.

이러한 발견을 바탕으로, 저자들은 LLM의 훈련 궤적을 따라 슬라이딩 윈도우(sliding window)를 사용하여 체크포인트 평균화를 수행하는 LAWA ( LA test W eight A veraging)를 제안합니다; 그림은 위를 참조하십시오. LAWA는 훈련 프로세스 전반에 걸쳐 샘플링된 체크포인트의 선입선출(first-in-first-out) 버퍼(buffer)를 유지하고, 이 버퍼에서 가장 최근 k개의 체크포인트에 대한 평균을 계산합니다. 체크포인트는 많은 훈련 단계 간격을 두고 버퍼에 삽입되어, 더 먼 체크포인트(즉, 훈련의 초기 단계에서 온 체크포인트)가 병합 프로세스에 포함되도록 보장합니다; 아래를 참조하십시오.

(출처: [27])

[27]에서 우리는 LAWA가 더 큰 학습률이 일반적으로 선호되는 언어 모델링 도메인에서 EMA 및 SWA와 같은 기존 체크포인트 평균화 기술보다 우수한 성능을 보인다는 것을 알 수 있습니다. LAWA로 훈련된 LLM은 더 빠르게 수렴하고 더 잘 일반화합니다. LAWA의 관찰된 이점은 평균화를 위해 샘플링되는 체크포인트 사이에 더 많은 훈련 단계를 추가할수록 향상되는 경향이 있습니다. 이는 모델 훈련 궤적의 다양성을 포착하고, 이를 통해 더욱 강건하고 일반화 가능한 모델을 구축하는 데 기여합니다.

**대규모 언어 모델을 위한 모델 병합**
이제 모델 병합에 대한 초기 연구에 대해 배웠으니, 태스크 벡터(task vectors), TIES, DARE 등과 같은 더 최근의 기술들을 살펴보겠습니다. LLM 연구의 최근 발전을 추적해 온 사람들은 이러한 기술들을 보았을 것입니다. 이러한 알고리즘 중 다수는 mergekit [54]와 같은 LLM용 인기 있는 오픈 소스 소프트웨어에서 지원됩니다. 이 섹션에서는 LLM 병합에 사용되는 가장 일반적인 알고리즘을 살펴보고, 모델 병합이 LLM 정렬 프로세스를 어떻게 변화시켰는지 알아보겠습니다.

**태스크 산술(Task Arithmetic)로 모델 편집 [1]**
“태스크 산술(task arithmetic)을 통해 실무자들은 데이터 접근이나 추가 훈련 없이도 자신이 만든 모델 또는 공개적으로 사용 가능한 수많은 모델로부터 지식을 재사용하거나 전이할 수 있습니다.” - 출처: [1]

실무자로서 우리는 일반적으로 i) 사전 훈련된 모델(예: LLaMA-3 또는 Mistral)로 시작하고 ii) 이 모델을 우리가 원하는 사용 사례에 맞게 조정(adapting)(또는 조종(steering))함으로써 작업을 해결합니다. 예를 들어, 우리는 모델을 다운스트림 작업에 대해 추가로 미세 조정하거나, 모델의 편향(bias)을 줄이거나, 정렬(alignment)을 수행할 수 있습니다. 이를 위해 우리는 두 가지 기본적인 옵션을 사용할 수 있습니다:

*   모델의 프롬프트(prompt) 내에서 원하는 동작을 지시(instruction)로 지정합니다 (즉, 프롬프트 엔지니어링(prompt engineering)을 사용합니다).
*   추가 데이터에 모델을 미세 조정합니다.

일반적으로 우리는 단순성 때문에 먼저 프롬프팅(prompting)을 통해 문제를 해결하려고 시도하고, 성능이 필요하거나 기대하는 수준에 미치지 못하면 미세 조정을 수행합니다. 그러나 LLM을 미세 조정하는 과정은 작업별 데이터(task-specific data)를 필요로 하며, 시간 및 금전적 비용 모두에서 비쌀 수 있습니다. [1]에서 저자들은 태스크 산술(task arithmetic)이라고 불리는 사전 훈련된 모델을 편집하는 훨씬 더 간단하고 쉬운 방법을 제안합니다.

태스크 벡터(task vector)의 묘사 (출처: [1])

**태스크 벡터(task vector)란 무엇일까요?**
[1]에서 처음 소개된 개념은 태스크 벡터(task vector)로, 이는 단순히 사전 훈련된 모델의 가중치에서 미세 조정된 모델의 가중치를 뺀 결과로 얻어지는 벡터를 의미합니다; 위를 참조하십시오. 직관적으로, 태스크 벡터는 미세 조정을 통해 학습된 특정 작업을 해결하는 데 필요한 모든 정보를 압축적으로 인코딩합니다. 이러한 태스크 벡터는 신경망의 매개변수 공간 내에 존재하며, 이는 우리가 편집하려는 모델의 가중치와 동일한 크기와 형태를 가진다는 것을 의미합니다. [1]에서 우리는 이러한 태스크 벡터가 사전 훈련된 모델의 동작을 변경하는 데 활용될 수 있음을 알 수 있습니다. 태스크 벡터는 프롬프팅(prompting) 또는 미세 조정(finetuning)에 대한 간단하고 저렴한 대안입니다. 특히, 위에서 보듯이 모델의 매개변수와 태스크 벡터 사이에 산술 연산(arithmetic operation)을 수행하여 모델을 편집할 수 있습니다. 스케일링 항(scaling term)은 일반적으로 홀드아웃 검증 세트를 통해 튜닝됩니다. 직관적으로, 이러한 태스크 벡터는 우리 모델의 매개변수를 원하는 동작을 가진 모델의 매개변수 방향으로 이동시킵니다. 이 접근 방식은 모든 모델이 정확히 동일한 아키텍처를 공유해야 합니다.

**산술의 종류.**
기본적인 덧셈 외에도, [1]에서 태스크 벡터로 수행할 수 있는 여러 형태의 의미 있는 산술 연산이 있음을 알 수 있습니다; 위를 참조하십시오. 새로운 기술을 학습하기 위해 태스크 벡터를 추가하거나, 기술을 제거하기 위해 태스크 벡터를 부정(negate)할 수 있습니다. 심지어 여러 태스크 벡터를 한 번에 추가하거나 부정할 수도 있습니다!

“벡터를 부정하는 것은 바람직하지 않은 행동을 제거하거나 작업을 잊는 데 사용될 수 있으며, 태스크 벡터를 추가하는 것은 더 나은 다중 작업 모델(multi-task models)로 이어지거나 단일 작업의 성능을 향상시키기도 합니다.” - 출처: [1]

더 나아가, 저자들은 [1]에서 태스크 벡터 간의 유추(analogies)도 성립한다는 것을 발견합니다. “A는 B에 대한 C는 D에 대한”과 같은 유추 관계를 가진 네 가지 작업 A, B, C, D가 있다고 가정해 봅시다. 그런 다음, 아래에 표시된 태스크 벡터를 사용하여 작업 D의 성능을 향상시킬 수 있습니다. 여기서 우리는 다음을 통해 태스크 벡터를 구성합니다:

*   작업 A와 B 사이의 태스크 벡터 차이를 찾습니다.
*   이 차이를 작업 C의 태스크 벡터에 추가합니다.

유추 기반 태스크 벡터(Analogy-based task vector) (출처: [1])

**실험 결과.**
태스크 벡터는 [1]에서 LLM과 전문 모델(예: 이미지 및 텍스트 분류기(text classifiers))을 포함한 수많은 유형의 모델에 적용됩니다. 우리는 태스크 벡터를 추가하고 부정하는 것이 분명히 효과적임을 알 수 있습니다. 예를 들어, 유해한 텍스트에 대해 LLM을 미세 조정하여 유해성 태스크 벡터(toxicity task vector)를 얻을 수 있습니다. 그런 다음, 이 태스크 벡터를 부정함으로써 LLM을 덜 유해하게 만들 수 있습니다; 아래를 참조하십시오.

(출처: [1])

우리는 또한 부정을 통해 특정 이미지 분류 작업을 잊을 수 있으며, 덧셈을 통해 새로운 작업(심지어 여러 작업을 동시에)을 학습할 수 있습니다. 예를 들어, 아래 이미지는 태스크 벡터 쌍이 다운스트림 작업에서 이미지 분류기의 성능을 어떻게 향상시킬 수 있는지 보여주며, 표는 다운스트림 작업에 대해 미세 조정된 LLM에서 얻은 태스크 벡터가 추가 미세 조정 없이 해당 작업에서 모델의 성능을 향상시키는 데 사용될 수 있음을 보여줍니다!

(출처: [1])

또한, 이러한 성능 향상은 제어 작업(control tasks)에서의 관련 성능 저하를 피하는 것으로 보입니다. 즉, 모델은 태스크 벡터의 결과로 다른 영역에서 나빠지지 않습니다. 유사한 실험 결과는 유추 태스크 벡터(analogous task vectors)에서도 관찰되며, 여기서 대부분의 태스크 벡터가 직교(orthogonal)하며 새로운 도메인으로 일반화하는 데 사용될 수 있음을 알 수 있습니다. 여러 면에서 이 분석은 단어 벡터(word vectors)에 대한 초기 분석을 연상시키며, 여기서 우리는 관련 단어의 벡터들 사이에 유사한 유추 관계를 관찰했습니다; 아래를 참조하십시오.

(출처)

**주요 이점.**
프롬프팅(prompting) 또는 미세 조정(finetuning)과 비교할 때, 태스크 산술을 통한 모델 편집은 저렴하고 쉽습니다. 훈련을 위해 외부 데이터나 GPU가 필요하지 않습니다. 오히려, 우리는 미세 조정된 모델에 접근하기만 하면 됩니다. 그 중 많은 모델이 이미 온라인에서 사용 가능합니다! 태스크 산술은 다른 태스크 벡터를 빠르게 실험하기 위해 모델 가중치에 대한 요소별 연산(element-wise operations)만 필요로 합니다. 따라서 우리는 공개적으로 사용 가능한 모델로부터 지식을 쉽게 재사용하거나 전이할 수 있습니다. 이는 AI 개발의 민주화를 가속화하고, 사용자들이 특정 목적에 맞게 모델을 '수술'하듯이 정교하게 조작할 수 있는 새로운 가능성을 열어줍니다.

**TIES-병합(TIES-Merging): 모델 병합 시 간섭(Interference) 해결 [2]**
“한 모델에는 영향력이 있지만 다른 모델에는 중복되는(즉, 영향력이 없는) 매개변수를 병합할 때, 영향력 있는 값이 중복되는 값에 의해 가려져 전체 모델 성능을 저하시킬 수 있습니다.” - 출처: [2]

온라인에서 작업별 미세 조정 모델이 확산됨에 따라, 모델 병합은 이러한 모델들을 통합하는 데 도움이 될 수 있는 유망한 기술입니다. 그러나 기본적인 모델 병합 기술(예: 매개변수의 평균 또는 가중 평균)의 성능은 더 많은 수의 모델을 병합할수록 저하되는 경향이 있습니다. [2]에서 저자들은 태스크 벡터 기반 모델 병합 환경 [1]을 연구하고, 모델 병합으로 인한 성능 저하가 병합 과정에서 모델 매개변수 사이에 발생하는 “간섭(interference)”에 의해 주로 발생한다는 것을 확인합니다. 특히, 두 가지 주요 간섭 원인이 확인됩니다:

*   **중복 매개변수(Redundant parameters)** : 태스크 벡터의 많은 매개변수는 중복되며, 이 매개변수를 제거해도 성능에 영향을 미치지 않습니다.
*   **부호 불일치(Sign disagreements)** : 특정 매개변수는 일부 모델에서는 양수 값을 가지고 다른 모델에서는 음수 값을 가질 수 있으며, 이는 충돌을 야기합니다.

이러한 다양한 간섭 패턴의 개략적인 묘사는 아래에 제공됩니다.

(출처: [2])

이 간섭이 발생하고 있음을 증명하기 위해, 우리는 모델 매개변수의 기본 속성을 연구할 수 있습니다. 아래 (왼쪽) 그림에서 우리는 먼저 모델 성능이 주로 소수의 (큰 크기의) 매개변수에 의해 결정되며, 대부분의 다른 매개변수는 중복된다는 것을 알 수 있습니다. 즉, 이 매개변수들을 제거해도 모델 성능에 영향을 미치지 않습니다 12 . 마찬가지로, 부호 충돌(sign conflicts)은 매우 흔하며 고려되는 모델 수가 증가할수록 더 흔해진다는 것을 알 수 있습니다.

(출처: [2])

**간섭 처리.** [2]에서 간섭을 완화하기 위해 고안된 방법인 T r I m, E lect S ign, and Merge (TIES-병합(TIES-Merging))는 태스크 벡터 기반 모델 병합 프로세스에 세 가지 추가 단계를 추가합니다:

*   **가지치기(Trim)** : 각 태스크 벡터에서 영향력 있는 가중치(즉, 가장 큰 크기 값의 상위 K%)만 유지하고 나머지는 0으로 설정합니다. 이는 불필요한 노이즈를 제거하고 핵심적인 지식만 추출하는 과정입니다.
*   **부호 선택(Elect Sign)** : 태스크 벡터 전체에 걸쳐 각 요소에 대한 총 최고 크기의 부호를 선택합니다(이는 부호 벡터 13 를 생성함). 이는 태스크 벡터 전체에 걸쳐 요소별 합계를 취하고 각 결과 요소가 양수인지 음수인지 확인하여 이루어집니다. 이 단계는 상충되는 방향의 가중치를 조정하여 일관성을 확보합니다.
*   **분리 병합(Disjoint Merge)** : 다수 부호와 일치하는 태스크 벡터 값의 평균을 취하여, 가지치기되었거나 부호 충돌이 있는 매개변수를 무시합니다. 이는 병합 과정에서 발생할 수 있는 충돌을 최소화하고 안정적인 통합을 가능하게 합니다.

이 세 가지 추가 단계를 완료하면, 결과 태스크 벡터를 사용하여 정상적으로 모델 병합을 수행할 수 있습니다. TIES-병합 내의 세 단계는 아래에 묘사되어 있습니다. 흥미롭게도, [2]에서 태스크 벡터 구성 요소의 상위 20%만 유지해도 안정적인 성능을 보인다는 것을 알 수 있습니다. 이는 태스크 벡터 구성 요소의 대다수가 중복된다는 것을 나타냅니다!

(출처: [2])

**간섭이 적을수록 이점이 있습니다.**
TIES-병합이 경험적으로 분석될 때, 우리가 배울 수 있는 다양한 흥미로운 발견들이 있습니다. 전반적으로, TIES 병합은 다양한 실험 설정에서 명확한 이점을 제공한다는 것을 알 수 있습니다; 아래를 참조하십시오. 특히, TIES는 여러 양식(modalities)(텍스트 및 비전)에 잘 작동하며, 매개변수 효율적인 미세 조정(parameter-efficient finetuning)과도 호환됩니다.

(출처: [2])

기준선 기술과 비교할 때, TIES-병합은 새로운 작업에 더 잘 일반화되고, 병합되는 모델 수가 (합리적으로) 증가함에 따라 향상된 스케일링 속성(scaling properties)을 가지는 것으로 나타났습니다; 아래를 참조하십시오.

(출처: [2])

TIES-병합의 두 가지 구성 요소(중복 매개변수 제거 및 다수 부호 선택)는 모두 중요하지만, 다수 부호를 올바르게 추정하는 것이 특히 중요한 것으로 보입니다. 예를 들어, 큰 크기의 매개변수 부호를 뒤집으면 성능이 급격히 저하됩니다. 또한, 저자들은 [2]에서 다중 작업 방식으로 훈련된 모델의 부호를 취하여 다수 부호를 추정하는 오라클(oracle)을 만드는 흥미로운 실험을 포함합니다. TIES-병합의 선택 과정에서 이 부호 오라클을 사용하는 것이 실제로 성능을 향상시키는 것으로 나타났습니다!

**추가 미세 조정.**
전통적인 모델 병합 설정을 넘어서기 위해, 우리는 병합을 통해 얻은 모델로 추가 미세 조정을 수행할 수 있습니다. 이 도메인에서 TIES-병합은 [2]에서 더 나은 시작점을 제공하는 것으로 나타났습니다. 특히, TIES-병합을 통해 얻은 모델은 추가 미세 조정 후 기준선 병합 기술을 통해 얻은 모델보다 우수한 성능을 보입니다; 아래를 참조하십시오.

(출처: [2])

**언어 모델은 슈퍼 마리오: 동종 모델로부터 능력을 공짜로 흡수하기 [3]**
(출처: [3])

“엑스맨 아포칼립스에서 캐릭터는 다른 뮤턴트의 힘을 흡수하여 자신을 강화할 수 있습니다… 슈퍼 마리오의 주인공은 게임 내 아이템을 흡수하여 초능력을 얻을 수 있습니다… 우리는 놀랍게도 언어 모델(LM)이 재훈련이나 심지어 GPU 없이도 다른 모델을 흡수하여 능력을 향상시킬 수 있음을 발견합니다.” - 출처: [3]

[3]의 저자들은 기존 모델 병합 방법에 대한 추가 사항을 제안하는데, 이는 지도 미세 조정(supervised finetuning, SFT)을 거친 언어 모델에 특히 효과적입니다. 기본 모델과 SFT 후 얻은 모델 사이의 매개변수 값 차이(이를 “델타 매개변수(delta parameters)”라고 함)를 연구할 때, [3]에서 (다시 한번) 이 매개변수 값들이 많은 중복성을 가지고 있음을 알 수 있습니다. 결과적으로, 이 델타 매개변수 중 다수는 [3]에서 제안된 D rop A nd RE scale (DARE)이라는 기술을 통해 제거될 수 있습니다. DARE 프로세스는 SFT로 미세 조정된 언어 모델을 모델 병합에 훨씬 더 적합하게 만듭니다.

(출처: [3])

**DARE란 무엇일까요?**
[3]에서 제안된 DARE(Drop And REscale) 개념은 사실 매우 간단합니다. 우리는 단지:

*   델타 매개변수를 무작위로 제거합니다 (확률 p로).
*   남은 매개변수를 1 / (1 - p) 계수로 재조정(rescale)합니다.
*   남은 가지치기되고 스케일링된 매개변수를 사전 훈련된 기본 모델의 가중치에 추가합니다.

이 단계들은 위 그림에 요약되어 있습니다. 주목할 점은 DARE가 모델 병합 기술 그 자체는 아니라는 것입니다. 오히려, 이는 SFT 모델 내 델타 매개변수를 희소화(sparsifying)하는 기술로, 경험적으로 결과 모델의 성능에 최소한의 영향을 미치는 것으로 밝혀졌습니다. 실제로, 우리는 DARE를 사용하여 충분히 큰 언어 모델의 델타 매개변수의 최대 99%를 제거할 수도 있습니다; 아래를 참조하십시오. 이러한 발견은 SFT 모델의 델타 매개변수가 매우 중복된다는 것을 보여줍니다.

(출처: [3])

**모델 병합에의 적용.**
DARE 자체는 모델 병합 기술이 아니지만, 기존 방법(예: TIES-병합 [2])에 유용한 플러그인(plug-in)입니다. DARE가 고려하는 델타 매개변수는 이전 모델 병합 기술 [1]이 고려하는 태스크 벡터와 동일합니다. DARE는 기본 모델의 성능을 손상시키지 않으면서 이러한 태스크 벡터를 희소화하며, 이는 이 모델들의 매개변수가 실제로 병합될 때 간섭을 완화합니다! 병합되는 모델들이 동일한 백본(backbone)을 공유한다고 가정할 때, DARE가 적용된 여러 모델을 병합할 때 간섭 발생 가능성은 훨씬 낮습니다. 이 모델들 내의 많은 델타 매개변수가 0으로 설정될 것이기 때문입니다.

(출처: [3])

[3]에서 저자들은 DARE를 적용하거나 적용하지 않고 인코더 전용(encoder-only) 및 디코더 전용(decoder-only) 모델을 포함한 다양한 종류의 언어 모델을 병합합니다. 위 표에서, 디코더 전용 LLM에 대한 기존 모델 병합 기술 위에 DARE를 사용하는 것이 병합된 모델의 성능을 (약간) 향상시키는 경향이 있음을 알 수 있습니다. 이러한 성능 차이는 여러 전문 모델(예: 지시 따르기, 수학, 코드 모델)을 병합할 때 더 두드러집니다. 그 유용성을 입증하기 위해, DARE는 NeuralBeagle / Turdus ( supermario-v1 ) 및 WildMorcoroni / WestSeverus ( supermario-v2 ) 모델을 병합하여 두 개의 70억 개 매개변수 LLM을 생성하는 데 사용됩니다. 이 모델들은 Open LLM 리더보드에서 70억 개 모델 중 최고 성능(당시)을 달성합니다; 아래를 참조하십시오.

(출처: [2])

DARE의 성능 영향은 인코더 전용 모델에서 훨씬 더 두드러집니다; 아래 (왼쪽)를 참조하십시오. 각 SFT 모델에서 소수의 델타 매개변수만 유지하면서도 병합 후 여러 전문 모델의 성능을 유지할 수 있습니다. 그러나 DARE의 재조정 단계는 더 높은 수준의 희소성 하에서 성능에 필수적입니다; 아래 (오른쪽)를 참조하십시오.

(출처: [3])

**항상 DARE를 사용할 수 있을까요?**
DARE는 언어 모델에 대한 유용한 통찰력(즉, 델타 매개변수가 매우 희소함)을 제공하는 희소화 기술이며, 모델 병합 성능에 약간의 향상을 가져올 수 있습니다. 그러나 DARE는 모든 설정의 모델에 적용 가능한 것은 아닙니다. [3]에서 우리는 SFT를 통해 미세 조정된 언어 모델이 고유하게 작은 델타 매개변수를 가진다는 것을 알 수 있습니다. 즉, 사전 훈련된 LLM에 최소한의 수정만 이루어집니다. 유사한 모델이 연속 사전 훈련(continued pretraining) 설정을 사용하여 미세 조정될 때, 우리는 훨씬 더 큰 크기의 델타 매개변수를 관찰합니다. 결과적으로, 이 설정에서 DARE를 적용하는 것은 성능에 더 해로우며, 특히 더 많은 비율의 델타 매개변수를 제거할 때 그렇습니다.

“이 발견은 SFT가 주로 사전 훈련된 LM의 능력을 잠금 해제하는 것이지, 새로운 기능을 도입하는 것이 아님을 더욱 확인시켜 줍니다.” - 출처: [3]

이 발견은 표면적 정렬 가설(Superficial Alignment Hypothesis) [4]에 대한 이전 분석과 관련이 있으며, 이는 다음을 가정합니다:

*   언어 모델의 모든 지식은 사전 훈련 중에 학습됩니다.
*   정렬은 모델이 이 지식을 적절하게 표현하는 방법(예: 스타일, 형식, 어조 등)을 가르치는 역할을 합니다.
*   이 때문에 정렬은 데이터 효율적일 수 있습니다.

이를 염두에 두면, 정렬 기술인 SFT로 미세 조정된 언어 모델이 사전 훈련된 모델에 비해 상대적으로 작은 델타를 보이는 것에 대해 너무 놀라서는 안 됩니다. 마찬가지로, 연속 사전 훈련은 일반적으로 모델에 새로운 지식을 주입하는 목적을 가지므로 더 큰 델타를 가져야 합니다. DARE는 이러한 LLM의 학습 메커니즘에 대한 깊은 이해를 바탕으로, 특정 종류의 모델 병합에 최적화된 기법을 제공합니다. 이는 모든 모델 병합 시나리오에 대한 만능 해결책은 아니지만, SFT 모델의 효율적인 활용을 위한 중요한 도구로 자리매김하고 있습니다.

**WARP: 가중치 평균 보상 정책(Weight Averaged Rewarded Policies)의 이점 [10]**
“가중치 평균화는 처음에는 주로 판별 작업(discriminative tasks)에 사용되었지만… 이제 생성 작업(generative tasks)에도 인기를 얻고 있습니다. KL 제약 RLHF(KL-constrained RLHF)에서의 사용은 이미 초기 성공을 보여주었습니다.” - 출처: [10]

우리가 보았듯이, 모델 병합은 딥러닝 내에서 흥미로운 응용과 기술의 오랜 역사를 가지고 있습니다. 그러나 최근에는 LLM 정렬(alignment) 맥락에서 모델 병합이 탐구되는 것을 보기 시작했습니다. 이 도메인에서 모델 병합의 성공은 최첨단 모델(frontier models) 훈련에 사용되는 파이프라인(pipelines)에 상당한 영향을 미쳤습니다. 병합은 일반적으로 사용되는 구성 요소가 되고 있습니다.

**정렬(alignment) 복습.**
대부분의 LLM은 사전 훈련(pretraining), 지도 미세 조정(supervised finetuning, SFT) 및 인간 피드백으로부터의 강화 학습(reinforcement learning from human feedback, RLHF)을 포함하는 3단계 프로세스를 사용하여 훈련됩니다; 아래를 참조하십시오. 사전 훈련 동안, 우리는 레이블 없는(unlabeled) 대량의 텍스트에 대해 다음 토큰 예측(next token prediction)을 사용하여 언어 모델을 훈련하여 모델 내에 큰 지식 기반을 구축합니다. 여기서부터 SFT 및/또는 RLHF를 수행합니다. 이러한 알고리즘은 LLM 미세 조정(또는 정렬) 프로세스를 구동하며 사전 훈련에 비해 계산 비용이 적게 듭니다.

언어 모델 훈련 및 정렬 단계

일반적으로 우리는 먼저 (상대적으로) 작은 14 고품질 예시 세트에 대해 SFT를 수행하여 RLHF를 위한 더 나은 “시작점”을 제공합니다. 그런 다음, 새로운 선호도 데이터(preference data) 배치를 지속적으로 수집하고 모델을 추가로 미세 조정함으로써 RLHF를 반복적인 방식(iterative fashion)으로 적용합니다. 정렬의 목적은 LLM 내에 새로운 지식을 주입하는 것이 아니라, 모델이 기존 지식을 인간 사용자에게 선호되는 방식으로 표현하는 방법을 가르치는 것입니다.

KL 발산(KL divergence)을 포함한 RLHF 목표 (출처: [10])

**왜 모델 병합이 필요할까요?**
RLHF를 사용할 때, 우리는 일반적으로 사용되는 목표에 쿨백-라이블러(Kullback-Leibler, KL) 발산 항(divergence term)(위에 표시됨)을 추가하는데, 이는 현재 모델과 SFT 모델 또는 다른 기준 모델(anchor model) 사이의 거리를 측정합니다. 높은 수준에서, 이 발산 항은 RLHF를 사용한 훈련 중에 모델이 얼마나 많이 변했는지를 포착합니다. 이 항이 너무 커지지 않도록 함으로써, 우리는 다음과 같은 문제를 피할 수 있습니다:

*   사전 훈련으로부터의 지식 망각(즉, 정렬 세금(alignment tax) [28]).
*   보상 해킹(Reward hacking)(예: 장황하고, 안전하지 않거나, 결함 있는 출력).

모델 병합은 이러한 RLHF의 복잡성을 관리하고, 특히 여러 보상 모델(reward models)이나 다양한 정렬 목표를 통합해야 할 때 중요한 역할을 합니다. 예를 들어, 안전성, 유용성, 그리고 특정 전문 지식을 동시에 갖춘 LLM을 구축하기 위해서는 각 목표에 특화된 모델들을 병합하는 것이 효과적인 전략이 될 수 있습니다. 이는 단일 모델을 모든 목표에 대해 미세 조정하는 것보다 훨씬 효율적이고 유연한 접근 방식입니다.