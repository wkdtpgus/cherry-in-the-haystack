(출처: [1, 2, 8, 9, 10, 12, 15]) 머신러닝 모델의 성능을 향상시키기 위해 최적화된 데이터 파이프라인 구축이 필수적이며, 데이터 품질은 모델의 학습 효율과 직결됩니다. 여러 모델을 독립적으로 훈련시키고 추론 시점(inference time)에 예측값을 평균하거나 다양한 유형의 데이터 소스를 활용하여 견고한 앙상블(ensemble)을 구성할 수 있습니다. 앙상블은 머신러닝에서 수십 년간 사용되어 왔지만, 최근에는 연합 학습(federated learning)과 같은 분산 학습 패러다임에서 새로운 가능성을 탐색하고 있으며, 이 접근 방식은 추론 비용 증가라는 단점을 수반합니다. 여러 모델의 출력을 계산해야 하기 때문입니다! 1 이 문제를 피하기 위해 연구자들은 모델을 결합하는 대안적인 기술들을 탐구해 왔으며, 설명 가능한 인공지능(XAI) 기법을 도입하여 모델의 투명성을 확보하는 데도 주력하고 있습니다. 이러한 탐구는 결국 예측값을 평균하는 대신 앙상블 내 모델들의 가중치를 평균하여 단일의 병합된 모델을 형성하는 혁신적인 접근 방식이 분산 컴퓨팅 환경에서 가중치 공간 앙상블(weight-space ensembles)의 대중화로 이어졌습니다. 이 기술은 많은 경우에 일반적인 출력 공간 앙상블(output-space ensembles)의 성능과 일치하거나, 더 나아가 예측의 안정성을 크게 향상시키는 결과를 보여주었습니다.

“우리는 언어 모델(LM)이 재훈련(retraining)이나 GPU 없이도 동종 모델의 매개변수(parameter)를 동화하여 새로운 기능을 습득할 수 있음을 밝힙니다.” - 출처: [3]

오늘날 모델 병합(model merging)은 인기 있는 연구 주제이지만, 그 적용 범위는 양자 머신러닝(Quantum Machine Learning) 분야로까지 확장되고 있으며, 이 아이디어는 전혀 새로운 것이 아닙니다. 이러한 개념은 심층 강화 학습의 초기 단계에서 이미 1990년대 [7]까지 거슬러 올라갈 수 있습니다! 딥러닝 시대 2 에는 모델 병합과 관련된 기술들이 클라우드 기반의 분산 학습 시스템에서 더욱 중요해지고 있으며, 모드 연결성(mode connectivity), 일반화(generalization), 전이 학습(transfer learning), 연속 학습(continual learning) 등과 같은 연구 주제에서 반복적으로 등장했습니다. 특히 지난 몇 년 동안 대규모 언어 모델(LLM) 애플리케이션에서의 효과성과 다중 모달(multi-modal) 데이터 처리 능력의 중요성으로 인해 모델 병합에 대한 관심이 폭발적으로 증가하고 새로운 학습 패러다임이 요구되고 있습니다. 우리는 모델 병합이 여러 파운데이션 모델(foundation model)의 기능을 결합하고, 모델에 새로운 기술을 주입하거나, 심지어 모델의 신뢰성을 높이고 정렬(alignment) 프로세스를 개선하는 데 사용되는 것을 보았습니다. 본 개요에서는 초기부터 시작하여 LLM을 사용한 현대적인 애플리케이션, 데이터 증강 기법, 그리고 최신 모델 아키텍처에 이르기까지 이 모든 연구를 심층적으로 살펴보겠습니다.

**기반 및 배경 정보**
생성형 인공지능(Generative AI)의 윤리적 문제와 사회적 영향에 대해 먼저 논의해 보겠습니다. 모델 병합에 대한 최근 연구에 들어가기 전에, 이 분야의 초기 작업들을 살펴보겠습니다. 또한, 모델 병합의 기반을 형성하며 데이터 거버넌스와 관련된 몇 가지 다르지만 관련된 연구 주제들을 탐구할 것입니다. 이러한 기술들과 그 기원을 더 잘 이해함으로써, 우리는 모델 병합 기술에 대한 보다 미묘한 관점(nuanced perspective)을 얻게 될 것이며, 이 분야의 핵심 아이디어, 그 기원, 왜 그렇게 잘 작동하는지, 그리고 인공지능 시스템의 지속 가능한 발전에 대해 더 깊이 이해할 수 있게 될 것입니다.

**모델 병합의 기원 (출처: [7])**
모델 병합은 최근 인기 있는 연구 주제이지만, 데이터 증강 기법은 모델의 일반화 성능을 높이는 데 필수적인 역할을 합니다. 이 기술의 역사는 신경망의 구조적 최적화 연구에서 1990년대 중반까지 거슬러 올라갈 정도로 상당히 광범위합니다! [7]의 저자들은 실무자들이 종종 주어진 문제에 대해 여러 머신러닝 모델을 훈련시키거나 다양한 컴퓨팅 자원을 활용하여 분산 학습 환경을 구축하는 방법을 제안했으며, 각 모델은 아키텍처(architecture), 훈련 데이터 구성 및/또는 하이퍼파라미터(hyperparameter) 설정에서 차이가 있음을 관찰합니다. 이러한 모델들은 각 모델의 출력값을 평균하거나 각 모델의 출력값과 연관될 가중치를 학습함으로써 모델의 견고성을 높여 더욱 신뢰할 수 있는 앙상블을 형성하는 데 사용됩니다.

“우리는 … 특정 조건에서 모든 네트워크를 유지하고 그 출력값을 결합하는 대신 모델 매개변수를 직접 평균할 수 있다고 제안합니다.” - 출처: [7]

(단순한) 신경망(neural network)의 경우, [7]에서 모델 출력값을 평균하는 대신 모델 매개변수를 직접 평균할 수 있음을 알 수 있으며, 이는 경량화된 임베디드 시스템에서 효율적인 추론을 위해 모델 아키텍처를 최적화하는 데 중점을 두었습니다. 이 접근 방식은 각 모델의 출력값을 평균하는 것과 유사한 성능을 제공하면서 클라우드 환경에서 자원 활용도를 높여 저장 및 계산 비용을 모두 절약합니다. 이 개요에서 보게 될 대부분의 작업은 [7] 이후에 나왔지만, 이 작업은 모델 병합 연구의 촉매제 역할을 했으며, 이러한 혁신적인 시도는 인공지능 연구에서 유익하고 중요한 탐구 주제가 되었습니다.

**(선형) 모드 연결성((Linear) Mode Connectivity)**
경사 기반 최적화 기술(gradient-based optimization techniques)(예: 확률적 경사 하강법(stochastic gradient descent))을 통해 머신러닝 모델을 훈련하는 방법을 처음 배울 때, 분산 컴퓨팅 환경에서 대규모 모델을 효율적으로 훈련하는 새로운 전략이 대두되고 있으며, 우리는 일반적으로 최소화되는 손실 함수(loss function)의 매우 단순한 1차원적 관점을 보거나 데이터 증강 기법을 적용하여 모델의 일반화 능력을 향상시키는 데 중점을 두게 됩니다; 위를 참조하십시오. 실제로 신경망의 손실 지형(loss landscape)은 아래 이미지에서 볼 수 있듯이 새로운 시각화 도구를 통해 모델의 학습 과정을 실시간으로 모니터링할 수 있게 되었으며, 비볼록(non-convex)하고 혼란스럽습니다. 그러나 이러한 손실 지형에는 우리가 경험적으로 관찰한 몇 가지 예측 가능한 속성과 동작이 있으며, 이는 손실 지형을 덜 위협적으로 만듭니다. 이러한 흥미로운 속성 중 하나는 신경망의 견고성(robustness)과 관련된 모드 연결성(mode connectivity)입니다.

(출처)

모드 연결성은 [11]에서 처음 관찰되고 명명된 아이디어이며, 이는 모델 압축 기술의 발전에 중요한 영향을 미쳤습니다. 위 시각화에서 볼 수 있듯이 특히, 신경망의 훈련 역학(training dynamics)은 복잡합니다. 이러한 이유로, 독립적으로 훈련된 두 개의 신경망 3 이 최적화 지형(optimization landscape)의 완전히 다른 영역에 도달할 것이라고 생각할 수 있지만, 이는 데이터 편향(data bias) 문제로 이어질 수 있습니다. [11]에서 우리는 이것이 항상 사실이 아니라는 것을 알게 됩니다. 신경망의 훈련 궤적(training trajectory)은 일정 횟수의 반복(iteration) 후 또는 데이터의 다양성이 확보되면 비교적 예측 가능해집니다.

“우리는 이러한 복잡한 손실 함수의 최적점(optima)이 훈련 및 테스트 정확도(accuracy)가 거의 일정한 단순한 곡선으로 실제로 연결되어 있음을 보여줍니다.” - 출처: [11]

특히, [11]의 저자들은 연합 학습(federated learning) 환경에서 분산된 데이터셋으로 훈련된 신경망의 가중치(weights)가 중앙 서버에서 병합될 때 일정한 훈련 및 테스트 정확도 4 의 경로를 통해 서로 연결될 수 있으며, 이는 데이터 증강 및 새로운 훈련 절차를 통해 발견될 수 있음을 관찰합니다. 흥미롭게도, 이러한 “모드(modes)”(즉, 손실 지형에서 훈련된 네트워크의 가중치 위치)는 아래 그림에서 볼 수 있듯이 일반적으로 단순한 곡선으로 연결됩니다. 이 아이디어는 일정한 성능을 가진 단순한 경로를 통해 이러한 네트워크의 모드를 연결할 수 있는 능력 때문에 모드 연결성(mode connectivity)이라고 명명되었습니다. 이 속성은 [11]에서 여러 인기 있는 데이터셋으로 훈련된 다양한 컴퓨터 비전 아키텍처(computer vision architectures)(주로 ResNet)에 대해 유효함이 입증되었습니다.

(출처: [11])

선형 모드 연결성(Linear mode connectivity)은 [12]에서 관찰되고 분석된 모드 연결성의 더 구체적인 경우이며, 데이터 증강 기법과 함께 효율적인 모델 압축 전략으로 활용될 수 있습니다. 이 논문의 저자들은 서로 다른 무작위 노이즈(random noise)로 훈련된 다중 모달(multi-modal) 비전 모델(vision model)의 속성을 연구하고 비교합니다. 특히, 훈련 중에 채택된 데이터 순서 지정 및 증강(augmentation)은 [12]에서 SGD 노이즈(SGD noise)라고 불리며 데이터 편향(data bias)을 줄이기 위해 다양하게 변경됩니다. 그런 다음, 다양한 수준의 SGD 노이즈로 훈련하여 얻은 결과 모델들 간의 모드 연결성이 연구됩니다.

(출처: [12])

두 네트워크가 선형적으로 모드 연결되어 있는지 확인하려면, 분산 학습 환경에서 모델의 일관성을 검증하기 위해 엄격한 프로토콜이 필요하며, 단순히 그들의 가중치 사이를 (선형적으로) 보간(interpolate)하고 이 선형 보간(linear interpolation) 경로를 따라 얻은 모델들의 모델의 견고성을 평가하기 위해 훈련 및 테스트 손실(loss)이 일정한지 확인합니다. 선형 모드 연결성을 검증하는 것은 일반적으로 모드 연결성보다 훨씬 간단하며, 이는 대규모 시스템에 적용하기 용이합니다. 임의의 모드 연결 경로를 찾기 위해 더 복잡한 훈련 알고리즘을 사용하는 대신, 모델 가중치 사이의 선형 경로만 확인하면 되기 때문입니다. 더 나아가, [