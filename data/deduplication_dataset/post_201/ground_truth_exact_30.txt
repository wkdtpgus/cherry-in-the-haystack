1년 구독 시 75% 할인

최근 몇 년간 대규모 언어 모델(LLM)은 빠르게 발전했습니다. 새로운 세대의 모델이 개발됨에 따라, 연구자와 엔지니어는 최신 진행 상황을 계속 파악해야 합니다. 이 글은 2025년 10월 셋째 주에 발표된 가장 중요한 LLM 논문 중 일부를 요약합니다. 이 논문들은 모델 최적화 및 스케일링, 추론, 벤치마킹, 성능 향상 등 차세대 언어 모델을 형성하는 다양한 주제를 다룹니다. 이러한 분야의 새로운 LLM 연구를 계속 파악하는 것은 더욱 유능하고 견고하며 인간의 가치에 부합하는 모델을 향한 지속적인 발전을 이끄는 데 도움이 될 것입니다.

목차:
1. LLM 발전 및 기술 보고서
2. 멀티모달 LLM과 비전 언어 모델
3. LLM 추론 및 성능 향상 기법
4. 후속 학습 및 정렬

**내 모든 책을 한 번의 클릭으로 40% 할인된 가격에 만나보세요**
유세프 호스니(Youssef Hosni) · 6월 17일

제 책과 로드맵을 묶어 번들을 만들었으니, 한 번의 클릭으로 모든 것을 원가보다 40% 저렴하게 구매할 수 있습니다. 이 번들에는 다음을 포함한 8권의 전자책이 있습니다. 전체 이야기 읽기

---

### 1. LLM 발전 및 기술 보고서

#### 1.1. 표현 오토인코더(Representation Autoencoders)를 사용한 확산 트랜스포머(Diffusion Transformers)

뉴욕 대학교의 이 논문은 잠재 확산 모델(latent diffusion models)이 구축되는 방식에 있어 근본적이고 강력한 변화를 제시하며, 더 효율적이고 확장 가능하며 고품질 결과를 생성하는 새로운 기본 방식을 제안합니다. 이 연구는 스테이블 디퓨전(Stable Diffusion)과 같은 모델에 사용되는 오토인코더(autoencoders)에 대한 오랜 가정에 도전하며, 표현 오토인코더(Representation Autoencoders, RAE)를 우월한 대안으로 소개합니다.

**핵심 아이디어: 압축된 VAE에서 의미론적 RAE로**

핵심 주장은 대부분의 확산 트랜스포머(Diffusion Transformers, DiT)에서 사용되는 오토인코더(일반적으로 스테이블 디퓨전의 원래 VAE)가 시대에 뒤떨어지고 제한적인 병목 현상이라는 것입니다. SD-VAE는 계산 비용이 많이 들고, 공격적인 압축이라는 주요 목표로 인해 중요한 정보를 손실하는 저차원적이고 의미론적으로 취약한 잠재 공간(latent space)을 초래합니다.

이 논문은 VAE를 완전히 대체할 것을 제안합니다. 재구성을 위한 오토인코더를 훈련하는 대신, 그들은 강력한 사전 훈련된 표현 인코더(representation encoders)(예: DINO 또는 SigLIP)를 고정된 인코더(frozen encoder)로 활용하고, 이를 간단하고 경량화된 훈련된 디코더(trained decoder)와 결합합니다. 이를 통해 **표현 오토인코더(Representation Autoencoder, RAE)**가 생성됩니다. 핵심 통찰력은 RAE에 의해 생성된 잠재 공간이 작고 압축된 것이 아니라, 크고 고차원적이며 의미론적 정보가 풍부하여 확산 프로세스(diffusion process)에 훨씬 더 나은 기반을 제공한다는 것입니다.

이 그림은 무거운 컨볼루션(convolutional) 기반 SD-VAE와 경량의 ViT 기반 RAE 간의 명확한 시각적 및 계산적 비교를 제공하며, 효율성 향상을 강조합니다.

**주요 방법론: 고차원 공간에서 확산 제어하기**

RAE는 우월한 잠재 공간을 제공하지만, 그 높은 차원성은 저차원 VAE 잠재 공간을 위해 설계된 표준 DiT 아키텍처에 큰 도전 과제를 제기합니다. 저자들은 표준 DiT가 RAE 잠재 공간에서 즉시 훈련되지 않는다는 것을 발견했습니다. 이를 해결하기 위해 그들은 일련의 원칙적인 해결책을 제시합니다.

*   **DiT 너비 스케일링(Scaling DiT Width)**: 그들은 먼저 중요한 설계 원칙을 확립합니다. 즉, 공간을 효과적으로 모델링하려면 DiT의 은닉 차원(hidden dimension, 너비)이 RAE의 토큰 차원(token dimension)과 일치하거나 이를 초과해야 합니다.
*   **넓은 확산 헤드(The Wide Diffusion Head, DiTDH)**: 계산량의 2차 폭발 없이 이 너비 요구 사항을 충족하기 위해 그들은 **DiTDH**라는 새로운 DiT 변형을 소개합니다. 이 아키텍처는 표준 DiT에 경량의 얕지만 매우 넓은 "DDT 헤드"를 추가하여 고차원 토큰을 효율적으로 처리합니다.
*   **차원 의존적 노이즈 스케줄링(Dimension-Dependent Noise Scheduling)**: 그들은 표준 노이즈 스케줄이 고차원 공간에서 실패한다는 것을 발견하고, 유효 데이터 차원(토큰 × 채널)을 기반으로 조정되는 새로운 스케줄을 제안합니다.
*   **노이즈 증강 디코딩(Noise-Augmented Decoding)**: RAE 디코더가 확산 프로세스에서 발생하는 노이즈가 많은 출력에 더 견고하도록, 소량의 노이즈를 추가하여 훈련됩니다.

이 그림은 DiT의 너비가 잠재 토큰 차원(latent token dimension)보다 크거나 같을 때만 단일 샘플에 성공적으로 과적합(overfit)된다는 것을 보여줌으로써 "너비가 차원과 일치해야 한다"는 발견을 시각적으로 입증하므로 방법론의 핵심입니다.

**가장 중요한 발견**

RAE와 새로운 DiTDH 아키텍처의 조합은 놀라운 효율성으로 이미지 생성 분야에서 새로운 최첨단(state-of-the-art) 결과를 가져왔습니다.

*   **ImageNet에서의 새로운 최첨단**: 최종 모델은 ImageNet 256x256에서 가이던스(guidance) 없이 1.51, 가이던스 포함 시 1.13이라는 새로운 기록적인 FID 점수를 달성하여 이전의 모든 확산 모델을 능가합니다. 또한 512x512 해상도에서 1.13 FID를 달성합니다.
*   **대폭 빨라진 훈련 수렴**: 의미론적으로 풍부한 RAE 잠재 공간은 확산 모델이 훨씬 더 효율적으로 학습할 수 있도록 합니다. 이 프레임워크는 SiT-XL과 같은 이전 기준선에 비해 최대 47배 빠른 훈련 수렴을 달성하며, REPA-XL과 같은 표현 정렬(representation alignment) 방법보다 16배 빠른 속도를 제공합니다.
*   **우월한 재구성 및 표현**: RAE 자체는 표준 VAE보다 더 나은 오토인코더이며, 훨씬 적은 계산 비용으로 더 높은 충실도의 재구성(reconstruction)을 달성합니다(예: 14배 더 효율적). 또한 사전 훈련된 인코더의 강력한 의미론적 이해를 계승합니다.

그림 1은 다른 유명 모델들과 비교한 이 논문의 SOTA(State-Of-The-Art) 결과를 개략적으로 보여줍니다. 표 8은 새로운 최첨단 주장을 입증하는 최종적이고 상세한 FID 점수를 포함합니다.

이 차트는 훈련 효율성의 극적인 향상을 시각적으로 보여주며, 모델이 이전의 선도적인 방법보다 훨씬 빠르게 더 나은 FID 점수를 달성함을 나타냅니다.

**중요 자료**:
arXiv 페이지 보기
PDF 보기
프로젝트 페이지

---

#### 1.2. 초거대 언어 모델의 효율적 스케일링: Mixture-of-Experts (MoE) 아키텍처의 부상

최근 LLM의 규모가 기하급수적으로 커지면서, 모델의 효율적인 훈련과 추론은 핵심적인 과제가 되었습니다. 이 문제를 해결하기 위해 Mixture-of-Experts (MoE) 아키텍처가 다시 주목받고 있습니다. MoE는 모델의 파라미터 수를 크게 늘리면서도 계산 비용은 상대적으로 낮게 유지할 수 있는 혁신적인 방법입니다.

**핵심 아이디어: 희소 활성화(Sparsely Activated) 네트워크**

MoE의 기본 아이디어는 하나의 대규모 네트워크 대신, 여러 개의 작은 "전문가(expert)" 네트워크를 병렬로 배치하는 것입니다. 입력 토큰이 주어지면 "게이트(gate)" 또는 "라우터(router)" 네트워크가 해당 토큰을 처리할 가장 적합한 전문가 한두 명을 선택합니다. 이로 인해 전체 모델의 파라미터 수는 방대하지만, 특정 입력에 대해 활성화되는 파라미터는 매우 적어 계산 효율성을 높입니다. 예를 들어, Mixtral 8x7B 모델은 총 470억 개의 파라미터를 가지고 있지만, 추론 시에는 129억 개의 파라미터만 활성화되어 130억 파라미터 모델과 유사한 추론 비용으로 470억 파라미터 모델에 버금가는 성능을 냅니다. 이는 모델의 용량(capacity)을 크게 늘리면서도 계산 비용의 폭발적인 증가를 막는 효과적인 방법입니다.

**최근 발전과 적용 사례**

Mixtral 8x7B는 MoE 아키텍처의 성공적인 적용 사례 중 하나이며, 최근 Grok-1과 같은 모델들도 MoE를 활용하여 뛰어난 성능을 보였습니다. 이러한 모델들은 기존의 조밀한(dense) 모델들이 달성하기 어려웠던 규모의 효율성과 성능을 제공합니다. MoE는 대규모 데이터셋에 대한 훈련을 가속화하고, 더 복잡한 패턴을 학습할 수 있게 하며, 다양한 작업을 처리하는 데 있어 유연성을 제공합니다. 그러나 전문가 간의 부하 분산, 라우터 네트워크의 최적화, 그리고 희소성(sparsity)으로 인한 하드웨어 친화성 문제 등 여전히 해결해야 할 과제들이 존재합니다. 그럼에도 불구하고, MoE는 미래 LLM 스케일링의 핵심 방향 중 하나로 자리매김하고 있습니다.

---

#### 1.3. DITING: 웹 소설 번역 벤치마킹을 위한 다중 에이전트 평가 프레임워크

우한 대학교(Wuhan University) 등의 이 논문은 웹 소설이라는 독특하고 도전적인 장르에 대한 대규모 언어 모델(LLM) 번역의 품질을 적절하게 평가하도록 설계된 포괄적인 새 프레임워크인 **DITING**을 소개합니다. 새로운 벤치마크와 혁신적인 다중 에이전트 평가 시스템인 **AgentEval**을 구축함으로써, 이 연구는 결함 있는 표면 수준의 측정 기준을 넘어 문학 번역에 필요한 더 깊은 "서사적 및 문화적 충실도(narrative and cultural fidelity)"를 평가합니다.

---

### 2. 멀티모달 LLM과 비전 언어 모델

멀티모달 대규모 언어 모델(MLLM)은 텍스트뿐만 아니라 이미지, 오디오, 비디오 등 다양한 형태의 데이터를 이해하고 생성하는 능력을 갖추며 LLM의 역량을 확장하고 있습니다. 이러한 모델들은 단순한 정보 결합을 넘어, 모달리티 간의 복잡한 관계를 학습하여 더욱 풍부한 상호작용과 추론을 가능하게 합니다.

#### 2.1. 언어 중심 옴니모달 표현 학습(Language-Centric Omnimodal Representation Learning) 확장

알리바바(Alibaba)의 다모 아카데미(DAMO Academy)에서 발표한 이 논문은 멀티모달 대규모 언어 모델(MLLM)이 강력한 임베딩 모델(embedding models)을 생성하는 데 왜 그렇게 효과적인지에 대한 근본적인 통찰력을 제시합니다. 이 논문은 이러한 통찰력을 활용하여 **LCO-EMB(언어 중심 옴니모달 임베딩)**라는 새로운 최첨단 프레임워크를 만듭니다. 이 연구는 전통적인 접근 방식에 도전하고, 이러한 중요한 모델을 구축하는 방법에 대한 우리의 이해를 재구성하는 새로운 스케일링 법칙(scaling law)을 소개합니다.

**핵심 아이디어: 생성-표현 스케일링 법칙(Generation-Representation Scaling Law, GRSL)**

핵심 발견은 **생성-표현 스케일링 법칙(GRSL)**입니다. 즉, 멀티모달 임베딩 모델의 품질은 기본 MLLM 백본(backbone)의 생성 능력(generative capability)과 직접적이고 긍정적으로 비례합니다. 간단히 말해, 더 나은 생성 모델이 더 나은 임베딩 모델을 만듭니다.

이는 전체 문제를 재구성합니다. 대조 학습(contrastive learning, CL)을 (CLIP처럼) 처음부터 정렬(alignment)을 생성하는 주요 엔진으로 보는 대신, 이 연구는 MLLM의 경우 생성 사전 훈련(generative pre-training) 중에 이미 많은 작업이 수행된다고 주장합니다. CL의 주요 역할은 이러한 잠재 구조를 "정제"하거나 "활성화"하는 것입니다.

**주요 방법론: 언어 중심 정제**

연구자들은 먼저 핵심 가설에 대한 강력한 실증적 증거를 제시합니다. 즉, MLLM은 생성 사전 훈련을 통해 암묵적인 교차 모달 정렬(cross-modal alignment)을 가지고 있다는 것입니다. 그들은 강력한 기성 MLLM(Qwen2.5-Omni)을 가져와 **텍스트 전용 데이터(text-only data)**를 사용하여 대조 학습으로 미세 조정했습니다. 그들은 이 텍스트 전용 튜닝이 텍스트 임베딩(text embeddings)의 품질을 향상시켰을 뿐만 아니라 다른 모달리티(modalities)로 일반화되어 이미지, 오디오 및 비디오 임베딩의 구조와 품질을 크게 향상시키는 것을 관찰했습니다.

이를 바탕으로 그들은 CL을 경량의 사후 정제 단계로 취급하는 LCO-EMB 프레임워크를 제안합니다. 언어 중심 데이터에 매개변수 효율적인 LoRA를 사용하여, 이 프레임워크는 MLLM의 사전 정렬된 생성 임베딩(pre-aligned generative embeddings)을 모델의 강력한 사전 훈련된 지식에 대한 최소한의 방해로 고성능 유사성 매칭 공간(similarity-matching space)으로 매핑합니다.

GRSL을 검증하기 위해 그들은 새롭고 도전적인 시각 문서 검색 벤치마크인 **SeaDoc**을 만들었으며, CL을 적용하기 전에 모델의 생성 능력을 향상시키기 위해 지속적으로 사전 훈련하는 것이 훨씬 더 나은 최종 임베딩 성능을 가져온다는 것을 보여주었습니다.

그림 1은 텍스트 전용 훈련이 모든 모달리티에서 이방성(anisotropy)을 어떻게 감소시키는지(임베딩 품질을 향상시키는지) 보여주는 핵심 증거를 제공합니다. 그림 3은 "붕괴된(collapsed)" 임베딩 공간에서 "등방성(isotropic)" 임베딩 공간으로의 이러한 변화를 보여주는 훌륭한 개념도입니다.

**가장 중요한 발견**

LCO-EMB 프레임워크와 GRSL의 발견은 멀티모달 표현 학습(multimodal representation learning)의 미래에 중요한 의미를 가집니다.

*   **임베딩을 위한 새로운 스케일링 법칙**: GRSL은 더 나은 임베딩 모델을 구축하기 위한 새로운 방법을 제공합니다. 즉, 가능한 최고의 생성 MLLM으로 시작하는 것입니다. 생성기가 좋을수록 최종 표현 품질의 상한선이 높아집니다. 이것은 생성 성능(x축)과 표현 성능(y축) 사이에 명확한 양의 상관관계를 보여주는 산점도(scatter plots)를 통해 GRSL에 대한 직접적인 시각적 증거를 제공하는 논문의 핵심 그림입니다.
*   **언어 중심 훈련의 놀라운 효과**: 주로 텍스트 전용 데이터와 소량의 추가 멀티모달 데이터로 훈련된 LCO-EMB 모델은 포괄적인 MIEB-Lite 벤치마크에서 새로운 최첨단 성능을 달성하며, 훨씬 더 큰 멀티모달 데이터셋으로 훈련된 강력한 독점 모델들을 능가합니다.
*   **MLLM 기반 접근 방식의 우월성**: 이 논문은 MLLM 기반 임베딩 모델이 기존 CLIP 스타일 모델보다 근본적으로 우월한 이유에 대한 명확한 이론적 및 실증적 설명을 제공합니다. 생성 사전 훈련은 전통적인 대조 방법에는 없는 잠재적인 교차 모달 정렬의 귀중한 "웜 스타트(warm start)"를 제공합니다.
*   **도전적인 새로운 작업에서의 검증**: SeaDoc 벤치마크의 생성과 그에 대한 성공적인 실험은 GRSL을 더욱 검증하며, 특정 작업에서 모델의 생성 능력을 향상시키는 것이 해당 작업에서 더 나은 검색 및 표현 성능으로 직접 이어진다는 것을 증명합니다.

이 그림은 MIEB-Lite 벤치마크에서 LCO-EMB의 성능을 다른 선도적인 오픈 소스 및 독점 모델과 비교한 주요 SOTA 결과를 보여줍니다.

**중요 자료**:
arXiv 페이지 보기
PDF 보기
프로젝트 페이지

---

#### 2.2. 멀티모달 추론 및 상호작용의 발전

최근 GPT-4o와 같은 모델의 등장은 멀티모달 LLM이 단순한 임베딩을 넘어 복합적인 추론과 실시간 상호작용이 가능한 수준으로 발전했음을 보여줍니다. 이러한 모델들은 시각, 청각, 텍스트 정보를 동시에 처리하고 통합하여 인간과 유사한 방식으로 세상을 이해하고 반응합니다.

**새로운 기능과 활용 분야**

멀티모달 LLM은 이미지 내의 복잡한 관계를 분석하고, 차트나 그래프에서 데이터를 추출하며, 심지어 비디오 콘텐츠의 맥락을 파악하여 질문에 답하거나 설명을 생성할 수 있습니다. 예를 들어, 사용자가 복잡한 공학 도면을 보여주면서 특정 부품의 기능에 대해 질문하면, 모델은 도면을 시각적으로 이해하고 관련 텍스트 정보를 종합하여 상세한 답변을 제공할 수 있습니다. 또한, 실시간 음성 대화를 통해 시각 정보를 공유하고 즉각적인 피드백을 주고받는 것이 가능해지면서, 교육, 의료, 고객 서비스 등 다양한 분야에서 혁신적인 애플리케이션 개발이 가속화되고 있습니다. 이러한 발전은 LLM이 단순히 정보를 처리하는 도구를 넘어, 인간의 인지 과정을 모방하고 증강하는 강력한 파트너로 진화하고 있음을 시사합니다.

---

### 3. LLM 추론 및 성능 향상 기법

대규모 언어 모델의 강력한 성능을 실제 애플리케이션에서 최대한 활용하기 위해서는 추론(inference) 과정의 효율성과 정확성을 극대화하는 것이 중요합니다. 최근 연구들은 모델의 추론 능력을 향상시키기 위한 다양한 전략과 최적화 기법을 제시하고 있습니다.

#### 3.1. 복합 추론 전략: CoT에서 ToT까지

LLM의 추론 능력을 향상시키는 핵심 방법 중 하나는 모델이 복잡한 문제를 단계적으로 해결하도록 유도하는 것입니다. **사고의 사슬(Chain-of-Thought, CoT)** 프롬프팅은 모델이 최종 답변을 도출하기까지의 중간 단계를 명시적으로 생성하도록 하여, 복잡한 산술 문제나 논리적 추론 문제에서 성능을 크게 향상시켰습니다. 여기서 한발 더 나아가, **사고의 나무(Tree-of-Thought, ToT)**는 CoT를 확장하여 모델이 여러 추론 경로를 탐색하고, 각 단계에서 잠재적인 오류를 평가하며, 가장 유망한 경로를 선택하도록 합니다. 이는 문제 해결 과정에 대한 메타 인지적 접근 방식을 도입하여, 모델이 더욱 견고하고 정확한 추론을 수행할 수 있게 합니다. 또한, **자기 수정(self-correction)** 및 **성찰(reflection)** 기법은 모델이 자신의 생성물을 비판적으로 평가하고, 외부 도구의 피드백이나 내부 지식을 활용하여 오류를 식별하고 수정하도록 훈련함으로써 추론의 신뢰성을 높입니다. 이러한 복합 추론 전략들은 LLM이 단순한 패턴 매칭을 넘어, 인간과 유사한 방식으로 복잡한 문제를 해결하는 데 필수적인 요소로 자리 잡고 있습니다.

#### 3.2. 효율적인 추론을 위한 최적화 기술

LLM의 실용적인 배포를 위해서는 추론 속도와 자원 효율성이 필수적입니다. **양자화(quantization)**는 모델의 가중치를 낮은 비트(예: 16비트에서 8비트 또는 4비트)로 압축하여 메모리 사용량과 계산 비용을 줄이는 기술입니다. 이는 모델의 크기를 크게 줄이면서도 성능 저하를 최소화하여 엣지 디바이스나 리소스가 제한된 환경에서도 LLM을 실행할 수 있게 합니다. **추측 디코딩(speculative decoding)**은 작은 모델이 다음 토큰 시퀀스를 예측하고, 큰 모델이 이를 한 번에 검증하여 디코딩 속도를 비약적으로 향상시키는 방법입니다. 또한, **KV 캐싱(Key-Value Caching) 최적화**는 어텐션 메커니즘에서 이전에 계산된 키(Key)와 값(Value) 벡터를 저장하여 반복적인 계산을 피함으로써 추론 속도를 높입니다. **분산 추론(distributed inference)** 기술은 대규모 모델을 여러 GPU나 서버에 분산하여 처리함으로써 단일 장치의 한계를 극복하고 대규모 트래픽을 효율적으로 처리할 수 있도록 합니다. 이러한 최적화 기술들은 LLM이 더 넓은 범위의 애플리케이션에서 실시간으로 작동할 수 있도록 하는 핵심적인 역할을 합니다.

---

### 4. 후속 학습 및 정렬

대규모 언어 모델이 사회에 미치는 영향이 커짐에 따라, 모델이 인간의 가치와 의도에 부합하도록 만드는 **정렬(alignment)** 연구의 중요성이 강조되고 있습니다. 후속 학습(fine-tuning)은 모델의 성능을 특정 작업에 최적화하는 것을 넘어, 안전하고 유익하며 신뢰할 수 있는 AI를 구축하는 데 필수적인 단계가 되고 있습니다.

#### 4.1. 인간 피드백 기반 강화 학습(RLHF)의 진화

**인간 피드백 기반 강화 학습(Reinforcement Learning from Human Feedback, RLHF)**은 LLM을 인간의 선호도에 맞춰 정렬하는 데 가장 성공적인 방법 중 하나입니다. RLHF는 모델의 응답에 대한 인간의 선호도 피드백을 수집하고, 이를 보상 모델(reward model) 훈련에 사용하여 LLM이 인간이 선호하는 응답을 생성하도록 강화 학습을 통해 미세 조정합니다. **PPO(Proximal Policy Optimization)**는 RLHF에서 널리 사용되는 알고리즘이지만, 복잡한 구현과 튜닝의 어려움이 있습니다. 최근에는 **DPO(Direct Preference Optimization)**와 같은 새로운 방법들이 등장하여 보상 모델 없이 직접적으로 인간 선호도를 모델에 반영함으로써 RLHF의 복잡성을 크게 줄였습니다. 또한, **RLAIF(Reinforcement Learning from AI Feedback)**는 인간의 피드백 대신 다른 LLM이 생성한 피드백을 활용하여 정렬 과정을 자동화하고 확장하는 가능성을 보여주고 있습니다. 이러한 기술들은 LLM이 더욱 유용하고 안전하며, 인간과 효과적으로 상호작용할 수 있도록 진화하는 데 기여하고 있습니다.

#### 4.2. 윤리적 AI 및 안전성 확보를 위한 노력

LLM의 정렬은 단순히 성능 향상을 넘어, 모델이 생성할 수 있는 유해하거나 편향된 콘텐츠를 줄이고 사회적 책임을 다하는 AI를 구축하는 데 필수적입니다. 연구자들은 모델이 잘못된 정보를 퍼뜨리거나, 혐오 발언을 생성하거나, 특정 집단에 대한 편견을 강화하는 것을 방지하기 위한 다양한 기술을 개발하고 있습니다. 여기에는 데이터셋의 편향을 줄이는 방법, 안전 지침을 따르도록 모델을 미세 조정하는 방법, 그리고 모델의 의사 결정 과정을 투명하게 만드는 설명 가능한 AI(Explainable AI, XAI) 기법 등이 포함됩니다. 또한, 모델의 견고성(robustness)을 높여 적대적 공격이나 예상치 못한 입력에도 안정적으로 작동하도록 하는 연구도 활발히 진행 중입니다. 이러한 윤리적 AI 및 안전성 확보 노력은 LLM이 사회에 긍정적인 영향을 미치고, 사용자들이 안심하고 AI 기술을 활용할 수 있는 기반을 마련하는 데 중요합니다.