1년 구독 시 75% 할인

최근 몇 년 동안 거대 언어 모델(LLM) 분야는 눈부신 진보를 거듭해 왔습니다. 새로운 세대의 모델이 속속 등장함에 따라, 연구자와 개발자들은 이 분야의 최신 동향을 끊임없이 주시해야 할 필요가 있습니다. 본 글에서는 2025년 10월 셋째 주에 공개된, 가장 주목할 만한 LLM 관련 논문들을 요약하여 소개합니다. 이 연구들은 모델의 최적화 기법, 규모 확장 전략, 추론 방식, 성능 평가 기준, 그리고 전반적인 효율성 향상 등 차세대 언어 모델의 미래를 좌우할 핵심 주제들을 다룹니다. 이처럼 빠르게 변화하는 LLM 연구의 흐름을 이해하는 것은 더욱 강력하고 안정적이며, 궁극적으로 인간의 가치와 부합하는 모델을 개발하는 데 필수적인 지침이 될 것입니다.

LLM 연구는 이제 단순한 언어 처리의 영역을 넘어, 다학제적 접근 방식이 요구되는 복합적인 문제 해결의 장으로 진화하고 있습니다. 모델의 아키텍처 설계부터 학습 데이터의 구축, 윤리적 고려사항에 이르기까지, 각 단계마다 새로운 도전과 혁신적인 해결책이 제시되고 있습니다.

목차:
LLM 발전 및 기술 보고서
비전 언어 모델의 새로운 지평
LLM 추론 효율성 극대화
강화 학습 기반의 후속 미세 조정

1년 구독 시 75% 할인

**내 모든 책을 한 번의 클릭으로 40% 할인된 가격에 만나보세요**
유세프 호스니(Youssef Hosni) · 6월 17일

제 책과 로드맵을 묶어 번들을 만들었으니, 한 번의 클릭으로 모든 것을 원가보다 40% 저렴하게 구매할 수 있습니다. 이 번들에는 다음을 포함한 8권의 전자책이 있습니다. 전체 이야기 읽기

---

### 1. LLM 발전 및 기술 보고서

#### 1.1. 표현 오토인코더(Representation Autoencoders) 기반의 확산 트랜스포머(Diffusion Transformers)

1년 구독 시 75% 할인

뉴욕 대학교 연구팀의 이 논문은 잠재 확산 모델(latent diffusion models)의 근간을 이루는 방식에 근본적이면서도 강력한 변화를 제안합니다. 이는 기존 방법론의 한계를 뛰어넘어, 더욱 능률적이고 확장 가능하며 최상급의 결과물을 생성할 수 있는 새로운 패러다임을 제시합니다. 이 연구는 스테이블 디퓨전(Stable Diffusion) 같은 모델에서 오랫동안 사용되어 온 오토인코더(autoencoders)에 대한 통념에 이의를 제기하며, **표현 오토인코더(Representation Autoencoders, RAE)**를 더욱 우월한 대안으로 제시합니다.

생성 모델의 역사는 픽셀 단위의 직접적인 이미지 생성을 넘어, 잠재 공간(latent space)을 활용하여 복잡성을 줄이는 방향으로 발전해 왔습니다. 특히 확산 모델은 이 잠재 공간에서 노이즈를 제거하며 이미지를 생성하는데, 이 잠재 공간의 특성이 모델의 성능과 효율성에 결정적인 영향을 미칩니다.

**핵심 아이디어: 압축 위주 VAE를 넘어선 의미론적 RAE**

이 연구의 핵심 주장은 대부분의 확산 트랜스포머(Diffusion Transformers, DiT)에서 활용되는 오토인코더(일반적으로 스테이블 디퓨전의 초기 VAE)가 더 이상 현대 기술에 부합하지 않으며, 성능을 제약하는 병목 현상으로 작용한다는 것입니다. 기존 SD-VAE는 막대한 연산 비용을 요구하며, 과도한 압축을 목표로 함으로써 중요한 정보를 상실하고, 저차원적이며 의미론적으로 취약한 잠재 공간을 만들어냅니다. 이러한 잠재 공간은 확산 과정에서 미세한 디테일이나 복잡한 개념을 정확하게 표현하는 데 한계를 보였습니다.

본 논문은 VAE를 완전히 새로운 방식으로 대체할 것을 제안합니다. 이미지 재구성을 위한 오토인코더를 처음부터 훈련하는 대신, 강력하게 사전 훈련된 표현 인코더(representation encoders)(예: DINO 또는 SigLIP)를 고정된 인코더(frozen encoder)로 활용하고, 이를 간단하고 가벼운 훈련된 디코더(trained decoder)와 결합합니다. 이를 통해 **표현 오토인코더(Representation Autoencoder, RAE)**가 탄생합니다. RAE의 핵심 통찰력은 그 잠재 공간이 작고 압축적인 것이 아니라, 크고 고차원적이며 의미론적으로 풍부하다는 점입니다. 이는 확산 과정에 훨씬 더 견고하고 표현력 있는 기반을 제공하여, 생성되는 이미지의 품질과 다양성을 비약적으로 향상시킵니다.

이 그림은 무거운 컨볼루션(convolutional) 기반의 SD-VAE와 경량의 ViT 기반 RAE 사이의 명확한 시각적 및 계산적 비교를 보여주며, 효율성 측면에서의 혁신적 진보를 강조합니다.

내 모든 책을 40% 할인된 가격에 만나보세요

**주요 방법론: 고차원 잠재 공간에서의 확산 제어**

1년 구독 시 75% 할인

RAE는 월등히 우수한 잠재 공간을 제공하지만, 그 높은 차원성은 기존의 저차원 VAE 잠재 공간에 맞춰 설계된 표준 DiT 아키텍처에 상당한 난제를 안겨줍니다. 연구진은 표준 DiT가 RAE의 고차원 잠재 공간에서 곧바로 훈련될 수 없다는 점을 발견했습니다. 이러한 문제를 해결하기 위해 그들은 다음과 같은 일련의 원칙적인 해결책들을 제시합니다.

*   **DiT 은닉층 크기 조절(Scaling DiT Width)**: 연구팀은 중요한 설계 원칙을 확립했습니다. 즉, 고차원 공간을 효과적으로 모델링하기 위해서는 DiT의 은닉 차원(hidden dimension, 너비)이 RAE의 토큰 차원(token dimension)과 동일하거나 이를 능가해야 한다는 것입니다. 이는 모델이 잠재 공간의 모든 정보를 충분히 처리할 수 있도록 보장합니다.
*   **폭넓은 확산 헤드(The Wide Diffusion Head, DiTDH)**: 계산량의 기하급수적인 증가 없이 이러한 '너비' 요구사항을 충족시키기 위해, 그들은 **DiTDH**라는 새로운 DiT 변형을 도입했습니다. 이 아키텍처는 표준 DiT에 가벼우면서도 얕지만 매우 넓은 "DDT 헤드"를 추가하여, 고차원 토큰들을 효율적으로 처리합니다.
*   **차원 의존적 노이즈 스케줄링(Dimension-Dependent Noise Scheduling)**: 기존의 노이즈 스케줄이 고차원 공간에서 적절히 작동하지 않는다는 점을 발견하고, 유효 데이터 차원(토큰 × 채널)을 기반으로 정교하게 조정되는 새로운 스케줄링 방식을 제안합니다. 이는 노이즈 제거 과정의 정확도를 높입니다.
*   **노이즈 증강 디코딩(Noise-Augmented Decoding)**: RAE 디코더가 확산 과정에서 발생하는 노이즈가 많은 출력에 대해 더욱 견고하게 작동하도록, 훈련 시 소량의 노이즈를 의도적으로 추가합니다. 이를 통해 디코더의 강건성을 향상시킵니다.

이 그림은 DiT의 너비가 잠재 토큰 차원(latent token dimension)보다 크거나 같을 때만 단일 샘플에 성공적으로 과적합(overfit)된다는 사실을 시각적으로 입증하며, "너비가 차원과 일치해야 한다"는 발견이 방법론의 핵심임을 보여줍니다. 이러한 아키텍처적 개선은 향후 비디오 생성이나 3D 에셋 생성과 같은 더욱 복잡한 생성 모델 설계에도 중요한 시사점을 제공합니다.

내 모든 책을 40% 할인된 가격에 만나보세요

**가장 중요한 발견**

RAE와 혁신적인 DiTDH 아키텍처의 결합은 이미지 생성 분야에서 전례 없는 효율성으로 최고 성능(state-of-the-art)을 달성했습니다.

*   **ImageNet에서의 최고 성능 경신**: 최종 모델은 ImageNet 256x256 해상도에서 가이던스(guidance) 없이 1.51, 가이던스를 포함할 경우 1.13이라는 경이로운 FID 점수를 기록하며, 기존의 모든 확산 모델을 능가했습니다. 또한 512x512 해상도에서도 1.13 FID를 달성하는 성과를 보였습니다.
*   **학습 효율성 극대화**: 의미론적으로 풍부한 RAE 잠재 공간 덕분에 확산 모델은 훨씬 더 빠르게 학습할 수 있습니다. 이 프레임워크는 SiT-XL과 같은 이전 기준 모델 대비 최대 47배 빠른 훈련 수렴 속도를 달성했으며, REPA-XL과 같은 표현 정렬(representation alignment) 방식보다도 16배 빠른 속도를 제공합니다.
*   **우월한 재구성 및 표현 능력**: RAE 자체는 표준 VAE보다 뛰어난 오토인코더로서, 훨씬 적은 연산 비용으로 더 높은 충실도의 재구성(reconstruction)을 이뤄냅니다(예: 14배 더 효율적). 게다가 사전 훈련된 인코더의 강력한 의미론적 이해를 그대로 계승하여, 생성된 이미지의 품질과 개념적 일관성을 보장합니다.

그림 1은 다른 저명한 모델들과 비교한 이 논문의 최첨단(SOTA) 결과를 개략적으로 보여줍니다. 표 8은 새로운 최고 성능 주장을 입증하는 최종적이고 상세한 FID 점수를 포함합니다. 이러한 RAE+DiTDH 조합은 단순한 벤치마크 성능 향상을 넘어, 맞춤형 콘텐츠 제작, 개인화된 미디어 생성 등 다양한 실용적 응용 분야에 혁신적인 영향을 미 미칠 잠재력을 가지고 있습니다.

이 차트는 훈련 효율성의 극적인 향상을 시각적으로 보여주며, 모델이 이전의 선도적인 방법보다 훨씬 빠르게 더 나은 FID 점수를 달성함을 나타냅니다.

**중요 자료**:
arXiv 페이지 보기
PDF 보기
프로젝트 페이지

---

#### 1.2. 언어 중심 옴니모달 표현 학습(Language-Centric Omnimodal Representation Learning) 확장

알리바바(Alibaba)의 다모 아카데미(DAMO Academy)에서 발표한 이 논문은 멀티모달 대규모 언어 모델(MLLM)이 왜 그토록 강력한 임베딩 모델(embedding models)을 구축하는 데 효과적인지에 대한 본질적인 통찰력을 제공합니다. 이 연구는 이러한 통찰을 바탕으로 **LCO-EMB(언어 중심 옴니모달 임베딩)**라는 새로운 최고 성능 프레임워크를 개발했습니다. 이 연구는 기존의 접근 방식에 도전장을 내밀고, 이러한 중요한 모델을 구성하는 방법에 대한 우리의 이해를 재정의하는 새로운 스케일링 법칙(scaling law)을 선보입니다.

멀티모달 표현 학습은 이미지, 텍스트, 오디오 등 다양한 형태의 데이터를 하나의 일관된 의미 공간으로 매핑하는 것을 목표로 합니다. 이는 각 모달리티 간의 복잡한 관계를 이해하고 정렬하는 데 있어 큰 어려움을 수반합니다.

**핵심 아이디어: 생성-표현 스케일링 법칙(Generation-Representation Scaling Law, GRSL)**

내 모든 책을 40% 할인된 가격에 만나보세요

이 연구의 핵심적인 발견은 바로 **생성-표현 스케일링 법칙(GRSL)**입니다. 이는 멀티모달 임베딩 모델의 품질이 기반이 되는 MLLM 백본(backbone)의 생성 능력(generative capability)과 직접적이고 긍정적인 상관관계를 가진다는 것을 의미합니다. 간단히 말해, 더욱 뛰어난 생성 모델일수록 더 우수한 임베딩 모델을 만들어낸다는 것입니다. 이는 MLLM이 데이터를 얼마나 깊이 이해하고 있는지를 나타내는 지표로 해석될 수 있습니다.

이 법칙은 전체 문제에 대한 관점을 새롭게 정립합니다. 전통적인 대조 학습(contrastive learning, CL)을 (CLIP처럼) 처음부터 모달리티 간 정렬(alignment)을 생성하는 주요 동력으로 간주하는 대신, 이 연구는 MLLM의 경우 생성 사전 훈련(generative pre-training) 과정에서 이미 많은 정렬 작업이 이루어진다고 주장합니다. CL의 주된 역할은 이러한 잠재된 구조를 "정제"하거나 "활성화"하여 더욱 명확하고 활용 가능한 형태로 만드는 것입니다.

**주요 방법론: 언어 중심의 정제 과정**

연구자들은 먼저 핵심 가설에 대한 강력한 실증적 증거를 제시합니다. 즉, MLLM은 생성 사전 훈련을 통해 암묵적인 교차 모달 정렬(cross-modal alignment) 능력을 이미 내재하고 있다는 것입니다. 그들은 강력한 기성 MLLM(Qwen2.5-Omni)을 활용하여 **텍스트 전용 데이터(text-only data)**를 사용한 대조 학습으로 미세 조정을 수행했습니다. 놀랍게도, 이 텍스트 전용 튜닝이 텍스트 임베딩(text embeddings)의 품질을 향상시켰을 뿐만 아니라, 다른 모달리티(modalities)로까지 일반화되어 이미지, 오디오 및 비디오 임베딩의 구조와 품질을 현저히 개선하는 것을 관찰했습니다.

이를 바탕으로 그들은 CL을 경량의 사후 정제 단계로 취급하는 LCO-EMB 프레임워크를 제안합니다. 언어 중심 데이터에 매개변수 효율적인 LoRA(Low-Rank Adaptation) 기법을 사용하여, 이 프레임워크는 MLLM의 사전 정렬된 생성 임베딩(pre-aligned generative embeddings)을 모델의 강력한 사전 훈련된 지식에 최소한의 간섭으로 고성능 유사성 매칭 공간(similarity-matching space)으로 매핑합니다. 이러한 '언어 중심 정제'는 데이터 효율성을 극대화하며, 방대한 텍스트 코퍼스를 활용하여 다양한 모달리티의 임베딩을 개선할 수 있는 실용적인 이점을 제공합니다.

GRSL을 검증하기 위해 그들은 새롭고 도전적인 시각 문서 검색 벤치마크인 **SeaDoc**을 구축했으며, CL을 적용하기 전에 모델의 생성 능력을 지속적으로 향상시키는 사전 훈련이 훨씬 더 우수한 최종 임베딩 성능으로 이어진다는 것을 입증했습니다.

그림 1은 텍스트 전용 훈련이 모든 모달리티에서 임베딩의 이방성(anisotropy)을 어떻게 감소시키는지(이는 임베딩 품질 향상을 의미함) 보여주는 핵심적인 증거를 제공합니다. 그림 3은 "붕괴된(collapsed)" 임베딩 공간에서 "등방성(isotropic)" 임베딩 공간으로의 이러한 변화를 시각적으로 보여주는 훌륭한 개념도입니다.

**가장 중요한 발견**

LCO-EMB 프레임워크와 GRSL의 발견은 멀티모달 표현 학습(multimodal representation learning)의 미래에 지대한 영향을 미칩니다.

1년 구독 시 75% 할인

*   **임베딩을 위한 새로운 스케일링 법칙**: GRSL은 더 나은 임베딩 모델을 구축하기 위한 새로운 길을 제시합니다. 즉, 가능한 최고의 생성 MLLM에서 출발하는 것입니다. 생성 능력이 뛰어날수록 최종 표현 품질의 상한선이 높아집니다. 이는 생성 성능(x축)과 표현 성능(y축) 사이에 명확한 양의 상관관계를 보여주는 산점도(scatter plots)를 통해 GRSL에 대한 직접적인 시각적 증거를 제공하는 논문의 핵심 그림입니다.
*   **언어 중심 훈련의 놀라운 효과**: 주로 텍스트 전용 데이터와 소량의 추가 멀티모달 데이터로 훈련된 LCO-EMB 모델은 포괄적인 MIEB-Lite 벤치마크에서 새로운 최고 성능을 달성하며, 훨씬 더 큰 멀티모달 데이터셋으로 훈련된 강력한 독점 모델들을 능가합니다. 이는 데이터 효율적인 학습 전략의 중요성을 부각합니다.
*   **MLLM 기반 접근 방식의 우월성**: 이 논문은 MLLM 기반 임베딩 모델이 기존 CLIP 스타일 모델보다 근본적으로 우월한 이유에 대한 명확한 이론적 및 실증적 설명을 제공합니다. 생성 사전 훈련은 전통적인 대조 방법에는 없는 잠재적인 교차 모달 정렬이라는 귀중한 "웜 스타트(warm start)"를 제공하여, 모델이 데이터를 더 깊이 이해하도록 돕습니다.
*   **도전적인 새 작업에서의 검증**: SeaDoc 벤치마크의 생성과 그에 대한 성공적인 실험은 GRSL을 더욱 확고히 검증하며, 특정 작업에서 모델의 생성 능력을 향상시키는 것이 해당 작업에서 더 나은 검색 및 표현 성능으로 직접 이어진다는 것을 증명합니다. 이는 차세대 검색 엔진이나 추천 시스템 개발에 중요한 통찰을 제공합니다.

이 그림은 MIEB-Lite 벤치마크에서 LCO-EMB의 성능을 다른 선도적인 오픈 소스 및 독점 모델과 비교한 주요 SOTA 결과를 보여줍니다.

내 모든 책을 40% 할인된 가격에 만나보세요

**중요 자료**:
arXiv 페이지 보기
PDF 보기
프로젝트 페이지

---

#### 1.3. DITING: 웹 소설 번역 벤치마킹을 위한 다중 에이전트 평가 프레임워크

우한 대학교(Wuhan University) 등의 연구팀이 발표한 이 논문은 웹 소설이라는 독특하고 도전적인 장르에 대한 대규모 언어 모델(LLM) 번역의 품질을 정교하게 평가하기 위해 고안된 포괄적인 새 프레임워크인 **DITING**을 소개합니다. 새로운 벤치마크와 혁신적인 다중 에이전트 평가 시스템인 **AgentEval**을 구축함으로써, 이 연구는 피상적인 측정 기준을 넘어 문학 번역에 필수적인 더 깊은 "서사적 및 문화적 충실도(narrative and cultural fidelity)"를 평가하는 데 중점을 둡니다.

웹 소설은 빠르게 연재되고, 독자 커뮤니티와 상호작용하며 진화하는 특성 때문에 일반적인 문학 번역과는 다른 복잡성을 가집니다. 특정 장르의 용어, 문화적 배경 지식, 캐릭터 간의 미묘한 관계, 그리고 스토리 전반의 일관성 유지는 기계 번역에 있어 큰 난관으로 작용합니다. 기존의 번역 평가 지표들은 주로 어휘나 문법적 정확성에 초점을 맞추어, 이러한 서사적, 문화적 뉘앙스를 포착하는 데 한계가 있었습니다.

DITING 프레임워크는 이러한 문제점을 해결하기 위해 다면적인 접근 방식을 채택합니다. 단순히 원문과 번역문의 어휘 일치도를 측정하는 것을 넘어, 번역된 텍스트가 원작의 플롯, 캐릭터의 감정선, 세계관 설정, 그리고 문화적 맥락을 얼마나 정확하고 자연스럽게 전달하는지를 평가합니다. 이는 특히 웹 소설 독자들이 중요하게 여기는 '몰입감'과 '재미'를 번역이 얼마나 잘 보존하는지에 대한 깊이 있는 분석을 가능하게 합니다.

이 프레임워크의 핵심 요소인 **AgentEval**은 여러 개의 AI 에이전트가 번역의 다양한 측면을 평가하도록 설계되었습니다. 예를 들어, 한 에이전트는 캐릭터의 일관성을 담당하고, 다른 에이전트는 줄거리의 논리적 흐름을 검토하며, 또 다른 에이전트는 문화적 비유나 속담이 적절하게 현지화되었는지를 판단하는 식입니다. 이들 에이전트는 서로 협력하거나 독립적으로 평가를 수행한 후, 종합적인 피드백을 제공하여 LLM 번역의 강점과 약점을 심층적으로 분석합니다. 이 시스템은 인간 평가자의 주관성을 줄이면서도, 복잡한 문학적 기준을 효과적으로 반영하도록 설계되었습니다.

1년 구독 시 75% 할인

DITING과 AgentEval의 도입은 LLM 기반 번역 시스템의 발전에 새로운 이정표를 제시합니다. 이는 웹 소설뿐만 아니라 게임 시나리오, 영화 대본, 시와 같은 창의적이고 문화 의존적인 텍스트 번역의 품질을 향상시키는 데 기여할 것입니다. 또한, 번역 품질에 대한 객관적이고 다각적인 평가 기준을 제공함으로써, 개발자들이 더욱 정교하고 문화적으로 민감한 번역 모델을 구축하는 데 필요한 지침을 제공할 것으로 기대됩니다. 궁극적으로 이러한 발전은 전 세계 독자들이 언어의 장벽 없이 다양한 문화 콘텐츠를 즐길 수 있는 기반을 마련할 것입니다.