1년 구독 시 75% 할인

최근 몇 년 동안 대규모 언어 모델(LLM) 분야는 경이로운 속도로 발전해 왔습니다. 새로운 세대의 모델들이 끊임없이 등장함에 따라, 연구자들과 개발자들은 최신 동향을 끊임없이 주시하고 이해해야 할 필요성이 커지고 있습니다. 본 글에서는 2025년 10월 셋째 주에 발표된 가장 중요한 LLM 관련 논문들을 간략히 소개합니다. 이 연구들은 모델의 최적화 및 확장, 추론 방식, 성능 평가 기준, 그리고 전반적인 역량 개선 등 차세대 언어 모델의 방향을 제시하는 다양한 핵심 주제들을 다룹니다. 이러한 분야의 새로운 LLM 연구를 지속적으로 파악하는 것은 더욱 유능하고 안정적이며 인간의 가치에 부합하는 모델을 향한 발전을 가속화하는 데 필수적입니다.

목차:
LLM 발전 및 기술 보고서
비전 언어 모델
LLM 추론
후속 학습 및 RL

1년 구독 시 75% 할인

**내 모든 책을 한 번의 클릭으로 40% 할인된 가격에 만나보세요**
유세프 호스니(Youssef Hosni) · 6월 17일

제 책과 로드맵을 묶어 번들을 만들었으니, 한 번의 클릭으로 모든 것을 원가보다 40% 저렴하게 구매할 수 있습니다. 이 번들에는 다음을 포함한 8권의 전자책이 있습니다. 전체 이야기 읽기

---

### 1. LLM 발전 및 기술 보고서

#### 1.1. 표현 오토인코더(Representation Autoencoders)를 사용한 확산 트랜스포머(Diffusion Transformers)

1년 구독 시 75% 할인

뉴욕 대학교에서 발표된 이 논문은 잠재 확산 모델(latent diffusion models)의 구축 방식에 있어 근본적이고 혁신적인 변화를 제안합니다. 이는 보다 효율적이고 확장 가능하며 고품질의 결과를 생성하는 새로운 기반 접근 방식을 제시합니다. 이 연구는 스테이블 디퓨전(Stable Diffusion)과 같은 모델에서 널리 사용되는 오토인코더(autoencoders)에 대한 기존의 가정에 의문을 제기하며, **표현 오토인코더(Representation Autoencoders, RAE)**를 우월한 대안으로 소개합니다.

**핵심 아이디어: 압축 위주의 VAE를 넘어 의미론적 RAE로 전환**

논문의 핵심 주장은 대부분의 확산 트랜스포머(Diffusion Transformers, DiT)에서 활용되는 오토인코더, 특히 스테이블 디퓨전의 초기 VAE가 시대에 뒤떨어지고 제한적인 병목 현상을 야기한다는 것입니다. 기존의 SD-VAE는 계산 비용이 높을 뿐만 아니라, 공격적인 압축을 주 목표로 삼아 중요한 정보 손실을 초래하는 저차원적이고 의미론적으로 취약한 잠재 공간(latent space)을 생성했습니다.

이 논문은 VAE를 완전히 대체하는 방안을 제시합니다. 재구성을 위해 오토인코더를 훈련하는 대신, 그들은 강력하게 사전 훈련된 표현 인코더(representation encoders)(예: DINO 또는 SigLIP)를 고정된 인코더(frozen encoder)로 활용하고, 이를 간단하고 경량화된 훈련된 디코더(trained decoder)와 결합합니다. 이로써 **표현 오토인코더(Representation Autoencoder, RAE)**가 탄생합니다. 핵심 통찰력은 RAE에 의해 생성된 잠재 공간이 작고 압축된 것이 아니라, 크고 고차원적이며 의미론적 정보가 풍부하여 확산 과정(diffusion process)에 훨씬 더 나은 기반을 제공한다는 점입니다. 이는 단순히 픽셀 정보를 넘어 개념적이고 의미적인 정보를 더 잘 포착할 수 있음을 의미합니다.

이 그림은 무거운 컨볼루션(convolutional) 기반 SD-VAE와 경량의 ViT 기반 RAE 간의 명확한 시각적 및 계산적 비교를 제공하며, 효율성 향상을 강조합니다.

내 모든 책을 40% 할인된 가격에 만나보세요

**주요 방법론: 고차원 잠재 공간에서의 확산 모델링 전략**

1년 구독 시 75% 할인

RAE는 우월한 잠재 공간을 제공하지만, 그 높은 차원성은 저차원 VAE 잠재 공간을 위해 설계된 표준 DiT 아키텍처에 큰 도전 과제를 안겨줍니다. 연구팀은 표준 DiT가 RAE 잠재 공간에서 곧바로 훈련될 수 없다는 점을 발견했습니다. 이러한 난관을 극복하기 위해 그들은 일련의 원칙적인 해결책들을 제시합니다.

*   **DiT 너비 스케일링(Scaling DiT Width)**: 그들은 효과적인 공간 모델링을 위해 DiT의 은닉 차원(hidden dimension, 너비)이 RAE의 토큰 차원(token dimension)과 일치하거나 이를 초과해야 한다는 중요한 설계 원칙을 확립했습니다. 이는 모델의 표현력을 잠재 공간의 복잡성에 맞추는 데 필수적입니다.
*   **넓은 확산 헤드(The Wide Diffusion Head, DiTDH)**: 계산량의 2차 폭발 없이 이 너비 요구 사항을 충족하기 위해 그들은 **DiTDH**라는 새로운 DiT 변형을 도입합니다. 이 아키텍처는 표준 DiT에 경량의 얕지만 매우 넓은 "DDT 헤드"를 추가하여 고차원 토큰을 효율적으로 처리합니다. 이는 작은 모델로도 넓은 정보를 다룰 수 있게 합니다.
*   **차원 의존적 노이즈 스케줄링(Dimension-Dependent Noise Scheduling)**: 기존의 노이즈 스케줄이 고차원 공간에서 적절하지 않다는 것을 발견하고, 유효 데이터 차원(토큰 × 채널)을 기반으로 조정되는 새로운 스케줄을 제안했습니다. 이는 노이즈 제거 과정의 정확성을 높입니다.
*   **노이즈 증강 디코딩(Noise-Augmented Decoding)**: RAE 디코더가 확산 프로세스에서 발생하는 노이즈가 많은 출력에 더 견고하도록, 훈련 시 소량의 노이즈를 추가하여 일반화 성능을 향상시킵니다.

이 그림은 DiT의 너비가 잠재 토큰 차원(latent token dimension)보다 크거나 같을 때만 단일 샘플에 성공적으로 과적합(overfit)된다는 것을 보여줌으로써 "너비가 차원과 일치해야 한다"는 발견을 시각적으로 입증하므로 방법론의 핵심입니다. 이러한 RAE 기반 확산 모델의 발전은 단순히 이미지 생성의 질을 높이는 것을 넘어, 비디오 합성, 3D 에셋 생성, 심지어 의료 영상 분야에까지 혁신적인 변화를 가져올 잠재력을 지니고 있습니다. 특히 고차원 데이터를 효율적으로 처리하는 능력은 복잡한 현실 세계 데이터를 모델링하는 데 있어 새로운 지평을 열 것으로 기대됩니다.

내 모든 책을 40% 할인된 가격에 만나보세요

**가장 중요한 발견**

RAE와 새로운 DiTDH 아키텍처의 조합은 놀라운 효율성을 바탕으로 이미지 생성 분야에서 새로운 최첨단(state-of-the-art) 결과를 달성했습니다.

*   **ImageNet에서의 새로운 최첨단 기록**: 최종 모델은 ImageNet 256x256에서 가이던스(guidance) 없이 1.51, 가이던스 포함 시 1.13이라는 새로운 기록적인 FID 점수를 달성하여 이전의 모든 확산 모델을 능가합니다. 또한 512x512 해상도에서도 1.13 FID를 달성하여 고해상도 생성에서도 뛰어난 성능을 보입니다.
*   **대폭 빨라진 훈련 수렴 속도**: 의미론적으로 풍부한 RAE 잠재 공간 덕분에 확산 모델이 훨씬 더 효율적으로 학습할 수 있게 됩니다. 이 프레임워크는 SiT-XL과 같은 이전 기준선에 비해 최대 47배 빠른 훈련 수렴을 달성하며, REPA-XL과 같은 표현 정렬(representation alignment) 방법보다 16배 빠른 속도를 보여줍니다. 이는 연구 및 개발 비용을 획기적으로 줄이는 데 기여합니다.
*   **우월한 재구성 및 표현 능력**: RAE 자체는 표준 VAE보다 더 나은 오토인코더로서, 훨씬 적은 계산 비용으로 더 높은 충실도의 재구성(reconstruction)을 달성합니다(예: 14배 더 효율적). 또한 사전 훈련된 인코더의 강력한 의미론적 이해를 계승하여, 생성된 이미지가 단순히 시각적으로 유사한 것을 넘어 의미적으로도 일관성을 유지할 수 있도록 합니다.

그림 1은 다른 유명 모델들과 비교한 이 논문의 SOTA(State-Of-The-Art) 결과를 개략적으로 보여줍니다. 표 8은 새로운 최첨단 주장을 입증하는 최종적이고 상세한 FID 점수를 포함합니다. 이러한 결과는 고차원 잠재 공간을 효율적으로 다루는 새로운 패러다임이 이미지 생성 분야에 가져올 혁신적인 파급력을 명확히 보여줍니다.

내 모든 책을 40% 할인된 가격에 만나보세요

이 차트는 훈련 효율성의 극적인 향상을 시각적으로 보여주며, 모델이 이전의 선도적인 방법보다 훨씬 빠르게 더 나은 FID 점수를 달성함을 나타냅니다.

**중요 자료**:
arXiv 페이지 보기
PDF 보기
프로젝트 페이지

---

#### 1.2. 언어 중심 옴니모달 표현 학습(Language-Centric Omnimodal Representation Learning) 확장

알리바바(Alibaba)의 다모 아카데미(DAMO Academy)에서 발표한 이 논문은 멀티모달 대규모 언어 모델(MLLM)이 왜 그토록 강력한 임베딩 모델(embedding models)을 생성하는 데 효과적인지에 대한 근본적인 통찰력을 제공합니다. 이 통찰력을 바탕으로 **LCO-EMB(언어 중심 옴니모달 임베딩)**라는 새로운 최첨단 프레임워크를 개발했습니다. 이 연구는 기존의 접근 방식에 도전하며, 이러한 중요한 모델을 구축하는 방법에 대한 우리의 이해를 재구성하는 혁신적인 스케일링 법칙(scaling law)을 제시합니다.

**핵심 아이디어: 생성-표현 스케일링 법칙(Generation-Representation Scaling Law, GRSL)의 발견**

내 모든 책을 40% 할인된 가격에 만나보세요

가장 중요한 발견은 **생성-표현 스케일링 법칙(GRSL)**입니다. 이는 멀티모달 임베딩 모델의 품질이 기반이 되는 MLLM 백본(backbone)의 생성 능력(generative capability)과 직접적이고 긍정적으로 비례한다는 원칙입니다. 간단히 말해, 더 우수한 생성 모델일수록 더 뛰어난 임베딩 모델을 만들어낼 수 있다는 것입니다.

이러한 발견은 전체 문제에 대한 관점을 재정립합니다. 대조 학습(contrastive learning, CL)을 (CLIP처럼) 처음부터 정렬(alignment)을 생성하는 주요 동력으로 보는 대신, 이 연구는 MLLM의 경우 생성 사전 훈련(generative pre-training) 과정에서 이미 많은 교차 모달 정렬 작업이 이루어진다고 주장합니다. 따라서 CL의 주된 역할은 이러한 잠재적 구조를 "정제"하거나 "활성화"하는 보조적인 단계로 작용한다는 것입니다.

**주요 방법론: 언어 중심의 정제 전략**

연구자들은 먼저 핵심 가설에 대한 강력한 실증적 증거를 제시합니다. 즉, MLLM은 생성 사전 훈련을 통해 암묵적인 교차 모달 정렬(cross-modal alignment) 능력을 갖추게 된다는 것입니다. 그들은 강력한 기성 MLLM(Qwen2.5-Omni)을 가져와 **텍스트 전용 데이터(text-only data)**를 사용하여 대조 학습 방식으로 미세 조정했습니다. 놀랍게도, 이 텍스트 전용 튜닝이 텍스트 임베딩(text embeddings)의 품질을 향상시켰을 뿐만 아니라, 다른 모달리티(modalities)로까지 일반화되어 이미지, 오디오 및 비디오 임베딩의 구조와 품질을 크게 개선하는 것을 관찰했습니다. 이는 언어 모델의 핵심 역량이 다른 모달리티에도 긍정적인 영향을 미칠 수 있음을 시사합니다.

이를 바탕으로 그들은 CL을 경량의 사후 정제 단계로 취급하는 LCO-EMB 프레임워크를 제안합니다. 언어 중심 데이터에 매개변수 효율적인 LoRA를 사용하여, 이 프레임워크는 MLLM의 사전 정렬된 생성 임베딩(pre-aligned generative embeddings)을 모델의 강력한 사전 훈련된 지식에 대한 최소한의 방해로 고성능 유사성 매칭 공간(similarity-matching space)으로 매핑합니다.

GRSL을 검증하기 위해 그들은 새롭고 도전적인 시각 문서 검색 벤치마크인 **SeaDoc**을 만들었으며, CL을 적용하기 전에 모델의 생성 능력을 향상시키기 위해 지속적으로 사전 훈련하는 것이 훨씬 더 나은 최종 임베딩 성능을 가져온다는 것을 보여주었습니다. 이는 MLLM 기반 임베딩 모델이 멀티모달 검색, 콘텐츠 추천, 심지어 멀티모달 에이전트 능력과 같은 실용적인 응용 분야에서 어떻게 성능을 향상시킬 수 있는지에 대한 중요한 지침을 제공합니다.

그림 1은 텍스트 전용 훈련이 모든 모달리티에서 이방성(anisotropy)을 어떻게 감소시키는지(임베딩 품질을 향상시키는지) 보여주는 핵심 증거를 제공합니다. 그림 3은 "붕괴된(collapsed)" 임베딩 공간에서 "등방성(isotropic)" 임베딩 공간으로의 이러한 변화를 보여주는 훌륭한 개념도입니다.

**가장 중요한 발견**

LCO-EMB 프레임워크와 GRSL의 발견은 멀티모달 표현 학습(multimodal representation learning)의 미래에 중요한 의미를 가집니다.

1년 구독 시 75% 할인

*   **임베딩을 위한 새로운 스케일링 법칙 제시**: GRSL은 더 나은 임베딩 모델을 구축하기 위한 새로운 방법을 제시합니다. 즉, 가능한 최고의 생성 MLLM으로 시작하는 것이 중요하다는 것입니다. 생성기가 좋을수록 최종 표현 품질의 상한선이 높아집니다. 이는 생성 성능(x축)과 표현 성능(y축) 사이에 명확한 양의 상관관계를 보여주는 산점도(scatter plots)를 통해 GRSL에 대한 직접적인 시각적 증거를 제공하는 논문의 핵심 그림입니다.
*   **언어 중심 훈련의 놀라운 효과 입증**: 주로 텍스트 전용 데이터와 소량의 추가 멀티모달 데이터로 훈련된 LCO-EMB 모델은 포괄적인 MIEB-Lite 벤치마크에서 새로운 최첨단 성능을 달성하며, 훨씬 더 큰 멀티모달 데이터셋으로 훈련된 강력한 독점 모델들을 능가합니다. 이는 데이터 효율적인 학습 전략의 가능성을 열어줍니다.
*   **MLLM 기반 접근 방식의 우월성 설명**: 이 논문은 MLLM 기반 임베딩 모델이 기존 CLIP 스타일 모델보다 근본적으로 우월한 이유에 대한 명확한 이론적 및 실증적 설명을 제공합니다. 생성 사전 훈련은 전통적인 대조 방법에는 없는 잠재적인 교차 모달 정렬의 귀중한 "웜 스타트(warm start)"를 제공하여, 모델이 더 견고하고 일반화 가능한 임베딩을 학습하도록 돕습니다.
*   **도전적인 새로운 작업에서의 검증 완료**: SeaDoc 벤치마크의 생성과 그에 대한 성공적인 실험은 GRSL을 더욱 검증하며, 특정 작업에서 모델의 생성 능력을 향상시키는 것이 해당 작업에서 더 나은 검색 및 표현 성능으로 직접 이어진다는 것을 증명합니다. 이는 연구자들이 멀티모달 모델 개발 시 생성 능력 향상에 우선순위를 두어야 함을 시사합니다.

이 그림은 MIEB-Lite 벤치마크에서 LCO-EMB의 성능을 다른 선도적인 오픈 소스 및 독점 모델과 비교한 주요 SOTA 결과를 보여줍니다. 이러한 발견은 향후 멀티모달 AI의 발전 방향에 중요한 영향을 미칠 것이며, 특히 효율적인 자원 활용과 모델 성능 최적화 측면에서 새로운 패러다임을 제시합니다.

내 모든 책을 40% 할인된 가격에 만나보세요

**중요 자료**:
arXiv 페이지 보기
PDF 보기
프로젝트 페이지

---

#### 1.3. DITING: 웹 소설 번역 벤치마킹을 위한 다중 에이전트 평가 프레임워크

우한 대학교(Wuhan University) 등의 연구진이 발표한 이 논문은 웹 소설이라는 독특하고 도전적인 장르에 대한 대규모 언어 모델(LLM) 번역의 품질을 적절하게 평가하도록 설계된 포괄적인 새 프레임워크인 **DITING**을 소개합니다. 새로운 벤치마크와 혁신적인 다중 에이전트 평가 시스템인 **AgentEval**을 구축함으로써, 이 연구는 단순한 표면 수준의 측정 기준을 넘어 문학 번역에 필수적인 더 깊은 "서사적 및 문화적 충실도(narrative and cultural fidelity)"를 평가하고자 합니다.

1년 구독 시 75% 할인

**핵심 아이디어: 웹 소설 번역의 복잡성 해결 및 다중 에이전트 평가**

기존의 기계 번역 평가는 주로 뉴스 기사나 기술 문서와 같이 사실 전달에 중점을 둔 텍스트에 최적화되어 있었습니다. 그러나 웹 소설과 같은 창작물은 줄거리의 일관성, 캐릭터의 개성 유지, 문화적 뉘앙스 전달, 그리고 독자의 몰입도를 결정하는 문체적 특징 등 훨씬 더 복잡한 요소를 포함합니다. 이러한 요소들은 단순한 단어 일치나 문법적 정확성만으로는 평가하기 어렵습니다. DITING은 이러한 웹 소설 번역의 고유한 도전 과제를 해결하기 위해 설계되었습니다.

**AgentEval**은 이러한 복잡성을 다루기 위한 핵심적인 혁신입니다. 이는 단순히 번역된 텍스트를 분석하는 것을 넘어, 다양한 역할을 맡은 LLM 기반 에이전트들이 번역 품질을 다각적으로 평가하도록 합니다. 예를 들어, 한 에이전트는 '원문 작가'의 입장에서 번역이 원문의 의도와 감성을 잘 살렸는지 평가하고, 다른 에이전트는 '독자'의 입장에서 번역이 자연스럽고 몰입감을 주는지 평가할 수 있습니다. 또한 '편집자' 에이전트는 문법적 오류나 어색한 표현을 지적할 수 있습니다. 이러한 다중 에이전트 접근 방식은 번역 품질에 대한 보다 총체적이고 인간적인 관점을 제공하며, 특히 서사적 흐름과 문화적 적절성을 심층적으로 평가하는 데 강력한 도구가 됩니다.

**주요 방법론: DITING 벤치마크와 AgentEval의 통합**

DITING 프레임워크는 크게 두 가지 구성 요소로 이루어집니다. 첫째, 웹 소설 번역에 특화된 광범위하고 다양한 데이터셋을 포함하는 **DITING 벤치마크**입니다. 이 벤치마크는 다양한 장르와 스타일의 웹 소설을 포함하여, LLM이 실제 웹 소설 번역 환경에서 얼마나 잘 작동하는지 평가할 수 있도록 합니다. 둘째, 앞서 언급한 **AgentEval** 시스템입니다. AgentEval은 다중 에이전트 시뮬레이션을 통해 번역의 품질을 정량적, 정성적으로 평가하며, 각 에이전트의 피드백을 종합하여 최종 점수를 산출합니다.

이러한 방법론은 기존 평가 방식의 한계를 뛰어넘어, 창작물 번역에서 가장 중요한 '충실도(fidelity)'와 '유창성(fluency)'을 동시에 포착하는 데 중점을 둡니다. 특히, 문화적 배경이 다른 독자들에게도 원작의 감동과 재미를 전달할 수 있는 번역을 식별하는 데 큰 도움이 됩니다.

**가장 중요한 발견 및 시사점**

DITING과 AgentEval의 도입은 LLM 기반 번역 모델의 평가 방식에 새로운 지평을 열었습니다.

*   **창작물 번역 평가의 새로운 표준**: DITING은 웹 소설과 같은 문학적 콘텐츠 번역에 특화된 최초의 포괄적인 벤치마크 중 하나로, 기존 벤치마크로는 측정하기 어려웠던 서사적 일관성, 문화적 적절성, 문체 유지 등의 요소를 정밀하게 평가할 수 있는 기반을 마련합니다. 이는 단순한 언어학적 정확성을 넘어선 '번역 예술'의 평가 기준을 제시합니다.
*   **다중 에이전트 평가의 강력함 입증**: AgentEval은 인간의 평가 프로세스를 모방하는 다중 에이전트 접근 방식을 통해, 단일 메트릭으로는 포착하기 힘든 번역의 미묘한 차이를 식별하는 데 탁월한 성능을 보였습니다. 이는 특히 주관적인 판단이 많이 개입되는 창작물 번역에서 LLM의 평가 능력을 획기적으로 향상시킵니다.
*   **LLM의 문화 이해도 및 서사 능력 평가**: 이 프레임워크는 LLM이 단순한 언어 변환을 넘어 얼마나 깊이 있게 문화적 맥락을 이해하고 서사적 요소를 재구성할 수 있는지 평가하는 데 중요한 도구가 됩니다. 이는 향후 LLM이 더욱 복잡한 창작 활동에 기여할 수 있는 잠재력을 측정하는 데 필수적입니다.
*   **미래 LLM 개발 방향 제시**: DITING을 통해 얻은 결과는 웹 소설 번역 분야에서 현재 LLM의 강점과 약점을 명확히 보여줍니다. 이는 연구자들이 LLM의 문화적 지식, 문체 모방 능력, 그리고 장기적인 서사 유지 능력을 개선하는 데 필요한 구체적인 방향을 제시합니다. 이러한 통찰은 번역뿐만 아니라 LLM의 전반적인 창작 및 이해 능력을 향상시키는 데 기여할 것입니다.

이러한 연구는 LLM이 단순한 정보 처리 도구를 넘어, 인간의 섬세한 감성과 문화적 이해를 필요로 하는 분야에서도 얼마나 발전할 수 있는지를 보여주는 중요한 사례가 될 것입니다. 궁극적으로 DITING은 LLM이 인간 작가와 번역가에 더욱 가까워지는 길을 밝혀줄 것입니다.