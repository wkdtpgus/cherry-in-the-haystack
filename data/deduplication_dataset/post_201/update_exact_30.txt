1년 구독 시 75% 할인

최근 몇 년간 대규모 언어 모델(LLM)은 빠르게 발전했습니다. 새로운 세대의 모델이 개발됨에 따라, 연구자와 엔지니어는 최신 진행 상황을 계속 파악해야 합니다. 이 글은 2024년 5월 넷째 주에 발표된 가장 중요한 LLM 논문 중 일부를 요약합니다. 이 논문들은 모델 최적화 및 스케일링, 추론, 벤치마킹, 성능 향상 등 차세대 언어 모델을 형성하는 다양한 주제를 다룹니다. 이러한 분야의 새로운 LLM 연구를 계속 파악하는 것은 더욱 유능하고 견고하며 인간의 가치에 부합하는 모델을 향한 지속적인 발전을 이끄는 데 도움이 될 것입니다.

목차:
1. LLM 발전 및 기술 보고서
2. 멀티모달 LLM과 비전 언어 모델
3. LLM 추론 및 성능 향상 기법
4. 후속 학습 및 정렬

1년 구독 시 75% 할인

**내 모든 책을 한 번의 클릭으로 40% 할인된 가격에 만나보세요**
유세프 호스니(Youssef Hosni) · 6월 17일

제 책과 로드맵을 묶어 번들을 만들었으니, 한 번의 클릭으로 모든 것을 원가보다 40% 저렴하게 구매할 수 있습니다. 이 번들에는 다음을 포함한 8권의 전자책이 있습니다. 전체 이야기 읽기

---

### 1. LLM 발전 및 기술 보고서

#### 1.1. 표현 오토인코더(Representation Autoencoders)를 사용한 확산 트랜스포머(Diffusion Transformers)

1년 구독 시 75% 할인

뉴욕 대학교의 이 연구는 이미지 생성 모델의 효율성과 품질을 혁신하는 새로운 접근 방식인 표현 오토인코더(RAE)를 도입합니다. 기존의 확산 모델이 직면했던 병목 현상을 해결하며, 특히 스테이블 디퓨전(Stable Diffusion)과 같은 모델의 성능을 비약적으로 향상시킬 잠재력을 보여줍니다.

**핵심 아이디어: 압축된 VAE에서 의미론적 RAE로**

핵심 주장은 대부분의 확산 트랜스포머(Diffusion Transformers, DiT)에서 사용되는 오토인코더(일반적으로 스테이블 디퓨전의 원래 VAE)가 시대에 뒤떨어지고 제한적인 병목 현상이라는 것입니다. SD-VAE는 계산 비용이 많이 들고, 공격적인 압축이라는 주요 목표로 인해 중요한 정보를 손실하는 저차원적이고 의미론적으로 취약한 잠재 공간(latent space)을 초래합니다. 이 논문은 VAE를 완전히 대체할 것을 제안합니다. 재구성을 위한 오토인코더를 훈련하는 대신, 그들은 강력한 사전 훈련된 표현 인코더(representation encoders)(예: DINO 또는 SigLIP)를 고정된 인코더(frozen encoder)로 활용하고, 이를 간단하고 경량화된 훈련된 디코더(trained decoder)와 결합합니다. 이를 통해 **표현 오토인코더(Representation Autoencoder, RAE)**가 생성됩니다. 핵심 통찰력은 RAE에 의해 생성된 잠재 공간이 작고 압축된 것이 아니라, 크고 고차원적이며 의미론적 정보가 풍부하여 확산 프로세스(diffusion process)에 훨씬 더 나은 기반을 제공한다는 것입니다. 이 그림은 무거운 컨볼루션(convolutional) 기반 SD-VAE와 경량의 ViT 기반 RAE 간의 명확한 시각적 및 계산적 비교를 제공하며, 효율성 향상을 강조합니다.

내 모든 책을 40% 할인된 가격에 만나보세요

**주요 방법론: 고차원 공간에서 효율적인 확산 제어**

RAE가 제공하는 고차원적이고 의미론적으로 풍부한 잠재 공간은 확산 모델의 학습 효율성을 극대화하지만, 이를 효과적으로 활용하기 위한 새로운 아키텍처와 훈련 전략이 필요합니다. 이 논문은 기존 DiT 아키텍처의 한계를 극복하기 위해 몇 가지 혁신적인 기술을 제시합니다. 그들은 DiT의 은닉 차원(hidden dimension)이 RAE의 토큰 차원(token dimension)과 일치하거나 초과해야 한다는 중요한 설계 원칙을 확립했습니다. 이를 위해 **DiTDH(The Wide Diffusion Head)**라는 새로운 DiT 변형을 제안하여, 경량의 얕지만 매우 넓은 "DDT 헤드"를 통해 고차원 토큰을 효율적으로 처리합니다. 또한, 표준 노이즈 스케줄이 고차원 공간에서 실패하는 문제를 해결하기 위해 유효 데이터 차원(effective data dimension)에 기반한 새로운 노이즈 스케줄링 방식을 도입합니다. 마지막으로, RAE 디코더가 확산 과정에서 발생하는 노이즈에 더욱 강건하도록 노이즈 증강 디코딩(Noise-Augmented Decoding) 기법을 사용하여 훈련됩니다. 이러한 방법론은 RAE의 잠재력을 최대한 발휘하여 이미지 생성의 새로운 지평을 엽니다.

**가장 중요한 발견: 효율성과 성능의 비약적 발전**

RAE와 DiTDH 아키텍처의 결합은 이미지 생성 분야에서 전례 없는 효율성과 최첨단 성능을 달성했습니다. 이 모델은 ImageNet 256x256에서 가이던스(guidance) 없이 1.51, 가이던스 포함 시 1.13이라는 기록적인 FID 점수를 달성하며, 이전의 모든 확산 모델을 능가합니다. 512x512 해상도에서도 1.13 FID를 달성하여 고해상도 생성에서도 뛰어난 능력을 입증했습니다. 주목할 만한 점은, 의미론적으로 풍부한 RAE 잠재 공간 덕분에 훈련 수렴 속도가 SiT-XL과 같은 이전 기준선에 비해 최대 47배, REPA-XL과 같은 표현 정렬(representation alignment) 방법보다 16배 빨라졌다는 것입니다. 이는 모델 개발에 소요되는 시간과 자원을 크게 절감할 수 있음을 의미합니다. 또한, RAE 자체는 표준 VAE보다 훨씬 적은 계산 비용으로 더 높은 충실도의 재구성(reconstruction)을 제공하며(예: 14배 더 효율적), 강력한 사전 훈련된 인코더의 의미론적 이해를 계승하여 이미지 생성의 품질과 효율성을 동시에 끌어올렸습니다.

**중요 자료**:
arXiv 페이지 보기
PDF 보기
프로젝트 페이지

---

#### 1.2. 초거대 언어 모델의 효율적 스케일링: Mixture-of-Experts (MoE) 아키텍처의 부상

최근 LLM의 규모가 기하급수적으로 커지면서, 모델의 효율적인 훈련과 추론은 핵심적인 과제가 되었습니다. 이 문제를 해결하기 위해 Mixture-of-Experts (MoE) 아키텍처가 다시 주목받고 있습니다. MoE는 모델의 파라미터 수를 크게 늘리면서도 계산 비용은 상대적으로 낮게 유지할 수 있는 혁신적인 방법입니다.

**핵심 아이디어: 희소 활성화(Sparsely Activated) 네트워크**

MoE의 기본 아이디어는 하나의 대규모 네트워크 대신, 여러 개의 작은 "전문가(expert)" 네트워크를 병렬로 배치하는 것입니다. 입력 토큰이 주어지면 "게이트(gate)" 또는 "라우터(router)" 네트워크가 해당 토큰을 처리할 가장 적합한 전문가 한두 명을 선택합니다. 이로 인해 전체 모델의 파라미터 수는 방대하지만, 특정 입력에 대해 활성화되는 파라미터는 매우 적어 계산 효율성을 높입니다. 예를 들어, Mixtral 8x7B 모델은 총 470억 개의 파라미터를 가지고 있지만, 추론 시에는 129억 개의 파라미터만 활성화되어 130억 파라미터 모델과 유사한 추론 비용으로 470억 파라미터 모델에 버금가는 성능을 냅니다. 이는 모델의 용량(capacity)을 크게 늘리면서도 계산 비용의 폭발적인 증가를 막는 효과적인 방법입니다.

**최근 발전과 적용 사례**

Mixtral 8x7B는 MoE 아키텍처의 성공적인 적용 사례 중 하나이며, 최근 Grok-1과 같은 모델들도 MoE를 활용하여 뛰어난 성능을 보였습니다. 이러한 모델들은 기존의 조밀한(dense) 모델들이 달성하기 어려웠던 규모의 효율성과 성능을 제공합니다. MoE는 대규모 데이터셋에 대한 훈련을 가속화하고, 더 복잡한 패턴을 학습할 수 있게 하며, 다양한 작업을 처리하는 데 있어 유연성을 제공합니다. 그러나 전문가 간의 부하 분산, 라우터 네트워크의 최적화, 그리고 희소성(sparsity)으로 인한 하드웨어 친화성 문제 등 여전히 해결해야 할 과제들이 존재합니다. 그럼에도 불구하고, MoE는 미래 LLM 스케일링의 핵심 방향 중 하나로 자리매김하고 있습니다.

---

내 모든 책을 40% 할인된 가격에 만나보세요

### 2. 멀티모달 LLM과 비전 언어 모델

멀티모달 대규모 언어 모델(MLLM)은 텍스트뿐만 아니라 이미지, 오디오, 비디오 등 다양한 형태의 데이터를 이해하고 생성하는 능력을 갖추며 LLM의 역량을 확장하고 있습니다. 이러한 모델들은 단순한 정보 결합을 넘어, 모달리티 간의 복잡한 관계를 학습하여 더욱 풍부한 상호작용과 추론을 가능하게 합니다.

#### 2.1. 언어 중심 옴니모달 표현 학습(Language-Centric Omnimodal Representation Learning) 확장

알리바바(Alibaba)의 다모 아카데미(DAMO Academy)에서 발표한 이 논문은 멀티모달 대규모 언어 모델(MLLM)이 강력한 임베딩 모델(embedding models)을 생성하는 데 왜 그렇게 효과적인지에 대한 근본적인 통찰력을 제시합니다. 이 논문은 이러한 통찰력을 활용하여 **LCO-EMB(언어 중심 옴니모달 임베딩)**라는 새로운 최첨단 프레임워크를 만듭니다. 이 연구는 전통적인 접근 방식에 도전하고, 이러한 중요한 모델을 구축하는 방법에 대한 우리의 이해를 재구성하는 새로운 스케일링 법칙(scaling law)을 소개합니다.

**핵심 아이디어: 생성-표현 스케일링 법칙(Generation-Representation Scaling Law, GRSL)**

핵심 발견은 **생성-표현 스케일링 법칙(GRSL)**입니다. 즉, 멀티모달 임베딩 모델의 품질은 기본 MLLM 백본(backbone)의 생성 능력(generative capability)과 직접적이고 긍정적으로 비례합니다. 간단히 말해, 더 나은 생성 모델이 더 나은 임베딩 모델을 만듭니다. 이는 전체 문제를 재구성합니다. 대조 학습(contrastive learning, CL)을 (CLIP처럼) 처음부터 정렬(alignment)을 생성하는 주요 엔진으로 보는 대신, 이 연구는 MLLM의 경우 생성 사전 훈련(generative pre-training) 중에 이미 많은 작업이 수행된다고 주장합니다. CL의 주요 역할은 이러한 잠재 구조를 "정제"하거나 "활성화"하는 것입니다.

1년 구독 시 75% 할인

**주요 방법론: 언어 중심 정제를 통한 임베딩 최적화**

이 연구는 MLLM이 생성 사전 훈련을 통해 이미 암묵적인 교차 모달 정렬(cross-modal alignment)을 가지고 있다는 강력한 증거를 제시합니다. 그들은 강력한 MLLM인 Qwen2.5-Omni를 사용하여 **텍스트 전용 데이터(text-only data)**로 대조 학습을 수행했습니다. 놀랍게도, 이 텍스트 전용 튜닝은 텍스트 임베딩의 품질을 향상시켰을 뿐만 아니라, 이미지, 오디오, 비디오 등 다른 모달리티의 임베딩 구조와 품질까지도 크게 개선했습니다. 이를 바탕으로 LCO-EMB 프레임워크는 CL을 경량의 사후 정제 단계로 활용합니다. 언어 중심 데이터에 매개변수 효율적인 LoRA(Low-Rank Adaptation)를 적용하여, MLLM의 강력한 사전 훈련된 지식에 대한 방해를 최소화하면서 사전 정렬된 생성 임베딩(pre-aligned generative embeddings)을 고성능 유사성 매칭 공간으로 매핑합니다. 이는 MLLM의 내재된 잠재력을 최적화하는 효율적인 방법을 제시합니다.

**가장 중요한 발견: MLLM 기반 임베딩의 잠재력**

LCO-EMB 프레임워크와 GRSL의 발견은 멀티모달 표현 학습 분야에 중대한 영향을 미칩니다. GRSL은 더 나은 임베딩 모델을 구축하기 위한 새로운 패러다임을 제공합니다. 즉, 최고의 생성 MLLM에서 시작하여 그 생성 능력을 바탕으로 임베딩 품질의 상한선을 높이는 것입니다. 이 논문은 생성 성능과 표현 성능 사이에 명확한 양의 상관관계를 시각적으로 입증합니다. 또한, LCO-EMB 모델은 주로 텍스트 전용 데이터와 소량의 추가 멀티모달 데이터로 훈련되었음에도 불구하고, 포괄적인 MIEB-Lite 벤치마크에서 새로운 최첨단 성능을 달성하여 훨씬 더 큰 멀티모달 데이터셋으로 훈련된 독점 모델들을 능가합니다. 이는 MLLM 기반 접근 방식이 기존 CLIP 스타일 모델보다 근본적으로 우월하며, 생성 사전 훈련이 전통적인 대조 방법에는 없는 귀중한 "웜 스타트(warm start)"를 제공함을 명확히 보여줍니다.

**중요 자료**:
arXiv 페이지 보기
PDF 보기
프로젝트 페이지

---

#### 2.2. 멀티모달 추론 및 상호작용의 발전

최근 GPT-4o와 같은 모델의 등장은 멀티모달 LLM이 단순한 임베딩을 넘어 복합적인 추론과 실시간 상호작용이 가능한 수준으로 발전했음을 보여줍니다. 이러한 모델들은 시각, 청각, 텍스트 정보를 동시에 처리하고 통합하여 인간과 유사한 방식으로 세상을 이해하고 반응합니다.

**새로운 기능과 활용 분야**

멀티모달 LLM은 이미지 내의 복잡한 관계를 분석하고, 차트나 그래프에서 데이터를 추출하며, 심지어 비디오 콘텐츠의 맥락을 파악하여 질문에 답하거나 설명을 생성할 수 있습니다. 예를 들어, 사용자가 복잡한 공학 도면을 보여주면서 특정 부품의 기능에 대해 질문하면, 모델은 도면을 시각적으로 이해하고 관련 텍스트 정보를 종합하여 상세한 답변을 제공할 수 있습니다. 또한, 실시간 음성 대화를 통해 시각 정보를 공유하고 즉각적인 피드백을 주고받는 것이 가능해지면서, 교육, 의료, 고객 서비스 등 다양한 분야에서 혁신적인 애플리케이션 개발이 가속화되고 있습니다. 이러한 발전은 LLM이 단순히 정보를 처리하는 도구를 넘어, 인간의 인지 과정을 모방하고 증강하는 강력한 파트너로 진화하고 있음을 시사합니다.

내 모든 책을 40% 할인된 가격에 만나보세요

### 3. LLM 추론 및 성능 향상 기법

대규모 언어 모델의 강력한 성능을 실제 애플리케이션에서 최대한 활용하기 위해서는 추론(inference) 과정의 효율성과 정확성을 극대화하는 것이 중요합니다. 최근 연구들은 모델의 추론 능력을 향상시키기 위한 다양한 전략과 최적화 기법을 제시하고 있습니다.

#### 3.1. 복합 추론 전략: CoT에서 ToT까지

LLM의 추론 능력을 향상시키는 핵심 방법 중 하나는 모델이 복잡한 문제를 단계적으로 해결하도록 유도하는 것입니다. **사고의 사슬(Chain-of-Thought, CoT)** 프롬프팅은 모델이 최종 답변을 도출하기까지의 중간 단계를 명시적으로 생성하도록 하여, 복잡한 산술 문제나 논리적 추론 문제에서 성능을 크게 향상시켰습니다. 여기서 한발 더 나아가, **사고의 나무(Tree-of-Thought, ToT)**는 CoT를 확장하여 모델이 여러 추론 경로를 탐색하고, 각 단계에서 잠재적인 오류를 평가하며, 가장 유망한 경로를 선택하도록 합니다. 이는 문제 해결 과정에 대한 메타 인지적 접근 방식을 도입하여, 모델이 더욱 견고하고 정확한 추론을 수행할 수 있게 합니다. 또한, **자기 수정(self-correction)** 및 **성찰(reflection)** 기법은 모델이 자신의 생성물을 비판적으로 평가하고, 외부 도구의 피드백이나 내부 지식을 활용하여 오류를 식별하고 수정하도록 훈련함으로써 추론의 신뢰성을 높입니다. 이러한 복합 추론 전략들은 LLM이 단순한 패턴 매칭을 넘어, 인간과 유사한 방식으로 복잡한 문제를 해결하는 데 필수적인 요소로 자리 잡고 있습니다.

#### 3.2. 효율적인 추론을 위한 최적화 기술

LLM의 실용적인 배포를 위해서는 추론 속도와 자원 효율성이 필수적입니다. **양자화(quantization)**는 모델의 가중치를 낮은 비트(예: 16비트에서 8비트 또는 4비트)로 압축하여 메모리 사용량과 계산 비용을 줄이는 기술입니다. 이는 모델의 크기를 크게 줄이면서도 성능 저하를 최소화하여 엣지 디바이스나 리소스가 제한된 환경에서도 LLM을 실행할 수 있게 합니다. **추측 디코딩(speculative decoding)**은 작은 모델이 다음 토큰 시퀀스를 예측하고, 큰 모델이 이를 한 번에 검증하여 디코딩 속도를 비약적으로 향상시키는 방법입니다. 또한, **KV 캐싱(Key-Value Caching) 최적화**는 어텐션 메커니즘에서 이전에 계산된 키(Key)와 값(Value) 벡터를 저장하여 반복적인 계산을 피함으로써 추론 속도를 높입니다. **분산 추론(distributed inference)** 기술은 대규모 모델을 여러 GPU나 서버에 분산하여 처리함으로써 단일 장치의 한계를 극복하고 대규모 트래픽을 효율적으로 처리할 수 있도록 합니다. 이러한 최적화 기술들은 LLM이 더 넓은 범위의 애플리케이션에서 실시간으로 작동할 수 있도록 하는 핵심적인 역할을 합니다.

1년 구독 시 75% 할인

### 4. 후속 학습 및 정렬

대규모 언어 모델이 사회에 미치는 영향이 커짐에 따라, 모델이 인간의 가치와 의도에 부합하도록 만드는 **정렬(alignment)** 연구의 중요성이 강조되고 있습니다. 후속 학습(fine-tuning)은 모델의 성능을 특정 작업에 최적화하는 것을 넘어, 안전하고 유익하며 신뢰할 수 있는 AI를 구축하는 데 필수적인 단계가 되고 있습니다.

#### 4.1. 인간 피드백 기반 강화 학습(RLHF)의 진화

**인간 피드백 기반 강화 학습(Reinforcement Learning from Human Feedback, RLHF)**은 LLM을 인간의 선호도에 맞춰 정렬하는 데 가장 성공적인 방법 중 하나입니다. RLHF는 모델의 응답에 대한 인간의 선호도 피드백을 수집하고, 이를 보상 모델(reward model) 훈련에 사용하여 LLM이 인간이 선호하는 응답을 생성하도록 강화 학습을 통해 미세 조정합니다. **PPO(Proximal Policy Optimization)**는 RLHF에서 널리 사용되는 알고리즘이지만, 복잡한 구현과 튜닝의 어려움이 있습니다. 최근에는 **DPO(Direct Preference Optimization)**와 같은 새로운 방법들이 등장하여 보상 모델 없이 직접적으로 인간 선호도를 모델에 반영함으로써 RLHF의 복잡성을 크게 줄였습니다. 또한, **RLAIF(Reinforcement Learning from AI Feedback)**는 인간의 피드백 대신 다른 LLM이 생성한 피드백을 활용하여 정렬 과정을 자동화하고 확장하는 가능성을 보여주고 있습니다. 이러한 기술들은 LLM이 더욱 유용하고 안전하며, 인간과 효과적으로 상호작용할 수 있도록 진화하는 데 기여하고 있습니다.

#### 4.2. 윤리적 AI 및 안전성 확보를 위한 노력

LLM의 정렬은 단순히 성능 향상을 넘어, 모델이 생성할 수 있는 유해하거나 편향된 콘텐츠를 줄이고 사회적 책임을 다하는 AI를 구축하는 데 필수적입니다. 연구자들은 모델이 잘못된 정보를 퍼뜨리거나, 혐오 발언을 생성하거나, 특정 집단에 대한 편견을 강화하는 것을 방지하기 위한 다양한 기술을 개발하고 있습니다. 여기에는 데이터셋의 편향을 줄이는 방법, 안전 지침을 따르도록 모델을 미세 조정하는 방법, 그리고 모델의 의사 결정 과정을 투명하게 만드는 설명 가능한 AI(Explainable AI, XAI) 기법 등이 포함됩니다. 또한, 모델의 견고성(robustness)을 높여 적대적 공격이나 예상치 못한 입력에도 안정적으로 작동하도록 하는 연구도 활발히 진행 중입니다. 이러한 윤리적 AI 및 안전성 확보 노력은 LLM이 사회에 긍정적인 영향을 미치고, 사용자들이 안심하고 AI 기술을 활용할 수 있는 기반을 마련하는 데 중요합니다.

1년 구독 시 75% 할인