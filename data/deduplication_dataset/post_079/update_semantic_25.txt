**1. 대규모 언어 모델의 '허위 정보 생성' 현상 분석 및 개선 방안**

대규모 언어 모델(LLM)이 생성하는 허위 정보, 즉 '환각' 현상은 불가사의한 오류가 아닌, 모델 훈련 및 평가 방식에서 비롯되는 예측 가능한 결과입니다. 사전 훈련(pretraining)은 오류를 유발하는 통계적 압력을 생성하며, 사후 훈련 벤치마크(post-training benchmark)는 종종 솔직한 불확실성보다 자신감 있는 추측에 보상하는 경향이 있습니다. 이에 대한 해결책은 모델이 답변을 보류하는 행위(기권, abstention)에 페널티를 부여하는 현행 평가 방식을 재조정하는 것입니다. 이러한 환각은 의료나 법률 같은 민감한 분야에서 심각한 오용을 초래할 수 있어, AI의 신뢰성과 사회적 수용도를 저해하는 주된 요인으로 작용합니다.

본 연구는 LLM의 환각 발생률에 대한 하한치(lower bound)를 제시합니다. 이는 생성 과정을 이진 '유효성 판단' 문제로 축소하여, 생성 오류율이 해당 분류기의 오분류율에 비례한다고 설명합니다. 오류 없는 데이터셋에서도, 교차 엔트로피(cross-entropy) 최적화는 '모르겠다'고 말하기보다 오류를 생성하는 보정된 기본 모델(calibrated base model)을 만듭니다. 특히, 훈련 데이터 내에서 한 번만 등장하는 정보(싱글턴 비율, singleton rate)는 환각의 주요 원인이 되며, 모델 클래스(model class)의 내재적 한계 또한 오류를 지속시킵니다. 이러한 분석은 LLM이 단순히 통계적 패턴을 학습할 뿐, 실제 사실을 '이해'하는 것이 아님을 시사합니다.

현재의 사후 훈련(post-training) 평가는 모델의 추측 행위를 강화합니다. 대부분의 벤치마크(benchmark)는 기권에 0점을 부여하므로, 불확실한 답변을 보류하는 모델보다 항상 추측하는 모델이 더 높은 점수를 얻게 됩니다. 이는 과도하게 자신감 있는 환각이 지속되는 이유입니다. 제안된 해결책은 명시적인 신뢰도 목표(explicit confidence target)를 설정하는 것입니다. 오답에 대한 명확한 페널티와 '모르겠다(IDK)' 답변에 대한 중립적인 점수를 평가에 통합하여, 모델이 특정 신뢰도 임계값(confidence threshold) 이상일 때만 답변하도록 지시해야 합니다. 이는 모델이 답변과 기권 사이에서 스스로 선택하는 '행동 보정(behavioral calibration)'을 촉진하고, 궁극적으로 AI 시스템의 신뢰도를 높이는 데 기여할 것입니다.

**2. 뇌와 컴퓨터 비전 모델 간의 수렴(Convergence) 요인 분리**

자연 이미지로 학습된 대규모 자기 지도 학습(self-supervised learning) 비전 트랜스포머(ViT) 모델은 인간 뇌와 유사한 내부 표상(internal representation)을 발전시킵니다. 본 연구는 DINOv3(DINOv3) 모델의 크기, 훈련 데이터량, 이미지 유형을 조절하여 뇌와 컴퓨터 비전 모델 간의 유사성(convergence)을 촉진하는 요인들을 분석했습니다. 모델 활성화를 인간 fMRI(공간) 및 MEG(시간) 데이터와 인코딩, 공간, 시간의 세 가지 측정 기준으로 비교한 결과, 이 세 요소 모두 중요하며 정렬은 초기 감각 피질에서 고차원 연합 피질까지 일관되게 전개됨을 확인했습니다. 이는 인공지능이 생물학적 지능의 처리 방식을 모방하는 원리를 이해하는 데 핵심적입니다.

실험에서 8가지 DINOv3(DINOv3) 변형 모델이 사용되었고, fMRI 예측 가능성은 시각 경로(visual pathway)에 집중되었으며 MEG 예측 가능성은 이미지 제시 후 약 70ms(밀리초)부터 상승했습니다. 모델의 하위 계층(layer)은 초기 시각 영역과, 상위 계층은 전전두엽과 강한 상관관계(r≈0.38)를 보였으며, 초기 MEG 윈도우(window)는 모델의 초기 계층과 높은 상관관계(r≈0.96)를 나타냈습니다. 훈련 과정에서 정렬(alignment)은 빠르게 나타났으나 균일하지 않았고, 시간 점수가 가장 먼저 최종 값의 절반에 도달했습니다(훈련의 약 0.7% 시점). 이러한 결과는 인공 신경망의 학습 동역학이 뇌의 정보 처리 계층 구조와 유사함을 시사합니다.

모델의 규모(scale) 및 데이터(data) 효과도 중요했습니다. 더 큰 모델은 인코딩, 공간, 시간 점수 모두에서 높은 성능을 달성했으며, 인간 중심 이미지로 훈련된 모델이 위성/세포 이미지보다 우수했습니다. 이는 모델이 학습하는 시각 정보의 종류가 뇌 유사성 발현에 결정적인 영향을 미친다는 것을 의미합니다. 피질 상관관계(cortical correlate) 분석 결과, 모델 정렬이 늦게 나타나는 뇌 영역(ROI)은 발달적 확장이 크고, 피질이 두꺼우며, 미엘린(myelin)이 적은 특징을 보였습니다. 이러한 발견은 AI 모델 설계에 생물학적 영감을 통합하는 데 있어 중요한 이정표를 제시합니다.

**3. 사용자 맞춤형 연구 전략을 위한 범용 심층 연구 에이전트(UDR)**

본 연구는 사용자가 '자신만의 모델과 전략을 활용'할 수 있도록 지원하는, 일반적이고 특정 모델에 국한되지 않는 심층 연구 에이전트(deep-research agent)인 UDR(Universal Deep Research)을 소개합니다. UDR은 고정된 처리 절차(pipeline) 대신, 자연어로 기술된 연구 전략을 실행 가능한 코드(code)로 변환하고, 이를 격리된 환경(sandbox)에서 실행합니다. 이 과정에서 구조화된 진행 상황 알림을 지속적으로 제공하며, 최종적으로는 완성된 보고서를 사용자에게 전달합니다. 기존 연구 도구의 한계인 전략 및 모델 선택의 경직성을 극복하며, 연구의 유연성과 확장성을 극대화합니다.

UDR의 작동 방식은 사용자가 제공한 연구 전략과 초기 지시(prompt)를 엄격한 도구 사용 및 제어 흐름 제약 조건 하에서 단일 호출 가능 함수(callable function)로 변환하는 것입니다. 이 함수는 외부 환경과 분리된 안전한 공간에서 실행되며, 모든 오케스트레이션(orchestration)은 순수한 코드 형태로 이루어집니다. 대규모 언어 모델(LLM)은 요약, 순위 지정, 정보 추출과 같은 국소적인 작업에만 제한적으로 호출됩니다. 시스템의 상태는 명명된 변수(variable) 내에 저장되어 불필요한 컨텍스트(context) 증가를 방지합니다. 이러한 설계는 LLM의 '환각' 위험을 줄이고, 자율 에이전트의 신뢰성을 높이는 데 기여합니다.

효율성 및 신뢰성 측면에서, 제어 로직(logic)은 CPU(CPU)에서 실행되는 반면, LLM 호출은 범위가 제한적이고 드물게 발생하도록 설계되어 비용과 지연 시간(latency)을 개선합니다. 종단 간(end-to-end) 전략 컴파일 방식은 LLM에게 '스스로 오케스트레이션'하도록 지시하거나 단계별 코드를 연결하는 방식보다 더 높은 신뢰성을 보장하는 것으로 입증되었습니다. 보안 강화를 위해 전략은 프롬프트 주입(prompt-injection) 공격이나 코드 익스플로잇(code exploit)을 방지하도록 샌드박스(sandbox) 환경에서 실행됩니다. 주요 한계점으로는 코드 생성의 정확도 의존성, 실행 중 사용자 상호작용의 부족, 그리고 사용자 작성 전략의 건전성 가정 등이 있습니다. UDR은 인간 연구자와 AI 에이전트 간의 협업 방식을 재정의하며, 연구 생산성을 획기적으로 향상시킬 잠재력을 가집니다.

**4. 시각적 조작을 통한 서사 창작 지원 시스템: 비주얼 스토리텔링**

본 연구는 작가가 인물, 장소, 시간 흐름과 같은 이야기의 시각적 요소들을 직접 조작함으로써 서사를 구성하고 수정할 수 있도록 돕는 시스템과 디자인 프레임워크(framework)를 제시합니다. 단순히 텍스트 프롬프트(prompt)를 사용하는 것을 넘어, 작가는 시각적인 구성 요소들을 끌어다 놓거나(drag), 서로 연결하고, 순서를 재배치하는 방식으로 이야기를 만들어나갑니다. 이 도구는 시각적 조작에 맞춰 텍스트 편집을 실시간으로 제안하며, 시각적 구성을 기반으로 이야기의 특정 구절을 재생성할 수 있는 기능을 제공합니다. 이는 영화, 게임, 웹툰 등 시각적 요소가 중요한 현대 미디어의 스토리텔링 방식에 부합하는 새로운 창작 패러다임을 제안합니다.

프레임워크는 서사학(narratology)의 파불라(fabula)와 시제트(sjuzhet) 개념에 기반하여, 행위자(인물), 시간(시간성), 장소(공간), 사건(초점화)의 스토리 요소와 위치, 연관, 연결, 전개의 4가지 구성 연산자(operator)를 활용합니다. 프로토타입(prototype)은 객체-행동 그래프(graph), 장소 캔버스(canvas), 이벤트 타임라인(timeline)의 세 가지 상호 연동되는 뷰(view)를 제공하여 직접적인 조작을 가능하게 합니다. 양방향 편집 및 버전 관리(versioning) 기능은 작가가 수동으로 텍스트를 편집하면 시각적 요소들이 새로 고쳐지고, 시각적 편집은 텍스트에 추적 가능한 변경점(diff)을 생성하도록 합니다. 이러한 기능은 복잡한 서사의 구조를 직관적으로 파악하고 일관성을 유지하는 데 큰 이점을 제공합니다.

두 가지 사용자 연구가 진행되었습니다. 스토리 계획(planning) 연구에서는 시각적 요소 활용이 텍스트만 사용하는 경우보다 계획 수립, 정보 탐색, 반성적 사고를 개선하는 것으로 나타났습니다. 전문 작가들을 대상으로 한 편집 연구에서는, 참가자들이 공간적, 시간적, 객체 관련 편집을 성공적으로 수행했으며, 시스템이 아이디어 탐색 및 불일치 해소에 도움이 된다고 평가하며 높은 창의성 지원 지수(Creativity Support Index)를 부여했습니다. 구현에는 React + Slate.js 프론트엔드(front end)와 GPT-4o 프롬프트(prompt)가 사용되었으나, LLM 지연 시간(latency)과 의도치 않은 편집이 한계로 남았습니다. 향후에는 관계나 감정 같은 풍부한 구성 요소, 스타일 제어, 비선형 서사 지원 등이 필요합니다. 궁극적으로 이 시스템은 작가의 상상력을 더욱 자유롭고 효율적으로 표현하게 돕는 강력한 도구가 될 것입니다.

**5. 에이전트 강화 학습 기반 수학 추론 모델: rStar2-Agent의 혁신**

rStar2-Agent(rStar2-Agent)는 파이썬(Python) 도구 환경을 활용하여 수학적 추론 능력을 향상시킨 140억 매개변수(parameter) 규모의 에이전트 강화 학습(agentic RL) 모델입니다. 이 모델은 단순히 긴 사고의 사슬(CoT: Chain of Thought)을 넘어 지능적으로 사고하는 법을 학습합니다. GRPO-RoC(GRPO-RoC)라는 롤아웃 전략(rollout strategy)을 도입하여 노이즈(noisy)가 섞인 성공적인 추적 경로를 필터링하며, 대규모 및 저지연 시간(low-latency) 도구 실행을 위한 인프라(infrastructure)를 갖추었습니다. 64개의 MI300X GPU(GPU)에서 510단계의 강화 학습을 거쳐 훈련된 rStar2-Agent는 더 간결한 해법을 도출하며 최첨단 AIME(AIME) 수준의 성능에 도달했습니다. 이는 AI가 외부 도구와 상호작용하며 복잡한 문제를 해결하는 새로운 패러다임을 제시합니다.

GRPO-RoC(GRPO-RoC) 방법론은 롤아웃(rollout)을 과도하게 샘플링(oversample)한 후, 가장 명료하고 정확한 경로만을 선별하여 훈련 중 도구 호출 오류를 줄입니다. 인프라(infrastructure)는 전용 코드 서비스를 통해 훈련 단계당 약 45,000건의 동시 도구 호출을 약 0.3초의 지연 시간으로 안정적으로 처리하며, 로드 밸런싱(load-balancing) 스케줄러(scheduler)로 GPU(GPU) 유휴 시간을 최소화합니다. 훈련 과정은 도구 사용 학습을 위한 비추론 지도 미세 조정(SFT: Supervised Fine-Tuning)으로 시작하여, 출력 길이를 확장하는 세 단계의 강화 학습으로 이어집니다. 이러한 시스템은 LLM이 내부적으로만 추론하는 CoT 방식의 한계를 넘어, 실제 계산을 통해 결과를 검증하고 수정하는 능력을 부여합니다.

연구 결과, rStar2-Agent는 Pass@1 기준으로 AIME24 80.6점, AIME25 69.8점, HMMT25 52.7점을 기록하며, 훨씬 작은 모델 크기에도 불구하고 기존 모델들과 동등하거나 그 이상의 성능을 보여주었습니다. AIME24/25 응답은 다른 모델들보다 간결했습니다. 일반화 능력에서 GPQA-Diamond(GPQA-Diamond) 벤치마크(benchmark)에서도 60.9점으로 성능을 개선했으며, 엔트로피(entropy) 분석은 도구 피드백(feedback)에 의해 촉발된 새로운 반영 토큰(reflection token)을 활용하여 문제 해결 과정의 검증 및 수정(correction)을 가능하게 함을 보여주었습니다. 이는 AI 에이전트가 자신의 실수를 인식하고 교정하는 메타인지(metacognition)적 특성을 발전시킬 수 있음을 시사하며, STEM 교육 및 연구 분야에 큰 영향을 미칠 잠재력을 가집니다.

**6. 비용 효율적인 LLM 활용을 위한 적응형 라우팅 프레임워크**

본 연구는 지출 한도를 준수하며 각 질의(query)에 대해 어떤 대규모 언어 모델(LLM)을 호출할지 실시간으로 학습하는 라우팅 프레임워크(routing framework)를 제안합니다. 이 프레임워크는 라우팅을 문맥적 밴딧(contextual bandit)으로 취급하고, 인간 선호도 데이터(data)로 초기화하며, 질의 전반에 걸쳐 예산을 할당하는 온라인 비용 정책을 추가합니다. 이는 다양한 LLM의 성능과 비용을 최적화하여, AI 서비스의 경제성과 효율성을 동시에 개선하는 데 필수적입니다.

핵심 아이디어는 질의와 후보 LLM을 위한 공통 임베딩 공간(embedding space)을 구축하고, 이를 오프라인(offline) 인간 선호도와 정렬한 다음, 밴딧 피드백(feedback)을 사용하여 LLM 임베딩(embedding)을 실시간으로 업데이트하는 것입니다. 모델 선택은 코사인 유사도(cosine-similarity) 보상을 사용하는 선호도 사전 LinUCB 변형(PILOT) 알고리즘을 통해 이루어집니다. 예산 제어는 보상-비용 임계값(threshold)으로 적격 모델을 필터링(filter)하고, 총 지출이 예산 내에 유지되도록 온라인 다중 선택 배낭 정책(online multi-choice knapsack policy)을 도입합니다. 이 접근 방식은 동적 환경에서 모델을 지능적으로 선택하는 중요한 발전을 보여줍니다.

연구 결과, RouterBench(RouterBench) 다중 작업 라우팅(routing)에서 GPT-4(GPT-4) 성능의 약 93%를 약 25%의 비용으로 달성했습니다. 단일 작업인 MMLU(MMLU)에서는 약 27%의 비용으로 약 86%의 성능을 달성했습니다. 누적 후회(cumulative regret)는 밴딧 기준선(baseline)보다 지속적으로 낮았으며, 온라인 비용 정책은 강력한 오프라인(offline) 오라클(oracle)과 동등하거나 그 이상의 성능을 보였습니다. 지연 시간(latency) 오버헤드(overhead)는 라우팅이 추론(inference) 자체에 비해 거의 지연을 추가하지 않음을 보여주었습니다(GPT-4의 약 2.5초 대비 0.065~0.239초). 이는 실시간 AI 애플리케이션의 비용 효율적 배포에 중요한 영향을 미칩니다.

**7. LLM의 숨겨진 사고 과정: 암묵적 추론의 이해와 활용**

본 조사는 대규모 언어 모델(LLM)이 중간 단계를 외부에 명시적으로 출력하지 않고도, 모델의 잠재적 상태(latent state) 내부에서 다단계 문제 해결을 수행하는 현상을 '암묵적 추론(implicit reasoning)'으로 정의합니다. 이 연구는 이 분야를 실행 패러다임(paradigm)별로 분류하고, 암묵적 추론의 존재를 뒷받침하는 증거, 평가 방법, 그리고 아직 해결되지 않은 과제들을 심층적으로 검토합니다. 암묵적 추론은 명시적 사고의 사슬(CoT: Chain-of-Thought) 방식과 대비되며, 모델의 추론 속도와 비용 효율성을 극대화하려는 시도입니다.

암묵적 추론의 세 가지 실행 패러다임이 제시됩니다. 첫째, **잠재 최적화(latent optimization)**는 모델의 내부 표상(internal representation)을 직접 조절하여 추론 신호를 전달합니다. 둘째, **신호 유도 제어(signal-guided control)**는 텍스트 생성 없이 경량 제어(lightweight control)를 통해 계산을 조절합니다. 셋째, **계층 순환 실행(layer-recurrent execution)**은 루프(loop)에서 공유 블록(block)을 재사용하여 내부적으로 더 깊은 사고의 사슬을 시뮬레이션(simulate)합니다(예: ITT, 루프형 트랜스포머). 이러한 접근 방식은 LLM이 인간처럼 모든 사고 과정을 언어로 표현하지 않고도 문제를 해결하는 메타인지(metacognition)적 특성을 모색합니다.

잠재적 프로세스가 실재한다는 증거로는 구조적 신호(계층별 분해), 행동적 특징(단계 건너뛰기), 그리고 표현 연구(숨겨진 상태에서 중간 사실 복구) 등이 있습니다. 평가는 최종 답변 정확도(accuracy, Pass@k), 효율성(latency, FLOPs), 혼란도(perplexity) 등을 포함하며, 상식, 수학/코드, 독해, 다단계 QA(QA) 등 광범위한 벤치마크(benchmark)를 활용합니다. 주요 해결 과제로는 제한된 해석 가능성(interpretability), 약한 제어 및 신뢰성, 어려운 작업에서 명시적 CoT(CoT)와의 정확도 격차, 불균일한 평가, 아키텍처(architecture) 제약 등이 있습니다. 궁극적으로 암묵적 추론은 더 빠르고 저렴한 추론(inference)과 풍부한 내부 계산을 약속하며, AI의 신뢰성과 투명성을 높이는 하이브리드(hybrid) 설계 및 표준화된 평가가 요구됩니다.

**8. 임베딩 기반 검색의 이론적 한계에 대하여**

질의(query)가 충분히 많은 '혼합 및 일치(mix-and-match)' 문서 집합(document set)을 요구할 때, 단일 벡터(vector) 밀집 검색기(dense retriever)는 모든 가능한 상위 k개의 관련성 조합을 실현할 수 없습니다. 본 논문은 이러한 실패의 원인을 관련성 행렬(relevance matrix)의 부호 순위(sign-rank)와 연결 짓고, 필요한 임베딩 차원(embedding dimension)에 대한 하한(lower bound)과 상한(upper bound)을 증명합니다. 나아가, 간단하지만 의도적으로 조합적 난이도를 높인 데이터셋(LIMIT)을 사용하여 모델들을 스트레스 테스트(stress-test)합니다. 이는 임베딩 기반 검색의 근본적인 한계를 이론적으로 밝히는 중요한 연구입니다.

이론적으로, 검색은 이진 qrel 행렬(matrix)에서 행별 순서나 임계값(threshold)을 보존하는 문제로 형식화되며, 이 용량은 행렬의 부호 순위(sign-rank)에 의해 제한됩니다. 고정된 차원 ddd에 대해 일부 상위 k 집합은 표현 자체가 불가능하며, 이는 특정 검색 작업이 단일 벡터 임베딩 모델로는 불가능함을 의미합니다. 최적의 경우에도, k=2일 때 해결 가능한 코퍼스(corpus) 크기는 ddd의 세제곱에 비례하며, 4096차원 임베딩에서도 웹 스케일(web scale)보다 훨씬 낮은 한계를 보여, 훈련 데이터(training data)나 손실 함수(loss function)와 무관한 근본적인 제약을 시사합니다. 이러한 발견은 현재의 임베딩 모델들이 복잡한 논리적 관계나 '구성성(compositionality)'을 이해하는 데 취약함을 드러냅니다.

LIMIT 데이터셋(dataset) 결과, 최첨단(SOTA) 단일 벡터 모델들은 복잡한 조합 질의에서 Recall@100(Recall@100)이 20% 미만을 기록하는 등 저조한 성능을 보였습니다. 조합 밀도가 높을 때 점수가 급격히 하락하는 반면, 희소한 패턴(무작위, 주기, 분리)은 훨씬 쉽게 해결되어, 실현 가능한 상위 k 집합의 수가 병목 현상임을 강조합니다. 대안으로는 교차 인코더(cross-encoder)가 작은 LIMIT 변형을 완벽히 해결했으며, 다중 벡터(vector) 후기 상호작용 모델(late-interaction model)과 BM25(BM25) 같은 고차원 희소 기준선(baseline)도 강력한 성능을 보였습니다. 이는 밀집 1단계 검색이 재순위 지정기(reranker), 다중 벡터, 또는 희소 방법과 결합되거나 대체되어야 함을 시사하며, 차세대 검색 시스템 설계에 중요한 방향을 제시합니다.

**9. 지속적인 성장과 적응을 위한 자체 진화 AI 에이전트의 기술 동향**

이 조사는 피드백 루프(feedback loop)를 통해 지속적으로 적응하여 정적 기반 모델(foundation model)과 평생 적응성(adaptability)을 연결하는 자체 진화 AI 에이전트(AI agent) 구축 기술을 검토합니다. 연구는 통합 프레임워크(framework)를 소개하고, 도메인(domain)별 전략을 다루며, 자율 에이전트 시스템(agentic system) 발전에 있어 평가, 안전, 윤리를 논의합니다. 이러한 에이전트는 변화하는 환경에 유연하게 대처하며, AI의 '평생 학습(lifelong learning)'이라는 궁극적인 목표에 중요한 진전을 가져옵니다.

**10. Hermes 4: 구조화된 다중 턴 추론을 갖춘 하이브리드 모델 계열**

Hermes 4(Hermes 4)는 구조화된 다중 턴 추론(multi-turn reasoning)과 광범위한 지시 따르기(instruction following)를 통합하는 하이브리드(hybrid) 추론 모델(reasoning model) 계열을 소개합니다. 이 보고서는 데이터(data) 및 훈련 과제를 상세히 설명하고, 추론, 코딩, 정렬 작업 전반에 걸쳐 성능을 평가하며, 모든 모델 가중치(weight)를 공개적으로 출시합니다. 이러한 접근 방식은 LLM의 복잡한 문제 해결 능력을 향상시키고, 오픈 소스(open-source) 커뮤니티의 발전에 기여합니다.