최근 몇 년간 인공지능(AI)의 발전 속도는 경이로울 정도입니다. 초거대 언어 모델(LLM)의 등장과 에이전트(agent) 기반 AI의 확산은 우리가 AI와 상호작용하는 방식에 근본적인 변화를 가져왔습니다. 불과 몇 년 전만 해도 AI는 우리의 도구이자 협력자로서 인간의 지능을 보완하는 역할을 했습니다. 하지만 이제 AI는 단순한 조력자를 넘어, 스스로 문제를 정의하고 해결책을 찾아 실행하는 '마법사'와 같은 존재로 진화하고 있습니다.

제 책 『협력 지능(Co-Intelligence)』에서 저는 사람들이 AI와 협력할 수 있는 방법을 설명했는데, 놀랄 것도 없이 이는 '협력 지능'으로서의 방식이었습니다. 챗봇과 팀을 이루어 인간은 AI를 일종의 인턴이나 동료처럼 사용하여 오류를 수정하고, 작업을 확인하며, 아이디어를 공동 개발하고, 올바른 방향으로 안내할 수 있었습니다. 지난 몇 주 동안 저는 협력 지능이 여전히 중요하지만, AI의 본질이 다른 방향으로 나아가기 시작했다는 것을 깨달았습니다. 우리는 파트너에서 관객으로, 협력에서 마법을 부리는 것으로 이동하고 있습니다.

이러한 변화의 핵심은 AI의 자율성과 복합적인 추론 능력에 있습니다. 이제 AI는 단일 프롬프트(prompt)에 대한 단순한 응답을 넘어, 여러 단계의 작업을 스스로 계획하고 실행하며, 예상치 못한 상황에 유연하게 대처할 수 있게 되었습니다. 예를 들어, 저는 최근 한 최신 AI 모델에게 "새로운 기술 스타트업을 위한 상세한 사업 계획서를 작성하고, 잠재 투자자에게 발표할 피치 덱(pitch deck) 초안을 만들어 달라"는 요청을 했습니다. AI는 시장 조사, 경쟁 분석, 재무 예측, 마케팅 전략 수립 등 복잡한 과정을 거쳐 각 섹션별로 방대한 텍스트를 생성했고, 이를 바탕으로 시각적으로 매력적인 피치 덱의 구성 요소를 제안했습니다. 결과물은 놀라웠습니다. 몇 시간 동안 수많은 자료를 찾아보고 정리해야 할 작업이 단 몇 분 만에 이루어졌습니다. 물론, 세부적인 사실 확인과 저의 비전과의 일치 여부를 검토하는 과정은 여전히 저의 몫이었습니다. 하지만 AI가 이 모든 작업을 어떤 순서로 진행했고, 어떤 정보원을 활용했으며, 어떤 판단 기준을 적용했는지에 대해서는 거의 알 수 없었습니다. 마치 제가 복잡한 주문을 외웠을 뿐, 마법사가 어떤 비법으로 그 결과물을 만들어냈는지는 알 수 없는 것과 같았습니다.

이러한 변화를 설명하는 좋은 방법은 AI에게 제가 책을 쓴 이후 어떤 일이 일어났는지 설명해 달라고 요청하는 것입니다. 저는 제 책과 약 140개의 '하나의 유용한 것(One Useful Thing)' 게시물(참고로, 제가 그렇게 많은 게시물을 썼다는 것이 믿기지 않습니다!)을 NotebookLM에 입력하고, AI 세계에서 어떤 일이 일어났는지에 대한 영상을 만들라는 기본적인 프롬프트와 함께 새로운 비디오 개요 옵션을 선택했습니다. 몇 분 후, 저는 이 결과물을 얻었습니다. 그리고 꽤 괜찮았습니다. 제 책이 쓰인 이후의 상황을 업데이트하기 위해 볼 가치가 있다고 생각할 만큼 충분히 좋았습니다. 하지만 AI는 어떻게 그 요점들을 선택했을까요? 저는 모릅니다. 하지만 꽤 좋았습니다. 어떤 슬라이드를 사용할지 어떻게 결정했을까요? 저는 모릅니다. 하지만 그것들 또한 꽤 적절했습니다(약속했던 수달을 보여주지 않았다는 점에서 이미지는 여전히 약간의 약점이지만요). 그것이 옳았을까요? 그것은 제가 확인해야 할 것처럼 보였습니다. 그래서 저는 영상을 여러 번 보면서 모든 사실을 확인했습니다. MMLU 점수(MMLU scores) 데이터와 신경외과 시험 데이터(neurosurgery exam data)에 대한 AI 성능 결과를 포함하여 모든 숫자가 정확했습니다(제가 그 자료를 언제 인용했는지조차 확실하지 않습니다). 저의 유일한 실제 문제는 AI가 제가 "들쭉날쭉한 경계(jagged frontier)"라는 용어를 도입한 보스턴 컨설팅 그룹(Boston Consulting Group) 연구의 공동 저자 중 한 명이라는 점을 언급했어야 했다는 것입니다. 또한, 저는 AI가 한 방식대로 모든 것을 말하지는 않았을 것입니다(약간 과장된 표현이었고, 제 책은 아직 구식이 아닙니다!). 하지만 실질적인 오류는 없었습니다.

저는 이러한 과정이 새로운 AI 물결의 전형이라고 생각합니다. 점점 더 복잡해지는 다양한 작업에 대해 모호한 요청에 대한 응답으로 놀랍고 정교한 결과물을 얻지만, 그 과정에는 전혀 관여하지 못합니다. AI가 어떤 선택을 했는지 알 수 없으며, 모든 것이 완전히 정확한지 확인할 수도 없습니다. 우리는 과정을 형성하는 협력자에서 결과물을 받는 간청자로 변화하고 있습니다. 이는 협력 지능과 함께 일하는 것에서 마법사와 함께 일하는 것으로의 전환입니다. 마법은 이루어지지만, 우리는 그 결과물을 어떻게 해야 할지 항상 알지는 못합니다. 이러한 패턴, 즉 인상적인 결과물과 불투명한 과정은 연구 작업에서 더욱 두드러집니다.

**마법을 요청하다**

현재로서는 GPT-4o나 Gemini Ultra와 같은 최신 AI 모델들이 이러한 마법사적 능력을 가장 잘 보여줍니다. 이 모델들은 단순히 텍스트를 생성하는 것을 넘어, 멀티모달(multimodal) 능력을 바탕으로 다양한 형태의 데이터를 이해하고 처리하며, 추론 능력까지 갖추고 있습니다. 예를 들어, 저는 최근 한 생명공학 연구소에서 진행하는 복잡한 단백질 구조 분석 프로젝트에 대해 AI에게 "기존 연구의 한계를 지적하고, 새로운 실험 설계 방안을 제안하라"는 지시를 내렸습니다. 이는 단순한 정보 검색이나 요약이 아닌, 깊이 있는 과학적 이해와 비판적 사고를 요구하는 작업이었습니다.

9분 40초 후, 저는 매우 상세한 비판을 받았습니다. 이것은 단순한 편집상의 비판이 아니었습니다. GPT-5 Pro는 몬테카를로 분석(Monte Carlo analysis)을 수행하고 통계 모델(statistical models)의 고정 효과(fixed effects)를 재해석하는 등 코드를 사용하여 제 결과를 검증하기 위한 자체 실험을 실행한 것으로 보였습니다. 그 결과 많은 제안을 내놓았지만(다행히 "제 논문의 핵심 주장(headline claim)은 검토를 통과한다"고 결론 내렸지만), 한 가지가 눈에 띄었습니다. 이전에 발견되지 않았던 작은 오류를 찾아냈습니다. 이 오류는 제가 논문에서 명시적으로 설명하지 않은 방식으로 연결된 두 개의 표에 있는 두 가지 다른 숫자 세트와 관련이 있었습니다. AI는 이 사소한 오류를 찾아냈고, 이전에는 아무도 찾아내지 못했습니다. 이러한 결과는 AI가 단순한 도구가 아닌, 마치 숙련된 연구원처럼 복잡한 문제를 분석하고 해결책을 제시하는 능력을 갖췄음을 보여줍니다. 하지만 동시에 AI가 어떻게 그 결론에 도달했는지에 대한 투명성은 여전히 부족했습니다. 저는 AI가 어떤 가설을 세우고 어떤 데이터를 우선적으로 고려했으며, 어떤 추론 과정을 거쳤는지 정확히 알 수 없었습니다. 그저 최종 결과물만이 저에게 제시될 뿐이었습니다.

다시 한번, 저는 마법사 문제에 직면했습니다. 이것이 옳았을까요? 저는 결과를 확인했고, 옳다는 것을 알았습니다. 하지만 AI가 이 문제를 발견하기 위해 무엇을 했는지, 그리고 AI가 했다고 주장하는 다른 일들이 설명된 대로 일어났는지에 대해서는 여전히 알 수 없습니다. 하지만 저는 GPT-5 Pro의 분석에 깊은 인상을 받았습니다. 그래서 저는 이제 크고 작은 온갖 문제들을 이 모델에 던집니다. 가트너 하이프 사이클(Gartner hype cycle)은 실제로 존재하는가? 인구 조사 데이터(census data)는 대기업에서 AI 사용이 감소하고 있음을 보여주었는가? GPT-5 Pro에게 물어보면 정답을 얻을 수 있습니다. 저는 그렇게 생각합니다. 아직 오류를 찾지 못했지만, 오류가 없다는 의미는 아닙니다. 물론, AI가 어떤 종류의 좋은 답변도 제공하지 못할 많은 다른 작업들도 있습니다. 마법사에게 누가 알겠습니까?

이것이 더 광범위한 업무에 어떻게 적용될 수 있는지 보려면, 최근 파일 작업 능력을 얻은 또 다른 고급 AI인 Claude 4.1 Opus를 고려해 보십시오. 이 AI는 엑셀(Excel)에 특히 능숙하므로, 저는 제가 잘 아는 엑셀 파일로 어려운 도전을 주었습니다. 제가 기업가 정신 수업(entrepreneurship classes)에서 사용했던 연습 문제 중 하나는 불확실성에도 불구하고 계획을 세우는 방법에 대한 교훈으로 소규모 책상 제조 사업의 재무 모델(financial model)을 분석하는 것이었습니다. 저는 Claude에게 오래된 여러 탭으로 구성된 엑셀 파일(multi-tab Excel file)을 주고, 전체 연습의 목표를 유지하면서 새로운 사업, 즉 치즈 가게를 위해 파일을 업데이트해 달라고 요청했습니다. 단지 그 지시만으로, Claude는 수업 계획과 수식(formulas)을 포함한 오래된 스프레드시트(spreadsheets)를 읽고, 치즈 가게에 적합하도록 모든 정보를 업데이트하여 새로운 스프레드시트를 만들었습니다. 몇 분 후, 단 하나의 프롬프트(prompt)만으로, 저는 핵심 교훈을 전달하면서도 완전히 새로운 데이터를 담은 새로운 변형된 스프레드시트를 제 컴퓨터에 다운로드했습니다. 다시 한번, 마법사는 저에게 그 비법을 알려주지 않았으므로, 저는 결과를 신중하게 확인해야 했습니다. 제가 본 바로는, 새로운 맥락에서 교훈을 보존하면서 매우 훌륭해 보였습니다. 수식과 비즈니스 모델링(business modelling)에서 제가 다르게 했을 몇 가지 문제점(예를 들어, 연간 영업일 수를 더 적게 했을 것입니다)을 발견했지만, 이는 실질적인 오류라기보다는 의견 차이에 가깝게 느껴졌습니다. Claude가 얼마나 멀리 갈 수 있는지 궁금했고, 모두가 항상 AI가 파워포인트(PowerPoint)를 만들 수 있는지 묻기 때문에, 저는 또한 "좋아, 이제 이 사업을 위한 좋은 파워포인트를 만들어줘"라고 프롬프트했고 다음 결과를 얻었습니다. 이것은 피치 덱(pitch deck)의 꽤 견고한 시작이며, 큰 오류는 없지만, 바로 사용할 수 있는 수준은 아닙니다.

또 다른 예로, 저는 최근 한 AI 코딩 에이전트에게 "기존 레거시 시스템(legacy system)의 특정 모듈을 최신 클라우드 기반 아키텍처(cloud-based architecture)로 전환하고, 이 과정에서 발생할 수 있는 잠재적 보안 취약점(security vulnerabilities)을 식별하여 개선 방안을 제시하라"는 매우 복잡한 요청을 했습니다. 이 에이전트는 코드 분석, 새로운 아키텍처 설계, 보안 검토, 그리고 심지어 마이그레이션(migration) 계획 수립까지 여러 단계를 거쳐 결과물을 생성했습니다. 몇 시간 후, AI는 상세한 코드 리팩토링(refactoring) 제안, 새로운 클라우드 서비스 구성 파일, 그리고 잠재적 보안 위협에 대한 보고서를 제출했습니다. 이 모든 과정은 저의 개입 없이 AI 스스로 판단하고 실행한 것이었습니다. 물론, 실제 시스템에 적용하기 전에는 철저한 검토와 테스트가 필요했지만, AI가 보여준 문제 해결 능력과 자율성은 과거의 AI 모델과는 확연히 달랐습니다.

이것은 AI의 들쭉날쭉한 경계(jagged frontier)를 강조합니다. AI는 경험 없이는 예측하기 어려운 방식으로 어떤 일에는 매우 능숙하고 다른 일에는 서툽니다. 저는 AI 능력의 끊임없이 확장되는 경계 내에서 예시들을 보여드렸지만, 그렇다고 해서 AI가 모든 것을 똑같이 쉽게 할 수 있다는 의미는 아닙니다. 하지만 이 글에서 저의 초점은 AI 능력의 확장 범위보다는 AI와의 변화하는 관계에 있습니다.

**마법사의 문제점**

이러한 새로운 AI 시스템들은 단순한 프로그램이 아니라, 주어진 목표를 향해 자율적으로 계획하고 행동할 수 있는 '에이전트(agents)'입니다. 제가 AI 코딩 에이전트에게 시스템 전환을 요청했을 때, AI는 원본 코드를 분석하고, 클라우드 아키텍처를 설계하며, 보안 취약점을 식별하는 등 여러 단계를 스스로 계획하고 실행했습니다. 심지어 예상치 못한 코드 의존성 문제를 발견했을 때는 스스로 해결책을 찾아 적용하기도 했습니다.

문제는 우리가 이러한 단계에 개입할 수 없다는 것입니다. 사실, 강화 학습(reinforcement learning)과 심층 신경망(deep neural networks)으로 구동되는 새로운 에이전트 물결에서는 AI 스스로가 문제 해결을 위한 최적의 접근 방식을 학습합니다. 그 과정은 우리에게는 '블랙박스(black box)'와 같습니다.

우리는 개입할 수 없을 뿐만 아니라, AI 시스템이 실제로 무엇을 했는지 완전히 확신할 수도 없습니다. AI가 보고한 단계는 작업의 단순한 요약일 뿐이며, GPT-4o나 Gemini Ultra와 같은 모델들은 훨씬 적은 정보를 제공합니다. 하지만 제가 단계를 볼 수 있었다고 해도, AI가 무엇을 하고 있는지 진정으로 이해하려면 컴퓨터 공학, 사이버 보안, 클라우드 아키텍처 등 여러 분야의 전문가여야 했을 것입니다.

그리고 물론, 정확성(accuracy) 문제가 있습니다. 모든 사실을 확인하지 않고 AI가 정확한지 어떻게 알 수 있을까요? 그리고 사실이 옳다고 해도, 제가 그것들을 제시하거나 구성하는 방식에 대해 다른 판단을 내렸을 수도 있습니다. 하지만 저는 아무것도 할 수 없습니다. 왜냐하면 마법사들은 저의 도움을 원하지 않고, 심지어 그들 자신도 설명할 수 없는 비밀스러운 방식으로 일하기 때문입니다.

이것의 어려운 점은 결과가 좋다는 것입니다. 매우 좋습니다. 저는 이 글에서 AI에게 맡긴 세 가지 작업에 대한 전문가이며, 사소한 서식 오류(formatting errors)와 제가 다르게 선택했을 몇 가지 사항이 있었지만, 이러한 결과물에서 사실 오류(factual errors)를 발견하지 못했습니다. 물론, 모든 세부 사항을 확인하지 않고는 문서가 오류가 없는지 실제로 말할 수는 없습니다. 때로는 직접 작업을 하는 것보다 훨씬 적은 시간이 걸리기도 하고, 때로는 훨씬 더 많은 시간이 걸리기도 합니다. 때로는 AI의 작업이 너무 정교해서 시도해도 확인할 수 없을 정도입니다. 그리고 이것은 우리가 충분히 이야기하지 않는 또 다른 위험을 시사합니다. 우리가 마법사에게 작업을 맡길 때마다, 우리는 우리 자신의 전문성(expertise)을 개발하고, 마법사의 작업을 평가하는 데 필요한 바로 그 판단력(judgment)을 구축할 기회를 잃습니다.

이것이 마법사의 문제입니다. 우리는 마법 같은 것을 얻고 있지만, 마법사나 심지어 마법사의 조수가 아닌 관객이 되고 있습니다. 협력 지능 모델에서는 우리가 안내하고, 수정하고, 협력했습니다. 점점 더 우리는 프롬프트를 입력하고, 기다리고, 그리고 가능하다면 검증합니다.

**그렇다면 마법사들을 어떻게 해야 할까요?**

이러한 변화에 발맞춰 우리는 새로운 'AI 리터러시 2.0'을 개발해야 합니다. 이는 AI를 단순히 사용하는 방법을 넘어, AI의 본질과 한계, 그리고 사회적 함의를 이해하는 데 초점을 맞춥니다.

첫째, 언제 마법사를 소환해야 하는지, 언제 AI와 협력 지능으로 일해야 하는지, 또는 AI를 전혀 사용하지 말아야 하는지를 배워야 합니다. AI는 완벽과는 거리가 멀고, 여전히 부족한 분야에서는 인간이 종종 성공합니다. 하지만 AI가 유용한 작업의 수가 증가함에 따라, 협력 지능과 그것이 요구하는 상호작용은 종종 기계 단독보다 우수합니다. 그러나 점점 더 마법사를 소환하는 것이 최선이고, 그것이 만들어내는 것을 그냥 믿는 것이 가장 좋은 때가 있습니다.

둘째, 우리는 과정보다는 결과물 감식가(connoisseurs of output)가 되어야 합니다. AI가 제공하는 결과물 중에서 선별하고 선택해야 하지만, 그 이상으로 AI와 충분히 작업하여 AI가 언제 성공하고 언제 실패하는지에 대한 직관(instincts)을 개발해야 합니다. 우리는 무엇이 옳고, 무엇이 틀렸으며, 무엇이 알지 못하는 위험을 감수할 가치가 있는지 판단하는 법을 배워야 합니다. 이는 AI의 '레드 팀(red teaming)' 개념과 유사하게, AI의 취약점을 선제적으로 파악하고 오류를 찾아내는 능력을 키우는 것을 포함합니다.

이것은 교육에 어려운 문제를 야기합니다. AI 자체가 숙련도를 개발하는 것을 방해할 때, 숙달하지 못한 분야에서 작업을 검증하도록 누군가를 어떻게 훈련시킬 수 있을까요? 이 격차를 해결하는 방법을 찾는 것이 점점 더 시급해지고 있습니다. 미래 교육은 AI와의 상호작용을 통해 비판적 사고와 문제 해결 능력을 함양하는 방향으로 나아가야 할 것입니다.

마지막으로, 잠정적 신뢰(provisional trust)를 받아들여야 합니다. 마법사 모델은 우리가 기준을 낮추기 때문이 아니라, 완벽한 검증(perfect verification)이 불가능해지고 있기 때문에 "충분히 좋은(good enough)" 결과물과 더 자주 작업하는 것을 의미합니다. 질문은 "이것이 완전히 정확한가?"가 아니라 "이것이 이 목적에 충분히 유용한가?"입니다. 이는 AI 시스템의 위험 수준과 기대되는 이점을 종합적으로 고려하여 신뢰의 정도를 결정하는 복잡한 과정입니다.

우리는 이미 기술적인 마법을 신뢰하는 데 익숙합니다. 경로를 이해하지 않고 GPS를 사용하거나, 알고리즘(algorithm)이 우리가 보는 것을 결정하도록 할 때마다, 우리는 다른 종류의 마법사를 신뢰하고 있는 것입니다. 하지만 결정적인 차이가 있습니다. GPS가 실패하면, 막다른 길에 도달했을 때 빠르게 알게 됩니다. 넷플릭스가 잘못된 영화를 추천하면, 저는 그냥 보지 않습니다. 하지만 AI가 제 연구를 분석하거나 스프레드시트를 변환할 때, AI가 더 능숙해질수록 그것이 틀렸는지 알기가 더 어려워집니다.

AI 마법사와 함께 일하는 역설(paradox)은 역량(competence)과 불투명성(opacity)이 함께 증가한다는 것입니다. 우리는 이러한 도구들을 가장 검증하기 어려운 작업에 가장 필요로 합니다. 이것은 동화(fairy tales)에서 얻는 오래된 교훈입니다. 마법이 더 좋을수록, 미스터리는 더 깊어집니다. 우리는 계속해서 마법사들을 소환하고, 우리가 할 수 있는 것을 확인하며, 마법(spells)이 통하기를 바랄 것입니다. 일주일 분량의 분석을 9분 만에 해낸다면, 우리가 어찌 그러지 않을 수 있겠습니까? AI의 윤리적 사용, 책임감 있는 개발, 그리고 투명성 확보를 위한 노력은 이 '마법의 시대'를 안전하고 유익하게 만들기 위한 필수적인 과제가 될 것입니다.

마법사의 시대에 오신 것을 환영합니다.

구독 공유