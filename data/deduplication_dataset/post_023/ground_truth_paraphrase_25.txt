제 저서 『협력 지능(Co-Intelligence)』에서는 인간이 인공지능과 함께 일하는 방식을 '협력 지능'이라는 개념으로 제시했습니다. 당시에는 챗봇 같은 AI를 인턴이나 동료처럼 활용하여 실수를 고치고, 업무를 검토하며, 아이디어를 발전시키고, 적절한 방향으로 유도하는 것이 가능했습니다. 그러나 최근 몇 주간 AI의 본질이 변화하고 있음을 감지했습니다. 이제 AI는 단순한 조력자를 넘어, 우리가 그 작동 방식을 완전히 이해하기 어려운 '마법'과 같은 결과물을 내놓는 존재가 되어가고 있습니다. 이는 인간의 역할과 의사결정 과정에 근본적인 영향을 미치는 패러다임 전환을 의미하며, AI가 제공하는 '마법'의 편리함 뒤에 숨겨진 복잡성과 불투명성에 대한 새로운 이해를 요구합니다.

이러한 흐름을 명확히 보여주기 위해, 저는 AI에게 제 저서 출간 이후 인공지능 분야에서 발생한 변화를 설명해 달라고 요청했습니다. 저는 제 책과 약 140여 개의 '하나의 유용한 것(One Useful Thing)' 게시물을 NotebookLM 시스템에 제공한 뒤, AI 기술의 최신 동향에 대한 영상 개요를 제작해 달라는 간단한 지시를 내렸습니다. 불과 몇 분 만에 생성된 결과물은 상당히 만족스러웠고, 제 책이 발간된 이후의 상황을 파악하는 데 충분히 유용하다고 판단했습니다. 이 실험은 AI가 단순히 텍스트를 요약하는 것을 넘어, 방대한 양의 비정형 데이터를 이해하고 이를 시각적 콘텐츠로 재구성하는 능력에 도달했음을 시사하며, 이는 개인이 복잡한 정보를 대중에게 전달하는 방식에 새로운 가능성을 열어주고 있습니다.

AI가 핵심 내용을 어떻게 선별하고, 어떤 슬라이드를 선택했는지 그 과정은 여전히 불투명했지만, 결과물의 품질은 매우 우수했으며, 사용된 시각 자료 또한 적절했습니다(비록 약속했던 수달 이미지는 없었지만). 저는 결과물의 정확성을 검증하기 위해 영상을 여러 차례 면밀히 검토했습니다. MMLU 점수(MMLU scores)와 신경외과 시험 데이터(neurosurgery exam data)와 관련된 AI 성능 수치를 포함하여 모든 정보가 정확하다는 것을 확인했습니다. 다만, AI가 제가 "들쭉날쭉한 경계(jagged frontier)"라는 개념을 제시한 보스턴 컨설팅 그룹(Boston Consulting Group) 연구의 공동 저자임을 언급하지 않은 점이 아쉬웠고, AI의 서술 방식이 다소 과장된 측면도 있었습니다. 이러한 경험은 AI가 생성한 콘텐츠의 '블랙박스' 문제와 인간의 검증 필요성을 동시에 보여줍니다. AI는 놀라운 결과물을 내놓지만, 그 내면의 의사결정 로직은 여전히 베일에 싸여 있습니다.

이와 같은 경험은 최근 부상하는 AI의 특징을 잘 보여준다고 생각합니다. 우리는 복잡한 과제에 대해 모호한 지시를 내리더라도, AI로부터 경이롭고 정교한 산출물을 받을 수 있게 되었습니다. 하지만 이러한 결과물이 어떻게 도출되었는지 그 과정에는 전혀 개입할 수 없습니다. 이제 우리는 작업 과정을 함께 만들어가는 협력자에서, AI가 내놓은 결과물을 수동적으로 받아들이는 존재로 역할이 바뀌고 있습니다. 이는 '협력 지능'의 시대에서 '마법사와 함께 일하는' 시대로의 전환을 의미합니다. 특히 학술 연구 분야에서 이러한 인상적인 결과물과 불투명한 과정의 패턴은 더욱 뚜렷하게 나타납니다. 이러한 현상은 'AI의 블랙박스' 문제로 알려져 있으며, 기술적 투명성(technical transparency)의 중요성을 다시금 일깨웁니다. AI 시스템이 복잡해질수록 내부 작동 방식에 대한 이해는 더욱 어려워지고, 이는 잠재적으로 편향(bias)이나 오류(error)가 발생했을 때 이를 식별하고 수정하기 어렵게 만듭니다. 따라서 AI 개발자와 사용자 모두가 결과물의 신뢰성을 보장하기 위한 '설명 가능한 AI (Explainable AI, XAI)' 기술의 발전이 더욱 중요해질 것입니다.

**마법을 요청하다**

현재 유료 구독자에게만 제공되는 GPT-5 Pro만큼 '마법사' 같은 인공지능 모델은 찾아보기 어렵습니다. GPT-5 Pro는 솔직히 경이로운 성과를 보여줄 수 있습니다. 예를 들어, 저는 GPT-5 Pro에게 한 학술 논문(academic paper)을 분석하여 "이 논문의 연구 방법론을 비판적으로 검토하고, 개선된 방법론을 찾아 적용하라"는 지시를 내렸습니다. 이 논문은 단순한 작업물이 아니었습니다. 이는 학자로서 저의 첫 번째 주요 연구를 대표하는 취업 시장용 논문(job market paper)으로, 1년 이상 공들여 작성되었고, 해당 분야의 저명한 전문가들에게 철저히 검토된 후 동료 심사(peer reviewed)를 거쳐 주요 학술지에 실렸던 것입니다. 이처럼 AI가 단순한 정보 처리 수준을 넘어, 고도로 전문화된 지식 영역에서 비판적 사고와 문제 해결 능력을 보여준다는 점은 학계와 산업계 모두에 큰 파장을 일으키고 있습니다.

9분 40초 만에 저는 매우 면밀하고 심층적인 비평을 받았습니다. 이는 단순한 문구 수정 수준의 비판이 아니었습니다. GPT-5 Pro는 몬테카를로 분석(Monte Carlo analysis)을 수행하고 통계 모델(statistical models)의 고정 효과(fixed effects)를 새롭게 해석하는 등, 코드를 활용하여 제 논문의 결과를 검증하기 위한 독자적인 실험을 실행한 것으로 보였습니다. 이 과정에서 여러 가지 제안이 나왔고(다행히도 "제 논문의 핵심 주장(headline claim)은 타당하다"는 결론을 내렸지만), 특히 한 가지 점이 매우 인상 깊었습니다. AI는 이전에 아무도 찾아내지 못했던 미세한 오류 하나를 발견했습니다. 이 오류는 논문에서 명시적으로 연결되지 않았던 두 개의 표에 있는 서로 다른 숫자 세트와 관련되어 있었습니다. 이 사례는 AI가 단순한 패턴 인식이나 정보 검색을 넘어, 복잡한 데이터 간의 숨겨진 관계를 파악하고 논리적 일관성을 검증하는 능력을 보여줍니다.

또다시 저는 '마법사 딜레마'에 봉착했습니다. AI의 결과가 과연 정확한가? 저는 확인 과정을 거쳐 그 내용이 옳다는 것을 알 수 있었습니다. 하지만 AI가 이 오류를 어떻게 찾아냈는지, 그리고 AI가 수행했다고 주장하는 다른 작업들이 실제로 설명된 대로 진행되었는지는 여전히 파악하기 어렵습니다. 그럼에도 불구하고 GPT-5 Pro의 분석 능력에 깊은 감명을 받았기에, 이제 크고 작은 다양한 질문들을 이 모델에 맡기고 있습니다. 예를 들어, '가트너 하이프 사이클(Gartner hype cycle)은 실제로 존재하는 개념인가?', '인구 조사 데이터(census data)는 대기업의 AI 활용이 줄어들었음을 보여주는가?'와 같은 질문에 대해 GPT-5 Pro는 정확한 답변을 제공한다고 믿게 되었습니다. 아직까지 중대한 오류를 발견하지는 못했지만, 그렇다고 해서 오류가 전혀 없다는 뜻은 아닐 것입니다. 물론, AI가 어떤 종류의 좋은 답변도 제공하지 못할 많은 다른 작업들도 있습니다. 마법사에게 누가 알겠습니까? 이러한 '마법사 딜레마'는 AI에 대한 신뢰와 투명성 사이의 본질적인 긴장 관계를 보여주며, AI의 결과물에 대한 맹목적인 신뢰를 경계하고 항상 비판적인 검증 과정을 거쳐야 함을 강조합니다.

이 기술이 더 넓은 범위의 업무에 어떻게 활용될 수 있는지 이해하려면, 최근 파일 처리 능력을 갖춘 또 다른 선진 AI 모델인 Claude 4.1 Opus를 살펴보는 것이 좋습니다. 이 AI는 특히 엑셀(Excel) 스프레드시트 작업에 강점을 보이므로, 저는 제가 잘 아는 엑셀 파일로 어려운 과제를 부여했습니다. 제가 기업가 정신 수업(entrepreneurship classes)에서 활용했던 실습 과제 중 하나는, 불확실한 상황에서도 사업 계획을 수립하는 방법을 가르치기 위해 소규모 책상 제조 사업의 재무 모델(financial model)을 분석하는 것이었습니다. 저는 Claude에게 여러 탭으로 구성된 이 오래된 엑셀 파일(multi-tab Excel file)을 제공하고, 원래 연습의 학습 목표는 유지하면서 새로운 사업 아이템인 치즈 가게에 맞게 파일을 수정해 달라고 지시했습니다. Claude와 같은 고급 AI의 파일 처리 능력은 기존의 복잡한 문서 구조를 이해하고, 새로운 맥락에 맞춰 데이터를 재구성하는 고차원적인 문서 지능(document intelligence)을 의미합니다.

단 한 번의 지시만으로 Claude는 수업 계획과 복잡한 수식(formulas)이 담긴 기존 스프레드시트(spreadsheets) 내용을 파악하고, 치즈 가게라는 새로운 사업 환경에 맞춰 모든 정보를 갱신하여 완전히 새로운 스프레드시트를 생성했습니다. 불과 몇 분 뒤, 저는 단 하나의 프롬프트(prompt) 입력만으로 핵심 학습 목표를 그대로 유지하면서도 새로운 데이터를 포함한 변형된 스프레드시트 파일을 제 컴퓨터로 내려받을 수 있었습니다. 이 결과는 AI가 단순한 '번역기'가 아니라, 복잡한 비즈니스 로직과 교육적 목표까지 이해하여 작업을 수행하는 '지능형 에이전트'임을 명확히 보여줍니다. 이는 교육 분야에서 개인 맞춤형 학습 자료 제작이나 비즈니스 분야에서 시장 변화에 따른 신속한 사업 모델 조정에 큰 도움이 될 것입니다.

왼쪽은 원본 문서, 오른쪽은 Claude가 제공한 문서

다시금, AI는 그 마법의 원리를 제게 공개하지 않았기에, 저는 생성된 결과물을 면밀히 검토해야 했습니다. 제가 확인한 바에 따르면, 새로운 사업 맥락에서도 원래의 학습 목표가 잘 보존되어 있었고, 전반적으로 매우 뛰어난 결과물이었습니다. 다만, 수식이나 비즈니스 모델링(business modelling) 과정에서 제가 다르게 설정했을 몇몇 부분(예를 들어, 연간 영업일 수를 더 적게 책정했을 것)을 발견했지만, 이는 실제적인 오류라기보다는 관점의 차이에 가깝다고 판단했습니다. 이러한 검토 과정은 AI가 생성한 결과물에 대한 인간의 '최종 판단' 역할이 얼마나 중요한지를 보여줍니다. AI는 데이터를 기반으로 최적의 논리를 구성하지만, 인간은 경험, 직관, 그리고 맥락적 이해를 바탕으로 '더 나은' 또는 '더 적절한' 대안을 제시할 수 있습니다.

Claude의 능력이 어디까지 미치는지 궁금했고, 많은 사람이 AI가 파워포인트(PowerPoint) 제작이 가능한지 묻는다는 점을 고려하여, 저는 추가적으로 "이제 이 사업을 위한 훌륭한 파워포인트 자료를 만들어줘"라고 지시를 내렸고, 그 결과물을 얻었습니다. 생성된 자료는 피치 덱(pitch deck)의 꽤 탄탄한 초안이었고, 중대한 오류는 없었지만, 즉시 활용할 수 있는 완성도는 아니었습니다. 이는 AI의 '들쭉날쭉한 경계' 특성을 명확히 보여줍니다. AI는 예측하기 어려운 방식으로 어떤 작업에는 탁월한 능력을 발휘하는 반면, 다른 작업에서는 미숙함을 드러냅니다. 이 글의 주요 목적은 AI의 능력 범위 그 자체보다는, AI와의 관계가 어떻게 변화하고 있는지에 초점을 맞추는 것입니다. AI의 '들쭉날쭉한 경계'는 사용자가 AI를 활용할 때 기대치를 현실적으로 설정하고, AI의 강점과 약점을 정확히 파악해야 함을 시사합니다.

**마법사의 문제점**

최근 등장한 이러한 AI 시스템들은 본질적으로 '에이전트(agents)'의 특성을 지닙니다. 이는 특정 목표를 달성하기 위해 스스로 계획을 수립하고 자율적으로(autonomously) 행동할 수 있는 인공지능을 의미합니다. 제가 Claude에게 스프레드시트 수정을 요청했을 때, Claude는 원본 파일 분석부터 새로운 스프레드시트 코딩(coding)에 이르기까지 일련의 단계를 직접 계획하고 실행했습니다. 더 나아가, 예상치 못한 문제 상황에 유연하게 대처하여, 제가 별도로 지시하지 않았음에도 불구하고 스프레드시트를 두 차례 수정하고 자신의 답변을 여러 번 검증하는 모습을 보였습니다. AI 에이전트의 이러한 자율성은 인간의 개입 없이도 복잡한 문제를 해결할 수 있는 잠재력을 제공하지만, 동시에 AI의 행동에 대한 예측 불가능성과 통제 불능성이라는 윤리적, 기술적 과제를 동반하기도 합니다.

저는 AI가 거치는 이러한 작업 단계를 직접 선택하거나 조정할 수 없었습니다. 사실, 강화 학습(reinforcement learning) 기반의 새로운 에이전트 모델들은 문제 해결을 위한 자신만의 방식을 학습하기 때문에, 그 누구도 세부 단계를 지정하지 않습니다.

Claude가 스프레드시트를 변경하기 위해 거쳤다고 보고한 단계들

저는 AI의 작업 과정에 개입할 수 없을 뿐만 아니라, 실제로 AI 시스템이 어떤 방식으로 작동했는지 완벽하게 확신할 수도 없습니다. Claude가 제시한 단계는 그저 작업의 간략한 요약에 불과하며, GPT-5 Pro는 이보다 더 적은 정보를 제공하고, NotebookLM은 영상 제작 과정에 대한 어떠한 통찰도 거의 주지 않습니다. 설령 AI의 모든 단계를 볼 수 있었다 하더라도, AI가 수행한 작업을 온전히 이해하려면 코딩 기술부터 기업가 정신에 이르는 광범위한 분야에서 전문 지식을 갖추고 있어야 했을 것입니다. AI의 이러한 '블랙박스' 특성은 기술적 신뢰성(technical trustworthiness)과 책임성(accountability)의 문제를 야기합니다.

물론, 정확성(accuracy) 문제도 간과할 수 없습니다. 모든 사실을 일일이 확인하지 않고서 AI가 생성한 결과물이 정확하다고 어떻게 확신할 수 있을까요? 설령 내용이 사실이라 할지라도, 제가 정보를 제시하거나 구성하는 방식은 AI와 다를 수 있습니다. 그러나 저는 이에 대해 어떠한 개입도 할 수 없습니다. 왜냐하면 '마법사'와 같은 AI는 인간의 도움을 필요로 하지 않으며, 심지어 자신들조차 완전히 설명하기 어려운 비밀스러운 방식으로 작동하기 때문입니다. AI의 '판단'은 데이터에 기반한 통계적 추론의 결과물이지만, 인간의 판단은 윤리적 가치, 사회적 맥락, 개인적 경험 등 훨씬 더 복합적인 요소들을 고려합니다.

이 상황의 가장 어려운 부분은 AI가 내놓는 결과물이 실제로 매우 훌륭하다는 점입니다. 저는 이 글에서 AI에게 맡긴 세 가지 과제 각각에 대한 전문가로서, 미미한 서식 오류(formatting errors)나 제가 다르게 선택했을 몇몇 부분은 있었지만, 본질적인 사실 오류(factual errors)는 발견하지 못했습니다. 물론, 모든 세부 내용을 철저히 검토하지 않고서는 문서가 완벽하게 오류가 없다고 단정할 수는 없습니다. AI 결과물의 검증은 때로는 직접 작업을 수행하는 것보다 훨씬 적은 시간을 요구하기도 하지만, 때로는 훨씬 더 많은 시간을 소모하기도 합니다. 심지어 AI의 작업 방식이 너무나 정교하여, 인간의 능력으로는 검증을 시도하는 것조차 불가능할 때도 있습니다. AI의 뛰어난 결과물은 인간에게 '확인 편향(confirmation bias)'을 유발할 수 있으며, 이는 AI의 전문성이 인간의 전문성을 뛰어넘는 영역에서 더욱 심화될 수 있습니다.

이는 우리가 충분히 논의하지 않는 또 다른 위험을 내포하고 있습니다. 우리가 '마법사'와 같은 AI에게 업무를 위임할 때마다, 우리는 스스로 전문성(expertise)을 함양하고 AI의 결과물을 평가하는 데 필요한 판단력(judgment)을 키울 기회를 상실하게 됩니다. 하지만 적어도 제가 경험한 사례들에서는 AI의 결과물이 매우 뛰어나다는 피할 수 없는 사실에 다시 직면합니다. 마치 대학원생(graduate student)이 몇 시간(혹은 그 이상)을 투자하여 얻을 수 있는 수준의 논문 재분석 결과를, 저는 단 몇 분 만에 받아볼 수 있었던 것입니다. 이러한 '전문성 상실'의 위험은 장기적으로 인간의 역량 발전과 사회 전체의 지식 생태계에 부정적인 영향을 미칠 수 있습니다.

이것이 바로 '마법사의 문제'입니다. 우리는 경이로운 결과물을 얻고 있지만, 정작 우리는 마법사나 그 조수가 아닌 단순한 관객의 위치에 머무르고 있습니다. 과거의 협력 지능 모델에서는 우리가 AI를 안내하고, 오류를 수정하며, 적극적으로 협력했습니다. 그러나 이제는 점차 프롬프트를 입력하고, 기다린 다음, 가능하다면 결과물을 검증하는 역할로 전환되고 있습니다. 이러한 변화는 AI가 인간의 인지적 부담을 줄여주는 동시에, 인간의 능동적인 참여 기회를 제한한다는 양면성을 가집니다. AI의 '마법'에 의존하는 경향이 심화될수록, 우리는 문제 해결 과정에서 주도권을 잃고 수동적인 소비자로 전락할 위험이 있습니다.

**그렇다면 마법사들을 어떻게 해야 할까요?**

저는 우리가 새로운 형태의 '문해력(literacy)'을 길러야 한다고 생각합니다.

첫째, 우리는 언제 AI를 '마법사'처럼 활용해야 하는지, 언제 '협력 지능' 방식으로 AI와 함께 작업해야 하는지, 또는 아예 AI를 사용하지 않아야 할 때를 명확히 구분하는 법을 배워야 합니다. AI는 아직 완벽하지 않으며, 여전히 AI가 부족한 영역에서는 인간의 능력이 더 뛰어난 경우가 많습니다. 그러나 AI가 유용하게 활용될 수 있는 작업의 범위가 넓어짐에 따라, 인간과 AI의 상호작용을 통한 '협력 지능' 방식이 기계 단독 수행보다 우수한 결과를 낳는 경우가 많습니다. 하지만 때로는 AI를 '마법사'처럼 소환하고, 그 결과물을 단순히 신뢰하는 것이 가장 효과적인 상황도 점차 늘어나고 있습니다. 이 새로운 문해력은 단순한 기술 습득을 넘어, AI의 본질과 한계를 이해하는 '메타 인지(meta-cognition)' 능력을 요구합니다.

둘째, 우리는 AI의 내부 과정보다는 '결과물 감식가(connoisseurs of output)'가 되어야 합니다. AI가 생성한 결과물 중에서 가치 있는 것을 선별하고 선택하는 능력이 필요하며, 더 나아가 AI와 충분히 상호작용함으로써 AI가 언제 성공적이고 언제 실패하는지에 대한 직관(instincts)적인 이해를 발전시켜야 합니다. 우리는 어떤 내용이 올바른지, 어떤 내용이 잘못되었는지, 그리고 불확실한 위험을 감수할 만한 가치가 있는지를 판단하는 기술을 습득해야 합니다. '결과물 감식가'로서의 역할은 AI가 생성하는 정보의 홍수 속에서 '정보 선별 능력'을 핵심 역량으로 만듭니다.

이러한 상황은 교육 분야에 중대한 난제를 안겨줍니다. AI가 특정 분야의 숙련도 발전을 저해할 수 있는 상황에서, 아직 완전히 숙달되지 않은 영역의 AI 결과물을 검증하도록 사람들을 어떻게 교육할 수 있을까요? 이와 같은 지식 및 기술 격차를 해소할 방안을 모색하는 것이 점점 더 시급한 과제가 되고 있습니다. 교육 시스템은 이제 '무엇을 가르칠 것인가'라는 질문뿐만 아니라 '어떻게 가르칠 것인가'라는 질문에도 새로운 답을 찾아야 합니다. AI와 협력하여 문제를 해결하는 능력, AI의 한계를 이해하고 비판적으로 사고하는 능력을 키우는 교육이 중요해질 것입니다.

마지막으로, 우리는 '잠정적 신뢰(provisional trust)'라는 개념을 수용해야 합니다. '마법사' 모델은 우리가 기대 기준을 낮추기 때문이 아니라, 완벽한 검증(perfect verification)이 점차 불가능해지는 현실 때문에 '충분히 좋은(good enough)' 결과물과 더욱 자주 협력해야 함을 의미합니다. 이제 핵심 질문은 "이것이 완벽하게 정확한가?"가 아니라, "이것이 주어진 목적을 달성하는 데 충분히 유용한가?"로 바뀌어야 합니다. '잠정적 신뢰'는 AI의 불확실성을 인정하면서도 그 잠재적 가치를 활용하려는 실용적인 접근 방식입니다. 이는 모든 상황에서 100%의 정확성을 추구하기보다는, 특정 작업의 요구사항과 위험 수준을 고려하여 합리적인 수준의 신뢰를 부여하는 것을 의미합니다.

우리는 이미 다양한 기술적 '마법'을 신뢰하는 데 익숙합니다. GPS의 작동 원리를 완전히 이해하지 못한 채 길 안내를 따르거나, 특정 알고리즘(algorithm)이 우리가 접하는 정보를 선별하도록 맡길 때마다, 우리는 이미 다른 형태의 '마법사'를 신뢰하고 있는 셈입니다. 그러나 여기에는 결정적인 차이점이 존재합니다. GPS가 오류를 일으키면 막다른 길에 다다랐을 때처럼 그 실패를 비교적 빨리 인지할 수 있습니다. 넷플릭스가 부적절한 영화를 추천한다면, 단순히 시청하지 않으면 그만입니다. 하지만 AI가 제 연구를 분석하거나 복잡한 스프레드시트를 변환할 때, AI의 능력이 정교해질수록 그 결과에 오류가 있는지 여부를 파악하기가 더욱 어려워집니다. 이 결정적인 차이는 AI의 '인지적 개입' 수준에 있습니다.

AI '마법사'와 협력하는 것의 역설(paradox)은 AI의 역량(competence)이 향상될수록 그 내부 작동 방식의 불투명성(opacity) 또한 심화된다는 점입니다. 아이러니하게도, 우리는 가장 검증하기 어려운 복잡한 작업일수록 이러한 AI 도구들의 도움을 절실히 필요로 합니다. 이는 마치 동화(fairy tales) 속 교훈처럼, 마법이 강력해질수록 그 신비로움은 더욱 깊어지는 것과 같습니다. 우리는 계속해서 AI 마법사들을 호출하고, 가능한 범위 내에서 결과물을 확인하며, 그들의 '마법(spells)'이 제대로 발휘되기를 기대할 수밖에 없을 것입니다. 만약 AI가 일주일 걸릴 분석 작업을 단 9분 만에 해낼 수 있다면, 우리가 어찌 그 유혹을 뿌리칠 수 있겠습니까? 이러한 역설은 인간과 AI의 관계가 단순한 도구 사용을 넘어, '신뢰'와 '의존'이라는 복합적인 차원으로 진화하고 있음을 보여줍니다.

마법사의 시대에 오신 것을 환영합니다.

구독 공유