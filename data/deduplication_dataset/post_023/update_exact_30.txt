최근 몇 년간 인공지능(AI)의 발전 속도는 경이로울 정도입니다. 초거대 언어 모델(LLM)의 등장과 에이전트(agent) 기반 AI의 확산은 우리가 AI와 상호작용하는 방식에 근본적인 변화를 가져왔습니다. 불과 몇 년 전만 해도 AI는 우리의 도구이자 협력자로서 인간의 지능을 보완하는 역할을 했습니다. 하지만 이제 AI는 단순한 조력자를 넘어, 스스로 문제를 정의하고 해결책을 찾아 실행하는 '마법사'와 같은 존재로 진화하고 있습니다.

제 책 『협력 지능(Co-Intelligence)』에서 저는 사람들이 AI와 협력할 수 있는 방법을 설명했는데, 놀랄 것도 없이 이는 '협력 지능'으로서의 방식이었습니다. 챗봇과 팀을 이루어 인간은 AI를 일종의 인턴이나 동료처럼 사용하여 오류를 수정하고, 작업을 확인하며, 아이디어를 공동 개발하고, 올바른 방향으로 안내할 수 있었습니다. 지난 몇 주 동안 저는 협력 지능이 여전히 중요하지만, AI의 본질이 다른 방향으로 나아가기 시작했다는 것을 깨달았습니다. 우리는 파트너에서 관객으로, 협력에서 마법을 부리는 것으로 이동하고 있습니다.

이러한 변화의 핵심은 AI의 자율성과 복합적인 추론 능력에 있습니다. 이제 AI는 단일 프롬프트(prompt)에 대한 단순한 응답을 넘어, 여러 단계의 작업을 스스로 계획하고 실행하며, 예상치 못한 상황에 유연하게 대처할 수 있게 되었습니다. 예를 들어, 저는 최근 한 최신 AI 모델에게 "새로운 기술 스타트업을 위한 상세한 사업 계획서를 작성하고, 잠재 투자자에게 발표할 피치 덱(pitch deck) 초안을 만들어 달라"는 요청을 했습니다. AI는 시장 조사, 경쟁 분석, 재무 예측, 마케팅 전략 수립 등 복잡한 과정을 거쳐 각 섹션별로 방대한 텍스트를 생성했고, 이를 바탕으로 시각적으로 매력적인 피치 덱의 구성 요소를 제안했습니다.

결과물은 놀라웠습니다. 몇 시간 동안 수많은 자료를 찾아보고 정리해야 할 작업이 단 몇 분 만에 이루어졌습니다. 물론, 세부적인 사실 확인과 저의 비전과의 일치 여부를 검토하는 과정은 여전히 저의 몫이었습니다. 하지만 AI가 이 모든 작업을 어떤 순서로 진행했고, 어떤 정보원을 활용했으며, 어떤 판단 기준을 적용했는지에 대해서는 거의 알 수 없었습니다. 마치 제가 복잡한 주문을 외웠을 뿐, 마법사가 어떤 비법으로 그 결과물을 만들어냈는지는 알 수 없는 것과 같았습니다.

저는 이러한 과정이 새로운 AI 물결의 전형이라고 생각합니다. 점점 더 복잡해지는 다양한 작업에 대해 모호한 요청에 대한 응답으로 놀랍고 정교한 결과물을 얻지만, 그 과정에는 전혀 관여하지 못합니다. AI가 어떤 선택을 했는지 알 수 없으며, 모든 것이 완전히 정확한지 확인할 수도 없습니다. 우리는 과정을 형성하는 협력자에서 결과물을 받는 간청자로 변화하고 있습니다. 이는 협력 지능과 함께 일하는 것에서 마법사와 함께 일하는 것으로의 전환입니다. 마법은 이루어지지만, 우리는 그 결과물을 어떻게 해야 할지 항상 알지는 못합니다. 이러한 패턴, 즉 인상적인 결과물과 불투명한 과정은 연구 작업에서 더욱 두드러집니다.

**마법을 요청하다**

현재로서는 GPT-4o나 Gemini Ultra와 같은 최신 AI 모델들이 이러한 마법사적 능력을 가장 잘 보여줍니다. 이 모델들은 단순히 텍스트를 생성하는 것을 넘어, 멀티모달(multimodal) 능력을 바탕으로 다양한 형태의 데이터를 이해하고 처리하며, 추론 능력까지 갖추고 있습니다. 예를 들어, 저는 최근 한 생명공학 연구소에서 진행하는 복잡한 단백질 구조 분석 프로젝트에 대해 AI에게 "기존 연구의 한계를 지적하고, 새로운 실험 설계 방안을 제안하라"는 지시를 내렸습니다. 이는 단순한 정보 검색이나 요약이 아닌, 깊이 있는 과학적 이해와 비판적 사고를 요구하는 작업이었습니다.

9분 40초 후, 저는 매우 상세한 비판을 받았습니다. 이것은 단순한 편집상의 비판이 아니었습니다. GPT-5 Pro는 몬테카를로 분석(Monte Carlo analysis)을 수행하고 통계 모델(statistical models)의 고정 효과(fixed effects)를 재해석하는 등 코드를 사용하여 제 결과를 검증하기 위한 자체 실험을 실행한 것으로 보였습니다. 그 결과 많은 제안을 내놓았지만(다행히 "제 논문의 핵심 주장(headline claim)은 검토를 통과한다"고 결론 내렸지만), 한 가지가 눈에 띄었습니다. 이전에 발견되지 않았던 작은 오류를 찾아냈습니다. 이 오류는 제가 논문에서 명시적으로 설명하지 않은 방식으로 연결된 두 개의 표에 있는 두 가지 다른 숫자 세트와 관련이 있었습니다. AI는 이 사소한 오류를 찾아냈고, 이전에는 아무도 찾아내지 못했습니다.

이러한 결과는 AI가 단순한 도구가 아닌, 마치 숙련된 연구원처럼 복잡한 문제를 분석하고 해결책을 제시하는 능력을 갖췄음을 보여줍니다. 하지만 동시에 AI가 어떻게 그 결론에 도달했는지에 대한 투명성은 여전히 부족했습니다. 저는 AI가 어떤 가설을 세우고 어떤 데이터를 우선적으로 고려했으며, 어떤 추론 과정을 거쳤는지 정확히 알 수 없었습니다. 그저 최종 결과물만이 저에게 제시될 뿐이었습니다.

또 다른 예로, 저는 최근 한 AI 코딩 에이전트에게 "기존 레거시 시스템(legacy system)의 특정 모듈을 최신 클라우드 기반 아키텍처(cloud-based architecture)로 전환하고, 이 과정에서 발생할 수 있는 잠재적 보안 취약점(security vulnerabilities)을 식별하여 개선 방안을 제시하라"는 매우 복잡한 요청을 했습니다. 이 에이전트는 코드 분석, 새로운 아키텍처 설계, 보안 검토, 그리고 심지어 마이그레이션(migration) 계획 수립까지 여러 단계를 거쳐 결과물을 생성했습니다.

몇 시간 후, AI는 상세한 코드 리팩토링(refactoring) 제안, 새로운 클라우드 서비스 구성 파일, 그리고 잠재적 보안 위협에 대한 보고서를 제출했습니다. 이 모든 과정은 저의 개입 없이 AI 스스로 판단하고 실행한 것이었습니다. 물론, 실제 시스템에 적용하기 전에는 철저한 검토와 테스트가 필요했지만, AI가 보여준 문제 해결 능력과 자율성은 과거의 AI 모델과는 확연히 달랐습니다.

이처럼 AI는 이제 특정 도메인(domain)의 전문 지식과 복합적인 추론 능력을 바탕으로 인간의 개입 없이도 상당한 수준의 작업을 수행할 수 있게 되었습니다. 하지만 이러한 능력의 '들쭉날쭉한 경계(jagged frontier)'는 여전히 존재합니다. AI는 특정 분야에서는 놀라운 성과를 내지만, 다른 분야에서는 여전히 한계를 보입니다. 예를 들어, 복잡한 코드 작성에는 능숙하지만, 인간의 감성을 깊이 이해해야 하는 창의적인 스토리텔링에서는 아직 부족함을 드러낼 수 있습니다. 이 글에서 저의 초점은 AI 능력의 확장 범위보다는 AI와의 변화하는 관계에 있습니다.

**마법사의 문제점**

이러한 새로운 AI 시스템들은 단순한 프로그램이 아니라, 주어진 목표를 향해 자율적으로 계획하고 행동할 수 있는 '에이전트(agents)'입니다. 제가 AI 코딩 에이전트에게 시스템 전환을 요청했을 때, AI는 원본 코드를 분석하고, 클라우드 아키텍처를 설계하며, 보안 취약점을 식별하는 등 여러 단계를 스스로 계획하고 실행했습니다. 심지어 예상치 못한 코드 의존성 문제를 발견했을 때는 스스로 해결책을 찾아 적용하기도 했습니다.

문제는 우리가 이러한 단계에 개입할 수 없다는 것입니다. 사실, 강화 학습(reinforcement learning)과 심층 신경망(deep neural networks)으로 구동되는 새로운 에이전트 물결에서는 AI 스스로가 문제 해결을 위한 최적의 접근 방식을 학습합니다. 그 과정은 우리에게는 '블랙박스(black box)'와 같습니다.

우리는 개입할 수 없을 뿐만 아니라, AI 시스템이 실제로 무엇을 했는지 완전히 확신할 수도 없습니다. AI가 보고한 단계는 작업의 단순한 요약일 뿐이며, GPT-4o나 Gemini Ultra와 같은 모델들은 훨씬 적은 정보를 제공합니다. 하지만 제가 단계를 볼 수 있었다고 해도, AI가 무엇을 하고 있는지 진정으로 이해하려면 컴퓨터 공학, 사이버 보안, 클라우드 아키텍처 등 여러 분야의 전문가여야 했을 것입니다.

그리고 물론, 정확성(accuracy) 문제가 있습니다. 모든 사실을 확인하지 않고 AI가 정확한지 어떻게 알 수 있을까요? 그리고 사실이 옳다고 해도, 제가 그것들을 제시하거나 구성하는 방식에 대해 다른 판단을 내렸을 수도 있습니다. 하지만 저는 아무것도 할 수 없습니다. 왜냐하면 마법사들은 저의 도움을 원하지 않고, 심지어 그들 자신도 설명할 수 없는 비밀스러운 방식으로 일하기 때문입니다.

이것이 마법사의 문제입니다. 우리는 마법 같은 것을 얻고 있지만, 마법사나 심지어 마법사의 조수가 아닌 관객이 되고 있습니다. 협력 지능 모델에서는 우리가 안내하고, 수정하고, 협력했습니다. 점점 더 우리는 프롬프트를 입력하고, 기다리고, 그리고 가능하다면 검증합니다.

**그렇다면 마법사들을 어떻게 해야 할까요?**

이러한 변화에 발맞춰 우리는 새로운 'AI 리터러시 2.0'을 개발해야 합니다. 이는 AI를 단순히 사용하는 방법을 넘어, AI의 본질과 한계, 그리고 사회적 함의를 이해하는 데 초점을 맞춥니다.

첫째, 언제 마법사를 소환해야 하는지, 언제 AI와 협력 지능으로 일해야 하는지, 또는 AI를 전혀 사용하지 말아야 하는지를 배워야 합니다. AI는 완벽과는 거리가 멀고, 여전히 부족한 분야에서는 인간이 종종 성공합니다. 하지만 AI가 유용한 작업의 수가 증가함에 따라, 협력 지능과 그것이 요구하는 상호작용은 종종 기계 단독보다 우수합니다. 그러나 점점 더 마법사를 소환하는 것이 최선이고, 그것이 만들어내는 것을 그냥 믿는 것이 가장 좋은 때가 있습니다.

둘째, 우리는 과정보다는 결과물 감식가(connoisseurs of output)가 되어야 합니다. AI가 제공하는 결과물 중에서 선별하고 선택해야 하지만, 그 이상으로 AI와 충분히 작업하여 AI가 언제 성공하고 언제 실패하는지에 대한 직관(instincts)을 개발해야 합니다. 우리는 무엇이 옳고, 무엇이 틀렸으며, 무엇이 알지 못하는 위험을 감수할 가치가 있는지 판단하는 법을 배워야 합니다. 이는 AI의 '레드 팀(red teaming)' 개념과 유사하게, AI의 취약점을 선제적으로 파악하고 오류를 찾아내는 능력을 키우는 것을 포함합니다.

이것은 교육에 어려운 문제를 야기합니다. AI 자체가 숙련도를 개발하는 것을 방해할 때, 숙달하지 못한 분야에서 작업을 검증하도록 누군가를 어떻게 훈련시킬 수 있을까요? 이 격차를 해결하는 방법을 찾는 것이 점점 더 시급해지고 있습니다. 미래 교육은 AI와의 상호작용을 통해 비판적 사고와 문제 해결 능력을 함양하는 방향으로 나아가야 할 것입니다.

마지막으로, 잠정적 신뢰(provisional trust)를 받아들여야 합니다. 마법사 모델은 우리가 기준을 낮추기 때문이 아니라, 완벽한 검증(perfect verification)이 불가능해지고 있기 때문에 "충분히 좋은(good enough)" 결과물과 더 자주 작업하는 것을 의미합니다. 질문은 "이것이 완전히 정확한가?"가 아니라 "이것이 이 목적에 충분히 유용한가?"입니다. 이는 AI 시스템의 위험 수준과 기대되는 이점을 종합적으로 고려하여 신뢰의 정도를 결정하는 복잡한 과정입니다.

우리는 이미 기술적인 마법을 신뢰하는 데 익숙합니다. 경로를 이해하지 않고 GPS를 사용하거나, 알고리즘(algorithm)이 우리가 보는 것을 결정하도록 할 때마다, 우리는 다른 종류의 마법사를 신뢰하고 있는 것입니다. 하지만 결정적인 차이가 있습니다. GPS가 실패하면, 막다른 길에 도달했을 때 빠르게 알게 됩니다. 넷플릭스가 잘못된 영화를 추천하면, 저는 그냥 보지 않습니다. 하지만 AI가 제 연구를 분석하거나 스프레드시트를 변환할 때, AI가 더 능숙해질수록 그것이 틀렸는지 알기가 더 어려워집니다.

AI 마법사와 함께 일하는 역설(paradox)은 역량(competence)과 불투명성(opacity)이 함께 증가한다는 것입니다. 우리는 이러한 도구들을 가장 검증하기 어려운 작업에 가장 필요로 합니다. 이것은 동화(fairy tales)에서 얻는 오래된 교훈입니다. 마법이 더 좋을수록, 미스터리는 더 깊어집니다. 우리는 계속해서 마법사들을 소환하고, 우리가 할 수 있는 것을 확인하며, 마법(spells)이 통하기를 바랄 것입니다. 일주일 분량의 분석을 9분 만에 해낸다면, 우리가 어찌 그러지 않을 수 있겠습니까? AI의 윤리적 사용, 책임감 있는 개발, 그리고 투명성 확보를 위한 노력은 이 '마법의 시대'를 안전하고 유익하게 만들기 위한 필수적인 과제가 될 것입니다.

마법사의 시대에 오신 것을 환영합니다.

구독 공유