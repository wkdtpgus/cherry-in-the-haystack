제 책 『협력 지능(Co-Intelligence)』에서 저는 사람들이 AI와 협력할 수 있는 방법을 설명했는데, 놀랄 것도 없이 이는 '협력 지능'으로서의 방식이었습니다. 챗봇과 팀을 이루어 인간은 AI를 일종의 인턴이나 동료처럼 사용하여 오류를 수정하고, 작업을 확인하며, 아이디어를 공동 개발하고, 올바른 방향으로 안내할 수 있었습니다. 지난 몇 년 동안, 특히 최근 몇 달간 AI 기술의 급속한 발전은 이러한 협력의 본질을 변화시켰습니다. 이제 우리는 단순히 파트너로서 AI와 함께하는 것을 넘어, AI가 만들어내는 결과물을 경이롭게 지켜보는 관객의 역할로 이동하고 있습니다. 협력에서 마법을 부리는 단계로 진화하고 있는 것입니다.

이러한 변화를 설명하는 좋은 방법은 AI에게 제가 책을 쓴 이후 어떤 일이 일어났는지 설명해 달라고 요청하는 것입니다. 저는 제 책과 약 140개의 '하나의 유용한 것(One Useful Thing)' 게시물(참고로, 제가 그렇게 많은 게시물을 썼다는 것이 믿기지 않습니다!)을 NotebookLM에 입력하고, AI 세계에서 어떤 일이 일어났는지에 대한 영상을 만들라는 기본적인 프롬프트와 함께 새로운 비디오 개요 옵션을 선택했습니다. 몇 분 후, 저는 이 결과물을 얻었습니다. 그리고 꽤 괜찮았습니다. 제 책이 쓰인 이후의 상황을 업데이트하기 위해 볼 가치가 있다고 생각할 만큼 충분히 좋았습니다. 이처럼 AI는 방대한 정보를 빠르게 요약하고 시각화하는 능력을 갖추게 되었습니다.

하지만 AI는 어떻게 그 요점들을 선택했을까요? 저는 모릅니다. 하지만 꽤 좋았습니다. 어떤 슬라이드를 사용할지 어떻게 결정했을까요? 저는 모릅니다. 하지만 그것들 또한 꽤 적절했습니다(약속했던 수달을 보여주지 않았다는 점에서 이미지는 여전히 약간의 약점이지만요). 그것이 옳았을까요? 그것은 제가 확인해야 할 것처럼 보였습니다. 그래서 저는 영상을 여러 번 보면서 모든 사실을 확인했습니다. MMLU 점수(MMLU scores) 데이터와 신경외과 시험 데이터(neurosurgery exam data)에 대한 AI 성능 결과를 포함하여 모든 숫자가 정확했습니다(제가 그 자료를 언제 인용했는지조차 확실하지 않습니다). 저의 유일한 실제 문제는 AI가 제가 "들쭉날쭉한 경계(jagged frontier)"라는 용어를 도입한 보스턴 컨설팅 그룹(Boston Consulting Group) 연구의 공동 저자 중 한 명이라는 점을 언급했어야 했다는 것입니다. 물론, AI의 정보 출처와 추론 과정이 투명하게 공개되지 않는다는 점은 여전히 해결해야 할 과제로 남아있습니다.

저는 이러한 과정이 새로운 AI 물결의 전형이라고 생각합니다. 점점 더 복잡해지는 다양한 작업에 대해 모호한 요청에 대한 응답으로 놀랍고 정교한 결과물을 얻지만, 그 과정에는 전혀 관여하지 못합니다. AI가 어떤 선택을 했는지 알 수 없으며, 모든 것이 완전히 정확한지 확인할 수도 없습니다. 우리는 과정을 형성하는 협력자에서 결과물을 받는 간청자로 변화하고 있습니다. 이는 협력 지능과 함께 일하는 것에서 마법사와 함께 일하는 것으로의 전환입니다. 마법은 이루어지지만, 우리는 그 결과물을 어떻게 해야 할지 항상 알지는 못합니다. 이러한 패턴, 즉 인상적인 결과물과 불투명한 과정은 연구 작업에서 더욱 두드러집니다. 특히 멀티모달(multi-modal) AI의 발전으로 이러한 현상은 더욱 심화되고 있습니다.

**마법을 요청하다**

현재 가장 발전된 AI 모델들은 솔직히 놀라운 위업을 달성할 수 있습니다. 예를 들어, 저는 초거대 언어 모델에게 학술 논문(academic paper)을 읽고 "이 논문의 방법론을 비판하고, 더 나은 방법론을 찾아 적용하라"는 지시를 내렸습니다. 이것은 평범한 논문이 아니었습니다. 저의 취업 시장용 논문(job market paper)이었고, 이는 학자로서 저의 첫 주요 연구를 의미합니다. 이 논문을 쓰는 데 1년 이상이 걸렸고, 제 분야의 가장 뛰어난 많은 사람들에 의해 신중하게 읽힌 후 최종적으로 동료 심사(peer reviewed)를 거쳐 주요 학술지에 게재되었습니다.

9분 40초 후, 저는 매우 상세한 비판을 받았습니다. 이는 단순히 문장이나 편집상의 비판을 넘어섰습니다. AI는 몬테카를로 분석(Monte Carlo analysis)을 수행하고 통계 모델(statistical models)의 고정 효과(fixed effects)를 재해석하는 등 코드를 사용하여 제 결과를 검증하기 위한 자체 실험을 실행한 것으로 보였습니다. 그 결과 많은 제안을 내놓았지만(다행히 "제 논문의 핵심 주장(headline claim)은 검토를 통과한다"고 결론 내렸지만), 한 가지가 눈에 띄었습니다. 이전에 발견되지 않았던 작은 오류를 찾아냈습니다. 이 오류는 제가 논문에서 명시적으로 설명하지 않은 방식으로 연결된 두 개의 표에 있는 두 가지 다른 숫자 세트와 관련이 있었습니다. AI는 이 사소한 오류를 찾아냈고, 이전에는 아무도 찾아내지 못했습니다. 이는 AI의 교차 검증 능력과 미세한 패턴 감지 능력의 향상을 보여주는 사례입니다.

다시 한번, 저는 마법사 문제에 직면했습니다. 이것이 옳았을까요? 저는 결과를 확인했고, 옳다는 것을 알았습니다. 하지만 AI가 이 문제를 발견하기 위해 무엇을 했는지, 그리고 AI가 했다고 주장하는 다른 일들이 설명된 대로 일어났는지에 대해서는 여전히 알 수 없습니다. 저는 이제 크고 작은 온갖 문제들을 이 모델에 던집니다. 가트너 하이프 사이클(Gartner hype cycle)은 실제로 존재하는가? 인구 조사 데이터(census data)는 대기업에서 AI 사용이 감소하고 있음을 보여주었는가? 최신 AI 모델에게 물어보면 정답을 얻을 수 있습니다. 저는 그렇게 생각합니다. 아직 오류를 찾지 못했지만, 오류가 없다는 의미는 아닙니다. 물론, AI가 어떤 종류의 좋은 답변도 제공하지 못할 많은 다른 작업들도 있습니다. 마법사에게 누가 알겠습니까?

이것이 더 광범위한 업무에 어떻게 적용될 수 있는지 보려면, 최근 파일 작업 능력이 강화된 고급 AI 모델을 고려해 보십시오. 이 AI는 엑셀(Excel)에 특히 능숙하므로, 저는 제가 잘 아는 엑셀 파일로 어려운 도전을 주었습니다. 제가 기업가 정신 수업(entrepreneurship classes)에서 사용했던 연습 문제 중 하나는 불확실성에도 불구하고 계획을 세우는 방법에 대한 교훈으로 소규모 책상 제조 사업의 재무 모델(financial model)을 분석하는 것이었습니다. 저는 AI에게 오래된 여러 탭으로 구성된 엑셀 파일(multi-tab Excel file)을 주고, 전체 연습의 목표를 유지하면서 새로운 사업, 즉 치즈 가게를 위해 파일을 업데이트해 달라고 요청했습니다.

단지 그 지시만으로, AI는 수업 계획과 수식(formulas)을 포함한 오래된 스프레드시트(spreadsheets)를 읽고, 치즈 가게에 적합하도록 모든 정보를 업데이트하여 새로운 스프레드시트를 만들었습니다. 몇 분 후, 단 하나의 프롬프트(prompt)만으로, 저는 핵심 교훈을 전달하면서도 완전히 새로운 데이터를 담은 새로운 변형된 스프레드시트를 제 컴퓨터에 다운로드했습니다. 이러한 효율성은 단순 반복 작업을 넘어 복잡한 데이터 구조를 이해하고 재구성하는 AI의 능력이 크게 향상되었음을 의미합니다.

다시 한번, 마법사는 저에게 그 비법을 알려주지 않았으므로, 저는 결과를 신중하게 확인해야 했습니다. 제가 본 바로는, 새로운 맥락에서 교훈을 보존하면서 매우 훌륭해 보였습니다. 수식과 비즈니스 모델링(business modelling)에서 제가 다르게 했을 몇 가지 문제점(예를 들어, 연간 영업일 수를 더 적게 했을 것입니다)을 발견했지만, 이는 실질적인 오류라기보다는 의견 차이에 가깝게 느껴졌습니다. 이처럼 AI의 결과물은 인간 전문가의 관점에서 검토하고 개선할 여지가 여전히 존재합니다.

AI가 얼마나 멀리 갈 수 있는지 궁금했고, 모두가 항상 AI가 파워포인트(PowerPoint)를 만들 수 있는지 묻기 때문에, 저는 또한 "좋아, 이제 이 사업을 위한 좋은 파워포인트를 만들어줘"라고 프롬프트했고 다음 결과를 얻었습니다. 이것은 피치 덱(pitch deck)의 꽤 견고한 시작이며, 큰 오류는 없지만, 바로 사용할 수 있는 수준은 아닙니다. 이는 AI의 들쭉날쭉한 경계(jagged frontier)를 강조합니다. AI는 경험 없이는 예측하기 어려운 방식으로 어떤 일에는 매우 능숙하고 다른 일에는 서툽니다. 저는 AI 능력의 끊임없이 확장되는 경계 내에서 예시들을 보여드렸지만, 그렇다고 해서 AI가 모든 것을 똑같이 쉽게 할 수 있다는 의미는 아닙니다. 하지만 이 글에서 저의 초점은 AI 능력의 확장 범위보다는 AI와의 변화하는 관계에 있습니다.

**마법사의 문제점**

이러한 새로운 AI 시스템은 본질적으로 에이전트(agents)입니다. 즉, 주어진 목표를 향해 자율적으로(autonomously) 계획하고 행동할 수 있는 AI입니다. 제가 AI에게 스프레드시트를 변경해 달라고 요청했을 때, AI는 원본 스프레드시트를 읽는 것부터 새로운 스프레드시트를 코딩(coding)하는 것까지 단계를 계획하고 실행했습니다. 하지만 예상치 못한 오류에도 적응하여, 제가 요청하지 않았는데도 스프레드시트를 두 번 수정하고 답변을 여러 번 검증했습니다. 최근에는 이러한 AI 에이전트의 자율성이 더욱 강조되며, 복잡한 다단계 작업을 스스로 해결하려는 경향이 강해지고 있습니다.

저는 이러한 단계를 선택할 수 없었습니다. 사실, 강화 학습(reinforcement learning)으로 구동되는 새로운 에이전트 물결에서는 아무도 단계를 선택하지 않습니다. 모델이 문제 해결을 위한 자체 접근 방식을 학습합니다. 비록 AI가 자체적으로 도구(tools)를 사용하거나 함수 호출(function calling)을 통해 외부 시스템과 연동하더라도, 그 내부적인 추론 과정은 여전히 불투명한 경우가 많습니다.

저는 개입할 수 없을 뿐만 아니라, AI 시스템이 실제로 무엇을 했는지 완전히 확신할 수도 없습니다. AI가 보고한 단계는 작업의 단순한 요약일 뿐이며, 많은 모델들은 그 과정에 대한 통찰력을 거의 제공하지 않습니다. 하지만 제가 단계를 볼 수 있었다고 해도, AI가 무엇을 하고 있는지 진정으로 이해하려면 코딩부터 기업가 정신에 이르기까지 여러 분야의 전문가여야 했을 것입니다. AI 모델의 복잡성이 증가함에 따라, 한 명의 인간이 그 모든 작동 방식을 이해하는 것은 더욱 어려워지고 있습니다.

그리고 물론, 정확성(accuracy) 문제가 있습니다. 모든 사실을 확인하지 않고 AI가 정확한지 어떻게 알 수 있을까요? 그리고 사실이 옳다고 해도, 제가 그것들을 제시하거나 구성하는 방식에 대해 다른 판단을 내렸을 수도 있습니다. 하지만 저는 아무것도 할 수 없습니다. 왜냐하면 마법사들은 저의 도움을 원하지 않고, 심지어 그들 자신도 설명할 수 없는 비밀스러운 방식으로 일하기 때문입니다. 이러한 불투명성은 중요한 의사결정에 AI를 활용할 때 윤리적인 문제를 야기할 수 있습니다.

이것의 어려운 점은 결과가 좋다는 것입니다. 매우 좋습니다. 저는 이 글에서 AI에게 맡긴 세 가지 작업에 대한 전문가이며, 사소한 서식 오류(formatting errors)와 제가 다르게 선택했을 몇 가지 사항이 있었지만, 이러한 결과물에서 사실 오류(factual errors)를 발견하지 못했습니다. 물론, 모든 세부 사항을 확인하지 않고는 문서가 오류가 없는지 실제로 말할 수는 없습니다. 때로는 직접 작업을 하는 것보다 훨씬 적은 시간이 걸리기도 하고, 때로는 훨씬 더 많은 시간이 걸리기도 합니다. 때로는 AI의 작업이 너무 정교해서 시도해도 확인할 수 없을 정도입니다. 우리가 마법사에게 작업을 맡길 때마다, 우리는 우리 자신의 전문성(expertise)을 개발하고, 마법사의 작업을 평가하는 데 필요한 바로 그 판단력(judgment)을 구축할 기회를 잃습니다. 이는 특히 초보 학습자들에게는 '기술 상실(deskilling)'의 위험으로 작용할 수 있습니다.

이것이 마법사의 문제입니다. 우리는 마법 같은 것을 얻고 있지만, 마법사나 심지어 마법사의 조수가 아닌 관객이 되고 있습니다. 협력 지능 모델에서는 우리가 안내하고, 수정하고, 협력했습니다. 점점 더 우리는 프롬프트를 입력하고, 기다리고, 그리고 가능하다면 검증합니다.

**그렇다면 마법사들을 어떻게 해야 할까요?**

저는 우리가 새로운 문해력(literacy)을 개발해야 한다고 생각합니다. 첫째, 언제 마법사를 소환해야 하는지, 언제 AI와 협력 지능으로 일해야 하는지, 또는 AI를 전혀 사용하지 말아야 하는지를 배워야 합니다. AI는 완벽과는 거리가 멀고, 여전히 부족한 분야에서는 인간이 종종 성공합니다. 하지만 AI가 유용한 작업의 수가 증가함에 따라, 협력 지능과 그것이 요구하는 상호작용은 종종 기계 단독보다 우수합니다. 그러나 점점 더 마법사를 소환하는 것이 최선이고, 그것이 만들어내는 것을 그냥 믿는 것이 가장 좋은 때가 있습니다. 현대 직장에서 요구되는 'AI 활용 능력'은 이러한 판단력을 포함합니다.

둘째, 우리는 과정보다는 결과물 감식가(connoisseurs of output)가 되어야 합니다. AI가 제공하는 결과물 중에서 선별하고 선택해야 하지만, 그 이상으로 AI와 충분히 작업하여 AI가 언제 성공하고 언제 실패하는지에 대한 직관(instincts)을 개발해야 합니다. 우리는 무엇이 옳고, 무엇이 틀렸으며, 무엇이 알지 못하는 위험을 감수할 가치가 있는지 판단하는 법을 배워야 합니다. 이는 AI 시대에 인간의 비판적 사고와 도메인 지식의 중요성을 더욱 강조합니다.

이것은 교육에 어려운 문제를 야기합니다. AI 자체가 숙련도를 개발하는 것을 방해할 때, 숙달하지 못한 분야에서 작업을 검증하도록 누군가를 어떻게 훈련시킬 수 있을까요? 이 격차를 해결하는 방법을 찾는 것이 점점 더 시급해지고 있습니다. 최근에는 AI를 책임감 있게 통합하는 새로운 교육 방식들이 모색되고 있습니다.

마지막으로, 잠정적 신뢰(provisional trust)를 받아들여야 합니다. 마법사 모델은 우리가 기준을 낮추기 때문이 아니라, 완벽한 검증(perfect verification)이 불가능해지고 있기 때문에 "충분히 좋은(good enough)" 결과물과 더 자주 작업하는 것을 의미합니다. 질문은 "이것이 완전히 정확한가?"가 아니라 "이것이 이 목적에 충분히 유용한가?"입니다. 예를 들어, 복잡한 아이디어의 초안을 작성하거나 대량의 데이터를 빠르게 분석할 때, 잠정적 신뢰는 효율적인 작업 흐름을 가능하게 합니다.

우리는 이미 기술적인 마법을 신뢰하는 데 익숙합니다. 경로를 이해하지 않고 GPS를 사용하거나, 알고리즘(algorithm)이 우리가 보는 것을 결정하도록 할 때마다, 우리는 다른 종류의 마법사를 신뢰하고 있는 것입니다. 하지만 결정적인 차이가 있습니다. GPS가 실패하면, 막다른 길에 도달했을 때 빠르게 알게 됩니다. 넷플릭스가 잘못된 영화를 추천하면, 저는 그냥 보지 않습니다. 하지만 AI가 제 연구를 분석하거나 스프레드시트를 변환할 때, AI가 더 능숙해질수록 그것이 틀렸는지 알기가 더 어려워집니다. 특히 AI의 환각(hallucination) 현상은 이러한 문제를 더욱 심화시킵니다.

AI 마법사와 함께 일하는 역설(paradox)은 역량(competence)과 불투명성(opacity)이 함께 증가한다는 것입니다. 우리는 이러한 도구들을 가장 검증하기 어려운 작업에 가장 필요로 합니다. 이것은 동화(fairy tales)에서 얻는 오래된 교훈입니다. 마법이 더 좋을수록, 미스터리는 더 깊어집니다. 우리는 계속해서 마법사들을 소환하고, 우리가 할 수 있는 것을 확인하며, 마법(spells)이 통하기를 바랄 것입니다. 일주일 분량의 분석을 9분 만에 해낸다면, 우리가 어찌 그러지 않을 수 있겠습니까? 이러한 역설을 현명하게 관리하는 것이 미래의 핵심 역량이 될 것입니다.

마법사의 시대에 오신 것을 환영합니다.