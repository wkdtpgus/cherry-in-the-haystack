최근 몇 주 사이, 구글에 이어 OpenAI가 다중 모드 이미지 생성(multimodal image generation) 역량을 공개했습니다. 이는 기술적으로 대단히 중요한 진전입니다. 과거에는 거대 언어 모델(Large Language Model, LLM) 기반 인공지능이 시각 자료를 만들어낼 때, 실제로는 LLM 자체의 직접적인 개입이 아니었습니다. 그 대신, 인공지능은 텍스트 형태의 지시문(text prompt)을 외부의 다른 이미지 제작 도구로 전달하고 그 결과물을 받아보는 방식이었습니다. 즉, 인공지능이 문자를 생성했지만, 그림은 상대적으로 지능이 낮은 별개의 체계가 만들어냈습니다. 예를 들어, "코끼리가 없는 방을 그려줘. 그리고 코끼리가 존재할 수 없는 이유를 그림에 설명해 줘"라고 명령했을 때, 지능이 떨어지는 그림 생성 시스템은 '코끼리'라는 단어를 여러 차례 인식하고는 오히려 그림에 코끼리를 삽입하곤 했습니다. 결과적으로, AI 이미지 창작물은 글자가 뒤틀리거나 무작위적인 요소가 포함되어 대체로 평범한 수준에 머물렀습니다. 간혹 흥미로웠지만, 실질적인 활용 가치는 거의 없었습니다.

이와는 대조적으로, 다중 모드 이미지 생성(multimodal image generation)은 인공지능이 결과물을 직접적으로 조형할 수 있게끔 합니다. 비록 여러 가지 구현 방식이 존재하고(물론 관련 기업들은 세부적인 접근법을 비공개로 하고 있지만), 핵심은 거대 언어 모델이 글을 구성하는 방식과 마찬가지로, 시각 정보 역시 개별 단위(token)로 생성된다는 점입니다. 문장을 완성하기 위해 낱말 하나하나를 붙여나가듯이, 인공지능은 그림을 이루는 각 요소를 순차적으로 만들어내어 하나의 완전한 형태로 조합합니다. 이러한 방식 덕분에 인공지능은 훨씬 더 뛰어나고 정교한 이미지를 그려낼 수 있습니다. 단순히 코끼리가 나타나지 않도록 보장하는 것을 넘어, 이 시각 자료 생성 과정의 최종 결과물은 LLM의 '사고' 역량과 명료한 표현력, 그리고 세밀한 통제 능력을 고스란히 드러냅니다.

이러한 발전은 "코끼리가 없는 방을 보여줘. 코끼리가 있을 수 없는 이유를 이미지에 주석으로 표시해 줘"라는 지시에 대한 Microsoft Copilot의 구식 이미지 생성기(좌측)와 GPT-4o의 다중 모드 모델(우측)의 결과물 비교에서 명확히 드러납니다. 이전 방식의 모델이 여러 마리의 코끼리를 그려낼 뿐만 아니라, 알아보기 힘든 글자들도 포함하고 있다는 점에 주목할 필요가 있습니다. 이처럼 진보된 이미지 모델들이 미치는 파급력은 막대하지만(이와 관련된 일부 쟁점들은 추후 논의할 것입니다), 우선 몇 가지 실례를 통해 이들 체계가 현실에서 어떤 능력을 발휘하는지 알아보겠습니다.

**시각 자료 지시(Visual Prompting)의 새로운 지평**
제가 작성한 글들과 출판물에서 인공지능에게 효과적으로 지시(prompt)하는 핵심은, 비록 기계임에도 불구하고 마치 인간 동료처럼 상호작용하는 것이라고 강조해왔습니다. 구체적이고 명료한 명령을 내리고, 반복적인 작업 과정에서 지속적인 피드백을 제공하며, 의사 결정을 위한 충분한 배경 정보를 부여하는 것은 사람과의 협업에서 필수적이듯이, 인공지능과의 소통에서도 동일하게 중요합니다. 과거에는 이러한 대화가 오직 글자 형태의 지시문으로만 가능했으나, 이제는 시각적 요소를 통해서도 이러한 정교한 상호작용이 가능해졌습니다.

예를 들어, 저는 GPT-4o에게 "효율적인 시간 관리를 위한 팁을 담은 간결한 인포그래픽(infographic)을 제작해 줘"라고 명령했습니다. 기존의 이미지 생성 도구로는 이러한 요청에 대해 이미지를 제대로 안내할 만한 이해력이 부족하여, 글자가 뒤죽박죽이 되거나 의미 없는 그림들로 채워져 황당한 결과가 나왔을 것입니다. 하지만 이제는 첫 시도만으로도 훌륭한 초기 시안을 받아볼 수 있습니다. 다만, 제가 구체적인 방향성이나 추가적인 상세 정보를 제시하지 않았기 때문에, 인공지능이 모든 창의적인 결정권을 행사했다는 점은 분명합니다.

그렇다면 만약 제가 마음에 들지 않아 수정하고 싶다면 어떨까요? 한번 시도해 보죠. 먼저, 저는 "이 시각 자료를 좀 더 사이버펑크(cyberpunk) 스타일로 바꿔줘"라고 요구했고, 인공지능이 초기 구상의 핵심을 유지하면서도 전체적인 미학을 변화시키는 것을 확인할 수 있었습니다. 저는 여기서 더 나아가 몇 가지 수정을 더 원했습니다: "색감은 차갑고 미래적인 네온 톤으로 변경하고, 다른 요소들은 그대로 유지해 줘. 그리고 작은 글머리 기호(bulleted text)는 더 선명하게 처리해서 가독성을 높여줘." 새로 바뀐 모습은 마음에 들었지만, 'Innovation'이라는 단어가 'Innovaton'으로 오타가 난 것을 발견했습니다. 이는 아무리 뛰어난 시스템이라 할지라도 아직 완벽과는 거리가 멀다는 증거입니다. 저는 즉시 "Innovation의 철자가 틀렸어, 수정해 줘"라고 지시했고, 곧바로 만족스러운 결과물을 얻을 수 있었습니다.

하지만 이 모델들이 가진 진정한 매력은 상상하는 거의 모든 시각 자료를 구현할 수 있다는 데 있습니다. 예를 들어, 저는 이렇게 요구했습니다: "이 인포그래픽을 우주복을 입은 고양이가 달 표면에서 들고 있는 모습으로 만들어줘. 실제 사진처럼 보여야 하고, 고양이가 홀로그램(hologram) 형태의 인포그래픽을 공중에 띄우고 있는 것처럼 보이게 해 줘." 여기서 멈출 이유가 있을까요? "황혼 무렵이고, 고양이의 헬멧 바이저에 비치는 지구의 푸른 빛이 홀로그램을 비추는 것처럼 보이게 해 줘 (헬멧은 직접적으로 보이지 않도록)." — 이 결과물은 단순히 조명을 재현하는 것을 넘어, 정교한 광원 모델(lighting model) 없이도 환경적 빛을 자연스럽게 반영했기에, 겉으로 보이는 것보다 훨씬 더 놀랍습니다.

"로봇 요리사 액션 피규어(action figure)를 포장된 상태로 만들어 줘. 작은 요리책을 옆에 있는 부속품 중 하나로 넣어줘. 이름은 'Chef Bot'으로 하고 다른 주방 용품 몇 가지를 추가해 줘."

"미래형 기차 안에서 태블릿을 사용하는 강아지를 그려줘. 그 강아지는 'TechPaws'라는 온라인 상점에서 Chef Bot 피규어를 주문하고 있는 중이야."

놀랍지만 완벽하게 정확하지는 않았습니다: "태블릿 화면의 인터페이스를 더 현실적으로 수정하고, 강아지가 입고 있는 우주복을 평범한 스웨터로 바꿔줘."

여러분도 보셨듯이, 현재의 시스템들이 아직 무결점이라고는 할 수 없습니다. 그러나 불과 2년 6개월 전, "무선 인터넷을 사용하는 비행기 내의 수달"이라는 지시에 대한 결과물이 어떠했는지 상기해 보십시오. 최고 수준의 기술은 놀라운 속도로 진보하고 있습니다.

그렇다면 이러한 혁신이 실질적으로 어떤 효용성을 가질까요? 지난 몇 년간 우리는 텍스트 기반 인공지능 모델의 활용처를 끊임없이 탐색해 왔으며, 지금도 새로운 응용 분야(use case)가 계속해서 발굴되고 있습니다. 시각 정보 처리 능력을 갖춘 거대 언어 모델(image-based LLM) 역시 마찬가지의 경로를 밟을 것입니다. 이미지를 생성하는 능력은 우리가 아직 온전히 예측하지 못하는 방식으로 사회 전반에 지대한 변화를 가져올 잠재력을 지니고 있습니다. 특히, LLM이 이제 단순히 텍스트를 넘어 이미지를 직접 '인지'하고 '수정'할 수 있도록 업로드 기능까지 지원한다는 점에서 그 파급력은 더욱 커질 것입니다.

다음은 몇 가지 구체적인 예시들입니다. 이 모든 시연은 GPT-4o를 활용하여 이루어졌습니다 (물론 Google의 Gemini Flash 또한 시각 자료를 업로드하고 생성하는 기능을 제공합니다):

저는 직접 손으로 그린 간단한 스케치를 가져와 인공지능에게 이렇게 지시할 수 있습니다: "이 그림을 '에코 그린 세제(Eco Green Detergent)'의 광고 포스터로 디자인해 줘. 포장 디자인과 로고는 현대적이고 세련되게, 그리고 실제 제품 사진처럼 보이게 해 줘." (이 작업은 두 번의 수정 지시를 필요로 했습니다. 첫 시도에서는 라벨에 'Eco Green' 철자가 잘못 표기되었습니다.) 최종 결과물이 숙련된 전문 디자이너의 작품만큼 완벽하지는 않지만, 초기 단계의 시제품(prototype)으로는 충분히 인상적인 수준입니다.

GPT-4o에게 두 장의 사진을 제시하고 "초록색 벽지 방에 있는 액자를 빨간색 벽지 방에 있는 것으로 교체해 줄 수 있을까?"라고 요청할 수도 있습니다. (새로운 액자의 그림자가 원본 이미지에는 없던 공간감을 부여하는 방식에 주목해 주십시오. 반면, 교체된 액자 디자인이 원본과 완전히 일치하지는 않습니다.) 이어서 저는 "창밖 풍경을 좀 더 밝고 화사하게 바꿔줄 수 있을까?"라고 질문했습니다. 물론, 아직 완벽하지 않은 미세한 부분들이 남아있지만, 이처럼 평범한 한국어로 시각 자료를 수정하는 기능은 과거에는 상상조차 할 수 없던 일입니다.

혹은 인공지능을 활용하여, 가상현실(VR) 기반의 맞춤형 명상 앱이라는 저의 기발한 스타트업 아이디어(성공은 따 놓은 당상이라고 확신합니다)를 위한 즉각적인 웹사이트 시안(mockup), 광고 컨셉, 그리고 투자 유치 제안서(pitch deck)를 만들어낼 수 있습니다. 보시는 바와 같이, 이러한 결과물이 아직은 숙련된 인간 디자이너의 독창적인 통찰력을 완전히 대체할 수는 없지만, 초기 단계의 시제품으로서는 여전히 대단히 유용합니다.

이밖에도 저와 여러 사람들이 끊임없이 발굴하고 있는 수많은 활용 사례들이 존재합니다. 몇 가지만 예로 들자면: 맞춤형 교육 자료(custom educational materials), 소셜 미디어 콘텐츠, 가상현실(VR) 환경 구성 요소, 인터랙티브 스토리북, 상황극 대본(role-play scenarios), 예술 작품 복원, 그리고 몰입형 시뮬레이션 등이 있습니다.

**윤리적 난제**
이러한 신형 시각 자료 생성 도구들에 대한 온라인상의 담론을 접하셨다면, 제가 가장 큰 화제를 모으는 활용법인 양식 변환(style transfer) 기능을 시연하지 않았다는 사실을 알아차리셨을 것입니다. 양식 변환은 사용자가 인공지능에게 특정 사진을 심슨 가족(The Simpsons)이나 스튜디오 지브리(Studio Ghibli) 애니메이션처럼 보이도록 바꾸어 달라고 요청하는 기법입니다. 이러한 종류의 응용 방식은 인공지능을 예술 분야에 적용하는 것과 관련된 모든 복합적인 문제들을 부각시킵니다. 인공지능을 활용하여 다른 예술가들이 오랜 노력 끝에 정립한 독자적인 양식을 재현하는 것이 과연 정당한가? 그렇게 만들어진 예술 작품의 소유권은 누구에게 귀속되는가? 이 과정에서 누가 이득을 취하는가? 인공지능의 학습 자료(training data)에는 어떤 창작자들의 작품이 포함되어 있으며, 저작권이 있는 저작물을 학습에 사용하는 것의 법적, 윤리적 입장은 무엇인가? 이 질문들은 다중 모드 인공지능이 등장하기 전부터도 중요했지만, 이제는 그 해답을 찾아야 할 필요성이 더욱 절실해지고 있습니다.

물론, 다중 모드 인공지능과 연관된 수많은 다른 잠재적 위험성 또한 존재합니다. 딥페이크(Deepfakes)는 이미 최소 1년 전부터 손쉽게 제작될 수 있었지만, 다중 모드 인공지능은 위조 영수증과 같은 온갖 형태의 기만적인 시각적 조작(visual illusions)을 만들어내는 능력을 더함으로써 이러한 문제를 한층 더 심화시킵니다. 또한, 우리는 다중 모드 인공지능이 시각 자료 생성 과정에서 어떤 종류의 편향(biases)이나 예상치 못한 문제점들을 야기할 수 있는지 아직 충분히 파악하지 못하고 있습니다.

그러나 텍스트 영역에서 발생했던 변화가 이제 시각 자료에, 그리고 궁극적으로는 동영상과 3D 환경으로까지 확산될 것이라는 점은 명확합니다. 이러한 다중 모드 체계들은 시각적 창작의 풍경을 근본적으로 바꾸어 놓으며, 강력한 신기능을 제공하는 동시에 창작물의 저작권과 진위 여부에 대한 정당한 의문을 제기합니다. 인간과 인공지능 창작물 사이의 경계는 끊임없이 희미해질 것이며, 몇 마디 지시만으로 누구든 복잡한 시각 콘텐츠를 만들어낼 수 있는 세상에서 '독창성'이 무엇을 의미하는지 재고하도록 우리를 유도할 것입니다. 일부 창의적인 분야의 직업은 새로운 환경에 적응할 것이고, 어떤 직업은 현상 유지를 할 수도 있으며, 또 다른 직업은 완전히 새로운 형태로 변모할 수 있습니다. 모든 중대한 기술적 변혁과 마찬가지로, 우리는 앞으로 펼쳐질 복합적인 상황을 현명하게 헤쳐나가기 위한 심사숙고된 지침(frameworks)이 필요할 것입니다. 핵심적인 질문은 이 도구들이 시각 매체를 변화시킬 것인가가 아니라, 우리가 그 변화의 방향을 의도적으로 설정할 만큼 충분히 숙고할 수 있을 것인가에 달려 있습니다.

소식 받기 및 공유