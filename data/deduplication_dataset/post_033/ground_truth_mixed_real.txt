지난 2주 동안, 구글에 이어 OpenAI가 멀티모달 이미지 생성(multimodal image generation) 기능을 선보였습니다. 이는 매우 중요한 발전입니다. 과거에는 대규모 언어 모델(Large Language Model, LLM) AI가 이미지를 만들 때, 직접적인 생성 과정에 관여하지 않았습니다. 대신, AI는 텍스트 프롬프트(text prompt)를 외부 이미지 생성기에 전달하고 그 결과물을 사용자에게 보여주는 방식이었습니다. 이러한 분리된 시스템은 종종 예측 불가능한 결과를 초래했습니다. 예를 들어, "코끼리가 없는 방을 보여줘. 코끼리가 있을 수 없는 이유를 이미지에 주석으로 표시해 줘"라고 프롬프트하면, 덜 지능적인 이미지 생성 시스템은 '코끼리'라는 단어를 여러 번 보고 그림에 코끼리를 추가했습니다. 이러한 한계로 인해 초기 AI 이미지 생성은 실용적이기보다는 실험적인 수준에 머물렀습니다. 하지만 최근 등장한 멀티모달 기능은 이러한 패러다임을 근본적으로 바꾸고 있습니다.

반면, 멀티모달 이미지 생성(multimodal image generation)은 AI가 생성되는 이미지를 직접 제어할 수 있도록 합니다. 정확한 구현 방식은 각 기업의 기밀에 부쳐져 있지만, 본질적으로 멀티모달 AI는 텍스트를 구성하는 단어처럼 이미지를 토큰(token) 단위로 생성합니다. 문장을 만들기 위해 개별 단어를 추가하는 대신, AI는 이미지를 개별 조각으로 하나씩 생성하여 전체 그림으로 조립합니다. 이러한 방식은 AI가 단순히 이미지를 만들어내는 것을 넘어, 이미지의 내용과 맥락을 깊이 이해하고 반영할 수 있게 합니다. 즉, LLM의 추론 능력과 정교한 제어력이 시각적 결과물에 그대로 투영되어, 사용자 의도에 훨씬 더 부합하는 결과물을 도출할 수 있습니다. 이는 이미지 생성의 정확도와 유용성을 비약적으로 향상시켰습니다.

이전 세대 모델과 최신 멀티모달 모델의 차이는 극명합니다. 예를 들어, "코끼리가 없는 방을 보여줘. 코끼리가 있을 수 없는 이유를 이미지에 주석으로 표시해 줘"라는 프롬프트에 대한 Microsoft Copilot의 기존 이미지 생성기(왼쪽)와 GPT-4o의 멀티모달 모델(오른쪽)의 결과입니다. 기존 모델은 여러 코끼리를 보여줄 뿐만 아니라 왜곡된 텍스트도 포함하고 있음에 주목하십시오. 이러한 새로운 이미지 모델의 영향은 엄청나지만(일부 문제는 나중에 다루겠습니다), 먼저 몇 가지 예시를 통해 이 시스템들이 실제로 무엇을 할 수 있는지 살펴보겠습니다.

**이미지를 위한 프롬프트(prompting)**
제가 쓴 책과 여러 글에서 강조했듯이, AI에게 효과적으로 프롬프트하는 핵심은 AI를 마치 사람처럼 대하는 것입니다. 명확한 지시와 반복적인 피드백, 그리고 충분한 맥락을 제공하는 것은 AI의 결과물 품질을 크게 향상시킵니다. 이전에는 텍스트로만 가능했던 일이지만, 이제는 이미지로도 할 수 있습니다.

예를 들어, GPT-4o에 '좋은 보드게임을 만드는 인포그래픽을 만들어 줘'라고 요청했을 때, 과거의 AI 이미지 생성기는 이러한 복잡한 요청을 처리할 지능이 부족하여 텍스트 오류나 무의미한 결과로 이어졌을 것입니다. 하지만 이제는 첫 시도만으로도 훌륭한 초안을 얻을 수 있습니다. 하지만 제가 찾고 있는 것에 대한 맥락이나 추가적인 내용을 제공하지 않았기 때문에, AI가 모든 창의적인 선택을 했습니다.

만약 결과물을 수정하고 싶다면 어떨까요? 먼저 '그래픽을 초현실적인 스타일로 바꿔줘'라고 지시하자, AI는 기존 초안의 핵심 요소를 유지하면서 시각적 스타일을 즉시 변경했습니다. 저는 더 많은 변경을 원했습니다: "색상을 흙색 톤(earth toned)이 아닌 질감 있는 금속처럼 보이게 해 줘. 다른 모든 것은 그대로 유지하고, 작은 글머리 기호 텍스트(bulleted text)는 더 밝게 해서 읽기 쉽게 해 줘." 저는 새로운 모습이 마음에 들었지만, "Define"이라는 단어가 "Definc"로 바뀌는 오류가 발생했음을 발견했습니다. 이는 이 시스템들이 아무리 뛰어나더라도 아직 완벽에 가깝지 않다는 신호입니다. 저는 "Define을 Definc로 철자를 틀렸어, 고쳐 줘"라고 프롬프트했고, 합리적인 결과물을 얻었습니다.

이 모델들의 진정한 강점은 상상하는 거의 모든 시나리오를 시각화할 수 있다는 점입니다. 예를 들어, '이 인포그래픽을 화산 앞에 서 있는 수달이 금속판에 새겨진 형태로 들고 있는 사진처럼 보여줘'와 같은 복잡한 요청도 가능합니다. 심지어 '밤이고, 태블릿 중앙에 손전등 빛이 비치게 해 줘(손전등은 보이지 않게)'와 같이 추상적인 조명 조건까지도 정확히 구현해냅니다. 이는 단순한 이미지 생성을 넘어, 물리적 현실을 시뮬레이션하는 AI의 능력이 얼마나 발전했는지 보여주는 사례입니다.

"수달 액션 피규어(action figure)를 포장과 함께 만들어 줘. 보드게임을 옆에 있는 액세서리 중 하나로 만들어 줘. 이름을 "Game Design Otter"라고 하고 다른 액세서리 몇 개를 추가해 줘."

"노트북을 사용하는 비행기 안의 수달을 만들어 줘. 그들은 OtterExpress라는 사이트에서 Game Design Otter 사본을 구매하고 있어."

물론, 여전히 개선의 여지는 있습니다. 예를 들어 '키보드를 사실적으로 고치고 들고 있는 수달 액션 피규어를 제거해 줘'와 같은 수정 요청도 필요할 수 있습니다. 이러한 시스템이 완벽하지 않다는 점은 분명하지만, 불과 2년 전 '와이파이를 사용하는 비행기 안의 수달' 프롬프트가 얼마나 조악한 결과를 냈는지 상기해보면, 기술 발전 속도는 경이롭습니다. 이제는 이미지 내 객체의 위치, 자세, 심지어 재질까지 세밀하게 제어하는 것이 가능해졌습니다.

그렇다면 이러한 멀티모달 AI는 구체적으로 어떤 면에서 유용할까요? 지난 몇 년 동안 텍스트 기반 AI 모델의 활용 사례가 끊임없이 확장되어 왔듯이, 이미지 기반 LLM 또한 상상 이상의 파괴적인 잠재력을 지니고 있습니다. 특히 LLM이 이제 이미지를 직접 보고 조작할 수 있도록 업로드할 수 있기 때문에 더욱 그렇습니다.

몇 가지 예시입니다. 모두 GPT-4o를 사용하여 수행되었습니다 (Google의 Gemini Flash에서도 이미지를 업로드하고 생성할 수 있습니다):

손으로 그린 스케치를 업로드하고 AI에게 '이것을 스피드스터 에너지 드링크(Speedster Energy drink) 광고로 만들어 줘. 포장과 로고를 멋지게 디자인하고, 실제 사진처럼 보이게 해 줘'라고 요청할 수 있습니다. 단 몇 번의 프롬프트 수정으로 전문가 수준은 아니지만, 매우 인상적인 초기 프로토타입을 얻을 수 있습니다.

저는 GPT-4o에게 두 장의 사진을 주고 "파란색 소파가 있는 이미지의 커피 테이블을 흰색 소파에 있는 것으로 바꿔줄 수 있을까?"라고 프롬프트할 수 있습니다. (새로운 유리 상판이 원본에는 없던 이미지의 일부를 보여주는 방식에 주목하십시오. 반면에 교체된 테이블은 완전히 동일하지는 않습니다.) 그다음 저는 "카펫을 덜 바래게 할 수 있을까?"라고 물었습니다. 다시 말하면, 완벽하지 않은 몇 가지 세부 사항이 있지만, 이렇게 평이한 영어로 이미지를 편집하는 것은 이전에는 불가능했습니다.

드론으로 과카몰리를 배달하는 혁신적인 스타트업 아이디어를 가지고 있다면, 즉석에서 웹사이트 목업(mockup), 광고 콘셉트, 피치 덱(pitch deck)을 만들어 볼 수 있습니다. 물론 인간 디자이너의 깊이 있는 통찰력을 완전히 대체할 수는 없겠지만, 아이디어를 빠르게 시각화하고 발전시키는 데 매우 효과적인 초기 프로토타입 도구 역할을 합니다.

이 외에도 멀티모달 AI는 무수히 많은 새로운 용도로 활용되고 있습니다. 예를 들어, 시각적 레시피(visual recipes) 제작, 웹사이트 레이아웃 디자인, 게임 에셋(asset) 및 텍스처(textures) 생성, 동화 삽화 제작, 복잡한 데이터 시각화, 제품 디자인 초기 구상, 그리고 증강 현실(AR) 콘텐츠 개발 등 다양한 분야에서 혁신을 이끌고 있습니다. 이러한 활용 사례는 매일 새롭게 발견되고 있으며, 그 범위는 계속해서 확장될 것입니다.

**복잡성**
새로운 이미지 생성기에 대한 온라인 논의에서 자주 언급되는 '스타일 전이(style transfer)'는 제가 이 글에서 직접 시연하지 않은 가장 널리 퍼진 활용법 중 하나입니다. 이는 특정 사진을 심슨 가족(The Simpsons)이나 스튜디오 지브리(Studio Ghibli)와 같은 유명 예술 스타일로 변환하는 기능입니다. 이러한 종류의 응용 프로그램은 예술에 AI를 사용하는 것의 모든 복잡성을 부각시킵니다: AI를 사용하여 다른 예술가들의 어렵게 얻은 스타일을 재현하는 것이 괜찮은가? 결과물인 예술의 소유권은 누구에게 있는가? 누가 이익을 얻는가? AI의 훈련 데이터(training data)에는 어떤 예술가들이 포함되어 있으며, 저작권이 있는 작품을 훈련에 사용하는 것의 법적, 윤리적 지위는 무엇인가? 이것들은 멀티모달 AI 이전에도 중요한 질문이었지만, 이제는 이에 대한 답을 찾는 것이 점점 더 시급해지고 있습니다.

물론, 멀티모달 AI의 발전은 사회에 새로운 종류의 위험을 안겨줄 수 있습니다. 딥페이크(Deepfakes)는 이미 널리 알려진 위협이지만, 멀티모달 AI는 이를 넘어 가짜 영수증, 위조 문서, 심지어 존재하지 않는 사건 현장 이미지와 같은 정교한 시각적 환상(visual illusions)을 더욱 쉽게 만들어낼 수 있습니다. 이는 정보의 진위 여부를 판단하는 데 막대한 혼란을 야기할 수 있습니다. 또한, AI 모델의 훈련 데이터에 내재된 편향(biases)이 시각적 결과물에 그대로 반영되어 특정 집단에 대한 고정관념을 강화하거나 차별을 조장할 수 있다는 점도 심각한 문제입니다. 이러한 윤리적, 사회적 문제에 대한 깊이 있는 이해와 해결책 마련이 시급합니다.

텍스트 AI가 그랬듯이, 멀티모달 AI는 이미지, 나아가 비디오와 3D 환경까지 변화시킬 것이 분명합니다. 이러한 멀티모달 시스템은 시각적 콘텐츠 제작의 지형을 근본적으로 재편하며, 전례 없는 기능을 제공함과 동시에 창작물의 소유권, 진정성, 그리고 윤리적 책임에 대한 중요한 질문을 제기하고 있습니다. 인간과 AI 창작물 간의 경계는 계속해서 모호해질 것이며, 몇 가지 프롬프트만으로 누구나 정교한 시각 자료를 생성할 수 있는 세상에서 독창성이 무엇을 의미하는지 재고하도록 우리를 이끌 것입니다. 일부 창의적인 직업은 빠르게 적응하고 새로운 기회를 찾을 것이며, 어떤 직업은 변화의 파고를 겪을 것이고, 또 다른 직업은 완전히 새로운 형태로 재편될 것입니다. 모든 기술적 혁신이 그렇듯이, 우리는 이러한 복잡한 변화를 슬기롭게 헤쳐나가기 위한 신중하고 포괄적인 프레임워크(frameworks)를 구축해야 합니다. 문제는 이러한 도구들이 시각 미디어를 변화시킬 것인가가 아니라, 우리가 그 변화를 의도적으로 형성할 만큼 충분히 사려 깊을 것인가입니다.

이 놀라운 기술의 발전과 그에 따른 복잡성에 대해 더 깊이 논의하고 싶으시다면, 댓글을 남겨주시거나 이 글을 공유해 주십시오. 여러분의 생각과 의견은 이 중요한 대화에 큰 도움이 됩니다.