OpenAI의 '실패하기엔 너무 거대하다'는 신화, 그 이면의 현실과 도전 과제

최근 AI 산업을 둘러싼 논의의 핵심에는 OpenAI가 자리 잡고 있습니다. 챗봇을 넘어 브라우저, 기기, 칩, 소셜 미디어 등으로의 전방위적인 제품 다각화부터 엔비디아(Nvidia), 오라클(Oracle), 브로드컴(Broadcom), AMD, 아마존(Amazon) 등과의 전반에 걸친 막대한 계약, AGI, 초지능(superintelligence), 특이점(singularity)에 대한 약속, 국방부(DoD)와의 대규모 계약, 보도된 5천억 달러 기업 가치, 그리고 영리 기업으로 재편성된 후 1조 달러 가치(2026-2027년경)의 기업공개(IPO) 가능성에 이르기까지, 이 모든 것이 실패하기에는 너무 거대해지는 것(too big to fail)이라는 단 하나의 목표를 가지고 있다는 것입니다. (이는 이달 초 널리 공유된 월스트리트 저널(Wall Street Journal) 기사의 제목입니다.) 이러한 관점에서 OpenAI CEO 샘 알트만(Sam Altman)은 마치 명장 직공처럼 소비자부터 기업, 정부에 이르는 경제 전반과 문화 및 정치 전반에 걸쳐 자신의 영향력을 엮어내고 있으며, 이는 산업 버블(AI는 작동하지만 너무 많은 돈이 몰려 있음)이나 데이터센터 자본 지출(CapEx)에서 불충분한 수익(AI는 작동하지만 충분한 생산성 향상을 제공하지 못함)이 발생하는 시나리오에서도 그의 제국이 구제될 수 있도록 하기 위함입니다. 하지만 이러한 거대 기업의 지위는 동시에 막대한 운영 비용, 치열한 경쟁, 그리고 리더십 신뢰성 문제 등 다양한 도전을 수반합니다. AI 산업의 미래를 좌우할 수 있는 OpenAI가 직면한 현실적인 난관들을 심층적으로 분석해보고자 합니다.

경제학계에서는 AI의 경제적 영향에 대한 낙관론과 비관론이 엇갈립니다. AI가 침체된 경제에 새로운 활력을 불어넣을 '마지막 동력'이 될 수 있다는 기대가 크지만, 과도한 자본 지출(CapEx) 대비 불충분한 수익률, 즉 'AI 버블' 가능성에 대한 경고도 끊이지 않습니다. 경제학자 타일러 코웬(Tyler Cowen)은 더 프리 프레스(The Free Press)에 역류하는 긍정적인 견해를 썼습니다. 그는 AI 산업이 침체된 미국 경제 엔진의 동력으로 존재한다는 것이 좋다고 주장합니다. 비록 그것이 동종 업계에서 마지막으로 남은 것일지라도 말이죠. 따라서 월스트리트(Wall Street)가 그것에 집착하는 것은 "완벽하게 이치에 맞다"고 말합니다. 엔비디아의 5조 달러 시가총액(market cap)이 독일과 일본의 GDP에 필적하거나(지표들이 직접 비교 대상은 아니지만, 누가 신경 쓰겠습니까), OpenAI의 수익이 손실을 보전하기에는 턱없이 부족하더라도(마이크로소프트(Microsoft)의 지난 실적 보고서에 따르면 OpenAI는 지난 분기에만 120억 달러의 손실을 입었습니다), 코웬은 이것이 반드시 버블의 징후나 경기 침체의 증상은 아니며, 미국이 최악의 시기를 최고의 시기로 바꾸는 데 특화되어 있다는 점을 상기시켜주는 것이라고 말합니다. 출처: 뉴욕 타임스(New York Times) 구체적인 수익 모델이 아직 불분명한 상황에서, AI 기술이 실제 생산성 향상으로 이어질지에 대한 회의적인 시각도 존재합니다. 결국, AI 산업의 지속 가능한 성장은 견고한 비즈니스 모델과 실질적인 경제적 가치 창출에 달려있습니다.

노아 스미스(Noah Smith) — 역시 경제학자이자 기술 낙관론자(techno-optimist) — 는 최근 들어 그렇게 긍정적이지 않았으며, 지난 몇 년간 그의 가장 우울한 글이 될 만한 것을 발표했습니다: 제2차 세계대전 이후의 파티는 끝났다. 저는 코웬과 스미스 두 사람의 견해 모두에 공감합니다. 한편으로는 AI가 반세기 동안 지속된 서구 문명의 쇠퇴에 대한 해답이 될 수 있다고 믿는 것이 좋습니다. 다른 한편으로는 그것을 믿기 어렵습니다. 그러니 우리가 이것으로부터 얻을 수 있는 결론이 무엇인지는 꽤 명확하겠죠? 경제학자들은 자신들의 학문이 정확한 과학이 아니라는 것을 거듭해서 재차 강조하는 것이 옳습니다. 불안한 진실은 미국이 AI에 대한 막대한 투자로 어디로 가고 있는지 아무도 모른다는 것입니다(유럽이 AI의 부재로 어디로 가고 있는지는 알지만요). 또는 '매그니피센트 세븐(magnificent seven)' 주식의 끊임없는 급등이 무엇을 의미하는지, 혹은 서로 거래하고 한편으로는 광고를 팔고, 다른 한편으로는 AI 모델을 훈련시켜 더 많은 광고를 돌리는 칩을 파는 회사들로 경제를 유지하는 것이 가능한지 아무도 모른다는 것입니다. 그래서 우리는 기다립니다. (세상에서 가장 강력한 산업에 대해 약간 비꼬는 말을 하지 않을 수 없네요, 죄송합니다.)

팀 히긴스(Tim Higgins)는 입소문 난 월스트리트 저널(WSJ) 기사 — "OpenAI는 실패하기에는 너무 거대해지고 있는가?(Is OpenAI Becoming Too Big to Fail?)" — 에서 OpenAI의 잠재적 실패가 국가 전체에 "시스템적 위험(systemic risk)"을 초래할 수 있다고 주장합니다. 그의 주장은 이렇습니다: 미국의 GDP는 오로지 7개의 대기업과 몇몇 소규모 기업들 덕분에 성장하고 있습니다. S&P 500은 S&P 10 덕분에 성장하고 있습니다. OpenAI는 이들 중 절반과 계약을 맺고 있으며, 총 1조 달러가 넘습니다. 생성형 AI 혁명의 선두 주자로서, OpenAI의 몰락은 주주 손실과 그에 따른 전체 부문에 대한 불신을 초래할 것입니다(이 시나리오에서 AI 겨울(AI winter)은 우리의 가장 작은 문제일 것입니다). 이것이 바로 OpenAI가 "실패하기에는 너무 거대하다"는 이유입니다. 정부가 개입하여 시스템적 위험이 실제 위험으로 변하는 것을 막을 것이기 때문입니다. 출처: 마이클 A. 아루에(Michael A. Arouet)

히긴스의 주장은 2008년 금융 위기 당시 "실패하기에는 너무 거대했던" 은행들의 사례를 상기시킵니다. 이는 2008년에도 일어났던 일입니다. 히긴스는 문제적인 유사점들을 지적합니다("거짓말 대출(liar loans)과 서브프라임 모기지(subprime mortgages)"를 제외하면): 이러한 거대 기술 기업들과 주식 시장의 그들에 대한 의존성 사이의 연관성은 주목할 만합니다. 이번 세기 초 금융 위기의 교훈은 은행들이 실패하기에는 너무 거대했을 뿐만 아니라, 실패하기에는 너무 상호 연결되어 있었다는 것입니다. 대형 금융 기관들은 복잡한 금융 상품과 수단의 거미줄처럼 얽혀 있었고, 특정 플레이어들이 붕괴 직전에 있을 때 미국 시스템 전체를 무너뜨릴 위협을 가했습니다. 이는 미국 정부가 구제금융 패키지를 가지고 개입하고 다른 이례적인 조치들을 취하게 만들었습니다. AI 기술이 금융, 국방, 의료 등 핵심 인프라에 깊숙이 통합되는 현 상황에서, OpenAI와 같은 선도 기업의 잠재적 불안정성은 단순한 기업의 문제를 넘어설 수 있습니다. 이는 AI 기술의 사회적 파급력에 대한 규제 당국의 주의를 환기시키며, AI 거버넌스와 안전망 구축의 필요성을 더욱 부각시키고 있습니다.

저는 그 주장이 설득력 있다는 것을 인정해야 합니다. OpenAI는 궁극적인 목표로 인공 일반 지능(artificial general intelligence)을 추구하는 AGI 회사라기보다는, AGI가 원래 예상했던 것보다 조금 더 멀리 떨어져 있을 수 있다는 것을 서서히 깨닫고 이제는 생존을 확보하기 위해 서두르고 있는 회사처럼 보입니다. OpenAI는 이미 몰락에서 살아남을 만큼 충분히 거대해졌을까요?

그 점에 대해서는 알트만의 이 능숙한 연기에 찬사를 보냅니다. 첫째, 그는 OpenAI가 모든 인류에게 이익을 주기 위해 AGI를 만들고 싶어 하는 약자(underdog)이며, 인력 부족, 자본 부족의 오픈소스 비영리 AI 연구소라고 말했고, 우리는 그를 믿었습니다. 나중에 그는 희소성 없는 유토피아(post-scarcity utopia)를 실현하고 암 등을 치료하기 위해 예상보다 더 많은 돈이 필요하다고 말했고, 우리는 그를 믿었습니다. 그리고 그는 우리의 꿈이 실현될 수 있도록 OpenAI가 기술 기업 및 미디어와 다각화하고 거래를 해야 하며, 저품질 콘텐츠(slop)와 에로티카(erotica) 및 광고를 만들어야 한다고 말했고, 우리는 그를 믿었습니다. 마지막으로, 우리가 과장과 과도한 약속에서 깨어나고, 그가 자신의 제국의 생존을 확보했다고 말하면, 우리는 분명 그를 믿을 것입니다.

질문은 이겁니다: OpenAI가 구제되는 것이 그렇게 중요한가요? 저는 알트만이 우리에게 말했던 그 모든 것들을 아마도 약간 과장했을 수도 있다는 것을 인정하는 것을 보면서 최대한의 샤덴프로이데(schadenfreude, 남의 불행을 기뻐하는 마음)를 즐길 것입니다. 그러니, 혼란스러운 견해를 얻기 위해 저를 읽으신다면, 운이 좋으신 겁니다. 왜냐하면 이 글은 사실 OpenAI가 실패할 수 있는 모든 이유들의 목록이기 때문입니다. 지상에 추락하기 전에 구제되든 말든 저에게는 중요하지 않습니다. 저는 그저 "내가 말했잖아"라고 말할 수 있기를 바랄 뿐입니다.

자, 여기 있습니다: OpenAI가 생각보다 더 곤경에 처한 다섯 가지 이유.

### 1. 영원한 경쟁자: 구글과 딥마인드(Google and DeepMind)

구글(Google)과 딥마인드(DeepMind)는 OpenAI의 가장 강력한 경쟁자로, 통합 생태계의 강점을 가지고 있습니다. (다른 회사들이 그렇지 않은 이유 목록은 다음과 같습니다: 메타(Meta)는 안정적인 팀을 꾸리려 애쓰고 있고, 앤트로픽(Anthropic)은 선점자 이점(first-mover advantage)이 없으며, xAI는 머스크가 어리석은 농담을 하는 속도보다 더 빠르게 인재를 잃고 있고, 마이크로소프트(Microsoft) AI의 CEO는 무스타파 술레이만(Mustafa Suleyman)이며, 딥시크(DeepSeek)는 충분한 엔비디아(Nvidia) 칩을 확보하는 데 어려움을 겪고 있지만, 오래 필요하지 않을 수도 있습니다. 애플(Apple)은 애플 인텔리전스(Apple Intelligence)를 가지고 있지만, 걱정 마세요, 저도 그게 뭔지 모릅니다.) 그래서, 구글과 딥마인드입니다. 저는 2025년 4월에 이렇게 썼고, 그 주장을 고수합니다: . . . 챗GPT(ChatGPT) 대실패(debacle) 2년 반 후, 구글 딥마인드가 이기고 있습니다. 그들은 지금 너무나 압도적으로 이기고 있어서 "제발, 제발, 더 이상 못 참겠어, 너무 많이 이기고 있잖아!"라고 소리치고 있습니다. 아니, 하지만 정말로 — 저는 OpenAI, 앤트로픽, 메타 등이 단 한 번이라도 이길 수 있는 아주 작은 기회라도 가졌던 유일한 이유가 구글이 한 번 실수했기 때문이 아닐까 궁금합니다. 이제는 그렇지 않습니다. 세부 사항은 바뀌었습니다 — OpenAI는 GPT-5와 수많은 신제품을 출시했고, 구글은 제품군을 강화했습니다 — 하지만 주장의 본질은 동일합니다: 검색 거대 기업은 모든 주요 AI 부문을 아우르고 있습니다: 모델(가격 및 성능 전반), 에이전트(agents), 멀티모달(multimodal), 오픈소스(open-source), 그리고 모든 보완적인 수직 계열: 검색, 데이터, 하드웨어, 클라우드, 기기, 앱. 아마도 가장 중요한 것은, 구글이 엄청난 수익(지난 분기 1,000억 달러)과 AI 사용 수치(제미니(Gemini) 월간 활성 사용자 6억 5천만 명)를 기록하고 있으며, 이는 챗GPT의 주간 활성 사용자 8억 명과 경쟁한다는 점입니다. 출처: 순다르 피차이(Sundar Pichai) 이것이 의미하는 바는, 구글이 챗봇 시장 점유율에서 순위를 올리면서 기술을 계속 개선하는 동안, 가격을 계속 낮춰 OpenAI의 유일한 수익원인 챗GPT에 대한 강력한 지배력을 행사할 수 있다는 것입니다. 이 시점에서 GPT, 클로드(Claude), 제미니 등 사이에는 최고 수준을 제외하고는 큰 차이가 없습니다. 그들은 대부분 상호 교환 가능합니다. 구글이 아니라 OpenAI가 시간에 쫓기고 있습니다. 그래서 알트만은 필요하다면 OpenAI에 생명줄을 제공할 수 있는 다른 시장에서 입지를 구축하려고 노력하고 있습니다. 어떤 사람들은 OpenAI의 진정한 경쟁자는 구글이나 앤트로픽이 아니라 메타라고 말하며, 따라서 알트만은 구글에 대해 걱정할 필요가 없다고 합니다. 저는 단호히 반대합니다. 출처: 밈 풀(the meme pool) 이러한 생각은 사람들이 챗GPT의 훈련 및 추론 비용을 충당하는 데 필요한 만큼의 금액을 지불할 의사가 없다는 것을 OpenAI가 깨닫게 되면, 소셜 미디어 + 광고 수익을 추진해야 할 것(즉, 메타; 디 인포메이션(The Information)은 이를 "OpenAI의 메타화(Meta-fication of OpenAI)"라고 부릅니다)이라는 사실에서 비롯됩니다. 챗GPT는 약 4천만 명의 유료 구독자(전체 활성 사용자 기반의 5%)를 보유하고 있으며, OpenAI는 지난 분기에 여전히 120억 달러의 손실을 입었습니다. 사용자 수익이 빠르게 성장하고 있다고 해도, 이는 분명 그들에게 한 줄기 희망이지만, 한계가 있습니다(메타와 구글이 그렇게 많은 수익을 내는 이유는 우리가 돈을 지불하는 것에 의존하는 것이 아니라 광고주의 돈에 의존하기 때문입니다). "음," 당신은 말할 수도 있습니다, "개별 소비자들이 지불하지 않더라도, 기업들은 지불할 것이다." 맞습니다, 이는 다음 요점으로 이어집니다.

### 2. 앤트로픽이 AI 기업 시장을 장악하고 있다

이것은 큰 문제입니다. 벤처 캐피탈(VC) 회사인 멘로 벤처스(Menlo Ventures)는 지난 몇 년간 기업 시장의 진화를 다루고 있습니다. 최근 그들은 새로운 보고서를 발표했는데, 2022년 OpenAI가 챗GPT를 출시한 이래 처음으로 기업 시장에서 앤트로픽에게 선두를 내주었다는 것을 밝혔습니다. (현재 추세로 볼 때, 저는 구글도 2026년까지 OpenAI를 앞지를 것이라고 믿으며, 이는 제 주장을 더욱 강화합니다.) 출처: 멘로 벤처스 2023년 말까지 OpenAI는 기업 LLM(대규모 언어 모델) 시장의 50%를 장악했지만, 초기 선두는 약화되었습니다. 오늘날, OpenAI는 기업 사용량의 25%만을 차지하며 — 2년 전 보유했던 것의 절반입니다. 앤트로픽은 기업 AI 시장에서 32%로 새로운 선두 주자이며, 최근 몇 달 동안 강한 성장을 보인 OpenAI와 구글(20%)을 앞서고 있습니다. 메타의 라마(Llama)는 9%를 차지하며, 딥시크는 연초에 세간의 이목을 끄는 출시에도 불구하고 1%만을 차지합니다. 이러한 시장 변화는 기업 고객들이 단순히 모델 성능을 넘어, 신뢰성, 안전성, 그리고 특정 비즈니스 요구사항에 최적화된 솔루션을 중요하게 여기기 시작했음을 보여줍니다. 앤트로픽의 클로드(Claude) 모델은 '헌법적 AI(Constitutional AI)' 접근 방식을 통해 윤리적 사용과 안전성을 강조하며, 특히 코딩(code generation) 및 복잡한 문서 처리와 같은 기업의 핵심 업무에서 높은 평가를 받고 있습니다. 간단한 해석은 이렇습니다: 코딩은 킬러 앱(killer app)이며 기업들은 OpenAI의 모델(코덱스(Codex), GPT-5 등)보다 앤트로픽의 모델(클로드 코드(Claude Code), 소네트 4.5(Sonnet 4.5) 등)을 선호합니다. 멘로 벤처스는 다음과 같이 썼습니다: "클로드는 코드 생성(code generation)을 위한 개발자들의 최고의 선택이 되었고, OpenAI(21%)의 두 배가 넘는 42%의 시장 점유율을 차지했습니다." (앤트로픽은 전 세계적으로 OpenAI의 챗GPT 유료 구독자 수만큼의 클로드 구독자를 보유하고 있으며, 약 4천만 명에 달한다는 점을 주목하십시오. 이는 이 통계를 더욱 놀랍게 만듭니다.) 앤트로픽은 기업 성장에 대해 낙관적으로 2028년까지 수익성을 예상하는 반면, OpenAI는 2029년까지 예상합니다. 만약 이것이 실현된다면, 둘 다 전례 없는 성장을 기록할 것입니다(OpenAI의 수익 예상치가 앤트로픽보다 높은 이유는 훨씬 더 많은 사용자를 서비스하기 때문에 더 많은 돈을 벌지만, 더 높은 비용이 발생하기 때문입니다). 다음은 그들이 서로 그리고 다른 기술 기업들과 어떻게 비교되는지 보여줍니다: 출처: 디 인포메이션 출처: 에포크 AI(Epoch AI) 하지만 기업 시장을 선도하는 것은 수익 점유율을 넘어 중요합니다: AI 기업들에게 중요한 것은 대규모 계약입니다. OpenAI는 월 20달러를 지불하는 4천만 명의 사람들을 보유하여 월 8억 달러에 달하는 것보다 국방부(DoD)와 2억 달러 규모의 계약을 체결한 것에 더 기뻐합니다. 왜일까요? 구독은 왔다가 사라지고, 사람들의 충성도는 취약하며, 일반 사용자는 세상을 변화시킬 힘이 없기 때문입니다. 그러나 국방부는 기술 기업이 얻을 수 있는 최고의 고객입니다. (그래서 실리콘 밸리가 군사화되었습니다.) 제가 이 직관에 반하는 주장 — 국방부의 2억 달러가 구독 수익 100억 달러보다 OpenAI에게 더 가치 있다는 — 을 믿는 이유는 챗GPT가 영원히 기업-소비자 간(B2C) 제품으로 남지 않을 것이기 때문입니다. 생성형 AI는 근본적으로 기업-기업 간(B2B) 기술입니다. 가치 있으려면 — 그리고 수익이 1,000억 달러 이상이 되고 시간이 지나도 안정적이려면 — 전기나 인터넷처럼 경제 전반에 걸쳐 기본으로 자리 잡아야 합니다. 우리가 모두 독립형 챗봇(standalone chatbots)을 사용하는 데 갇혀 있다는 사실은 우리가 초기 단계에 있다는 것을 보여줍니다(또는, 반대로, 기술이 너무 비싸서 다른 것을 할 수 없다는 것을 보여주지만, 그것은 또 다른 문제입니다). OpenAI는 당신에게 월 20달러짜리 구독을 팔고 싶은 것이 아니라, 당신의 고용주에게 월 2만 달러짜리 서비스를 팔고 싶어 합니다. OpenAI에게 B2B 시장 점유율을 잃는 것은 단기적으로는 무시할 수 있는 성가신 일일 수 있지만, 장기적으로는 분명 실존적 위험입니다.

### 3. 샘 알트만의 일관성 없는 솔직함

OpenAI의 공동 창립자인 일론 머스크(Elon Musk)는 샘 알트만이 비영리에서 제한적 영리(capped-profit)로, 그리고 영리 기업으로의 재편성을 강행한 것에 대해 불만을 품고 있습니다. 그 결과, 그는 OpenAI를 고소했습니다. 소송은 진행 중입니다. 해당 소송을 위한 증언에서 OpenAI의 공동 창립자이자 전 수석 과학자였던 일리야 수츠케버(Ilya Sutskever)는 그와 전 CTO 미라 무라티(Mira Murati)가 2023년 11월 이사회 쿠데타가 일어나기 1년 전부터 샘 알트만을 CEO에서 해임하는 것을 고려하고 있었다고 밝혔습니다. 그 이유는, 그의 증언(녹취록) 중에 공개된 "계획 문서"에서 인용하자면, "샘은 일관되게 거짓말을 하고, 임원들을 약화시키며, 임원들끼리 서로 대립하게 만드는 패턴을 보인다"는 것입니다. 이는 2023년 쿠데타 이후 이사회가 알트만의 행동 패턴에 대해 작성한 보고서와 일치합니다: 알트만 씨의 퇴임은 이사회의 신중한 검토 과정에 따른 것으로, 이사회는 그가 이사회와의 소통에서 일관되게 솔직하지 않아 이사회가 책임을 다하는 능력을 방해했다고 결론 내렸습니다. 이사회는 더 이상 OpenAI를 계속 이끌어갈 그의 능력에 신뢰가 없습니다. 일론 머스크를 포함한 OpenAI나 어떤 경쟁자와도 독립적으로 작성되었으며 "기업의 책임과 공익 연구에 대한 헌신"에 따라 작성된 보고서인 'OpenAI 파일(The OpenAI Files)'에는 유사한 주장의 더 큰 데이터베이스가 있습니다. 다음은 OpenAI, 특히 샘 알트만에 대한 소송과 관련된 몇 가지 예시입니다: *   미라 무라티(Mira Murati): "샘이 우리를 AGI로 이끄는 것에 대해 편안하게 느끼지 않습니다." *   일리야 수츠케버(Ilya Sutskever): "샘이 AGI의 버튼을 누를 사람이라고 생각하지 않습니다." *   제프리 어빙(Geoffrey Irving): "OpenAI에서 2년간 그를 위해 일한 후 샘에 대한 나의 선입견은 매우 부정적입니다." *   스콧 애런슨(Scott Aaronson): "많은 사람들에게 이제 이전 이사회가 샘이 실제로 OpenAI를 비영리 사명에서 멀리 떨어뜨릴 계획이었다는 두려움에 대해 100% 정당화된 것처럼 보입니다. . ." *   다리오(Dario)와 다니엘라 아모데이(Daniela Amodei) [AI 제국(Empire of AI)에서]: "*“*그들 주변 사람들에게 아모데이 남매는 알트만의 전술을 '가스라이팅(gaslighting)'과 '심리적 학대(psychological abuse)'라고 묘사했습니다." 덜 알려진 OpenAI 전 직원들의 증언도 많지만, 그들 모두 동일한 패턴을 드러냅니다. 저는 알트만이 전시 CEO이자 거래 성사형 CEO라는 것을 이해하지만, 그가 이 민감한 다음 단계를 헤쳐나가기 위해 OpenAI에 필요한 CEO일까요? 앤트로픽의 성공이 다리오 아모데이 CEO의 더 신뢰할 수 있는 태도 덕분인지, 아니면 구글의 회복이 딥마인드의 데미스 하사비스(Demis Hassabis) CEO의 진실성 덕분인지 궁금하지 않을 수 없습니다. 저는 매우 중요하다고 생각합니다. 제가 업계의 과장과 허풍에 대한 선호를 비판하는 글에서 썼듯이(알트만만 그런 것은 아니지만, 그는 논쟁의 여지 없이 그 최대의 대표자입니다): "내용이 아니라 말이 유일하게 중요한 것처럼 게임을 한다면, 세상이 당신에게도 같은 기준을 적용할 때 놀라지 마라. . . . 만약 허풍이 [당신의] 통화이고 빈말이 [당신의] 무기라면, [당신은] 그에 상응하는 대가를 받을 수도 있다." 스페인 속담처럼, 거짓말쟁이는 절름발이보다 먼저 잡힙니다.

### 4. 알트만은 어려운 질문을 받는 것을 좋아하지 않는다

많은 분들이 아마 이 영상 을 이미 보셨을 겁니다. 샘 알트만과 마이크로소프트 CEO 사티아 나델라(Satya Nadella)가 브래드 거스트너(Brad Gerstner)의 팟캐스트(거스트너는 OpenAI 주주입니다)에 출연한 클립입니다: 영상을 보고 싶지 않으신 분들을 위해 관련 부분(11:54)의 녹취록을 첨부합니다: BG: 시장에 걸려 있는 가장 큰 질문은 이겁니다: 130억 달러의 수익을 내는 회사가 어떻게 1조 4천억 달러의 지출 약속을 할 수 있습니까? 샘, 비판을 들어보셨을 겁니다— SA (끼어들며): 우선, 우리는 그보다 훨씬 더 많은 수익을 내고 있습니다. 둘째, 브래드, 주식을 팔고 싶다면 구매자를 찾아주겠습니다. . . . 됐습니다. OpenAI 주식을 사고 싶어 하는 사람들이 많을 겁니다— BG (끼어들며): 저를 포함해서요. 저를 포함해서요. 알트만은 수익이 "가파르게 성장하고 있다"고 말하며, 계속 가파르게 성장할 것으로 예상한다고 덧붙였습니다. 저를 놀라게 한 것은 현재 수익과 지출 약속 사이의 대조를 고려할 때 완벽하게 합리적인 질문에 대한 알트만의 즉각적인 반응이었습니다: "당신은 130억 달러를 벌고 있는데(두 배가 된다고 해도 정말 중요할까? 말도 안 돼), 어떻게 1조 4천억 달러를 쓸 겁니까?" 합리적입니다. "그 모든 컴퓨팅(compute)과 에너지 비용을 지불할 수 있도록 수익을 100배로 늘릴 것인가요?" 합리적입니다. 거스트너는 자신이 투자자라는 사실에 기뻐한다고 말했는데, 이는 그가 불신이나 두려움 때문이 아니라 실사(due diligence) 차원에서 묻는 것임을 의미합니다: "관심 있는 투자자로서, 어떻게 이를 달성할 계획인지 설명해 줄 수 있습니까?" 논리로 답할 것인지 아니면 짜증으로 답할 것인지는 선택의 문제입니다. 참고로(알트만의 공로를 인정하자면), OpenAI의 보고된 수익(알트만은 그보다 더 많은 수익을 내고 있다고 말하며, 그럴 수도 있지만 공식 데이터는 없습니다)은 지난 몇 년간 급격하게 성장했습니다(위 그래프에서 보셨듯이), 2023년 10억 달러에서 2024년 40억 달러, 2025년 130억 달러로, 2029년까지 1,000억 달러 이상으로 예상됩니다. 출처: 디 인포메이션 그러나 제가 이미 두 번 언급한 새로운 데이터 포인트가 있습니다. 이는 일부 사람들이 금융 고고학(financial archaeology)에 정말 능숙하기 때문에 우리가 알게 된 것입니다: OpenAI는 지난 분기에만 120억 달러의 손실을 기록했습니다. 이는 앤트로픽의 기업 시장 선두와 구글의 업계 전반의 강력한 지배력을 더욱 강화할 뿐입니다. 다시 말하지만, 2년 만에 10억 달러에서 130억 달러로 성장하는 것은 엄청난 성장입니다. 하지만 AI 모델처럼 확장될까요? 두고 볼 일입니다. AI 모델 훈련 및 운영에 필요한 천문학적인 컴퓨팅(compute) 및 에너지 비용을 감당하기 위한 명확하고 현실적인 수익 모델이 제시되지 않는다면, 투자자들의 신뢰는 점차 약화될 수밖에 없습니다.

### 5. 지나친 다각화는 위험한 사업이다

이것은 위에서 언급한 모든 것의 원인입니다: OpenAI는 한 번에 너무 많은 것을 시도하고 있습니다. 챗봇을 넘어 브라우저, 기기, 칩 설계, 소셜 미디어 등 전방위적인 사업 확장은 막대한 자원과 인력을 소모하며 핵심 역량에 대한 집중도를 약화시킬 수 있습니다. 각 분야에는 이미 강력한 기존 선두 주자들이 존재하며, OpenAI가 이 모든 분야에서 동시에 경쟁 우위를 확보하는 것은 매우 어려운 일입니다. 이러한 지나친 확장은 재정적 부담을 가중시키고, 핵심 AI 연구 개발에 필요한 자원을 분산시켜 궁극적으로는 주력 모델의 경쟁력 약화로 이어질 수 있습니다. 여러 전선에서 동시에 싸우는 것은 AGI 연구에 대한 집중력을 떨어뜨리고, 예상치 못한 곳에서 취약점을 노출할 위험이 있습니다.

결론적으로, OpenAI가 현재 직면한 도전 과제들은 단순히 단일 기업의 문제를 넘어 AI 산업 전체의 성숙통(growing pains)을 반영합니다. "실패하기에는 너무 거대하다"는 주장은 그들의 시장 영향력을 인정하는 것이지만, 동시에 그들이 감당해야 할 책임과 위험이 얼마나 큰지를 보여줍니다. 샘 알트만 CEO의 리더십 스타일, 경쟁사들의 맹렬한 추격, 그리고 지속 가능한 수익 모델에 대한 불확실성은 OpenAI의 미래에 대한 신중한 접근을 요구합니다. AI 기술이 진정으로 인류에게 혜택을 주기 위해서는 기술적 진보뿐만 아니라 윤리적 책임, 투명한 거버넌스, 그리고 건전한 비즈니스 생태계가 함께 발전해야 합니다.