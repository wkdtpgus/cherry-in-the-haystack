AI 엔지니어 코드 서밋(11월 20-22일, 뉴욕) 참가 신청이 시작되었습니다. 생성형 비디오(Generative Video)와 인공지능의 윤리적 사용은 2025년의 주요 트렌드 중 하나였습니다. NBA 결승전 중 방영된 Kalshi 광고처럼 주류 미디어에서도 볼 수 있으며, 개인화된 학습 경험 또한 주류 미디어에서 찾아볼 수 있습니다. 오늘 저희는 이러한 모델 다수의 추론(inference)을 지원하는 숨은 주역인 Fal.ai(잘 알려진 일부 비공개 소스 이미지 및 비디오 확산 모델 포함)에 대해 다룹니다. 이들은 올해에만 약 1억 달러의 신규 매출을 추가할 것으로 예상되며, 그중 비디오가 차지하는 비중은 점점 더 커지고 있습니다. 하지만 불과 2년 전만 해도 이들은 dbt 데이터 파이프라인을 위한 도구를 만들고 있었습니다! Fal은 이제 플랫폼에서 600개 이상의 다양한 AI 모델을 호스팅하며, 성능 향상을 위해 100개 이상의 맞춤형 CUDA 커널(CUDA kernels)로 구동됩니다. 저희는 이 팟캐스트를 통해 생성형 모델의 역사와 그 역사 속 주요 변곡점이 무엇이었는지 요약해보고자 했습니다. 즐겁게 감상해주세요!

**Fal의 모델 역사**
아래 모든 링크는 참고 자료에서 확인하세요.

*   **스테이블 디퓨전 1.5**
    *   Fal이 최적화된 추론 호스팅으로 방향을 전환했을 때 첫 번째 주요 히트작으로, 시장의 변화를 감지하게 했습니다.
    *   광범위한 미세 조정(fine-tuning) 생태계로 매우 인기를 얻으며 새로운 비즈니스 기회를 창출했습니다.
    *   빠르고, 저렴하며, 신뢰할 수 있어 LoRA와 함께 오늘날에도 여전히 사용됩니다.
*   **스테이블 디퓨전 2.1**
    *   큰 주목을 받지 못한 채 사라진 "약간의 실패작"으로 묘사됨.
*   **스테이블 디퓨전 XL(SDXL)**
    *   FAL에 첫 백만 달러 매출을 안겨준 최초의 주요 모델로, 기업 성장의 발판을 마련했습니다.
    *   미세 조정(fine-tuning) 생태계(LoRA)를 폭발적으로 성장시킴.
    *   **SDXL Lightning**: 더 빠른 생성을 위해 ByteDance가 만든 증류 버전(distilled version)으로, 모바일 환경에 최적화된 경량화된 모델입니다.
*   **스테이블 디퓨전 3(SD3)**
    *   "약간의 논란이 있었음"
    *   팀이 Stability를 떠나 Black Forest Labs를 설립.
*   **Flux 모델(Flux Models) (Black Forest Labs)**
    *   "상업적으로 사용 가능하고, 엔터프라이즈급" 모델의 장벽을 처음으로 허물었음이 오픈소스 솔루션을 통해 증명되었습니다.
    *   첫 달에 FAL의 매출을 2백만 달러에서 1천만 달러로 급증시켰으며, 그 후 2천만 달러로 추가 성장했습니다.
    *   세 가지 버전:
        *   **Schnell**: Apache 2 라이선스, 극도로 증류됨, 저품질을 위한 4단계 생성
        *   **Dev**: 수익 공유가 있는 비상업적 라이선스
        *   **Pro**: 호스팅을 위해 협업 필요
*   **Gemini 이미지 모델**
    *   Google의 자기회귀 이미지 모델(autoregressive image models), 과소평가된 것으로 간주됨.
*   **이미지 편집 모델**
    *   **Flux Context (Dev)**
        *   5월 말 출시
        *   인기 있는 편집 모델
    *   **Qwen Image/Qwen Imager**
        *   팟캐스트 2주 전 출시
        *   현재 Flux Context Dev를 능가함
        *   비디오 모델의 단일 프레임을 사용할 때 매우 우수한 텍스트-투-이미지(text-to-image) 성능
    *   **Stepfun의 Hydream**
        *   소규모 중국 연구소의 이미지 편집 모델
    *   **VivaGo**
        *   중국 연구소의 또 다른 편집 모델
*   **생성형 비디오 모델**
    *   **Sora**
        *   가능성의 문을 연 OpenAI의 모델로, 초기 연구자들에게 동기를 부여했지만 기술 발전은 예상보다 빠르게 진행되었습니다.
    *   **Veo3 (Google DeepMind)**
        *   사운드가 포함된 "사용 가능한 텍스트-투-비디오(text-to-video) 구성 요소"를 만듦으로써 음성 인식 기술을 통해 접근성을 크게 향상시켰습니다.
        *   운영 비용이 매우 비쌈
        *   대화, 타이밍, 립싱크에 탁월함
        *   최고의 텍스트-투-스피치(text-to-speech) 모델 중 하나로도 기능함
    *   **Hun Yuan Video**
        *   중국 모델, "꽤 괜찮다"고 평가됨
    *   **Mochi (Genmo)**
        *   초기에는 품질이 다소 미흡했음
    *   **One (Alibaba)**
        *   "엄청나게 좋은 모델"로, 새로운 머신러닝 알고리즘을 통해 뛰어난 성능을 보여주었습니다.
        *   최근 새로운 버전 출시
        *   480p 드래프트 모드를 5초 이내에 실행 가능
        *   720p 전체 해상도를 20초 만에 실행 (10초 목표)
    *   **Minimax**
        *   중국 비디오 모델 파트너
    *   **Kling (Kuaishou)**
        *   중국 비디오 모델 파트너
    *   **Movie Jam**
        *   MMDiT 아키텍처가 불필요하다고 주장하는 연구 논문
    *   **Multitalk**
        *   One의 사후 학습 버전(post-trained version)
        *   대화에는 좋지만 너무 전문화된 시스템은 종종 일반화 능력을 잃음으로써 유연성이 저해됩니다.
        *   말하는 얼굴만 생성 가능
*   **오디오/음악 모델**
    *   **PlayHD/PlayAI**
        *   Fal이 추론 최적화를 도움
        *   일부는 자기회귀 모델(autoregressive models) 사용
        *   일부는 확산 기반 접근법(diffusion-based approaches) 사용
    *   **Notorious**
        *   확산 기반 오디오 생성으로 유명함

**참고 자료**
*   Fal.ai
*   Gorkem
*   Bathuan
*   Kuaishou
*   Minimax
*   Genmo
*   PJ Ace
*   Black Forest Labs
*   Stable Diffusion
*   Stable Diffusion 1.5
*   Stable Diffusion 2.1
*   Stable Diffusion XL (STXL)
*   Flux Models
*   PixArt
*   Qwen/Qwen-VL
*   PlayHT
*   SDXL Lightning
*   AnimateDiff
*   Tail Draw
*   HunYuan
*   Hydream
*   OmniHuman
*   Seedream
*   Multitalk
*   Genie (Google’s world model)
*   ComfyUI
*   Scaling Rectified Flow of Transformers
*   Diffusion Transformers
*   Consistency Models

**타임라인**
*   [00:00:00] 서론: AI의 새로운 시대
*   [00:04:29] 주요 AI 모델의 역사와 Fal.ai 및 기술 발전에 미친 영향
*   [00:07:06] 확산 모델 전문화로의 방향 전환
*   [00:10:46] CUDA 커널 작성의 중요성
*   [00:15:50] 지연 시간의 중요성과 사용자 경험에 미치는 영향
*   [00:17:56] 오픈 모델의 가용성이 Fal의 성장 및 AI 생태계에 미친 영향
*   [00:19:00] 비공개 소스 모델 제공업체와의 협력 사례
*   [00:21:19] 오디오 및 음악 워크로드를 위한 추론 최적화
*   [00:29:10] 비디오 생성을 위한 성능 개선 동향
*   [00:29:47] OpenAI와 Gemini의 자기회귀 이미지 생성 기술
*   [00:34:45] 제어 가능한 비디오 생성을 위한 월드 모델의 잠재력
*   [00:36:26] 중국 오픈소스 비디오 모델의 부상과 영향
*   [00:39:30] AI 기술의 수익화 전략 및 수익 공유 모델
*   [00:42:48] 콘텐츠 중재 및 엔터프라이즈 콘텐츠 안전성 문제
*   [00:45:10] 스타트업 론칭 비디오 및 생성형 비디오 도입 트렌드
*   [00:46:59] LoRA 기반 맞춤화의 확산
*   [00:47:11] ComfyUI, 모델 체이닝, 그리고 엔터프라이즈 워크플로우의 진화
*   [00:51:58] 생성형 미디어의 다양한 응용 분야
*   [00:54:15] 스타트업을 위한 제안 및 미래 기회
*   [00:56:34] Fal 기반 스타트업 창업 아이디어
*   [01:00:29] Fal.ai의 채용 및 팀 빌딩
*   [01:03:27] 뛰어난 엔지니어의 조건

**전문**
Alessio [00:00:03]: 안녕하세요, 여러분. Latent Space 팟캐스트(AI 혁신 팟캐스트)에 오신 것을 환영합니다. 저는 Kernel Labs의 창업자 알레시오이고, SmolAI의 창업자 스윅스와 함께합니다.

Swyx [00:00:09]: 안녕하세요. 오늘 스튜디오에 Fal의 고르켐과 바투한을 모시게 되어 정말 기쁩니다. 환영합니다. 네, 초대해 주셔서 감사합니다. 오랫동안 애청했는데, 드디어 제 생각을 나눌 기회가 생겼습니다.

Swyx [00:00:21]: 고르켐, 당신과 저는 회사가 아직 features and labels였을 때부터, 당신이 막 아마존에서 나왔을 때부터 꽤 오래 알고 지냈죠. 피치가 뭐였는지 기억도 안 나네요. 솔직히 제 노트를 다시 봐야겠지만, 런타임을 최적화하고 있었죠.

Gorkem [00:00:33]: 네, 처음에는 데이터 피처 스토어를 만들고 있었고, 그 다음 한 발 물러서서 클라우드에 파이썬 런타임을 만들기로 결정했습니다. 그리고 그게 추론 시스템으로 발전했고, 오늘날의 Fal, 즉 생성형 미디어 플랫폼으로 진화했습니다. 저희는 이미지, 비디오, 오디오 모델의 추론을 최적화하지만, 그보다 훨씬 더 많은 일을 합니다. 기본적으로 개발자들을 위한 이 전체 생성형 미디어 분야를 장악하려고 노력하고 있습니다.

Swyx [00:01:01]: 네, 놀랍네요. 그 여정에 대해서도 이야기해 볼 수 있겠네요. 바투한도 소개하고 싶습니다. 저희는 서로 알게 된 지 얼마 안 됐지만, 제 밋업에 몇 번 오셨었죠. 엔지니어링 총괄이시죠.

Batuhan [00:01:09]: 네, Fal에서 엔지니어링을 이끌고 있습니다. 이 자리에 함께하게 되어 기쁩니다.

Swyx [00:01:14]: 당신의 여정은 어땠나요?

Batuhan [00:01:16]: 2021년에 버케이가 막 회사를 시작할 때 만났습니다. 시드 라운드 직전이었죠. 버케이와 고르켐과 온라인에서 만났습니다. 저희 둘 다 터키인이라서 그게 연결고리가 되었던 것 같아요. 그냥 만났는데 그들이 "우리와 함께하지 않을래요?"라고 하더군요. 저는 파이썬 언어의 핵심 개발자 중 한 명이어서 파이썬 언어 주변의 개발자 도구에 대해 정말 좋은 경험이 있었습니다. 그래서 파이썬 클라우드를 만들기 위해 이곳에 오기 시작했고, 그것이 오늘날 우리가 만들고 있는 이 추론 엔진과 생성형 미디어 클라우드로 발전했습니다.

Swyx [00:01:43]: 그리고 이제는 파이썬보다는, 글쎄요, CUDA, 맞춤형 커널과 더 많은 시간을 보내시죠.

Alessio [00:01:50]: 네, 네, 네. 네. 모던 데이터 스택이 나왔을 때의 DBT Fal이 기억나네요. Fal의 규모에 대해 간단히 설명해 주실 수 있나요? 방금 1억 2,500만 달러를 투자받으셨죠. 정말로요. 맞습니다. 그 얘기도 해보죠. 네. 제가 당신들의 초기 라운드 중 하나를 패스했던 이유죠. 그것도 짚어볼 수 있겠네요. 개발자는 몇 명이나 되고, 몇 개의 모델을 서비스하며, 그 외에 다른 멋진 숫자들은요?

Gorkem [00:02:11]: 플랫폼에 약 200만 명의 개발자가 있습니다. 오랫동안 깃허브 로그인이 필요했는데 최근에 바뀌었습니다. 그래서 깃허브 계정이 있는 모든 사람을 개발자로 가정하고 있습니다. 플랫폼에는 약 350개의 모델이 있습니다. 대부분 이미지, 비디오, 오디오 모델입니다. 처음에는 이미지만 있었고, 그 다음에 오디오를 추가했으며, 이 분야가 비디오로도 발전했습니다. 네, 그게 대략적인 규모입니다. 저희는 방금 시리즈 C 라운드를 발표했고, 지난 1년 동안 많이 성장했으며, 지금도 계속되고 있습니다. 네.

Alessio [00:02:50]: 아주 멋진 시리즈 C 파티를 하셨더군요. 그리고 매출이 1억 달러가 넘으셨죠? 이는 단순한 개발자들이 시험 삼아 사용해보는 수준이 아니라는 거죠. 맞습니다. 네, 대단하네요. 350개 모델이라고 하셨는데, 그게 여러분이 서비스할 수 있는 모든 모델의 몇 퍼센트 정도 되나요? 특히 어떤 분야에서는요.

Batuhan [00:03:08]: 이 모델들의 사후 학습된 버전은 무한히 많습니다. 저희는 스택의 빈틈을 메우는, 즉 격차를 채우는 모델을 제공하려고 노력합니다. 그래서 저희가 가진 다른 모델들과 비교했을 때 어떤 면에서든 현저히 떨어지는 모델은 추가하지 않습니다. 저희는 고객의 요구를 해결하는 독특한 모델을 가져오려고 노력합니다. 그래서 이 350개의 모델이 있는 겁니다. 텍스트-이미지 모델이 20~30개 정도 있지만, 그중 하나는 로고 생성에 뛰어나고, 다른 하나는 사람 얼굴 생성에 뛰어납니다. 그럼에도 불구하고, 모든 모델이 독특한 개성을 가지고 있는 거죠. 하지만 모든 면에서 현저히 성능이 떨어지는 모델은 플랫폼에 추가하지 않습니다. 그래서 저희가 추가할 수 있는 모델은 무한히 많습니다. 자체 평가에 의존하시나요, 아니면 커뮤니티가 말해주는 것에 의존하시나요? 저희는 주로 자체 평가에 의존할 뿐만 아니라, 저희도 커뮤니티에 속해 있기 때문에 커뮤니티를 잘 따라서 차세대 앱에 어떤 것이 등장할지 지켜봅니다. 그래서 저희가 좋은 직감을 가지고 무언가 뜰 것 같다고 생각하면 그냥 추가합니다. 네.

Swyx [00:03:59]: 제가 알기로는 자체 평가를 발표한 적은 없으시죠? 아뇨. 아뇨, 하지 않습니다. 내부 자료입니다. 그럼 커뮤니티는 레딧, 트위터인가요?

Batuhan [00:04:05]: 트위터, 레딧, 허깅 페이스, 허깅 페이스나 다른 데모에서 모델들이 얼마나 인기 있는지 보는 거죠. 알겠습니다.

Gorkem [00:04:12]: 이 정보는 어디서 얻는지 명확히 밝히는 것이 중요합니다. 이 일의 가장 좋은 점은 모델 출시일의 아드레날린 분출, 팀 전체가 무언가를 급하게 만들어 출시하려는 노력입니다. 그리고 그게 매주 일어납니다. 그렇죠. 매주가 흥미진진합니다.

Alessio [00:04:27]: 가장 큰 급등을 보였던 모델들의 간략한 역사를 짚어볼 수 있을까요? 아마도 사용량 측면에서요. 제 생각에 모두가 스테이블 디퓨전을 알고 있고, 그 다음에는 Flux 모델, 그리고 Black Forest Labs 같은 것들이 있죠. 여러 다른 이정표들이 있잖아요.

Batuhan [00:04:40]: 역사적으로 볼 때, 가장 큰, 최초의 히트작은 스테이블 디퓨전 1.5였습니다. 그때가 바로 저희가 Fal, 즉 생성형 미디어 클라우드라는 새로운 패러다임으로 실제로 방향을 전환한 시점이었습니다. 저희는 그것을 호스팅하기 시작했습니다. 저희는 서버리스 런타임을 가지고 있었고 모두가 스테이블 디퓨전 1.5를 직접 실행하고 있었는데, 활용도 면에서 끔찍하고 최적화도 하지 않고 있다는 것을 알아차렸습니다. 그래서 저희는 이것의 최적화된 버전을 제공하기로 했습니다. API 2.0에 준비되어 있고, 확장 가능하며, 사람들이 파이썬 코드를 배포할 필요가 없도록 말이죠. 왜냐하면 저희는 제품 엔지니어들이 사용하기 시작하길 원했고, 모바일 엔지니어들이 사용하기 시작하길 원했기 때문입니다. 그래서 저희는 스테이블 디퓨전 1.5를 제공하기 시작했습니다. 매우 인기가 많았고, 그 주변의 파인튜닝도 매우 인기가 많았습니다. 스테이블 디퓨전 2.1이 나왔지만, 약간 실패작이어서 그다지 주목을 받지 못했습니다. 그리고 STXL이 나왔는데, 이것이 저희에게 첫 백만 달러의 매출을 안겨준 최초의 주요 모델이었습니다. 그리고 STXL과 함께, 당연히 작은 파인튜닝 생태계도 폭발적으로 성장하려고 했습니다. 사람들은 자신의 얼굴, 물건 등을 파인튜닝하기 시작했고, LORA를 이용한 생성이 매우 인기를 끌기 시작했습니다. 그리고 스테이블 디퓨전 XL 이후에는 약간의 조용한 시기가 있었습니다. 아시다시피, ST3는 약간의 논란이 있었고, Stability의 팀이 떠나 Black Forest Labs를 시작했고, 그들이 Flux 모델을 출시했습니다. 그리고 그것이 상업적으로 사용 가능한, 엔터프라이즈급의 훌륭한 모델이라는 장벽에 도달한 첫 번째 모델이었습니다. Flux 모델 출시 첫 달에 저희는 매출이 200만 달러에서 1000만 달러로 뛰었습니다. 엄청난 도약이었죠. 다음 달에는 280만 달러였습니다. 거기서부터 계속 성장하기 시작했습니다. 그리고 비디오 모델이 등장하기 시작했습니다. 저희는 Luma Labs와 파트너십을 맺었고, 중국의 다른 비디오 모델 회사들과도 파트너십을 맺었습니다. Kling, Kuaishou, Minimax와 파트너십을 맺었고, 이 모델들로 인해 또 다른 시장 부문이 창출되어 큰 도약을 이루었습니다. 그리고 마지막으로 가장 큰 것은 VO3였습니다. 이것이 실제로 사용 가능한 텍스트-투-비디오 구성 요소를 만들었습니다. 이전에는 텍스트-투-비디오가 매우 지루하고 소리 없는 비디오여서 즐거움을 얻을 수 없었지만, 이제는 정말 훌륭한 경험이 되었습니다. 온라인에서 보는 모든 밈, 모든 광고를 만들 수 있습니다. 그래서 Google, DeepMind와 VO3를 위해 파트너십을 맺은 것은 저희에게 또 다른 큰 도약이었습니다.

Swyx [00:06:41]: 네, 정말 생성형 미디어의 역사를 잘 요약해 주셨네요. 그래서 그 부분에 대해 더 깊이 파고들고 싶었습니다. 왜냐하면 당연히 비디오에 대해 깊이 파고들 수 있지만, 그 전에 다루고 싶었던 이미지 측면의 전체 역사가 있기 때문입니다. 확실히 시작하고 싶었던 것은 바로 방향 전환 결정이었습니다. 그 점을 더 깊이 파고들고 싶습니다. 아시다시피, 사소한 결정은 아니었지만 분명히 올바른 결정이었습니다. 당시에는 많은 사람들이 스테이블 디퓨전을 호스팅하고 있었죠. 그래서 단지 확산과 추론에 특화하는 것만으로 전체 회사를 세울 수 있다는 것이 명백하지는 않았습니다. 무엇이 당신에게 자신감을 주었나요? 어떤 논쟁이 오갔나요?

Gorkem [00:07:16]: 네, 거기서 몇 가지 결정을 내려야 했습니다. 저희는 회사를 GPU 오케스트레이션 쪽으로 더 발전시킬 수도 있었습니다. 본질적으로 저희는 이 파이썬 런타임을 가지고 있었고, GPU 위에서 실행하고 있었죠. 그게 회사가 될 수도 있었습니다. 하지만 저희는 저희가 가진 것, 즉 GPU에서 파이썬 코드를 실행하기 위한 작은 SDK를 사용하는 모든 사람, 모든 회사가 똑같은 일을 하고 있다는 것을 보았습니다. 그들은 스테이블 디퓨전 애플리케이션을 배포하고 있었고, 아마도 그 위에 일부 LORA를 사용하고, 다른 버전을 사용하고, 인페인팅, 아웃페인팅 같은 것들을 하고 있었습니다. 이건 매우 낭비적이었습니다. 저희는 이것이 우리가 추론 과정을 실제로 최적화하고 모두가 그 혜택을 받는 API가 되어야 한다고 결정했습니다. 그리고 멀티테넌트로 실행할 수 있죠, DTools.io처럼요. 그리고 멀티테넌트로 실행할 수 있죠, DTools.io처럼요. 그리고 멀티테넌트로 실행할 수 있죠, DTools.io처럼요. 그래서 그것이 첫 번째 결정이었습니다. 그리고 당연히 스테이블 디퓨전 이후 4~5개월 뒤에 라마 2가 나왔고, 다시 결정의 순간이 왔습니다. 언어 모델을 할 수도 있었죠. 맞습니다. 그리고 당시의 추론 제공업체들, 아마 두어 곳 있었을 텐데, 그들 모두 언어 모델에 올인했습니다. 특정 니치 시장에서 언어 모델 호스팅이 좋은 사업이 아니라고 결정했습니다. 당시 저희는 생각했습니다. 우리는 다시 경쟁하게 될 것이다. OpenAI, Anthropic, 그리고 이 모든 연구소들과 경쟁하게 될 것이다. 결과적으로는 더 나빴습니다. 왜냐하면 언어 모델의 킬러 애플리케이션은 검색이고, 결국에는 구글과 경쟁하게 되는 것이기 때문입니다. 그리고 구글은 원한다면 이것을 무료로 제공할 수 있습니다. 왜냐하면 그것이 그들에게 매우 중요하고, 그들의 사업을 즉시 위협하기 때문입니다. 그리고 이미지와 비디오 모델은 완전히 새로운 시장이었습니다. 작은 스타트업은 종종 어떤 기존 강자와도 맞서지 않았습니다. 저희는 저희보다 훨씬 큰 누군가로부터 시장 점유율을 뺏으려 하지 않았습니다. 그리고 저희는 그 점이 마음에 들었습니다. 저희는 여기서 리더가 될 수 있다고 생각했습니다. 틈새 시장이었지만 매우 빠르게 성장하고 있었습니다. 그래서 저희는 구글이나 OpenAI, Anthropic과 맞서 싸우기보다는 이 빠르게 성장하는 틈새 시장에서 리더가 되거나 리더가 되기 위해 노력하기로 선택했습니다. 그것이 저희가 내린 결정이었습니다. 그리고 결과적으로 좋은 결정이었습니다. 왜냐하면 저희는 저희가 속한 시장을 정의하고, 사람들을 교육하며, 그것과 함께 성장할 수 있었기 때문입니다. 그리고 지금까지는 저희가 그 주변에 전체 회사를 세울 수 있을 만큼 충분히 빠르게 성장해 왔습니다.

Swyx [00:09:37]: 네, 그리고 AIE에서 언급하셨듯이, 이제는 생성형 미디어 트랙, 생성형 미디어 전문 투자자들이 있죠. 그걸 생성형 미디어라고 불러주셔서 감사합니다. 네, 당연히 이건 하나의 현상이고 사람들은 그것에 관심을 가집니다. 그리고 저는 이것이 경제를 바꿀 것이라고 생각합니다. 그리고 창의적인 사람으로서, 저는 이것이 우리에게 어떤 영향을 미칠지 궁금합니다. 기술적인 부분을 유지하고 방향 전환에 대해 계속 생각해보고 싶습니다. 왜냐하면 제가 본 것 중 가장 흥미로운 방향 전환 중 하나라고 생각하기 때문입니다. 그리고 AI 시대에, 당신들은 당시 CUDA 커널 전문가가 아니었죠?

Batuhan [00:10:05]: 저는 컴파일러 배경 출신입니다. 제 일은 파이썬 바이트코드 인터프리터를 최적화해서 더 빠르게 만드는 것이었고, 그게 바로 성능 엔지니어링입니다. 그리고 네, 당시에는 CUDA 커널 전문가도 그렇게 많지 않았다고 생각합니다. 그래서 저희는 적절한 시기에 있었던 거죠. 아시다시피, 사실 그 분야는 오늘날 우리가 가진 것보다 훨씬 더 열악했습니다. 기본적인 스테이블 디퓨전 1.5를 실행하는 것이 컨볼루션이 있는 유닛과 같았고, AI에서의 컨볼루션 성능은 그냥 러프 터치를 사용하면 GPU 성능의 30% 정도밖에 얻지 못했습니다. 왜냐하면 아무도 신경 쓰지 않았기 때문입니다. 그래서 저희가 주워 담고 최적화하기 시작한 손쉬운 개선점들이 아주 많았고, 그것이 계속 진화하고, 진화하고, 진화했습니다. 지금은 훨씬 더 경쟁적인 분야가 되었죠. 엔비디아는 커널을 작성하는 50%, 100% 커널 팀을 가지고 있습니다. 당신은 그들과 경쟁하고 있는 겁니다. 당시에는 아무도 신경 쓰지 않았습니다. 아무도 정말로 신경 쓰지 않았죠. 그래서 저희가 번성할 수 있는 좋은 새로운 분야였습니다. 그리고 VLM과 같은 커뮤니티의 노력도 없었고요.

Gorkem [00:10:57]: 정확히는 아닙니다. 이 모델들이 처음 출시되었을 때, 세상의 누구도 이것들을 프로덕션 환경에서 실행해 본 적이 없었습니다. 그냥 존재하지 않았죠. 연구 결과물 같은 것이었습니다. 맞습니다. 네, Stability였죠. 네. 아마 로컬 GPU가 있었을 겁니다. 아마 클라우드에서 빌린 단일 GPU가 있었을 겁니다. 그리고 기본적으로 이것은 제품에 대한 관심보다는 연구에 대한 관심이었습니다. 그리고 메타의 누구도, 메타, 구글의 누구도 이것을 프로덕션 환경에서 실행해 본 적이 없었습니다. 그래서 저희는 이것을 중심으로 회사를 시작하고 실제로 가능한 한 많이 최적화하는 데 시간을 보내기에 좋은 시기라고 생각했습니다. 왜냐하면 수백만 명의 사람들이 이것을 사용하게 할 수 있다면, 거기서 창출될 수 있는 경제적 가치가 많기 때문입니다.

Alessio [00:11:36]: 어느 정도의 성능 향상을 얻었는지에 대해 좀 이야기해 주실 수 있나요? 제가 여러분을 만났을 때 매출이 백만 달러 정도였고, "우리는 이 모든 맞춤형 커널을 작성하고 있어요"라고 하셨죠. 그리고 아마도 그 일부는 "실제로 얼마나 많은 커널을 작성할 수 있을까?"라는 문제일 겁니다. 물론이죠. 아시다시피, 이 모든 다른 모델들을 지원하면서요. 그것들의 범위는 어느 정도인가요? 여러 모델에 걸쳐 재사용할 수 있는 커널을 작성하고 있나요? 모델별로 얼마나 많은 작업을 해야 하나요?

Batuhan [00:11:59]: 지난 3년 동안 정말 많이 발전했습니다. 처음 시작했을 때는 스테이블 디퓨전 1.5라는 단일 모델만 있었습니다. 그래서 저희의 모든 커널 노력은 어떻게 하면 스테이블 디퓨전 1.5를 최대한 빠르게 만들 수 있을까에 집중되었습니다. 당시에는 PyTorch로 10초 정도 걸렸는데, torch compiled나 torch inductor 같은 것도 없었습니다. 그래서 같은 GPU에서 10초에서 아마 2초 정도로 줄일 수 있었습니다. 어. 그리고. 그리고 저희는 그것으로 시작했습니다. 다음으로, 더 많은 모델을 추가하면서, 스테이블 디퓨전 엑셀은 다른 아키텍처였고, PicsArt도 다른 아키텍처였습니다. 이 모든 다른 아키텍처들이 등장하기 시작했습니다. 저희는 추론 엔진을 만들자고 했습니다. 저희는 이것을 커널, 병렬화 유틸리티, 확산 캐싱 방법, 양자화 등 모든 것을 하나의 패키지로 결합한 것이라고 부릅니다. 그리고 저희는 이 추론 엔진을 만들었습니다. 동시에 PyTorch 2.0이 Torch inductor와 Torch Dynamo와 함께 출시되었는데, 이것은 Torch compiled를 하기 위한 것으로, 본질적으로 신경망의 실행을 추적하고 융합된, 즉 더 효율적인 Triton 커널을 생성하는 방법입니다. 그리고 저는 JIT(just-in-time) 컴파일러의 열렬한 팬입니다. 저는 파이썬을 위한 JIT 컴파일러인 PyPi에서 일했었습니다. 그리고 저희는 초기 단계에서는 이것이 훌륭한 아이디어라고 생각했습니다. 이것을 확산 모델에 더 전문화되고 수직적인 방식으로 적용하자고요. 당시에는 Unet이었고, 지금은 확산 트랜스포머입니다. 이것들은 계산 바운드 정도, 어떤 종류의 커널이 대부분의 시간을 차지하는지, 양방향 어텐션을 하는지 인과적 어텐션을 하는지 등 프로파일 측면에서 자기회귀 트랜스포머와는 상당히 다릅니다. 그래서 저희는 그것을 하기 시작했습니다. 그리고 지금 저희가 가진 것은 확산 트랜스포머의 대부분의 모델에서 70~80%의 성능을 얻을 수 있는 추론 엔진입니다. 그리고 저희는 여전히 많은 모델에 대해 많은 맞춤형 커널을 가지고 있습니다. 왜냐하면 그것들은 여전히 작기 때문입니다. 모든 모델은 아키텍처적인 차이를 만들고 싶어 합니다. 여러분도 이런 것을 보셨을 겁니다. Kven, DeepSeq 같은 것들에서도요. 사람들이 우리가 어떤 아키텍처가 최고인지 알더라도, 그들은 "우리는 멋진 것을 출시하고 있어"라고 확실히 하기 위해 약간 수정하고 싶어 합니다. 그래서 저희는 이것을 보았습니다. 그리고 그것을 위해 저희는 사람들이 하는 맞춤형 RMS norm이나 그런 것들을 위해 맞춤형 커널을 작성해야 했습니다. 그래서 저희는 100개가 넘는 상당한 양의 맞춤형 커널을 가지고 있습니다. 이것은 자동 생성된 것은 포함하지 않습니다. 저희는 수천 개의 다른 모양, 문제 공간 등을 위해 생성되는 커널 템플릿을 가지고 있습니다. 하지만 그것들을 고려한다면, 저희는 런타임에 수만 개의 커널을 실행하고 디스패치하고 있습니다. 하지만 그것이 대략적인 깊이와 넓이입니다.

Alessio [00:14:13]: 그리고 평균적으로, Fal에 있는 모델은 제가 직접 호스팅하는 것보다 10배 더 빠르게 실행되나요? 예를 들어 제가 스테이블 디퓨전을 가져다가. 그걸 넣으면요.

Batuhan [00:14:20]: 이게 더 큰 논의점이 될 수도 있겠네요. 속도를 모드로 고려해야 할까요? 이건 거기에 이릅니다. 기존 오픈소스 산업은 너무 빨리 발전해서, 3년 전에는 이게 사실이었을지 모릅니다. 지금은 PyTorch가 H1N1에 대해 이미 매우, 매우 좋습니다. 그렇죠? P200은 어떨까요? P200, Blackwell 칩과 함께 PyTorch를 사용하면 최상의 성능을 얻지 못합니다. 그래서 저희의 주요 목표는 여러분이 사용하는 GPU 유형에 관계없이, 이 확산 모델들에서 최고의 성능을 이끌어내는 것입니다. 어느 시점에서든 1.5배, 3배, 5배가 될 수 있습니다. 특정 모델의 경우 10배가 될 수도 있습니다. 모든 것을 마법처럼 10배 더 빠르게 만들 것이라고 말하는 것은 약간 불공평할 것입니다. 세상 누구도 그렇게 할 수 없습니다.

Gorkem [00:14:57]: 이것이 움직이는 목표이고 오픈소스 커뮤니티, 모두가 따라잡는다는 점이 다행입니다. 하지만 동시에 새로운 칩이 나오고, 새로운 아키텍처가 출시됩니다. 그래서 저희는 항상 가능한 것보다 앞서 있지만, 그들이 따라잡으면 저희는 그보다 앞서 있어야 합니다. 그리고 그것이 저희가 차별화를 만들 수 있는 방법입니다. 왜냐하면 그것이 움직이는 목표이기 때문이고, 너무 많은 일이 일어나고 있기 때문입니다. 저희는 새로운 것이 나올 때마다 그것을 가장 먼저 최적화하고, 저희의 추론 엔진을 그것에 가장 먼저 적용합니다. 그래서 그 당시에는 그것을 실행하기에 가장 빠른 곳이었고, 그것이 마진 등에 도움이 됩니다. 하지만 결국 사람들은 따라잡습니다. 저는 이 차별화를 장기적으로 만드는 것은 매우 어렵다고 생각합니다. 그래서 "새로운 아키텍처가 없다면, 새로운 칩이 없다면 장기적으로 이것을 할 것이다"와 같습니다. 하지만 다행히도 항상 있습니다. 네.

Alessio [00:15:43]: 네. 그리고 특히 이미지의 경우, 응답을 스트리밍할 수 없다고 할 수 있죠. 그래서 언어 모델의 경우, 얼마나 빨리 읽을 수 있느냐에 따라 제한되는 것과 같습니다. 그래서 록 같은 경우에도 초당 천 개의 토큰을 보여주는 것은 인상적이지만, 저는 그렇게 빨리 읽지 못합니다. 그렇죠. 그래서 더 느리게 갈 수 있습니다. 반면 이미지는 그냥 봐야 합니다. 그래서 미드저니가 지금 드래프트 모드를 가지고 있는 이유입니다. 예를 들어, 이것을 그냥 줍니다. 매우 낮은 품질의 해상도입니다. 네. 하지만 적어도 올바른 방향으로 가고 있는지 볼 수 있습니다. 당신의 고객들에게는 이것이 실제로 얼마나 사실인가요? 그들은 무엇을 가장 중요하게 생각하나요? 지연 시간이 그렇게 중요한가요? 중요한 지연 시간의 범위는 어느 정도인가요? 네.

Gorkem [00:16:20]: 실시간 시스템에서 지연 시간은 정말 중요합니다. 저희 고객 중 한 곳은 실제로 매우 광범위한 A/B 테스트를 했습니다. 그들은 의도적으로 Fal의 지연 시간을 늦춰서 그것이 그들의 지표에 어떤 영향을 미치는지 확인했습니다. 그리고 그것은 큰 영향을 미쳤습니다. 이것은 거의 페이지 로드 시간과 같습니다. 페이지 로드가 느려지면 돈을 덜 벌게 되는 것과 같죠. 아마존이 이것에 대해 유명한, 아주 큰 A/B 테스트를 했다고 생각합니다. 매우 비슷합니다. 사용자가 이미지를 요청하고, 그것에 대해 반복 작업을 할 때, 생성 속도가 느리면 참여도가 떨어지고, 더 적은 수의 이미지를 생성하는 등의 일이 발생합니다. 네.

Swyx [00:16:56]: 아마존이 가진 것과 같은 학습이죠. 속도가 10% 향상될 때마다. 네, 맞습니다. 탄력성이 높다는 거죠. 제가 또 깊이 파고들고 싶었던 다른 것은, 투자자 모자를 약간 쓰고 말하자면, Fal 성공의 이유 중 하나는 당신의 통제 범위 밖에 있다는 것입니다. 즉, 사람들이 확산을 위해 언제, 어떻게 오픈 모델을 출시하는가 하는 점이죠. 당시에는 Stability뿐이었고, 중국산은 없었죠. 제 말은, 다른 이미지 모델도 있었지만 훌륭하지는 않았다는 겁니다. 네. 그래서 당신은 그것이 그다지 명백하지 않을 때 베팅을 한 거죠. 하지만 다른 하나는, 당신이 언급하고 있는 것인데, 확산 워크로드는 언어 워크로드와 매우 다르고, 언어 워크로드는 매우 최적화되고 있는 반면 확산은 그렇지 않다는 것입니다. 그래서 당신은 한동안 경쟁이 없었던 셈이고, 그건 당신에게 환상적인 일이었죠.

Gorkem [00:17:44]: 100%입니다. 그리고 오픈소스, 저희는 당연히 그것으로부터 많은 혜택을 받습니다. 하지만 지난 6개월, 1년 동안 저희는 일부 비공개 소스 모델 개발자들과도 협력하기 시작했습니다. 막후에서 그들을 돕는 거죠. 하지만 그들이 당신에게 가중치를 보내지는 않죠.

Swyx [00:17:58]: 보냅니다. 보냅니다. 와. 네. 어떤 보안을 보장해야 하나요?

Batuhan [00:18:02]: 보장해야 하나요? 우리의 서비스 모델은 어떤 클라우드 제공업체와도 같습니다. AWS나 구글 클라우드, 아니면 이 새로운 클라우드들, 50개의 새로운 클라우드가 있잖아요? 저희는 다른 클라우드 제공업체와 그렇게 다르지 않습니다. 그리고 이것이 저희가 추론 엔진을 그들이 셀프서비스로 80%, 90%의 성능을 얻을 수 있는 방식으로 패키징한 이유입니다. 그래서 그들은 저희에게 코드를 보여줄 필요조차 없습니다. 그들은 저희의 클라우드 플랫폼에 배포하는데, 저희의 추론 엔진은 그 플랫폼에서만 사용할 수 있습니다. 그래서 그들은 그들의 코드와 모델 가중치를 저희에게 배포할 때 그것을 활용할 수 있습니다. 그리고 저희는 그것을 볼 필요가 정말 없습니다. 만약 그들이 저희와 협력하고 싶다면, 과거에 일부 회사들이 그랬던 것처럼, 저희는 본질적으로 그들을 대신하여 전진 배치된 엔지니어 역할을 하는 성능 엔지니어들을 두고 그들을 위해 맞춤형 커널을 작성합니다. 알겠습니다.

Swyx [00:18:43]: 누구를 위해 이 일을 하고 있는지 공개했나요?

Batuhan [00:18:45]: PlayHD, PlayAI를 공개했습니다. 그중 하나였죠. 저희는 이 일을 함께 하고 있는 4개의 다른 회사, 4개의 주요 비디오 회사들이 있고, 공개하지 않은 이미지 회사도 하나 있습니다. 네.

Gorkem [00:18:56]: 상상하시겠지만, 그들에게는 좀 민감한 문제입니다. 그래서 네. 네.

Swyx [00:19:00]: 말하자면, 몇 년 전에 sorgenoplicate가 V03 모델을 서비스하기 시작했을 때 저희는 "그냥 그들의 API를 래핑하는 건가?"라고 생각했습니다. 그래서 얼마나 많은 통합이 이루어지고 있고, 얼마나 당신의 인프라나 기술 위에서 이루어지고 있는지가 명확하지 않습니다.

Gorkem [00:19:13]: 솔직히 말해서, 그런 일도 일부 일어나고 있습니다. 네. V03 같은 경우, 제 생각에 모두가. 그냥 API 래퍼입니다. 네.

Batuhan [00:19:19]: 그렇습니다. 네. 다른 속도 SLA 보장 등을 통해 고객에게 서비스할 수 있는 전용 풀이 있습니다. 알겠습니다. V03 같은 것에는 그렇게 작동합니다.

Swyx [00:19:27]: 하지만 당신의 목표는 원스톱 샵이 되는 것이죠.

Batuhan [00:19:32]: 이 자리에 초대해 주셔서 정말 감사합니다.

Swyx [00:20:02]: 이 자리에 초대해 주셔서 정말 감사합니다.

Swyx [00:20:50]: 이 자리에 초대해 주셔서 정말 감사합니다. 이 자리에 초대해 주셔서 정말 감사합니다.

Batuhan [00:21:30]: 이 자리에 초대해 주셔서 정말 감사합니다.

Batuhan [00:22:00]: 이 자리에 초대해 주셔서 정말 감사합니다.

Batuhan [00:22:30]: 이 자리에 초대해 주셔서 정말 감사합니다. 알겠습니다, 알겠습니다. 별도의 제품이군요. 네.

Alessio [00:22:32]: GPU 관점에서 볼 때, 항상 최신 제품을 사용해야 하나요? 계속 H100을 언급하시네요.

Batuhan [00:22:37]: 저희 워크로드의 대부분은 H100에서 실행됩니다. 왜냐하면 파일당 가격 면에서 합리적이기 때문입니다. 하지만 BlackVal은 당연히, 저희는 지금 BlackVal 커널을 작성하는 데 전념하는 5명의 인력이 있습니다. 이론적으로는 좋아 보이기 때문이죠. 그렇죠? 달러당 플롭스(flops) 면에서 합리적입니다. 하지만 그 실제 플롭스에 도달할 수 있을까요? 아니요. 그래서 저희는 엔비디아와 직접 협력하여 특정 하드웨어에 최적화된 맞춤형 커널, 확산 트랜스포머를 위한 커널을 작성하는 전담 팀을 두고 있습니다. 성능 대비 가격이 합리적인 지점에 도달하기 위해서요. 그리고 나면 저희 자체 워크로드뿐만 아니라 일부 파운데이션 모델 회사들에게도 "BlackVal로 마이그레이션하고 싶다면, 이미 작동하는 추론 스택이 여기 있습니다"라고 제안할 것입니다.

Gorkem [00:23:11]: 저희는 BlackVal의 한계를 밀어붙여야 하는 시점에 와 있습니다. 왜냐하면 다른 누구도 이 작업을 하고 있지 않기 때문입니다. 그리고 아마도 지금 당장은 경제적으로, 가격 대비 성능 면에서 합리적이지 않을 수도 있지만, 저희는 그럴 수 있다는 것을 알고 있습니다. 그래서 저희는 아마도 그 지점에서 몇 달 정도 떨어진 곳을 향해 노력하고 있습니다. 그리고 그것이 가능해지면, 저희는 아마도 가능한 한 많은 워크로드를 BlackVal로 전환할 것입니다.

Swyx [00:23:33]: 아주 극단적으로 말해서, 언제 ASIC을 개발하는 것이 합리적일까요?

Batuhan [00:23:38]: 저는 그렇지 않다고 생각합니다. 그게 솔직한 의견입니다. 아시다시피, 사람들은, 이것은 가장 논란이 많은 주제 중 하나죠? 이 모든 ASIC이 훌륭한 아이디어인가? 만약 당신이 S-RAM, 메모리 대역폭에 제약을 받고 모든 S-RAM을 넣을 수 있다면, 그 시점에서 경제적으로 실행 가능한가? 저는 모르겠습니다. 하지만 서밋은 이 칩 설계를 중심으로 이루어집니다. 그래서 당신은 "엔비디아 GAM 명령어의 오버헤드는 무엇인가?"를 보게 됩니다. 그렇죠. 16% 정도입니다. 그래서 당신은 본질적으로 행렬 곱셈 기계를 사고 있는 겁니다. 그래서 그것을 그렇게 많이 전문화하는 것은 별로 의미가 없습니다. 그리고 B300 같은 것들은 1.5배 정도의 성능을 내는 더 나은 소프트맥스 명령어를 가질 것입니다. 그리고 그것이 엔비디아가 대부분의 워크로드, 즉 어텐션이 많은 작업에서 더 나은 성능을 얻는 한 가지 방법이 될 수 있습니다. 저는 엔비디아가 더 전문화된 것들을 추가하는 것이 의미가 있을 수 있다고 생각하지만, 저희에게는 그것이 결코 의미가 있을 것이라고 생각하지 않습니다.

Swyx [00:24:30]: I6를 만드는 거죠. 첫 원칙부터 생각해보면 확산 워크로드는 매우 다르지만, 분명히 아키텍처에는 여전히 많은 변화가 필요하고, 이는 범용적이어야 합니다.

Gorkem [00:24:40]: 저희는 최적화하려는 단일 모델이 없습니다. 저희는 항상 최신의, 최고의 것을 위해 노력하고 있습니다. 따라서 유연성이 정말 중요합니다.

Swyx [00:24:48]: 제가 보여주려고 했던 것은, Quen MMDIT를 꺼내려고 했는데, 거기에는 이중 스트리밍 같은 것이 있습니다. 제 생각에 마지막으로 SD3에 있었던 것 같습니다. 네, SD3 Flux. 네. 그것이 지금 표준 모델인가요? MMDIT.

Batuhan [00:24:59]: 그것도 논란의 여지가 있는 주제입니다. 아시다시피, 'Scaling Rectified Flow of Transformers' 논문, 즉 SD3 논문이 이 아키텍처를 제시했습니다. 그리고 저희 연구팀 중 한 명인 Simo Raya, 저희 연구 책임자인데, 그가 MMDIT만 사용하는 것은 비효율적이라는 것을 발견했습니다. 그것들을 섞어야 한다는 거죠. 그리고 이제 논란의 여지가 있는 의견들이 있습니다. 예를 들어, movie jam 논문에서는 "MMDIT는 완전히 불필요하다. 그냥 단일 스트림 DIT를 사용하면 된다"고 말합니다. 그래서 아키텍처 변경 측면에서 논란의 여지가 있는 의견들이 발생하고 있습니다. 저는 그것을 이해합니다. 왜냐하면 모두가 다른 아키텍처를 만들고 싶어 하고, 아무도 같은 아키텍처를 사용하고 싶어 하지 않기 때문입니다. 그건 재미없으니까요. 네. 네. 그렇지 않으면, 그것은 단지 컴퓨팅과 데이터의 문제일 뿐이고, 이 연구자들은 그들의 모델이 데이터와 컴퓨팅의 결과물이라는 것에 자부심을 느끼지 못합니다. 그들은 새로운 연구적 변화를 만들고 싶어 합니다. 그래서 저는 이 패러다임, 즉 연구자들이 변화를 위한 변화, 즉 특징을 바꾸는 패러다임이 끝날 때까지 아키텍처는 계속 바뀔 것이라고 생각합니다.

Swyx [00:25:47]: 몇 가지 다른 아키텍처적인 것들에 대해 이야기하고 이 주제 내에서 범위를 한정하겠습니다. 증류(distillation)는 한동안 유행이었습니다. SDXL Lightning, 여러분은 Tail Draw의 환상적인 데모를 보여주셨죠. 저희도 팟캐스트에 출연시킨 적이 있습니다. 환상적인 에피소드였죠. 그들에게 무슨 일이 있었나요? 왜 더 이상 인기가 없나요?

Gorkem [00:26:03]: 좋은 데모를 만들었다고 생각합니다. 실시간 애플리케이션을 만들 수 있었고, 이런 드로잉 애플리케이션을 만들 수 있었습니다. 하지만 사람들이 장기적으로 사용자 유지율을 가질 수 있는 애플리케이션을 만들 수 있었다고는 생각하지 않습니다. 사람들이 그것으로 정말 유용한 것을 만들지는 못했습니다.

Swyx [00:26:19]: 제가 생각했던 일이 왜 일어나지 않았는지 말씀드릴 테니, 왜 그랬는지 말해주세요. 물론이죠. 바로 드래프팅을 위한 일관성 모델(consistency models)입니다. 펜을 사용해서 그림을 그리고, 그것이 드래프트를 만듭니다. 그런 다음 실제 모델로 업스케일링하는 거죠. 하지만 그게 다입니다. 왜 1단계가 아닌 2단계 프로세스가 될 수 없는 거죠? 네.

Gorkem [00:26:39]: 그리고 제 생각에 일어난 한 가지 일은 Flux, 즉 그 세대의 모델들이 처음 나왔을 때 이미지-투-이미지에 능숙하지 않았다는 것입니다. 그래서 그림을 그리려면 좋은 이미지-투-이미지 모델이 필요합니다. 아마도 이 시점에서 일부 편집 모델들과 함께 다시 검토될 필요가 있을지도 모릅니다. 이미지-투-이미지와 컨트롤 같은 것들이요. 그게 Flux입니다.

Batuhan [00:26:58]: 엑셀이나 컨트롤러는 매우 인기가 많았습니다. 사람들은 스케치-투-이미지 같은 것을 하곤 했죠. 그리고 Flux와 함께, 제 생각에 사람들은 그것에 대해 덜 신경 썼습니다. 제가 계속 생각하는 한 가지는, 이것이 LLM에도 해당되는가 하는 점입니다. 아시다시피, 저는 항상 클로드 4.1 오퍼스를 기본으로 사용합니다. 소네트보다 느리더라도, 저는 최고의 품질을 얻을 것이라는 것을 알고 있기 때문입니다. 맞습니다. 여기서도 그런 일이 일어나고 있습니다. 네. 그것이 여기서도 일어나고 있는 일인 것 같습니다.

Swyx [00:27:22]: 알겠습니다, 어쨌든, 창작자로서 저는 빠르고 신속한 초안을 원하고, 그 다음에 다듬을 수 있기를 원합니다. 그렇죠? 그래서. 모르겠습니다. 왜 그런 일이 일어나지 않았는지 모르겠습니다.

Gorkem [00:27:29]: 비디오 모델의 경우 더 그렇죠? 예전에는 5초짜리 생성 하나에 5분, 4분이 걸렸습니다. 지금은 대부분 1분 미만이지만, 10초, 5초짜리 생성을 원합니다. 그리고 창작자들이 작업할 때의 워크플로우 때문에, 그들은 수많은 비디오를 생성한 다음 하나를 골라 그것을 중심으로 이야기를 만듭니다. 그래서 이 사람들이 실제로 비디오를 생성하는 것을 보면, 한 번에 수백 개를 생성하고 그 주변에 앉아 있어야 합니다. 그리고 기다렸다가 그것을 반복 작업해야 합니다. 더 빠른 속도는 창작자들에게 큰 의미가 있습니다.

Swyx [00:28:05]: 네, 그렇습니다. 제가 또 간단히 언급하고 싶었던 다른 것은, 당신이 언급한 자기회귀 모델(autoregressive models)입니다. 솔직히 저는 여전히 Gemini가 과소평가되었다고 생각합니다. 왜냐하면 그들이 먼저였기 때문입니다. 그리고 그 다음에 당연히, 공개적으로, 저는 4.0 이미지 생성을 했고 그것은 큰 일이었습니다. 저는 심지어 당신들에게 패닉이 있었는지 궁금합니다. 왜냐하면 당연히 이것은 소다 이미지 생성이고 다른 누구도 가지고 있지 않기 때문입니다. 오픈소스가 아니죠.

Batuhan [00:28:30]: 그런 시대를 너무 많이 겪어봐서요.

Gorkem [00:28:34]: 걱정하는 것을 멈췄습니다.

Batuhan [00:28:35]: 당신의 카메라는 돌리(Dolly)에 대한 좋은 이야기를 가지고 있습니다.

Gorkem [00:28:38]: 네, 저는 돌리 2가 처음 나왔을 때, "오케이, OpenAI는 다른 누구보다 훨씬 앞서 있어. 미드저니는 불가능해"라고 생각했던 것에 대해 이야기합니다. 그리고 몇 달 안에 사람들이 따라잡았고, 그 다음 스테이블 디퓨전은 아마도 돌리보다 더 좋거나, 돌리만큼 좋았습니다. 몇 달 후에 말이죠. 그리고 그것은 오픈소스였습니다. 그래서 1년 후, 소라(Sora)와 같은 일이 일어났습니다. 그들이 그 비디오들을 공개했을 때, 그 당시에는 저희는 흥분했습니다. 왜냐하면 이제 사람들이 그것이 가능하다는 것을 보았기 때문입니다. 이것은 실제로 할 수 있는 일입니다. 연구자들은 동기를 부여받고, 그들은 과대광고를 봅니다. 그들은 이것이 가능하다는 것을 봅니다. 그래서 그들은 그것에 대해 작업합니다. 그리고 몇 달 안에, 저희는 아마도 소라 수준은 아니지만 경쟁사보다 훨씬 더 나은 비디오 모델을 가지고 있습니다. 지금 저희는 소라보다 훨씬 더 나은 비디오 모델을 가지고 있습니다. 그래서 누군가가 실제로 경계를 밀어붙이는 것을 볼 때마다, 그것은 흥분의 이유가 됩니다. 왜냐하면 이제 그것이 가능하기 때문입니다. 다른 사람들은 몇 달 안에 그것을 할 것입니다. 그래서 더 이상 패닉하지 않습니다.

Alessio [00:29:38]: Anthropic이 이미지 생성 모델을 가지고 있지 않다는 사실이 대형 연구소들이 무엇에 관심을 가지는지에 대해 무언가를 말해주나요?

Batuhan [00:29:44]: 그것은 다른 연구소들이 일반적으로 무엇에 관심을 가지는지보다는 Anthropic 자체의 우선순위에 대해 더 많은 것을 말해줍니다. 왜냐하면 XAI, Meta, OpenAI, Google을 보면, 그들은 모두 정말 좋은 이미지 모델을 가지고 있기 때문입니다. 네.

Gorkem [00:29:58]: 구글은 지난 발표에서 '생성형 미디어'라는 단어를 사용했습니다. 저희에게는 자랑스러운 순간이었죠. 승리입니다. 그리고 많이, 아시다시피, 그들은 새로운 LLM 모델만큼이나 생성형 미디어에 집중했습니다. 그래서 일부 연구소는 확실히 그것에 관심을 가지고 있고, 일부 연구소에게는 그것이 우선순위가 아닙니다. XAI를 보세요. 그들은 계속해서 이미지 언어, AI 슬롭을 밀어붙이고 있습니다. 네, 알아요.

Alessio [00:30:19]: 알아요, 미쳤어요. 그리고 와이푸들. 그리고 상호작용 수준. 이미지, 비디오가 있고, 이제는 지니(Genie)가 있습니다. 이것은 일종의 월드 모델에 가깝고, 게임 애플리케이션도 있습니다. Fal이 그 모델들에서 많은 트래픽을 얻기까지 얼마나 남았나요? 오늘날 오픈소스에서는 대부분 실험적인가요? 지니는 인상적이지만, 구글 모델이잖아요?

Gorkem [00:30:39]: 저는 이것에 대해 매우 낙관적인 견해를 가지고 있으며, 그것이 아마도 정상적인 결과일 것입니다. 최악의 경우, 저희는 월드 모델에서 나오는 매우 유능한 비디오 모델을 갖게 될 것이라고 생각합니다. 그렇죠? 그것은 매우 제어 가능한 비디오 모델이 될 것이고, 사용 사례는 비디오 모델과 비슷할 것입니다. 콘텐츠를 만들게 될 것이지만, 카메라 각도를 제어할 수 있고, 오늘날 할 수 있는 것보다 훨씬 더 잘 비디오 모델을 제어할 수 있게 될 것입니다. 최악의 경우, 저희는 월드 모델로부터 그것을 얻게 될 것입니다. 그리고 최상의 경우, 저는 누구도 무슨 일이 일어날지 예측하기 매우 어렵다고 생각합니다. 네. 영화와 게임. 그것은 당신이 플레이 가능한 전체 영화 세계의 일부가 될 수 있는 중간 지점의 무언가가 될 것입니다. 그래서 무한한 가능성이 있습니다. 최상의 경우에 무슨 일이 일어날지, 그리고 그것이 얼마나 저렴해질지, 이것이 주류 채택에 도달할 수 있을지, 저희는 그 모든 것을 보게 될 것입니다. 하지만 기술적으로는 확실히 믿을 수 없을 정도로 흥미롭고 인상적입니다. 이 연구소들에서 나오는 것들이요. 네.

Alessio [00:31:42]: 논문을 다시 찾아봐야겠는데, 비디오 모델과 이미지 생성, 물리학 이해에 대한 연구가 있었습니다. 네. 그리고 행성의 궤도를 예측할 수 있었지만, 실제로 중력장을 그리게 했을 때는 완전히 틀렸습니다. 네. 그렇죠. 그래서 저는 월드 모델에 대한 제 생각이 그렇습니다. 창작자 애플리케이션, 즉 일관된 세계를 만드는 방법을 이해합니다. 하지만 다른 쪽 사람들, 즉 "이것들이 세상을 시뮬레이션하고 지능을 얻는 가장 좋은 방법이다"라고 말하는 사람들에 대해서는 잘 모르겠습니다. 저는 그것을 모릅니다.

Gorkem [00:32:10]: 두 가지에 대한 낙관론도 있습니다. 왜냐하면 로봇 공학을 연구하는 사람과 이야기할 때마다 그들은 가지고 있는 데이터의 양에 의해 병목 현상을 겪기 때문입니다. 그리고 지난 3년간의 모든 AI 혁신에서 저희는 그것을 보았습니다. 그렇죠. 하지만 데이터가 풍부할 때마다 그 유형의 모델은 실제로 많이 개선되고, 그래서 로봇 공학에서도 비슷한 것을 기대합니다. 그들이 이 데이터 문제를 해결할 때마다 그 모델들도 더 좋아질 것입니다. 그래서 사람들이 그렇게 낙관적인 것입니다. 오케이. 아마도 이것이 로봇 공학의 데이터 문제를 해결할 것이고, 거기에는 무한한 기회가 있습니다.

Batuhan [00:32:46]: 그리고 당신이 언급한 중력에 대한 예와 관련하여, 저는 이것이 여전히 "LMS는 9.5를 할 수 없다"는 것과 같은 문제라고 생각합니다. 9.9 더하기 9, 9.9. 네, 할 수 있습니다. 더 많은 데이터로 훈련시키고, 더 나은 토크나이저를 가지면 됩니다. 그것이 이유입니다. 성능 개선은 단지 데이터 규모와 기본 아키텍처의 문제입니다. 하지만 저는 그것이 그렇게 많이 바뀔 것이라고 생각하지 않습니다. 저희는 그냥 1000배 더 많은 데이터, 1000배 더 많은 컴퓨팅을 투입할 것이고, 최고의 물리 시뮬레이터를 얻게 될 것입니다. 그리고 저는 이것이 데이터에서 오는 기존 신호로 가능해야 한다고 생각합니다.

Swyx [00:33:18]: 비디오 관련해서도 더 깊이 파고들고 싶네요. 네. AI에서 멋진 슬라이드를 보여주셨죠. 현재 Fal 매출의 18%가 비디오 모델에서 나온다고 하셨는데, 그게 2월이었죠.

Gorkem [00:33:29]: 그래서 지금은 아마 80, 50, 50을 넘을 겁니다. 네. 알겠습니다. 50 이상이군요. 네. 네. 100%입니다. 와. 알겠습니다. 편집 모델이 이미지에도 활력을 불어넣었으니, 둘 다 성장했지만, 네, 비디오가 더 빨리 성장했습니다.

Batuhan [00:33:46]: 비디오는 꽤, 꽤 중요합니다. 그리고 주요 동인 중 하나는 오픈소스 모델입니다. 2월에는 후뉴안 비디오가 있었는데, 꽤 좋았다고 생각합니다. 젠모의 모치도 있었지만, 품질은 아직 거기까지 미치지 못했습니다. 그리고 알리바바의 원(One)은 정말 엄청나게 좋은 모델이었습니다. 그리고 그들은 한 달 전인가, 몇 주 전에 새로운 버전을 출시했습니다. 그리고 지금은 정말, 정말 인기가 많아지고 있습니다. 그리고 저희는 이것을 실행할 수 있습니다. 저는 4 ADP, 즉 드래프트 모드 버전을 5초 이내에 실행할 수 있습니다. 그래서 사람들은 즉각적인 피드백 루프를 가질 수 있습니다. 그리고 720P 전체 해상도로 가고 싶을 때는 20초밖에 걸리지 않습니다. 저희는 그것을 10초로 줄일 계획이었습니다. 네.

Swyx [00:34:25]: 정말 놀랍네요. 그리고 그 점에 대해 더 깊이 파고들고 싶습니다. 한동안 저는 알리바바에 대해 다소 비관적이었습니다. 왜냐하면 그들은 계속해서 매우 체리피킹된 논문들을 발표했고, 마치 "우리는 깃허브에 있다"고 한 다음 깃허브에 가보면 리드미(readme) 파일만 있었기 때문입니다.

Gorkem [00:34:37]: 정말 뭔가 변했다는 걸 알 수 있습니다. 그들은, 그들에게 무슨 일이 있었나요?

Batuhan [00:34:45]: 아뇨, 아뇨, 저희는 그들과 이야기해 본 적이 없습니다. 하지만 그렇게 보입니다. 그리고 지금 알리바바 내부에는 경쟁하는 팀들이 있습니다. 하나는 정말 좋은 이미지 모델이지만, 그들은 경쟁 이미지 모델로서 출시했습니다. 저희 생각에, 한 번의 이미지 모델은 실제로 매우, 매우 좋습니다. 81 프레임 대신 단일 프레임으로 한 번만 하면, 정말 좋은 텍스트-이미지 모델을 얻을 수 있습니다. 그리고 이것은 단지 비디오에서 가져온 순수한 데이터 양 때문입니다. 그래서 지금 알리바바는 그들의 연구소에서 나온 정말 좋은 모델 두 개를 가지고 있습니다. 그리고 중국에는 여러분이 들어보지 못했을 수도 있는 작은 연구소들이 있습니다. 예를 들어 스텝펀(Step fun)은 이미지 편집 모델인 하이드림(Hi dream)을 출시했습니다. 저희는 그렇게 가고 싶습니다. 이런 작은 연구소들이 모두 출시하고 있습니다. 왜냐하면 이런 이미지나 편집 모델을 훈련하는 것이 그렇게 비싸지 않다고 생각하기 때문입니다. 그리고 비디오 모델은 약간 더 비쌀 수 있습니다. 제 생각에 이런 모델들을 훈련하는 데는 수백만 달러 정도가 드는데, 특히 그들이 아마도 어떤 단체에 의해 지원받고 있다는 것을 고려하면 그렇게 많은 금액은 아닙니다. 알리바바 외에도, 스테판 같은 곳들이 있죠. 그들은 아마 상당한 금액의 돈을 모았을 겁니다. 그래서 이런 모델들을 훈련하면 많은 주목을 받을 수 있고, 그것은 수준 이하의 LLM을 출시하는 것보다 더 많은 주목을 받는 것입니다. 왜냐하면 특정 시장은 경쟁이 훨씬 더 치열하기 때문입니다. 그래서 단지 백만 달러를 들여 비디오 모델을 훈련하고 그것을 출시하는 것은 많은 주목을 가져다준다고 생각합니다.

Gorkem [00:35:57]: 그것은 꼼수입니다. 허깅 페이스를 보면, 지금 당장 봐도, 상위 모델들은 이미지 모델일 것이라고 확신합니다. 꽤나 이미지 편집 모델이 아마 상위권에 있을 겁니다. 네. 아마 상위권에 있을 겁니다.

Alessio [00:36:08]: 1위, 1위. 네.

Batuhan [00:36:11]: 후난 게임크래프트가 3위, 4위, 4위, 젬마, 2억 7천만, 일부 이미지 관련. 바이트댄스는 오픈소스가 있지만, 그들은 정말 좋은 팀 시드(Seed)를 가지고 있습니다. 그곳이 그들의 새로운 연구소입니다. 그들은 시드림(Seedream), 시댄스(Seedance), 옴니휴먼(OmniHuman) 같은 것들을 연구하고 있습니다. 저희는 그들과 좋은 파트너십을 맺고 있어서, 그들의 모델을 미국에서도 호스팅할 수 있기를 바랍니다. 네. 그리고 아이디어는, 제 생각에 그들이 구성한 팀은 매우 훌륭하고, 그들의 이전 연구 등에서 비롯된 것입니다. 바이트댄스는 SDXL 라이트닝 같은 것에 대해 정말 좋은 오픈소스 작업을 하고 있었습니다. 그들은 SDXL 라이트닝 논문, 애니메이티브 라이트닝을 발표했습니다. 그래서 저는 그들에 대해 꽤, 꽤 희망적입니다. 네.

Swyx [00:36:47]: 우선, 그들이 출시할 때 당신에게 연락하지 않고 그냥 공개해서 당신이 서둘러야 하는 일이 없기를 바랍니다. 알겠습니다.

Batuhan [00:36:53]: 이 시점에서는 사람들이 저희에게 연락합니다. 왜냐하면 저희가 시장 선두주자이기 때문입니다.

Swyx [00:36:56]: 그래서 그들은 배포를 얻기 위해 저희에게 연락합니다. 네. 그들이 항상 먼저 출시하는 중국 플랫폼이 있는데, 이름은 잊어버렸지만, 당신은... 저희도 이 모델들 대부분과 함께 출시 첫날부터 함께합니다. 하지만, 기본적으로 제 질문은 항상 "돈을 버는 것은 당신들인데, Stability는 스테이블 디퓨전으로 돈을 벌지 못했다"는 것입니다.

Batuhan [00:37:17]: 저는 Black Forest Labs가 한 일이 이 측면에서 매우, 매우 흥미로웠다고 생각합니다. 그들은 세 가지 다른 모델을 출시했습니다. 네. 아파치 2 라이선스의 극도로 증류된 모델, 이것은 개발용으로 좋습니다. 샤넬 버전입니다. 이것은 낮은 품질의 것을 위한 4단계 생성입니다. 그들은 비상업적 라이선스를 가진 개발용 모델을 출시했는데, 그들의 추론 파트너들은 수익 공유를 지불합니다. 그리고 이것은 매우 좋은 방법입니다. 그리고 프로 버전이 있는데, 이것은 호스팅을 위해 협력할 수 있습니다. 그리고 수익 공유는 당연히 그것에 따라 다릅니다. 이것은 모델 출시가 전부인 연구소들에게는 매우 현명한 선택이라고 생각합니다. 하지만 만약 당신이 부가적으로 제품을 만드는 회사라면, 오픈소스 모델로 돈을 벌 필요는 없습니다. 당신은 연구자들을 고용하고, 배포를 얻기 위해 그것을 하는 것입니다. 그래서 그것은 회사의 목표에 따라 정말 다릅니다. 알리바바 규모에서는, 그들은 하나의 모델이 그들의 API에서 호스팅되는지 신경 쓰지 않습니다. 그렇죠? 알리바바는, 원(One)이 만드는 것은 알리바바의 전체 매출에 영향을 미치지 않습니다. 그래서 그들에게는 그것을 출시하고 주목을 받고, 아마도 일부 리드를 얻는 것이 당연한 선택입니다. 그들의 알리바바 클라우드 제품을 위해서요. 하지만 Black Forest Labs나 그런 회사들에게는, 증류된 버전을 완전히 오픈소스로 출시하고, 덜 증류되거나 실제 모델을 비상업적으로 출시한 다음 추론 회사들과 파트너십을 맺는 것이 현명한 조치라고 생각합니다.

Alessio [00:38:32]: 사용량 분포는 어떻게 되나요? 예를 들어 매출의 80%가 5개 모델에서 나오나요? 아니면 사람들이 초기 출시 이후에 이 모든 오픈 모델의 롱테일을 정말로 사용하나요?

Gorkem [00:38:42]: 멱법칙(power law)이 어느 정도 있지만, 생각만큼 심하지는 않습니다. 그리고 계속 바뀝니다. 그게 또 다른 부분입니다. 단 하나의 모델만 많이 사용되는 것이 아닙니다. 월별로 많이 바뀝니다. 이번 여름은 정말 미쳤습니다. 수많은 새로운 비디오 모델, 새로운 이미지 편집 모델이 나왔고, 리더가 매주 바뀌었습니다. 하지만 한 발 물러서서 어떤 모델이 사용되고 있는지 보면, 사람들은 최고급, 가장 비싼 비디오 모델을 사용하고 싶어 하거나, 비용 효율적이고, 좋지만 충분히 저렴한 비디오 모델을 사용하고 싶어 합니다. 그래서 그 두 모델이 보통 많이 사용되고, 그 모델들이 무엇인지는 매주 바뀝니다. 네.

Batuhan [00:39:29]: 한 가지 좋은 예는 폭스 컨텍스트(Fox context)가 5월 말에 출시되었고, 코에딧(co-edit)은 2주 전에 출시되었다는 것입니다. 그리고 지금은 컨텍스트를 능가하고 있습니다. 더 나은 품질의 모델이 있기 때문에 이런 것들이 얼마나 빨리 전환되는지 정말 놀랍습니다. 그리고 그것이 바로 가치 제안입니다. 코에딧이 사용 가능해지자마자 플럭스 컨텍스트 개발을 관리하기 위해 인프라를 설정할 필요가 없습니다. Fal을 사용하면 바로 그것으로 전환할 수 있습니다.

Alessio [00:39:51]: 제 생각에는 그렇네요. 일부 모델은 오픈되어 있고 일부 모델은 수익 공유를 지불해야 한다면, 이상적으로는 사람들을 수익 공유 모델에서 오픈 모델로 옮기고 싶을 겁니다. 그렇죠? 그 역학 관계는 어떤가요? 모두 가격에 달려 있습니다.

Gorkem [00:40:03]: 저도 생각하고 있습니다. "고객이 성공할 수 있는 일이라면 무엇이든 할 것이다." 저희는 아직 이런 작은 계산이 중요하지 않을 만큼 초기 단계에 있습니다. 저는 사람들이 실제로 프로덕션에 들어가서 제품을 만들고 성공하는 것을 더 원합니다. "여기서 20%, 저기서 10%" 같은 것보다요. 제 말은.

Alessio [00:40:22]: 당신은 1억 달러의 매출을 올리고 있습니다.

Swyx [00:40:26]: 좋습니다. 사람들이 이것을 실제로 어떻게 사용하는지에 대해 몇 가지 질문을 더 하겠습니다. 알겠습니다. 아주 뻔한 질문을 하겠습니다. 네. NSFW(Not Safe For Work) 콘텐츠는 얼마나 되나요? 거의 무시할 수 있는 수준입니다. 네. 모든 것을 중재하지는 않고, 중재는 선택 사항이죠?

Batuhan [00:40:40]: 중재는 불법적인 콘텐츠가 중재되는 수준까지 선택 사항입니다. 그리고 저희는 불법이 아닌 콘텐츠, NSFW 중재도 추적합니다. 그리고 1% 이상 본 적이 없습니다.

Gorkem [00:40:51]: 모델 자체도 그런 종류의 콘텐츠를 생성하지 않습니다.

Batuhan [00:40:54]: 이것은 일부 모델 제공업체, 특히 Black Forest Labs 모델을 보면, 모델이 그런 용도가 아니라는 것입니다. 그것은 생성할 수 없거나, 방지되는 방식으로 어닐링(annealed)되었습니다. 그리고 저희 고객 기반의 대부분은, 매출 기준으로 보면, 엔터프라이즈가 더 높은 수준에 있으며, 그중 일부는 사용자 공간, 모바일 애플리케이션일 수 있습니다. 하지만 지난 6개월, 9개월 동안 저희는 점점 더 엔터프라이즈로 전환하고 있으며, 그들에게는 그럴 필요가 덜합니다.

Swyx [00:41:19]: 선택의 여지가 적다는 뜻인가요? 그럼 그 기업들은 무엇을 하고 있나요? 이미지를 생성할 수 있는 범용 챗봇을 만드는 것 외에요. 아마도 캔바(Canva)가 좋은 사용 사례가 될 수 있겠네요. 하지만 제 상상력은 그 이상으로는 좀 제한적입니다.

Gorkem [00:41:32]: 광고가 절대적으로 성장하고 있는 것 같습니다. 그리고 생각해보면, 그것은 매우 잘 맞습니다. 비디오 광고에 대해 이야기해 봅시다. 제가 계속 반복해서 말하지만, 일부 회사들은 "우리는 할리우드를 바꿀 것이다. 영화 제작이 혁신될 것이다"라고 말합니다. 저는 그것이 그렇게 흥미롭다고 생각하지 않습니다. 일 년에 몇 편의 영화를 보시나요? 아마 20편, 25편 정도일 겁니다. 극장에서 보는 영화는 몇 편인가요? 기껏해야 서너 편입니다. 그래서 일 년에 수천 편의 영화가 나온다고 해도, 사람들은 이 모든 영화를 다 볼 수 없을 겁니다. 시간이 충분하지 않습니다. 그것은 최대 품질 게임입니다. 맞습니다. 맞습니다. 그리고 광고는 정반대입니다. 콘텐츠가 많을수록, 광고를 만드는 다양한 방법이 있을수록, 항상 경제적 가치가 붙습니다. 그래서 무한한 수의 광고, 무한한 다른 버전의 광고를 만들 수 있고, 더 개인화될수록 그 뒤에 더 많은 경제적 가치가 있습니다. 그래서 광고는 이런 종류의 기술에 매우 잘 맞습니다. 왜냐하면 당신이 만들 수 있는 것에는 한계가 없기 때문입니다.

Swyx [00:42:35]: 실리콘 밸리에서 제가 보고 있는 한 가지 트렌드에 대해 덧붙여 말하자면, 설명할 수는 없지만, 이 모든 YC 스타트업들과 모든 회사들이 론칭 비디오 하나당 1만 달러에서 7만 달러 사이를 쓰고 있다는 것입니다. 네. 생성형 비디오 시대에 말이죠. 그들은 실제 크리에이티브 디렉터를 고용하고, 스튜디오를 고용하고, 배우를 고용하고 있습니다. 저도 그중 하나에 참여했었는데, 생성형 비디오가 있는데 그 모든 것이 필요한가요? 제 생각에 로이(Roy)도 생성형 비디오에 대해 이야기하기 시작했습니다. PJ Ace를 아시는지 모르겠네요.

Batuhan [00:43:05]: 그는 이 분야에서 절대적인 킬러라고 생각합니다.

Swyx [00:43:08]: 그는 슈퍼볼 광고 같은 것을 론칭했죠? 농구 플레이오프, NBA 결승전을 했죠?

Batuhan [00:43:15]: 그는 저희 시리즈 B 발표 영상도 만들었습니다. 저희는 그와 꽤 가깝습니다. 그리고 그가 생각해내는 것과 그것이 얼마나 바이럴되는지는 정말 놀랍습니다. 수십만 달러를 쓰는 이런 비디오들 말이죠. 그렇죠? 그냥 바이럴 콘텐츠를 만들면 되고, 이 생성형 미디어 모델들이 그것을 하는 가장 좋은 방법입니다. 그리고 저희는 아직 이것의 초기 단계에 있습니다. 그렇죠? 당연히 전문적인 품질이 아닐 수도 있습니다. 저는 여전히 인간 참여형(human in the loop), 즉 혼합된 콘텐츠가 오늘날의 방식이라고 생각하지만, 6개월 후에는 누가 알겠습니까? 12개월 후에는 80%가 생성될 것이라고 생각합니다. 저희는 슈퍼볼을 보면서 "이 중 얼마나 많은 부분이 생성될까?"라고 말하고 있었습니다. 그리고 지금 이 비디오는 AI 생성처럼 보입니다. AI 생성일 수도 있습니다. 그렇죠? 구별할 수 없습니다.

Swyx [00:43:54]: 그래서 제 생각에 어느 시점에는 80, 90%가 AI로 생성될 것입니다. 그것은 저에게, 제 생각에, Replicate의 Fofur라는 사람을 생각나게 합니다. 그는 분명히 이 모든 워크플로우에 대한 최고의 영감입니다. 그는 게임 영상 위에 일종의 NBA 현실적인 로어(lore)를 겹쳤습니다. 그래서 NBA 2K를 플레이할 수 있지만, 실제 비디오처럼 보입니다. 저도 봤습니다. 네. 저는 "뭐야"라고 생각했습니다.

Swyx [00:44:21]: 정말 멋지네요. 그리고 아마도, 그리고 그것이 제 질문의 다른 부분인데, ComfyUI에 대해 이야기하고 싶었습니다. 얼마나 많은 로어(lore) 서빙이 이루어지고 있나요? 그렇죠? 얼마나 많은 맞춤형이 있나요? 많습니다. 많습니다. 아시나요? 알겠습니다. 대다수인가요? 그것이 이유 중 하나입니다. 대다수는 아니지만, 30% 정도라면 대다수인가요? 그리고 모두가 자신의 로어를 훈련시키나요, 아니면 로어 마켓플레이스에서 가져오나요?

Gorkem [00:44:42]: 그래서 오픈소스가 이미지 및 비디오 모델과 매우 잘 작동하는 이유입니다. 왜냐하면 이 큰 로어 생태계에 접근할 수 있기 때문입니다. 모두가. 좋은 로어 생태계를 만들 수 있는 비공개 소스 모델을 본 적이 없습니다. 기본적으로 존재하지 않습니다. 아마도 미드저니의 SREFs가 있겠지만, 그것들을 로어로 간주할 수 있을지는 모르겠습니다. SREFs는 그냥 시드(seed)죠? 조건화.

Batuhan [00:45:06]: 다른 조건, 프롬프트 같은 것이라고 부릅시다. 네.

Gorkem [00:45:08]: 네. 그리고 오직 오픈소스 모델만이 이 풍부한 로어 생태계를 가지고 있으며, 그것은 극도로, 극도로 인기가 많습니다.

Batuhan [00:45:15]: 하지만 가장 오래된 모델들에게도 새로운 생명을 불어넣습니다. 아시나요? 이런 멋진 로어들을 보면요. 저희는 여전히 많은 사람들이 자신의 로어와 함께 STXL을 사용하고 있습니다. 왜냐하면 그들은 품질에 만족하고, 충분히 빠르고, 충분히 저렴하기 때문입니다. 아시나요? 놀랍습니다. 이 모델들은 언어 모델처럼 단 한 번에 해결되지 않습니다. 편집 모델조차도, GPT 이미지 원이나 플럭스 컨텍스트, 코인 이미지 같은 것들도, 당신의 얼굴이나 여러 사람을 넣으면 품질을 얻을 수 없습니다. 90% 정도는 될 겁니다. 하지만 6개에서 20개의 이미지로 1000번 정도 훈련하면, 99%의 정확도를 얻을 수 있습니다. 저희는 올바른 하이퍼파라미터를 미세 조정하고, 분산 트레이너, 분산 옵티마이저 같은 것을 만드는 데 많은 노력을 기울였습니다. 그리고 그것들로, 사람들은 이제 플랫폼에서 30초 이내에 자신의 로어를 훈련하고, 같은 작업에서 추론을 실행하며, 같은 얼굴 캐릭터에 대해 99%의 정확도를 얻을 수 있습니다. 이것은 아마도 소비자 측보다는 엔터프라이즈 측에서 더 많이 직면하는 가장 큰 과제 중 하나입니다. 아시나요? 자산을 만들고 있다면, 그것이 누구처럼 보이는지는 별로 신경 쓰지 않습니다. 하지만 실제로 제품 광고를 하고 있다면, 제품과 똑같이 보이기를 원합니다. 제품의 배너에 있는 모든 픽셀이 그렇게 보이기를 원합니다. 그래서 20개의 이미지로 LaCroix 로어를 훈련합니다. 그리고 그 후에는 거의 완벽한 픽셀, 완벽한 모델을 갖게 됩니다.

Alessio [00:46:29]: 알겠습니다. 모든 게스트에 대해 LoRA를 훈련시켜야겠네요. 그러면 게스트가 썸네일을 만드는 데 사용할 수 있겠어요.

Swyx [00:46:35]: 네. 저는 그것이 매우 좋은 애플리케이션이라고 생각합니다. 왜냐하면 엄격한 스타일이 아닌 방식으로 브랜드를 주입하는 좋은 방법이기 때문입니다. 그리고.

Gorkem [00:46:42]: 저희는 이제 막 비디오 모델에 대한 사후 학습(post-training)에 진입하고 있으며, 그것이 무엇을 의미할지에 대해 생각하고 있습니다. 왜냐하면 저희는 의미 있는 좋은 기본 비디오 모델이 없었기 때문입니다. 하지만 이제 저희는 2.2 또는 후니온(who neon)에 대한 사후 학습에 정말로 투자하는 회사들을 가지고 있으며, 그 위에 립싱크 모델을 만들고, 다른 비디오 효과, 카메라 앵글을 만들고 있습니다. 사람들이 창의적인 데이터 세트로 할 수 있는 많은 가능성이 있는 것 같습니다. 제 생각에 다음 6개월에서 1년 안에 저희는 오픈소스 비디오 모델의 사후 학습을 기반으로 구축된 많은 회사들을 갖게 될 것입니다. 와.

Alessio [00:47:18]: 파이프라인에 대해 이야기해 봅시다. 저희는 팟캐스트에서 Comfy Anonymous입니다. ComfyUI는 일종의 커뮤니티 같은데, 만약 당신이 그것에 빠져 있다면, 당신은 그것을 사랑할 것입니다. 만약 당신이 그것에 대해 모른다면, 당신은 그것을 과소평가하는 경향이 있습니다. 하지만 사람들은 온갖 종류의 미친 워크플로우를 만듭니다. 첫째, 파이프라인을 만드는 것에 대해 생각해 본 적이 있나요? 당연히 당신은 모든 모델을 호스팅하고 있습니다. 이런 질문이 있습니다.

Batuhan [00:47:36]: 저희는 File Workflows라는 파이프라인 제품을 가지고 있고, 모델들을 함께 연결할 수 있습니다. 하지만 Comfy보다는 덜 유연합니다. Comfy에서는 중간 단계의 것들도 연결할 수 있지만, 저희는 다른 모델들의 출력만 연결할 수 있습니다. ComfyUI에서는 한 모델의 잠재 공간(latents)에 접근해서 그것을 잠재 공간 업스케일러 같은 것에 전달할 수 있습니다. 저희의 경우에는 더 제한적이지만, 워크포스 제품과 서버리스 Comfy 제품이 있습니다. 사람들은 자신의 ComfyUI 워크플로우를 가져와서 워크플로우와 입력을 게시하는 것만으로 API로 실행할 수 있습니다. 그리고 모델은 당신이 제공하는 거죠. 네. 그럼, 그것은 긍정적인 신호인가요? 그것은 대형 모델에 의해 상품화될까요? 저희가 본 것은 모델이 더 좋아질수록, ComfyUI는 2년 전, 1년 전 모델이, 아시다시피, 가장 큰 ComfyUI 사용 사례 중 하나는 ST 1.5나 STXL 이미지를 생성하고 여섯 손가락 상황을 수정하는 것이었습니다. 해상도를 수정하거나, 업스케일링하는 것이었죠. 이제 모델이 실제로 너무 좋아서, 이미지 측면에서는 ComfyUI 워크플로우가 실제로 더 간단해지고 있습니다. 비디오의 경우 여전히 매우 복잡합니다. 일부 비디오 워크플로우를 보면, 50개의 노드가 있고, 그것을 처리하고 있습니다. 그래서 저는 이것이 여전히 모델이 얼마나 좋은지, 그리고 대부분의 사용 사례에 대해 주변에서 얼마나 많은 추가 작업을 해야 하는지의 문제라고 생각합니다. 예술적인 사용 사례의 경우, 여전히 그 모든 작업을 하고 있고, 그것은 저희가 지원하고 싶은 것입니다. 하지만 저희는 그것이 초대규모로 일어나는 것을 보지 못합니다. 초대규모에서는 API로 이것을 실행하는 데 천만 달러 이상을 쓰는 회사는 없습니다. 그래서 그것은 아직 일어나지 않는 것 같습니다. 왜냐하면 그것은 약간 비효율적이고, 기존 모델을 사용하는 것이 50개의 다른 것들을 짜깁기하는 것보다 더 신뢰할 수 있기 때문입니다. 언제 작동하지 않을지 모르니까요. 네.

Alessio [00:49:07]: 하지만 광고 같은 것들을 위해서는, 한 번에 하고 싶을 것 같습니다. 예를 들어, 새로운 단계를 할 거라면, 배경을 생성하는 단계, 카피를 추가하는 단계 같은 것들이요. 모델이 너무 좋다는 말씀이신가요?

Gorkem [00:49:17]: 모델 체이닝은 확실히 일어나고 있습니다. 하지만 ConfUI가 매우 잘한 것은 모델의 조각들로도 놀 수 있다는 것입니다. 네, 당신은 기본적으로 그게 전부라고 말하고 있는 겁니다. 네. 그래서 모델 체이닝, 그것이 File Workflow 제품이 하는 일입니다. 기본적으로 여러 다른 API를 연속적으로 또는 병렬로 호출한 다음 마지막에 결과를 만듭니다. 그리고 그것은 매우 인기가 있습니다.

Swyx [00:49:37]: 저희는 매우 큰 이름들로부터 엔터프라이즈 채택을 받았습니다. 네. 놀랍네요. 저는 더 넓은 주제로 넘어가려고 했습니다. 가장 먼저 떠오르는 것은 스타트업을 위한 요청입니다. 만약 당신이 Fal에서 일하지 않지만, 생태계에서 많은 것을 본다면. 그렇죠. 사람들이 작업해야 할 가장 명백한 것은 무엇인가요?

Batuhan [00:49:53]: 더 많은 모델 회사들. 더 많은 돈을 모아서 모델을 훈련시키세요. 그것은 당연히 Fal에 좋습니다. 그리고 Fal에 호스팅하세요. 만약 모델 훈련에 관심이 없다면, 다른 사람들이 훈련하는 것은 놀라운 일입니다. 더 많은 돈을 모으세요. 돈은 아주 많습니다.

Gorkem [00:50:05]: 또는 이미지 및 비디오 모델을 위한 Scale AI처럼, 데이터, 데이터 수집. 비디오 모델을 위한 더 많은 준비된 데이터 세트, 효과, 다른 카메라 앵글. 모두가 그 데이터를 수집하는 데 있어서 바퀴를 재발명하는 것 같습니다. 저는 누군가가 들어와서 이것을 대규모로 하는 것이 좋은 기회라고 생각합니다.

Swyx [00:50:27]: 정말 흥미롭네요. 왜냐하면 제 생각에 이것이 Together AI가 Red Pajama로 한 일이기 때문입니다. 그들은 실제로 언어 모델을 위한 데이터 세트를 구축하여 사람들이 서비스할 수 있는 더 많은 오픈 언어 모델을 만드는 데 도움을 주었습니다. 그래서 어느 시점에는, 실제로 여러분이 그것을 하는 것이 합리적일 수 있습니다. 네.

Batuhan [00:50:40]: 이미지 데이터는 저작권 문제 등에서 좀 더 까다로운 상황입니다. 하지만 흥미로운 분야입니다. 일본에서 하세요.

Gorkem [00:50:49]: 집중이 필요하다고 생각합니다. 이것은...

Batuhan [00:50:54]: Görkem이 말한 것과 연결된 한 가지는 이미지/비디오 RL(강화 학습)입니다. 그것은 저희에게 미지의 영역입니다. 더 말씀해주세요. 못합니다. 그것이 어떤 모습일까요? 비디오 모델을 RL하여 월드 모델로 만들 수 있을까요? 할 수 있습니다. 그렇죠? 만약 할 수 있다면. 본질적으로 동사 모델은 RL된 비디오 모델이 아닙니다. 당신이 그것을 움직이도록 조건화하는 곳이죠. 그래서 이미지 및 비디오 모델을 RL하는 사용 사례는 무엇일까요? 저는 모르겠습니다. 하지만 만약 제가 일하지 않았다면, 그것은 탐험해 볼 만한 재미있는 일이 될 것입니다. 네.

Swyx [00:51:24]: 그리고 이것은 편집을 위한 것인가요? 왜냐하면 RL은 보상이 편집이기 때문인가요?

Batuhan [00:51:29]: 그게 문제입니다. 그것이 당신이 찾아야 할 것입니다. 그렇죠? 보상 함수는 무엇이며, 이 기본 모델 위에 적용할 수 있는 흥미로운 보상 함수는 무엇인가요?

Swyx [00:51:37]: 알겠습니다. 흥미롭네요. 알겠습니다. 사실, 저는 정말로 묻고 있었습니다. 하지만 만약 제가 Fal 래퍼 스타트업을 만든다면, 그 위에요. 왜냐하면 여러분은 매우 낮은 수준에 있고, 그것은 환상적입니다. 하지만 저는 또한 우리 청취자들에게 몇 가지 아이디어를 주고 싶습니다. 만약 그들이 그 수준에서 일하지 않을 것이라면요.

Gorkem [00:51:51]: 다시 한번 말하겠습니다. 디지털 마케팅 분야는 광고, 광고입니다. 거기에는 너무 많은 기회가 있고, 모두가 여전히 어떤 창작자든 들어와서 무언가를 할 수 있는 수평적인 애플리케이션을 만들려고 노력하고 있습니다. 하지만 특정 산업에 훨씬 더 집중하고, 다른 종류의 제품에 훨씬 더 집중해야 합니다. 애드 네트워크처럼요. 거기에는 많은 잠재력이 있습니다. 클릭.

Swyx [00:52:13]: 그리고 모델에 대한 요청, 당연히 더 많은 오픈 모델을 원하시겠죠. 그건 당신에게 좋습니다. 하지만 모델의 전문화 같은 것이 있나요? 제 생각에 이미지, 이미지 편집은 제가 올해까지 예상하지 못했던 큰 돌파구였습니다.

Batuhan [00:52:26]: 저희는 "오, 당연히 그럴 거야"라고 생각했습니다. 심지어 OpenAI도 이것이 이렇게 커질 것이라고 예상하지 못했습니다. 최근 기술이 얼마나 인기가 많아졌는지요. 그리고 모두가 따라잡기 시작했습니다.

Swyx [00:52:35]: 저는 매년 유럽에서 만나는 유럽 그룹의 일원이었는데, 그들이 이것에 대해 이야기하고 있었습니다.

Batuhan [00:53:02]: 스윅스와 알레시오 이미지 모델은 사용하는 데이터 세트에 의해 정말, 정말, 정말 영향을 많이 받습니다.

Gorkem [00:53:13]: 네, 제 생각에 시장에 공백이 있는 한 가지 명백한 것은 VO3가 매우 비싸다는 것입니다. 그리고 사람들이 그것을 좋아하는 이유는 대화입니다. 그렇죠? 만약 당신이 더 작고, 더 저렴하며, 덜 유능하지만 대화와 사운드를 매우 잘 할 수 있는 비디오 모델을 만들 수 있다면, 저는 확실히...

Batuhan [00:53:31]: 저희가 본 오픈소스 중 하나는 멀티토크(Multitalk)였습니다. 그것은 원(One)의 사후 학습 버전이었고, 대화에 정말, 정말 좋습니다. 하지만 일반화 능력을 잃었습니다. 어느 시점에서는 말하는 얼굴만 가능하고, VO3는 일반화할 수 있고 장면 등을 할 수 있습니다. 그래서 저는 이 둘 사이에, 말하는 얼굴과 극도로 일반화된 비디오 모델 사이에 어떤 중간 지점이 있어야 한다고 생각합니다. 그것은 실행 비용이 훨씬 저렴합니다. 하지만 동시에, 이것은 매우 모방적이기 때문에 대화를 얻을 수 있습니다. 아시다시피, 사람들이 이것으로 게시할 수 있는 밈은 무한하고, 이것으로 할 수 있는 광고도 무한합니다.

Alessio [00:54:05]: 하지만 비디오 모델이 있고, 그 비디오에 대한 오디오를 생성할 수 있는 별도의 오디오 전용 모델이 있는 세상은 상상하지 않으시나요?

Swyx [00:54:11]: 이것이 이 질문에 대한 단어죠?

Gorkem [00:54:13]: 네. 여러 가지를 꿰매어 맞추나요, 아니면 더 나은 것을 덜 하나요? 사람들은 VO3 이전에 그렇게 했습니다. 하지만 VO3가 매우 잘하는 것은 타이밍입니다. 마치 농담을 요청하면, 그 전달과 타이밍, 웃음, 그리고 농담이 터지기 직전에 기다리는 것, 그 모든 것이 너무 완벽하게 맞춰져 있습니다. 따로 할 때는 그것을 얻을 수 있다고 생각하지 않습니다. 모두 똑같습니다.

Batuhan [00:54:37]: 그것은 또한 말하는 얼굴에 인간의 억양 소리를 맞춥니다. 그렇죠? 그것은 다른 텍스트-투-스피치 모델에게는 알려지지 않은 도전입니다. 매우 자연스럽게 느껴집니다. VO3가 최고의 텍스트-투-스피치 모델인가요? 그것은 또한 최고의 텍스트-투-스피치 모델 중 하나입니다. 정말 좋습니다. 어떤 모델도 그것이 하는 것을 할 수 있다고 생각하지 않습니다.

Alessio [00:54:53]: 하지만 반론은 우리가 영화를 더빙한다는 것입니다. 그래서 이미, 아시다시피, 당연히 할 수 있습니다.

Batuhan [00:55:00]: 그것은 또한 최고의 립싱크 모델입니다. VO3는 가장 정확한 립싱크를 가지고 있습니다. 왜냐하면 매우 자연스럽게 생성되기 때문입니다. 정말 좋은 립싱크 모델들이 있습니다. 제 생각에 그들은 95% 정도 도달했지만, VO3는 100% 도달했습니다. 99% 정도요.

Swyx [00:55:11]: 저에게 이것은 워크플로우, ComfyUI, 그리고 이 모든 것들에 대해 가장 비관적인 한 가지입니다. 왜냐하면 그냥 더 큰 모델을 기다리면 되기 때문입니다. 이것은 순전히 뼈아픈 교훈입니다. 네, 저희는 ComfyUI를 사랑합니다.

Swyx [00:55:23]: 하지만 당연히 기술이 아직 존재하지 않을 때는 여러 가지를 꿰매어 맞춰야 합니다. 네. 그럼 엔지니어를 구하시나요? 네.

Alessio [00:55:30]: 제 말은, 분명히 채용 중이시죠? 방금 1억 2,500만 달러를 투자받으셨잖아요. 저희 조직은 매우 선별적인 채용 방식을 가지고 있습니다.

Batuhan [00:55:36]: 저희는 최근에 100명, 40명을 넘게 채용했습니다. 하지만 3개월 전에는 20명이었습니다. 그래서 지난 3개월 동안 저희는 실제로 최고의 커널 엔지니어, 최고의 인프라 엔지니어, 최고의 제품 엔지니어, 최고의 ML 엔지니어를 가속화해 왔습니다. 만약 당신이 하는 일에서 최고라면, 그냥 저희와 함께하세요. 저는 당신이 무엇을 하든 상관없다고 생각합니다. 저희는 지금 최고의 인재를 채용하고 있습니다.

Gorkem [00:55:56]: 시장 진출(go-to-market) 측면에서도 저희는 어카운트 이그제큐티브, 고객 성공 매니저를 채용하고 있습니다. 왜냐하면 저희는 매우 큰 기업들과 협력하기 때문입니다. 저희는 회사의 그쪽도 성장시켜야 합니다. 네.

Alessio [00:56:07]: 특히 엔지니어링 측면에서, 얼마나 많은 인력이 필요하다고 생각하시나요? "린 AI(Lean AI)"라는 질문이 있습니다. 코딩 에이전트 같은 거죠.

Batuhan [00:56:14]: 저희 성능 팀은 7명 정도입니다. 제 생각에 7명이 항상 성능에 집중하고 있고, 저희 응용 ML 팀과 일부 중복되는 부분이 있습니다. 이 팀은 이 모델들을 가져와서 제품화하고, 새로운 기능을 노출하고, 파인튜너를 구축합니다. 그리고 고객들이 이 모델들을 채택하도록 돕습니다. 그래서 그 팀은, 제 생각에 두 배, 세 배로 확장할 수 있습니다. 왜냐하면 무한한 수의 모델이 있고, 더 많은 독점 모델을 가진 더 많은 고객을 갖게 될 것이기 때문입니다. 네. 그래서 그들을 최적화하는 것을 돕는 것은 저희가 가진 정말 좋은 기능입니다.

Gorkem [00:56:40]: 그 팀은 매우 잘 확장됩니다. 왜냐하면 항상 독립적인 작업이 가능하기 때문입니다. 아, 알겠습니다. 그래서 이 세 사람은 이 새로운 모델에 대해 작업하면서 그것을 최적화하려고 노력하고 있습니다. 그리고 그것은 이 다른 모델을 최적화하려는 노력과는 완전히 독립적입니다. 그래서 저희는 그 응용 ML 팀을 위해 많은 채용을 해왔습니다.

Batuhan [00:56:56]: 저희 팀의 목표는, 응용 ML 팀과 제품 팀과는 대조적으로, 아마도 팀을 간결하게 유지하고, 사람들이 자신의 애플리케이션에 직접 통합할 수 있는 더 높은 수준의 구성 요소를 더 많이 구축하는 것입니다. 왜냐하면 지금은 SDK나 SDK만 있지만, 구성 요소를 생각해보세요. 당신이 전자 상거래 웹사이트 디자이너이고, 최고의 구성 요소 디자이너가 아니라고 상상해보세요. 그래서 여기에 당신의 앱에 넣을 수 있는 가상 시착 구성 요소가 있습니다. 그런 것들, 더 높은 수준의 구성 요소들입니다. 그리고 이것은 또한, 아시다시피, 와이프 코딩이 매우, 매우 놀라웠다는 사실에서 비롯됩니다. 저희는 모두, 저희는 상당한, 매출 면에서는 매우 작지만, 사용자 채택이 상당한 양으로 증가하는 것을 봅니다. 단지 저희 지원 티켓을 보면, 아마도 그들은 더 많은 지원이 필요하지만, 제품 구축에 대한 전문 지식이 그다지 많지 않은 사람들이 이러한 애플리케이션을 코딩하고 있습니다.

Swyx [00:57:43]: 그래서 저희는 그들에게 더 많은 가드레일 경험을 제공하여, 다른 모든 낮은 수준의 구성 요소를 건드리지 않고도 훨씬 쉽게 통합할 수 있도록 하고 싶습니다. 개발자 경험을 정말 잘 챙겨주시네요. 그럼 뛰어난 저수준 엔지니어들.

Alessio [00:57:57]: 그리고 뛰어난 고수준. 음, 네, 고수준 엔지니어, 뛰어난 엔지니어, 뛰어난 시장 진출 인력, 뛰어난 뭐든지, 그냥 당신의 생각입니다.

Swyx [00:58:04]: 저는 항상 정의를 다듬으려고 노력하고 있습니다. 아시다시피, '뛰어난(cracked)'. 두 분 모두 실패의 기술적인 측면을 이끌고 계시죠. 정말 어려운 기술적인 문제가 있는데, 만약 누군가 해결책을 가지고 있다면, 그들이 즉시 당신과 이야기해야 하는 그런 문제가 있나요? 아마도 그렇게 질문을 구성하는 것이 방법일 수 있겠네요.

Batuhan [00:58:16]: Blackwell에서 FBA를 사용하여 희소 어텐션 커널(sparse attention kernel)을 작성하고 말해보세요. 만약 그것을 할 수 없다면, 저희와 함께하세요. 저희는 이미 좋은 기반을 가지고 있습니다. 즉석에서 채용됩니다. 즉석에서 채용됩니다. 아시나요? 그런 것들입니다. 저는 이런 응용 ML 사람들 중 일부를 뽑는 것을 정말 좋아합니다. 저희는 그들을 디스코드에서 뽑았는데, 그들은 이런 종류의 용어와 미디어에 대해 작업하고 있었고, 이미 관심이 있었습니다. 우리 팀의 모든 사람들이 혁신적인 기술에 매료되었습니다. 그들은 그것에 집착합니다. 이것이 그들의 직업이 아니었더라도 이것을 했을 것입니다. 저희는 이 훌륭한 구성을 가지고 있습니다. 항상, 필수 조건은 아니지만, 자연스럽게 그렇게 되었습니다. 저희는 이 사람들을 디스코드, 트위터, 허깅 페이스에서 채용했습니다. 저희 응용 ML 엔지니어 중 한 명은 창의적인 워크플로우 등으로 허깅 페이스 스페이스에서 1위를 차지했습니다. 그래서 저희는 Fal에서 도리스를 훈련시키던 사람을 채용했습니다. 단지 그들이 멋진 로라를 훈련하고 게시하고 있었기 때문입니다. 아시나요? 그냥 멋진 일을 하세요. 그러면 저희가 당신을 찾거나, 당신이 할 수 있습니다.

Swyx [00:59:06]: 네, 그것이 제가 이 사람을 부르는 '마스터 빌더'입니다.

Alessio [00:59:10]: 왜 더 명시적으로 만들지 않나요? 만약 제가 당신의 채용 웹사이트에 들어가면, 그렇죠. "응용 ML 엔지니어에 지원하세요"라고 되어 있습니다. 그냥 어떤 채용 공고처럼 보입니다. 제 생각에 "그래서 팟캐스트를 해야 한다"는 질문이 있는 것 같습니다. 하지만 저는 그것이 Fal에 관한 것만은 아니라고 생각합니다.

Batuhan [00:59:25]: 제 생각에 일반적으로, "아는 사람은 안다"는 식인데, 저는 그것이 최선의 방법은 아니라는 것을 압니다. 사람들은 이미 Fal에 대해 알고 있습니다. 그래서 저희는 그다지 신경 쓰지 않았지만, 당신 말이 절대적으로 맞습니다.

Alessio [00:59:35]: 저희는 그것을 더... 하지만 제가 조지 호츠의 타이니그래드(tiny grad)를 보면, 이런 균형이 있습니다. "이것을 해결할 수 있다면, 아마 여기서 일해야 할 것이다." 현상금을 추가하는 것을 보시나요? "이 커널을 작성할 수 있다면, 그냥 채용될 것이다"와 같습니다.

Batuhan [01:00:00]: 그것은 또한, 저희가 본 한 가지는, 많은 사람들이 그냥 와이프 코딩을 하고 그것들을 검토하는 것과도 관련이 있습니다. 그것들을 정말로 할 수 있는 사람은 제한적입니다. 그렇죠.

Alessio [01:00:00]: 예를 들어, 그것이 형편없는 커널이 아니라 좋은 호출이라는 것을 어떻게 알 수 있나요? 하지만 당신은 인터뷰에 시간을 쓰고 있습니다. 네.

Batuhan [01:00:06]: 그래서 저희는 채용 담당자들과 함께 1차 방어선을 가지고 있습니다. 그래서 당신은... 그래서 트레이드오프가 있지만, 저는 절대적으로 동의합니다. 아마도 저희는 당신이 커널을 업로드하고, 안정성, 성능 등을 자동으로 평가할 수 있는 커널 벤치 버전을 가져야 할 것입니다. 그리고 만약 당신이 그렇게 하면, 당신은 저희 이메일을 잠금 해제하게 됩니다. 당신을 위한 이메일이지만, 네, 좋은 아이디어입니다. 저희와 함께하세요.

Alessio [01:00:31]: 멋지네요, 여러분. 다른 할 말 있나요? 마지막 생각. 네. 당신의 열변을 좋아합니다. 정말 좋았어요. 네.

Gorkem [01:00:37]: 기꺼이 열변을 토하겠습니다. 하지만 이것은 팟캐스트 스타일입니다. 네.

Swyx [01:00:40]: 아뇨, 모든 성공을 축하합니다. 음, 여러분과 노래방 가는 것도 재미있다고 말해야겠네요. 네. 다시 합시다. 둘 다 극도로 기술적이면서도 재미있는 팀입니다. 그리고 제 생각에 그렇게 하기는 꽤 어렵고 드뭅니다. 그래서 좋은 사람들이 이기는 것을 보게 되어 감사합니다.

Alessio [01:00:56]: 멋지네요, 여러분. 멋져요.