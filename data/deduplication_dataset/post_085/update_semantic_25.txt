**AI 엔지니어링의 최전선: Fal.ai와 생성형 미디어 혁신**

인공지능 공학자들을 위한 기술 컨퍼런스(11월 20일부터 22일까지 뉴욕에서 개최)의 등록 절차가 개시되었습니다. 이번 행사에서는 2025년 핵심 동향 중 하나로 생성형 영상 기술이 부상했습니다. 이 분야는 그야말로 폭발적인 성장세를 보이며, NBA 결승전 광고에서 Kalshi 사례와 같이 주류 매체에서도 쉽게 접할 수 있게 되었습니다. 저희는 무어 쌍둥이와 함께 이 주제에 대한 심층적인 에피소드를 제작한 바 있습니다. 오늘 저희는 이러한 모델들(널리 알려진 일부 비공개 소스 이미지 및 비디오 확산 모델 포함)의 추론 과정을 지원하는 핵심 주체인 Fal.ai에 대해 집중 조명합니다. 이 기업은 올해에만 연간 매출액 1억 달러에 육박하는 실적을 추가할 것으로 예상되며, 그중 영상 부문이 차지하는 비중은 점진적으로 증대하고 있습니다. 놀랍게도 불과 2년 전만 해도 이들은 데이터 파이프라인 관리 솔루션을 개발하고 있었습니다. 현재 Fal.ai는 자사 플랫폼에서 600개 이상의 모델을 운영하며, 성능 향상을 위해 100여 개가 넘는 특수 제작된 CUDA 연산 코어(CUDA kernels)를 활용합니다. 이번 팟캐스트를 통해 저희는 생성형 모델의 발전사와 그 과정에서 나타난 주요 변곡점들을 간략하게 되짚어보았습니다. 즐겁게 청취해주시길 바랍니다!

**Fal의 모델 발전 과정**
아래 언급된 모든 자료 링크는 쇼 노트에서 확인 가능합니다.

*   **스테이블 디퓨전 1.5(Stable Diffusion 1.5)**
    *   Fal이 고성능 추론 서비스 제공으로 전략적 전환을 했을 때 얻은 첫 번째 주요 성공작.
    *   광범위한 세부 조정(fine-tuning) 환경 덕분에 큰 인기를 얻음.
    *   신속하고, 경제적이며, 안정적인 특성으로 인해 LoRA와 함께 현재까지도 활용됨.
*   **스테이블 디퓨전 2.1(Stable Diffusion 2.1)**
    *   대중의 관심을 크게 받지 못한 "기대치에 미치지 못하는 결과물"로 평가됨.
*   **스테이블 디퓨전 XL(SDXL)**
    *   Fal에 초기 100만 달러 규모의 수익을 안겨준 최초의 핵심 모델.
    *   세부 조정(fine-tuning) 생태계(LoRA)를 비약적으로 성장시킴.
    *   **SDXL 라이트닝(SDXL Lightning)**: ByteDance가 개발한 경량화된 형태로, 더 빠른 결과물 생성을 가능하게 함.
*   **스테이블 디퓨전 3(SD3)**
    *   "일부 논란에 휩싸였음."
    *   개발 팀이 Stability를 떠나 Black Forest Labs를 창립하는 계기가 됨.
*   **플럭스 모델(Flux Models) (Black Forest Labs)**
    *   "비즈니스 환경에 적합한 고품질 모델"의 기준을 처음으로 제시함.
    *   출시 첫 달에 Fal의 월간 매출을 2백만 달러에서 1천만 달러, 나아가 2천만 달러 수준으로 급증시켰습니다.
    *   세 가지 버전:
        *   **슈넬(Schnell)**: Apache 2 라이선스를 따르는 극도로 경량화된 모델로, 저품질의 4단계 생성에 적합.
        *   **개발(Dev)**: 수익 공유 방식의 비상업적 라이선스.
        *   **프로(Pro)**: 호스팅을 위한 협업이 필수.
*   **제미니 이미지 모델(Gemini Image Models)**
    *   구글의 자기회귀 이미지 모델(autoregressive image models)로, 시장 가치가 제대로 평가되지 않은 것으로 간주됨.
*   **이미지 편집 모델(Image Editing Models)**
    *   **플럭스 콘텍스트(Flux Context) (Dev)**
        *   5월 말 출시.
        *   대중적 인기를 얻은 편집 모델.
    *   **취안 이미지/취안 이마저(Qwen Image/Qwen Imager)**
        *   팟캐스트 녹음 2주 전 공개.
        *   현재 플럭스 콘텍스트 개발 버전을 능가하는 성능.
        *   영상 모델의 단일 프레임을 활용할 때 뛰어난 텍스트-투-이미지(text-to-image) 성능 발휘.
    *   **스텝펀의 하이드림(Stepfun’s Hydream)**
        *   소규모 중국 연구소에서 개발한 이미지 편집 모델.
    *   **비바고(VivaGo)**
        *   또 다른 중국 연구소의 편집 모델.
*   **비디오 모델(Video Models)**
    *   **소라(Sora)**
        *   오픈AI의 모델로, 새로운 가능성을 제시했으나, 단기간 내에 후발 주자들에게 추월당하는 양상.
        *   연구자들에게 영감을 주었으나, 몇 달 만에 다른 모델들이 이를 뛰어넘기 시작.
    *   **베오3(Veo3) (Google DeepMind)**
        *   음성을 포함한 "실질적으로 활용 가능한 텍스트-투-비디오(text-to-video) 구성 요소"를 구현.
        *   운영 비용이 매우 높음.
        *   대화, 시간 동기화, 립싱크 구현에 탁월.
        *   최고 수준의 텍스트-투-스피치(text-to-speech) 모델 역할도 수행.
    *   **훈위안 비디오(Hun Yuan Video)**
        *   중국 모델로, "상당히 우수하다"는 평가를 받음.
    *   **모치(Mochi) (Genmo)**
        *   초기에는 품질 면에서 다소 미흡.
    *   **원(One) (Alibaba)**
        *   "매우 뛰어난 모델"로 평가됨.
        *   최근 새로운 버전이 공개됨.
        *   480p 초안 모드를 5초 이내에 실행 가능.
        *   720p 전체 해상도를 20초 만에 생성 (목표는 10초).
    *   **미니맥스(Minimax)**
        *   중국 비디오 모델 파트너.
    *   **클링(Kling) (Kuaishou)**
        *   중국 비디오 모델 파트너.
    *   **무비 잼(Movie Jam)**
        *   MMDiT 아키텍처의 불필요성을 주장하는 연구 논문.
    *   **멀티토크(Multitalk)**
        *   원(One)의 후처리 학습 버전(post-trained version).
        *   대화 생성에는 유리하나, 일반화 능력은 저하됨.
        *   말하는 얼굴만 생성 가능.
*   **오디오/음악 모델(Audio/Music Models)**
    *   **플레이HD/플레이AI(PlayHD/PlayAI)**
        *   Fal이 추론 최적화를 지원.
        *   일부는 자기회귀 모델(autoregressive models)을 사용.
        *   일부는 확산 기반 접근법(diffusion-based approaches)을 채택.
    *   **노토리어스(Notorious)**
        *   확산 기반 오디오 생성으로 명성이 높음.

**쇼 노트(Show Notes)**
*   Fal.ai
*   Gorkem
*   Bathuan
*   Kuaishou
*   Minimax
*   Genmo
*   PJ Ace
*   Black Forest Labs
*   Stable Diffusion
*   Stable Diffusion 1.5
*   Stable Diffusion 2.1
*   Stable Diffusion XL (STXL)
*   Flux Models
*   PixArt
*   Qwen/Qwen-VL
*   PlayHT
*   SDXL Lightning
*   AnimateDiff
*   Tail Draw
*   HunYuan
*   Hydream
*   OmniHuman
*   Seedream
*   Multitalk
*   Genie (Google’s world model)
*   ComfyUI
*   Scaling Rectified Flow of Transformers
*   Diffusion Transformers
*   Consistency Models

**타임스탬프(Timestamps)**
*   [00:00:00] 서론
*   [00:04:29] 주요 AI 모델의 변천사와 Fal.ai에 미친 영향
*   [00:07:06] 확산 모델 전문화로의 전략적 전환
*   [00:10:46] CUDA 커널 개발
*   [00:15:50] 응답 지연 시간의 중요성 및 고객 대상 A/B 테스트 결과
*   [00:17:56] 공개 모델의 접근성이 Fal의 성장에 미친 영향
*   [00:19:00] 비공개 소스 모델 제공업체와의 협력 관계
*   [00:21:19] 오디오 및 음악 작업을 위한 추론 최적화
*   [00:29:10] 영상 생성 성능 개선 노력
*   [00:29:47] OpenAI와 Gemini의 자기회귀 이미지 생성 기법
*   [00:34:45] 제어 가능한 영상 생성을 위한 월드 모델
*   [00:36:26] 중국산 오픈소스 비디오 모델의 부상
*   [00:39:30] 수익 창출 전략 및 수익 공유 모델
*   [00:42:48] 유해 콘텐츠(NSFW) 관리 및 기업용 콘텐츠 안전성 확보
*   [00:45:10] 스타트업 홍보 영상 및 생성형 비디오 도입 동향
*   [00:46:59] LoRA 기반 개인화 기술
*   [00:47:11] ComfyUI, 모델 연계, 그리고 기업용 워크플로우
*   [00:51:58] 생성형 미디어의 실제 적용 분야
*   [00:54:15] 스타트업을 위한 제언 및 미래 기회 탐색
*   [01:00:29] Fal.ai의 인재 채용 및 팀 구성
*   [01:03:27] 탁월한 엔지니어의 자질

**전문 녹취록(Transcript)**
Alessio [00:00:03]: 여러분, 안녕하십니까. Latent Space 팟캐스트에 오신 것을 환영합니다. 저는 Kernel Labs의 창립자 알레시오(Alessio)입니다. SmolAI의 창립자 스윅스(Swyx)와 함께 진행합니다.

Swyx [00:00:09]: 안녕하세요. 오늘 FAL의 고르컴(Gorkem)과 바투한(Batuhan)을 스튜디오에 모시게 되어 매우 기쁩니다. 환영합니다. 네, 초대해주셔서 감사합니다. 오랫동안 애청해왔는데, 출연은 처음입니다.

Swyx [00:00:21]: 고르컴, 당신과 저는 회사가 아직 features and labels였을 때부터, 당신이 아마존을 떠났을 때부터 꽤 오랫동안 알고 지냈죠. 당시 사업 아이템이 무엇이었는지 정확히 기억나지 않네요. 솔직히 제 기록을 다시 확인해야겠지만, 그때도 런타임 최적화에 집중하고 있었죠.

Gorkem [00:00:33]: 맞습니다. 초창기에는 피처 스토어 구축에 몰두했고, 이후 방향을 전환하여 클라우드 환경에서 파이썬 런타임을 개발하는 데 집중했습니다. 이 노력이 점차 발전하여 추론 시스템으로 확장되었고, 오늘날의 FAL, 즉 생성형 미디어 플랫폼으로 진화했습니다. 저희는 이미지, 비디오, 오디오 모델의 추론 성능을 최적화하는 것을 넘어, 개발자들이 생성형 미디어 분야 전체를 효과적으로 활용할 수 있도록 지원하는 것을 목표로 합니다.

Swyx [00:01:01]: 정말 놀랍네요. 그 여정에 대해서도 깊이 있게 논의할 수 있겠군요. 바투한도 소개하고 싶습니다. 저희가 서로 알게 된 지는 얼마 되지 않았지만, 제 밋업에 몇 차례 참석하셨죠. 당신은 엔지니어링 총괄을 맡고 계십니다.

Batuhan [00:01:09]: 네, FAL에서 엔지니어링 부문을 이끌고 있습니다. 이 자리에 함께하게 되어 기쁩니다.

Swyx [00:01:14]: 당신의 경로는 어떠했습니까?

Batuhan [00:01:16]: 2021년, 부르카이(Burkay)가 회사를 막 시작할 무렵, 시드 투자 유치 직전에 그를 만났습니다. 부르카이와 고르컴을 온라인에서 알게 되었는데, 저희 모두 터키 출신이라는 공통점이 연결고리가 된 것 같습니다. 그들을 만났을 때, "저희와 함께 하시겠습니까?"라는 제안을 받았습니다. 저는 파이썬 언어의 핵심 개발자 중 한 명이었기에, 파이썬 언어 기반의 개발자 도구에 대한 풍부한 경험을 가지고 있었습니다. 그래서 파이썬 클라우드를 구축하기 위해 이곳에 합류했고, 이것이 현재 저희가 개발하고 있는 추론 엔진과 생성형 미디어 클라우드로 발전했습니다.

Swyx [00:01:43]: 그리고 이제 당신은 파이썬보다는 CUDA와 맞춤형 커널 작업에 더 많은 시간을 할애하고 계시겠군요.

Alessio [00:01:50]: 네, 맞습니다. 모던 데이터 스택이 등장했을 때의 DBT Fal이 기억나네요. Fal의 규모에 대해 간략히 설명해주실 수 있을까요? 방금 1억 2,500만 달러 투자를 유치하셨죠. 정말 대단합니다. 그 이야기도 해보죠. 네. 제가 당신들의 초기 투자 라운드를 놓쳤던 이유이기도 합니다. 그것도 한번 짚어볼 수 있겠네요. 현재 개발자 수는 몇 명이며, 몇 개의 모델을 서비스하고 있나요? 그 외에 인상적인 수치들이 있다면 말씀해주세요.

Gorkem [00:02:11]: 저희 플랫폼에는 약 200만 명의 개발자가 등록되어 있습니다. 오랫동안 깃허브(GitHub) 로그인을 필수로 했었는데 최근에 변경되었습니다. 따라서 깃허브 계정을 가진 모든 사용자를 개발자로 간주하고 있습니다. 현재 플랫폼에서 서비스하는 모델은 약 350개에 달합니다. 대부분 이미지, 비디오, 오디오 모델이죠. 초기에는 이미지에 집중했지만, 이후 오디오를 추가했고, 이제는 비디오 분야로도 확장되었습니다. 네, 대략적인 규모는 이렇습니다. 최근 시리즈 C 투자를 발표했으며, 지난 한 해 동안 크게 성장했고, 이러한 성장세는 지속되고 있습니다.

Alessio [00:02:50]: 아주 성대한 시리즈 C 투자 축하 파티를 여셨더군요. 그리고 매출이 1억 달러를 넘어섰다고요? 이는 단순히 개발자들이 시험 삼아 사용하는 수준을 넘어섰다는 의미로 해석됩니다. 맞습니다. 네, 정말 대단하네요. 350개 모델이라고 하셨는데, 이는 여러분이 서비스할 수 있는 전체 모델의 어느 정도 비율을 차지합니까? 특히 특정 분야에서는요.

Batuhan [00:03:08]: 이 모델들의 후처리 학습(post-trained) 버전은 무한히 많습니다. 저희는 플랫폼 스택의 부족한 부분을 채우는, 즉 격차를 해소하는 모델들을 제공하고자 노력합니다. 따라서 저희가 기존에 보유한 모델들과 비교했을 때 어떤 면에서든 현저히 뒤떨어지는 모델은 추가하지 않습니다. 저희는 고객의 특정 요구사항을 해결할 수 있는 독창적인 모델들을 도입하려고 합니다. 이것이 바로 현재 350개 모델을 보유하게 된 이유입니다. 예를 들어, 텍스트-이미지 모델이 20~30개 정도 있지만, 그중 하나는 로고 생성에 탁월하고, 다른 하나는 인물 얼굴 생성에 뛰어납니다. 각 모델이 고유한 특성을 지니고 있는 것이죠. 그러나 전반적으로 성능이 현저히 떨어지는 모델은 플랫폼에 추가하지 않습니다. 따라서 저희가 추가할 수 있는 모델의 수는 실질적으로 무한합니다. 모델 평가 시 자체 기준에 의존하십니까, 아니면 커뮤니티의 피드백을 주로 참고하십니까? 저희는 주로 자체 평가를 활용하며, 동시에 저희 또한 커뮤니티의 일원이므로 커뮤니티의 동향을 면밀히 주시하며 차세대 애플리케이션에 어떤 모델이 등장할지 파악합니다. 그래서 저희가 직관적으로 "이것이 유망하다"고 판단하면 주저 없이 추가합니다.

Swyx [00:03:59]: 제가 알기로는 자체 평가 결과를 외부에 공개한 적은 없으시죠? 아뇨, 공개하지 않습니다. 내부 자료입니다. 그럼 커뮤니티는 레딧(Reddit), 트위터(Twitter) 같은 소셜 미디어 플랫폼을 의미하나요?

Batuhan [00:04:05]: 트위터, 레딧, 허깅 페이스(Hugging Face) 등에서 모델들의 인기를 확인합니다. 알겠습니다.

Gorkem [00:04:12]: 이 정보를 어디서 얻는지 사람들에게 알리고 싶네요. 이 일의 가장 매력적인 점은 모델이 출시될 때마다 느껴지는 아드레날린 분출, 즉 팀 전체가 무언가를 신속하게 개발하고 배포하려는 열정입니다. 그리고 이런 일이 매주 반복됩니다. 매주가 흥미진진하죠.

Alessio [00:04:27]: 가장 큰 도약을 보였던 모델들의 간략한 역사를 짚어볼 수 있을까요? 아마도 사용량 측면에서요. 모두가 스테이블 디퓨전을 알고 있고, 그 다음에는 플럭스 모델, 그리고 블랙 포레스트 랩스(Black Forest Labs) 같은 것들이 있죠. 여러 다른 이정표들이 있습니다.

Batuhan [00:04:40]: 역사적으로 볼 때, 저희의 가장 큰 첫 성공작은 스테이블 디퓨전 1.5였습니다. 그 시점이 바로 저희가 생성형 미디어 클라우드라는 새로운 패러다임으로 실제로 전환한 때였습니다. 저희는 이 모델의 호스팅을 시작했습니다. 당시 저희는 서버리스(serverless) 런타임을 보유하고 있었는데, 모두가 스테이블 디퓨전 1.5를 직접 실행하고 있었고, 이는 자원 활용 면에서 비효율적이며 최적화되지 않았다는 것을 인지했습니다. 그래서 저희는 이 모델의 최적화된 버전을 API 2.0 형태로 제공하여 확장성을 확보하고, 개발자들이 파이썬 코드를 직접 배포할 필요가 없도록 만들기로 결정했습니다. 이는 제품 엔지니어와 모바일 엔지니어들이 쉽게 활용하기를 바랐기 때문입니다. 저희는 스테이블 디퓨전 1.5를 제공하기 시작했고, 이는 엄청난 인기를 얻었으며, 그 주변의 세부 조정(fine-tuning) 생태계 또한 매우 활발했습니다. 스테이블 디퓨전 2.1이 출시되었지만, 다소 기대에 못 미치는 결과물로 큰 주목을 받지 못했습니다. 이후 STXL이 등장했는데, 이 모델이 저희에게 최초로 100만 달러 규모의 수익을 안겨준 핵심 모델이었습니다. STXL과 함께, 로라(LoRA)를 활용한 세부 조정 생태계 또한 폭발적으로 성장하기 시작했습니다. 사용자들은 자신의 얼굴이나 사물을 세부 조정하기 시작했고, 로라를 이용한 생성 작업이 크게 유행했습니다. 스테이블 디퓨전 XL 이후에는 잠시 조용한 시기가 있었습니다. 아시다시피, ST3는 일부 논란이 있었고, Stability 팀이 회사를 떠나 블랙 포레스트 랩스를 설립했으며, 그들이 플럭스 모델을 공개했습니다. 이 모델은 상업적으로 활용 가능한, 엔터프라이즈급의 고품질 모델이라는 기준을 처음으로 제시했습니다. 플럭스 모델 출시 첫 달에 저희 매출은 200만 달러에서 1,000만 달러로 급증했습니다. 이는 엄청난 도약이었죠. 다음 달에는 2,800만 달러를 기록하며 꾸준히 성장했습니다. 이후 비디오 모델들이 등장하기 시작했습니다. 저희는 루마 랩스(Luma Labs)와 협력 관계를 맺었고, 중국의 다른 비디오 모델 기업들, 예를 들어 클링(Kling), 콰이쇼우(Kuaishou), 미니맥스(Minimax)와도 파트너십을 체결했습니다. 이러한 모델들은 또 다른 시장 부문을 창출하며 저희에게 큰 성장을 가져다주었습니다. 그리고 마지막으로 가장 큰 기여를 한 것은 베오3(VO3)였습니다. 이 모델이 실제로 활용 가능한 텍스트-투-비디오 구성 요소를 만들어냈습니다. 이전에는 텍스트-투-비디오가 지루하고 소리 없는 영상으로 만족도가 낮았지만, 이제는 정말 훌륭한 경험을 제공합니다. 온라인에서 볼 수 있는 모든 밈(meme)과 광고를 만들 수 있게 된 것이죠. 따라서 구글 딥마인드(Google DeepMind)와 베오3를 위해 파트너십을 맺은 것은 저희에게 또 다른 중대한 도약이었습니다.

Swyx [00:06:41]: 네, 정말 생성형 미디어의 역사를 잘 요약해주셨네요. 그래서 그 부분에 대해 더 깊이 파고들고 싶었습니다. 당연히 비디오 분야에 대해 심층적으로 다룰 수 있지만, 그 전에 이미지 측면의 전체적인 역사를 먼저 다루고 싶었습니다. 특히 시작하고 싶었던 것은 바로 방향 전환 결정이었습니다. 그 점을 더 깊이 탐구하고 싶습니다. 아시다시피, 사소한 결정은 아니었지만 분명히 올바른 선택이었습니다. 당시에는 많은 기업들이 스테이블 디퓨전을 호스팅하고 있었죠. 그래서 단순히 확산 모델 추론에 특화하는 것만으로 회사를 설립하고 성공할 수 있다는 것이 명확하지 않았습니다. 어떤 확신이 있었나요? 어떤 논의가 오갔습니까?

Gorkem [00:07:16]: 네, 그 시점에서 몇 가지 중요한 결정을 내려야 했습니다. 저희는 회사를 GPU 오케스트레이션(orchestration) 방향으로 더 발전시킬 수도 있었습니다. 본질적으로 저희는 파이썬 런타임을 보유하고 있었고, 이를 GPU 위에서 실행하고 있었죠. 그 자체가 회사의 핵심 사업이 될 수도 있었습니다. 하지만 저희는 저희가 가진 작은 SDK(GPU에서 파이썬 코드를 실행하기 위한 도구)를 사용하는 모든 개인과 기업들이 똑같은 작업을 수행하고 있다는 사실을 목격했습니다. 그들은 스테이블 디퓨전 애플리케이션을 배포하고 있었고, 아마도 그 위에 로라(LoRA)를 일부 적용하거나, 다른 버전을 사용하고, 인페인팅(in-painting), 아웃페인팅(out-painting)과 같은 작업을 하고 있었습니다. 이는 매우 비효율적인 방식이었습니다. 저희는 이 추론 과정을 실제로 최적화하고, 모두가 그 혜택을 누릴 수 있는 API를 제공해야 한다고 결론 내렸습니다. 그리고 이를 멀티테넌트(multi-tenant) 방식으로 운영할 수 있다고 판단했습니다. 이것이 첫 번째 결정이었습니다. 그리고 당연히 스테이블 디퓨전 출시 4~5개월 후 라마2(Llama 2)가 등장했고, 다시 한번 중요한 결정의 순간이 찾아왔습니다. 언어 모델 분야로 진출할 수도 있었죠. 맞습니다. 당시 추론 서비스 제공업체들은 아마 두세 곳 정도 있었는데, 그들 모두 언어 모델에 집중했습니다. 저희는 언어 모델 호스팅이 좋은 사업이 아니라고 판단했습니다. 그 당시 저희는 "우리는 결국 OpenAI, Anthropic, 그리고 이 모든 거대 연구소들과 경쟁하게 될 것"이라고 생각했습니다. 결과적으로는 저희의 판단이 옳았습니다. 왜냐하면 언어 모델의 킬러 애플리케이션은 검색(search)이며, 이는 결국 구글(Google)과 경쟁하는 것을 의미하기 때문입니다. 그리고 구글은 원한다면 이 서비스를 무료로 제공할 수도 있습니다. 이는 그들에게 매우 중요하고, 그들의 사업을 즉각적으로 위협하기 때문입니다. 반면 이미지와 비디오 모델은 완전히 새로운 시장이었습니다. 저희는 어떤 기존 강자와도 직접적으로 경쟁할 필요가 없었습니다. 저희보다 훨씬 큰 기업으로부터 시장 점유율을 빼앗으려 하지 않아도 되었습니다. 그리고 저희는 그 점이 마음에 들었습니다. 저희는 이 분야에서 리더가 될 수 있다고 생각했습니다. 틈새시장이었지만 매우 빠르게 성장하고 있었죠. 그래서 저희는 구글이나 OpenAI, Anthropic과 같은 거대 기업들과 맞서 싸우기보다는, 이 급성장하는 틈새시장에서 리더가 되거나 리더가 되기 위해 노력하는 길을 선택했습니다. 그것이 저희가 내린 결정이었고, 결과적으로 현명한 선택이었습니다. 왜냐하면 저희는 저희가 속한 시장을 정의하고, 사용자들을 교육하며, 그 시장과 함께 성장할 수 있었기 때문입니다. 그리고 지금까지는 저희가 이 분야를 중심으로 회사를 구축할 수 있을 만큼 충분히 빠르게 성장해왔습니다.

Swyx [00:09:37]: 네, 그리고 AIE에서 언급하셨듯이, 이제는 생성형 미디어 트랙, 생성형 미디어 전문 투자자들이 있죠. 그것을 생성형 미디어라고 불러주셔서 감사합니다. 네, 당연히 이것은 하나의 현상이고 사람들은 그것에 관심을 가집니다. 그리고 저는 이것이 경제를 변화시킬 것이라고 생각합니다. 그리고 창의적인 사람으로서, 저는 이것이 우리에게 어떤 영향을 미칠지 궁금합니다. 기술적인 부분을 유지하고 방향 전환에 대해 계속 생각해보고 싶습니다. 왜냐하면 제가 본 것 중 가장 흥미로운 방향 전환 중 하나라고 생각하기 때문입니다. 그리고 AI 시대에, 당신들은 당시 CUDA 커널 전문가가 아니었죠?

Batuhan [00:10:05]: 저는 컴파일러(compiler) 분야 출신입니다. 제 주된 업무는 파이썬 바이트코드(bytecode) 인터프리터(interpreter)를 최적화하여 속도를 높이는 것이었고, 이는 곧 성능 엔지니어링(performance engineering)의 영역입니다. 그리고 당시에는 CUDA 커널 전문가가 그렇게 많지 않았다고 생각합니다. 그래서 저희는 적절한 시기에 이 분야에 뛰어든 셈입니다. 아시다시피, 사실 그 당시의 기술 환경은 현재보다 훨씬 열악했습니다. 기본적인 스테이블 디퓨전 1.5를 실행하는 것은 컨볼루션(convolution)이 포함된 유닛(unit)과 같았고, AI 분야에서 컨볼루션 성능은 단순히 기본 기능을 사용하면 GPU 성능의 30% 정도밖에 활용하지 못했습니다. 왜냐하면 아무도 이 부분에 신경 쓰지 않았기 때문입니다. 그래서 저희가 발굴하고 최적화하기 시작한 손쉬운 개선점들이 매우 많았고, 이는 지속적으로 진화하고 발전했습니다. 현재는 훨씬 더 경쟁적인 분야가 되었죠. 엔비디아(NVIDIA)는 커널 개발에 50%에서 100%에 달하는 전담 팀을 운영하고 있습니다. 당신은 그들과 경쟁하고 있는 것입니다. 하지만 당시에는 아무도 신경 쓰지 않았습니다. 아무도 정말로 신경 쓰지 않았죠. 그래서 저희가 번성할 수 있는 좋은 새로운 분야였습니다. 그리고 VLM과 같은 커뮤니티의 노력도 없었고요.

Gorkem [00:10:57]: 정확히는 아닙니다. 이 모델들이 처음 공개되었을 때, 전 세계 어느 누구도 이들을 실제 운영 환경(production environment)에서 실행해 본 경험이 없었습니다. 그러한 사례 자체가 존재하지 않았죠. 그저 연구 결과물에 불과했습니다. 맞습니다. 네, Stability였습니다. 아마 로컬 GPU를 사용했을 겁니다. 아니면 클라우드에서 빌린 단일 GPU를 사용했을 수도 있습니다. 기본적으로 이는 제품화에 대한 관심보다는 연구에 대한 관심에 가까웠습니다. 그리고 메타(Meta)나 구글(Google)의 누구도 이 모델들을 프로덕션 환경에서 실행해 본 적이 없었습니다. 그래서 저희는 이 분야를 중심으로 회사를 시작하고, 가능한 한 최대한 최적화하는 데 시간을 투자하기에 좋은 시기라고 판단했습니다. 왜냐하면 수백만 명의 사람들이 이 기술을 사용하게 할 수 있다면, 그로 인해 창출될 수 있는 경제적 가치가 매우 크기 때문입니다.

Alessio [00:11:36]: 어느 정도의 성능 향상을 이루었는지 구체적으로 설명해주실 수 있나요? 제가 여러분을 처음 만났을 때 매출이 100만 달러 정도였고, 그때 "우리는 이 모든 맞춤형 커널을 개발하고 있어요"라고 말씀하셨죠. 그리고 아마도 그 일부는 "실제로 얼마나 많은 커널을 작성할 수 있을까?"라는 질문과 관련이 있을 겁니다. 물론이죠. 아시다시피, 이 모든 다양한 모델들을 지원하면서요. 그 성능 향상의 범위는 어느 정도입니까? 여러 모델에 걸쳐 재사용 가능한 커널을 작성하고 있습니까? 아니면 모델별로 얼마나 많은 작업을 해야 합니까?

Batuhan [00:11:59]: 지난 3년 동안 정말 많은 발전이 있었습니다. 처음 시작했을 때는 스테이블 디퓨전 1.5라는 단일 모델만 있었습니다. 그래서 저희의 모든 커널 개발 노력은 어떻게 하면 스테이블 디퓨전 1.5를 최대한 빠르게 만들 수 있을까에 집중되었습니다. 당시 PyTorch로는 약 10초 정도 걸렸는데, torch compiled나 torch inductor 같은 도구도 없었습니다. 그래서 같은 GPU에서 10초 걸리던 것을 아마 2초 정도로 줄일 수 있었습니다. 그리고 저희는 그것으로 시작했습니다. 다음으로, 더 많은 모델을 추가하면서 스테이블 디퓨전 XL은 다른 아키텍처였고, 픽스아트(PicsArt)도 다른 아키텍처였습니다. 이 모든 다른 아키텍처들이 등장하기 시작했습니다. 저희는 추론 엔진을 만들기로 했습니다. 저희는 이것을 커널, 병렬화 유틸리티, 확산 캐싱 방법, 양자화(quantization) 등 모든 것을 하나의 패키지로 결합한 것이라고 부릅니다. 그리고 저희는 이 추론 엔진을 개발했습니다. 동시에 PyTorch 2.0이 토치 인덕터(Torch inductor)와 토치 다이나모(Torch Dynamo)와 함께 출시되었는데, 이는 토치 컴파일드(Torch compiled)를 위한 것으로, 본질적으로 신경망의 실행을 추적하고 융합된, 즉 더 효율적인 트라이톤(Triton) 커널을 생성하는 방법입니다. 그리고 저는 JIT(Just-In-Time) 컴파일러의 열렬한 팬입니다. 저는 파이썬을 위한 JIT 컴파일러인 파이파이(PyPy)에서 일했었습니다. 그리고 저희는 이것이 훌륭한 아이디어라고 생각했습니다. 이것을 확산 모델에 더 전문화되고 수직적인 방식으로 적용하자고요. 당시에는 유넷(Unet)이었고, 지금은 확산 트랜스포머(Diffusion Transformers)입니다. 이것들은 계산량, 어떤 종류의 커널이 대부분의 시간을 차지하는지, 양방향 어텐션(bidirectional attention)을 하는지 인과적 어텐션(causal attention)을 하는지 등 프로파일(profile) 측면에서 자기회귀 트랜스포머(autoregressive transformers)와는 상당히 다릅니다. 그래서 저희는 그것을 하기 시작했습니다. 그리고 지금 저희가 가진 것은 확산 트랜스포머의 대부분의 모델에서 70~80%의 성능을 얻을 수 있는 추론 엔진입니다. 그리고 저희는 여전히 많은 모델에 대해 많은 맞춤형 커널을 가지고 있습니다. 왜냐하면 그것들은 여전히 작기 때문입니다. 모든 모델은 아키텍처적인 차이를 만들고 싶어 합니다. 여러분도 이런 것을 보셨을 겁니다. 케이븐(Kven), 딥시크(DeepSeq) 같은 것들에서도요. 사람들이 우리가 어떤 아키텍처가 최고인지 알더라도, 그들은 "우리는 멋진 것을 출시하고 있어"라고 확실히 하기 위해 약간 수정하고 싶어 합니다. 그래서 저희는 이것을 목격했습니다. 그리고 그것을 위해 저희는 사람들이 사용하는 맞춤형 RMS norm이나 그런 것들을 위해 맞춤형 커널을 작성해야 했습니다. 그래서 저희는 100개가 넘는 상당한 양의 맞춤형 커널을 보유하고 있습니다. 이는 자동 생성된 것은 포함하지 않습니다. 저희는 수천 개의 다른 모양, 문제 공간 등을 위해 생성되는 커널 템플릿을 가지고 있습니다. 하지만 그것들을 고려한다면, 저희는 런타임에 수만 개의 커널을 실행하고 디스패치(dispatch)하고 있습니다. 하지만 그것이 대략적인 깊이와 넓이입니다.

Alessio [00:14:13]: 그리고 평균적으로, Fal 플랫폼의 모델은 제가 직접 호스팅하는 것보다 10배 더 빠르게 실행되나요? 예를 들어 제가 스테이블 디퓨전을 가져다가. 그걸 넣으면요.

Batuhan [00:14:20]: 이 부분은 더 큰 논의를 필요로 할 수 있습니다. 속도를 절대적인 기준으로 삼아야 할까요? 결론적으로 말씀드리면, 기존 오픈소스 산업은 너무나 빠르게 발전했기 때문에, 3년 전에는 이 말이 사실이었을지 모릅니다. 하지만 지금은 PyTorch가 H100(NVIDIA H100 GPU)에 대해 이미 매우, 매우 뛰어난 성능을 보입니다. 그렇죠? P200은 어떨까요? P200이나 블랙웰(Blackwell) 칩과 함께 PyTorch를 사용하면 최상의 성능을 얻지 못합니다. 따라서 저희의 핵심 목표는 여러분이 어떤 유형의 GPU를 사용하든 관계없이, 이러한 확산 모델들에서 최고의 성능을 이끌어내는 것입니다. 어느 시점에서는 1.5배, 3배, 5배의 성능 향상을 가져올 수 있습니다. 특정 모델의 경우 10배가 될 수도 있습니다. 모든 것을 마법처럼 10배 더 빠르게 만들 것이라고 말하는 것은 다소 불공평할 것입니다. 세상 누구도 그렇게 할 수는 없습니다.

Gorkem [00:14:57]: 이것이 끊임없이 변화하는 목표(moving target)이며, 오픈소스 커뮤니티 모두가 이를 따라잡는다는 점은 다행입니다. 하지만 동시에 새로운 칩이 출시되고, 새로운 아키텍처가 등장합니다. 그래서 저희는 항상 가능한 기술의 한계보다 앞서 있지만, 그들이 따라잡으면 저희는 그보다 더 앞서 있어야 합니다. 그리고 그것이 저희가 차별점을 만들 수 있는 방법입니다. 왜냐하면 이것이 끊임없이 변화하는 목표이고, 너무나 많은 일이 일어나고 있기 때문입니다. 저희는 새로운 기술이 나올 때마다 그것을 가장 먼저 최적화하고, 저희의 추론 엔진을 그것에 가장 먼저 적용합니다. 그래서 그 당시에는 그것을 실행하기에 가장 빠른 곳이었고, 그것이 마진 등에 도움이 됩니다. 하지만 결국 사람들은 따라잡습니다. 저는 이 차별화를 장기적으로 유지하는 것이 매우 어렵다고 생각합니다. 그래서 "새로운 아키텍처가 없다면, 새로운 칩이 없다면 장기적으로 이것을 할 것이다"와 같습니다. 하지만 다행히도 항상 새로운 것이 나옵니다.

Alessio [00:15:43]: 네. 그리고 특히 이미지의 경우, 응답을 스트리밍할 수 없다고 할 수 있죠. 그래서 언어 모델의 경우, 얼마나 빨리 읽을 수 있느냐에 따라 제한되는 것과 같습니다. 그래서 록 같은 경우에도 초당 천 개의 토큰을 보여주는 것은 인상적이지만, 저는 그렇게 빨리 읽지 못합니다. 그렇죠. 그래서 더 느리게 갈 수 있습니다. 반면 이미지는 그냥 봐야 합니다. 그래서 미드저니(Midjourney)가 지금 드래프트 모드(draft mode)를 가지고 있는 이유입니다. 예를 들어, 이것을 그냥 줍니다. 매우 낮은 품질의 해상도입니다. 네. 하지만 적어도 올바른 방향으로 가고 있는지 볼 수 있습니다. 당신의 고객들에게는 이것이 실제로 얼마나 중요한가요? 그들은 무엇을 가장 중요하게 생각하나요? 응답 지연 시간이 그렇게 중요한가요? 중요한 지연 시간의 범위는 어느 정도인가요?

Gorkem [00:16:20]: 응답 속도는 사용자 경험에 결정적인 요소입니다. 저희 고객 중 한 곳은 실제로 매우 광범위한 A/B 테스트를 수행했습니다. 그들은 의도적으로 Fal 플랫폼의 응답 지연 시간을 증가시켜 이것이 그들의 핵심 지표에 어떤 영향을 미치는지 확인했습니다. 그리고 그 결과는 매우 중대한 영향을 미쳤습니다. 이는 웹페이지 로딩 시간과 유사합니다. 페이지 로딩이 느려지면 수익이 감소하는 것과 마찬가지죠. 아마존(Amazon)이 이와 관련하여 유명하고 대규모의 A/B 테스트를 진행했다고 생각합니다. 매우 유사한 맥락입니다. 사용자가 이미지를 요청하고, 그 결과물에 대해 반복 작업을 할 때, 생성 속도가 느리면 사용자 참여도가 저하되고, 생성되는 이미지의 수도 줄어드는 등의 현상이 발생합니다.

Swyx [00:16:56]: 아마존이 얻은 교훈과 같군요. 속도가 10% 향상될 때마다. 네, 맞습니다. 탄력성이 높다는 거죠. 제가 또 깊이 파고들고 싶었던 다른 것은, 투자자의 관점에서 말하자면, Fal의 성공 이유 중 하나는 여러분의 통제 범위를 벗어나는 요소에 있다는 점입니다. 즉, 사람들이 확산 모델을 언제, 어떻게 오픈 소스로 공개하느냐 하는 점이죠. 당시에는 Stability뿐이었고, 중국산 모델은 없었죠. 제 말은, 다른 이미지 모델도 있었지만 훌륭하지는 않았다는 겁니다. 네. 그래서 여러분은 그것이 그다지 명확하지 않을 때 과감한 투자를 한 거죠. 하지만 또 다른 점은, 당신이 언급하고 있는 것처럼, 확산 작업 부하(diffusion workload)는 언어 작업 부하와 매우 다르며, 언어 모델은 매우 최적화되고 있는 반면 확산 모델은 그렇지 않았다는 것입니다. 그래서 여러분은 한동안 경쟁이 없었던 셈이고, 그건 여러분에게 환상적인 기회였습니다.

Gorkem [00:17:44]: 100% 동의합니다. 그리고 오픈소스(open-source)는 당연히 저희에게 많은 이점을 가져다줍니다. 하지만 지난 6개월에서 1년 동안 저희는 일부 비공개 소스 모델 개발자들과도 협력하기 시작했습니다. 막후에서 그들을 지원하는 것이죠. 하지만 그들이 당신에게 가중치(weights)를 보내지는 않죠.

Swyx [00:17:58]: 보냅니다. 보냅니다. 와. 네. 어떤 보안을 보장해야 하나요?

Batuhan [00:18:02]: 보장해야 합니다. 저희는 어떤 클라우드 제공업체와도 유사합니다. AWS나 구글 클라우드, 아니면 최근 등장한 50개에 달하는 새로운 클라우드 서비스 제공업체들과 크게 다르지 않습니다. 그리고 이것이 저희가 추론 엔진을 패키징하여, 모델 개발자들이 자체적으로 80% 또는 90%의 성능을 달성할 수 있도록 만든 이유입니다. 따라서 그들은 저희에게 코드를 직접 보여줄 필요조차 없습니다. 그들은 저희의 클라우드 플랫폼에 모델을 배포하는데, 저희의 추론 엔진은 그 플랫폼 내에서만 활용 가능합니다. 그래서 그들이 코드와 모델 가중치를 저희 플랫폼에 배포할 때, 그들은 이 엔진의 이점을 누릴 수 있습니다. 저희는 굳이 그 내용을 들여다볼 필요가 없습니다. 만약 그들이 저희와 더 긴밀한 협력을 원한다면, 과거 일부 기업들이 그랬던 것처럼, 저희는 본질적으로 그들을 대신하여 현장에 파견된 엔지니어 역할을 하는 성능 엔지니어들을 투입하여 맞춤형 커널을 개발해줍니다. 알겠습니다.

Swyx [00:18:43]: 누구를 위해 이 작업을 수행하고 있는지 공개했습니까?

Batuhan [00:18:45]: 플레이HD(PlayHD), 플레이AI(PlayAI)를 공개했습니다. 그중 하나였습니다. 저희는 현재 이 작업을 함께 진행 중인 4개의 다른 기업, 즉 4개의 주요 비디오 관련 기업을 보유하고 있으며, 아직 공개되지 않은 이미지 관련 기업도 하나 있습니다.

Gorkem [00:18:56]: 상상하시겠지만, 그들에게는 다소 민감한 문제입니다. 그래서 네.

Swyx [00:19:00]: 말하자면, 몇 년 전에 소게노플리케이트(sorgenoplicate)가 V03 모델을 서비스하기 시작했을 때 저희는 "그냥 그들의 API를 래핑하는 건가?"라고 생각했습니다. 그래서 얼마나 많은 통합이 이루어지고 있고, 얼마나 당신의 인프라나 기술 위에서 이루어지고 있는지가 명확하지 않습니다.

Gorkem [00:19:13]: 솔직히 말씀드리자면, 그런 경우도 일부 존재합니다. 네. V03 같은 경우, 제 생각에 모두가. 그냥 API 래퍼(wrapper)입니다. 네.

Batuhan [00:19:19]: 그렇습니다. 네. 다른 속도 서비스 수준 협약(SLA) 보장 등을 통해 고객에게 서비스를 제공할 수 있는 전용 풀이 있습니다. 알겠습니다. V03 같은 경우에는 그렇게 작동합니다.

Swyx [00:19:27]: 하지만 당신의 목표는 원스톱(one-stop) 서비스를 제공하는 것이죠.

Batuhan [00:19:32]: 초대해주셔서 정말 감사합니다.

Swyx [00:20:02]: 초대해주셔서 정말 감사합니다.

Swyx [00:20:50]: 초대해주셔서 정말 감사합니다. 초대해주셔서 정말 감사합니다.

Batuhan [00:21:30]: 초대해주셔서 정말 감사합니다.

Batuhan [00:22:00]: 초대해주셔서 정말 감사합니다.

Batuhan [00:22:30]: 초대해주셔서 정말 감사합니다. 알겠습니다, 알겠습니다. 별도의 제품이군요. 네.

Alessio [00:22:32]: GPU 관점에서 볼 때, 항상 최신 장비를 사용해야 합니까? 계속 H100을 언급하시네요.

Batuhan [00:22:37]: 저희 작업 부하의 대부분은 H100에서 실행됩니다. 왜냐하면 단위 비용 대비 성능 면에서 합리적이기 때문입니다. 하지만 블랙웰(Blackwell)은 당연히, 저희는 현재 블랙웰 커널 개발에 전념하는 5명의 인력을 보유하고 있습니다. 이론적으로는 좋아 보이기 때문이죠. 그렇죠? 달러당 플롭스(flops) 면에서 합리적입니다. 하지만 그 실제 플롭스에 도달할 수 있을까요? 아닙니다. 그래서 저희는 엔비디아와 직접 협력하여 블랙웰을 위한 맞춤형 커널, 확산 트랜스포머를 위한 커널을 개발하는 전담 팀을 운영하고 있습니다. 성능 대비 가격이 합리적인 지점에 도달하기 위해서죠. 그리고 나면 저희 자체 작업 부하뿐만 아니라 일부 파운데이션 모델(foundation model) 기업들에게도 "블랙웰로 전환하고 싶다면, 이미 작동하는 추론 스택이 여기에 있습니다"라고 제안할 것입니다.

Gorkem [00:23:11]: 저희는 블랙웰의 한계를 극복해야 하는 시점에 와 있습니다. 왜냐하면 다른 어떤 기업도 이 작업을 수행하고 있지 않기 때문입니다. 그리고 아마도 지금 당장은 경제적으로, 즉 가격 대비 성능 면에서 합리적이지 않을 수도 있지만, 저희는 그것이 가능하다고 확신합니다. 그래서 저희는 아마도 그 지점에서 몇 달 정도 떨어진 목표를 향해 노력하고 있습니다. 그리고 그것이 가능해지면, 저희는 아마도 가능한 한 많은 작업 부하를 블랙웰로 전환할 것입니다.

Swyx [00:23:33]: 아주 극단적으로 말해서, 언제 ASIC(Application-Specific Integrated Circuit)을 개발하는 것이 합리적일까요?

Batuhan [00:23:38]: 저는 그렇지 않다고 생각합니다. 그게 솔직한 의견입니다. 아시다시피, 사람들은, 이것은 가장 논란이 많은 주제 중 하나죠? 이 모든 ASIC이 훌륭한 아이디어인가? 만약 당신이 S-RAM, 메모리 대역폭에 제약을 받고 모든 S-RAM을 넣을 수 있다면, 그 시점에서 경제적으로 실행 가능한가? 저는 모르겠습니다. 하지만 서밋(Summit)은 이 칩 설계를 중심으로 이루어집니다. 그래서 당신은 "엔비디아 GAM 명령어의 오버헤드는 무엇인가?"를 보게 됩니다. 그렇죠. 16% 정도입니다. 그래서 당신은 본질적으로 행렬 곱셈 기계(matrix multiplication machine)를 사고 있는 겁니다. 그래서 그것을 그렇게 많이 전문화하는 것은 별로 의미가 없습니다. 그리고 B300 같은 것들은 1.5배 정도의 성능을 내는 더 나은 소프트맥스 명령어(softmax instruction)를 가질 것입니다. 그리고 그것이 엔비디아가 대부분의 작업 부하, 즉 어텐션(attention)이 많은 작업에서 더 나은 성능을 얻는 한 가지 방법이 될 수 있습니다. 저는 엔비디아가 더 전문화된 것들을 추가하는 것이 의미가 있을 수 있다고 생각하지만, 저희에게는 그것이 결코 의미가 있을 것이라고 생각하지 않습니다.

Swyx [00:24:30]: I6를 만드는 거죠. 첫 원칙부터 생각해보면 확산 작업 부하는 매우 다르지만, 분명히 아키텍처에는 여전히 많은 변화가 필요하고, 이는 범용적이어야 합니다.

Gorkem [00:24:40]: 저희는 최적화하려는 단일 모델에 얽매이지 않습니다. 저희는 항상 최신의, 최고의 기술을 추구하고 있습니다. 따라서 유연성이 정말 중요합니다.

Swyx [00:24:48]: 제가 보여주려고 했던 것은, 퀘인 엠엠디아이티(Quen MMDIT)를 꺼내려고 했는데, 거기에는 이중 스트리밍(dual streaming) 같은 것이 있습니다. 제 생각에 마지막으로 SD3에 있었던 것 같습니다. 네, SD3 플럭스(Flux). 네. 그것이 지금 표준 모델인가요? MMDIT.

Batuhan [00:24:59]: 그것도 논란의 여지가 있는 주제입니다. 아시다시피, '스케일링 정류 흐름 트랜스포머(Scaling Rectified Flow of Transformers)' 논문, 즉 SD3 논문이 이 아키텍처를 제시했습니다. 그리고 저희 연구팀 중 한 명인 시모 라야(Simo Raya), 저희 연구 책임자인데, 그가 MMDIT만 사용하는 것은 비효율적이라는 것을 발견했습니다. 그것들을 혼합해야 한다는 거죠. 그리고 이제 논란의 여지가 있는 의견들이 있습니다. 예를 들어, 무비 잼(Movie Jam) 논문에서는 "MMDIT는 완전히 불필요하다. 그냥 단일 스트림 DIT(single stream DIT)를 사용하면 된다"고 말합니다. 그래서 아키텍처 변경 측면에서 논란의 여지가 있는 의견들이 발생하고 있습니다. 저는 그것을 이해합니다. 왜냐하면 모두가 다른 아키텍처를 만들고 싶어 하고, 아무도 같은 아키텍처를 사용하고 싶어 하지 않기 때문입니다. 그건 재미없으니까요. 네. 네. 그렇지 않으면, 그것은 단지 컴퓨팅과 데이터의 문제일 뿐이고, 이 연구자들은 그들의 모델이 데이터와 컴퓨팅의 결과물이라는 것에 자부심을 느끼지 못합니다. 그들은 새로운 연구적 변화를 만들고 싶어 합니다. 그래서 저는 이 패러다임, 즉 연구자들이 변화를 위한 변화, 즉 특징을 바꾸는 패러다임이 끝날 때까지 아키텍처는 계속 바뀔 것이라고 생각합니다.

Swyx [00:25:47]: 몇 가지 다른 아키텍처적인 것들에 대해 이야기하고 이 주제 내에서 범위를 한정하겠습니다. 증류(distillation)는 한동안 유행이었습니다. SDXL 라이트닝, 여러분은 테일 드로우(Tail Draw)의 환상적인 데모를 보여주셨죠. 저희도 팟캐스트에 출연시킨 적이 있습니다. 환상적인 에피소드였죠. 그들에게 무슨 일이 있었나요? 왜 더 이상 인기가 없나요?

Gorkem [00:26:03]: 좋은 데모를 만들었다고 생각합니다. 실시간 애플리케이션을 만들 수 있었고, 이런 드로잉 애플리케이션을 만들 수 있었습니다. 하지만 사람들이 장기적으로 사용자 유지율을 가질 수 있는 애플리케이션을 만들 수 있었다고는 생각하지 않습니다. 사람들이 그것으로 정말 유용한 것을 만들지는 못했습니다.

Swyx [00:26:19]: 제가 생각했던 일이 왜 일어나지 않았는지 말씀드릴 테니, 왜 그랬는지 말해주세요. 물론이죠. 바로 드래프팅을 위한 일관성 모델(consistency models)입니다. 펜을 사용해서 그림을 그리고, 그것이 드래프트를 만듭니다. 그런 다음 실제 모델로 업스케일링(upscaling)하는 거죠. 하지만 그게 다입니다. 왜 1단계가 아닌 2단계 프로세스가 될 수 없는 거죠? 네.

Gorkem [00:26:39]: 그리고 제 생각에 일어난 한 가지 일은 플럭스(Flux), 즉 그 세대의 모델들이 처음 나왔을 때 이미지-투-이미지(image-to-image)에 능숙하지 않았다는 것입니다. 그래서 그림을 그리려면 좋은 이미지-투-이미지 모델이 필요합니다. 아마도 이 시점에서 일부 편집 모델들과 함께 다시 검토될 필요가 있을지도 모릅니다. 이미지-투-이미지와 컨트롤(control) 같은 것들이요. 그게 플럭스입니다.

Batuhan [00:26:58]: 엑셀이나 컨트롤러는 매우 인기가 많았습니다. 사람들은 스케치-투-이미지 같은 것을 하곤 했죠. 그리고 플럭스와 함께, 제 생각에 사람들은 그것에 대해 덜 신경 썼습니다. 제가 계속 생각하는 한 가지는, 이것이 LLM에도 해당되는가 하는 점입니다. 아시다시피, 저는 항상 클로드 4.1 오퍼스(Claude 4.1 Opus)를 기본으로 사용합니다. 소네트(Sonnet)보다 느리더라도, 저는 최고의 품질을 얻을 것이라는 것을 알고 있기 때문입니다. 맞습니다. 여기서도 그런 일이 일어나고 있습니다. 네. 그것이 여기서도 일어나고 있는 일인 것 같습니다.

Swyx [00:27:22]: 알겠습니다, 어쨌든, 창작자로서 저는 빠르고 신속한 초안을 원하고, 그 다음에 다듬을 수 있기를 원합니다. 그렇죠? 그래서. 모르겠습니다. 왜 그런 일이 일어나지 않았는지 모르겠습니다.

Gorkem [00:27:29]: 비디오 모델의 경우 더 그렇죠? 예전에는 5초짜리 생성 하나에 5분, 4분이 걸렸습니다. 지금은 대부분 1분 미만이지만, 10초, 5초짜리 생성을 원합니다. 그리고 창작자들이 작업할 때의 워크플로우(workflow) 때문에, 그들은 수많은 비디오를 생성한 다음 하나를 골라 그것을 중심으로 이야기를 만듭니다. 그래서 이 사람들이 실제로 비디오를 생성하는 것을 보면, 한 번에 수백 개를 생성하고 그 주변에 앉아 있어야 합니다. 그리고 기다렸다가 그것을 반복 작업해야 합니다. 더 빠른 속도는 창작자들에게 큰 의미가 있습니다.

Swyx [00:28:05]: 네, 그렇습니다. 제가 또 간단히 언급하고 싶었던 다른 것은, 당신이 언급한 자기회귀 모델(autoregressive models)입니다. 솔직히 저는 여전히 제미니(Gemini)가 과소평가되었다고 생각합니다. 왜냐하면 그들이 먼저였기 때문입니다. 그리고 그 다음에 당연히, 공개적으로, 저는 4.0 이미지 생성을 했고 그것은 큰 일이었습니다. 저는 심지어 당신들에게 패닉이 있었는지 궁금합니다. 왜냐하면 당연히 이것은 소다 이미지 생성이고 다른 누구도 가지고 있지 않기 때문입니다. 오픈소스가 아니죠.

Batuhan [00:28:30]: 그런 시대를 너무 많이 겪어봐서요.

Gorkem [00:28:34]: 걱정하는 것을 멈췄습니다.

Batuhan [00:28:35]: 당신의 카메라는 돌리(Dolly)에 대한 좋은 이야기를 가지고 있습니다.

Gorkem [00:28:38]: 네, 저는 돌리2(Dolly 2)가 처음 나왔을 때, "오케이, OpenAI는 다른 누구보다 훨씬 앞서 있어. 미드저니는 불가능해"라고 생각했던 것에 대해 이야기합니다. 그리고 몇 달 안에 사람들이 따라잡았고, 그 다음 스테이블 디퓨전은 아마도 돌리보다 더 좋거나, 돌리만큼 좋았습니다. 몇 달 후에 말이죠. 그리고 그것은 오픈소스였습니다. 그래서 1년 후, 소라(Sora)와 같은 일이 일어났습니다. 그들이 그 비디오들을 공개했을 때, 그 당시에는 저희는 흥분했습니다. 왜냐하면 이제 사람들이 그것이 가능하다는 것을 보았기 때문입니다. 이것은 실제로 할 수 있는 일입니다. 연구자들은 동기를 부여받고, 그들은 과대광고를 봅니다. 그들은 이것이 가능하다는 것을 봅니다. 그래서 그들은 그것에 대해 작업합니다. 그리고 몇 달 안에, 저희는 아마도 소라 수준은 아니지만 훨씬 더 나은 비디오 모델을 가졌습니다. 지금 저희는 소라보다 훨씬 더 나은 비디오 모델을 가지고 있습니다. 그래서 누군가가 실제로 경계를 밀어붙이는 것을 볼 때마다, 그것은 흥분의 이유가 됩니다. 왜냐하면 이제 그것이 가능하기 때문입니다. 다른 사람들은 몇 달 안에 그것을 할 것입니다. 그래서 더 이상 패닉하지 않습니다.

Alessio [00:29:38]: 앤트로픽(Anthropic)이 이미지 생성 모델을 보유하고 있지 않다는 사실이 대형 연구소들이 무엇에 관심을 가지는지에 대해 무언가를 시사한다고 보십니까?

Batuhan [00:29:44]: 그것은 다른 연구소들이 일반적으로 무엇에 관심을 가지는지보다는 앤트로픽 자체의 우선순위에 대해 더 많은 것을 말해줍니다. 왜냐하면 XAI, 메타(Meta), OpenAI, 구글을 보면, 그들은 모두 정말 좋은 이미지 모델을 가지고 있기 때문입니다.

Gorkem [00:29:58]: 구글은 지난 발표에서 '생성형 미디어'라는 용어를 사용했습니다. 저희에게는 자랑스러운 순간이었죠. 승리입니다. 그리고 많이, 아시다시피, 그들은 새로운 LLM 모델만큼이나 생성형 미디어에 집중했습니다. 그래서 일부 연구소는 확실히 그것에 관심을 가지고 있고, 일부 연구소에게는 그것이 우선순위가 아닙니다. XAI를 보세요. 그들은 계속해서 이미지 언어, AI 슬롭(AI slop)을 밀어붙이고 있습니다. 네, 알아요.

Alessio [00:30:19]: 알아요, 미쳤어요. 그리고 와이푸들(Waifudle). 그리고 상호작용 수준. 이미지, 비디오가 있고, 이제는 지니(Genie)가 있습니다. 이것은 일종의 월드 모델(world model)에 가깝고, 게임 애플리케이션도 있습니다. Fal이 그 모델들에서 많은 트래픽을 얻기까지 얼마나 남았나요? 오늘날 오픈소스에서는 대부분 실험적인가요? 지니는 인상적이지만, 구글 모델이잖아요?

Gorkem [00:30:39]: 저는 이것에 대해 매우 낙관적인 견해를 가지고 있으며, 그것이 아마도 정상적인 결과일 것이라고 생각합니다. 최악의 경우, 저희는 월드 모델에서 파생되는 매우 유능한 비디오 모델을 갖게 될 것이라고 봅니다. 그렇죠? 그것은 매우 제어 가능한 비디오 모델이 될 것이고, 사용 사례는 현재의 비디오 모델과 유사할 것입니다. 콘텐츠를 생성하게 되겠지만, 카메라 각도를 제어할 수 있고, 오늘날보다 훨씬 더 정교하게 비디오 모델을 제어할 수 있게 될 것입니다. 최악의 경우, 저희는 월드 모델로부터 그러한 이점을 얻게 될 것입니다. 그리고 최상의 경우에 대해서는, 누구도 무슨 일이 일어날지 예측하기 매우 어렵다고 생각합니다. 네. 영화와 게임. 그것은 당신이 플레이 가능한 전체 영화 세계의 일부가 될 수 있는 중간 지점의 무언가가 될 것입니다. 그래서 무한한 가능성이 있습니다. 최상의 경우에 무슨 일이 일어날지, 그리고 그것이 얼마나 경제적으로 실현 가능해질지, 이것이 주류 채택에 도달할 수 있을지, 저희는 그 모든 것을 목격하게 될 것입니다. 하지만 기술적으로는 확실히 믿을 수 없을 정도로 흥미롭고 인상적입니다. 이 연구소들에서 나오는 결과물들이요.

Alessio [00:31:42]: 논문을 다시 찾아봐야겠는데, 비디오 모델과 이미지 생성, 물리학 이해에 대한 연구가 있었습니다. 네. 그리고 행성의 궤도를 예측할 수 있었지만, 실제로 중력장을 그리게 했을 때는 완전히 틀렸습니다. 네. 그렇죠. 그래서 저는 월드 모델에 대한 제 생각이 그렇습니다. 창작자 애플리케이션, 즉 일관된 세계를 만드는 방법을 이해합니다. 하지만 다른 쪽 사람들, 즉 "이것들이 세상을 시뮬레이션하고 지능을 얻는 가장 좋은 방법이다"라고 말하는 사람들에 대해서는 잘 모르겠습니다. 저는 그것을 모릅니다.

Gorkem [00:32:10]: 두 가지에 대한 낙관론도 존재합니다. 로봇 공학을 연구하는 사람과 대화할 때마다, 그들은 항상 데이터의 양에 의해 제약을 받습니다. 그리고 지난 3년간의 모든 AI 혁신에서 우리는 이 현상을 목격했습니다. 하지만 데이터가 풍부해질 때마다, 해당 유형의 모델은 실제로 크게 개선됩니다. 따라서 로봇 공학 분야에서도 유사한 결과를 기대합니다. 그들이 이 데이터 문제를 해결하는 순간, 모델들도 더 나아질 것입니다. 이것이 사람들이 그토록 낙관적인 이유입니다. 좋습니다. 아마도 이것이 로봇 공학의 데이터 문제를 해결할 것이고, 그 안에는 무한한 기회가 있습니다.

Batuhan [00:32:46]: 그리고 당신이 언급한 중력에 대한 예시와 관련하여, 저는 이것이 여전히 "LLM은 9.5를 할 수 없다"는 것과 같은 문제라고 생각합니다. 9.9 더하기 9, 9.9. 네, 할 수 있습니다. 더 많은 데이터로 훈련시키고, 더 나은 토크나이저(tokenizer)를 가지면 됩니다. 그것이 이유입니다. 그것은 단지 데이터 규모와 기본 아키텍처의 문제입니다. 하지만 저는 그것이 그렇게 많이 바뀔 것이라고 생각하지 않습니다. 저희는 그냥 1000배 더 많은 데이터, 1000배 더 많은 컴퓨팅을 투입할 것이고, 최고의 물리 시뮬레이터(physics simulator)를 얻게 될 것입니다. 그리고 저는 이것이 데이터에서 오는 기존 신호로 가능해야 한다고 생각합니다.

Swyx [00:33:18]: 비디오 관련해서도 더 깊이 파고들고 싶네요. 네. AI에서 멋진 슬라이드를 보여주셨죠. 현재 Fal 매출의 18%가 비디오 모델에서 나온다고 하셨는데, 그게 2월이었죠.

Gorkem [00:33:29]: 그래서 지금은 아마 80, 50, 50을 넘을 겁니다. 네. 알겠습니다. 50 이상이군요. 네. 네. 100%입니다. 와. 알겠습니다. 편집 모델이 이미지에도 활력을 불어넣었으니, 둘 다 성장했지만, 네, 비디오가 더 빨리 성장했습니다.

Batuhan [00:33:46]: 비디오는 꽤, 꽤 중요합니다. 그리고 주요 동인 중 하나는 오픈소스 모델입니다. 2월에는 훈위안 비디오(Hun Yuan Video)가 있었는데, 꽤 좋았다고 생각합니다. 젠모(Genmo)의 모치(Mochi)도 있었지만, 품질은 아직 거기까지 미치지 못했습니다. 그리고 알리바바(Alibaba)의 원(One)은 정말 엄청나게 좋은 모델이었습니다. 그리고 그들은 한 달 전인가, 몇 주 전에 새로운 버전을 출시했습니다. 그리고 지금은 정말, 정말 인기가 많아지고 있습니다. 그리고 저희는 이것을 실행할 수 있습니다. 저는 4 ADP, 즉 드래프트 모드(draft mode) 버전을 5초 이내에 실행할 수 있습니다. 그래서 사람들은 즉각적인 피드백 루프(feedback loop)를 가질 수 있습니다. 그리고 720P 전체 해상도로 가고 싶을 때는 20초밖에 걸리지 않습니다. 저희는 그것을 10초로 줄일 계획이었습니다.

Swyx [00:34:25]: 정말 놀랍네요. 그리고 그 점에 대해 더 깊이 파고들고 싶습니다. 한동안 저는 알리바바에 대해 다소 비관적이었습니다. 왜냐하면 그들은 계속해서 매우 체리피킹(cherry-picking)된 논문들을 발표했고, 마치 "우리는 깃허브에 있다"고 한 다음 깃허브에 가보면 리드미(readme) 파일만 있었기 때문입니다.

Gorkem [00:34:37]: 정말 뭔가 변했다는 걸 알 수 있습니다. 그들은, 그들에게 무슨 일이 있었나요?

Batuhan [00:34:45]: 아뇨, 저희는 그들과 직접 대화해 본 적은 없습니다. 하지만 분명히 변화가 감지됩니다. 그리고 현재 알리바바 내부에는 경쟁하는 팀들이 존재합니다. 한 팀은 정말 뛰어난 이미지 모델을 개발했지만, 이를 경쟁적인 이미지 모델로 출시했습니다. 저희 생각에, 한 번의 이미지 모델은 실제로 매우, 매우 우수합니다. 81프레임 대신 단일 프레임만 사용하더라도, 정말 훌륭한 텍스트-이미지 모델을 얻을 수 있습니다. 그리고 이는 비디오에서 파생된 순수한 데이터 양 덕분입니다. 따라서 현재 알리바바는 연구소에서 개발한 정말 좋은 모델 두 가지를 보유하고 있습니다. 그리고 중국에는 여러분이 들어보지 못했을 수도 있는 작은 연구소들이 많습니다. 예를 들어 스텝펀(Stepfun)은 이미지 편집 모델인 하이드림(Hydream)을 출시했습니다. 저희는 이런 현상을 긍정적으로 봅니다. 이런 작은 연구소들이 모두 새로운 모델을 출시하고 있습니다. 이는 이미지나 편집 모델을 훈련하는 데 드는 비용이 그렇게 높지 않다고 생각하기 때문입니다. 비디오 모델은 다소 더 비쌀 수 있습니다. 제 생각에 이런 모델들을 훈련하는 데는 수백만 달러 정도가 드는데, 특히 그들이 아마도 어떤 단체의 지원을 받고 있다는 점을 고려하면 그렇게 많은 금액은 아닙니다. 알리바바 외에도, 스텝펀 같은 곳들이 있죠. 그들은 아마 상당한 금액의 자금을 유치했을 겁니다. 그래서 이런 모델들을 훈련하여 출시하면 많은 주목을 받을 수 있고, 이는 수준 미달의 LLM을 출시하는 것보다 더 많은 관심을 끄는 효과가 있습니다. 왜냐하면 LLM 분야는 경쟁이 훨씬 더 치열하기 때문입니다. 따라서 단지 백만 달러를 들여 비디오 모델을 훈련하고 그것을 출시하는 것은 많은 주목을 가져다준다고 생각합니다.

Gorkem [00:35:57]: 그것은 매우 영리한 전략입니다. 허깅 페이스를 보면, 지금 당장 보더라도, 상위권 모델들은 아마 이미지 모델일 것입니다. 꽤나 많은 이미지 편집 모델이 상위권에 있을 겁니다. 네. 아마 상위권에 있을 겁니다.

Alessio [00:36:08]: 1위, 1위. 네.

Batuhan [00:36:11]: 훈난 게임크래프트(Hunan Gamecraft)가 3위, 4위, 4위, 젬마(Gemma), 2억 7천만, 일부 이미지 관련. 바이트댄스(ByteDance)는 오픈소스 모델도 있지만, 그들은 정말 좋은 팀 시드(Seed)를 가지고 있습니다. 그곳이 그들의 새로운 연구소입니다. 그들은 시드림(Seedream), 시댄스(Seedance), 옴니휴먼(OmniHuman) 같은 것들을 연구하고 있습니다. 저희는 그들과 좋은 파트너십을 맺고 있어서, 그들의 모델을 미국에서도 호스팅할 수 있기를 바랍니다. 네. 그리고 아이디어는, 제 생각에 그들이 구성한 팀은 매우 훌륭하고, 그들의 이전 연구 등에서 비롯된 것입니다. 바이트댄스는 SDXL 라이트닝 같은 것에 대해 정말 좋은 오픈소스 작업을 하고 있었습니다. 그들은 SDXL 라이트닝 논문, 애니메이티브 라이트닝(Animative Lightning)을 발표했습니다. 그래서 저는 그들에 대해 꽤, 꽤 희망적입니다.

Swyx [00:36:47]: 우선, 그들이 출시할 때 당신에게 연락하지 않고 그냥 공개해서 당신이 서둘러야 하는 일이 없기를 바랍니다. 알겠습니다.

Batuhan [00:36:53]: 이 시점에서는 사람들이 저희에게 연락합니다. 왜냐하면 저희가 시장 선두주자이기 때문입니다.

Swyx [00:36:56]: 그래서 그들은 배포를 얻기 위해 저희에게 연락합니다. 네. 그들이 항상 먼저 출시하는 중국 플랫폼이 있는데, 이름은 잊어버렸지만, 당신은... 저희도 이 모델들 대부분과 함께 출시 첫날부터 함께합니다. 하지만, 기본적으로 제 질문은 항상 "돈을 버는 것은 당신들인데, Stability는 스테이블 디퓨전으로 돈을 벌지 못했다"는 것입니다.

Batuhan [00:37:17]: 저는 블랙 포레스트 랩스(Black Forest Labs)가 한 일이 이 측면에서 매우, 매우 흥미로웠다고 생각합니다. 그들은 세 가지 다른 모델을 출시했습니다. 네. 아파치 2(Apache 2) 라이선스의 극도로 경량화된 모델, 이것은 개발용으로 좋습니다. 샤넬(Schnell) 버전입니다. 이것은 낮은 품질의 것을 위한 4단계 생성입니다. 그들은 비상업적 라이선스를 가진 개발용 모델을 출시했는데, 그들의 추론 파트너들은 수익 공유를 지불합니다. 그리고 이것은 매우 좋은 방법입니다. 그리고 프로 버전이 있는데, 이것은 호스팅을 위해 협력할 수 있습니다. 그리고 수익 공유는 당연히 그것에 따라 다릅니다. 이것은 모델 출시가 전부인 연구소들에게는 매우 현명한 선택이라고 생각합니다. 하지만 만약 당신이 부가적으로 제품을 만드는 회사라면, 오픈소스 모델로 돈을 벌 필요는 없습니다. 당신은 연구자들을 고용하고, 배포를 얻기 위해 그것을 하는 것입니다. 그래서 그것은 회사의 목표에 따라 정말 다릅니다. 알리바바 규모에서는, 그들은 하나의 모델이 그들의 API에서 호스팅되는지 신경 쓰지 않습니다. 그렇죠? 알리바바는, 원(One)이 만드는 것은 알리바바의 전체 매출에 영향을 미치지 않습니다. 그래서 그들에게는 그것을 출시하고 주목을 받고, 아마도 일부 리드(lead)를 얻는 것이 당연한 선택입니다. 그들의 알리바바 클라우드 제품을 위해서요. 하지만 블랙 포레스트 랩스나 그런 회사들에게는, 증류된 버전을 완전히 오픈소스로 출시하고, 덜 증류되거나 실제 모델을 비상업적으로 출시한 다음 추론 회사들과 파트너십을 맺는 것이 현명한 조치라고 생각합니다.

Alessio [00:38:32]: 사용량 분포는 어떻게 됩니까? 예를 들어, 매출의 80%가 5개 모델에서 나옵니까? 아니면 사람들이 초기 출시 이후에도 이 모든 공개 모델의 롱테일(long tail)을 정말로 사용합니까?

Gorkem [00:38:42]: 멱법칙(power law)이 어느 정도 작용하지만, 생각만큼 심하지는 않습니다. 그리고 계속 바뀝니다. 그게 또 다른 부분입니다. 단 하나의 모델만 많이 사용되는 것이 아닙니다. 월별로 많이 바뀝니다. 이번 여름은 정말 미쳤습니다. 수많은 새로운 비디오 모델, 새로운 이미지 편집 모델이 나왔고, 리더가 매주 바뀌었습니다. 하지만 한 발 물러서서 어떤 모델이 사용되고 있는지 보면, 사람들은 최고급, 가장 비싼 비디오 모델을 사용하고 싶어 하거나, 비용 효율적이고, 좋지만 충분히 저렴한 비디오 모델을 사용하고 싶어 합니다. 그래서 그 두 모델이 보통 많이 사용되고, 그 모델들이 무엇인지는 매주 바뀝니다.

Batuhan [00:39:29]: 한 가지 좋은 예는 플럭스 콘텍스트(Flux Context)가 5월 말에 출시되었고, 코에딧(Coedit)은 2주 전에 출시되었다는 것입니다. 그리고 지금은 콘텍스트를 능가하고 있습니다. 더 나은 품질의 모델이 있기 때문에 이런 것들이 얼마나 빨리 전환되는지 정말 놀랍습니다. 그리고 그것이 바로 가치 제안입니다. 코에딧이 사용 가능해지자마자 플럭스 콘텍스트 개발을 관리하기 위해 인프라를 설정할 필요가 없습니다. Fal을 사용하면 바로 그것으로 전환할 수 있습니다.

Alessio [00:39:51]: 제 생각에는 그렇네요. 일부 모델은 오픈되어 있고 일부 모델은 수익 공유를 지불해야 한다면, 이상적으로는 사람들을 수익 공유 모델에서 오픈 모델로 옮기고 싶을 겁니다. 그렇죠? 그 역학 관계는 어떤가요? 모두 가격에 달려 있습니다.

Gorkem [00:40:03]: 저도 이렇게 생각합니다. "고객이 성공할 수 있는 일이라면 무엇이든 할 것이다." 저희는 아직 이런 미미한 계산이 중요하지 않을 만큼 초기 단계에 있습니다. 저는 사람들이 실제로 프로덕션(production)에 진입하여 제품을 만들고 성공하는 것을 더 중요하게 생각합니다. "여기서 20%, 저기서 10%"와 같은 수치적인 이득보다는요. 제 말은.

Alessio [00:40:22]: 당신은 1억 달러의 매출을 올리고 있습니다.

Swyx [00:40:26]: 좋습니다. 사람들이 이것을 실제로 어떻게 사용하는지에 대해 몇 가지 질문을 더 하겠습니다. 알겠습니다. 아주 뻔한 질문을 하겠습니다. 네. NSFW(Not Safe For Work) 콘텐츠는 얼마나 되나요? 거의 무시할 수 있는 수준입니다. 네. 모든 것을 중재하지는 않고, 중재는 선택 사항이죠?

Batuhan [00:40:40]: 중재는 불법적인 콘텐츠가 중재되는 수준까지는 선택 사항이 아닙니다. 그리고 저희는 불법이 아닌 콘텐츠, 즉 NSFW 콘텐츠에 대한 중재도 추적합니다. 그리고 1% 이상을 본 적이 없습니다.

Gorkem [00:40:51]: 모델 자체도 그런 종류의 콘텐츠를 생성하지 않습니다.

Batuhan [00:40:54]: 이것은 일부 모델 제공업체, 특히 블랙 포레스트 랩스(Black Forest Labs) 모델을 보면, 모델이 그런 용도가 아니라는 점입니다. 그것은 생성할 수 없거나, 방지되는 방식으로 어닐링(annealed)되었습니다. 그리고 저희 고객 기반의 대부분은, 매출 기준으로 보면, 엔터프라이즈(enterprise)가 더 높은 수준에 있으며, 그중 일부는 사용자 공간, 모바일 애플리케이션일 수 있습니다. 하지만 지난 6개월, 9개월 동안 저희는 점점 더 엔터프라이즈로 전환하고 있으며, 그들에게는 그러한 종류의 콘텐츠가 필요할 가능성이 적습니다.

Swyx [00:41:19]: 선택의 여지가 적다는 뜻인가요? 그럼 그 기업들은 무엇을 하고 있나요? 이미지를 생성할 수 있는 범용 챗봇을 만드는 것 외에요. 아마도 캔바(Canva)가 좋은 사용 사례가 될 수 있겠네요. 하지만 제 상상력은 그 이상으로는 좀 제한적입니다.

Gorkem [00:41:32]: 광고 분야가 절대적으로 성장하고 있다고 생각합니다. 그리고 생각해보면, 이는 매우 잘 들어맞습니다. 비디오 광고에 대해 이야기해 봅시다. 제가 계속해서 강조하지만, 일부 기업들은 "우리는 할리우드(Hollywood)를 바꿀 것이다. 영화 제작이 혁신될 것이다"라고 말합니다. 저는 그 주장이 그렇게 흥미롭다고 생각하지 않습니다. 여러분은 일 년에 몇 편의 영화를 보십니까? 아마 20편에서 25편 정도일 겁니다. 극장에서 보는 영화는 몇 편입니까? 기껏해야 서너 편입니다. 따라서 일 년에 수천 편의 영화가 쏟아져 나온다고 해도, 사람들은 이 모든 영화를 다 볼 수 없을 겁니다. 시간이 충분하지 않기 때문이죠. 그것은 최고 품질 경쟁(maximum quality game)입니다. 맞습니다. 맞습니다. 그리고 광고는 정반대입니다. 콘텐츠가 많을수록, 광고를 만드는 다양한 방식이 존재할수록, 항상 경제적 가치가 따라붙습니다. 따라서 무한한 수의 광고, 무한히 다양한 버전의 광고를 만들 수 있고, 더 개인화될수록 그 뒤에 더 많은 경제적 가치가 생성됩니다. 그래서 광고는 이러한 종류의 기술에 매우 잘 부합합니다. 왜냐하면 당신이 만들 수 있는 것에는 한계가 없기 때문입니다.

Swyx [00:42:35]: 실리콘 밸리에서 제가 목격하고 있는 한 가지 경향을 덧붙이자면, 설명하기는 어렵지만, 모든 YC(Y Combinator) 스타트업들과 모든 기업들이 하나의 론칭 비디오(launch video)에 1만 달러에서 7만 달러 사이를 지출하고 있다는 것입니다. 네. 생성형 비디오 시대에 말이죠. 그들은 실제 크리에이티브 디렉터(creative director)를 고용하고, 스튜디오를 고용하고, 배우를 고용하고 있습니다. 저도 그중 하나에 참여했었는데, 생성형 비디오가 있는데 그 모든 것이 필요한가요? 제 생각에 로이(Roy)도 생성형 비디오에 대해 이야기하기 시작했습니다. PJ 에이스(PJ Ace)를 아시는지 모르겠네요.

Batuhan [00:43:05]: 그는 이 분야에서 절대적인 실력자라고 생각합니다.

Swyx [00:43:08]: 그는 슈퍼볼(Super Bowl) 광고 같은 것을 론칭했죠? 농구 플레이오프, NBA 결승전을 했죠?

Batuhan [00:43:15]: 그는 저희 시리즈 B 발표 영상도 제작했습니다. 저희는 그와 꽤 가깝습니다. 그리고 그가 만들어내는 결과물과 그것이 얼마나 바이럴되는지는 정말 놀랍습니다. 수십만 달러를 지출하는 이런 비디오들 말이죠. 그렇죠? 그냥 바이럴 콘텐츠를 만들면 되고, 이 생성형 미디어 모델들이 그것을 수행하는 가장 좋은 방법입니다. 그리고 저희는 아직 이 기술의 초기 단계에 있습니다. 그렇죠? 당연히 전문가 수준의 품질이 아닐 수도 있습니다. 저는 여전히 '인간 개입형(human in the loop)', 즉 혼합된 콘텐츠 제작 방식이 현재의 주류라고 생각하지만, 6개월 후에는 누가 알겠습니까? 12개월 후에는 80%가 생성될 것이라고 생각합니다. 저희는 슈퍼볼을 시청하면서 "이 중 얼마나 많은 부분이 생성될까?"라고 이야기하고 있었습니다. 그리고 지금 이 비디오는 AI 생성처럼 보입니다. AI 생성일 수도 있습니다. 그렇죠? 구별할 수 없습니다.

Swyx [00:43:54]: 그래서 제 생각에 어느 시점에는 80%, 90%가 AI로 생성될 것입니다. 그것은 저에게, 제 생각에, 레플리케이트(Replicate)의 포푸르(Fofur)라는 사람을 생각나게 합니다. 그는 분명히 이 모든 워크플로우에 대한 최고의 영감입니다. 그는 게임 영상 위에 일종의 NBA 현실적인 로어(lore)를 겹쳤습니다. 그래서 NBA 2K를 플레이할 수 있지만, 실제 비디오처럼 보입니다. 저도 봤습니다. 네. 저는 "뭐야"라고 생각했습니다.

Swyx [00:44:21]: 정말 멋지네요. 그리고 아마도, 그리고 그것이 제 질문의 다른 부분인데, ComfyUI에 대해 이야기하고 싶었습니다. 얼마나 많은 로어(LoRA) 서빙이 이루어지고 있나요? 그렇죠? 얼마나 많은 맞춤형이 있나요? 많습니다. 많습니다. 아시나요? 알겠습니다. 대다수인가요? 그것이 이유 중 하나입니다. 대다수는 아니지만, 30% 정도라면 대다수인가요? 그리고 모두가 자신의 로어를 훈련시키나요, 아니면 로어 마켓플레이스에서 가져오나요?

Gorkem [00:44:42]: 그래서 오픈소스가 이미지 및 비디오 모델과 매우 잘 작동하는 이유입니다. 왜냐하면 이 거대한 로어 생태계에 접근할 수 있기 때문입니다. 모두가. 좋은 로어 생태계를 구축할 수 있는 비공개 소스 모델을 본 적이 없습니다. 기본적으로 존재하지 않죠. 아마도 미드저니의 SREF(Style Reference)가 있겠지만, 그것들을 로어로 간주할 수 있을지는 모르겠습니다. SREF는 그냥 시드(seed)죠? 조건화(conditioning).

Batuhan [00:45:06]: 다른 조건, 프롬프트(prompt) 같은 것이라고 부릅시다. 네.

Gorkem [00:45:08]: 네. 그리고 오직 오픈소스 모델만이 이 풍부한 로어 생태계를 가지고 있으며, 그것은 극도로, 극도로 인기가 많습니다.

Batuhan [00:45:15]: 하지만 가장 오래된 모델들에게도 새로운 생명을 불어넣습니다. 아시나요? 이런 멋진 로어들을 보면요. 저희는 여전히 많은 사람들이 자신의 로어와 함께 STXL을 사용하고 있습니다. 왜냐하면 그들은 품질에 만족하고, 충분히 빠르고, 충분히 저렴하기 때문입니다. 아시나요? 놀랍습니다. 이 모델들은 언어 모델처럼 단 한 번에 해결되지 않습니다. 편집 모델조차도, GPT 이미지 원(GPT Image One)이나 플럭스 콘텍스트, 코인 이미지(Coin Image) 같은 것들도, 당신의 얼굴이나 여러 사람을 넣으면 품질을 얻을 수 없습니다. 90% 정도는 될 겁니다. 하지만 6개에서 20개의 이미지로 1000번 정도 훈련하면, 99%의 정확도를 얻을 수 있습니다. 저희는 올바른 하이퍼파라미터(hyperparameter)를 세부 조정하고, 분산 트레이너(distributed trainer), 분산 옵티마이저(distributed optimizer) 같은 것을 만드는 데 많은 노력을 기울였습니다. 그리고 그것들로, 사람들은 이제 플랫폼에서 30초 이내에 자신의 로어를 훈련하고, 같은 작업에서 추론을 실행하며, 같은 얼굴 캐릭터에 대해 99%의 정확도를 얻을 수 있습니다. 이것은 아마도 소비자 측보다는 엔터프라이즈 측에서 더 많이 직면하는 가장 큰 과제 중 하나입니다. 아시나요? 자산을 만들고 있다면, 그것이 누구처럼 보이는지는 별로 신경 쓰지 않습니다. 하지만 실제로 제품 광고를 하고 있다면, 제품과 똑같이 보이기를 원합니다. 제품의 배너에 있는 모든 픽셀이 그렇게 보이기를 원합니다. 그래서 20개의 이미지로 라크로아(LaCroix) 로어를 훈련합니다. 그리고 그 후에는 거의 완벽한 픽셀, 완벽한 모델을 갖게 됩니다.

Alessio [00:46:29]: 알겠습니다. 모든 게스트에 대해 LoRA를 훈련시켜야겠네요. 그러면 게스트가 썸네일(thumbnail)을 만드는 데 사용할 수 있겠어요.

Swyx [00:46:35]: 네. 저는 그것이 매우 좋은 애플리케이션이라고 생각합니다. 왜냐하면 엄격한 스타일이 아닌 방식으로 브랜드를 주입하는 좋은 방법이기 때문입니다. 그리고.

Gorkem [00:46:42]: 저희는 이제 막 비디오 모델에 대한 후처리 학습(post-training) 단계에 진입하고 있으며, 그것이 어떤 의미를 가질지에 대해 깊이 고민하고 있습니다. 왜냐하면 저희는 그동안 의미 있는 수준의 좋은 기본 비디오 모델을 보유하고 있지 않았기 때문입니다. 하지만 이제 저희는 2.2 또는 후니온(HunYuan) 모델에 대한 후처리 학습에 적극적으로 투자하는 기업들을 보유하고 있으며, 그 위에 립싱크 모델, 다양한 비디오 효과, 카메라 앵글 등을 구축하고 있습니다. 사람들이 창의적인 데이터 세트로 할 수 있는 무궁무진한 가능성이 있다고 생각합니다. 제 생각에 다음 6개월에서 1년 안에 저희는 오픈소스 비디오 모델의 후처리 학습을 기반으로 성장한 수많은 기업들을 만나게 될 것입니다. 와.

Alessio [00:47:18]: 파이프라인(pipeline)에 대해 이야기해 봅시다. 저희는 팟캐스트에서 Comfy Anonymous입니다. ComfyUI는 일종의 커뮤니티 같은데, 만약 당신이 그것에 빠져 있다면, 당신은 그것을 사랑할 것입니다. 만약 당신이 그것에 대해 모른다면, 당신은 그것을 과소평가하는 경향이 있습니다. 하지만 사람들은 온갖 종류의 기상천외한 워크플로우(workflow)를 만듭니다. 첫째, 파이프라인을 만드는 것에 대해 생각해 본 적이 있나요? 당연히 당신은 모든 모델을 호스팅하고 있습니다. 이런 질문이 있습니다.

Batuhan [00:47:36]: 저희는 파일 워크플로우(File Workflows)라는 파이프라인 제품을 보유하고 있으며, 모델들을 서로 연결할 수 있습니다. 하지만 ComfyUI만큼 유연하지는 않습니다. ComfyUI에서는 중간 단계의 요소들도 연결할 수 있지만, 저희는 다른 모델들의 출력만 연결할 수 있습니다. ComfyUI에서는 한 모델의 잠재 공간(latents)에 접근하여 그것을 잠재 공간 업스케일러(upscaler) 같은 곳에 전달할 수 있습니다. 저희의 경우 더 제한적이지만, 워크플로우 제품과 서버리스(serverless) Comfy 제품이 있습니다. 사용자들은 자신의 ComfyUI 워크플로우를 가져와서, 워크플로우와 입력값을 게시하는 것만으로 API로 실행할 수 있습니다. 그리고 모델은 당신이 제공하는 거죠. 네. 그럼, 그것은 긍정적인 신호인가요? 그것은 대형 모델에 의해 상품화될까요? 저희가 목격한 바에 따르면, 모델이 더 좋아질수록, ComfyUI는 2년 전, 1년 전 모델이, 아시다시피, 가장 큰 ComfyUI 사용 사례 중 하나는 ST 1.5나 STXL 이미지를 생성하고 여섯 손가락 상황을 수정하는 것이었습니다. 해상도를 수정하거나, 업스케일링하는 것이었죠. 이제 모델이 실제로 너무 뛰어나서, 이미지 측면에서는 ComfyUI 워크플로우가 실제로 더 간소화되고 있습니다. 비디오의 경우 여전히 매우 복잡합니다. 일부 비디오 워크플로우를 보면, 50개의 노드(node)가 있고, 그것을 처리하고 있습니다. 그래서 저는 이것이 여전히 모델의 품질과, 대부분의 사용 사례에 대해 주변에서 얼마나 많은 추가 작업을 해야 하는지의 문제라고 생각합니다. 예술적인 사용 사례의 경우, 여전히 그 모든 작업을 수행하고 있으며, 그것은 저희가 지원하고 싶은 부분입니다. 하지만 저희는 그것이 초대규모(hyperscale)로 일어나는 것을 목격하지는 못합니다. 초대규모에서는 API로 이것을 실행하는 데 천만 달러 이상을 지출하는 기업은 없습니다. 그래서 그것은 아직 일어나지 않는 것 같습니다. 왜냐하면 그것은 다소 비효율적이고, 기존 모델을 사용하는 것이 50개의 다른 것들을 짜깁기하는 것보다 더 신뢰할 수 있기 때문입니다. 언제 작동하지 않을지 모르니까요. 네.

Alessio [00:49:07]: 하지만 광고 같은 것들을 위해서는, 한 번에 처리하고 싶을 것 같습니다. 예를 들어, 새로운 단계를 진행할 때, 배경을 생성하는 단계, 문구를 추가하는 단계 같은 것들이요. 모델이 너무 뛰어나다는 말씀이신가요?

Gorkem [00:49:17]: 모델 체이닝(model chaining)은 확실히 일어나고 있습니다. 하지만 ComfyUI가 매우 잘한 것은 모델의 조각들로도 자유롭게 다룰 수 있다는 점입니다. 네, 당신은 기본적으로 그게 전부라고 말하고 있는 겁니다. 네. 그래서 모델 체이닝, 그것이 Fal Workflow 제품이 하는 일입니다. 기본적으로 여러 다른 API를 연속적으로 또는 병렬로 호출한 다음 마지막에 결과를 생성합니다. 그리고 그것은 매우 인기가 있습니다.

Swyx [00:49:37]: 저희는 매우 큰 기업들로부터 엔터프라이즈 채택(enterprise adoption)을 이끌어냈습니다. 네. 놀랍네요. 저는 더 넓은 주제로 넘어가려고 했습니다. 가장 먼저 떠오르는 것은 스타트업을 위한 조언입니다. 만약 당신이 Fal에서 직접 일하지 않더라도, 이 생태계에서 많은 것을 보았을 테니. 그렇죠. 사람들이 집중해야 할 가장 명백한 기회는 무엇일까요?

Batuhan [00:49:53]: 더 많은 모델 회사들. 더 많은 자금을 유치하여 모델을 훈련시키세요. 그것은 당연히 Fal에 좋은 일입니다. 그리고 Fal에 호스팅하세요. 만약 모델 훈련에 관심이 없다면, 다른 사람들이 훈련하는 것은 놀라운 일입니다. 더 많은 돈을 모으세요. 돈은 아주 많습니다.

Gorkem [00:50:05]: 또는 이미지 및 비디오 모델을 위한 스케일 AI(Scale AI)처럼, 데이터, 데이터 수집 분야도 있습니다. 비디오 모델을 위한 더 많은 준비된 데이터 세트, 효과, 다양한 카메라 앵글 등. 모두가 그 데이터를 수집하는 데 있어서 바퀴를 재발명하는 것처럼 보입니다. 저는 누군가가 이 분야에 뛰어들어 대규모로 이 작업을 수행한다면 좋은 기회가 될 것이라고 생각합니다.

Swyx [00:50:27]: 정말 흥미롭네요. 왜냐하면 제 생각에 이것이 투게더 AI(Together AI)가 레드 파자마(Red Pajama) 프로젝트로 했던 일이기 때문입니다. 그들은 실제로 언어 모델을 위한 데이터 세트를 구축하여 사람들이 서비스할 수 있는 더 많은 오픈 언어 모델을 만드는 데 기여했습니다. 그래서 어느 시점에는, 실제로 여러분이 직접 그 일을 하는 것이 합리적일 수도 있겠네요.

Batuhan [00:50:40]: 이미지 데이터는 저작권 문제 등에서 좀 더 까다로운 상황입니다. 하지만 흥미로운 분야입니다. 일본에서 하세요.

Gorkem [00:50:49]: 집중이 필요하다고 생각합니다. 이것은...

Batuhan [00:50:54]: 고르컴이 언급한 것과 연결되는 한 가지는 이미지/비디오 RL(강화 학습)입니다. 그것은 저희에게 미지의 영역입니다. 더 자세히 말씀해주세요. 지금은 불가능합니다. 그것이 어떤 모습일까요? 비디오 모델을 강화 학습시켜 월드 모델로 만들 수 있을까요? 가능합니다. 그렇죠? 만약 할 수 있다면. 본질적으로 동사 모델은 강화 학습된 비디오 모델이 아닙니다. 당신이 그것을 움직이도록 조건화하는 곳이죠. 그래서 이미지 및 비디오 모델을 강화 학습하는 사용 사례는 무엇일까요? 저는 아직 모르겠습니다. 하지만 만약 제가 현재 이 일을 하고 있지 않았다면, 탐험해 볼 만한 재미있는 분야가 될 것입니다.

Swyx [00:51:24]: 그리고 이것은 편집을 위한 것인가요? 왜냐하면 강화 학습의 보상(reward)이 편집이기 때문인가요?

Batuhan [00:51:29]: 그게 문제입니다. 그것이 당신이 찾아야 할 것입니다. 그렇죠? 보상 함수는 무엇이며, 이 기본 모델 위에 적용할 수 있는 흥미로운 보상 함수는 무엇인가요?

Swyx [00:51:37]: 알겠습니다. 흥미롭네요. 알겠습니다. 사실, 저는 정말로 묻고 있었습니다. 하지만 만약 제가 Fal 래퍼(wrapper) 스타트업을 만든다면, 그 위에요. 왜냐하면 여러분은 매우 낮은 수준에 있고, 그것은 환상적입니다. 하지만 저는 또한 우리 청취자들에게 몇 가지 아이디어를 주고 싶습니다. 만약 그들이 그 수준에서 일하지 않을 것이라면요.

Gorkem [00:51:51]: 다시 한번 강조하겠습니다. 광고, 광고입니다. 그 분야에는 너무나 많은 기회가 있으며, 모두가 여전히 어떤 창작자라도 쉽게 접근하여 무언가를 만들 수 있는 수평적인 애플리케이션(horizontal application)을 개발하려고 노력하고 있습니다. 하지만 특정 산업에 훨씬 더 집중하고, 다른 종류의 제품에 훨씬 더 집중해야 합니다. 애드 네트워크(ad network)처럼요. 거기에는 엄청난 잠재력이 있습니다. 클릭.

Swyx [00:52:13]: 그리고 모델에 대한 요청, 당연히 더 많은 오픈 모델을 원하시겠죠. 그건 당신에게 좋습니다. 하지만 모델의 전문화 같은 것이 있나요? 제 생각에 이미지, 이미지 편집은 제가 올해까지 예상하지 못했던 큰 돌파구였습니다.

Batuhan [00:52:26]: 저희는 "오, 당연히 그럴 거야"라고 생각했습니다. 심지어 OpenAI도 이것이 이렇게 커질 것이라고 예상하지 못했습니다. 이것은 정말 놀랍습니다. 얼마나 인기가 많아졌는지요. 그리고 모두가 따라잡기 시작했습니다.

Swyx [00:52:35]: 저는 매년 유럽에서 만나는 유럽 그룹의 일원이었는데, 그들이 이것에 대해 이야기하고 있었습니다.

Batuhan [00:53:02]: 스윅스와 알레시오, 이미지 모델은 사용하는 데이터 세트에 의해 정말, 정말, 정말 크게 영향을 받습니다.

Gorkem [00:53:13]: 네, 제 생각에 시장에 명백한 공백이 있는 한 가지는 베오3(VO3)가 매우 비싸다는 점입니다. 그리고 사람들이 그것을 좋아하는 이유는 대화 기능입니다. 그렇죠? 만약 당신이 더 작고, 더 저렴하며, 덜 유능하지만 대화와 사운드를 매우 잘 처리할 수 있는 비디오 모델을 만들 수 있다면, 저는 확실히...

Batuhan [00:53:31]: 저희가 목격한 오픈소스 모델 중 하나는 멀티토크(Multitalk)였습니다. 그것은 원(One)의 후처리 학습 버전이었고, 대화 생성에 정말, 정말 뛰어났습니다. 하지만 일반화 능력은 상실했습니다. 어느 시점에서는 말하는 얼굴만 생성 가능하고, 베오3는 일반화할 수 있으며 장면 등을 처리할 수 있습니다. 그래서 저는 이 두 가지, 즉 말하는 얼굴만 생성하는 모델과 극도로 일반화된 비디오 모델 사이에 어떤 중간 지점이 존재해야 한다고 생각합니다. 그것은 실행 비용이 훨씬 저렴합니다. 하지만 동시에, 이것은 매우 모방적이기 때문에 대화를 얻을 수 있습니다. 아시다시피, 사람들이 이것으로 게시할 수 있는 밈(meme)은 무한하고, 이것으로 할 수 있는 광고도 무한합니다.

Alessio [00:54:05]: 하지만 비디오 모델이 있고, 그 비디오에 대한 오디오를 생성할 수 있는 별도의 오디오 전용 모델이 있는 세상은 상상하지 않으시나요?

Swyx [00:54:11]: 이것이 이 질문에 대한 핵심 단어죠?

Gorkem [00:54:13]: 네. 여러 가지를 꿰매어 맞추나요, 아니면 더 나은 것을 덜 하나요? 사람들은 베오3 이전에 그렇게 했습니다. 하지만 베오3가 매우 잘하는 것은 타이밍입니다. 마치 농담을 요청하면, 그 전달과 타이밍, 웃음, 그리고 농담이 터지기 직전에 기다리는 것, 그 모든 것이 너무 완벽하게 맞춰져 있습니다. 따로 할 때는 그것을 얻을 수 있다고 생각하지 않습니다. 모두 똑같습니다.

Batuhan [00:54:37]: 그것은 또한 말하는 얼굴에 인간의 억양 소리를 맞춥니다. 그렇죠? 그것은 다른 텍스트-투-스피치 모델에게는 알려지지 않은 도전입니다. 매우 자연스럽게 느껴집니다. 베오3가 최고의 텍스트-투-스피치 모델인가요? 그것은 또한 최고의 텍스트-투-스피치 모델 중 하나입니다. 정말 좋습니다. 어떤 모델도 그것이 하는 것을 할 수 있다고 생각하지 않습니다.

Alessio [00:54:53]: 하지만 반론은 우리가 영화를 더빙한다는 것입니다. 그래서 이미, 아시다시피, 당연히 할 수 있습니다.

Batuhan [00:55:00]: 그것은 또한 최고의 립싱크(lipsync) 모델입니다. 베오3는 가장 정확한 립싱크를 가지고 있습니다. 왜냐하면 매우 자연스럽게 생성되기 때문입니다. 정말 좋은 립싱크 모델들이 있습니다. 제 생각에 그들은 95% 정도 도달했지만, 베오3는 100% 도달했습니다. 99% 정도요.

Swyx [00:55:11]: 저에게 이것은 워크플로우, ComfyUI, 그리고 이 모든 것들에 대해 가장 비관적인 한 가지입니다. 왜냐하면 그냥 더 큰 모델을 기다리면 되기 때문입니다. 이것은 순전히 뼈아픈 교훈입니다. 네, 저희는 ComfyUI를 사랑합니다.

Swyx [00:55:23]: 하지만 당연히 기술이 아직 존재하지 않을 때는 여러 가지를 꿰매어 맞춰야 합니다. 네. 그럼 엔지니어를 구하시나요? 네.

Alessio [00:55:30]: 제 말은, 분명히 채용 중이시죠? 방금 1억 2,500만 달러를 투자받으셨잖아요. 저희는 매우 선별적인 채용 방식을 가지고 있습니다.

Batuhan [00:55:36]: 저희는 최근에 100명, 40명을 넘게 채용했습니다. 하지만 3개월 전에는 20명이었습니다. 그래서 지난 3개월 동안 저희는 실제로 최고의 커널 엔지니어, 최고의 인프라 엔지니어, 최고의 제품 엔지니어, 최고의 ML 엔지니어를 가속화해 왔습니다. 만약 당신이 하는 일에서 최고라면, 그냥 저희와 함께하세요. 저는 당신이 무엇을 하든 상관없다고 생각합니다. 저희는 지금 최고의 인재를 채용하고 있습니다.

Gorkem [00:55:56]: 시장 진출(go-to-market) 측면에서도 저희는 어카운트 이그제큐티브(account executive), 고객 성공 매니저(customer success manager)를 채용하고 있습니다. 왜냐하면 저희는 매우 큰 기업들과 협력하기 때문입니다. 저희는 회사의 그쪽도 성장시켜야 합니다. 네.

Alessio [00:56:07]: 특히 엔지니어링 측면에서, 얼마나 많은 인력이 필요하다고 생각하십니까? "린 AI(Lean AI)"라는 질문이 있습니다. 코딩 에이전트(coding agent) 같은 거죠.

Batuhan [00:56:14]: 저희 성능 팀은 7명 정도입니다. 제 생각에 7명이 항상 성능에 집중하고 있고, 저희 응용 ML 팀과 일부 중복되는 부분이 있습니다. 이 팀은 이 모델들을 가져와서 제품화하고, 새로운 기능을 노출하고, 파인튜너(fine-tuner)를 구축합니다. 그리고 고객들이 이 모델들을 채택하도록 돕습니다. 그래서 그 팀은, 제 생각에 두 배, 세 배로 확장할 수 있습니다. 왜냐하면 무한한 수의 모델이 있고, 더 많은 독점 모델을 가진 더 많은 고객을 갖게 될 것이기 때문입니다. 네. 그래서 그들을 최적화하는 것을 돕는 것은 저희가 가진 정말 좋은 기능입니다.

Gorkem [00:56:40]: 그 팀은 매우 효율적으로 확장됩니다. 왜냐하면 항상 독립적인 작업이 가능하기 때문입니다. 아, 알겠습니다. 그래서 이 세 사람은 이 새로운 모델에 대해 작업하면서 그것을 최적화하려고 노력하고 있습니다. 그리고 그것은 이 다른 모델을 최적화하려는 노력과는 완전히 독립적입니다. 그래서 저희는 그 응용 ML 팀을 위해 많은 채용을 해왔습니다.

Batuhan [00:56:56]: 저희 팀의 목표는, 응용 ML 팀과 제품 팀과는 대조적으로, 아마도 팀을 간결하게 유지하고, 사람들이 자신의 애플리케이션에 직접 통합할 수 있는 더 높은 수준의 구성 요소를 더 많이 구축하는 것입니다. 왜냐하면 지금은 SDK나 SDK만 있지만, 구성 요소를 생각해보세요. 당신이 전자 상거래 웹사이트 디자이너이고, 최고의 구성 요소 디자이너가 아니라고 상상해보세요. 그래서 여기에 당신의 앱에 넣을 수 있는 가상 시착 구성 요소가 있습니다. 그런 것들, 더 높은 수준의 구성 요소들입니다. 그리고 이것은 또한, 아시다시피, 와이프 코딩(wife coding)이 매우, 매우 놀라웠다는 사실에서 비롯됩니다. 저희는 모두, 저희는 상당한, 매출 면에서는 매우 작지만, 사용자 채택이 상당한 양으로 증가하는 것을 봅니다. 단지 저희 지원 티켓을 보면, 아마도 그들은 더 많은 지원이 필요하지만, 제품 구축에 대한 전문 지식이 그다지 많지 않은 사람들이 이러한 애플리케이션을 코딩하고 있습니다.

Swyx [00:57:43]: 그래서 저희는 그들에게 더 많은 가드레일(guardrail) 경험을 제공하여, 다른 모든 낮은 수준의 구성 요소를 건드리지 않고도 훨씬 쉽게 통합할 수 있도록 하고 싶습니다. 개발자 경험을 정말 잘 챙겨주시네요. 그럼 뛰어난 저수준 엔지니어들.

Alessio [00:57:57]: 그리고 뛰어난 고수준. 음, 네, 고수준 엔지니어, 뛰어난 엔지니어, 뛰어난 시장 진출 인력, 뛰어난 뭐든지, 그냥 당신의 생각입니다.

Swyx [00:58:04]: 저는 항상 정의를 다듬으려고 노력하고 있습니다. 아시다시피, '뛰어난(cracked)'. 두 분 모두 실패의 기술적인 측면을 이끌고 계시죠. 정말 어려운 기술적인 문제가 있는데, 만약 누군가 해결책을 가지고 있다면, 그들이 즉시 당신과 이야기해야 하는 그런 문제가 있나요? 아마도 그렇게 질문을 구성하는 것이 방법일 수 있겠네요.

Batuhan [00:58:16]: 블랙웰(Blackwell)에서 FBA(Fused Batch Attention)를 사용하여 희소 어텐션 커널(sparse attention kernel)을 작성하고 말해보세요. 만약 그것을 할 수 없다면, 저희와 함께하세요. 저희는 이미 좋은 기반을 가지고 있습니다. 즉석에서 채용됩니다. 즉석에서 채용됩니다. 아시나요? 그런 것들입니다. 저는 이런 응용 ML 사람들 중 일부를 뽑는 것을 정말 좋아합니다. 저희는 그들을 디스코드(Discord)에서 뽑았는데, 그들은 이런 종류의 용어와 미디어에 대해 작업하고 있었고, 이미 관심이 있었습니다. 저희는 또한 매우 높은 문화적 기준을 가지고 있습니다. 팀의 모든 사람들이 생성 미디어에 깊이 빠져 있습니다. 그들은 그것에 집착합니다. 이것이 그들의 직업이 아니었더라도 이것을 했을 것입니다. 저희는 이 훌륭한 구성을 가지고 있습니다. 항상, 필수 조건은 아니지만, 자연스럽게 그렇게 되었습니다. 저희는 이 사람들을 디스코드, 트위터, 허깅 페이스에서 채용했습니다. 저희 응용 ML 엔지니어 중 한 명은 창의적인 워크플로우 등으로 허깅 페이스 스페이스에서 1위를 차지했습니다. 그래서 저희는 Fal에서 도리스(Doris)를 훈련시키던 사람을 채용했습니다. 단지 그들이 멋진 로라를 훈련하고 게시하고 있었기 때문입니다. 아시나요? 그냥 멋진 일을 하세요. 그러면 저희가 당신을 찾거나, 당신이 할 수 있습니다.

Swyx [00:59:06]: 네, 그것이 제가 이 사람을 부르는 '마스터 빌더(master builder)'입니다.

Alessio [00:59:10]: 왜 더 명시적으로 만들지 않나요? 만약 제가 당신의 채용 웹사이트에 들어가면, 그렇죠. "응용 ML 엔지니어에 지원하세요"라고 되어 있습니다. 그냥 어떤 채용 공고처럼 보입니다. 제 생각에 "그래서 팟캐스트를 해야 한다"는 질문이 있는 것 같습니다. 하지만 저는 그것이 Fal에 관한 것만은 아니라고 생각합니다.

Batuhan [00:59:25]: 제 생각에 일반적으로, "아는 사람은 안다"는 식인데, 저는 그것이 최선의 방법은 아니라는 것을 압니다. 사람들은 이미 Fal에 대해 알고 있습니다. 그래서 저희는 그다지 신경 쓰지 않았지만, 당신 말이 절대적으로 맞습니다.

Alessio [00:59:35]: 저희는 그것을 더... 하지만 제가 조지 호츠(George Hotz)의 타이니그래드(tinygrad)를 보면, 이런 균형이 있습니다. "이것을 해결할 수 있다면, 아마 여기서 일해야 할 것이다." 현상금을 추가하는 것을 보시나요? "이 커널을 작성할 수 있다면, 그냥 채용될 것이다"와 같습니다.

Batuhan [00:59:51]: 그것은 또한, 저희가 목격한 한 가지는, 많은 사람들이 그냥 와이프 코딩을 하고 그것들을 검토하는 것과도 관련이 있습니다. 그것들을 정말로 할 수 있는 사람은 제한적입니다. 그렇죠.

Alessio [01:00:00]: 예를 들어, 그것이 형편없는 커널이 아니라 좋은 호출(call)이라는 것을 어떻게 알 수 있나요? 하지만 당신은 인터뷰에 시간을 쓰고 있습니다. 네.

Batuhan [01:00:06]: 그래서 저희는 채용 담당자들과 함께 1차 방어선을 가지고 있습니다. 그래서 당신은... 그래서 트레이드오프(trade-off)가 있지만, 저는 절대적으로 동의합니다. 아마도 저희는 당신이 커널을 업로드하고, 안정성, 성능 등을 자동으로 평가할 수 있는 커널 벤치(kernel bench) 버전을 가져야 할 것입니다. 그리고 만약 당신이 그렇게 하면, 당신은 저희 이메일을 잠금 해제하게 됩니다. 당신을 위한 이메일이지만, 네, 좋은 아이디어입니다. 저희와 함께하세요.

Alessio [01:00:31]: 멋지네요, 여러분. 다른 할 말 있나요? 마지막 생각. 네. 당신의 열변을 좋아합니다. 정말 좋았어요. 네.

Gorkem [01:00:37]: 기꺼이 열변을 토하겠습니다. 하지만 이것은 팟캐스트 스타일입니다. 네.

Swyx [01:00:40]: 아뇨, 모든 성공을 축하합니다. 음, 여러분과 노래방 가는 것도 재미있다고 말해야겠네요. 네. 다시 합시다. 둘 다 극도로 기술적이면서도 재미있는 팀입니다. 그리고 제 생각에 그렇게 하기는 꽤 어렵고 드뭅니다. 그래서 좋은 사람들이 이기는 것을 보게 되어 감사합니다.

Alessio [01:00:56]: 멋지네요, 여러분. 멋져요.