AI 엔지니어 코드 서밋(11월 20-22일, 뉴욕) 참가 신청이 시작되었습니다. 생성형 비디오(Generative Video)는 2025년의 주요 트렌드 중 하나였습니다. 이 분야는 완전히 폭발적으로 성장했으며, NBA 결승전 중 방영된 Kalshi 광고처럼 주류 미디어에서도 볼 수 있습니다. 저희는 무어 쌍둥이와 함께 이에 대한 전체 에피소드를 제작하기도 했습니다! 오늘 저희는 이러한 모델 다수의 추론(inference)을 지원하는 숨은 주역인 Fal.ai(잘 알려진 일부 비공개 소스 이미지 및 비디오 확산 모델 포함)에 대해 다룹니다. 이들은 올해에만 약 1억 달러의 신규 매출을 추가할 것으로 예상되며, 그중 비디오가 차지하는 비중은 점점 더 커지고 있습니다. 하지만 불과 2년 전만 해도 이들은 dbt 데이터 파이프라인을 위한 도구를 만들고 있었습니다! Fal은 이제 플랫폼에서 600개 이상의 모델을 호스팅하며, 성능 향상을 위해 100개 이상의 맞춤형 CUDA 커널(CUDA kernels)로 구동됩니다. 저희는 이 팟캐스트를 통해 생성형 모델의 역사와 그 역사 속 주요 변곡점이 무엇이었는지 요약해보고자 했습니다. 즐겁게 감상해주세요!

### 생성형 AI 시장의 확장과 최신 동향

생성형 AI는 단순한 텍스트나 이미지 생성을 넘어, 비디오, 오디오, 3D 모델, 심지어 코드 생성에 이르기까지 그 영역을 폭발적으로 확장하고 있습니다. 2024년은 특히 멀티모달(multimodal) AI와 더욱 정교해진 제어 가능성(controllability)이 핵심 트렌드로 부상하고 있습니다. 이미지 모델은 이제 단순한 장면 생성을 넘어 스타일 전이(style transfer), 인페인팅(inpainting), 아웃페인팅(outpainting) 등 정교한 편집 기능을 제공하며, 비디오 모델은 텍스트 프롬프트만으로 현실적이고 일관된 장면을 생성하는 수준에 도달했습니다.

이러한 발전은 모델 자체의 성능 향상뿐만 아니라, Fal.ai와 같은 추론 최적화 플랫폼의 역할이 중요해졌음을 의미합니다. 수많은 모델이 등장하고 각 모델이 고유한 아키텍처와 요구사항을 가짐에 따라, 이들을 효율적으로 배포하고 운영하는 기술이 경쟁 우위를 결정짓는 요소가 됩니다. 특히 실시간 상호작용이 요구되는 애플리케이션의 경우, 지연 시간(latency)을 최소화하고 처리량(throughput)을 극대화하는 최적화 기술은 사용자 경험과 직결됩니다. 최근에는 모델 경량화 기술인 양자화(quantization) 및 증류(distillation) 기법이 더욱 고도화되어, 고품질 출력을 유지하면서도 훨씬 적은 컴퓨팅 자원으로 모델을 구동할 수 있게 되었습니다. 이는 클라우드 비용 절감은 물론, 엣지 디바이스(edge devices)에서의 AI 배포 가능성을 열어주며 생성형 AI의 적용 범위를 더욱 넓히고 있습니다.

### Fal의 모델 역사

아래 모든 링크는 쇼 노트에서 확인하세요.

*   **스테이블 디퓨전 1.5(Stable Diffusion 1.5)**
    *   Fal이 최적화된 추론 호스팅으로 방향을 전환했을 때 첫 번째 주요 히트작
    *   광범위한 미세 조정(fine-tuning) 생태계로 매우 인기를 얻음
    *   빠르고, 저렴하며, 신뢰할 수 있어 LoRA와 함께 오늘날에도 여전히 사용됨
*   **스테이블 디퓨전 2.1(Stable Diffusion 2.1)**
    *   큰 주목을 받지 못한 "약간의 실패작"으로 묘사됨
*   **스테이블 디퓨전 XL(SDXL)**
    *   FAL에 첫 백만 달러 매출을 안겨준 최초의 주요 모델
    *   미세 조정(fine-tuning) 생태계(LoRA)를 폭발적으로 성장시킴
    *   **SDXL Lightning**: 더 빠른 생성을 위해 ByteDance가 만든 증류 버전(distilled version)

### Fal의 모델 역사: 지속적인 혁신과 비디오 모델의 부상

생성형 AI 시장은 끊임없이 진화하며 새로운 기술과 모델이 빠르게 기존의 패러다임을 대체하고 있습니다. Fal.ai는 이러한 변화의 최전선에서 핵심적인 역할을 수행하며, 최신 모델들을 개발자들에게 제공하고 있습니다.

*   **Flux 모델(Flux Models) (Black Forest Labs)**
    *   "상업적으로 사용 가능하고, 엔터프라이즈급" 모델의 장벽을 처음으로 허물었음
    *   첫 달에 FAL의 매출을 2백만 달러에서 1천만 달러로, 그 후 2천만 달러로 끌어올림
    *   세 가지 버전:
        *   **Schnell**: Apache 2 라이선스, 극도로 증류됨, 저품질을 위한 4단계 생성
        *   **Dev**: 수익 공유가 있는 비상업적 라이선스
        *   **Pro**: 호스팅을 위해 협업 필요
*   **비디오 모델(Video Models)**
    *   **Sora**
        *   가능성의 문을 연 OpenAI의 모델
        *   연구자들에게 동기를 부여했지만 몇 달 만에 추월당함
    *   **Veo3 (Google DeepMind)**
        *   사운드가 포함된 "사용 가능한 텍스트-투-비디오(text-to-video) 구성 요소"를 만듦
        *   운영 비용이 매우 비쌈
        *   대화, 타이밍, 립싱크에 탁월함
        *   최고의 텍스트-투-스피치(text-to-speech) 모델 중 하나로도 기능함

이러한 모델들의 등장은 Fal.ai의 성장 동력이 되었을 뿐만 아니라, 생성형 미디어 시장 전체의 확장을 이끌었습니다. 특히 비디오 모델 분야는 Sora의 등장 이후 급격한 발전을 이루었으며, Veo3와 같은 후속 모델들은 단순히 시각적인 일관성을 넘어 오디오와의 통합, 정교한 타이밍 제어 등 실제 프로덕션에 활용 가능한 수준으로 진화하고 있습니다. 이는 Fal.ai가 비디오 모델 추론 최적화에 집중하게 된 주요 배경이며, 현재 Fal.ai 매출의 상당 부분을 비디오 모델이 차지하게 된 이유를 설명합니다.

### Fal.ai의 전략적 전환: LLM 대신 생성형 미디어를 선택한 이유

Fal.ai가 겪은 가장 중요한 변곡점 중 하나는 dbt 데이터 파이프라인에서 생성형 미디어 추론 최적화로의 전환이었습니다. 그리고 그 안에서도 거대 언어 모델(LLM)이 아닌 이미지 및 비디오 모델에 집중하기로 한 전략적 결정은 Fal.ai의 성공에 결정적인 역할을 했습니다.

"네, 거기서 몇 가지 결정을 내려야 했습니다. 저희는 회사를 GPU 오케스트레이션 쪽으로 더 발전시킬 수도 있었습니다. 본질적으로 저희는 이 파이썬 런타임을 가지고 있었고, GPU 위에서 실행하고 있었죠. 그게 회사가 될 수도 있었습니다. 하지만 저희는 저희가 가진 것, 즉 GPU에서 파이썬 코드를 실행하기 위한 작은 SDK를 사용하는 모든 사람, 모든 회사가 똑같은 일을 하고 있다는 것을 보았습니다. 그들은 스테이블 디퓨전 애플리케이션을 배포하고 있었고, 아마도 그 위에 일부 LORA를 사용하고, 다른 버전을 사용하고, 인페인팅, 아웃페인팅 같은 것들을 하고 있었습니다. 이건 매우 낭비적이었습니다. 저희는 이것이 우리가 추론 과정을 실제로 최적화하고 모두가 그 혜택을 받는 API가 되어야 한다고 결정했습니다. 그리고 멀티테넌트로 실행할 수 있죠, DTools.io처럼요. 그리고 멀티테넌트로 실행할 수 있죠, DTools.io처럼요. 그리고 멀티테넌트로 실행할 수 있죠, DTools.io처럼요. 그래서 그것이 첫 번째 결정이었습니다. 그리고 당연히 스테이블 디퓨전 이후 4~5개월 뒤에 라마 2가 나왔고, 다시 결정의 순간이 왔습니다. 언어 모델을 할 수도 있었죠. 맞습니다. 그리고 당시의 추론 제공업체들, 아마 두어 곳 있었을 텐데, 그들 모두 언어 모델에 올인했습니다. 저희는 언어 모델, 언어 모델 호스팅이 좋은 사업이 아니라고 결정했습니다. 당시 저희는 생각했습니다. 우리는 다시 경쟁하게 될 것이다. OpenAI, Anthropic, 그리고 이 모든 연구소들과 경쟁하게 될 것이다. 결과적으로는 더 나빴습니다. 왜냐하면 언어 모델의 킬러 애플리케이션은 검색이고, 결국에는 구글과 경쟁하게 되는 것이기 때문입니다. 그리고 구글은 원한다면 이것을 무료로 제공할 수 있습니다. 왜냐하면 그것이 그들에게 매우 중요하고, 그들의 사업을 즉시 위협하기 때문입니다. 그리고 이미지와 비디오 모델은 완전히 새로운 시장이었습니다. 저희는 어떤 기존 강자와도 맞서지 않았습니다. 저희는 저희보다 훨씬 큰 누군가로부터 시장 점유율을 뺏으려 하지 않았습니다. 그리고 저희는 그 점이 마음에 들었습니다. 저희는 여기서 리더가 될 수 있다고 생각했습니다. 틈새 시장이었지만 매우 빠르게 성장하고 있었습니다. 그래서 저희는 구글이나 OpenAI, Anthropic과 맞서 싸우기보다는 이 빠르게 성장하는 틈새 시장에서 리더가 되거나 리더가 되기 위해 노력하기로 선택했습니다. 그것이 저희가 내린 결정이었습니다. 그리고 결과적으로 좋은 결정이었습니다. 왜냐하면 저희는 저희가 속한 시장을 정의하고, 사람들을 교육하며, 그것과 함께 성장할 수 있었기 때문입니다."

### Fal.ai의 기술적 강점과 최적화 전략 심층 분석

Fal.ai의 핵심 경쟁력은 GPU 기반 AI 모델 추론을 위한 독보적인 최적화 기술에 있습니다. 특히 맞춤형 CUDA 커널 개발은 이들의 기술력을 상징합니다.

"지난 3년 동안 정말 많이 발전했습니다. 처음 시작했을 때는 스테이블 디퓨전 1.5라는 단일 모델만 있었습니다. 그래서 저희의 모든 커널 노력은 어떻게 하면 스테이블 디퓨전 1.5를 최대한 빠르게 만들 수 있을까에 집중되었습니다. 당시에는 PyTorch로 10초 정도 걸렸는데, torch compiled나 torch inductor 같은 것도 없었습니다. 그래서 같은 GPU에서 10초에서 아마 2초 정도로 줄일 수 있었습니다. 어. 그리고. 그리고 저희는 그것으로 시작했습니다. 다음으로, 더 많은 모델을 추가하면서, 스테이블 디퓨전 엑셀은 다른 아키텍처였고, PicsArt도 다른 아키텍처였습니다. 이 모든 다른 아키텍처들이 등장하기 시작했습니다. 저희는 추론 엔진을 만들자고 했습니다. 저희는 이것을 커널, 병렬화 유틸리티, 확산 캐싱 방법, 양자화 등 모든 것을 하나의 패키지로 결합한 것이라고 부릅니다. 그리고 저희는 이 추론 엔진을 만들었습니다. 동시에 PyTorch 2.0이 Torch inductor와 Torch Dynamo와 함께 출시되었는데, 이것은 Torch compiled를 하기 위한 것으로, 본질적으로 신경망의 실행을 추적하고 융합된, 즉 더 효율적인 Triton 커널을 생성하는 방법입니다. 그리고 저는 JIT(just-in-time) 컴파일러의 열렬한 팬입니다. 저는 파이썬을 위한 JIT 컴파일러인 PyPi에서 일했었습니다. 그리고 저희는 이것이 훌륭한 아이디어라고 생각했습니다. 이것을 확산 모델에 더 전문화되고 수직적인 방식으로 적용하자고요. 당시에는 Unet이었고, 지금은 확산 트랜스포머입니다. 이것들은 계산 바운드 정도, 어떤 종류의 커널이 대부분의 시간을 차지하는지, 양방향 어텐션을 하는지 인과적 어텐션을 하는지 등 프로파일 측면에서 자기회귀 트랜스포머와는 상당히 다릅니다. 그래서 저희는 그것을 하기 시작했습니다. 그리고 지금 저희가 가진 것은 확산 트랜스포머의 대부분의 모델에서 70~80%의 성능을 얻을 수 있는 추론 엔진입니다. 그리고 저희는 여전히 많은 모델에 대해 많은 맞춤형 커널을 가지고 있습니다. 왜냐하면 그것들은 여전히 작기 때문입니다. 모든 모델은 아키텍처적인 차이를 만들고 싶어 합니다. 여러분도 이런 것을 보셨을 겁니다. Kven, DeepSeq 같은 것들에서도요. 사람들이 우리가 어떤 아키텍처가 최고인지 알더라도, 그들은 "우리는 멋진 것을 출시하고 있어"라고 확실히 하기 위해 약간 수정하고 싶어 합니다. 그래서 저희는 이것을 보았습니다. 그리고 그것을 위해 저희는 사람들이 하는 맞춤형 RMS norm이나 그런 것들을 위해 맞춤형 커널을 작성해야 했습니다. 그래서 저희는 100개가 넘는 상당한 양의 맞춤형 커널을 가지고 있습니다. 이것은 자동 생성된 것은 포함하지 않습니다. 저희는 수천 개의 다른 모양, 문제 공간 등을 위해 생성되는 커널 템플릿을 가지고 있습니다. 하지만 그것들을 고려한다면, 저희는 런타임에 수만 개의 커널을 실행하고 디스패치하고 있습니다. 하지만 그것이 대략적인 깊이와 넓이입니다."

Fal.ai의 최적화 노력은 단순히 기존 커널을 개선하는 것을 넘어, 새로운 GPU 아키텍처(예: NVIDIA Blackwell)가 등장할 때마다 선제적으로 대응하여 최적의 성능을 끌어내는 데 집중됩니다. 이는 엔비디아(NVIDIA)와 같은 하드웨어 제조사도 따라잡기 어려운 수준의 전문성을 요구합니다. 특히 확산 모델의 경우 메모리 대역폭(memory bandwidth)과 행렬 곱셈(matrix multiplication) 효율성이 중요한데, Fal.ai는 이 부분을 심층적으로 분석하여 커널 수준에서 병목 현상(bottleneck)을 제거합니다. 예를 들어, 어텐션(attention) 메커니즘에서 발생하는 계산 비용을 줄이기 위해 희소 어텐션(sparse attention) 커널을 구현하거나, 특정 데이터 유형(예: FP16)에 최적화된 연산을 적용하여 처리 속도를 가속화합니다.

이러한 맞춤형 최적화는 단순히 속도 향상만을 의미하는 것이 아닙니다. 동일한 GPU에서 더 많은 작업을 처리할 수 있게 하여 운영 비용을 절감하고, 사용자에게는 더 낮은 비용으로 더 빠른 서비스를 제공할 수 있게 합니다. 또한, 모델 아키텍처가 끊임없이 변화하는 상황에서, Fal.ai의 추론 엔진은 새로운 모델이 출시될 때마다 유연하게 대응하여 빠르게 최적화된 버전을 제공할 수 있는 역량을 갖추고 있습니다. 이는 오픈소스 생태계와 비공개 소스 모델 제공업체 모두에게 Fal.ai가 매력적인 파트너가 되는 이유입니다.

### 생성형 비디오의 발전과 실제 적용 사례

생성형 비디오 기술은 최근 몇 년간 가장 빠르게 발전하고 있는 AI 분야 중 하나입니다. 과거에는 짧고 품질이 낮은 비디오 클립을 생성하는 데 그쳤지만, 이제는 복잡한 스토리텔링과 일관된 캐릭터를 가진 고품질 비디오를 생성하는 것이 가능해지고 있습니다.

**주요 발전:**

1.  **시공간적 일관성 향상:** 초기 비디오 모델의 가장 큰 한계는 프레임 간의 일관성 부족이었습니다. 최근 모델들은 시간적 일관성(temporal consistency)을 크게 개선하여, 캐릭터나 객체가 비디오 전체에서 자연스럽게 움직이고 형태를 유지하도록 합니다.
2.  **오디오 통합 및 립싱크:** Veo3와 같은 모델에서 볼 수 있듯이, 비디오와 오디오를 동시에 생성하고 립싱크(lip-sync)까지 완벽하게 맞추는 기술이 발전하고 있습니다. 이는 단순한 시각적 콘텐츠를 넘어 실제 대화나 음악이 포함된 비디오를 만드는 데 필수적입니다.
3.  **제어 가능성 강화:** 사용자들은 이제 카메라 앵글, 캐릭터 포즈, 스타일, 심지어 특정 액션까지 정교하게 제어할 수 있게 되었습니다. 이는 비디오 생성의 예술적, 상업적 활용 가능성을 크게 넓힙니다.
4.  **효율적인 생성:** 텍스트-투-비디오(text-to-video) 모델은 여전히 많은 컴퓨팅 자원을 요구하지만, 최적화 기술과 증류 모델(distilled models)의 발전으로 생성 시간이 단축되고 비용 효율성이 개선되고 있습니다. 알리바바(Alibaba)의 One 모델처럼 드래프트 모드에서는 수 초 내에 비디오를 생성하여 빠른 피드백 루프를 제공합니다.

**실제 적용 사례:**

*   **광고 및 마케팅:** 개인화된 광고 콘텐츠를 대량으로 빠르게 생성하여 특정 고객층에 최적화된 메시지를 전달할 수 있습니다. 제품 시연, 캠페인 비디오 등 다양한 형식으로 활용됩니다.
*   **콘텐츠 제작 및 미디어:** 짧은 형식의 소셜 미디어 콘텐츠, 뉴스 요약, 교육용 비디오, 애니메이션 스케치 등을 자동 생성하여 콘텐츠 제작 워크플로우를 가속화합니다. 특히 '인간 참여형(human-in-the-loop)' 방식으로 AI가 초안을 만들고 전문가가 다듬는 방식이 보편화되고 있습니다.
*   **게임 및 가상현실:** 게임 내 NPC(Non-Player Character)의 대화 애니메이션, 배경 영상, 가상 환경 요소 등을 동적으로 생성하여 더욱 몰입감 있는 경험을 제공합니다.
*   **개인화된 미디어:** 사용자의 취향이나 데이터에 기반하여 맞춤형 스토리, 비디오 메시지 등을 생성하는 서비스가 등장할 수 있습니다.
*   **기업 교육 및 설명:** 복잡한 개념이나 제품 사용법을 설명하는 교육용 비디오를 빠르게 생성하여 직원 교육 및 고객 지원에 활용할 수 있습니다.

### 생성형 미디어 생태계의 협력과 미래 전망

생성형 미디어 생태계는 모델 개발자, 인프라 제공업체, 애플리케이션 개발자, 그리고 최종 사용자 간의 유기적인 협력을 통해 성장하고 있습니다. Fal.ai와 같은 추론 플랫폼은 이 생태계의 핵심적인 연결 고리 역할을 합니다.

**개방형 모델과 상업적 활용:**
오픈소스 모델은 혁신의 속도를 가속화하고 광범위한 실험을 가능하게 합니다. 스테이블 디퓨전(Stable Diffusion)의 LoRA(Low-Rank Adaptation) 생태계는 사용자들이 특정 스타일, 캐릭터, 객체 등을 미세 조정(fine-tuning)하여 맞춤형 콘텐츠를 생성할 수 있게 하며, 이는 상업적 활용의 중요한 기반이 됩니다. Fal.ai는 이러한 오픈소스 모델을 최적화하여 개발자들이 쉽게 접근하고 활용할 수 있도록 지원하며, 동시에 Flux 모델과 같이 수익 공유 모델을 통해 상업적 사용을 장려하는 비공개 소스 모델 개발자들과도 협력합니다. 이러한 협력은 모델 개발자에게는 수익화 기회를, 사용자에게는 더 다양하고 강력한 도구를 제공하는 상생 구조를 만듭니다.

**워크플로우의 진화: ComfyUI와 엔터프라이즈 통합:**
ComfyUI와 같은 노드 기반 인터페이스는 복잡한 생성형 AI 워크플로우를 시각적으로 구성할 수 있게 하여, 창작자들이 다양한 모델과 기능을 조합해 고유한 결과물을 만들어낼 수 있도록 돕습니다. 초기에는 이미지 품질 개선이나 오류 수정과 같은 용도로 활용되었으나, 모델 자체의 성능이 향상됨에 따라 ComfyUI 워크플로우는 점차 간소화되거나, 비디오 생성과 같이 여전히 복잡한 작업에 집중되는 경향을 보입니다. Fal.ai는 이러한 추세를 인식하고 'Fal Workflows'와 같은 파이프라인 제품을 통해 모델 체이닝(model chaining)을 지원하며, ComfyUI 워크플로우를 API로 실행할 수 있는 서버리스(serverless) 솔루션도 제공하여 엔터프라이즈 환경에서의 통합을 용이하게 합니다.

**새로운 기회와 도전:**
생성형 미디어 시장의 급성장은 새로운 스타트업들에게 무한한 기회를 제공합니다. 특히 다음과 같은 분야에서 잠재력이 큽니다:
*   **데이터셋 구축 및 큐레이션:** 고품질의 정제된 이미지/비디오 데이터셋은 모델 훈련의 핵심입니다. 저작권 문제를 해결하고 특정 목적에 맞는 데이터를 대규모로 수집, 가공하는 전문 기업의 필요성이 커지고 있습니다.
*   **특정 산업 맞춤형 애플리케이션:** 범용적인 생성 도구를 넘어, 광고, 영화 제작, 게임 개발, 교육 등 특정 산업의 요구사항에 맞춰 특화된 생성형 미디어 솔루션을 개발하는 것이 중요합니다.
*   **AI 기반 콘텐츠 검증 및 중재:** 생성형 미디어의 확산과 함께 딥페이크(deepfake)와 같은 악용 사례나 NSFW(Not Safe For Work) 콘텐츠의 위험도 증가하고 있습니다. 이를 효과적으로 감지하고 중재하는 기술 및 서비스의 수요가 높아질 것입니다.
*   **멀티모달 상호작용 디자인:** 텍스트, 이미지, 비디오, 오디오를 유기적으로 결합하여 새로운 형태의 상호작용 경험을 제공하는 디자인 및 개발 역량이 중요해집니다.

### 마무리하며: 인재와 기회

생성형 미디어의 미래는 기술적 혁신뿐만 아니라, 이 분야에 열정을 가진 뛰어난 인재들에게 달려 있습니다. Fal.ai와 같은 선두 기업들은 커널 엔지니어, 인프라 엔지니어, ML 엔지니어, 제품 엔지니어 등 다양한 분야에서 최고의 인재를 적극적으로 찾고 있습니다. 특히 최신 GPU 아키텍처에 대한 깊은 이해와 실제 프로덕션 환경에서의 최적화 경험을 가진 전문가들은 이 시장에서 핵심적인 역할을 할 것입니다.

생성형 미디어는 단순한 기술 트렌드를 넘어, 우리가 콘텐츠를 만들고 소비하는 방식을 근본적으로 변화시키고 있습니다. Fal.ai의 여정은 이러한 변화의 중심에서 어떻게 기술적 통찰력과 전략적 결정을 통해 시장을 선도할 수 있는지를 보여주는 좋은 예시입니다. 앞으로도 이 분야는 예측 불가능한 속도로 발전할 것이며, 그 과정에서 수많은 새로운 기회와 도전이 기다리고 있습니다.