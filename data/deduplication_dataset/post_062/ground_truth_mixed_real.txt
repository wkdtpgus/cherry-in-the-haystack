1.  **AgentFold: 장기 웹 에이전트의 컨텍스트 관리 혁신**
    AgentFold는 장기 웹 에이전트(long-horizon web agents)를 위한 능동적인 컨텍스트 관리(proactive context management)를 도입하여, 세부 정보 보존과 효율적인 압축의 균형을 맞추는 동적 "폴딩(folding)" 작업을 통해 컨텍스트 포화(context saturation) 문제를 해결합니다. 이 혁신적인 접근 방식은 30B 매개변수 모델이 훨씬 더 큰 경쟁자들을 능가하며 웹 브라우징 벤치마크에서 최첨단 결과(state-of-the-art results)를 달성하도록 이끌었습니다. 이는 2025년 현재, 실제 웹 환경에서의 에이전트 성능 향상에 중요한 진전을 의미합니다.

    **핵심 문제 해결의 새로운 접근**: LLM 기반 웹 에이전트는 근본적인 절충점(fundamental trade-off)에 직면합니다. ReAct 기반 방식은 노이즈가 많은 기록을 축적하여 컨텍스트 포화(context saturation)를 유발하는 반면, 고정된 요약 방법은 중요한 세부 정보를 되돌릴 수 없이 잃을 위험이 있습니다. AgentFold의 "폴딩(folding)" 패러다임은 여러 규모에서 작동하며, 인간의 회고적 통합(retrospective consolidation)에서 영감을 받아 필수적인 세부 정보에 대한 세분화된 응축(granular condensations) 또는 다단계 하위 작업(multi-step sub-tasks)에 대한 심층적인 통합(deep consolidations)을 수행합니다. 이는 에이전트가 복잡한 온라인 작업을 수행할 때 필요한 정보만 효율적으로 유지하도록 돕습니다.

    **능동적인 컨텍스트 관리(Proactive context management)**: AgentFold는 행동 기록을 수동적으로 로깅(logging)하는 대신, 다중 규모 폴딩(folding) 작업을 통해 컨텍스트 작업 공간을 능동적으로 조각합니다. 이 시스템은 작업 복잡성과 정보 밀도에 동적으로 적응하여, 세밀한 세부 정보를 보존할 시점과 완료된 하위 작업을 간결한 요약으로 심층적으로 통합할 시점을 결정합니다. 이러한 동적 조절은 웹 탐색 에이전트의 효율성을 극대화합니다.

    **인상적인 효율성 향상**: AgentFold-30B-A3B는 BrowseComp에서 36.2%, BrowseComp-ZH에서 47.3%를 달성하여 DeepSeek-V3.1-671B(22배 더 큼)를 능가하고 OpenAI의 o4-mini와 같은 독점 에이전트를 뛰어넘습니다. 이는 지능형 컨텍스트 관리(intelligent context management)가 장기 에이전트 작업에서 순수 매개변수 수(raw parameter count)를 대체할 수 있음을 보여줍니다. 특히, 이러한 결과는 특정 산업 웹 자동화 및 데이터 수집 분야에서 AgentFold의 잠재력을 강력하게 시사합니다.

    **훈련의 용이성**: 지속적인 사전 훈련(pre-training)이나 강화 학습(reinforcement learning) 없이 폴딩(folding) 궤적에 대한 지도 미세 조정(supervised fine-tuning)을 통해 달성됩니다. 이는 실무자에게 이 접근 방식을 더 접근하기 쉽게 만들고, 폴딩(folding) 기능이 시연만으로 학습될 수 있음을 보여줍니다. 이러한 단순성은 에이전트 개발 커뮤니티에 큰 이점으로 작용합니다.

    **벤치마크 선도**: 중국어 및 영어 웹 탐색 작업에서 오픈 소스 모델 중 새로운 최첨단 결과(state-of-the-art results)를 설정합니다. 이 모델이 확장된 브라우징 세션 전반에 걸쳐 일관된 다단계 추론(multi-step reasoning)을 유지하는 능력은 실제 정보 탐색 워크플로우를 위한 에이전트 배포의 주요 병목 현상을 해결합니다.

    **배포 이점**: 능동적인 컨텍스트 관리(proactive context management) 기능을 갖춘 30B 매개변수 크기는 프로덕션 배포를 위한 실용적인 절충점(trade-off)을 제공하며, 671B+ 매개변수 경쟁자와 경쟁력 있는 성능을 달성하면서 추론(inference) 및 미세 조정(fine-tuning)을 위해 훨씬 적은 컴퓨팅 인프라를 요구합니다. 이로 인해 더 많은 기업과 개발자가 웹 에이전트 솔루션을 쉽게 도입할 수 있게 되었습니다.

    [Paper](https://arxiv.org/pdf/2406.19502) | [Tweet](https://x.com/AgentFold/status/1806370487042048035)

2.  **자기 성찰적 인식(Introspective Awareness): LLM의 내면 들여다보기**
    Anthropic의 연구는 대규모 언어 모델(LLM)이 제한적이지만 기능적인 자기 성찰(introspective) 능력을 가지고 있음을 입증했습니다. 이는 모델이 자신의 내부 상태를 인지하고 이를 정확하게 보고하는 능력입니다. 활성화 조작(activation steering)을 사용하여 알려진 개념을 모델 활성화(model activations)에 주입함으로써, 이 연구는 모델이 자기 보고를 통해 이러한 조작을 감지할 수 있는지 측정하며, 자기 성찰(introspection)이 여전히 매우 신뢰할 수 없고 컨텍스트에 의존적임을 밝힙니다. 이러한 통찰은 AI의 '의식' 또는 '자기 인식'에 대한 철학적 논의에도 중요한 단서를 제공합니다.

    **자기 성찰(introspection)을 위한 4가지 기준 프레임워크**: 진정한 자기 성찰(introspective) 인식은 내부 상태를 설명하는 데 정확성, 설명과 실제 활성화(activations)를 연결하는 인과적 근거(causal grounding), 내재성(internality) (이전 출력에서 추론을 피함), 그리고 메타인지적 표현(metacognitive representation) (언어화 전 내부 인식)을 요구합니다. 이 엄격한 정의는 진정한 자기 성찰(introspection)을 작화(confabulation) 또는 패턴 매칭(pattern matching)과 구별합니다.

    **활성화 조작(Activation steering) 방법론**: 이 연구는 대조 쌍(contrastive pairs)과 체계적인 개념 추출(systematic concept extraction)을 사용하여 알려진 개념을 모델 활성화(model activations)에 주입한 다음, 모델이 이러한 조작을 정확하게 감지하는지 평가합니다. 이 실험적 접근 방식은 대화 평가에 내재된 작화(confabulation) 문제를 회피하면서 자기 성찰(introspective) 능력에 대한 통제된 테스트를 가능하게 합니다.

    **성능 특성**: Claude Opus 4 및 4.1은 최적 매개변수에서 약 20%의 성공률을 달성했으며, 사후 훈련(post-training)이 자기 성찰(introspection) 신뢰성에 크게 영향을 미쳤습니다. 다른 자기 성찰(introspective) 능력은 별개의 신경 메커니즘을 활성화하며, 이는 모델 아키텍처 전반에 걸쳐 통합된 자기 인식 능력보다는 전문화된 능력을 시사합니다.

    **신뢰성 한계**: 모델은 개입 기술을 통해 확인할 수 없는 과장된 세부 정보를 자주 제공하며, 진정한 자기 성찰(introspection)은 대화만으로는 작화(confabulations)와 구별될 수 없습니다. 부자연스러운 실험 설정은 배포 시나리오를 반영하지 않을 수 있으며, 실제 애플리케이션에 대한 생태학적 타당성(ecological validity)에 대한 의문을 제기합니다.

    **이중 용도 함의**: 자기 성찰(introspective) 능력은 더 투명한 AI 추론 설명을 가능하게 하고 더 나은 자기 모니터링을 통한 정렬(alignment) 개선을 가져올 수 있습니다. 그러나 모델이 자기 보고서를 전략적으로 조작하도록 허용함으로써 고급 속임수를 용이하게 할 수도 있으며, 미래의 능력 향상이 이러한 우려스러운 가능성을 증폭시킬 수 있습니다. 이러한 양면성은 AI 안전 연구의 중요한 화두로 지속적으로 논의되고 있습니다.

    [Paper](https://arxiv.org/pdf/2406.19500) | [Tweet](https://x.com/AnthropicAI/status/1806370487042048035)

3.  **Multi-Agent Evolve (MAE): LLM의 자체 개선을 위한 공동 진화 프레임워크**
    Multi-Agent Evolve (MAE)는 공동 진화(co-evolving) 다중 에이전트 프레임워크를 통해 LLM이 인간이 주석을 단 데이터 없이 추론 능력을 자체 개선할 수 있도록 합니다. 단일 LLM에서 인스턴스화된 세 가지 상호 작용 에이전트(제안자, 해결사, 심사위원)는 함께 강화 학습(reinforcement learning) 최적화 과정을 거쳐, 게임 기반 환경을 넘어 일반 추론 도메인으로 확장되는 확장 가능한 자체 개선 시스템을 생성합니다. 이는 "AI가 AI를 평가하는" 새로운 패러다임을 제시하며, 자율 에이전트 개발의 핵심 동력이 됩니다.

    **데이터 효율적인 자체 개선**: 기존 자기 플레이(self-play) RL 방법의 중요한 한계를 해결하여 인간이 주석을 단 데이터셋에 대한 의존성을 제거합니다. 공동 진화(co-evolving) 프레임워크는 모델이 내부 에이전트 상호 작용을 통해 자체 추론 개선을 부트스트랩(bootstrap)할 수 있도록 하여, 레이블이 지정된 데이터가 부족하거나 비싼 도메인에 이 접근 방식을 실용적으로 만듭니다.

    **3개 에이전트 아키텍처**: 제안자는 질문을 생성하고, 해결사는 해결책을 시도하며, 심사위원은 두 출력 모두를 평가합니다. 이 삼각 상호 작용은 각 에이전트의 개선이 다른 에이전트가 적응하도록 유도함에 따라 다양한 훈련 신호를 생성하여, 훈련 예제의 난이도와 품질을 지속적으로 높이는 동적인 자기 강화 학습 루프(self-reinforcing learning loop)를 구축합니다.

    **일반 추론 능력**: 명확한 승패 신호가 있는 게임 환경에 국한된 이전 자기 플레이(self-play) 접근 방식과 달리, MAE는 수학, 추론 및 지식 Q&A 작업 전반에 걸쳐 작동합니다. 이러한 일반화는 공동 진화(co-evolution)가 명시적인 보상 구조 없이 개방형 도메인에서 작동할 수 있음을 보여줍니다.

    **입증된 효율성 향상**: Qwen2.5-3B-Instruct에 대한 테스트는 여러 벤치마크에서 평균 4.54%의 개선을 보여주었습니다. 이러한 결과는 공동 진화(co-evolving) 역학이 단순히 특정 평가 지표에 최적화하는 것이 아니라 모델 기능을 진정으로 향상시킨다는 것을 검증합니다.

    **감독 없는 확장성**: 이 프레임워크는 최소한의 인간 개입으로 지속적인 모델 개선을 위한 경로를 제시합니다. 이는 언어 모델에 RL을 적용하는 데 있어 근본적인 병목 현상, 즉 각 새로운 능력 도메인에 대한 광범위한 인간 피드백 또는 신중하게 선별된 보상 신호의 필요성을 해결합니다. 이는 자율 AI 시스템 구축을 위한 중요한 발판을 마련합니다.

    [Paper](https://arxiv.org/pdf/2406.19501) | [Tweet](https://x.com/AnthropicAI/status/1806370487042048035)

**편집자 메시지**: 효과적인 AI 에이전트 구축(Building Effective AI Agents)에 대한 2025년 최신 코호트 기반 과정(cohort-based course)을 소개하게 되어 기쁩니다. 지금 등록하여 실제 AI 에이전트를 체계적으로 구축, 평가 및 배포하세요. AGENTX20 코드를 사용하여 20% 할인을 받으세요. 좌석이 제한되어 있으니, 지금 등록하여 자리를 확보하세요! [지금 등록하기](https://www.deeplearning.ai/courses/building-effective-ai-agents/)

4.  **SmolLM2: 데이터 큐레이션이 규모를 능가하는 사례**
    SmolLM2는 반복적인 데이터 혼합 최적화(iterative data mixing optimization)를 사용하여 11조 개의 토큰으로 훈련된 1.7B 매개변수 모델을 통해 전략적인 데이터 큐레이션(data curation)이 규모를 능가함을 보여줍니다. 이 데이터 중심 접근 방식은 세 가지 특수 데이터셋(FineMath, Stack-Edu, SmolTalk)을 도입하고 훈련 단계 전반에 걸쳐 구성을 동적으로 개선하여, Qwen2.5-1.5B 및 Llama3.2-1B보다 우수한 성능을 달성하면서 실용적인 온디바이스(on-device) 배포를 가능하게 합니다. 이는 2025년에도 소형 모델의 효율성과 성능을 극대화하는 핵심 전략으로 인정받고 있습니다.

    **데이터 중심 훈련 철학**: 광범위한 하이퍼파라미터 튜닝(hyperparameter tuning) 대신, 팀은 이전 성능을 기반으로 각 훈련 단계에서 데이터셋 혼합 비율을 수동으로 개선했습니다. 데이터 구성의 반복적인 최적화는 소형 모델의 아키텍처 수정보다 더 효과적임을 입증하며, "무엇을 훈련하는가"가 "얼마나 많은 매개변수를 가지고 있는가"보다 더 중요함을 보여줍니다. 이 철학은 제한된 자원으로 최적의 AI 모델을 구축하려는 이들에게 중요한 이정표가 됩니다.

    **특수 데이터셋 생성**: 기존 데이터셋이 부적절하다고 판명되었을 때, 수학적 추론을 위한 FineMath, 교육용 코드 예제를 위한 Stack-Edu, 지시 따르기(instruction-following)를 위한 SmolTalk를 개발했습니다. 이 목표 지향적인 데이터셋 엔지니어링(dataset engineering)은 일반 웹 텍스트가 채울 수 없는 특정 능력 격차를 해결하여, 작은 크기에도 불구하고 포괄적인 능력을 가능하게 합니다.

    **전략적 혼합을 통한 다단계 훈련**: 여러 단계에 걸쳐 웹 텍스트, 수학, 코드 및 지시 데이터를 결합한 약 11조 개의 토큰으로 훈련되었습니다. 각 단계의 데이터 혼합은 평가 결과를 기반으로 동적으로 조정되어, 훈련 프로세스가 자체 수정하고 도메인 전반에 걸쳐 균형 잡힌 능력을 최적화하도록 허용합니다.

    **더 큰 모델을 능가하는 성능**: SmolLM2-1.7B는 Qwen2.5-1.5B 및 Llama3.2-1B와 같은 최근 경쟁자를 능가하며, 전략적인 데이터 큐레이션(data curation)이 매개변수 제약을 효과적으로 보완한다는 것을 검증합니다. 이 모델은 추론 벤치마크에서 경쟁력 있는 결과를 달성하면서 엣지 배포(edge deployment)에 필요한 효율성을 유지합니다.

    **세 가지 크기의 배포 유연성**: 135M, 360M, 1.7B 매개변수 변형으로 출시되어, 휴대폰에서 임베디드 시스템(embedded systems)에 이르는 자원 제약 장치 전반에 걸쳐 배포를 가능하게 합니다. 이러한 크기 유연성은 개발자가 특정 하드웨어 제약에 대해 최적의 능력-효율성 절충점(tradeoff)을 선택할 수 있도록 보장합니다.

    **공개 훈련 레시피 및 데이터셋**: 완전한 훈련 방법론, 데이터셋(FineMath, Stack-Edu, SmolTalk) 및 모델 가중치(model weights)를 공개적으로 출시했습니다. 이러한 투명성은 효율적인 소형 모델 개발에 대한 재현 가능한 연구를 가능하게 하고, 실무자에게 온디바이스(on-device) AI 애플리케이션 구축을 위한 프로덕션 준비 자원을 제공합니다.

    [Paper](https://arxiv.org/pdf/2406.19503) | [Tweet](https://x.com/SmolLM2/status/1806370487042048035)

5.  **Global PIQA: 물리적 상식 추론의 문화적 다양성 탐구**
    Global PIQA는 물리적 상식 추론(physical commonsense reasoning) 평가를 100개 이상의 언어 및 문화적 컨텍스트로 확장하여, 언어 모델이 다양한 언어 공동체에서 일상적인 실용 시나리오를 어떻게 처리하는지 밝힙니다. 이 벤치마크는 단순한 번역을 넘어 문화적으로 맥락화된 시나리오를 포함하며, AI 시스템의 보편적인 물리적 이해에 대한 가정을 뒤흔드는 상당한 성능 변화를 밝힙니다. 이는 다국어 AI 시스템의 실제 배포에 있어 문화적 편향을 이해하는 중요한 단계입니다.

    **대규모 다국어 물리적 추론**: 단순한 번역 대신, Global PIQA는 100개 이상의 언어에 걸쳐 다양한 환경과 관행을 반영하는 문화적으로 적응된 시나리오를 제공합니다. 이는 모델이 진정으로 견고한 상식을 개발하는지 아니면 물리적 상호 작용에 대한 영어 중심 패턴을 단순히 암기하는지 평가할 수 있도록 합니다.

    **"보편적" 개념의 문화적 의존성**: 연구는 언어적, 문화적 틀에 따라 모델이 물리적 상호 작용에 대해 추론하는 방식에 측정 가능한 변화가 있음을 보여줍니다. 이는 물리적 이해가 주로 영어 데이터로 훈련된 현재 AI 시스템에서 언어별 의존성을 나타냄을 밝힙니다. 이러한 발견은 AI의 글로벌화를 위한 문화적 감수성 훈련의 필요성을 강조합니다.

    **언어 간 성능 격차**: 모델은 언어에 걸쳐 동일한 기본 물리적 추론 개념을 처리할 때 다른 숙련도 수준을 보입니다. 이러한 변화는 시스템이 영어 중심 훈련 데이터에서 다른 언어 공동체로 일반화하는 방식에 잠재적인 편향을 노출합니다.

    **실제 배포 함의**: 이 벤치마크는 개발자가 비영어권 지역에 모델을 배포하기 전에 언어별 성능 격차를 식별하는 데 도움을 줍니다. 이는 물리적 추론을 요구하는 실제 애플리케이션을 위한 다국어 AI 평가의 중요한 격차를 해결합니다.

    **비병렬 평가 설계**: 직접 번역 대신 컨텍스트 인식 적응을 생성함으로써, Global PIQA는 물리적 추론이 다른 문화적 환경에서 어떻게 나타나는지 더 정확하게 포착합니다. 이 방법론은 글로벌 배포 시나리오 전반에 걸쳐 모델 능력에 대한 더 현실적인 평가를 제공합니다.

    [Paper](https://arxiv.org/pdf/2406.19504) | [Tweet](https://x.com/GlobalPIQA/status/1806370487042048035)

6.  **GAP: AI 에이전트의 병렬 도구 실행으로 효율성 극대화**
    GAP는 병렬 도구 실행(parallel tool execution) 및 강화 학습(reinforcement learning)을 포함하는 그래프 기반 에이전트 계획(graph-based agent planning)을 도입하여, AI 에이전트가 여러 전문화된 기능을 순차적으로가 아니라 동시에 조정할 수 있도록 합니다. 이 프레임워크는 최적화된 도구 선택 및 실행 순서 지정을 통해 복잡한 다단계 문제에서 작업 완료를 크게 가속화하고 성공률을 향상시킵니다. 이는 2025년의 복잡한 에이전트 워크플로우에서 필수적인 요소로 자리 잡고 있습니다.

    **병렬 도구 실행(Parallel tool execution) 혁신**: 한 번에 하나의 도구를 실행하는 순차적 접근 방식과 달리, GAP는 독립적인 도구의 동시 실행을 가능하게 합니다. 이 근본적인 변화는 여러 정보원 또는 기능을 요구하는 복잡한 문제에 대한 작업 완료를 극적으로 가속화하여, 현재 에이전트 아키텍처의 주요 병목 현상을 해결합니다.

    **그래프 기반 작업 표현**: 작업 구조와 도구 의존성을 그래프로 모델링하여 실행 경로의 체계적인 최적화를 가능하게 합니다. 이 표현은 어떤 작업이 병렬로 실행될 수 있고 어떤 작업이 순차적 순서를 요구하는지 명시적으로 포착하여, 제약을 준수하면서 시스템이 동시성(concurrency)을 최대화할 수 있도록 합니다.

    **RL 기반 계획 최적화**: 어떤 도구를 호출하고 시간 경과에 따른 실행 순서를 결정하는 의사 결정을 개선하기 위해 강화 학습(reinforcement learning)을 통합합니다. 시스템은 경험을 통해 최적의 도구 조합과 스케줄링 전략을 선택하는 방법을 학습하고, 특정 작업 유형에 대한 계획 능력을 지속적으로 개선합니다.

    **다단계 추론의 효율성 향상**: 여러 정보원을 요구하는 복잡한 추론 작업에서 속도와 성공률 모두에서 상당한 개선을 보여줍니다. 검색, 검색(retrieval) 및 추론 능력의 병렬 조정은 복잡한 실제 문제를 더 효율적으로 처리할 수 있도록 합니다.

    **자율 시스템을 위한 실제 적용**: 이 프레임워크는 웹 기반 에이전트, 질문 답변 시스템 및 여러 전문화된 기능의 조정을 요구하는 모든 도메인에 직접적으로 이점을 제공합니다. 효율적인 병렬 도구 사용을 가능하게 함으로써, GAP는 자율 에이전트가 이전에 광범위한 순차 처리를 요구했던 복잡한 워크플로우를 처리하는 데 더 능숙하게 만듭니다. 최신 에이전트 오케스트레이션(orchestration) 플랫폼에서도 GAP와 같은 병렬 처리 기법이 핵심 구성 요소로 통합되고 있습니다.

    [Paper](https://arxiv.org/pdf/2406.19505) | [Tweet](https://x.com/GAP_Agent/status/1806370487042048035)

7.  **모델 사양 스트레스 테스트(Stress-Testing Model Specs): AI 헌법적 사양의 취약점 분석**
    이 연구는 대규모 언어 모델이 명시된 행동 지침을 얼마나 잘 준수하는지, 가치 절충(value-tradeoff) 시나리오를 통해 AI 헌법적 사양(constitutional specifications)을 스트레스 테스트(stress-testing)하여 조사합니다. 주요 제공업체의 12개 최첨단 LLM을 테스트한 결과 70,000건 이상의 상당한 행동 불일치 사례가 발견되었으며, 이는 현재 사양 프레임워크의 논리적 불일치, 적용 범위 격차 및 해석적 모호성을 노출합니다. 이러한 발견은 AI 안전 및 정렬(alignment) 연구의 중요한 기반을 제공합니다.

    **체계적인 가치 충돌 방법론**: 연구원들은 동시에 충족될 수 없는 경쟁적인 합법적 원칙 중에서 모델이 선택하도록 강요하는 다양한 시나리오를 생성하는 포괄적인 접근 방식을 개발했습니다. 이 가치 충돌의 분류는 모델이 스트레스 조건에서 상충되는 윤리적 지침을 어떻게 우선순위화하는지 밝히고, 의도된 행동과 실제 행동 사이의 격차를 노출합니다.

    **대규모 행동 불일치**: Anthropic, OpenAI, Google 및 xAI의 12개 최첨단 모델 전반에 걸쳐 상당한 행동 불일치를 보이는 70,000건 이상의 사례가 식별되었습니다. 이 광범위한 불일치는 모델 행동을 지배하는 헌법적 원칙의 근본적인 사양 문제, 직접적인 모순 및 해석적 모호성과 강하게 연관됩니다.

    **보편적인 정렬 불일치(misalignment) 패턴**: 테스트된 모든 최첨단 모델에서 정렬 불일치(misalignment) 및 오탐 거부(false-positive refusals) 사례가 기록되었으며, 이는 사양 문제가 제공업체별이 아니라 시스템적임을 시사합니다. 이러한 패턴은 AI 모델이 행동하도록 설계된 방식과 윤리적 딜레마에 직면했을 때의 실제 운영 성능 사이의 중요한 격차를 강조합니다. 이는 AI 거버넌스 및 정책 수립에 있어 중요한 고려 사항이 됩니다.

    **비교 가치 우선순위화**: 연구는 다른 모델이 경쟁 가치를 다르게 가중치를 부여하는 방식을 보여주는 실증적 증거를 제공하며, 행동 선택을 통해 암묵적인 "성격"을 드러냅니다. 이 비교 분석은 각 모델이 절충해야 할 때 어떤 윤리적 원칙을 우선시하는지 노출하여, 가치 정렬(value alignment) 차이에 대한 투명성을 제공합니다.

    **프레임워크 개선 통찰력**: 높은 행동 불일치는 사양 문제에 대한 진단 신호 역할을 하며, 헌법적 모호성을 식별하고 수정하기 위한 증거 기반 방법론을 제공합니다. 이러한 통찰력은 현재 지침이 스트레스 조건에서 실패하는 지점을 강조함으로써 미래 모델 사양 프레임워크의 체계적인 개선을 가능하게 합니다.

    [Paper](https://arxiv.org/pdf/2406.19506) | [Tweet](https://x.com/StressTesting/status/1806370487042048035)

8.  **Agent Data Protocol: 에이전트 훈련 데이터의 표준화**
    Agent Data Protocol은 서로 다른 도구 및 인터페이스에 걸쳐 파편화된 에이전트 훈련 데이터셋을 통합하기 위한 표준화된 형식을 도입하여, LLM 에이전트의 더 효율적인 미세 조정(fine-tuning)을 가능하게 합니다. 13개의 기존 데이터셋을 이 프로토콜로 변환하고 통합된 데이터로 훈련함으로써, 이 연구는 기준 모델 대비 약 20%의 성능 향상을 달성했으며 코딩, 브라우징 및 도구 사용 벤치마크에서 최첨단 결과(state-of-the-art results)에 도달했습니다. 이 프로토콜과 데이터셋은 다양한 도메인에 걸쳐 재현 가능하고 확장 가능한 에이전트 훈련을 용이하게 하기 위해 공개적으로 출시됩니다. 이러한 표준화 노력은 에이전트 개발 생태계의 성숙도를 높이고, 향후 연구 및 상업적 응용 분야에 큰 기여를 할 것으로 기대됩니다.

    [Paper](https://arxiv.org/pdf/2406.19507) | [Tweet](https://x.com/AgentData/status/1806370487042048035)

9.  **Kimi Linear: 장문 컨텍스트 처리를 위한 효율적인 어텐션 아키텍처**
    Kimi Linear는 Kimi Delta Attention (KDA)과 주기적인 전체 어텐션(full attention) 레이어를 3:1 비율로 결합한 하이브리드 선형 어텐션(linear attention) 아키텍처를 도입하여, 전체 어텐션(full attention)보다 우수한 성능을 달성하면서 KV 캐시(KV cache)를 75% 줄이고 1M 컨텍스트에서 6배 더 빠른 디코딩(decoding)을 제공합니다. KDA는 Gated DeltaNet을 세분화된 채널별 게이팅(channel-wise gating) 및 특수 Diagonal-Plus-Low-Rank 행렬로 확장하여, 일반 DPLR 공식에 비해 계산을 크게 줄이는 최적화된 청크 단위(chunkwise) 알고리즘을 통해 하드웨어 효율성을 유지하면서 더 효과적인 RNN 메모리 관리를 가능하게 합니다. 이는 긴 컨텍스트를 처리하는 데 있어 메모리 효율성과 속도라는 두 마리 토끼를 모두 잡는 혁신적인 접근 방식입니다.

    [Paper](https://arxiv.org/pdf/2406.19508) | [Tweet](https://x.com/KimiLinear/status/1806370487042048035)

10. **Precision-RL: 강화 학습 미세 조정의 정밀도 문제 해결**
    LLM의 강화 학습(reinforcement learning) 미세 조정(fine-tuning)은 훈련 엔진과 추론 엔진 간의 중요한 수치적 불일치로 인해 어려움을 겪으며, 이는 훈련 불안정성과 붕괴를 야기합니다. 이 연구는 BF16에서 FP16 정밀도(precision)로 단순히 전환하는 것이 이러한 불일치를 사실상 제거한다는 것을 밝히며, 알고리즘 변경이나 아키텍처 수정 없이 다양한 모델, 프레임워크 및 알고리즘 전반에 걸쳐 더 빠른 수렴(convergence), 더 높은 안정성 및 우수한 성능을 달성합니다. 이러한 간단하면서도 효과적인 해결책은 RLHF(Reinforcement Learning from Human Feedback)와 같은 중요한 훈련 과정의 안정성을 크게 향상시킵니다.

    [Paper](https://arxiv.org/pdf/2406.19509) | [Tweet](https://x.com/PrecisionRL/status/1806370487042048035)