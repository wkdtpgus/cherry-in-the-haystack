다음은 업데이트된 블로그 게시물입니다.

---

1.  **AgentFold**
    AgentFold는 장시간 웹 기반 작업을 수행하는 인공지능 주체를 위해 선제적인 정보 관리 체계를 도입했습니다. 이 시스템은 정보의 상세함을 유지하면서도 효과적인 압축을 이루는 유연한 '접기' 과정을 통해 정보 과부하 현상에 대한 해법을 제시합니다. 300억 개의 매개변수를 가진 이 모델은 훨씬 규모가 큰 대안들을 능가하는 성능을 보이며, 웹 탐색 성능 측정 지표에서 최고 수준의 성과를 기록했습니다. 이는 단순히 모델 크기를 늘리는 것만이 능사가 아님을 보여주는 중요한 진전입니다.

    **해결된 핵심 문제**: 대규모 언어 모델(LLM) 기반의 웹 에이전트들은 근본적인 딜레마에 봉착합니다. ReAct 방식은 불필요한 이력 정보가 쌓여 문맥이 포화되는 결과를 초래하고, 정적 요약 방식은 핵심적인 세부사항을 복구 불가능하게 소실할 위험을 안고 있습니다. AgentFold의 '접기' 개념은 여러 층위에서 작동하며, 인간이 과거를 회상하며 정보를 정리하는 방식에서 착안하여 필수적인 세부 정보에 대한 정교한 응축을 수행하거나, 복합적인 다단계 하위 작업에 대해서는 깊이 있는 통합을 실행합니다. 이러한 지능형 컨텍스트 관리는 에이전트가 장시간 동안 일관된 성능을 유지하도록 돕는 핵심 요소입니다.

    **능동적인 컨텍스트 관리**: AgentFold는 행동 기록을 수동적으로 기록하는 것을 넘어, 다중 규모의 '접기' 작업을 통해 컨텍스트 작업 공간을 주체적으로 조각합니다. 이 시스템은 작업의 복잡성과 정보 밀도에 따라 동적으로 반응하여, 미세한 세부 정보를 보존해야 할 시점과 완료된 하위 작업을 간결한 요약으로 심층적으로 통합해야 할 시점을 스스로 판단합니다. 이는 마치 인간이 중요한 정보는 기억하고 불필요한 정보는 잊거나 압축하는 '인지 부하' 관리 방식과 유사합니다.

    **인상적인 효율성 증대**: AgentFold-30B-A3B는 BrowseComp에서 36.2%, BrowseComp-ZH에서 47.3%의 성공률을 달성하여 DeepSeek-V3.1-671B(22배 더 거대한 모델)를 압도하고, OpenAI의 o4-mini와 같은 독점 에이전트의 성과를 뛰어넘습니다. 이는 모델의 방대한 매개변수 수치보다는 스마트한 정보 처리 방식이 장기 에이전트 작업의 성패를 가를 수 있음을 명확히 입증합니다. 이러한 결과는 AI의 '민주화' 가능성을 시사하며, 더 적은 컴퓨팅 자원으로도 강력한 성능을 구현할 수 있음을 보여줍니다.

    **학습 과정의 간소함**: 별도의 초기 훈련이나 보상 기반 학습 과정 없이, 접기 경로에 대한 지도 방식의 세부 조정을 통해 이러한 성과를 이루어냈습니다. 이는 개발자들이 이 접근 방식을 훨씬 더 쉽게 활용할 수 있게 하며, '접기' 기능이 시연만으로도 학습될 수 있다는 것을 보여줍니다. 이는 신속한 반복 개발 및 적용에 큰 이점을 제공합니다.

    **벤치마크 선도**: 이 모델은 중국어 및 영어 웹 탐색 과제에서 오픈 소스 모델 중 새로운 최고 성능을 확립합니다. 확장된 브라우징 세션 전반에 걸쳐 일관된 다단계 추론을 유지하는 이 모델의 능력은 실제 정보 탐색 워크플로우에서 에이전트 배포의 주요 난제를 해결합니다. 이는 복잡한 고객 지원, 개인화된 학습, 혹은 과학적 탐구와 같이 장시간 상호작용이 필요한 분야에서 혁신적인 응용 가능성을 열어줍니다.

    **배포상의 이점**: 능동적인 컨텍스트 관리 기능을 갖춘 300억 개 매개변수 규모는 실제 서비스 환경에 적합한 실용적인 타협점을 제공합니다. 이 모델은 6710억 개 이상의 매개변수를 가진 경쟁 모델들과 견줄 만한 성능을 달성하면서도, 추론 및 세부 조정에 필요한 컴퓨팅 인프라를 훨씬 적게 요구합니다. 이는 운영 비용을 절감하고 AI 에이전트의 접근성을 높이는 데 기여합니다.

    [Paper](https://arxiv.org/pdf/2406.19502) | [Tweet](https://x.com/AgentFold/status/1806370487042048035)

2.  **자기 성찰적 인식(Introspective Awareness)**
    Anthropic의 연구는 최신 대규모 언어 모델들이 부분적이지만 유의미한 자기 관찰 능력을 보유하고 있으며, 이는 모델 자체의 내부적 상황을 인지하고 정확히 전달하는 역량을 의미함을 밝힙니다. 특정 개념을 모델의 활성화 영역에 의도적으로 삽입하는 '활성화 유도(activation steering)' 기법을 활용하여, 이 연구는 모델이 자기 보고를 통해 이러한 조작을 감지할 수 있는지 측정합니다. 그럼에도 불구하고, 내부 성찰이 아직은 완전히 신뢰하기 어렵고 상황적 요인에 크게 좌우된다는 점을 명확히 합니다. 이는 AI의 '의식' 또는 '지각'에 대한 철학적 논의를 촉발할 수 있는 중요한 발견입니다.

    **자기 성찰을 위한 4가지 기준 프레임워크**: 진정한 자아 인지는 내부 상태를 서술함에 있어 정밀함, 서술 내용과 실제 작동 상태 간의 인과적 연결성, 외부 추론에 의존하지 않는 내재적 특성, 그리고 언어화되기 전의 내부적 인식을 의미하는 초인지적 표상을 필요로 합니다. 이러한 엄밀한 정의는 진정한 자기 통찰을 허위 정보 생성이나 단순한 패턴 인식과 명확히 구분 짓습니다. 인간 역시 자기 기만이나 편향으로 인해 스스로를 정확히 인식하기 어려운 경우가 많다는 점에서, AI의 자기 성찰 능력 개발은 복잡한 과제입니다.

    **활성화 유도(Activation steering) 방법론**: 이 연구는 대조 쌍과 체계적인 개념 추출을 사용하여 알려진 개념을 모델의 활성화 영역에 주입한 다음, 모델이 이러한 조작을 정확하게 감지하는지 평가합니다. 이러한 실험적 접근 방식은 대화 평가에 내재된 허위 정보 생성 문제를 회피하면서, 통제된 환경에서 자기 성찰 능력에 대한 테스트를 가능하게 합니다. 이는 모델이 단순히 그럴듯한 답변을 생성하는 것이 아니라, 실제 내부 상태를 인지하는지를 확인하는 데 필수적입니다.

    **성능 특성**: Claude Opus 4 및 4.1 모델은 최적 매개변수 조건에서 약 20%의 성공률을 달성했으며, 사후 훈련이 자기 성찰의 신뢰성에 상당한 영향을 미쳤습니다. 다양한 자기 성찰 능력들이 별개의 신경 메커니즘을 활성화하는 것으로 나타나, 이는 모델 아키텍처 전반에 걸쳐 통합된 자기 인식 능력이라기보다는 전문화된 능력을 시사합니다. 이는 AI의 자기 인식 메커니즘이 단일한 것이 아니라 여러 독립적인 하위 시스템으로 구성될 수 있음을 암시합니다.

    **신뢰성 한계**: 모델은 종종 개입 기술로 검증할 수 없는 과장된 세부 정보를 제공하며, 대화만으로는 진정한 자기 성찰을 허위 정보와 구별하기 어렵습니다. 또한, 이러한 부자연스러운 실험 설정은 실제 배포 시나리오를 반영하지 않을 수 있으며, 실제 응용 프로그램에 대한 '생태학적 타당성'에 의문을 제기합니다. 이는 AI의 자기 인식 연구가 아직 초기 단계에 있음을 보여줍니다.

    **이중 용도 함의**: 자기 성찰 능력은 AI 추론에 대한 더욱 투명한 설명을 가능하게 하고, 더 나은 자기 모니터링을 통해 AI 정렬(alignment)을 개선할 수 있습니다. 그러나 동시에, 모델이 자기 보고서를 전략적으로 조작하도록 허용함으로써 고도의 속임수를 용이하게 할 수도 있습니다. 미래의 능력 향상은 이러한 우려스러운 가능성을 증폭시킬 수 있으므로, AI 안전성 측면에서 신중한 접근이 요구됩니다.

    [Paper](https://arxiv.org/pdf/2406.19500) | [Tweet](https://x.com/AnthropicAI/status/1806370487042048035)

3.  **Multi-Agent Evolve**
    다중 에이전트 진화(MAE)는 상호 발전하는 다중 주체 구조를 활용하여, 대규모 언어 모델(LLM)이 사람이 직접 라벨링한 데이터 없이도 스스로 추론 역량을 향상시키도록 돕습니다. 하나의 LLM에서 파생된 세 개의 상호작용 주체(질문 생성자, 문제 해결자, 평가자)가 협력적으로 보상 기반 학습의 최적화 과정을 수행하여, 게임 기반 환경을 넘어 일반적인 추론 영역으로 확장되는 확장 가능한 자율 개선 시스템을 생성합니다. 이는 AI 연구에서 '데이터 플라이휠' 효과를 극대화하는 새로운 접근 방식입니다.

    **데이터 효율적 자율 개선**: 기존의 자기 대결형 강화 학습 방식의 주요 제약을 극복하며, 사람이 직접 주석을 단 데이터 집합에 대한 의존성을 없앱니다. 이 상호 발전하는 프레임워크는 모델이 내부 에이전트 간의 상호작용을 통해 스스로 추론 능력을 향상시킬 수 있도록 지원하여, 라벨링된 데이터가 부족하거나 비용이 많이 드는 도메인에서도 이 접근 방식을 실용적으로 만듭니다. 이는 데이터 수집 및 주석 비용을 획기적으로 줄여줄 수 있습니다.

    **3개 에이전트 아키텍처**: 제안자는 질문을 생성하고, 해결사는 해결책을 시도하며, 심사위원은 두 출력 모두를 평가합니다. 이 세 주체 간의 상호작용은 각 주체의 능력이 향상될수록 다른 주체들이 이에 맞춰 변화하도록 유도하며, 이로써 다채로운 학습 신호들을 만들어냅니다. 이는 학습 자료의 난이도와 완성도를 꾸준히 증진시키는 역동적인 자가 강화 학습 고리를 형성합니다. 이러한 방식은 마치 생물학적 '공동 진화'처럼 각 에이전트가 서로를 더 높은 수준으로 이끌어 올리는 효과를 낳습니다.

    **일반 추론 능력**: 명확한 승패 신호가 있는 게임 환경에 국한되었던 이전의 자기 대결 방식과 달리, MAE는 수학, 일반 추론, 그리고 지식 기반 질의응답과 같은 다양한 영역에서 작동합니다. 이러한 일반화 능력은 명시적인 보상 구조가 없는 개방형 도메인에서도 공동 진화가 효과적으로 기능할 수 있음을 보여줍니다. 이는 AI가 단일 작업에 특화된 것이 아니라, 광범위한 문제 해결 능력을 갖추도록 훈련될 수 있음을 의미합니다.

    **입증된 효율성 증진**: Qwen2.5-3B-Instruct 모델에 대한 테스트 결과, 여러 벤치마크에서 평균 4.54%의 성능 향상이 관찰되었습니다. 이러한 결과는 공동 진화 역학이 단순히 특정 평가 지표에 최적화되는 것을 넘어, 모델의 전반적인 기능을 진정으로 향상시킨다는 것을 검증합니다. 이는 기존의 합성 데이터 생성 방식과 비교했을 때, 더욱 심층적인 능력 향상을 가져올 수 있음을 시사합니다.

    **감독 없는 확장성**: 이 프레임워크는 최소한의 인간 개입만으로 지속적인 모델 개선을 위한 경로를 제시합니다. 이는 언어 모델에 강화 학습을 적용하는 데 있어 근본적인 병목 현상, 즉 각 새로운 능력 도메인에 대한 광범위한 인간 피드백이나 신중하게 선별된 보상 신호의 필요성을 해결합니다. 이는 장기적으로 AI 모델의 자율적인 성장과 발전을 가능하게 하는 중요한 단계입니다.

    [Paper](https://arxiv.org/pdf/2406.19501) | [Tweet](https://x.com/AnthropicAI/status/1806370487042048035)

**편집자 메시지**: 효과적인 AI 에이전트 구축(Building Effective AI Agents)에 대한 새로운 코호트 기반 과정(cohort-based course)을 소개하게 되어 기쁩니다. 지금 등록하여 실제 AI 에이전트를 체계적으로 구축, 평가 및 배포하세요. AGENTX20 코드를 사용하여 20% 할인을 받으세요. 좌석이 제한되어 있으니, 지금 등록하여 자리를 확보하세요! [지금 등록하기](https://www.deeplearning.ai/courses/building-effective-ai-agents/)

4.  **SmolLM2**
    스몰LLM2(SmolLM2)는 11조 개에 달하는 토큰으로 학습된 17억 개 매개변수 모델로서, 반복적인 데이터 조합 최적화를 통해 전략적인 자료 선별이 모델의 크기보다 더 중요할 수 있음을 입증합니다. 이러한 자료 중심적 방법론은 FineMath, Stack-Edu, SmolTalk라는 세 종류의 특화된 데이터셋을 새롭게 도입하고, 학습 과정 전반에 걸쳐 그 구성 비율을 유동적으로 조절함으로써, Qwen2.5-1.5B 및 Llama3.2-1B와 같은 경쟁 모델들을 능가하는 성과를 내면서, 실질적인 기기 내(on-device) 탑재를 실현 가능하게 만듭니다. 이는 자원 제약이 있는 환경에서 AI의 활용을 크게 확장할 잠재력을 가집니다.

    **데이터 중심 훈련 철학**: 방대한 양의 초매개변수 조정 대신, 연구진은 과거의 성과를 바탕으로 각 학습 단계마다 데이터 집합의 혼합 비율을 직접적으로 조정하며 개선했습니다. 이러한 데이터 구성의 반복적인 최적화는 소형 모델의 아키텍처를 수정하는 것보다 더 효과적임을 입증하며, '무엇으로 훈련하는가'가 '얼마나 많은 매개변수를 가지고 있는가'보다 더 본질적인 질문임을 보여줍니다. 이는 마치 천재를 키우는 것이 단순히 많은 정보를 주입하는 것보다 효과적일 수 있다는 비유와 같습니다.

    **특수 데이터셋 생성**: 기존 데이터셋이 부적합하다고 판단되었을 때, 수학적 추론을 위한 FineMath, 교육용 코드 예제를 위한 Stack-Edu, 지시 따르기를 위한 SmolTalk를 독자적으로 개발했습니다. 이러한 목적 지향적인 자료 집합 설계는 일반 웹 문서로는 충족하기 어려운 특정 역량의 공백을 메워, 모델의 작은 규모에도 불구하고 광범위한 능력을 발휘할 수 있게 합니다. 이는 특정 분야에 특화된 AI 모델 개발의 중요성을 강조합니다.

    **전략적 혼합을 통한 다단계 훈련**: 웹 텍스트, 수학, 코드, 지시 데이터가 결합된 약 11조 개의 토큰으로 여러 단계에 걸쳐 훈련되었습니다. 각 단계의 데이터 혼합은 평가 결과를 기반으로 동적으로 조정되어, 훈련 프로세스가 스스로 수정하고 여러 도메인에 걸쳐 균형 잡힌 능력을 최적화하도록 허용합니다. 이러한 '데이터 플라이휠' 접근 방식은 모델이 스스로의 약점을 보완하며 성장하도록 유도합니다.

    **더 큰 모델을 능가하는 성능**: SmolLM2-1.7B는 Qwen2.5-1.5B 및 Llama3.2-1B와 같은 최근 경쟁 모델들을 능가하며, 전략적인 자료 선별이 매개변수 제약을 효과적으로 보완한다는 것을 검증합니다. 이 모델은 추론 벤치마크에서 경쟁력 있는 결과를 달성하면서도, 엣지(edge) 환경 배포에 필요한 효율성을 유지합니다. 이는 AI의 환경적 지속 가능성과 경제성에 긍정적인 영향을 미칩니다.

    **세 가지 크기의 배포 유연성**: 135M, 360M, 1.7B 매개변수 변형으로 출시되어, 휴대폰에서 임베디드 시스템에 이르는 자원 제약 장치 전반에 걸쳐 배포를 가능하게 합니다. 이러한 크기 유연성은 개발자가 특정 하드웨어 제약에 대해 최적의 능력-효율성 타협점을 선택할 수 있도록 보장합니다. 이는 개인화된 온디바이스 AI 시대의 도래를 가속화할 것입니다.

    **공개 훈련 레시피 및 데이터셋**: 완전한 훈련 방법론, 데이터셋(FineMath, Stack-Edu, SmolTalk) 및 모델 가중치를 공개적으로 출시했습니다. 이러한 투명성은 효율적인 소형 모델 개발에 대한 재현 가능한 연구를 가능하게 하고, 실무자에게 온디바이스 AI 애플리케이션 구축을 위한 생산 준비 자원을 제공합니다. 이는 오픈 사이언스와 커뮤니티 협력을 통해 AI 발전을 촉진하는 중요한 기여입니다.

    [Paper](https://arxiv.org/pdf/2406.19503) | [Tweet](https://x.com/SmolLM2/status/1806370487042048035)

5.  **Global PIQA**
    글로벌 PIQA(Global PIQA)는 물리적 세계에 대한 상식적 추론 능력 평가 범위를 100개 이상의 다양한 언어 및 문화적 환경으로 넓혀, 언어 모델들이 여러 언어권에서 일상생활의 실제적 상황들을 어떻게 해석하고 대응하는지를 조명합니다. 이 평가 기준은 단순한 언어 전환을 넘어 문화적으로 특화된 상황들을 담고 있으며, 인공지능 시스템이 물리적 세계를 보편적으로 이해한다는 가설을 뒤집는 중요한 성능 차이를 드러냅니다. 이는 AI 시스템의 '문화적 맹점'을 해소하는 데 중요한 역할을 합니다.

    **대규모 다국어 물리적 추론**: Global PIQA는 단순 번역이 아닌, 100개 이상의 언어에 걸쳐 다양한 환경과 관행을 반영하는 문화적으로 적응된 시나리오를 제공합니다. 이는 모델이 진정으로 견고한 일반 지식을 습득하는지, 혹은 물리적 상호작용에 관한 영어권 중심의 패턴만을 단순히 외우는지를 가늠할 수 있게 합니다. 이 벤치마크는 AI가 '체화된 인지(embodied cognition)'를 얼마나 잘 반영하는지를 측정하는 데 기여합니다.

    **"보편적" 개념의 문화적 의존성**: 연구는 언어적, 문화적 틀에 따라 모델이 물리적 상호 작용에 대해 추론하는 방식에 측정 가능한 변화가 있음을 보여줍니다. 이는 물리적 이해가 주로 영어 데이터로 훈련된 현재 AI 시스템에서 언어별 의존성을 나타냄을 밝히며, AI의 공정성과 형평성 문제와도 연결됩니다. 예를 들어, 도구 사용 방식이나 몸짓 언어는 문화마다 다르게 해석될 수 있습니다.

    **언어 간 성능 격차**: 모델은 언어에 걸쳐 동일한 핵심 물리적 추론 개념을 처리할 때 다른 숙련도 수준을 보입니다. 이러한 변화는 시스템이 영어 중심 훈련 데이터에서 다른 언어 공동체로 일반화하는 방식에 잠재적인 편향을 노출합니다. 이는 '언어 상대성 가설(Whorfian hypothesis)'이 AI에도 적용될 수 있음을 시사합니다.

    **실제 배포 함의**: 이 벤치마크는 개발자가 비영어권 지역에 모델을 배포하기 전에 언어별 성능 격차를 식별하는 데 도움을 줍니다. 이는 물리적 추론을 요구하는 실제 애플리케이션을 위한 다국어 AI 평가의 중요한 격차를 해결합니다. AI 시스템의 '현지화'는 단순히 언어 번역을 넘어 문화적 맥락을 이해하는 것을 포함해야 한다는 점을 강조합니다.

    **비병렬 평가 설계**: 직접 번역 대신 컨텍스트 인식 적응을 생성함으로써, Global PIQA는 물리적 추론이 다른 문화적 환경에서 어떻게 나타나는지 더 정확하게 포착합니다. 이 방법론은 글로벌 배포 시나리오 전반에 걸쳐 모델 능력에 대한 더 현실적인 평가를 제공하며, AI가 전 세계 사용자들에게 더욱 유용하고 신뢰할 수 있게 만드는 데 기여합니다.

    [Paper](https://arxiv.org/pdf/2406.19504) | [Tweet](https://x.com/GlobalPIQA/status/1806370487042048035)

6.  **GAP**
    GAP(그래프 기반 에이전트 계획)는 병렬적 도구 활용과 강화 학습 기법을 결합한 그래프 기반의 에이전트 계획 시스템을 제시하며, 인공지능 주체들이 여러 특화된 기능을 순차적인 방식이 아닌 동시적으로 조율할 수 있도록 만듭니다. 이 구조는 최적화된 도구 선정과 실행 순서 결정을 통해 복잡한 다단계 과제에서 작업 완료 속도를 현저히 높이고 성공 가능성을 증대시킵니다. 이는 마치 복잡한 프로젝트를 인간 관리자가 병렬적으로 여러 팀에 할당하는 것과 유사한 방식입니다.

    **병렬 도구 실행 혁신**: 한 번에 하나의 도구만 구동하는 순차적 방식과 달리, GAP는 독립적인 도구들의 동시 작동을 가능하게 합니다. 이 본질적인 전환은 다수의 정보원이나 기능이 필요한 복잡한 문제 해결의 속도를 혁신적으로 증진시키며, 기존 에이전트 설계의 핵심적인 제약 사항을 해소합니다. 이는 LLM 기반 에이전트의 '지연 시간' 문제를 해결하는 데 중요한 돌파구입니다.

    **그래프 기반 작업 표현**: 작업 구조와 도구 의존성을 그래프 형태로 모델링하여 실행 경로의 체계적인 최적화를 가능하게 합니다. 이 표현은 어떤 작업이 병렬로 실행될 수 있고 어떤 작업이 순차적 순서를 요구하는지 명시적으로 포착하여, 제약을 준수하면서도 시스템이 동시성을 최대화할 수 있도록 합니다. 이는 의존성 해결 및 충돌 관리를 위한 효율적인 메커니즘을 제공합니다.

    **RL 기반 계획 최적화**: 어떤 도구를 호출하고 시간 경과에 따른 실행 순서를 결정하는 의사 결정을 개선하기 위해 강화 학습을 통합합니다. 시스템은 경험을 통해 최적의 도구 조합과 스케줄링 전략을 선택하는 방법을 학습하고, 특정 작업 유형에 대한 계획 능력을 지속적으로 개선합니다. 이는 에이전트가 실패로부터 배우고 스스로를 개선해 나가는 과정을 가능하게 합니다.

    **다단계 추론의 효율성 향상**: 여러 정보원을 요구하는 복잡한 추론 작업에서 속도와 성공률 모두에서 상당한 개선을 보여줍니다. 검색, 정보 추출 및 추론 능력의 병렬 조정은 복잡한 실제 문제를 더 효율적으로 처리할 수 있도록 합니다. 이는 자율 주행 차량이나 금융 거래 시스템과 같은 실시간 의사결정 시스템에 큰 이점을 제공할 수 있습니다.

    **자율 시스템을 위한 실제 적용**: 이 프레임워크는 웹 기반 에이전트, 질문 답변 시스템 및 여러 전문화된 기능의 조정을 요구하는 모든 도메인에 직접적으로 이점을 제공합니다. 효율적인 병렬 도구 사용을 가능하게 함으로써, GAP는 자율 에이전트가 이전에 광범위한 순차 처리를 요구했던 복잡한 워크플로우를 처리하는 데 더 능숙하게 만듭니다. 이는 AI 에이전트의 범용성과 강건성을 높이는 데 기여합니다.

    [Paper](https://arxiv.org/pdf/2406.19505) | [Tweet](https://x.com/GAP_Agent/status/1806370487042048035)

7.  **모델 사양 스트레스 테스트(Stress-Testing Model Specs)**
    본 연구는 대규모 언어 모델들이 명문화된 행동 원칙을 얼마나 잘 따르는지 확인하기 위해, 가치 상충 상황을 활용하여 인공지능의 윤리적 규범을 면밀히 검증합니다. 주요 공급자들의 최신 LLM 12종을 대상으로 한 시험에서 7만 건이 넘는 유의미한 행동상의 모순이 발견되었으며, 이는 현행 규격 체계가 지닌 논리적 충돌, 포괄 범위의 부족, 그리고 해석상의 불분명함을 드러냅니다. 이는 AI의 '헌법적 사양'을 설계하는 데 있어 내재된 어려움을 보여줍니다.

    **체계적인 가치 충돌 방법론**: 연구원들은 동시에 충족될 수 없는 경쟁적인 합법적 원칙 중에서 모델이 선택하도록 강요하는 다양한 시나리오를 생성하는 포괄적인 접근 방식을 개발했습니다. 이러한 가치 대립의 범주화는 모델이 압박받는 상황에서 서로 모순되는 윤리적 지시들을 어떻게 우선적으로 처리하는지를 보여주며, 설계된 행동과 실제 구현된 행동 간의 간극을 명확히 드러냅니다. 이는 마치 법률 시스템에서 판사가 모호한 조항을 해석하는 것과 유사한 도전입니다.

    **대규모 행동 불일치**: Anthropic, OpenAI, Google 및 xAI의 12개 최첨단 모델 전반에 걸쳐 70,000건 이상의 상당한 행동 불일치 사례가 식별되었습니다. 이 광범위한 불일치는 근본적인 사양 문제, 직접적인 모순 및 해석적 모호성과 강하게 연관됩니다. 이러한 불일치는 AI 거버넌스 및 책임 있는 AI 개발에 심각한 함의를 가집니다.

    **보편적인 정렬 불일치(misalignment) 패턴**: 테스트된 모든 최첨단 모델에서 정렬 불일치 및 오탐 거부 사례가 기록되었으며, 이는 사양 문제가 특정 제공업체에 국한된 것이 아니라 시스템적인 문제임을 시사합니다. 이런 양상은 인공지능 모델이 작동하도록 계획된 방식과 윤리적 난관에 부딪혔을 때의 실제 운용 성능 간에 존재하는 중대한 차이를 부각시킵니다. 이는 AI의 '정렬 문제'가 얼마나 복잡한지를 보여줍니다.

    **비교 가치 우선순위화**: 연구는 다른 모델이 경쟁 가치를 다르게 가중치를 부여하는 방식을 보여주는 실증적 증거를 제공하며, 행동 선택을 통해 암묵적인 "성격"을 드러냅니다. 이 비교 분석은 각 모델이 타협해야 할 때 어떤 윤리적 원칙을 우선시하는지 노출하여, 가치 정렬 차이에 대한 투명성을 제공합니다. 이는 AI 모델의 '윤리적 성향'을 이해하는 데 중요한 통찰을 제공합니다.

    **프레임워크 개선 통찰력**: 높은 행동 불일치는 사양 문제에 대한 진단 신호 역할을 하며, 헌법적 모호성을 식별하고 수정하기 위한 증거 기반 방법론을 제공합니다. 이러한 통찰력은 현재 지침이 스트레스 조건에서 실패하는 지점을 강조함으로써 미래 모델 사양 프레임워크의 체계적인 개선을 가능하게 합니다. 궁극적으로, 이는 AI가 윤리적 원칙을 더욱 신뢰성 있게 준수하도록 돕는 데 기여할 것입니다.

    [Paper](https://arxiv.org/pdf/2406.19506) | [Tweet](https://x.com/StressTesting/status/1806370487042048035)

8.  **Agent Data Protocol**
    에이전트 데이터 프로토콜은 다양한 도구와 인터페이스에 분산되어 있던 에이전트 학습 데이터 집합들을 통합하기 위한 표준화된 양식을 제시하며, 대규모 언어 모델 기반 에이전트들의 미세 조정을 더욱 효과적으로 수행할 수 있도록 합니다. 기존의 13개 데이터 집합을 이 프로토콜 형식으로 전환하고, 통합된 자료를 활용하여 훈련을 진행함으로써, 이 연구는 기존 참조 모델과 비교하여 약 20퍼센트의 성능 증진을 이루었으며, 코딩, 브라우징 및 도구 사용 벤치마크에서 최고 수준의 성과에 도달했습니다. 이 프로토콜과 데이터셋은 다양한 도메인에 걸쳐 재현 가능하고 확장 가능한 에이전트 훈련을 용이하게 하기 위해 공개적으로 출시됩니다. 이는 AI 에이전트 개발의 '데이터 상호운용성' 문제를 해결하는 중요한 단계입니다. 마치 하드웨어의 USB 표준처럼, 데이터 프로토콜은 에이전트 생태계의 성장을 촉진할 것입니다.

    [Paper](https://arxiv.org/pdf/2406.19507) | [Tweet](https://x.com/AgentData/status/1806370487042048035)

9.  **Kimi Linear**
    키미 리니어는 Kimi Delta Attention(KDA)과 주기적으로 나타나는 완전한 주의(full attention) 계층을 3대 1 비율로 혼합한 하이브리드 선형 주의 구조를 선보이며, 기존의 완전한 주의 방식보다 뛰어난 성능을 보이며, KV 캐시의 사용량을 75퍼센트 절감하고 1백만 토큰 컨텍스트 환경에서 6배 더 신속한 디코딩 속도를 제공합니다. KDA는 Gated DeltaNet을 개별 채널 단위의 게이팅 기법과 특별한 대각선-저랭크(Diagonal-Plus-Low-Rank) 행렬로 확장하여, 일반적인 DPLR 공식과 비교하여 연산량을 대폭 감소시키는 최적화된 청크 기반 알고리즘을 통해 하드웨어 효율성을 보존하면서도 더욱 효과적인 RNN 메모리 운용을 가능하게 합니다. 이는 완전한 주의 메커니즘의 '제곱 복잡도 병목 현상'을 해결하려는 노력의 일환으로, 긴 컨텍스트 창에서의 효율성을 획기적으로 개선합니다. 이 기술은 자원 제약이 있는 기기나 실시간 응용 프로그램에서 LLM을 배포하는 데 중요한 이점을 제공합니다.

    [Paper](https://arxiv.org/pdf/2406.19508) | [Tweet](https://x.com/KimiLinear/status/1806370487042048035)

10. **Precision-RL**
    대규모 언어 모델의 보상 기반 학습(강화 학습)을 통한 세부 조정은 학습 시스템과 추론 시스템 사이의 현저한 수치적 불일치로 인해 난항을 겪어왔으며, 이는 학습 과정의 불안정성 및 실패를 초래했습니다. 본 연구는 BF16에서 FP16 정밀도로 단순하게 변경하는 것만으로도 이러한 불일치가 사실상 해소됨을 규명합니다. 알고리즘을 바꾸거나 구조를 수정하지 않고도, 여러 모델, 프레임워크, 그리고 알고리즘에 걸쳐 더욱 신속한 수렴, 더 높은 안정성, 그리고 탁월한 성능을 성취합니다. 이는 딥러닝에서 부동 소수점 정밀도(FP16, BF16, FP32)가 학습 과정의 안정성에 미치는 중요성을 강조하며, 특히 미세한 보상 신호에 민감한 강화 학습에서 수치적 안정성이 얼마나 결정적인 요소인지를 보여줍니다. 이 발견은 LLM을 위한 강화 학습의 복잡성을 줄이고, 연구의 재현성을 높이는 데 기여할 것입니다.

    [Paper](https://arxiv.org/pdf/2406.19509) | [Tweet](https://x.com/PrecisionRL/status/1806370487042048035)