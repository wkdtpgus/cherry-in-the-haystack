지난 한 달간 인공지능(AI) 분야의 지형은 급변했으며, 특히 최근 며칠 동안 그 변화의 속도는 전례 없이 빨라졌습니다. 각 AI 연구 기관들은 혁신적인 발상부터 점진적인 개선에 이르기까지 수많은 신기술을 선보였고, 그 결과 현장의 전문가들조차 모든 흐름을 파악하기 어려울 지경에 이르렀습니다. 저는 이러한 움직임 중 일부가 AI의 미래, 나아가 인류의 미래까지도 재정의할 진정한 전환점이 될 것이라고 확신합니다. 현재의 주요 상황을 정리해 보았습니다.

**지능형 AI가 일상에 스며들다**
지난해 말까지만 해도 대중에게 공개된 최상위권 모델은 사실상 GPT-4 하나뿐이었습니다. 그러나 이제는 그에 필적하는 모델이 여섯 개에서 열 개에 달하며, 이 중 일부는 '오픈 웨이트(open weights)' 방식으로 공개되어 누구나 자유롭게 활용하거나 변형할 수 있게 되었습니다. 미국에서는 OpenAI의 GPT-4o, Anthropic의 Claude Sonnet 3.5, Google의 Gemini 1.5, Meta의 개방형 Llama 3.2, Elon Musk의 Grok 2, 그리고 Amazon의 신규 Nova 등이 대표적입니다. 중국 기업들 또한 GPT-4 수준의 성능을 갖춘 세 가지 다국어 공개 모델을 선보였는데, Alibaba의 Qwen, R1의 DeepSeek, 01.ai의 Yi가 주목받고 있습니다. 유럽에서는 프랑스의 Mistral이 이 경쟁에 합류했습니다. 이러한 모델들의 범람은 고성능 인공지능 시스템을 구축하는 것이 더 이상 OpenAI만의 독점적인 비법이 아니라, 뛰어난 컴퓨터 과학 역량과 더불어 모델 훈련에 필요한 컴퓨팅 자원을 확보할 수 있는 기업이라면 어느 곳이든 달성 가능한 목표가 되었음을 의미합니다. 실제로, 출시 당시에는 미래에 대한 상당한 우려를 자아낼 정도로 놀라웠던 GPT-4급의 지능형 시스템이 이제는 제 개인용 컴퓨터에서도 구동될 수 있습니다. 이번 달에 공개된 Meta의 최신 경량 모델인 Llama 3.3은 유사한 성능을 제공하며 제 고성능 개인용 컴퓨터(gaming PC)에서 완전히 독립적으로(offline) 작동합니다. 그리고 Microsoft가 새로 개발한 소형 모델 Phi 4는 GPT-4와 동등한 수준으로 거의 휴대폰에서도 실행 가능하며, 그보다 약간 낮은 성능의 이전 버전 Phi 3.5는 이미 휴대폰에서 원활하게 작동합니다. 이제 어떤 종류의 지능이든 사용자 요구에 따라(on demand) 즉시 제공됩니다. 제 개인 컴퓨터에서 실행되는 Llama 3.3은 "치즈 관련 말장난이 포함된 운율 시"와 같은 복잡한 벤치마크(benchmark)를 몇 가지 어색한 유머를 섞어 가며 성공적으로 수행합니다. 이처럼 보편화된 AI들은 이제 자율적으로 목표를 추구할 수 있는 '에이전트(agent)' 즉, 지능형 작업 주체(autonomous AI)를 구동하기 시작했습니다. 초기 단계의 에이전트들을 활용하여 가격 비교 쇼핑을 하거나 건설 현장을 감시하는 등 다양한 활용 사례가 이미 나타나고 있습니다. 이러한 현상은 AI가 단순히 질의응답을 넘어 실제 세계의 문제를 해결하는 방향으로 진화하고 있음을 보여줍니다.

**고도화된 AI가 현실로 다가오다**
이 모든 상황은 만약 GPT-4 수준의 능력이 AI가 도달할 수 있는 한계였다면, 우리가 그 능력에 적응하는 데 5년에서 10년 정도의 시간을 벌 수 있었을 것이라는 가정을 무색하게 만듭니다. 하지만 AI 개발 속도가 둔화될 조짐은 전혀 보이지 않습니다. 지난 한 달 동안 두 가지 중요한 기술이 발표되면서 이러한 사실이 더욱 명확해졌습니다. 바로 'Gen3 모델(GPT-5급 모델로 이해할 수 있습니다)'의 첫 징후와, 답변을 생성하기 전에 '사고(thought)' 과정을 거치는 o1 모델의 출현입니다. 이러한 사전 사고 능력은 o1 모델을 다른 대규모 언어 모델(LLM)보다 훨씬 뛰어난 추론 능력자(reasoner)로 만듭니다. Gen3 모델은 아직 초기 단계이므로 이 글에서는 o1에 집중하고자 합니다. 저는 o1의 초기 버전인 o1-프리뷰(o1-preview)가 출시되었을 때 이미 이에 대해 논의했지만, 이후 공개된 o1과 o1-프로(o1-pro)라는 두 가지 개선된 변형 모델은 상당한 성능 향상을 이루었습니다. 이 모델들은 질문에 답하기 전, 마치 인간이 논리적인 문제를 해결하는 것처럼 내부적으로 '생각'하는 시간을 보이지 않게 가집니다. '테스트 시간 컴퓨트(test time compute)'라 불리는 이 접근 방식은 모델이 문제 해결 능력을 비약적으로 향상시키는 데 결정적인 역할을 하는 것으로 입증되었습니다. 실제로 이 모델들은 이제 크고 작은 방식으로 연구 분야에 의미 있는 기여를 할 만큼 충분히 영리해졌습니다. 흥미로운 예시로, 최근 소셜 미디어(social media)에서 한바탕 소동이 일었던 기사를 접했습니다. 한 학술 논문에서 검은색 플라스틱 식기가 재활용된 전자 폐기물(e-waste)로 부분적으로 제작되었기 때문에 인체에 유해한 독성 물질을 방출할 수 있다고 주장했습니다. 이 논문은 특정 화합물인 BDE-209가 이 식기에서 매우 높은 비율로 용출되어 미국 환경보호청(EPA)이 정한 안전 기준에 근접할 수 있다고 제안했습니다. 많은 사람들이 즉시 플라스틱 주걱을 버리기 시작했지만, 맥길 대학교(McGill University)의 조 슈워츠(Joe Schwarcz) 교수는 이 주장이 합리적이지 않다고 판단했고, 논문 저자와 동료 심사자들이 간과했던 수학적 오류를 발견했습니다. 논문 7페이지에서 BDE-209의 복용량을 계산하는 과정에서 10배의 오차가 있었던 것입니다. 저는 o1이 이 오류를 찾아낼 수 있을지 궁금했습니다. 그래서 제 휴대폰에서 해당 PDF 텍스트를 복사하여 붙여넣고 "이 논문의 수학을 주의 깊게 확인해 줘(carefully check the math in this paper)"라고 입력했습니다. 그것이 전부였습니다. o1은 즉시 오류를 찾아냈습니다(다른 AI 모델들은 찾아내지 못했습니다). 모델이 단순히 방대한 학술 논문을 처리하는 것을 넘어, "수학 확인"이라는 의미 있는 맥락을 이해하고 실제로 결과를 성공적으로 검증할 수 있을 만큼 유능해졌다는 것은 AI의 역량을 근본적으로 변화시키는 사건입니다. 실제로 저의 이 실험은 다른 연구자들과 함께 o1이 과학 문헌에서 얼마나 자주 오류를 발견할 수 있는지 체계적으로 탐구하려는 노력에 영감을 주었습니다. o1이 이러한 종류의 위업을 얼마나 자주 달성할 수 있는지는 아직 미지수이지만, 이는 새로운 능력의 지평을 제시하므로 그 가능성을 파악하는 것이 중요해 보입니다. 심지어 o1의 초기 버전인 프리뷰(preview) 모델조차도 과학적 역량의 도약을 보여주었습니다. 하버드(Harvard), 스탠포드(Stanford) 및 기타 유수 대학 연구원들의 충격적인 의료 연구 논문은 "o1-프리뷰(o1-preview)가 감별 진단(differential diagnosis), 진단 임상 추론(diagnostic clinical reasoning) 및 관리 추론(management reasoning)에서 초인적인 성능[강조는 필자]을 보이며, 이전 모델 세대와 인간 의사보다 여러 영역에서 우수하다"고 결론지었습니다. 이 논문은 아직 동료 심사(peer review)를 거치지 않았으며, AI가 의사를 완전히 대체할 수 있다고 주장하는 것은 아니지만, 위의 결과는 AI를 보조적인 자문(second opinion)으로 활용하지 않는 것이 곧 실수가 될 수 있는 변화하는 세상을 시사합니다. 잠재적으로 더 중요한 것은, o1, 특히 o1-프로(o1-pro)가 연구자들의 분야에서 새로운 아이디어를 생성하고 예상치 못한 문제들을 해결하고 있다는 보고가 점점 더 많아지고 있다는 점입니다(여기 한 가지 사례가 있습니다). 문제는 이제 전문가만이 AI의 답변이 정확한지 아닌지 평가할 수 있다는 것입니다. 예를 들어, 와튼(Wharton)의 매우 지적인 동료인 다니엘 록(Daniel Rock) 교수는 저에게 o1-프로(o1-pro)에게 다음과 같은 어려운 질문을 해보라고 요청했습니다. "문헌에 없는 증명을 사용하여, 1) 무한히 넓은 층(layer)을 가정하지 않고 2) 두 개 이상의 층(layer)에 대해 신경망(neural network)의 보편적 함수 근사 정리(universal function approximation theorem)를 증명하도록 요청해 보세요." 다음은 o1-프로가 작성한 내용입니다. 이것이 맞을까요? 저는 전혀 알 수 없습니다. 이는 제 전문 분야를 벗어납니다. 다니엘 교수와 이를 본 다른 전문가들도 첫눈에 이것이 맞는지 판단할 수 없었지만, 충분히 흥미로워서 더 깊이 조사할 가치가 있다고 느꼈습니다. 알고 보니 그 증명에는 오류가 있었습니다(비록 o1-프로와의 추가적인 상호작용을 통해 수정될 수도 있지만요). 하지만 그 결과는 여전히 추가적인 사고를 자극하는 몇 가지 새로운 접근 방식을 제시했습니다. 다니엘 교수가 저에게 말했듯이, 연구자들이 o1을 사용할 때 o1은 유용하기 위해 반드시 옳을 필요는 없습니다. "o1에게 창의적인 방식으로 증명을 완성하도록 요청하는 것은 사실상 o1에게 연구 동료가 되어달라고 요청하는 것입니다. 모델이 유용하기 위해 증명을 완벽하게 할 필요는 없으며, 단지 우리가 더 나은 연구자가 되도록 돕기만 하면 됩니다." 우리는 이제 매우 어려운 박사 학위 수준의 문제를 해결하거나, 적어도 그러한 문제를 해결하려는 연구자들을 위한 협력적 지능(co-intelligence)으로서 생산적으로 작업할 수 있는 AI를 갖게 된 것 같습니다. 물론 문제는 자신이 해당 분야의 박사 학위 소지자가 아니라면 이러한 답변이 정확한지 실제로 알 수 없다는 점이며, 이는 AI 평가에 있어 새로운 도전 과제를 만듭니다. 이것이 얼마나 유용하고 어떤 분야에서 유용한지 이해하기 위해서는 추가적인 테스트가 필요하겠지만, AI 능력의 이 새로운 지평은 주목할 가치가 있습니다.

**AI가 당신을 보고 소통할 수 있습니다**
우리는 몇 달 전부터 AI 음성 모델을 사용해 왔지만, 지난주에는 인공지능이 세상을 '보는' 새로운 기능인 시각(vision)이 도입되었습니다. 이제 ChatGPT와 Gemini는 실시간 비디오를 분석하고 음성으로 동시에 상호작용할 수 있습니다. 예를 들어, 저는 이제 Gemini의 새로운 경량 Gen3 모델인 Gemini 2.0 Flash와 제 실시간 화면을 공유할 수 있습니다. 이 기능이 어떤 느낌인지 보려면, 이 게시물의 초안에 대해 피드백(feedback)을 제공하는 과정을 시청해 보세요. 아니면 더 좋게는, 직접 무료로 시도해 보세요. 진지하게, 이 시스템이 무엇을 할 수 있는지 직접 경험해 볼 가치가 있습니다. Gemini 2.0 Flash는 여전히 제한된 메모리(memory)를 가진 작은 모델이지만, 여기서 핵심적인 개념을 이해하기 시작할 것입니다. 인간의 가장 일반적인 감각인 시각과 음성을 통해 인간과 실시간으로 상호작용할 수 있는 모델은 AI를 단순히 컴퓨터 채팅 상자에 갇힌 존재가 아니라, 당신과 같은 공간에 존재하는 현재의 동반자로 만듭니다. ChatGPT의 고급 음성 모드(Advanced Voice Mode)가 휴대폰에서 동일한 작업을 수행할 수 있다는 사실은 이 기능이 수백만 명의 사용자에게 광범위하게 제공된다는 것을 의미합니다. AI가 우리의 일상생활에 더욱 밀접하게 통합됨에 따라 그 영향은 상당히 심오할 것입니다. 이러한 멀티모달(multimodal) 능력은 교육, 접근성, 고객 서비스 등 다양한 분야에서 혁신적인 변화를 가져올 잠재력을 지니고 있으며, 인간과 기계의 상호작용 방식을 근본적으로 재정의할 것입니다.

**AI 비디오가 경이로운 수준에 도달하다**
지난 한 해 동안 인공지능 이미지 생성 기술은 제 노트북에서 실행되는 모델들이 실제 사진과 구별하기 어려운 이미지를 만들어내면서 정말 인상 깊은 발전을 이루었습니다. 또한 "블루투스(bluetooth) 이어폰을 사용하는 비행기 위의 수달"과 "와이파이(wifi)를 사용하는 비행기 위의 수달"과 같은 프롬프트(prompt)에 더욱 정확하게 반응하며 지시하기가 훨씬 쉬워졌습니다. 직접 실험해보고 싶다면, 지난주에 출시된 강력한 Imagen 3 모델을 사용하는 Google의 ImageFX는 정말 사용자 친화적인 인터페이스(interface)를 제공합니다. 하지만 지난주에 진정한 도약은 AI 기반 텍스트-투-비디오(text-to-video) 생성기 분야에서 나타났습니다. 이전에는 중국 기업의 AI 모델들이 Kling과 같은 인상적인 시스템과 일부 오픈 모델을 포함하여 비디오 생성 분야에서 일반적으로 최첨단(state-of-the-art) 기술을 대표했습니다. 하지만 상황은 급속도로 변화하고 있습니다. 먼저 OpenAI가 강력한 Sora 도구를 선보였고, 이어서 최근의 추세처럼 Google이 훨씬 더 강력한 Veo 2 비디오 생성기를 출시했습니다. ChatGPT Plus를 구독하면 지금 Sora를 사용할 수 있으며, 그럴 만한 가치가 있습니다. 하지만 저는 Veo 2(한두 달 안에 출시될 예정인 듯합니다)에 조기 접근(early access)할 기회를 얻었고, 그것은… 그야말로 경이로웠습니다. 말보다는 직접 보여주는 것이 항상 효과적입니다. 그러니 이 8초짜리 클립 모음(현재로서는 길이가 제한적이지만, 훨씬 더 긴 영화도 만들 수 있는 것으로 보입니다)을 살펴보세요. 저는 각 클립에 정확한 프롬프트(prompt)를 부여했으며, 이 클립들은 Veo 2가 생성한 첫 번째 영화 세트에서만 선택된 것입니다(한 번에 네 개의 클립을 만듭니다). 따라서 많은 예시 중에서 가장 좋은 것만 고른 것이 아닙니다. 사물의 명백한 무게감과 부피감, 그림자와 반사, 헤어스타일과 세부 사항이 유지되면서 장면 간의 일관성, 그리고 장면이 제가 요청한 내용과 얼마나 가까운지(자세히 찾아보면 빨간 풍선이 있습니다)에 주목하세요. 물론 오류가 여전히 존재하지만, 이제는 첫눈에 발견하기 훨씬 더 어렵습니다(비디오 모델에게 매우 어려운 체조 장면에서는 여전히 어려움을 겪지만요). 정말 인상 깊습니다. 이 기술은 영화 제작, 광고, 교육 콘텐츠 등 시각 매체 전반에 걸쳐 혁명적인 변화를 가져올 잠재력을 가지고 있습니다. 동시에, 사실과 허구의 경계를 모호하게 만들 수 있는 딥페이크(deepfake)와 같은 윤리적 문제에 대한 논의도 더욱 중요해질 것입니다.

**이 모든 것이 시사하는 바는 무엇일까요?**
더 자세한 성찰은 다음 게시물에서 다루겠지만, 여기서 얻을 수 있는 핵심적인 교훈은 좋든 나쁘든 인공지능 발전의 종착점은 아직 멀었다는 것입니다. 단순히 개별적인 기술적 돌파구(AI가 복잡한 수학 논문을 검토하고, 거의 영화 품질의 비디오 클립을 생성하거나, 개인용 컴퓨터에서 실행되는 것)만이 놀라운 것이 아닙니다. 진정으로 경이로운 것은 이러한 변화의 속도와 그 폭입니다. 불과 1년 전만 해도 GPT-4는 미래 기술의 한 단면을 엿보는 것 같았습니다. 이제 그 수준의 기술은 기본적으로 휴대폰에서 실행되며, 새로운 모델들은 학술 동료 심사를 통과한 논문의 오류까지 찾아내고 있습니다. 이것은 꾸준하고 선형적인 발전이 아닙니다. 우리는 AI가 그 함의를 쉽게 측정할 수 있는 우리의 능력을 뛰어넘어 불균형적인 도약을 하는 것을 목격하고 있습니다. 그리고 이는 이러한 기술이 당신의 전문 분야를 어떻게 변화시킬지 형성할 기회가, 모든 변화가 완료된 후가 아니라, 상황이 유동적인 바로 지금 존재한다는 것을 시사합니다. 이러한 급진적인 발전은 단순히 기술적 진보를 넘어 사회, 경제, 심지어 인간의 정체성에 대한 근본적인 질문을 던지고 있습니다. 우리가 이 변화의 흐름에 수동적으로 끌려갈 것인지, 아니면 적극적으로 참여하여 미래를 공동으로 설계해 나갈 것인지는 우리에게 달렸습니다.

구독 공유