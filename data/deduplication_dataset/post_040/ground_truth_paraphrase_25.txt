최근 한 달 사이 인공지능 분야의 판도가 급변했으며, 특히 지난주에는 그 변화의 속도가 전례 없이 가속화되었습니다. 여러 AI 연구 기관들은 혁신적인 성과와 점진적 개선을 아우르는 다양한 신기술을 연이어 발표하여, 일반 대중이 이를 모두 이해하기는 매우 어려운 지경에 이르렀습니다. 저는 이러한 흐름 속 일부 발전이 인공지능의 미래, 나아가 인류의 미래까지 근본적으로 바꾸어 놓을 중대한 전환점이라고 확신합니다. 이러한 기술적 진보는 단순한 개선을 넘어, 우리가 상상했던 것보다 훨씬 빠르게 미래를 현실로 만들고 있습니다. 이러한 압도적인 변화의 물결 속에서, 우리는 이 기술이 가져올 기회와 도전을 동시에 직시해야 합니다. 이제 주요 발전 사항들을 자세히 살펴보겠습니다.

**스마트 AI가 이제 어디에나 있습니다**
불과 작년 말까지만 해도, 범용적으로 활용 가능한 GPT-4급(Gen2 class) 모델은 오직 GPT-4 하나였습니다. 그러나 현재는 이러한 성능을 지닌 모델이 6개에서 10개에 이르며, 이 중 일부는 오픈 웨이트(open weights) 형태로 제공되어 누구나 자유롭게 접근하고 변형할 수 있게 되었습니다. 미국 시장에서는 OpenAI의 GPT-4o, Anthropic의 Claude Sonnet 3.5, Google의 Gemini 1.5, Meta의 공개형 Llama 3.2, Elon Musk의 Grok 2, 그리고 Amazon의 신규 Nova가 대표적입니다. 중국 기업들 또한 GPT-4급 역량을 자랑하는 세 가지 오픈 다국어 모델, 즉 Alibaba의 Qwen, R1의 DeepSeek, 01.ai의 Yi를 선보였습니다. 유럽에서는 프랑스의 Mistral이 이 분야의 중요한 주자로 자리매김했습니다. 이처럼 다양한 모델들이 쏟아져 나오는 현상은, 고성능 AI 개발이 더 이상 OpenAI만의 독점적인 비법이 아니라, 뛰어난 컴퓨터 과학적 역량과 모델 학습에 필요한 컴퓨팅 자원(칩과 전력)을 갖춘 기업이라면 어디든 가능한 보편적인 기술이 되었음을 시사합니다. 한때 출시와 동시에 미래에 대한 상당한 우려를 자아낼 정도로 놀라웠던 GPT-4 수준의 인공지능(artificial intelligence)이 이제는 개인용 컴퓨터에서도 구동될 수 있는 시대가 도래했습니다. 이번 달에 공개된 Meta의 최신 경량 모델인 Llama 3.3은 유사한 성능을 발휘하며 제 게이밍 PC에서 인터넷 연결 없이도 완벽하게 작동합니다. 또한 Microsoft의 새롭게 출시된 소형 Phi 4는 GPT-4급 성능을 지니며 휴대폰에서도 거의 실행 가능하고, 그보다 약간 낮은 성능의 이전 버전인 Phi 3.5는 이미 휴대폰에서 원활히 구동됩니다. 이제 지능형 기능은 언제든 필요할 때(on demand) 활용할 수 있게 되었습니다.

이러한 온디바이스(on-device) AI의 확산은 단순히 접근성 향상을 넘어, 개인 정보 보호와 보안 측면에서 혁신적인 가능성을 열어줍니다. 민감한 데이터가 클라우드로 전송되지 않고 사용자의 기기 내에서 처리되므로, 정보 유출의 위험을 현저히 줄일 수 있습니다. 또한, 네트워크 연결이 불안정한 환경에서도 AI 기능을 활용할 수 있게 되어, 오지나 특정 산업 현장과 같이 인터넷 접근이 어려운 곳에서도 AI의 이점을 누릴 수 있습니다. 이는 AI 기술이 특정 대기업의 서버에만 갇혀 있던 시대를 지나, 이제는 사용자 개개인의 손 안에서 강력한 지능을 발휘하는 진정한 대중화의 길로 접어들었음을 의미합니다. 제 개인 컴퓨터에서 실행되는 Llama 3.3이 비록 "치즈 말장난이 포함된 운율 시" 벤치마크(benchmark)에서는 몇 개의 어색한 말장난만으로 아쉬운 결과를 보였지만, 이러한 경량화된 모델들이 특정 작업을 위한 맞춤형 지능으로 진화하고 있다는 점에 주목해야 합니다. 더욱이, 제가 이전 게시물에서 언급했듯이(해당 내용은 곧 다시 공유될 예정입니다), 이처럼 도처에 존재하는(ubiquitous) AI들은 이제 에이전트(agent)의 형태로 진화하여, 스스로 목표를 설정하고 달성하는 자율 AI(autonomous AI)의 동력원이 되고 있습니다. 초기 에이전트들을 활용하여 복잡한 물류 경로를 최적화하거나, 대규모 공사 현장의 실시간 안전 규정 준수 여부를 모니터링하는 등의 사례에서 그 잠재력을 엿볼 수 있습니다. 이는 단순한 정보 처리기를 넘어, 능동적인 문제 해결자로서 AI의 역할이 확대되고 있음을 보여줍니다.

**매우 스마트한 AI가 이제 여기에 있습니다**
만약 GPT-4급 성능이 인공지능의 정점이었다면, 우리는 그 능력에 적응하는 데 최소 5년에서 10년의 시간을 가질 수 있었을 것입니다. 그러나 AI 발전의 속도가 둔화될 조짐은 전혀 보이지 않습니다. 지난 한 달간 발표된 두 가지 주요 기술, 즉 Gen3 모델(GPT-5급으로 이해될 수 있는)의 초기 형태와 답변 생성 전 '사고' 과정을 거치는 o1 모델의 출시는 이러한 사실을 명확히 보여줍니다. 특히 o1 모델은 다른 대규모 언어 모델(LLM)보다 월등히 뛰어난 추론 능력(reasoning capability)을 자랑합니다. Gen3의 출시는 아직 초기 단계이므로 본 게시물에서는 자세히 다루지 않겠지만, o1에 대해서는 집중적으로 이야기하고자 합니다. 저는 o1의 초기 버전인 o1-프리뷰(o1-preview)가 공개되었을 때 이미 이에 대해 논한 바 있지만, 이후 출시된 o1과 o1-프로(o1-pro)라는 두 가지 심화된 모델은 성능 면에서 괄목할 만한 발전을 이루었습니다. 이 모델들은 질문에 응답하기 전에 인간의 논리적 문제 해결 과정을 모방하여, 눈에 보이지 않는 '사고' 시간을 가집니다. 테스트 시간 컴퓨트(test time compute)라 불리는 이 방식은 모델의 문제 해결 역량을 비약적으로 증진시키는 핵심 요소로 작용하는 것으로 드러났습니다. 실제로 이 모델들은 이제 크고 작은 연구 분야에서 실질적인 기여를 할 만큼 충분히 영리해졌습니다.

이러한 '사고' 능력은 단순히 방대한 데이터를 빠르게 처리하는 것을 넘어, 문제의 본질을 파악하고 다단계 추론을 수행하는 '시스템 2 사고(System 2 thinking)'와 유사한 방식으로 작동합니다. 이는 모델이 단편적인 정보에 기반한 즉각적인 답변을 넘어, 복잡한 질문에 대한 심층적인 분석과 논리적 해결책을 제시할 수 있게 함으로써, AI의 지능 수준을 한 차원 높이는 중요한 이정표가 됩니다. 예를 들어, 저는 o1이 사회 과학 분야의 복잡한 가설을 검증하는 데 얼마나 효과적인지 실험해 보았습니다. 특정 사회 현상에 대한 여러 이론적 관점과 실증 연구 데이터를 제시한 후, "이 현상을 가장 잘 설명하는 이론은 무엇이며, 그 근거는?"이라고 질문했습니다. o1은 각 이론의 강점과 약점을 면밀히 분석하고, 제공된 데이터를 바탕으로 가장 설득력 있는 설명을 도출해냈습니다. 이는 단순히 정보를 요약하는 것을 넘어, 비판적 사고와 종합적인 추론이 필요한 영역에서도 AI가 유의미한 역할을 할 수 있음을 보여줍니다. 저의 실험은 o1이 과학 문헌에서 얼마나 자주 오류를 찾아낼 수 있는지에 대한 다른 연구자들의 노력과 맞물려, 이 모델이 지닌 새로운 능력의 지평을 탐색하는 데 중요한 동기를 부여했습니다. o1이 이러한 종류의 위업을 얼마나 자주 달성할 수 있는지는 아직 미지수이지만, 이는 AI의 잠재력을 가늠하는 중요한 척도가 될 것입니다. 특히 하버드(Harvard), 스탠포드(Stanford) 등 유수의 연구기관에서 발표된 의료 연구 논문은 "o1-프리뷰(o1-preview)가 감별 진단(differential diagnosis), 진단 임상 추론(diagnostic clinical reasoning), 그리고 관리 추론(management reasoning)에서 이전 세대 모델과 인간 의사를 능가하는 초인적인 성능[강조는 필자]을 보여준다"고 결론지으며, AI가 보조 의견(second opinion)을 넘어 실제 임상 의사 결정 과정에 깊이 관여할 수 있는 가능성을 제시했습니다. 물론 이 논문은 아직 동료 심사(peer review)를 거치지 않았으며 AI가 의사를 완전히 대체할 것이라는 주장은 아니지만, AI의 도움을 받지 않는 것이 오히려 실수가 될 수 있는 미래가 도래하고 있음을 시사합니다. 더욱 고무적인 것은, o1, 특히 o1-프로(o1-pro)가 각자의 전문 분야에서 새로운 아이디어를 제안하고 예상치 못한 문제에 대한 해결책을 찾아내고 있다는 연구자들의 증언이 늘고 있다는 점입니다. (관련 사례는 여기서 확인할 수 있습니다). 그러나 여기서 중요한 질문이 제기됩니다. AI가 제시하는 복잡한 해결책이나 증명이 과연 정확한지 판단할 수 있는 전문가는 누구인가? 와튼(Wharton)의 저명한 동료 다니엘 록(Daniel Rock) 교수가 저에게 o1-프로(o1-pro)에게 던진 도전 과제를 예로 들어봅시다. 그는 "문헌에 없는 증명을 사용하여, 1) 무한히 넓은 레이어(layer)를 가정하지 않고 2) 2개 이상의 레이어(layer)에 대해 신경망(neural network)의 보편적 함수 근사 정리(universal function approximation theorem)를 증명하도록 요청해 보세요."라고 했습니다. o1-프로가 생성한 증명은 다음과 같습니다. 과연 이 증명이 맞을까요? 저는 이 분야의 전문가가 아니기에 판단할 수 없었습니다. 다니엘 교수와 다른 전문가들 또한 처음에는 그 정확성을 단정할 수 없었지만, 그 내용이 충분히 흥미로워 더 깊이 탐구할 가치가 있다고 여겼습니다. 결국 증명에는 오류가 있었지만(물론 o1-프로와의 추가 상호작용을 통해 수정될 가능성은 있습니다), 여전히 새로운 접근 방식을 제시하며 추가적인 사고를 자극했습니다. 다니엘 교수의 말처럼, 연구자들이 o1을 사용할 때 o1은 반드시 완벽하게 옳을 필요는 없습니다. "o1에게 창의적인 방식으로 증명을 완성하도록 요청하는 것은 사실상 o1에게 연구 동료가 되어달라고 요청하는 것과 같습니다. 모델이 유용하기 위해 증명을 완벽하게 할 필요는 없으며, 단지 우리가 더 나은 연구자가 되도록 돕기만 하면 됩니다." 우리는 이제 매우 어려운 박사 학위 수준의 문제를 해결하거나, 적어도 그러한 문제 해결을 돕는 '공동 지능(co-intelligence)'으로서 생산적으로 기능할 수 있는 AI를 갖게 된 것입니다. 물론, 문제는 자신이 해당 분야의 박사 학위 소지자가 아니라면 이러한 AI의 답변이 정확한지 실제로 검증하기 어렵다는 점입니다. 이는 AI 평가와 인류의 지식 검증 방식에 새로운 도전 과제를 안겨줍니다. 이 새로운 능력의 지평이 얼마나 유용하며 어떤 분야에서 특히 빛을 발할지는 추가적인 테스트와 연구가 필요하겠지만, 그 잠재력은 분명 주목할 만합니다.

**AI가 당신을 보고 대화할 수 있습니다**
수개월간 우리는 AI 음성 모델을 활용해 왔지만, 지난주에는 '시각(vision)'이라는 혁신적인 기능이 새롭게 통합되었습니다. 이제 ChatGPT와 Gemini는 실시간 비디오 스트림을 분석하고 음성을 통해 동시에 반응할 수 있게 되었습니다. 예를 들어, 저는 Gemini의 최신 경량 Gen3 모델인 Gemini 2.0 Flash와 실시간으로 제 컴퓨터 화면을 공유할 수 있습니다. 이 경험이 어떤지 직접 확인하려면, 제가 작성 중인 이 게시물의 초안에 대해 피드백(feedback)을 제공하는 과정을 영상으로 시청해 보세요. 더 나아가, 직접 무료로 체험해 보는 것을 강력히 추천합니다. 이 시스템이 제공하는 가능성은 진정으로 경험할 만한 가치가 있습니다. Gemini 2.0 Flash는 아직 제한된 메모리(memory)를 가진 소형 모델임에도 불구하고, 그 핵심적인 잠재력을 명확히 보여줍니다. 인간의 가장 보편적인 감각인 시각과 청각을 통해 실시간으로 사용자와 소통하는 모델은 AI를 단순한 컴퓨터 채팅창 속 존재가 아닌, 마치 같은 공간에 있는 듯한 실제적인 동반자로 탈바꿈시킵니다.

ChatGPT의 고급 음성 모드(Advanced Voice Mode)가 휴대폰에서 이러한 멀티모달(multimodal) 기능을 제공할 수 있다는 사실은, 이 기술이 수백만 명의 일반 사용자에게 광범위하게 보급될 것임을 의미합니다. 이는 AI가 우리 일상생활에 더욱 깊이 통합되면서 가져올 변화가 실로 심오할 것임을 예고합니다. 예를 들어, 시각과 음성을 겸비한 AI는 원격 기술 지원 분야에서 혁명적인 역할을 할 수 있습니다. 사용자가 문제를 겪는 기기를 AI에게 보여주면, AI는 실시간으로 화면을 분석하고 음성으로 단계별 해결책을 안내할 수 있습니다. 이는 복잡한 매뉴얼을 찾아보거나 대기 시간을 기다릴 필요 없이 즉각적인 도움을 받을 수 있게 합니다. 또한, 시각 장애인이나 노년층과 같이 특정 도움이 필요한 사용자들에게는 AI가 주변 환경을 '보고' 설명해주는 개인 비서 역할을 수행하여, 독립적인 생활을 영위하는 데 큰 도움을 줄 것입니다. 이처럼 AI가 단순한 도구를 넘어 '동반자'의 형태로 진화함에 따라, 우리는 인간과 기술의 상호작용 방식에 대한 근본적인 재정의를 목격하고 있습니다. 이는 단순한 편의성을 넘어, 우리가 세상을 인지하고 상호작용하는 방식 자체에 영향을 미칠 것입니다.

**AI 비디오가 갑자기 매우 좋아졌습니다**
지난 한 해 동안 인공지능 기반의 이미지 생성 기술은 비약적인 발전을 거듭했습니다. 이제는 제 개인 노트북에서 구동되는 모델조차 실제 사진과 구별하기 어려운 고품질 이미지를 만들어내며 깊은 인상을 주고 있습니다. 또한, "블루투스(bluetooth)를 사용하는 비행기 위의 수달"이나 "와이파이(wifi)를 사용하는 비행기 위의 수달"과 같은 구체적인 프롬프트(prompt)에도 매우 정확하게 반응하여, 사용자가 원하는 결과물을 훨씬 더 쉽게 얻을 수 있게 되었습니다. 만약 직접 이 기술을 경험해보고 싶다면, 지난주에 공개된 강력한 Imagen 3 모델을 기반으로 하는 Google의 ImageFX가 매우 직관적인 인터페이스(interface)를 제공하므로 활용해보시길 권합니다. 그러나 지난주에 진정한 혁신은 AI 텍스트-투-비디오(text-to-video) 생성기 분야에서 나타났습니다. 이전에는 중국 기업들이 개발한 Kling과 같은 인상적인 시스템과 일부 오픈 소스 모델들이 비디오 생성 기술의 최전선(state-of-the-art)을 이끌었습니다. 하지만 이러한 상황은 급변하고 있습니다. 먼저 OpenAI가 강력한 Sora 도구를 선보였고, 이어서 최근 추세처럼 Google이 훨씬 더 강력한 Veo 2 비디오 생성기를 출시했습니다. ChatGPT Plus 구독자라면 지금 바로 Sora를 경험할 수 있으며, 그 가치는 충분합니다. 저는 Veo 2(한두 달 내에 일반에 공개될 것으로 예상됩니다)에 조기 액세스(early access)를 얻을 기회가 있었는데, 그 결과는… 경이로웠습니다. 백 마디 말보다 한 번 보여주는 것이 더 효과적이므로, 이 8초짜리 클립 모음(현재는 길이가 제한적이지만, 훨씬 더 긴 영상도 제작 가능한 것으로 보입니다)을 직접 확인해 보십시오. 저는 각 클립에 매우 구체적인 프롬프트(prompt)를 제공했으며, 이 클립들은 Veo 2가 처음 생성한 영화 세트 중 일부일 뿐입니다(한 번에 네 개의 클립을 생성합니다). 즉, 수많은 예시 중 가장 좋은 것들만 선별한 것이 아니라는 점을 강조합니다. 영상 속 사물의 명확한 무게감과 부피, 섬세한 그림자와 반사, 헤어스타일과 같은 세부 사항이 장면 전체에 걸쳐 일관되게 유지되는 점, 그리고 제가 요청한 내용과 얼마나 정확하게 일치하는지(자세히 보면 빨간 풍선이 있습니다)에 주목해 주십시오. 여전히 몇 가지 오류는 존재하지만, 이제는 육안으로 이를 발견하기가 훨씬 더 어려워졌습니다(비디오 모델에게 특히 어려운 체조와 같은 복잡한 동작에서는 아직 개선의 여지가 있습니다). 그야말로 놀라운 수준입니다.

이러한 영상 생성 기술의 발전은 단순한 시각적 효과를 넘어, 시간적 일관성(temporal coherence)과 실제 물리 법칙에 대한 AI의 이해도가 경이로운 수준에 도달했음을 의미합니다. 과거에는 AI 생성 영상에서 흔히 나타나던 객체의 깜빡임이나 비현실적인 움직임, 그리고 장면 간의 불연속성이 이제는 거의 찾아보기 어렵게 되었습니다. 이는 스토리텔링, 영화 제작, 광고, 그리고 게임 개발과 같은 창의적인 산업 분야에 혁명적인 변화를 가져올 잠재력을 지닙니다. 저예산으로도 고품질의 시각 효과를 구현하거나, 아이디어 스케치를 실제 영상으로 빠르게 전환하여 시각화할 수 있게 될 것입니다. 그러나 동시에 이러한 기술은 딥페이크(deepfake)와 같은 잘못된 정보(misinformation) 생성에 악용될 수 있다는 윤리적 문제와 사회적 우려를 낳기도 합니다. 강력한 기술의 발전은 항상 그에 상응하는 책임감을 요구하며, 우리는 이러한 기술이 가져올 긍정적 측면을 극대화하고 부정적 측면을 최소화하기 위한 사회적 논의와 기술적 방어책 마련에 적극적으로 나서야 할 시점입니다.

**이 모든 것이 무엇을 의미할까요?**
더 심층적인 고찰은 다음 글에서 다룰 예정이지만, 현재 우리가 얻을 수 있는 명확한 교훈은 인공지능 발전의 여정이 아직 초기 단계에 있다는 것입니다. 단지 개별적인 혁신(AI가 복잡한 수학 논문의 오류를 검토하고, 거의 영화 수준의 비디오 클립을 만들어내며, 심지어 개인 게이밍 PC에서도 구동되는 것)만이 놀라운 것이 아닙니다. 진정으로 경이로운 것은 이러한 변화의 속도와 그 범위의 광대함입니다. 불과 1년 전까지만 해도 GPT-4는 미래 기술의 한 단면을 보여주는 듯했습니다. 하지만 이제는 이 수준의 AI가 기본적으로 휴대폰에서도 작동하며, 최신 모델들은 심지어 학술적인 동료 심사를 통과한 논문 속 오류까지 찾아내는 경지에 이르렀습니다. 이는 점진적인 발전이 아닙니다. 우리는 인공지능이 그 영향력을 우리가 쉽게 가늠할 수 있는 능력을 훨씬 초월하여, 마치 기하급수적인 도약(disproportionate leaps)을 하는 모습을 목격하고 있습니다.

이는 곧 이러한 기술이 당신의 전문 분야를 어떻게 변화시킬지 직접 형성할 수 있는 기회가, 모든 변화가 완료된 후가 아니라 바로 지금, 상황이 유동적인 이 시점에 존재한다는 것을 강력히 시사합니다. 우리는 더 이상 AI를 먼 미래의 기술이나 특정 전문가들의 전유물로 여길 수 없습니다. AI는 이미 우리의 일상과 직업 환경 속으로 깊숙이 침투하고 있으며, 그 영향력은 앞으로 더욱 확대될 것입니다. 따라서 개인과 조직 모두에게, 이러한 기술적 흐름을 이해하고 적극적으로 참여하여 자신의 역할과 가치를 재정립하는 것이 필수적입니다. 단순히 변화에 수동적으로 대응하는 것을 넘어, AI를 활용하여 새로운 가치를 창출하고 기존의 문제들을 혁신적으로 해결할 수 있는 기회를 모색해야 합니다. 이는 AI 시대의 주역이 될 수 있는 중요한 갈림길이며, 지금의 선택이 미래를 결정할 것입니다. 이 글이 여러분의 AI 여정에 작은 영감을 주었기를 바랍니다. 다음 글에서는 이러한 심오한 변화가 사회 전반에 미칠 장기적인 영향과 윤리적 고려 사항에 대해 더 깊이 탐구해 보겠습니다. 이 여정에 함께해 주십시오. 구독하고 공유하여 더 많은 분들과 이 중요한 대화를 나누어 주세요.