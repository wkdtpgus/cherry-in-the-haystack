지난 한 달 동안 AI의 상태가 변화했으며, 특히 지난주에 새로운 기술의 등장으로 그 속도가 급격히 빨라졌습니다. AI 연구소들은 혁신적인 것부터 점진적인 것까지 수많은 신제품을 쏟아냈고, 이로 인해 누구도 따라잡기 어려울 정도입니다. 저는 이러한 변화 중 일부가 AI(그리고 어쩌면 우리의) 미래를 재편할 진정한 돌파구이자, 동시에 기술적 진보를 넘어 윤리적 질문을 던지며 사회 전반에 걸쳐 그 영향력이 심화되고 있다고 생각합니다. 현재 상황은 다음과 같습니다.

**스마트 AI의 확산과 창의적 잠재력의 발현**
작년 말에는 공개적으로 사용 가능한 GPT-4/Gen2 클래스 모델이 GPT-4 단 하나뿐이었습니다. 이제는 그러한 모델이 6개에서 10개 사이에 이르며, 그중 일부는 오픈 웨이트(open weights)로, 누구나 자유롭게 사용하거나 수정할 수 있습니다. 미국에서는 OpenAI의 GPT-4o, Anthropic의 Claude Sonnet 3.5, Google의 Gemini 1.5, Meta의 오픈 Llama 3.2, Elon Musk의 Grok 2, 그리고 Amazon의 새로운 Nova가 있습니다. 중국 기업들은 GPT-4 클래스 성능을 보이는 세 가지 오픈 다국어 모델을 출시했는데, 특히 Alibaba의 Qwen, R1의 DeepSeek, 그리고 01.ai의 Yi가 있습니다. 유럽에서는 프랑스의 Mistral이 유일한 참가자입니다. 이 혼란스러운 이름들의 나열이 의미하는 바는, 유능한 AI를 구축하는 것이 OpenAI만이 가지고 있던 어떤 마법 같은 공식에 의한 것이 아니라, 컴퓨터 과학적 재능과 모델 훈련에 필요한 칩과 전력을 확보할 수 있는 회사라면 누구에게나 가능했다는 것입니다. 사실, 출시 당시에는 미래에 대한 상당한 불안감을 불러일으킬 정도로 놀라웠던 GPT-4 수준의 인공지능(artificial intelligence)이 이제는 제 개인 컴퓨터에서도 실행될 수 있습니다. 이번 달에 출시된 Meta의 최신 소형 모델인 Llama 3.3은 유사한 성능을 제공하며 제 게이밍 PC에서 완전히 오프라인으로 작동할 수 있습니다. 그리고 Microsoft의 새롭고 작은 Phi 4는 GPT-4 수준이며 거의 휴대폰에서 실행될 수 있고, 그보다 약간 성능이 떨어지는 이전 버전인 Phi 3.5는 확실히 휴대폰에서 실행 가능합니다. 어떤 종류의 지능이든 주문형으로(on demand) 제공됩니다. 제 개인 컴퓨터에서 실행되는 Llama 3.3은 "치즈 말장난이 포함된 운율 시" 벤치마크(benchmark)를 몇 개의 어색한 말장난만으로 통과합니다. 그리고 제가 논의했듯이(곧 다시 게시할 예정입니다), 이러한 유비쿼터스(ubiquitous) AI들은 이제 에이전트(agent), 즉 스스로 목표를 추구할 수 있는 자율 AI(autonomous AI)에 동력을 공급하기 시작했습니다. 제가 초기 에이전트(agent)를 사용하여 가격 비교 쇼핑을 하고 건설 현장을 모니터링하는 이 게시물에서 그 의미를 확인할 수 있습니다.

과거에는 AI가 주로 데이터 분석이나 자동화된 작업에 활용된다는 인식이 지배적이었습니다. 하지만 이제는 AI가 인간의 창의성을 보조하고 확장하는 도구로 진화하고 있습니다. 이로 인해 예술과 디자인 분야에서 누구도 따라잡기 어려울 정도의 혁신이 일어나고 있습니다. 예를 들어, AI는 특정 작가의 화풍을 학습하여 새로운 그림을 그리거나, 고전 음악 작곡가의 스타일로 새로운 교향곡을 만들어낼 수 있습니다. 이러한 AI 생성 예술은 단순한 모방을 넘어, 인간 예술가에게 영감을 주고 새로운 표현 방식을 탐구하도록 돕습니다. 최근에는 텍스트 프롬프트(text prompt)만으로 고품질의 시각 예술 작품을 만들어내는 AI 모델들이 대중화되면서, 일반인들도 예술 창작의 문턱을 넘을 수 있게 되었습니다. 패션 디자인 분야에서는 AI가 트렌드를 분석하여 새로운 의류 디자인을 제안하고, 심지어 가상 모델에게 착용시켜 시뮬레이션하는 단계에 이르렀습니다. 문학 분야에서도 AI는 시나 소설의 초고를 작성하거나, 특정 장르의 스토리를 구성하는 데 활용됩니다. 이는 작가들이 아이디어 구상 단계에서 시간을 절약하고, 다양한 가능성을 탐색할 수 있도록 돕습니다. 과거에는 상상하기 어려웠던 이러한 예술적 협력은 인간과 AI가 함께 만들어낼 수 있는 창의성의 새로운 지평을 열고 있습니다.

**매우 스마트한 AI의 등장과 지속 가능한 개발 방향**
이 모든 것은 만약 GPT-4 수준의 성능이 AI가 달성할 수 있는 최대치였다면, 우리가 그들의 능력에 익숙해지는 동안 5년에서 10년간 지속적인 변화를 겪기에 충분했을 것이라는 의미입니다. 하지만 AI 개발의 큰 둔화가 임박했다는 징후는 없습니다. 우리는 지난 한 달 동안 두 가지 중요한 출시가 있었기 때문에 이를 알고 있습니다. 바로 Gen3 모델(GPT-5 클래스 모델로 생각할 수 있습니다)의 첫 징후와 답변하기 전에 "생각"할 수 있는 o1 모델의 출시입니다. 이는 o1 모델을 다른 대규모 언어 모델(LLM)보다 훨씬 더 나은 추론자(reasoner)로 만듭니다. Gen3 출시는 아직 초기 단계이므로 이 게시물에서 Gen3에 대해 너무 많이 다루지는 않겠지만, o1에 대해서는 이야기하고 싶습니다. 저는 o1이 초기 o1-프리뷰(o1-preview) 형태로 출시되었을 때 이에 대해 논의했지만, o1과 o1-프로(o1-pro)라는 두 가지 더 정교한 변형 모델은 상당한 성능 향상을 이루었습니다. 이 모델들은 질문에 답하기 전에 인간의 논리적 문제 해결을 모방하여 보이지 않게 "생각"하는 시간을 보냅니다. 테스트 시간 컴퓨트(test time compute)라고 불리는 이 접근 방식은 모델이 문제 해결 능력을 향상시키는 데 핵심적인 역할을 하는 것으로 밝혀졌습니다. 사실, 이 모델들은 이제 크고 작은 방식으로 연구에 의미 있는 기여를 할 만큼 충분히 똑똑합니다. 재미있는 예시로, 저는 최근 소셜 미디어(social media)에서 발생한 공황 상태에 대한 기사를 읽었습니다. 한 학술 논문에서 검은색 플라스틱 식기가 재활용된 전자 폐기물(e-waste)로 부분적으로 만들어졌기 때문에 사람을 중독시킬 수 있다고 주장했습니다. 논문은 BDE-209라는 화합물이 이 식기에서 매우 높은 비율로 용출되어 미국 환경보호청(EPA)이 정한 안전 복용량 수준에 근접할 수 있다고 제안했습니다. 많은 사람들이 주걱을 버렸지만, 맥길 대학교(McGill University)의 조 슈워츠(Joe Schwarcz)는 이것이 말이 안 된다고 생각했고, 논문 저자와 동료 심사자들이 놓쳤던 수학적 오류를 발견했습니다. 저자들이 논문 7페이지에서 BDE-209의 복용량을 10배 잘못 곱한 것이었습니다. 저는 o1이 이 오류를 찾아낼 수 있을지 궁금했습니다. 그래서 제 휴대폰에서 PDF 텍스트를 붙여넣고 "이 논문의 수학을 주의 깊게 확인해 줘(carefully check the math in this paper)"라고 입력했습니다. 그게 전부였습니다. o1은 즉시 오류를 찾아냈습니다(다른 AI 모델은 찾아내지 못했습니다). 모델이 단순히 전체 학술 논문을 처리하는 것을 넘어, "수학 확인"이 의미 있는 맥락을 이해하고 실제로 결과를 성공적으로 확인할 수 있을 만큼 충분히 유능해진다면, 이는 AI가 할 수 있는 일을 근본적으로 변화시킵니다. 사실, 저의 실험은 같은 일을 하는 다른 사람들과 함께 o1이 과학 문헌에서 얼마나 자주 오류를 찾을 수 있는지 알아보려는 노력을 고무시켰습니다. o1이 이러한 종류의 위업을 얼마나 자주 달성할 수 있는지는 알 수 없지만, 이는 새로운 능력의 지평을 가리키므로 알아내는 것이 중요해 보입니다. 사실, o1의 초기 버전인 프리뷰(preview) 모델조차도 과학적 능력의 도약을 나타내는 것 같습니다. 하버드(Harvard), 스탠포드(Stanford) 및 기타 연구원들의 충격적인 의료 연구 논문은 "o1-프리뷰(o1-preview)가 감별 진단(differential diagnosis), 진단 임상 추론(diagnostic clinical reasoning) 및 관리 추론(management reasoning)에서 초인적인 성능[강조는 필자]을 보여주며, 이전 모델 세대와 인간 의사보다 여러 영역에서 우수하다"고 결론지었습니다. 이 논문은 아직 동료 심사(peer review)를 거치지 않았으며, AI가 의사를 대체할 수 있다고 주장하는 것은 아니지만, 위의 결과와 함께 AI를 보조 의견(second opinion)으로 사용하지 않는 것이 곧 실수가 될 수 있는 변화하는 세상을 시사합니다. 잠재적으로 더 중요한 것은, 연구원들로부터 o1, 특히 o1-프로(o1-pro)가 자신들의 분야에서 새로운 아이디어를 생성하고 예상치 못한 문제를 해결하고 있다는 이야기를 점점 더 많이 듣고 있다는 것입니다(여기 한 가지 사례가 있습니다). 문제는 이제 전문가만이 AI가 틀렸는지 맞았는지 평가할 수 있다는 것입니다. 예를 들어, 와튼(Wharton)의 매우 똑똑한 동료인 다니엘 록(Daniel Rock)은 저에게 o1-프로(o1-pro)에게 도전 과제를 주라고 요청했습니다. "문헌에 없는 증명을 사용하여, 1) 무한히 넓은 레이어(layer)를 가정하지 않고 2) 2개 이상의 레이어(layer)에 대해 신경망(neural network)의 보편적 함수 근사 정리(universal function approximation theorem)를 증명하도록 요청해 보세요." 다음은 o1-프로가 작성한 내용입니다. 이것이 맞을까요? 저는 전혀 모릅니다. 이것은 제 전문 분야를 벗어납니다. 다니엘과 이를 본 다른 전문가들도 첫눈에 이것이 맞는지 알 수 없었지만, 충분히 흥미로워서 더 깊이 살펴볼 가치가 있다고 느꼈습니다. 알고 보니 그 증명에는 오류가 있었습니다(비록 o1-프로와의 더 많은 상호작용으로 수정될 수도 있지만요). 하지만 그 결과는 여전히 추가적인 사고를 촉진하는 몇 가지 새로운 접근 방식을 제시했습니다. 다니엘이 저에게 말했듯이, 연구자들이 o1을 사용할 때 o1은 유용하기 위해 반드시 옳을 필요는 없습니다. "o1에게 창의적인 방식으로 증명을 완성하도록 요청하는 것은 사실상 o1에게 연구 동료가 되어달라고 요청하는 것입니다. 모델이 유용하기 위해 증명을 완벽하게 할 필요는 없으며, 단지 우리가 더 나은 연구자가 되도록 돕기만 하면 됩니다." 우리는 이제 매우 어려운 박사 학위 수준의 문제를 해결하거나, 적어도 그러한 문제를 해결하려는 연구자들을 위한 공동 지능(co-intelligence)으로서 생산적으로 작업할 수 있는 AI를 갖게 된 것 같습니다. 물론 문제는 자신이 해당 분야의 박사 학위 소지자가 아니라면 이러한 답변이 정확한지 실제로 알 수 없다는 점이며, 이는 AI 평가에 있어 새로운 도전 과제를 만듭니다. 이것이 얼마나 유용하고 어떤 분야에서 유용한지 이해하기 위해서는 추가적인 테스트가 필요하겠지만, AI 능력의 이 새로운 지평은 주목할 가치가 있습니다.

AI 기술의 발전은 눈부시지만, 그 이면에는 막대한 컴퓨팅 자원과 에너지가 소모된다는 현실이 있습니다. 대규모 언어 모델(LLM)과 복잡한 신경망 훈련에 필요한 전력량은 환경 문제와 직결됩니다. 따라서 AI 개발의 지속 가능성은 이제 간과할 수 없는 중요한 과제가 되었습니다. 최근의 기술 발전은 AI 개발의 윤리적 방향에 대한 논의를 더욱 활발하게 만들었습니다. AI 산업은 이제 단순히 성능 경쟁을 넘어, 에너지 효율성을 높이고 탄소 발자국을 줄이는 '그린 AI(Green AI)'로의 전환을 모색하고 있습니다. 이는 모델의 경량화, 효율적인 알고리즘 개발, 그리고 재생 가능 에너지원을 활용한 데이터 센터 구축 등으로 구현될 수 있습니다. 또한, 학습 데이터를 최적화하고 불필요한 반복 학습을 줄이는 방법론도 연구되고 있습니다. 이러한 노력은 AI 기술이 인류에게 가져다줄 혜택을 지속 가능하게 유지하면서, 동시에 지구 환경에 미치는 영향을 최소화하려는 중요한 시도입니다. 궁극적으로는 어떤 종류의 지능이든 개인 맞춤형 학습에 활용될 수 있습니다.

**AI의 실시간 상호작용 능력: 교육 혁명과 미래 학습 환경**
우리는 몇 달 동안 AI 음성 모델을 사용해 왔지만, 지난주에는 새로운 기능인 시각(vision)이 도입되었습니다. 이제 ChatGPT와 Gemini는 실시간 비디오를 보고 음성으로 동시에 상호작용할 수 있습니다. 예를 들어, 저는 이제 Gemini의 새로운 소형 Gen3 모델인 Gemini 2.0 Flash와 실시간 화면을 공유할 수 있습니다. 이것이 어떤 느낌인지 보려면, 이 게시물의 초안에 대해 피드백(feedback)을 주는 것을 시청해 보세요. 아니면 더 좋게는, 직접 무료로 시도해 보세요. 진지하게, 이 시스템이 무엇을 할 수 있는지 경험해 볼 가치가 있습니다. Gemini 2.0 Flash는 여전히 제한된 메모리(memory)를 가진 작은 모델이지만, 여기서 핵심을 이해하기 시작할 것입니다. 가장 일반적인 인간의 감각인 시각과 음성을 통해 인간과 실시간으로 상호작용할 수 있는 모델은 AI를 컴퓨터 채팅 상자에 갇힌 존재가 아니라, 당신과 함께 방에 있는 현재의 동반자로 만들며, 특히 개인화된 학습 경험을 제공하는 데 핵심적인 역할을 합니다. ChatGPT 고급 음성 모드(Advanced Voice Mode)가 휴대폰에서 동일한 작업을 수행할 수 있다는 사실은 이 기능이 수백만 명의 사용자에게 널리 제공된다는 것을 의미합니다. AI가 우리 삶에 더욱 밀접해짐에 따라 그 영향은 상당히 심오할 것입니다.

교육 분야는 AI 기술의 가장 큰 잠재적 수혜자 중 하나로 떠오르고 있습니다. AI는 개인화된 학습 경험을 제공하고, 학생 개개인의 학습 속도와 스타일에 맞춰 교육 콘텐츠를 조절함으로써 학습 효과를 극대화할 수 있습니다. AI 튜터는 학생의 질문에 즉각적으로 답변하고, 약점을 파악하여 맞춤형 과제를 제시하며, 복잡한 개념을 시각적으로 설명해 줄 수 있습니다. 이는 교사가 모든 학생에게 개별적인 관심을 기울이기 어려운 현실적인 한계를 보완해 줍니다. 또한, AI는 학습 데이터를 분석하여 교육 과정의 효율성을 평가하고 개선하는 데 기여합니다. 예를 들어, 특정 주제에 대한 학생들의 이해도를 실시간으로 모니터링하고, 필요에 따라 교육 자료를 업데이트하거나 다른 학습 방법을 제안할 수 있습니다. 이러한 AI 기반 교육 환경은 단순히 지식을 전달하는 것을 넘어, 비판적 사고력과 문제 해결 능력을 함양하는 데 중점을 두며, 미래 사회가 요구하는 인재 양성에 필수적인 요소가 될 것입니다.

**AI 비디오의 급격한 발전과 새로운 보안 위협 및 방어 전략**
지난 한 해 동안 AI 이미지 생성은 제 노트북에서 실행되는 모델들이 실제 사진과 구별할 수 없는 이미지를 만들어내면서 정말 인상 깊어졌습니다. 또한 "블루투스(bluetooth)를 사용하는 비행기 위의 수달"과 "와이파이(wifi)를 사용하는 비행기 위의 수달"과 같은 프롬프트(prompt)에 적절하게 반응하며 훨씬 더 쉽게 지시할 수 있게 되었습니다. 직접 실험해보고 싶다면, 지난주에 출시된 강력한 Imagen 3 모델을 사용하는 데 Google의 ImageFX는 정말 쉬운 인터페이스(interface)입니다. 하지만 지난주에 진정한 도약은 AI 텍스트-투-비디오(text-to-video) 생성기에서 나왔습니다. 이전에는 중국 기업의 AI 모델들이 Kling과 같은 인상적인 시스템과 일부 오픈 모델을 포함하여 비디오 생성 분야에서 일반적으로 최첨단(state-of-the-art)을 대표했습니다. 하지만 상황은 빠르게 변하고 있습니다. 먼저 OpenAI가 강력한 Sora 도구를 출시했고, 이어서 최근의 추세가 된 것처럼 Google이 훨씬 더 강력한 Veo 2 비디오 생성기를 출시했습니다. ChatGPT Plus를 구독하면 지금 Sora를 사용할 수 있으며, 그럴 가치가 있습니다. 하지만 저는 Veo 2(한두 달 안에 출시될 예정인 듯합니다)에 조기 액세스(early access)를 얻었고, 그것은… 놀랍습니다. 말보다는 보여주는 것이 항상 낫습니다. 그러니 이 8초짜리 클립 모음(현재로서는 제한적이지만, 훨씬 더 긴 영화도 만들 수 있는 것으로 보입니다)을 살펴보세요. 저는 각 클립에 정확한 프롬프트(prompt)를 제공하며, 이 클립들은 Veo 2가 만든 첫 번째 영화 세트에서만 선택된 것입니다(한 번에 네 개의 클립을 만듭니다). 따라서 많은 예시 중에서 가장 좋은 것만 고른 것이 아닙니다. 사물의 명백한 무게와 부피, 그림자와 반사, 헤어스타일과 세부 사항이 유지되면서 장면 간의 일관성, 그리고 장면이 제가 요청한 내용과 얼마나 가까운지(찾아보면 빨간 풍선이 있습니다)에 주목하세요. 오류가 있지만, 이제는 첫눈에 발견하기 훨씬 더 어렵습니다(비디오 모델에게는 매우 어려운 체조에서는 여전히 어려움을 겪지만요). 정말 인상적입니다.

AI의 발전은 놀라운 기회를 제공하지만, 동시에 새로운 보안 위협을 야기하기도 합니다. 딥페이크(deepfake) 기술을 이용한 허위 정보 유포, AI 모델에 대한 적대적 공격(adversarial attack), 그리고 민감한 개인 정보의 오용 등은 AI 시대의 주요 보안 과제입니다. 이러한 기술이 악용될 경우 사회적 혼란과 불신을 초래할 수 있습니다. 이에 따라 AI 기반 보안 시스템의 중요성이 더욱 커지고 있습니다. AI는 방대한 데이터를 분석하여 비정상적인 패턴이나 잠재적 위협을 식별하고, 사이버 공격을 예측하며, 실시간으로 방어 체계를 구축하는 데 활용될 수 있습니다. 예를 들어, AI는 네트워크 트래픽에서 악성 코드를 감지하거나, 사용자 인증 과정에서 이상 징후를 포착하여 사기를 방지할 수 있습니다. 또한, AI 모델 자체의 보안을 강화하기 위한 연구도 활발히 진행 중입니다. 이는 모델의 견고성을 높이고, 예측 불가능한 공격에 대한 내성을 키우는 것을 목표로 합니다. AI와 보안은 끊임없이 진화하는 창과 방패의 관계이며, AI 기술이 안전하고 신뢰할 수 있는 방식으로 발전하기 위해서는 지속적인 연구와 투자가 필수적입니다.

**이 모든 것이 무엇을 의미할까요?**
더 자세한 성찰은 다음 게시물에서 다루겠지만, 여기서 얻을 수 있는 교훈은 AI 발전의 끝을 보려면 아직 멀었으며, 동시에 그 발전이 사회적 책임과 함께 이루어져야 한다는 점입니다. 놀라운 것은 단순히 개별적인 돌파구(AI가 수학 논문을 검토하고, 예술을 창작하며, 에너지 효율을 높이고, 교육을 혁신하며, 보안 위협에 대응하고, 거의 영화 품질의 비디오 클립을 생성하거나, 게이밍 PC에서 실행되는 것)만이 아닙니다. 변화의 속도와 폭, 그리고 기술 생태계가 예측 불가능한 방향으로 불균형적인 도약을 하는 것을 목격하고 있다는 점입니다. 1년 전만 해도 GPT-4는 미래를 엿보는 것 같았고, AI의 윤리적 측면과 지속 가능성은 주로 학계의 논의 주제였습니다. 이제는 GPT-4 수준의 AI가 기본적으로 휴대폰에서 실행되며 새로운 모델들은 학술 동료 심사를 통과한 오류까지 찾아내고 있고, AI의 사회적 영향은 정부, 기업, 그리고 시민 사회 전체가 함께 고민해야 할 현실적인 과제가 되었습니다. 이것은 꾸준한 발전이 아닙니다. 우리는 AI가 그 함의를 쉽게 측정할 수 있는 우리의 능력을 뛰어넘어 불균형적인 도약을 하는 것을 목격하고 있습니다. 그리고 이는 이러한 기술이 당신의 분야를 어떻게 변화시킬지 형성할 기회가, 변화가 완료된 후가 아니라 상황이 유동적인 지금 존재하며, 단순한 기술 적용을 넘어 새로운 비즈니스 모델을 창출할 수 있음을 시사합니다. AI의 미래는 기술적 진보뿐만 아니라, 우리가 이 강력한 도구를 어떻게 책임감 있게 활용하고 관리하느냐에 달려 있습니다.

구독 공유