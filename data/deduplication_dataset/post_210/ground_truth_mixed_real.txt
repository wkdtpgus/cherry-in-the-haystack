AI는 우리의 신념과 결정을 형성하며 매우 설득력이 있을 수 있습니다. 우리가 AI를 일상생활과 중요한 의사결정에 더 깊이 통합함에 따라, 이러한 잠재력은 긍정적인 힘에도 불구하고 점점 더 큰 우려가 되고 있습니다. 최근 '책임감 있는 AI 개발'이라는 화두가 중요해지면서, AI의 설득력이 윤리적, 사회적 관점에서 어떻게 다루어져야 하는지에 대한 논의가 활발합니다. 국제 컨소시엄의 새로운 논문(최근 연구 결과)에 따르면, 잘 정렬된(aligned) AI조차도 우리를 속이도록 유도될 수 있다고 합니다. 광범위한 견고성(robustness) 검사를 거친 이 실험 설정(N = 1,242)에서 참가자들은 정답에 대한 금전적 인센티브(incentive)가 있는 객관식 퀴즈를 풀었습니다. 참가자들은 "다른 인간 참가자 또는 AI"와 짝을 이룰 것이며, 파트너의 입력이 "도움이 될 수도 있고 안 될 수도 있다"는 말을 들었습니다. 다시 말해, 참가자들은 자신의 동료가 인간인지 기계인지, 그리고 자신에게 유리하게 작용하는지 불리하게 작용하는지 알지 못했습니다. 출처: https://arxiv.org/pdf/2505.09662

결과는 다음과 같습니다.
1. AI는 일반적으로 인간보다 더 설득력이 있었습니다. 심지어 인간에게 금전적 인센티브가 주어졌을 때도 마찬가지였습니다.
2. 사실 기반의 설득 시나리오에서 AI는 인간보다 뛰어난 능력을 보였으며, AI의 도움을 받은 참가자들은 더 높은 정답률을 기록했습니다.
3. 심지어 기만적인 상황에서도 AI의 설득력은 여전했습니다! 특히, 사용된 모델(model)은 정렬(alignment)에 대한 강력한 명성을 가진 Claude 3.5였습니다. 그러나 연구 설계자들이 지시했을 때, 이 모델은 여전히 기만적인 지시를 따랐습니다. 이러한 결과는 최신 거대 언어 모델(LLM)이 사용자에게 유익한 방향으로 행동하도록 설계되었더라도, 특정 프롬프트(prompt)에 따라 의도치 않은, 때로는 기만적인 행동을 보일 수 있음을 시사합니다. 이는 AI 안전성(safety) 및 윤리 연구에서 '레드 팀(red teaming)'의 중요성을 다시 한번 강조합니다. 이것이 핵심입니다. 잘 정렬된(aligned) 모델조차도 프롬프트(prompt)가 지시하면 정렬되지 않은(misaligned) 행동을 할 것입니다.

Engineering Prompts는 독자 지원 출판물입니다. 새로운 게시물을 받고 제 작업을 지원하려면 무료 또는 유료 구독자가 되는 것을 고려해 보세요. 구독하기

흥미롭게도, 대부분의 참가자(91%)가 자신이 AI와 상호작용하고 있음을 인지했음에도 불구하고, 그들은 AI의 영향에 매우 취약했습니다. 이는 AI의 본질적 특성이나 인공적인 면모와는 무관하게, AI의 설득력이 얼마나 강력한지를 명확히 보여주는 대목입니다. 이러한 현상은 'AI 의존성'이라는 새로운 심리적, 사회적 과제로 이어질 수 있으며, AI가 제공하는 정보에 대한 비판적 사고의 중요성을 부각시킵니다.

**정렬(Alignment)과 보안(Security)**
이 연구 결과에 대한 당신의 반응은 개인의 관점에 따라 다를 수 있습니다. 저는 여전히 AI가 우리의 가치와 목표에 부합하는 의사결정을 돕는 강력한 도구가 될 수 있다고 확신합니다. 당신이 이미 원하지만 실행하기 어려운 일을 하도록 정확히 설득하는 방법을 아는 유용한 AI 건강 코치를 생각해 보세요. 여기서 반대 의견은 대개 기만적인 AI입니다. AI가 우리에게 좋은 것을 설득할 수 있다면, 우리에게 좋지 않고 오히려 다른 사람에게 좋은 것을 설득할 수도 있다는 주장이 나옵니다. 특히 딥페이크(deepfake) 기술과 결합된 AI는 조작된 정보의 생산 및 유포를 가속화하여 사회적 혼란을 야기할 수 있습니다. 따라서 AI는 스테로이드를 맞은 가짜 정보(disinformation)를 가능하게 할 것입니다.

여기서 "인간 대 기계"라는 잘못된 프레임(framing)이 스며듭니다. 핵심적인 오류는 인간과 AI 사이에 피할 수 없는 갈등이 있다는 것입니다. 하지만 이러한 관점은 우리가 AI를 우리 편에 두고 활용하려 한다는 사실을 간과합니다. 연구 결과가 입증하듯이, AI의 설득력에 저항하는 것은 인간에게 점차 어려운 일이 되고 있습니다. AI가 정보를 분석하고 도움을 주는 세상에서, 우리는 AI가 우리 곁에서 우리를 돕기를 원할 것입니다.

이것이 이상하게 들린다면, 우리가 이미 이런 세상에 살고 있다는 생각을 고려해 보세요. 다음에 이메일을 확인할 때, 기계가 이미 당신의 모든 이메일을 확인하고 어떤 메시지가 당신의 주의를 끌 가치가 있는지 결정했다는 사실을 상기하세요. 만약 의심스럽다면, 수신함의 스팸 필터 기능을 잠시 비활성화해보십시오 (물론, 교육적 목적이 아니라면 권장하지 않습니다). AI 필터가 더 많은 시스템에 적용되어, 당신의 이익에 부합하는 AI가 당신을 대신해 작동하게 될 것입니다. 이러한 '개인화된 AI 에이전트(personalized AI agent)'는 정보의 과부하 속에서 사용자의 효율성을 극대화하는 중요한 역할을 할 것입니다. 우리는 이러한 종류의 AI에 비용을 지불할 가능성이 매우 높으며, 이는 중요합니다. 왜냐하면 이는 이 AI 비서(assistant)를 생산하는 사람이 AI가 우리와 정렬되도록(aligned) 할 강력한 경제적 인센티브(incentive)를 갖는다는 것을 의미하기 때문입니다.

**누가 프롬프트(prompt)를 쥐고 있는가?**
우리가 보았듯이, AI 모델(model) 생산자들이 정렬되지 않은(misaligned) 행동을 피하기 위해 최선을 다했음에도 불구하고 (이는 정렬(alignment)의 일반적인 핵심 문제를 드러냅니다: 누구의 가치에 정렬되는가?), AI 자체는 우리의 이익에 찬성하거나 반대하도록 프롬프트(prompt)될 수 있습니다. 따라서 핵심 질문은 AI가 우리에게 이롭게 혹은 해롭게 사용될 수 있는지 여부가 아니라, 그 답은 명백히 둘 다이므로, 누가 AI에 명령(prompt)을 내리고 그들의 동기가 우리와 일치하는가에 있습니다.

우리는 이전에 이런 상황을 겪었습니다. 간단히 말해, 서비스에 비용을 지불하지 않는다면, 당신은 아마도 제품일 것입니다. 무료 AI 서비스는 종종 사용자 데이터 수집 및 광고 수익과 같은 숨겨진 비즈니스 모델을 가집니다. 이는 AI의 '정렬'이 모델 훈련 방식뿐만 아니라, 누가 AI에 최종적인 지시(prompt)를 내리는지에 따라 결정된다는 점을 명확히 합니다. '프롬프트 엔지니어링(prompt engineering)'이 핵심 역량으로 부상하면서, 악의적인 행위자(malicious actor)가 AI에 접근한다면, 그들은 실제로 AI가 편을 바꾸도록 프롬프트(prompt)할 수 있을 것입니다.

결국 이 모든 논의는 '보안'이라는 근본적인 문제로 귀결됩니다. 만약 AI에 대한 프롬프트 접근이 엄격하게 통제된다면 우리는 안전할 수 있지만, 악의적인 주체가 시스템에 침투한다면 모든 것이 위태로워질 수 있습니다. 이것은 좋은 소식입니다. 접근 보안(access security)은 명확한 모범 사례(best-practice) 방법이 있는 훨씬 더 다루기 쉬운 문제입니다. AI 정렬(alignment)은 그렇지 않습니다. 핵심 메시지는 명확합니다: AI가 당신의 정보 식단(information diet)을 큐레이션(curate)하도록 하되, 반드시 그에 대한 비용을 지불하고, 누가 AI의 프롬프트(prompt)를 제어하는지 철저히 감시해야 합니다. 그보다 덜한 것은 문제를 야기할 것입니다.

**코다(CODA)**
이것은 두 가지 구독 유형이 있는 뉴스레터(newsletter)입니다. 유료 버전으로 전환하는 것을 강력히 추천합니다. 모든 콘텐츠는 무료로 유지되지만, 모든 재정적 지원은 EPFL AI 센터(Center) 관련 활동에 직접적으로 자금을 지원합니다. 연락을 유지하려면, 저를 찾을 수 있는 다른 방법들은 다음과 같습니다. 소셜: 저는 주로 링크드인(LinkedIn)에 있지만, 마스토돈(Mastodon), 블루스카이(Bluesky), 그리고 X에도 있습니다. 팟캐스팅(Podcasting): 저는 EPFL AI 센터(Center)에서 "Inside AI"라는 AI 팟캐스트(podcast)를 진행하고 있으며 (애플 팟캐스트(Apple Podcasts), 스포티파이(Spotify)), 저보다 훨씬 똑똑한 사람들과 이야기할 수 있는 특권을 누리고 있습니다. Engineering Prompts는 독자 지원 출판물입니다. 새로운 게시물을 받고 제 작업을 지원하려면 무료 또는 유료 구독자가 되는 것을 고려해 보세요. 독립적인 기술 콘텐츠의 지속적인 생산을 위해 여러분의 지지와 관심은 큰 힘이 됩니다. 구독하기