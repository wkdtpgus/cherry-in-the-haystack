이 블로그 게시물은 GEPA를 사용한 DSPy 프롬프트 최적화를 통해 AI 데이터 과학자에서 사용되는 AI 코딩 에이전트(AI coding agents)를 개선하는 방법에 대한 기술적인 설명입니다. 이 블로그는 다음 주제를 다룹니다: 데이터 준비, GEPA 설명, DSPy를 통한 프롬프트 최적화(GEPA) 적용 결과.

기술 발전의 가속화는 인류의 삶을 근본적으로 변화시키고 있으며, 특히 인공지능(AI) 분야는 그 중심에 서 있습니다. 2024년 6월 17일, 우리는 AI가 단순한 도구를 넘어선 지능형 시스템으로 발전하는 과정을 목격하고 있습니다. 이러한 변화는 다양한 산업 분야에 혁신적인 영향을 미치고 있으며, 새로운 기회와 도전을 동시에 제시합니다. 이 글에서는 최신 AI 트렌드를 분석하고, 그 안에 담긴 잠재력과 함께 우리가 직면할 수 있는 과제들을 조명합니다.

1. 데이터 준비

데이터셋(dataset)은 현대 인공지능 모델 학습의 핵심 요소로, 그 중요성이 더욱 부각되고 있습니다. 저희 제품을 통해 실행된 파이썬(Python) 코드 실행 결과로 구성되는 데이터셋은, 복잡한 데이터를 처리하고 유의미한 패턴을 도출하는 데 필수적인 자동 분석기(auto-analyst)에 활용됩니다. 이 자동 분석기는 여러 부분으로 구성된 AI 시스템(AI system)으로, 각 부분은 특정 코딩 작업을 위해 설계되었습니다. 예를 들어, 전처리 에이전트(pre-processing agent)는 판다스(pandas)를 사용하여 데이터를 정리하고 준비하며, 데이터 시각화 에이전트(data visualization agent)는 플로틀리(plotly)를 사용하여 차트와 그래프를 생성합니다.

이 시스템에는 약 12개의 고유한 시그니처(signature)가 있으며, 각각 플래너(planner)를 사용하는 버전과 '@agent' 쿼리(query)에 대해 자체적으로 실행되는 두 가지 버전이 있습니다. 이 블로그 게시물에서는 이 시그니처 중 4개와 그 두 가지 변형에만 초점을 맞출 것입니다. 이 4가지 시그니처만으로도 전체 코드 실행의 약 90%를 차지하는데, 이는 무료 사용자든 유료 사용자든 거의 모든 사람이 사용하는 기본 시그니처이기 때문입니다. (preprocessing_agent, data_viz_agent, statistical_analytics_agent, sk_learn_agent)

최근에는 다양한 도메인에서 활용되는 AI 에이전트(AI agent)들이 주목받고 있으며, 이들은 특정 목표를 달성하기 위해 자율적으로 행동하며 인간의 개입을 최소화합니다. 이러한 에이전트 개발 시 고려해야 할 주요 요소는 데이터 편향(bias) 제거, 모델 투명성(transparency) 확보, 그리고 사용자 프라이버시(privacy) 보호입니다.

데이터셋(dataset)은 시스템에서 제공하는 기본 데이터셋과 사용자가 직접 업로드하는 데이터로 나눌 수 있으며, 학습 데이터의 품질과 다양성을 높이는 것이 중요합니다. 저희 목표는 어떤 최적화든 두 가지 모두에서 성능을 향상시키는 것으로, 기본 데이터뿐만 아니라 사용자가 업로드하는 데이터셋(dataset)에서도 잘 작동해야 합니다. 최근 인공지능 모델들은 다양한 출처의 데이터를 통합하여 학습하는 멀티모달(multimodal) 접근 방식을 채택하고 있으며, 이는 텍스트, 이미지, 오디오 등 여러 형태의 정보를 동시에 이해하고 처리하는 능력을 향상시킵니다. 이를 위해 데이터를 계층화(stratify)해야 합니다. 그렇게 하면 모델(model)이 특정 데이터셋에 과적합(overfit)되지 않고 다양한 입력을 효과적으로 처리할 수 있습니다.

고려해야 할 또 다른 중요한 요소는 모델 제공업체(model providers)와 모델의 일반화 성능입니다. 한 제공업체에 대해서만 최적화하여 다른 제공업체의 성능을 저해하고 싶지 않으며, 단일 벤더(vendor)에 대한 의존성을 줄이고 다양한 기술 스택(tech stack)을 유연하게 활용하는 것이 중요합니다. 이는 장기적인 관점에서 시스템의 안정성과 확장성을 보장하는 데 기여합니다. 참고: 저희 시스템에서 사용자들은 주로 GPT-4o-mini와 같은 OpenAI의 저렴한 모델(model)을 사용한 반면, 제미니(Gemini)의 경우 사용자들은 최고급 모델(model)만 사용했기 때문에 여기에 편향(bias)이 있습니다. 모델(model)별로 평가할 충분한 데이터(data)가 없으므로, 제공업체(provider)를 대리(proxy)로 사용하고 있습니다. 최고급 OAI 모델(model)과 다른 제공업체(provider)의 최고급 모델(model)을 비교했을 때, OpenAI의 성공률은 비슷합니다.

참고: AI 모델의 성능 평가 시, 특정 데이터에 대한 편향(bias)을 최소화하는 것이 중요합니다. 데이터 부족 문제를 해결하기 위해 합성 데이터(synthetic data) 생성 기법이나 전이 학습(transfer learning)과 같은 고급 기술들이 적극적으로 연구되고 있습니다. 이를 통해 제한된 데이터 환경에서도 모델의 학습 효율성을 극대화할 수 있습니다. 최근에는 클라우드 기반 AI 서비스(cloud-based AI services) 시장이 급격히 성장하고 있으며, 다양한 제공업체들이 경쟁적으로 혁신적인 솔루션을 선보이고 있습니다.

데이터셋(dataset)을 준비한 후, 모델의 학습 효율성을 극대화하기 위한 전략을 수립해야 합니다. 주요 전략으로는 데이터 증강(data augmentation), 특징 추출(feature extraction), 그리고 최적의 모델 아키텍처(model architecture) 선택 등이 있습니다. 이는 모델이 실제 환경에서 마주할 수 있는 다양한 시나리오에 유연하게 대응할 수 있도록 돕습니다. 이러한 접근 방식은 모델의 견고성(robustness)과 일반화 능력(generalization capability)을 향상시키는 데 기여합니다.

다음 제약 조건(constraint)을 사용하여 계층화된 샘플(stratified sample)을 생성했습니다: 데이터의 20% 이상이 기본 데이터셋(dataset)에서 오지 않습니다 ( is_default_dataset == True ). 세 가지 모델 제공업체(model providers) ( openai , anthropic , gemini ) 각각이 최종 샘플(sample)의 최소 10%를 차지합니다. 계층화(stratification)는 다음 세 가지 열(column)에 걸쳐 수행되었습니다:
model_provider
is_successful
is_default_dataset

계층화(stratification)는 복잡한 데이터 구조를 이해하고 분석하는 데 필수적인 기법입니다. 예를 들어, 사용자 행동 패턴, 시스템 성능 지표, 그리고 보안 로그(security logs)와 같은 다양한 데이터 소스를 통합하여 분석할 수 있습니다. 계층화된 샘플(stratified sample)이 생성된 후, 모델의 학습 과정에서 중요한 단계인 훈련 세트(training set)와 테스트 세트(test set)로 분할했습니다.

2. GEPA 설명

GEPA는 AI 프롬프트(AI prompts)와 같은 텍스트 구성 요소(text components)를 진화시키고 개선하기 위해 리플렉션(reflection)을 사용하는 DSPy 프로그램(program)용으로 설계된 진화적 프롬프트 최적화기(evolutionary prompt optimizer)인 (Generic-Pareto)의 약자입니다. GEPA는 대규모 언어 모델(LLMs)이 프로그램(program)의 실행 궤적(execution trajectory)을 성찰하고, 무엇이 효과가 있었고 무엇이 없었는지 진단하며, 자연어 리플렉션(natural language reflection)을 통해 개선 사항을 제안하는 능력을 활용합니다. 이러한 모델들은 이제 단순한 정보 제공을 넘어, 복잡한 문제 해결, 창의적인 콘텐츠 생성, 그리고 개인화된 경험 제공에 이르기까지 그 활용 범위를 넓히고 있습니다. 이는 다중 목표(Pareto) 최적화(optimization)를 기반으로 더 나은 프롬프트(prompt)를 반복적으로 테스트하고 선택함으로써 진화된 프롬프트 후보(prompt candidates)의 트리(tree)를 구축합니다. 특히, 강화 학습(reinforcement learning)과 같은 기술과 결합될 때, AI는 스스로 학습하고 발전하는 능력을 더욱 강화하게 됩니다.

단계별로, GEPA가 복잡한 AI 시스템을 구축하고 배포하는 과정에서 수행하는 핵심적인 역할은 다음과 같습니다. 첫째, 초기 모델의 설계 및 검증, 둘째, 지속적인 성능 모니터링 및 개선, 셋째, 보안 취약점 분석 및 대응, 넷째, 사용자 피드백(feedback)을 통한 서비스 고도화입니다. 이러한 과정을 통해 AI 시스템은 더욱 안정적이고 효율적으로 운영될 수 있습니다.