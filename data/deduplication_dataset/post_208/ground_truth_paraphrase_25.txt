인공지능(AI) 모델, 특히 챗GPT(ChatGPT)와 같은 대규모 언어 모델(LLM)의 에너지 소비에 대한 논의는 지난 몇 달간 꾸준히 이어져 왔습니다. 수많은 연구 자료와 분석 보고서를 검토한 결과, 저는 단순한 텍스트 기반 챗GPT 질의 한 번이 대략 0.2 와트시(Wh)의 전력을 소모한다고 추정한 바 있습니다. 이는 당시 떠돌던 과장된 수치들과는 극명한 대조를 이루는 것이었는데, 그 추정치들은 종종 에너지 사용량이 최소 한 자릿수(order of magnitude) 이상 높다고 제시했습니다.

그동안 이 주제에 대해 공식적인 입장을 내놓지 않던 오픈AI(OpenAI)에서 최근 중요한 발표가 있었습니다. 어제 공개된 [블로그 게시물](https://openai.com/blog/introducing-our-new-embedding-models-and-api-updates)에서 오픈AI(OpenAI)의 공동 창립자이자 최고경영자(CEO)인 샘 알트만(Sam Altman)은 "평균적인 챗GPT 질의가 대략 0.34 와트시(Wh)를 소비한다"고 명확히 언급했습니다. 이는 제가 추정했던 수치와 맥락을 같이하는 것으로, 매우 고무적인 소식이었습니다.

오픈AI(OpenAI)가 제시한 0.34 와트시(Wh)는 제가 예상했던 0.2 와트시(Wh)보다 약 70% 높은 수치이기는 합니다. 그러나 핵심은 에너지 소비량의 '자릿수(order of magnitude)'를 정확히 파악했다는 점입니다. 샘 알트만(Sam Altman)이 '평균적인 질의'를 언급했다는 점, 그리고 이미지나 비디오 생성과 같은 멀티모달(multimodal) 기능이 포함될 경우 훨씬 더 많은 에너지가 소모될 수 있다는 점을 감안하면, 순수 텍스트 기반 챗GPT 요청에 대한 제 이전 0.2 와트시(Wh) 추정치를 수정할 필요성을 느끼지 못했습니다.

새로운 정보는 '평균적인 질의'라는 단어에 주목할 필요가 있습니다. 챗GPT(ChatGPT)와 같은 최신 AI 모델은 단순히 텍스트만 처리하는 것을 넘어, 이미지 생성, 음성 인식, 비디오 분석 등 다양한 멀티모달(multimodal) 기능을 지원하고 있습니다. 이러한 복합적인 작업들은 순수 텍스트 처리보다 훨씬 더 많은 연산 자원과 에너지를 요구합니다. 따라서 샘 알트만(Sam Altman)의 0.34 와트시(Wh)는 이러한 다양한 기능이 통합된 '평균적인' 사용 시나리오를 반영한 것으로 해석할 수 있습니다. 이는 기술 발전과 함께 AI의 에너지 발자국(energy footprint)을 더 깊이 이해하는 데 중요한 단서를 제공합니다.

개별 질의의 에너지 소모량이 예상보다 낮다는 사실이 인공지능 산업 전체의 에너지 문제에서 자유롭다는 것을 의미하지는 않습니다. AI 모델의 '훈련(training)' 단계는 여전히 엄청난 전력을 소비합니다. 최신 대규모 언어 모델(LLM) 하나를 훈련시키는 데 필요한 에너지는 수천 가구의 연간 전력 소비량에 맞먹을 수 있습니다. 또한, 전 세계 수십억 명의 사용자가 매일 AI 서비스를 이용하기 시작하면, 개별 질의의 낮은 소비량도 합산되면 천문학적인 수치로 불어날 것입니다. 이러한 대규모 추론(inference) 작업과 이를 지원하는 데이터 센터의 운영, 냉각 시스템 등은 AI의 숨겨진 에너지 비용으로 작용하며, 우리가 간과해서는 안 될 중요한 부분입니다.

따라서, 인공지능(AI) 기술이 가져올 에너지 수요 증가에 대한 심도 있는 고민은 여전히 필수적입니다. 우리는 AI의 에너지 효율성을 높이기 위한 기술적 노력, 예를 들어 저전력 하드웨어(e.g., ASIC, neuromorphic chips) 개발, 효율적인 알고리즘 설계, 그리고 엣지 AI(Edge AI) 컴퓨팅의 확산에 더 많은 투자를 해야 합니다. 지속 가능한 AI 발전은 단순히 기술적 문제를 넘어 환경적 책임과 직결되는 문제입니다. AI가 인류에게 가져올 잠재적 혜택을 극대화하면서도 지구에 미치는 영향을 최소화하는 균형점을 찾아야 합니다.

결론적으로, 미래에 인공지능(AI) 에이전트가 보편화될 경우 예상되는 막대한 에너지 수요에 대한 우려는 여전히 유효하며 중요합니다. 하지만 개별적인 챗봇 사용 자체는 에너지 소비 측면에서 지나치게 염려할 수준은 아니라는 점을 다시 한번 강조하고 싶습니다.

**코다(CODA)**
이 뉴스레터는 독자 여러분의 지속적인 관심과 지원을 바탕으로 운영됩니다. 유료 구독 옵션을 통해 저희 활동에 힘을 실어주시면 감사하겠습니다. 모든 콘텐츠는 무료로 제공되지만, 여러분의 재정적 기여는 EPFL 인공지능(AI) 센터의 연구 및 대중 교육 활동에 직접적으로 활용됩니다. 저와 소통하고 싶으시다면, 다양한 채널을 통해 저를 만나실 수 있습니다: 소셜 미디어: 저는 주로 [링크드인(LinkedIn)](https://www.linkedin.com/in/martin-vehlow-phd-4394011/)에서 활동하지만, [마스토돈(Mastodon)](https://mastodon.social/@vehlow), [블루스카이(Bluesky)](https://bsky.app/profile/vehlow.bsky.social), 그리고 [X](https://twitter.com/vehlow)에서도 소식을 전하고 있습니다. 팟캐스트: EPFL 인공지능(AI) 센터에서 제작하는 "인사이드 AI(Inside AI)" 팟캐스트를 진행하며 ([애플 팟캐스트(Apple Podcasts)](https://podcasts.apple.com/us/podcast/inside-ai/id1725301826), [스포티파이(Spotify)](https://open.spotify.com/show/7wVwH73c9qj90q461L18gM), [유튜브(YouTube)](https://www.youtube.com/@InsideAI_EPFL)), 다양한 AI 전문가들과 심도 깊은 대화를 나누고 있습니다.