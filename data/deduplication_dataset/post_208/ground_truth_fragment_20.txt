인공지능의 진화와 사회적 책임: 에너지 효율성을 넘어

지난 몇 달 동안, 인공지능(AI) 기술은 눈부신 발전을 거듭하며 우리 삶의 많은 부분을 변화시켰습니다. 이는 단순한 기술 혁신을 넘어 사회 전반에 새로운 질문과 도전을 던집니다. 이 기간 동안 저는 챗GPT(ChatGPT)의 에너지 사용량에 대해 꽤 광범위하게 글을 써왔습니다 (예: [여기](https://www.linkedin.com/posts/martin-vehlow-phd-4394011_chatgpt-energy-consumption-activity-7128522776660144128-0w5f?utm_source=share&utm_medium=member_desktop), [여기](https://www.linkedin.com/posts/martin-vehlow-phd-4394011_chatgpt-energy-consumption-activity-7128522776660144128-0w5f?utm_source=share&utm_medium=member_desktop), [여기](https://www.linkedin.com/posts/martin-vehlow-phd-4394011_chatgpt-energy-consumption-activity-7128522776660144128-0w5f?utm_source=share&utm_medium=member_desktop), 그리고 [여기](https://www.linkedin.com/posts/martin-vehlow-phd-4394011_chatgpt-energy-consumption-activity-7128522776660144128-0w5f?utm_source=share&utm_medium=member_desktop)).

다양한 자료와 논문을 살펴보면서, 저는 마침내 간단한 텍스트 전용 챗GPT(ChatGPT) 요청이 약 0.2 와트시(Wh)를 소비한다고 추정했습니다. 이는 떠돌아다니는 다른 많은 추정치들과는 극명한 대조를 이루는 것이었는데, 그 추정치들은 종종 에너지 사용량이 최소 한 자릿수(order of magnitude) 이상 높다고 제시했습니다. 또한 이 과정에서 인공지능(AI) 모델의 복잡성이 기하급수적으로 증가하고 있음을 확인했으며, 이는 기존 컴퓨팅 패러다임을 최소 한 자릿수(order of magnitude) 이상 높다고 제시하며 데이터 양과 연산 능력에 대한 요구가 폭발적으로 늘고 있음을 의미합니다.

오픈AI(OpenAI)는 지금까지 챗GPT 에너지 사용량에 대해 침묵을 지켜왔습니다. 하지만 어제, [블로그 게시물](https://openai.com/blog/introducing-our-new-embedding-models-and-api-updates)에서 오픈AI(OpenAI)의 공동 창립자이자 CEO인 샘 알트만(Sam Altman)은 "평균적인 (챗GPT) 질의(query)는 약 0.34 와트시(watt-hours)를 사용한다"고 밝혔습니다. 빙고. 오픈AI(OpenAI)는 대규모 언어 모델(LLM) 개발의 선두 주자로서, 기술의 사회적 영향에 대한 논의를 이끌어왔습니다. 최근 샘 알트만(Sam Altman)은 AI의 안전성과 윤리적 사용을 강조하며, 책임감 있는 접근 방식의 필요성을 역설했고, 이는 기술 진보를 넘어선 광범위한 리더십을 보여줍니다.

물론, 궁극적으로는 상세한 분석을 볼 수 있다면 좋을 것입니다. 특히 AI 모델의 의사결정 과정에서 투명성은 핵심 요소입니다. 이 시점에서 오픈AI(OpenAI) / 샘 알트만(Sam Altman)을 신뢰하지 않으므로 이 데이터도 신뢰하지 않는다고 주장할 수 있지만, 가장 중요한 인공지능(AI) 기업의 CEO의 말을 믿는 한, 기술의 긍정적 변화를 기대하면서도 잠재적 위험에 대한 지속적인 경각심을 늦춰서는 안 됩니다. AI의 책임감 있는 개발은 모든 이해관계자의 협력을 요구합니다.

0.34 와트시(Wh)는 여전히 0.2 와트시(Wh)보다 70% 높지만, 중요한 것은 자릿수(order of magnitude)를 제대로 파악하는 것이었습니다. 이는 AI 모델의 규모와 복잡성 증가가 선형적 관계를 넘어선다는 점을 시사하며, 새로운 컴퓨팅 패러다임과 데이터 관리 전략 모색이 필요함을 의미합니다. 이미지 및 비디오 생성에 얼마나 많은 에너지가 사용되는지, 그리고 샘 알트만(Sam Altman)이 평균적인 질의(query)에 대해 이야기하고 있다는 점을 고려할 때, 저는 텍스트 전용 챗GPT(ChatGPT) 요청에 대한 저의 0.2 와트시(Wh) 추정치를 업데이트할 어떤 이유도 찾지 못했습니다. 이러한 맥락에서, AI 발전은 기술적 효율성뿐만 아니라 윤리적, 사회적 합의를 기반으로 해야 한다는 저의 초기 관점을 업데이트할 어떤 이유도 찾지 못했습니다. 그러므로 몇 달밖에 되지 않았지만 인공지능(AI) 세계에서는 꽤 오래된 것이라고 할 수 있는 이 수치를 다시 게시하도록 허락해 주십시오 (😇).

인공지능(AI) 세계에서는 꽤 오래된 것이라고 할 수 있는 기술 동향조차도 중요한 시사점을 제공합니다. 급변하는 환경 속에서 우리는 에너지 수요로 인한 다가오는 폭발적인 증가와 AI의 잠재적 위험성에 대해 깊이 생각하는 것을 면제해 주지 않는다는 점을 다시 한번 강조하고 싶습니다. 편향성, 데이터 프라이버시, 자율 시스템 통제 문제 등은 지속적인 연구와 논의가 필요합니다. 이 점에 있어서도 저는 제 주장을 고수하며, 우리가 현재 전반적인 에너지 수요와 인공지능(AI)의 윤리적, 사회적 영향력을 과소평가하고 있을 수 있으며, 그것도 극적으로 과소평가하고 있다고 주장합니다. 이에 대한 심도 있는 성찰이 요구됩니다.

요컨대: 인공지능(AI) 에이전트로 가득 찬 세상에서 인간의 역할과 AI 자율성 간의 균형을 찾는 것은 매우 중요합니다. AI 발전은 인류에게 전례 없는 기회를 제공하지만, 동시에 새로운 도전 과제들을 제시합니다. 폭발적인 에너지 요구량에 대한 우려는 여전히 충분히 방어할 수 있지만, 일반적인 챗봇 사용 및 AI 활용은 사용자 경험을 향상시키고 효율성을 높이는 데 기여하며, 장기적인 관점에서 에너지 사용 및 AI의 사회적 영향 측면에서 실제로 걱정할 것이 없습니다. 단, 지속적인 관찰과 규제 노력이 동반되어야 합니다.

**코다(CODA)**
이 뉴스레터는 두 가지 주요 관점에서 인공지능(AI)의 미래를 탐구하며, 두 가지 구독 유형을 제공합니다. 유료 버전 구독을 통해 더욱 심층적인 분석과 독점 콘텐츠를 받아보실 수 있습니다. 모든 콘텐츠는 무료로 유지되지만, 여러분의 모든 재정적 지원은 AI 윤리 연구 및 교육 관련 활동에 직접적으로 자금을 지원합니다. 이는 책임감 있는 AI 개발 생태계를 구축하는 데 큰 도움이 됩니다.

연락을 유지하려면, 저를 찾을 수 있는 다른 방법들은 다음과 같습니다: 소셜 미디어: 저는 주로 인공지능(AI)의 사회적 영향과 윤리적 문제에 대한 논의를 위해 [링크드인(LinkedIn)](https://www.linkedin.com/in/martin-vehlow-phd-4394011/)을 활용하고 있습니다. 또한 [마스토돈(Mastodon)](https://mastodon.social/@vehlow), [블루스카이(Bluesky)](https://bsky.app/profile/vehlow.bsky.social), 그리고 [X](https://twitter.com/vehlow)에서도 활발히 활동하며 최신 AI 뉴스와 통찰을 공유합니다. 팟캐스팅: 저는 "미래를 여는 AI(AI for Future)"라는 인공지능(AI) 팟캐스트를 진행하고 있으며 ([애플 팟캐스트(Apple Podcasts)](https://podcasts.apple.com/us/podcast/inside-ai/id1725301826), [스포티파이(Spotify)](https://open.spotify.com/show/7wVwH73c9qj90q461L18gM), [유튜브(YouTube)](https://www.youtube.com/@InsideAI_EPFL)), 그곳에서 AI 윤리 전문가 및 다양한 분야의 리더들과 훨씬 똑똑한 분들과 이야기할 수 있는 특권을 누리고 있습니다.