# **금주의 AI 에이전트**

Author: Pascal Biese
URL: https://www.llmwatch.com/p/ai-agents-of-the-week-ddf

============================================================

이번 주에는 메모리 시스템, 도구 사용, 계획, 다중 에이전트 협업, 그리고 자기 개선을 아우르는 분야의 획기적인 발전을 살펴보겠습니다. 연구자들은 장기 기억 및 동적 도구 선택을 가능하게 하는 것부터 조정 능력을 개선하고 에이전트가 즉석에서 학습할 수 있도록 하는 것에 이르기까지 오랜 난제들을 해결하고 있습니다. 주요 내용은 다음과 같습니다:

**동적 메모리 아키텍처(Dynamic Memory Architectures)**: A-Mem은 제텔카스텐(Zettelkasten) 방식으로 지식을 조직하고 새로운 정보를 과거 기억과 연결하여 에이전트의 이해를 지속적으로 개선하는 에이전트적 메모리 시스템을 도입합니다. 이 동적 메모리는 이전의 정적 메모리(static-memory) 기준선보다 뛰어난 성능을 보였으며, 오래 지속되고 상황을 인지하는 에이전트(context-aware agents)를 향한 한 걸음입니다.

**도구 능력 학습(Learning Tool Capabilities)**: TOOLMEM은 에이전트에게 다양한 AI 도구의 강점과 약점을 기록하는 "도구 능력 메모리(tool capability memory)"를 제공합니다. 어떤 도구가 어떤 시나리오에서 뛰어난지 기억함으로써, 에이전트는 작업에 적합한 도구를 선택하여 작업 성능을 향상시켰습니다. 이는 도구를 사용하는 자율 시스템(autonomous systems)에 있어 중요한 발전입니다.

**기호 계획 통합(Integrating Symbolic Planning)**: 복잡한 작업에서 LLM 에이전트(LLM agents)의 오류를 줄이기 위해 Agent+P는 신경망(neural) 및 기호(symbolic) 접근 방식을 결합합니다. 학습된 UI 그래프(UI graph)에 기호 계획기(symbolic planner)를 사용하여 LLM 기반 사용자 인터페이스 에이전트(user interface agent)를 안내함으로써, 성공률을 최대 14% 높이고 불필요한 단계를 약 38% 줄였습니다. 이는 자율 에이전트(autonomous agents)를 올바른 방향으로 유지하는 데 있어 구조화된 계획(structured planning)의 힘을 보여줍니다.

**다중 에이전트 협업 프레임워크(Multi-Agent Collaboration Frameworks)**: 엄격한 중앙 통제 없이 여러 AI 에이전트가 함께 작업할 수 있도록 하는 새로운 패러다임이 등장하고 있습니다. 블랙보드 아키텍처(blackboard architecture)는 에이전트가 공유 보드에 정보를 게시하고 검색할 수 있도록 하며, 전문 지식(expertise)에 따라 자발적으로 작업을 수행하게 합니다. 이는 기존의 "마스터-슬레이브(master-slave)" 방식보다 13~57% 더 나은 작업 성공률을 보였습니다. 한편, ALMAS 프레임워크(ALMAS framework)는 자율적인 LLM 에이전트(autonomous LLM agents)가 소프트웨어 엔지니어링 팀에서 전문적인 역할을 맡아 전체 프로젝트 수명 주기(project lifecycle)를 처리하기 위해 협력하는 것을 구상합니다.

**구조화된 자기 개선(Structured Self-Improvement)**: 연구자들은 자신의 실수로부터 학습하는 에이전트를 탐구했습니다. 에이전트 컨텍스트 엔지니어링(Agentic Context Engineering, ACE)은 에이전트의 프롬프트 컨텍스트(prompt context)를 진화하는 플레이북(playbook)으로 취급하여, 각 상호작용(interaction)을 통해 전략을 성장시키고 개선함으로써 "컨텍스트 붕괴(context collapse)" 및 간결성 편향(brevity bias)을 피합니다. ACE는 더 낮은 비용으로 에이전트 벤치마크(agent benchmarks)에서 10.6% 더 높은 성공률을 달성했으며, 심지어 더 작은 모델을 사용하여 GPT-4 수준의 에이전트와 동등한 성능을 보였습니다. 이를 보완하여, 테스트 시간 자기 개선(Test-Time Self-Improvement, TT-SI) 방법은 에이전트가 실패를 식별하고 즉석에서 새로운 훈련 예시(training examples)를 생성하여 스스로를 미세 조정(fine-tune)할 수 있도록 합니다. 이를 통해 아주 적은 양의 데이터로도 정확도를 약 5.5% 향상시켰습니다.

아래 글에서는 이러한 각각의 발전을 자세히 살펴보겠습니다. 즉, 핵심 혁신, 자율 AI(autonomous AI)에 중요한 이유, 해결하는 문제, 그리고 에이전트적 AI(agentic AI)의 미래에 어떤 의미를 가지는지에 대해 다룹니다.