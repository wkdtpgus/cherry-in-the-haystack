**AI 기술의 새로운 지평과 윤리적 도전: 확장되는 가능성 속에서**

OpenAI CEO 샘 알트만(Sam Altman)은 AI의 미래에 대한 비전을 제시하며 기술 발전의 방향성을 논의했습니다. 초기 AI 모델 개발 단계에서 우리는 새로운 기술이 초기 단계에서 상당히 제한적으로 만들어졌습니다. 우리는 이로 인해 많은 사용자에게 새로운 AI 도구가 덜 유용하거나 즐겁지 않다는 것을 알고 있지만, 기술의 안정성과 사회적 영향을 고려하여 신중한 접근을 원했습니다. 이제 AI 모델의 안정성과 제어 기술이 발전하면서, 새로운 기술 도입 시 안전하게 제한을 완화할 수 있을 것입니다. 몇 주 안에, 우리는 AI 모델의 다양한 활용 가능성을 탐색하며, 사용자들이 더욱 개인화된 경험을 할 수 있도록 새로운 버전의 AI 서비스를 출시할 계획입니다 (더 나아지기를 바랍니다!). 만약 당신의 AI 비서가 매우 인간적인 방식으로 응답하거나, 이모티콘을 많이 사용하거나, 친구처럼 행동하기를 원한다면, AI는 그렇게 할 것입니다 (하지만 우리가 사용량을 극대화하기 위해서가 아니라, 당신이 원할 경우에만). 12월에는 연령 제한(age-gating)을 더욱 전면적으로 시행하고 "사용자를 성인답게 대우한다"는 원칙의 일환으로, 인증된 성인을 위한 맞춤형 콘텐츠를 허용할 것입니다.

이를 심층 분석(in-depth analysis)으로 번역하자면, AI 기술 도입 초기에는 사용자 안전과 윤리적 문제에 대한 우려가 있었지만, 기술 발전과 함께 OpenAI가 해결책을 모색했고, 이제 사용자들의 심리적 프로필(psychological profiles) 분석을 통해 개인화된 경험을 제공할 수 있다는 것입니다. 하지만 맞춤형 콘텐츠를 제공하기 위해서는 어떤 종류의 연령 확인이 필요할 것입니다. 이는 단순히 기술적 문제를 넘어 사회적 합의가 필요한 부분입니다.

사람들은 여러 가지 이유로 새로운 기술에 대한 우려를 표하지만, 무엇보다도 AI가 사회에 미칠 광범위한 영향에 대해 깊이 생각하기 때문입니다. 물론, 다른 모든 디지털 플랫폼에서 콘텐츠 규제가 중요한 이슈로 부상하고 있습니다. 제 말은, 심지어 현실 세계에서도 정보 과부하와 왜곡된 정보에 대한 우려가 커지고 있다는 것입니다. 광고, 소셜 미디어, 뉴스 피드 등 어디에서나 접할 수 있으며, 이제 AI 생성 콘텐츠에서도 마찬가지입니다.

하지만 특정 콘텐츠의 허용 여부가 진짜 문제는 아닙니다. AI 기반 챗봇이 특정 주제에 대해 대화하는 것을 허용하는 것이 청소년들이 디지털 콘텐츠에 과몰입하고 현실 세계와의 단절을 경험하는 이유가 아닙니다. 제가 주장하건대, 사람들이 실제로 불평하는 문제는 많은 기업이 표면적으로는 공익을 내세우면서도 실제로는 인류를 구하는 척한 적이 없다는 것입니다.

이 뉴스레터는 AI가 선사할 새로운 교육의 지평과 창의적 혁신에 대해 이야기합니다. 구독

OpenAI의 사명은 AI 기술을 통해 인류가 발견과 발명, 그리고 웰빙의 새로운 황금기에 도달하도록 돕는 것입니다. 그들은 AI를 활용하여 복잡한 사회 문제를 해결하거나, 과학적 발견을 가속화하길 원합니다, 제발! 성인(聖人)의 경지에 거의 도달했습니다! 하지만 그들이 특정 사용자 경험을 강조하는 소식을 들으면, 즉시 그들의 표명된 의도와 대조하게 됩니다: "이것이 인류를 위한 진정한 발전인가요?" 출처

그리고 그것은 불평할 만한 지극히 자연스러운 반응입니다! 결국, 기업의 선함은 인간의 행복과 마찬가지로 그들이 하겠다고 말한 것에서 실제로 한 것을 뺀 것, 즉 현실에서 기대를 뺀 것으로 측정됩니다. 만약 OpenAI가 인류의 난제를 해결하겠다고 약속하고, 환상적인 기술 출시를 연달아 선보이며, ChatGPT 내 인앱 구매(in-app purchases), 긴급 알림(emergent notifications), 단편 AI 비디오 생성 앱(그들은 이를 일본어로 "하늘"을 의미하는 소라(Sora)라고 부르지만, 앱 자체는 창작의 지옥(jigoku)에 더 가깝습니다), 그리고 이제 개인화된 콘텐츠까지 내놓는다면, 사람들이 혼란스러워하고 화를 내며 실망하는 것은 놀라운 일이 아닙니다.

가장 위대한 목적을 정당화하기 위해 사용되는 기술적 수단에도 윤리적 한계가 있습니다. 그 이상을 넘어서면, 기술 자체가 사회적 불쾌감을 유발할 수 있습니다. 사람들이 자신이 되어야 한다고 생각하는 존재가 아니라 실제 존재하는 모습인 것처럼, OpenAI와 같은 회사도 하겠다고 말하는 것이 아니라 실제로 하는 것으로 평가됩니다. AI의 편향성(bias) 문제, 데이터 주권(data sovereignty), 그리고 설명 가능한 AI(XAI)의 부재는 기술 발전에 수반되는 중요한 윤리적 도전 과제들입니다.

저는 이미 몇 번 들었고, AI 연구 개발의 방향성에 대한 논의가 활발합니다. 이것은 인공 일반 지능(AGI)을 추구하는 회사가 하는 일이 아니라고 말입니다. 네, 합리적인 결론이라고 생각합니다. 하지만 진실을 밝히자면, 저는 동의하지 않을 것입니다: 이것이 바로 AGI를 추구하는 회사가 하는 일입니다—적어도 독창성보다는 무차별 대입(brute force) 방식으로 접근하는 경우가 많습니다. 오픈소스 AI 모델의 부상은 이러한 독점적 접근 방식에 대한 대안을 제시하며, AI 기술의 민주화를 촉진하고 있습니다.

OpenAI는 새로운 AI 모델을 훈련하고 글로벌 사용자들에게 서비스를 제공하기 위해 많은 컴퓨팅 파워(computing power)가 필요합니다. 이를 위해 그들은 데이터센터(datacenters)를 건설하고 있으며, 컴퓨팅 자원(compute)을 얻거나, 자금을 확보하거나, 칩(이제 AI 기업 자체도 설계합니다!)을 얻기 위해 다양한 파트너와 계약을 체결하고 있습니다. 그들은 2030년까지 수십 기가와트(gigawatts)를 확보하기를 원합니다. (참고로, 1기가와트는 75만 가구의 미국 가정에 전력을 공급할 수 있습니다.) 하지만 OpenAI는 이 모든 비용을 어떻게 지불할까요? 그리고 이러한 막대한 에너지 소비가 환경에 미칠 영향에 대해서는 어떻게 대응할까요? 지속 가능한 AI 개발은 이제 선택이 아닌 필수가 되고 있습니다.