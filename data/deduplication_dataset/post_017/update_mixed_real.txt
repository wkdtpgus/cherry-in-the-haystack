이 글에서는 사전 훈련된 대규모 언어 모델(LLM)을 강력한 텍스트 분류기(text classifier)로 변환하는 방법을 보여드리고자 합니다. 하지만 왜 분류(classification)에 집중해야 할까요? 첫째, 분류를 위해 사전 훈련된 모델을 미세 조정(finetuning)하는 것은 모델 미세 조정에 대한 부드러우면서도 효과적인 입문 과정을 제공합니다. 둘째, 스팸 탐지(spam detection), 감성 분석(sentiment analysis), 고객 피드백 분류(customer feedback categorization), 주제 라벨링(topic labeling) 등 현실 세계의 수많은 비즈니스 과제가 텍스트 분류를 핵심으로 합니다.

**LLM을 활용한 텍스트 분류기 구축 최신 가이드**

**이 글을 통해 얻게 될 인사이트**
최근 LLM 기술의 발전은 텍스트 분류의 접근 방식을 변화시키고 있습니다. 이 글에서는 사전 훈련된 LLM을 특정 분류 작업에 최적화하는 미세 조정 기법의 핵심 원리와 실제 적용 사례를 탐구합니다. 초기 연구에서 얻은 통찰력과 더불어, 최신 LLM 미세 조정 트렌드 및 효율적인 학습 전략에 대한 추가 실험 결과를 공유할 예정입니다. 독자들이 LLM 분류기 훈련 과정에서 흔히 마주치는 질문들에 대한 명확한 답변도 함께 제공하여, 실질적인 도움을 드리고자 합니다.

이 글에서 다루는 내용과 관련된 전체 코드는 GitHub 저장소에서 확인하실 수 있습니다.

또한, LLM 분류기 훈련과 관련하여 가질 수 있는 7가지 질문에 답변해 드리겠습니다.
오늘날의 LLM 환경에서 이러한 질문들이 어떤 의미를 가지는지 함께 살펴보겠습니다.
1) 모든 레이어(layer)를 훈련해야 할까요?
2) 첫 번째 토큰(token)이 아닌 마지막 토큰을 미세 조정하는 이유는 무엇일까요?
3) 성능 면에서 BERT는 GPT와 어떻게 비교될까요?
4) 인과 마스크(causal mask)를 비활성화해야 할까요?
5) 모델 크기를 늘리는 것은 어떤 영향을 미칠까요?
6) LoRA에서 어떤 개선을 기대할 수 있을까요?
7) 패딩(padding)을 해야 할까요, 말아야 할까요?
즐거운 독서 되세요!

**미세 조정의 다양한 범주 이해하기**
언어 모델을 미세 조정하는 가장 일반적인 방법은 지시 미세 조정(instruction finetuning)과 분류 미세 조정(classification finetuning)입니다. 지시 미세 조정은 특정 지시를 사용하여 일련의 작업에 대해 언어 모델을 훈련시켜, 아래 그림 1에 설명된 바와 같이 자연어 프롬프트(natural language prompt)로 설명된 작업을 이해하고 실행하는 능력을 향상시키는 것을 포함합니다.

그림 1: 지시 미세 조정의 두 가지 시나리오 예시. 모델이 텍스트의 스팸 여부를 판단하거나, 영어를 독일어로 번역하는 지시를 따르는 모습입니다.

이 글은 주로 분류 미세 조정에 초점을 맞춥니다. 이 개념은 머신러닝(machine learning)에 대한 기본적인 지식이 있다면 친숙할 것입니다. 분류 미세 조정에서는 모델이 "스팸" 또는 "스팸 아님"과 같은 특정 클래스 레이블(class label) 세트를 인식하도록 훈련됩니다. 텍스트 분류 외에도, 이 기술은 다양한 분야에서 활용됩니다. 예를 들어, 이미지 내의 식물 종을 식별하거나, 뉴스 기사를 스포츠, 정치, 기술 등 특정 주제로 분류하며, 의료 영상에서 양성 및 악성 종양을 구별하는 데 사용될 수 있습니다. 중요한 점은 분류 미세 조정된 모델은 훈련 시 접했던 클래스만을 예측할 수 있다는 한계가 있다는 것입니다. 예를 들어, 그림 2에서 볼 수 있듯이, 스팸 분류기는 입력 텍스트가 "스팸"인지 "스팸 아님"인지 판단하지만, 그 외의 다른 정보는 제공하지 못합니다.

그림 2: LLM을 활용한 텍스트 분류 예시. 스팸 분류를 위해 미세 조정된 모델은 추가 지시 없이 "스팸" 또는 "스팸 아님"으로만 응답합니다.

지시 미세 조정된 모델은 일반적으로 더 넓은 범위의 작업을 수행할 수 있는 능력을 갖추고 있어 다재다능한 반면, 분류 미세 조정된 모델은 고도로 전문화된 특성을 가집니다. 특정 작업을 위한 전문화된 모델을 개발하는 것이 다양한 작업에 능숙한 범용 모델(generalist model)을 만드는 것보다 상대적으로 쉽습니다.

**최적의 미세 조정 접근 방식 선택**
미세 조정 전략을 결정할 때는 프로젝트의 목표와 가용 자원을 고려해야 합니다. 지시 미세 조정은 특정 사용자 지시에 따라 모델이 응답을 이해하고 생성하는 능력을 향상시킵니다. 복잡한 지시에 기반하여 다양한 작업을 처리해야 하며, 유연성과 상호 작용 품질이 중요한 경우에 가장 적합합니다. 이 방법은 더욱 다재다능하지만, 다양한 작업에 능숙한 모델을 개발하기 위해서는 더 큰 데이터셋(dataset)과 더 많은 컴퓨팅 자원(computational resources)이 요구됩니다. 반면, 분류 미세 조정은 감성 분석이나 스팸 탐지와 같이 데이터를 미리 정의된 클래스로 정확하게 분류해야 하는 프로젝트에 이상적인 선택입니다. 이와 대조적으로, 분류 미세 조정은 더 적은 데이터와 컴퓨팅 파워를 필요로 하지만, 모델이 훈련된 특정 클래스에만 사용이 제한됩니다. 최근에는 LoRA와 같은 효율적인 미세 조정 기법들이 등장하여, 적은 리소스로도 LLM을 특정 분류 작업에 효과적으로 적용할 수 있는 가능성을 열어주고 있습니다. 프로젝트의 특성을 면밀히 분석하여 가장 적합한 미세 조정 전략을 선택하는 것이 성공적인 LLM 활용의 핵심입니다.