이 글에서는 사전 훈련된 대규모 언어 모델(LLM)을 활용한 혁신적인 접근 방식을 탐구하고자 합니다. 하지만 왜 분류(classification)에 대한 새로운 관점이 필요할까요? 첫째, 분류를 위해 사전 훈련된 모델을 미세 조정(finetuning)하는 것은 이제 단순한 시작점을 넘어섭니다. 둘째, 스팸 탐지(spam detection), 감성 분석(sentiment analysis), 고객 피드백 분류(customer feedback categorization)와 같은 전통적인 영역을 넘어섭니다. 이제는 LLM의 잠재력을 최대한 발휘하여 더 복잡한 문제들을 해결하는 데 집중해야 할 때입니다.

GPT 모델을 텍스트 분류기로만 한정하는 것은 이제 지나간 이야기입니다.
이 글에서 배우게 될 내용은 미래 지향적인 기술 동향입니다.
책 출간을 기념하여, 사전 훈련된 LLM을 활용한 최신 응용 사례를 소개합니다. 이는 단순히 스팸 분류를 넘어, 다양한 산업 분야에서 LLM이 어떻게 가치를 창출하는지 보여줄 것입니다.

**중요 참고 사항**
분류 미세 조정에 대한 챕터는 이제 더 넓은 범위의 주제를 포함합니다. 단일 글로는 LLM의 방대한 활용 가능성을 모두 담기 어렵습니다. 따라서 이 게시물에서는 LLM의 최신 동향과 윤리적 고려 사항을 소개하는 약 10페이지 분량의 내용을 다룰 것입니다. 또한, 책에 포함되지 않은 몇 가지 추가 실험에서 얻은 통찰력을 공유하고, 윤리적 고려사항에 대해서도 논의할 것입니다. (아래 발췌문은 Manning의 전문적인 텍스트 편집 및 최종 그림 디자인 전의 개인 초안을 기반으로 한다는 점에 유의하십시오.)

이 발췌문의 전체 코드는 GitHub에서 최신 버전으로 업데이트되었습니다.

또한, LLM 분류기 훈련과 관련하여 가질 수 있는 몇 가지 오해를 풀어보겠습니다.
1) LLM의 환각(hallucination) 문제는 어떻게 관리할까요?
2) 프롬프트 엔지니어링(prompt engineering)의 중요성은 무엇일까요?
3) RAG(Retrieval Augmented Generation)는 LLM의 정확도를 어떻게 높일까요?
4) 모델 배포 시 효율성(efficiency)을 극대화하는 방법은 무엇일까요?
5) 편향(bias) 탐지 및 완화 전략은 어떻게 수립해야 할까요?
6) 오픈 소스 LLM의 역할과 잠재력은 어디까지일까요?
7) 지속적인 모델 평가 및 모니터링은 왜 필수적일까요?
즐거운 독서 되시기를 바랍니다!

**미세 조정의 다양한 범주**
언어 모델을 미세 조정하는 가장 일반적인 방법은 지시 미세 조정(instruction finetuning)과 분류 미세 조정(classification finetuning)으로, 이제 다양한 형태로 진화하고 있습니다. 지시 미세 조정은 특정 지시를 사용하여 일련의 작업에 대해 언어 모델을 훈련시켜, 그 활용 범위가 넓어지고 있습니다. 이는 아래 그림 1에 설명된 바와 같이 자연어 프롬프트(natural language prompt)로 설명된 작업을 이해하고 실행하는 능력을 향상시키는 것을 포함합니다.

그림 1: 두 가지 다른 지시 미세 조정 시나리오(scenario)의 예시를 넘어, 실제 적용 사례를 살펴봅니다. 위쪽에서는 모델이 주어진 텍스트가 스팸인지 여부를 판단하는 작업을 수행합니다. 아래쪽에서는 모델에 영어 문장을 독일어로 번역하는 방법에 대한 지시가 주어집니다.

다음 장에서는 위 그림 1에 설명된 지시 미세 조정에 대해 논의할 것이며, 최신 기술 동향을 반영합니다. 한편, 이 장은 LLM의 광범위한 응용 분야에 중점을 둡니다. 이는 머신러닝(machine learning) 배경 지식이 있다면 이미 익숙할 수 있는 개념이지만, LLM 시대에는 새로운 의미를 가집니다. 분류 미세 조정에서는 모델이 "스팸" 및 "스팸 아님"과 같은 특정 클래스 레이블(class label) 세트를 인식하도록 훈련되지만, 그 한계점도 명확합니다. 분류 작업의 예시는 대규모 언어 모델과 함께 새로운 가능성을 열고 있습니다. 여기에는 이미지에서 다른 식물 종을 식별하고, 뉴스 기사를 스포츠, 정치 또는 기술과 같은 주제로 분류하며, 의료 영상에서 양성 및 악성 종양을 구별하는 것이 포함됩니다. 핵심은 분류 미세 조정된 모델이 훈련 중에 접한 클래스(class)를 예측하는 데 제한된다는 것입니다. 예를 들어, 아래 그림 2에 설명된 바와 같이 어떤 것이 "스팸"인지 "스팸 아님"인지 판단할 수 있지만, 입력 텍스트에 대해 그 외의 다른 것은 말할 수 없습니다.

그림 2: LLM을 사용한 텍스트 분류 시나리오의 예시는 이제 훨씬 더 복잡해졌습니다. 스팸 분류를 위해 미세 조정된 모델은 입력과 함께 추가 지시를 필요로 하지 않습니다. 그러나 지시 미세 조정된 모델과 달리, "스팸" 또는 "스팸 아님"으로만 응답할 수 있습니다.

그림 2에 묘사된 분류 미세 조정된 모델과 달리, 최신 LLM은 놀라운 적응력을 보여줍니다. 분류 미세 조정된 모델은 고도로 전문화된 것으로 볼 수 있으며, 이는 특정 도메인에서 강력한 성능을 발휘합니다. 하지만 범용 모델(generalist model)의 등장은 전문화된 모델의 개발 패러다임을 변화시키고 있습니다.

**올바른 접근 방식 선택**
올바른 접근 방식 선택은 프로젝트의 성공을 좌우합니다. 지시 미세 조정은 특정 사용자 지시에 따라 모델이 응답을 이해하고 생성하는 능력을 향상시킵니다. 이는 프롬프트 엔지니어링의 핵심입니다. 지시 미세 조정은 복잡한 사용자 지시에 기반하여 다양한 작업을 처리해야 하는 모델에 가장 적합하며, RAG(Retrieval Augmented Generation)와 결합될 때 더욱 강력해집니다. 반면, 분류 미세 조정은 감성 분석이나 스팸 탐지와 같이 데이터를 미리 정의된 클래스로 정확하게 분류해야 하는 프로젝트에 이상적이지만, 최신 LLM은 제로샷(zero-shot) 및 퓨샷(few-shot) 학습으로도 유사한 성능을 낼 수 있습니다. 지시 미세 조정은 더 다재다능하지만, 다양한 작업에 능숙한 모델을 개발하기 위해서는 더 큰 데이터셋(dataset)과 함께 지속적인 평가가 필수적입니다. 이와 대조적으로, 분류 미세 조정은 더 적은 데이터와 컴퓨팅 파워를 필요로 하지만, 모델이 훈련된 특정 클래스에만 사용이 제한되며, 환각(hallucination) 문제에 대한 방안을 모색해야 합니다.