이 글에서는 기존에 학습된 대규모 언어 모형(Large Language Model)을 뛰어난 텍스트 분류 장치로 탈바꿈시키는 과정을 보여드릴 것입니다. 하지만 왜 이 분류 작업에 초점을 맞춰야 할까요? 첫째, 분류 목적으로 미리 훈련된 모형을 세부 조정(finetuning)하는 것은 모형 세부 조정의 쉽고 효율적인 첫걸음을 제공합니다. 둘째, 스팸 식별, 감정 분석, 고객 의견 구분, 내용 분류 등 수많은 현실적이고 상업적인 난제들이 텍스트 분류를 핵심으로 삼고 있기 때문입니다. 정보 과부하의 시대에 텍스트 분류는 단순히 데이터를 정리하는 것을 넘어, 의미 있는 통찰을 추출하고 의사결정을 자동화하는 데 필수적인 도구가 되었습니다. 기존의 기계 학습 방식과 달리, 대규모 언어 모형은 훨씬 더 정교하고 유연한 분류 능력을 제공하며 새로운 가능성을 열고 있습니다.

GPT 계열 모델을 텍스트 분류 장치로 변모시키기
본 게시물에서 다룰 내용
저서 발행을 기념하여, 미리 학습된 대규모 언어 모형을 스팸 식별기로 세부 조정하는 방법을 설명하는 장의 일부 내용을 발췌하여 선보입니다. 이 책은 복잡한 대규모 언어 모형의 세계를 탐험하고 실제 문제에 적용하는 데 필요한 깊이 있는 지식을 제공하며, 이번 발췌문은 그 실용적 가치의 일면을 보여줄 것입니다.

**중요 안내 사항**
분류 세부 조정에 관한 해당 장은 총 35쪽에 달하여, 한 편의 글로 담기에는 분량이 과도합니다. 그리하여 본 게시물에서는 분류 세부 조정의 배경 지식과 핵심 원리를 소개하는 대략 10쪽 분량의 내용을 다룰 예정입니다. 더불어, 서적에 포함되지 않은 몇몇 추가 실험에서 얻은 심도 깊은 이해를 공유하고 독자 여러분이 궁금해할 만한 일반적인 의문점들에 해답을 제시할 것입니다. 이러한 추가 통찰력은 실제 모형 개발 과정에서 흔히 발생하는 함정들을 피하고 성능을 최적화하는 데 중요한 지침이 될 것입니다. (아래 제시된 발췌문은 Manning의 전문적인 문서 편집과 최종 시각 자료 설계 이전의 개인적인 초고를 바탕으로 작성되었음을 알려드립니다.)

본 발췌문에 대한 모든 구현 코드는 GitHub 저장소에서 확인하실 수 있습니다.

나아가, 대규모 언어 모형 분류기 학습과 관련하여 제기될 수 있는 일곱 가지 주요 질문에 대해 답해드리겠습니다.
1) 모든 층(layer)을 학습시켜야 할까요? (효율성과 성능 간의 균형을 어떻게 잡아야 할까요?)
2) 첫 번째 토큰(token)이 아닌 마지막 토큰을 세부 조정하는 이유는 무엇일까요? (시퀀스 내 정보 압축과 최종 표현의 중요성은 무엇일까요?)
3) 성능 면에서 BERT는 GPT와 어떻게 비교될까요? (양방향 모델과 단방향 모델의 근본적인 차이는 분류 성능에 어떤 영향을 미칠까요?)
4) 인과 마스크(causal mask)를 비활성화해야 할까요? (예측 방향성과 정보 흐름 제어가 분류 작업에 미치는 영향은 무엇일까요?)
5) 모형 크기를 늘리는 것은 어떤 영향을 미칠까요? (확장성의 장점과 더불어 발생할 수 있는 잠재적 함정은 무엇일까요?)
6) LoRA(Low-Rank Adaptation)에서 어떤 개선을 기대할 수 있을까요? (적은 파라미터로 효율적인 업데이트를 가능하게 하는 이 기법의 가치는 무엇일까요?)
7) 패딩(padding)을 해야 할까요, 말아야 할까요? (배치 처리 시 시퀀스 길이 불일치 문제를 어떻게 해결해야 할까요?)
이 글이 여러분의 지식 확장에 도움이 되기를 바랍니다!

**세부 조정의 다양한 범주**
언어 모형을 세부 조정하는 대표적인 접근 방식으로는 지시 세부 조정(instruction finetuning)과 분류 세부 조정(classification finetuning)이 있습니다. 지시 세부 조정은 특정 명령어를 활용하여 일련의 과업에 대해 언어 모형을 학습시켜, 하단의 그림 1에서 보이듯이 자연어 형태의 지시문(natural language prompt)으로 기술된 작업을 파악하고 수행하는 역량을 증진시키는 과정을 의미합니다. 이는 모형이 단순히 정보를 이해하는 것을 넘어, 사용자의 의도에 따라 적절한 응답을 생성하거나 특정 행동을 취하도록 유도하는 데 중점을 둡니다.

그림 1: 두 가지 상이한 지시 세부 조정 상황(scenario)의 본보기. 상단 예시에서 모형은 제시된 문구가 스팸인지 아닌지를 판별하는 과제를 수행합니다. 하단 예시에서는 모형에게 영문 문장을 독일어로 옮기는 방법에 대한 지시가 주어집니다. 이러한 예시는 지시 세부 조정이 얼마나 다양한 종류의 작업에 적용될 수 있는지를 보여주며, 단일 인터페이스를 통해 여러 작업을 처리하는 다중 작업 학습의 가능성을 시사합니다.

이어지는 다음 장에서는 상기 그림 1에 나타난 지시 세부 조정에 대해 깊이 있게 다룰 것입니다. 반면, 본 장에서는 분류 세부 조정에 핵심적으로 초점을 맞춥니다. 이는 기계 학습(machine learning)에 대한 사전 지식이 있는 분들에게는 이미 친숙한 개념일 수 있습니다. 분류 세부 조정 시에는 모형이 '스팸' 및 '스팸 아님'과 같은 명확한 범주 라벨(class label) 집합을 인지하도록 학습됩니다. 분류 작업의 적용 사례는 대규모 언어 모형과 전자우편 필터링의 범위를 넘어섭니다. 여기에는 사진 내 다양한 식물 품종 구분, 보도 기사를 스포츠, 정치, 기술 등의 주제로 분류, 그리고 의학 영상에서 양성 및 악성 종양 구별 등이 포함됩니다. 핵심은 분류 세부 조정된 모형이 학습 과정에서 마주한 범주(class)만을 예측하는 데 한정된다는 점입니다. 이는 모형이 특정 결정 경계에 최적화되어 일반적인 이해나 새로운 내용 생성보다는 정해진 범주 내에서의 정확한 판단에 집중하도록 설계되었기 때문입니다. 예를 들어, 하단의 그림 2에서 설명된 바와 같이 어떤 것이 '스팸'인지 '스팸 아님'인지는 판별할 수 있으나, 입력된 텍스트에 대해 그 외의 다른 정보는 제공할 수 없습니다.

그림 2: 대규모 언어 모형을 활용한 텍스트 분류 상황의 본보기. 스팸 구분을 위해 세부 조정된 모형은 입력과 더불어 별도의 지시 사항을 요구하지 않습니다. 하지만 지시 세부 조정된 모형과는 다르게, '스팸' 또는 '스팸 아님'으로만 응답할 수 있습니다. 이러한 분류 세부 조정은 특정 작업에 대해 매우 간결하고 효율적인 접근 방식을 제공하여, 해당 문제에 대한 높은 정확도를 달성할 수 있습니다.

그림 2에 나타난 분류 세부 조정 모형과 달리, 지시 세부 조정 모형은 대개 더 광범위한 과업들을 처리할 수 있는 역량을 지닙니다. 분류 세부 조정 모형은 매우 특화된 형태로 간주될 수 있으며, 통상적으로 다채로운 과업에서 우수한 성능을 보이는 범용 모형(generalist model)에 비해 특화된 모형을 개발하는 것이 더 용이합니다. 이는 전문화된 모형이 특정 니치(niche)에 대해 더 높은 정확도를 보일 수 있지만, 유연성 측면에서는 범용 모형에 비해 떨어진다는 트레이드오프(trade-off)를 의미합니다. 범용 모형은 다양한 작업을 처리할 수 있는 잠재력을 가지지만, 이를 개발하고 훈련하는 데 훨씬 더 많은 자원이 필요합니다.

**올바른 접근 방식 선택**
지시 세부 조정은 구체적인 사용자 명령에 따라 모형이 응답을 파악하고 만들어내는 역량을 증진시킵니다. 지시 세부 조정은 복잡한 사용자 명령을 바탕으로 다채로운 과업을 처리해야 하는 모형에 최적이며, 유연성과 상호작용의 질을 높이는 데 기여합니다. 이는 마치 다재다능한 비서처럼, 다양한 질문에 답하고 여러 종류의 요청을 처리할 수 있는 능력을 부여하는 것과 같습니다. 이에 반해, 분류 세부 조정은 감정 분석이나 스팸 식별처럼 데이터를 사전에 정의된 범주로 정확히 구분해야 하는 기획에 더할 나위 없이 적합합니다. 이는 특정 정보를 신속하고 정확하게 분류해야 하는 상황에서 강력한 성능을 발휘합니다.

지시 세부 조정은 더욱 다재다능하나, 여러 과업에 능숙한 모형을 구축하기 위해서는 더 방대한 데이터 집합(dataset)과 더 많은 계산 자원(computational resources)이 요구됩니다. 이와는 대조적으로, 분류 세부 조정은 더 적은 데이터와 계산 능력을 필요로 하지만, 모형이 학습된 특정 범주에만 활용이 국한됩니다. 결국, 어떤 접근 방식을 선택할지는 특정 응용 프로그램의 요구 사항, 즉 일반성 대 특수성의 균형과 예산 제약에 따라 달라집니다. 때로는 두 가지 접근 방식을 결합하거나, 특정 작업에 가장 적합한 방법을 혼합하여 사용하는 하이브리드 전략이 최적의 결과를 가져올 수도 있습니다. 미래에는 이러한 미세 조정 기법들이 더욱 발전하여, 특정 도메인에 특화된 효율적인 모형을 구축하는 길이 더욱 넓어질 것으로 기대됩니다.