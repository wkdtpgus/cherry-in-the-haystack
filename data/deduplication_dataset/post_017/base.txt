# **처음부터 GPT 스타일(GPT-Style) LLM 분류기(LLM classifier) 구축하기**

Author: Sebastian Raschka
URL: https://magazine.sebastianraschka.com/p/building-a-gpt-style-llm-classifier

============================================================

이 글에서는 사전 훈련된 대규모 언어 모델(LLM)을 강력한 텍스트 분류기(text classifier)로 변환하는 방법을 보여드리고자 합니다. 하지만 왜 분류(classification)에 집중해야 할까요? 첫째, 분류를 위해 사전 훈련된 모델을 미세 조정(finetuning)하는 것은 모델 미세 조정에 대한 부드러우면서도 효과적인 입문 과정을 제공합니다. 둘째, 스팸 탐지(spam detection), 감성 분석(sentiment analysis), 고객 피드백 분류(customer feedback categorization), 주제 라벨링(topic labeling) 등 많은 실제 및 비즈니스 과제가 텍스트 분류를 중심으로 전개됩니다.

GPT 모델을 텍스트 분류기로 전환하기
이 글에서 배우게 될 내용
책 출간을 기념하여, 사전 훈련된 LLM을 스팸 분류기로 미세 조정하는 방법을 안내하는 챕터 중 일부 발췌문을 공유합니다.

**중요 참고 사항**
분류 미세 조정에 대한 챕터는 35페이지로, 단일 글로는 너무 깁니다. 따라서 이 게시물에서는 분류 미세 조정의 배경과 핵심 개념을 소개하는 약 10페이지 분량의 내용을 다룰 것입니다. 또한, 책에 포함되지 않은 몇 가지 추가 실험에서 얻은 통찰력을 공유하고 독자들이 가질 수 있는 일반적인 질문에 답변할 것입니다. (아래 발췌문은 Manning의 전문적인 텍스트 편집 및 최종 그림 디자인 전의 개인 초안을 기반으로 한다는 점에 유의하십시오.)

이 발췌문의 전체 코드는 GitHub에서 찾을 수 있습니다.

또한, LLM 분류기 훈련과 관련하여 가질 수 있는 7가지 질문에 답변해 드리겠습니다.
1) 모든 레이어(layer)를 훈련해야 할까요?
2) 첫 번째 토큰(token)이 아닌 마지막 토큰을 미세 조정하는 이유는 무엇일까요?
3) 성능 면에서 BERT는 GPT와 어떻게 비교될까요?
4) 인과 마스크(causal mask)를 비활성화해야 할까요?
5) 모델 크기를 늘리는 것은 어떤 영향을 미칠까요?
6) LoRA에서 어떤 개선을 기대할 수 있을까요?
7) 패딩(padding)을 해야 할까요, 말아야 할까요?
즐거운 독서 되세요!

**미세 조정의 다양한 범주**
언어 모델을 미세 조정하는 가장 일반적인 방법은 지시 미세 조정(instruction finetuning)과 분류 미세 조정(classification finetuning)입니다. 지시 미세 조정은 특정 지시를 사용하여 일련의 작업에 대해 언어 모델을 훈련시켜, 아래 그림 1에 설명된 바와 같이 자연어 프롬프트(natural language prompt)로 설명된 작업을 이해하고 실행하는 능력을 향상시키는 것을 포함합니다.

그림 1: 두 가지 다른 지시 미세 조정 시나리오(scenario)의 예시. 위쪽에서는 모델이 주어진 텍스트가 스팸인지 여부를 판단하는 작업을 수행합니다. 아래쪽에서는 모델에 영어 문장을 독일어로 번역하는 방법에 대한 지시가 주어집니다.

다음 장에서는 위 그림 1에 설명된 지시 미세 조정에 대해 논의할 것입니다. 한편, 이 장은 분류 미세 조정에 중점을 둡니다. 이는 머신러닝(machine learning) 배경 지식이 있다면 이미 익숙할 수 있는 개념입니다. 분류 미세 조정에서는 모델이 "스팸" 및 "스팸 아님"과 같은 특정 클래스 레이블(class label) 세트를 인식하도록 훈련됩니다. 분류 작업의 예시는 대규모 언어 모델과 이메일 필터링을 넘어섭니다. 여기에는 이미지에서 다른 식물 종을 식별하고, 뉴스 기사를 스포츠, 정치 또는 기술과 같은 주제로 분류하며, 의료 영상에서 양성 및 악성 종양을 구별하는 것이 포함됩니다. 핵심은 분류 미세 조정된 모델이 훈련 중에 접한 클래스(class)를 예측하는 데 제한된다는 것입니다. 예를 들어, 아래 그림 2에 설명된 바와 같이 어떤 것이 "스팸"인지 "스팸 아님"인지 판단할 수 있지만, 입력 텍스트에 대해 그 외의 다른 것은 말할 수 없습니다.

그림 2: LLM을 사용한 텍스트 분류 시나리오의 예시. 스팸 분류를 위해 미세 조정된 모델은 입력과 함께 추가 지시를 필요로 하지 않습니다. 그러나 지시 미세 조정된 모델과 달리, "스팸" 또는 "스팸 아님"으로만 응답할 수 있습니다.

그림 2에 묘사된 분류 미세 조정된 모델과 달리, 지시 미세 조정된 모델은 일반적으로 더 넓은 범위의 작업을 수행할 수 있는 능력을 가집니다. 분류 미세 조정된 모델은 고도로 전문화된 것으로 볼 수 있으며, 일반적으로 다양한 작업에서 잘 작동하는 범용 모델(generalist model)보다 전문화된 모델을 개발하는 것이 더 쉽습니다.

**올바른 접근 방식 선택**
지시 미세 조정은 특정 사용자 지시에 따라 모델이 응답을 이해하고 생성하는 능력을 향상시킵니다. 지시 미세 조정은 복잡한 사용자 지시에 기반하여 다양한 작업을 처리해야 하는 모델에 가장 적합하며, 유연성과 상호 작용 품질을 향상시킵니다. 반면, 분류 미세 조정은 감성 분석이나 스팸 탐지와 같이 데이터를 미리 정의된 클래스로 정확하게 분류해야 하는 프로젝트에 이상적입니다. 지시 미세 조정은 더 다재다능하지만, 다양한 작업에 능숙한 모델을 개발하기 위해서는 더 큰 데이터셋(dataset)과 더 많은 컴퓨팅 자원(computational resources)이 필요합니다. 이와 대조적으로, 분류 미세 조정은 더 적은 데이터와 컴퓨팅 파워를 필요로 하지만, 모델이 훈련된 특정 클래스에만 사용이 제한됩니다.