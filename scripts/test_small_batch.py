#!/usr/bin/env python3
"""ì†Œê·œëª¨ ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ - 10í˜ì´ì§€ë§Œ"""

import sys
import os

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.pdf.parser import extract_pages_lazy, get_pdf_metadata
from src.pdf.chunker import split_paragraphs
from src.db.connection import get_session
from src.db.operations import create_book, get_book_by_title
from src.model.schemas import ParagraphChunk
from src.workflow.state import State
from src.workflow.nodes import extract_core_idea, save_to_database
from tqdm import tqdm


def test_batch(pdf_path: str, start_page: int = 100, num_pages: int = 10):
    """ì†Œê·œëª¨ ë°°ì¹˜ ì²˜ë¦¬"""

    print("=" * 80)
    print(f"ğŸ“‹ ì†Œê·œëª¨ ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ({num_pages}í˜ì´ì§€)")
    print("=" * 80)
    print(f"ğŸ“„ PDF: {pdf_path}")
    print(f"ğŸ“ í˜ì´ì§€: {start_page + 1} ~ {start_page + num_pages}")
    print(f"ğŸ’¾ DB: local_dev.db (SQLite)")
    print()

    session = get_session()

    try:
        # Book í™•ì¸/ìƒì„±
        metadata = get_pdf_metadata(pdf_path)
        book = get_book_by_title(session, metadata["title"])

        if not book:
            book = create_book(
                session,
                title=metadata["title"],
                author=metadata["author"],
                source_path=pdf_path,
                total_pages=metadata["total_pages"]
            )
            print(f"âœ… Book ìƒì„±: '{book.title}' (ID: {book.id})")
        else:
            print(f"âœ… Book ì‚¬ìš©: '{book.title}' (ID: {book.id})")

        # í†µê³„
        stats = {
            "total_pages": 0,
            "total_paragraphs": 0,
            "total_ideas": 0,
            "failed": 0,
        }

        # í˜ì´ì§€ ë²”ìœ„
        target_pages = set(range(start_page, start_page + num_pages))

        print(f"\nğŸš€ {num_pages}í˜ì´ì§€ ì²˜ë¦¬ ì‹œì‘...\n")

        # ì§„í–‰ë¥  í‘œì‹œ
        for page_num, page_text in tqdm(
            extract_pages_lazy(pdf_path),
            total=metadata["total_pages"],
            desc="Processing"
        ):
            if page_num not in target_pages:
                continue

            try:
                # ë¬¸ë‹¨ ë¶„ë¦¬
                paragraphs = split_paragraphs(page_text)

                if not paragraphs:
                    continue

                stats["total_pages"] += 1
                stats["total_paragraphs"] += len(paragraphs)

                # ê° ë¬¸ë‹¨ ì²˜ë¦¬
                for para_idx, para_text in enumerate(paragraphs):
                    chunk = ParagraphChunk(
                        page_number=page_num,
                        paragraph_index=para_idx,
                        body_text=para_text
                    )

                    state = State(
                        chunk=chunk,
                        book_id=book.id,
                        model_version="gemini-2.5-flash"
                    )

                    # LLM ì¶”ì¶œ
                    state = extract_core_idea(state)
                    if state.error:
                        stats["failed"] += 1
                        continue

                    # DB ì €ì¥
                    state = save_to_database(state)
                    if state.error:
                        stats["failed"] += 1
                        continue

                    stats["total_ideas"] += 1

            except Exception as e:
                print(f"\nâŒ í˜ì´ì§€ {page_num + 1} ì˜¤ë¥˜: {str(e)}")
                stats["failed"] += 1

        # ê²°ê³¼
        print("\n" + "=" * 80)
        print("âœ… ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ")
        print("=" * 80)
        print(f"ğŸ“š Book ID: {book.id}")
        print(f"ğŸ“„ ì²˜ë¦¬ í˜ì´ì§€: {stats['total_pages']}")
        print(f"ğŸ“ ì´ ë¬¸ë‹¨: {stats['total_paragraphs']}")
        print(f"ğŸ’¾ ì €ì¥ ì„±ê³µ: {stats['total_ideas']}")
        print(f"âŒ ì‹¤íŒ¨: {stats['failed']}")
        print("=" * 80)

        # DB í†µê³„
        from src.db.models import ParagraphChunk as DBChunk, KeyIdea

        total_chunks = session.query(DBChunk).filter_by(book_id=book.id).count()
        total_ideas = session.query(KeyIdea).filter_by(book_id=book.id).count()

        print(f"\nğŸ” ì „ì²´ DB í†µê³„:")
        print(f"  - paragraph_chunks: {total_chunks}ê°œ")
        print(f"  - key_ideas: {total_ideas}ê°œ")

    finally:
        session.close()


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="ì†Œê·œëª¨ ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸")
    parser.add_argument("--pdf", type=str, default="AI Engineering.pdf")
    parser.add_argument("--start", type=int, default=100, help="ì‹œì‘ í˜ì´ì§€ (0ë¶€í„°)")
    parser.add_argument("--count", type=int, default=10, help="ì²˜ë¦¬í•  í˜ì´ì§€ ìˆ˜")

    args = parser.parse_args()

    test_batch(args.pdf, args.start, args.count)
