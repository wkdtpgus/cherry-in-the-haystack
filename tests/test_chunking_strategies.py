#!/usr/bin/env python3
"""ë¬¸ë‹¨ ì²­í‚¹ ì „ëµ ì‹¤í—˜ ë° ë¹„êµ

ë‹¤ì–‘í•œ ì²­í‚¹ ì „ëµì„ í…ŒìŠ¤íŠ¸í•˜ì—¬ ìµœì ì˜ ë°©ë²• ì°¾ê¸°
"""

import sys
import os
import re
from typing import List, Dict

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.pdf.parser import extract_page_text


def strategy_current(text: str) -> List[str]:
    """í˜„ì¬ ì „ëµ: ì´ì¤‘ ê°œí–‰ ê¸°ë°˜"""
    MIN_LENGTH = 50
    MAX_LENGTH = 3000

    chunks = text.split("\n\n")
    chunks = [c.strip() for c in chunks if c.strip()]

    # Merge short chunks
    merged = []
    buffer = ""
    for chunk in chunks:
        normalized = re.sub(r"\s+", " ", chunk)
        if len(buffer) < MIN_LENGTH:
            buffer += " " + normalized if buffer else normalized
        else:
            merged.append(buffer)
            buffer = normalized
    if buffer and len(buffer) >= MIN_LENGTH:
        merged.append(buffer)

    # Split long chunks
    final = []
    for chunk in merged:
        if len(chunk) <= MAX_LENGTH:
            final.append(chunk)
        else:
            sentences = re.split(r"(?<=[.!?])\s+", chunk)
            current = ""
            for sent in sentences:
                if len(current) + len(sent) <= MAX_LENGTH:
                    current += (" " if current else "") + sent
                else:
                    if current:
                        final.append(current.strip())
                    current = sent
            if current:
                final.append(current.strip())

    return [c for c in final if len(c) >= MIN_LENGTH]


def strategy_single_newline(text: str) -> List[str]:
    """ì „ëµ 1: ë‹¨ì¼ ê°œí–‰ë„ ë¶„ë¦¬ ê¸°ì¤€"""
    MIN_LENGTH = 100
    MAX_LENGTH = 1500

    # Split by single newline
    chunks = text.split("\n")
    chunks = [c.strip() for c in chunks if c.strip()]

    # Merge until MIN_LENGTH
    merged = []
    buffer = ""
    for chunk in chunks:
        if len(buffer) == 0:
            buffer = chunk
        elif len(buffer) < MIN_LENGTH:
            buffer += " " + chunk
        else:
            merged.append(buffer)
            buffer = chunk
    if buffer and len(buffer) >= MIN_LENGTH:
        merged.append(buffer)

    # Split long chunks
    final = []
    for chunk in merged:
        if len(chunk) <= MAX_LENGTH:
            final.append(chunk)
        else:
            sentences = re.split(r"(?<=[.!?])\s+", chunk)
            current = ""
            for sent in sentences:
                if len(current) + len(sent) <= MAX_LENGTH:
                    current += (" " if current else "") + sent
                else:
                    if current:
                        final.append(current.strip())
                    current = sent
            if current:
                final.append(current.strip())

    return [c for c in final if len(c) >= MIN_LENGTH]


def strategy_sentence_count(text: str) -> List[str]:
    """ì „ëµ 2: ë¬¸ì¥ ê°œìˆ˜ ê¸°ë°˜ (5-10ë¬¸ì¥)"""
    MIN_SENTENCES = 3
    MAX_SENTENCES = 8
    MIN_LENGTH = 100

    # Normalize text
    normalized = re.sub(r"\s+", " ", text).strip()

    # Split into sentences
    sentences = re.split(r"(?<=[.!?])\s+", normalized)

    chunks = []
    current = []

    for sent in sentences:
        current.append(sent)

        if len(current) >= MIN_SENTENCES:
            chunk_text = " ".join(current)
            if len(current) >= MAX_SENTENCES or len(chunk_text) >= 1500:
                if len(chunk_text) >= MIN_LENGTH:
                    chunks.append(chunk_text)
                current = []

    # Last chunk
    if current:
        chunk_text = " ".join(current)
        if len(chunk_text) >= MIN_LENGTH:
            chunks.append(chunk_text)

    return chunks


def strategy_hybrid(text: str) -> List[str]:
    """ì „ëµ 3: í•˜ì´ë¸Œë¦¬ë“œ - ê°œí–‰ + ë¬¸ì¥ ìˆ˜ + ê¸¸ì´"""
    MIN_LENGTH = 150
    MAX_LENGTH = 1000
    TARGET_SENTENCES = 5

    # First split by double newlines (paragraphs)
    paragraphs = text.split("\n\n")

    chunks = []
    for para in paragraphs:
        para = para.strip()
        if not para:
            continue

        # Normalize whitespace
        normalized = re.sub(r"\s+", " ", para)

        # If paragraph is good size, keep it
        if MIN_LENGTH <= len(normalized) <= MAX_LENGTH:
            chunks.append(normalized)
        elif len(normalized) < MIN_LENGTH:
            # Too short - will merge later
            chunks.append(normalized)
        else:
            # Too long - split by sentences
            sentences = re.split(r"(?<=[.!?])\s+", normalized)
            current = []

            for sent in sentences:
                current.append(sent)
                chunk_text = " ".join(current)

                if len(current) >= TARGET_SENTENCES or len(chunk_text) >= MAX_LENGTH:
                    if len(chunk_text) >= MIN_LENGTH:
                        chunks.append(chunk_text)
                    current = []

            if current:
                chunk_text = " ".join(current)
                if len(chunk_text) >= MIN_LENGTH:
                    chunks.append(chunk_text)

    # Merge short chunks
    merged = []
    buffer = ""
    for chunk in chunks:
        if len(buffer) == 0:
            buffer = chunk
        elif len(buffer) < MIN_LENGTH:
            buffer += " " + chunk
        else:
            merged.append(buffer)
            buffer = chunk
    if buffer and len(buffer) >= MIN_LENGTH:
        merged.append(buffer)

    return merged


def strategy_smart_semantic(text: str) -> List[str]:
    """ì „ëµ 4: ìŠ¤ë§ˆíŠ¸ ì˜ë¯¸ ê¸°ë°˜ - ë¬¸ë‹¨ êµ¬ì¡° + ë¬¸ë§¥"""
    MIN_LENGTH = 200
    MAX_LENGTH = 800

    # Remove footnote numbers at start of lines
    text = re.sub(r'^\d+\s+', '', text, flags=re.MULTILINE)

    # Split by double newlines first
    blocks = text.split("\n\n")

    chunks = []
    for block in blocks:
        block = block.strip()
        if not block:
            continue

        # Normalize
        normalized = re.sub(r"\s+", " ", block)

        # Check if it's a short header/title (merge with next)
        if len(normalized) < 80 and not normalized.endswith(('.', '!', '?', ':')):
            chunks.append(("header", normalized))
            continue

        chunks.append(("content", normalized))

    # Merge headers with following content
    merged = []
    i = 0
    while i < len(chunks):
        chunk_type, chunk_text = chunks[i]

        if chunk_type == "header" and i + 1 < len(chunks):
            next_type, next_text = chunks[i + 1]
            merged.append(chunk_text + " " + next_text)
            i += 2
        else:
            merged.append(chunk_text)
            i += 1

    # Handle length constraints
    final = []
    buffer = ""

    for chunk in merged:
        if len(buffer) == 0:
            buffer = chunk
        elif len(buffer) < MIN_LENGTH:
            buffer += " " + chunk
        elif len(buffer) >= MIN_LENGTH and len(buffer) <= MAX_LENGTH:
            final.append(buffer)
            buffer = chunk
        else:
            # Buffer too long, split it
            sentences = re.split(r"(?<=[.!?])\s+", buffer)
            current = ""
            for sent in sentences:
                if len(current) + len(sent) <= MAX_LENGTH:
                    current += (" " if current else "") + sent
                else:
                    if current and len(current) >= MIN_LENGTH:
                        final.append(current.strip())
                    current = sent
            if current and len(current) >= MIN_LENGTH:
                final.append(current.strip())
            buffer = chunk

    if buffer and len(buffer) >= MIN_LENGTH:
        final.append(buffer)

    return final


def analyze_chunks(chunks: List[str], strategy_name: str) -> Dict:
    """ì²­í¬ ë¶„ì„"""
    if not chunks:
        return {
            "strategy": strategy_name,
            "count": 0,
            "avg_length": 0,
            "min_length": 0,
            "max_length": 0,
            "total_chars": 0,
        }

    lengths = [len(c) for c in chunks]

    return {
        "strategy": strategy_name,
        "count": len(chunks),
        "avg_length": sum(lengths) / len(lengths),
        "min_length": min(lengths),
        "max_length": max(lengths),
        "total_chars": sum(lengths),
    }


def print_comparison(results: List[Dict]):
    """ê²°ê³¼ ë¹„êµ ì¶œë ¥"""
    print("\n" + "="*100)
    print("ì²­í‚¹ ì „ëµ ë¹„êµ ê²°ê³¼")
    print("="*100)

    print(f"\n{'ì „ëµ':<25} {'ë¬¸ë‹¨ìˆ˜':>8} {'í‰ê· ê¸¸ì´':>10} {'ìµœì†Œ':>8} {'ìµœëŒ€':>8} {'ì´ê¸€ì':>10}")
    print("-"*100)

    for r in results:
        print(f"{r['strategy']:<25} {r['count']:>8} {r['avg_length']:>10.0f} {r['min_length']:>8} {r['max_length']:>8} {r['total_chars']:>10}")

    print("-"*100)


def show_samples(page_text: str, strategy_func, strategy_name: str, max_samples=3):
    """ìƒ˜í”Œ ì²­í¬ ë¯¸ë¦¬ë³´ê¸°"""
    chunks = strategy_func(page_text)

    print(f"\n{'='*100}")
    print(f"ğŸ“‹ {strategy_name} - ìƒ˜í”Œ ë¯¸ë¦¬ë³´ê¸°")
    print(f"{'='*100}")

    for idx, chunk in enumerate(chunks[:max_samples]):
        print(f"\n[ë¬¸ë‹¨ {idx+1}/{len(chunks)}] ({len(chunk)} ê¸€ì)")
        print("-"*100)
        preview = chunk[:200] + ("..." if len(chunk) > 200 else "")
        print(preview)


def main():
    """ë©”ì¸ ì‹¤í—˜"""
    import argparse

    parser = argparse.ArgumentParser(description="ì²­í‚¹ ì „ëµ ì‹¤í—˜")
    parser.add_argument("--pdf", type=str, default="AI Engineering.pdf")
    parser.add_argument("--page", type=int, default=100)
    parser.add_argument("--show-samples", action="store_true", help="ìƒ˜í”Œ ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ")

    args = parser.parse_args()

    print(f"\n{'='*100}")
    print(f"ğŸ“„ PDF: {args.pdf}, í˜ì´ì§€: {args.page + 1}")
    print(f"{'='*100}")

    # Extract page
    page_text = extract_page_text(args.pdf, args.page)
    print(f"\nì›ë³¸ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(page_text)} ê¸€ì")

    # Test strategies
    strategies = [
        (strategy_current, "í˜„ì¬ ì „ëµ (ì´ì¤‘ê°œí–‰)"),
        (strategy_single_newline, "ì „ëµ1: ë‹¨ì¼ê°œí–‰"),
        (strategy_sentence_count, "ì „ëµ2: ë¬¸ì¥ê°œìˆ˜ ê¸°ë°˜"),
        (strategy_hybrid, "ì „ëµ3: í•˜ì´ë¸Œë¦¬ë“œ"),
        (strategy_smart_semantic, "ì „ëµ4: ìŠ¤ë§ˆíŠ¸ ì˜ë¯¸ê¸°ë°˜"),
    ]

    results = []
    for func, name in strategies:
        chunks = func(page_text)
        stats = analyze_chunks(chunks, name)
        results.append(stats)

    # Compare
    print_comparison(results)

    # Show samples
    if args.show_samples:
        for func, name in strategies:
            show_samples(page_text, func, name, max_samples=2)

    # Recommendation
    print(f"\n{'='*100}")
    print("ğŸ’¡ ê¶Œì¥ì‚¬í•­")
    print(f"{'='*100}")

    # Find best strategy (good balance of count and length)
    valid_results = [r for r in results if r['count'] > 0]

    if valid_results:
        # ë¬¸ë‹¨ ìˆ˜ê°€ ì ì ˆí•˜ê³  (3-10ê°œ), í‰ê·  ê¸¸ì´ê°€ ì ë‹¹í•œ (300-700ì) ì „ëµ ì°¾ê¸°
        scored = []
        for r in valid_results:
            score = 0
            # Prefer 3-10 chunks
            if 3 <= r['count'] <= 10:
                score += 10
            elif r['count'] > 1:
                score += 5

            # Prefer avg length 300-700
            if 300 <= r['avg_length'] <= 700:
                score += 10
            elif 200 <= r['avg_length'] <= 1000:
                score += 5

            # Penalize too much variance
            if r['max_length'] - r['min_length'] < 800:
                score += 5

            scored.append((score, r))

        scored.sort(reverse=True, key=lambda x: x[0])
        best = scored[0][1]

        print(f"\nğŸ† ìµœì  ì „ëµ: {best['strategy']}")
        print(f"   - ë¬¸ë‹¨ ìˆ˜: {best['count']}")
        print(f"   - í‰ê·  ê¸¸ì´: {best['avg_length']:.0f} ê¸€ì")
        print(f"   - ë²”ìœ„: {best['min_length']}-{best['max_length']} ê¸€ì")
        print(f"\n   ì´ ì „ëµì´ ì ì ˆí•œ ë¬¸ë‹¨ ìˆ˜ì™€ ê¸¸ì´ì˜ ê· í˜•ì„ ì œê³µí•©ë‹ˆë‹¤.")

    print(f"\n{'='*100}\n")


if __name__ == "__main__":
    main()
