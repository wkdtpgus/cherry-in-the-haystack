#!/usr/bin/env python3
"""íŒŒì´í”„ë¼ì¸ ë¯¸ë¦¬ë³´ê¸° í…ŒìŠ¤íŠ¸ - DB ì €ì¥ ì „ ê° ë‹¨ê³„ í™•ì¸

PDF ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì˜ ê° ë‹¨ê³„ê°€ ì˜ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸:
1. PDF ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
2. í˜ì´ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ
3. ë¬¸ë‹¨ ë¶„ë¦¬
4. í•µì‹¬ ì•„ì´ë””ì–´ ì¶”ì¶œ (LLM)
"""

import sys
import os

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.pdf.parser import extract_page_text, get_pdf_metadata
from src.pdf.chunker import split_paragraphs, get_paragraph_stats
from src.model.schemas import ParagraphChunk
from src.workflow.state import State
from src.workflow.nodes import extract_core_idea


def print_section(title):
    """ì„¹ì…˜ êµ¬ë¶„ì„  ì¶œë ¥"""
    print(f"\n{'='*80}")
    print(f"{title}")
    print(f"{'='*80}\n")


def test_metadata(pdf_path):
    """1ë‹¨ê³„: PDF ë©”íƒ€ë°ì´í„° í™•ì¸"""
    print_section("1ï¸âƒ£  PDF ë©”íƒ€ë°ì´í„° í™•ì¸")

    metadata = get_pdf_metadata(pdf_path)

    print(f"ğŸ“š ì œëª©: {metadata['title']}")
    print(f"âœï¸  ì €ì: {metadata['author']}")
    print(f"ğŸ“„ ì´ í˜ì´ì§€: {metadata['total_pages']}")
    print(f"ğŸ› ï¸  ìƒì„± ë„êµ¬: {metadata['creator']}")
    print(f"ğŸ“¦ PDF ìƒì„±ê¸°: {metadata['producer']}")

    return metadata


def test_page_extraction(pdf_path, page_num=30):
    """2ë‹¨ê³„: í˜ì´ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ í™•ì¸"""
    print_section(f"2ï¸âƒ£  í˜ì´ì§€ {page_num+1} í…ìŠ¤íŠ¸ ì¶”ì¶œ í™•ì¸")

    page_text = extract_page_text(pdf_path, page_num)

    print(f"ğŸ“Š ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(page_text)} ê¸€ì")
    print(f"\nğŸ“ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 500ì):")
    print("-" * 80)
    print(page_text[:500])
    print("-" * 80)

    return page_text


def test_paragraph_splitting(page_text, show_full=False):
    """3ë‹¨ê³„: ë¬¸ë‹¨ ë¶„ë¦¬ í™•ì¸"""
    print_section("3ï¸âƒ£  ë¬¸ë‹¨ ë¶„ë¦¬ í™•ì¸")

    paragraphs = split_paragraphs(page_text)
    stats = get_paragraph_stats(paragraphs)

    print(f"ğŸ“Š í†µê³„:")
    print(f"   - ì´ ë¬¸ë‹¨ ìˆ˜: {stats['count']}")
    print(f"   - í‰ê·  ê¸¸ì´: {stats['avg_length']:.0f} ê¸€ì")
    print(f"   - ìµœì†Œ ê¸¸ì´: {stats['min_length']} ê¸€ì")
    print(f"   - ìµœëŒ€ ê¸¸ì´: {stats['max_length']} ê¸€ì")
    print(f"   - ì´ ê¸€ì ìˆ˜: {stats['total_chars']} ê¸€ì")

    if show_full:
        print(f"\nğŸ“ ì „ì²´ ë¬¸ë‹¨ ë‚´ìš©:")
        for idx, para in enumerate(paragraphs):
            print(f"\n{'='*100}")
            print(f"[ë¬¸ë‹¨ {idx+1}/{len(paragraphs)}] ({len(para)} ê¸€ì)")
            print(f"{'='*100}")
            print(para)
    else:
        print(f"\nğŸ“ ê° ë¬¸ë‹¨ ë¯¸ë¦¬ë³´ê¸°:")
        for idx, para in enumerate(paragraphs):
            preview = para[:100].replace('\n', ' ')
            print(f"\n   [{idx+1}] ({len(para)} ê¸€ì)")
            print(f"       {preview}...")

    return paragraphs


def test_idea_extraction(paragraphs, page_num, max_paragraphs=3):
    """4ë‹¨ê³„: í•µì‹¬ ì•„ì´ë””ì–´ ì¶”ì¶œ í™•ì¸ (LLM)"""
    print_section("4ï¸âƒ£  í•µì‹¬ ì•„ì´ë””ì–´ ì¶”ì¶œ í™•ì¸ (LLM)")

    print(f"âš¡ ì²˜ìŒ {min(max_paragraphs, len(paragraphs))}ê°œ ë¬¸ë‹¨ì— ëŒ€í•´ LLMìœ¼ë¡œ í•µì‹¬ ì•„ì´ë””ì–´ ì¶”ì¶œ ì¤‘...\n")

    results = []

    for idx, para_text in enumerate(paragraphs[:max_paragraphs]):
        print(f"ğŸ“ ë¬¸ë‹¨ {idx+1}/{min(max_paragraphs, len(paragraphs))}")
        print(f"   í…ìŠ¤íŠ¸: {para_text[:80].replace(chr(10), ' ')}...")

        # Create chunk
        chunk = ParagraphChunk(
            page_number=page_num,
            paragraph_index=idx,
            body_text=para_text,
        )

        # Create state
        state = State(
            chunk=chunk,
            book_id=None,  # DB ì €ì¥ ì•ˆ í•¨
            model_version="gemini-2.5-flash",
        )

        # Extract core idea
        state = extract_core_idea(state)

        if state.error:
            print(f"   âŒ ì˜¤ë¥˜: {state.error}\n")
            continue

        # Display results
        print(f"   âœ… ì¶”ì¶œ ì™„ë£Œ:")
        print(f"      ğŸ·ï¸  Core Idea: {state.result.concept or '(ì—†ìŒ)'}\n")

        results.append({
            'paragraph_index': idx,
            'core_idea': state.result.concept,
        })

    return results


def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    import argparse

    parser = argparse.ArgumentParser(description="PDF ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ë¯¸ë¦¬ë³´ê¸°")
    parser.add_argument("--pdf", type=str, default="AI Engineering.pdf", help="PDF íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--page", type=int, default=30, help="í…ŒìŠ¤íŠ¸í•  í˜ì´ì§€ ë²ˆí˜¸ (0ë¶€í„° ì‹œì‘)")
    parser.add_argument("--max-paragraphs", type=int, default=3, help="LLMìœ¼ë¡œ ì¶”ì¶œí•  ìµœëŒ€ ë¬¸ë‹¨ ìˆ˜")
    parser.add_argument("--full", action="store_true", help="ë¬¸ë‹¨ ì „ì²´ ë‚´ìš© í‘œì‹œ")
    parser.add_argument("--no-llm", action="store_true", help="LLM ì¶”ì¶œ ê±´ë„ˆë›°ê¸° (ë¬¸ë‹¨ë§Œ í™•ì¸)")

    args = parser.parse_args()

    print_section("ğŸš€ PDF ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ë¯¸ë¦¬ë³´ê¸° í…ŒìŠ¤íŠ¸")
    print(f"ğŸ“„ PDF: {args.pdf}")
    print(f"ğŸ“ í˜ì´ì§€: {args.page + 1}")

    try:
        # 1. ë©”íƒ€ë°ì´í„°
        metadata = test_metadata(args.pdf)

        # 2. í˜ì´ì§€ ì¶”ì¶œ
        page_text = test_page_extraction(args.pdf, args.page)

        # 3. ë¬¸ë‹¨ ë¶„ë¦¬
        paragraphs = test_paragraph_splitting(page_text, show_full=args.full)

        if not paragraphs:
            print("\nâš ï¸  ì¶”ì¶œëœ ë¬¸ë‹¨ì´ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í˜ì´ì§€ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.")
            return

        # 4. í•µì‹¬ ì•„ì´ë””ì–´ ì¶”ì¶œ
        if args.no_llm:
            print_section("4ï¸âƒ£  í•µì‹¬ ì•„ì´ë””ì–´ ì¶”ì¶œ ê±´ë„ˆë›°ê¸°")
            print("â„¹ï¸  --no-llm ì˜µì…˜ìœ¼ë¡œ LLM ì¶”ì¶œì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            results = []
        else:
            results = test_idea_extraction(paragraphs, args.page, args.max_paragraphs)

        # ìµœì¢… ìš”ì•½
        print_section("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ - ìš”ì•½")
        print(f"ğŸ“š ì±…: {metadata['title']}")
        print(f"ğŸ“„ í˜ì´ì§€: {args.page + 1}/{metadata['total_pages']}")
        print(f"ğŸ“ ë¬¸ë‹¨ ìˆ˜: {len(paragraphs)}")

        if not args.no_llm:
            print(f"ğŸ’¡ ì•„ì´ë””ì–´ ì¶”ì¶œ: {len(results)}/{min(args.max_paragraphs, len(paragraphs))}")

            if results:
                print(f"\nğŸ·ï¸  ì¶”ì¶œëœ Core Ideas:")
                unique_core_ideas = set(r['core_idea'] for r in results if r['core_idea'])
                if unique_core_ideas:
                    for core_idea in unique_core_ideas:
                        print(f"   - {core_idea}")
                else:
                    print(f"   (Core Ideaê°€ ì¶”ì¶œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤)")

        print(f"\n{'='*80}")
        print("ğŸ‰ ëª¨ë“  ë‹¨ê³„ê°€ ì •ìƒì ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤!")
        print(f"{'='*80}\n")

    except FileNotFoundError:
        print(f"\nâŒ ì˜¤ë¥˜: PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.pdf}")
        print(f"   í˜„ì¬ ë””ë ‰í† ë¦¬: {os.getcwd()}")

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
