from langchain_core.prompts import ChatPromptTemplate
from tqdm import tqdm

from src.workflow.state import PipelineState
from src.model.model import get_default_llm
from src.model.schemas import ExtractedIdea, HierarchicalChunk
from src.prompts.extraction import EXTRACTION_PROMPT, HUMAN_PROMPT
from src.utils.pdf.hierarchy_detector import split_into_paragraphs
from src.db.connection import get_session
from src.db.models import ParagraphChunk as DBParagraphChunk, KeyIdea
from src.workflow.utils import get_concept_from_idea


def process_section(state: PipelineState) -> PipelineState:
    """
    í˜„ì¬ ì„¹ì…˜ ì²˜ë¦¬: ì²­í‚¹ â†’ ì•„ì´ë””ì–´ ì¶”ì¶œ â†’ ì €ì¥.
    all_sections[current_section_index]ì˜ ì„¹ì…˜ì„ ì²˜ë¦¬í•˜ê³ 
    ì¸ë±ìŠ¤ë¥¼ ì¦ê°€ì‹œí‚´.
    """
    all_sections = state.get("all_sections", [])
    current_idx = state.get("current_section_index", 0)
    book_id = state.get("book_id")
    total_sections = len(all_sections)

    # ë²”ìœ„ ì²´í¬
    if current_idx >= total_sections:
        return state

    section_info = all_sections[current_idx]
    chapter = section_info["chapter"]
    section = section_info["section"]
    chapter_id = section_info.get("chapter_id")
    section_id = section_info.get("section_id")
    hierarchy_path = section_info.get("hierarchy_path", "")

    section_text = section.content
    stats = state.get("stats", {})

    # ì§„í–‰ë¥  í‘œì‹œ
    progress_pct = (current_idx + 1) / total_sections * 100
    section_title = section.title[:30] + "..." if len(section.title) > 30 else section.title
    print(f"\rğŸ“ [{current_idx + 1}/{total_sections}] ({progress_pct:.1f}%) {chapter.title[:20]}.. > {section_title}", end="", flush=True)

    # ë„ˆë¬´ ì§§ì€ ì„¹ì…˜ ìŠ¤í‚µ
    if len(section_text.strip()) < 100:
        return {
            **state,
            "current_section_index": current_idx + 1,
            "stats": stats,
        }

    try:
        # 1. ì²­í‚¹ (LLM ê¸°ë°˜ ë¬¸ë‹¨ ë¶„í• )
        chunks = _chunk_section(
            section_text=section_text,
            section_title=section.title,
            chapter_id=chapter_id,
            chapter_title=chapter.title,
            hierarchy_path=hierarchy_path,
            section_level=section.level,
        )

        stats["total_paragraphs"] = stats.get("total_paragraphs", 0) + len(chunks)

        # 2. ê° ì²­í¬ ì²˜ë¦¬: ì•„ì´ë””ì–´ ì¶”ì¶œ â†’ ì¤‘ë³µ ì²´í¬ â†’ ì €ì¥
        for i, chunk in enumerate(chunks):
            chunk.section_id = section_id

            # ì•ë’¤ ë¬¸ë‹¨ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
            prev_text = chunks[i - 1].text if i > 0 else ""
            next_text = chunks[i + 1].text if i < len(chunks) - 1 else ""

            result = _process_chunk(
                chunk=chunk,
                book_id=book_id,
                chapter_id=chapter_id,
                section_id=section_id,
                prev_text=prev_text,
                next_text=next_text,
            )

            if result.get("saved"):
                stats["total_ideas"] = stats.get("total_ideas", 0) + 1
            if result.get("is_duplicate"):
                stats["duplicates_skipped"] = stats.get("duplicates_skipped", 0) + 1

        stats["completed_sections"] = stats.get("completed_sections", 0) + 1

    except Exception as e:
        stats["failed_sections"] = stats.get("failed_sections", 0) + 1
        print(f"   âš ï¸ ì„¹ì…˜ '{section.title}' ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

    return {
        **state,
        "current_section_index": current_idx + 1,
        "stats": stats,
    }


def _chunk_section(
    section_text: str,
    section_title: str,
    chapter_id: int,
    chapter_title: str,
    hierarchy_path: str,
    section_level: int,
) -> list[HierarchicalChunk]:
    """ì„¹ì…˜ì„ ì²­í¬ë¡œ ë¶„í• ."""
    try:
        # LLM ê¸°ë°˜ ë¬¸ë‹¨ ë¶„í• 
        paragraphs = split_into_paragraphs(
            text=section_text,
            section_title=section_title,
        )

        chunks = []
        for i, para in enumerate(paragraphs):
            chunk = HierarchicalChunk(
                text=para["text"],
                chapter_id=chapter_id,
                chapter_title=chapter_title,
                section_title=section_title,
                paragraph_index=i,
                chapter_paragraph_index=i,
                start_char=para.get("start_char", 0),
                end_char=para.get("end_char", 0),
                section_level=section_level,
                detection_method="llm",
                hierarchy_path=hierarchy_path,
            )
            chunks.append(chunk)

        return chunks

    except Exception:
        # í´ë°±: ê°„ë‹¨í•œ ë¶„í• 
        return _simple_split(
            text=section_text,
            chapter_id=chapter_id,
            chapter_title=chapter_title,
            section_title=section_title,
            hierarchy_path=hierarchy_path,
        )


def _simple_split(
    text: str,
    chapter_id: int = None,
    chapter_title: str = None,
    section_title: str = None,
    hierarchy_path: str = "",
    min_length: int = 100,
    max_length: int = 1500,
) -> list[HierarchicalChunk]:
    """ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ í…ìŠ¤íŠ¸ ë¶„í•  (í´ë°±ìš©)."""
    raw_chunks = text.split("\n\n")
    chunks = []
    current_chunk = ""
    paragraph_index = 0
    char_offset = 0

    for raw in raw_chunks:
        raw = raw.strip()
        if not raw:
            continue

        if current_chunk:
            current_chunk += "\n\n" + raw
        else:
            current_chunk = raw

        if len(current_chunk) >= max_length:
            if len(current_chunk) >= min_length:
                chunks.append(HierarchicalChunk(
                    text=current_chunk,
                    chapter_id=chapter_id,
                    chapter_title=chapter_title,
                    section_title=section_title,
                    paragraph_index=paragraph_index,
                    chapter_paragraph_index=paragraph_index,
                    start_char=char_offset,
                    end_char=char_offset + len(current_chunk),
                    detection_method="fallback",
                    hierarchy_path=hierarchy_path,
                ))
                char_offset += len(current_chunk)
                paragraph_index += 1
            current_chunk = ""

    if current_chunk and len(current_chunk) >= min_length:
        chunks.append(HierarchicalChunk(
            text=current_chunk,
            chapter_id=chapter_id,
            chapter_title=chapter_title,
            section_title=section_title,
            paragraph_index=paragraph_index,
            chapter_paragraph_index=paragraph_index,
            start_char=char_offset,
            end_char=char_offset + len(current_chunk),
            detection_method="fallback",
            hierarchy_path=hierarchy_path,
        ))

    return chunks


def _process_chunk(
    chunk: HierarchicalChunk,
    book_id: int,
    chapter_id: int,
    section_id: int,
    prev_text: str = "",
    next_text: str = "",
) -> dict:
    """
    ë‹¨ì¼ ì²­í¬ ì²˜ë¦¬: ì•„ì´ë””ì–´ ì¶”ì¶œ â†’ ì¤‘ë³µ ì²´í¬ â†’ ì €ì¥.

    Returns:
        {"saved": bool, "is_duplicate": bool, "error": str | None}
    """
    chunk_text = chunk.text

    if not chunk_text or len(chunk_text.strip()) < 50:
        return {"saved": False, "is_duplicate": False}

    try:
        # 1. ì•„ì´ë””ì–´ ì¶”ì¶œ (ì»¨í…ìŠ¤íŠ¸ í¬í•¨)
        extracted_idea = _extract_idea(
            chunk_text,
            hierarchy_path=chunk.hierarchy_path,
            prev_text=prev_text,
            next_text=next_text,
        )

        if not extracted_idea:
            return {"saved": False, "is_duplicate": False}

        # 2. ì¤‘ë³µ ì²´í¬
        concept = get_concept_from_idea(extracted_idea)
        is_duplicate = _check_duplicate(concept, book_id)

        if is_duplicate:
            return {"saved": False, "is_duplicate": True}

        # 3. DB ì €ì¥
        _save_to_db(
            chunk=chunk,
            extracted_idea=extracted_idea,
            book_id=book_id,
            chapter_id=chapter_id,
            section_id=section_id,
        )

        return {"saved": True, "is_duplicate": False}

    except Exception as e:
        return {"saved": False, "is_duplicate": False, "error": str(e)}


def _get_first_sentence(text: str) -> str:
    """í…ìŠ¤íŠ¸ì˜ ì²« ë¬¸ì¥ ì¶”ì¶œ (ìµœëŒ€ 150ì)."""
    if not text:
        return "N/A"
    # ì²« ë¬¸ì¥ ì¶”ì¶œ (ë§ˆì¹¨í‘œ, ë¬¼ìŒí‘œ, ëŠë‚Œí‘œ ê¸°ì¤€)
    for i, char in enumerate(text):
        if char in '.?!' and i > 20:  # ìµœì†Œ 20ì ì´í›„
            return text[:i+1].strip()[:150]
    # ë§ˆì¹¨í‘œê°€ ì—†ìœ¼ë©´ ì²« 150ì
    return text[:150].strip() + "..." if len(text) > 150 else text.strip()


def _extract_idea(
    chunk_text: str,
    hierarchy_path: str = "",
    prev_text: str = "",
    next_text: str = "",
) -> ExtractedIdea | None:
    """ì²­í¬ì—ì„œ ì•„ì´ë””ì–´ ì¶”ì¶œ (ì»¨í…ìŠ¤íŠ¸ ì •ë³´ í¬í•¨)."""
    try:
        llm = get_default_llm()
        structured_llm = llm.with_structured_output(ExtractedIdea, method="json_mode")

        prompt = ChatPromptTemplate.from_messages([
            ("system", EXTRACTION_PROMPT),
            ("human", HUMAN_PROMPT),
        ])

        chain = prompt | structured_llm
        return chain.invoke({
            "text": chunk_text,
            "hierarchy_path": hierarchy_path or "N/A",
            "prev_summary": _get_first_sentence(prev_text),
            "next_summary": _get_first_sentence(next_text),
        })

    except Exception:
        return None


def _check_duplicate(concept: str, book_id: int) -> bool:
    """ì¤‘ë³µ ì•„ì´ë””ì–´ ì²´í¬."""
    if not concept:
        return False

    try:
        session = get_session()
        try:
            query = session.query(KeyIdea).filter(
                KeyIdea.core_idea_text == concept
            )
            if book_id:
                query = query.filter(KeyIdea.book_id == book_id)

            return query.first() is not None
        finally:
            session.close()
    except Exception:
        return False


def _save_to_db(
    chunk: HierarchicalChunk,
    extracted_idea: ExtractedIdea,
    book_id: int,
    chapter_id: int,
    section_id: int,
) -> None:
    """ì²­í¬ì™€ ì•„ì´ë””ì–´ë¥¼ DBì— ì €ì¥."""
    session = get_session()
    try:
        # ParagraphChunk ì €ì¥
        db_chunk = DBParagraphChunk(
            book_id=book_id,
            chapter_id=chapter_id,
            section_id=section_id,
            paragraph_index=chunk.paragraph_index,
            chapter_paragraph_index=chunk.chapter_paragraph_index,
            body_text=chunk.text,
        )
        session.add(db_chunk)
        session.flush()

        # KeyIdea ì €ì¥
        concept = get_concept_from_idea(extracted_idea)
        db_idea = KeyIdea(
            chunk_id=db_chunk.id,
            book_id=book_id,
            core_idea_text=concept,
        )
        session.add(db_idea)
        session.commit()

    except Exception as e:
        session.rollback()
        raise e
    finally:
        session.close()


def route_sections(state: PipelineState) -> str:
    """
    ì„¹ì…˜ ìˆœíšŒ ë¼ìš°í„°.

    ë‹¤ìŒ ì„¹ì…˜ì´ ìˆìœ¼ë©´ 'continue', ì—†ìœ¼ë©´ 'finalize'.
    """
    current_idx = state.get("current_section_index", 0)
    all_sections = state.get("all_sections", [])

    if current_idx < len(all_sections):
        return "continue"
    else:
        return "finalize"
